# -*- coding: utf-8 -*-
"""pinned_repos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mJj0neHszyyRblTkoIPeiLE7dAQC7pEx
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

orgs = [
    'python',
    'rust-lang',
    'golang',
    'torvalds/linux ',
    'apache',
    'mozilla',
    'sagemath',
    'kubernetes',
    'aws',
    'facebookresearch ',
    'google',
    'google-research ',
    'tensorflow',
    'openai',
    'zcash',
    'OffchainLabs',
    'ethereum-optimism',
    'Layr-Labs',
    'matter-labs',
    'solana-labs',
    'brave',
    'filecoin-project',
    'ipfs',
    'protocol',
    '0xPolygon',
    'cardano-foundation',
    'near',
    'stellar',
    'dashpay',
    'tezos',
    'algorand',
]

pinned_repos = {}

for org in orgs:
    url = f'https://github.com/{org}'
    response = requests.get(url)

    if response.status_code == 200:
        html_content = response.text
    else:
        print(f"Failed to retrieve the page {org}. Status code: {response.status_code}")
        continue

    soup = BeautifulSoup(html_content, 'html.parser')
    pinned = soup.find('div', class_='js-pinned-items-reorder-container')
    if pinned is None:
        print(f"No pinned found for {org}")
        continue
    repo_spans = pinned.find_all('span', class_='repo')

    pinned_repos[org] = [span.text.strip() for span in repo_spans]


new_dict = {"facebookresearch": ["segment-anything", "fairseq", "detectron2", "faiss", "Detectron", "fastText"], "google-research": ["google-research"],"torvalds":["linux"]}
pinned_repos.update(new_dict)

for org, repos in pinned_repos.items():
    print(f'{org}\t{repos}')


Information=[]
for org, repos in pinned_repos.items():
    org_df = pd.read_csv(f"{org}.csv")
    for repo in repos:
      specific_row_series = org_df[org_df['name'] == repo].squeeze()
      desc=specific_row_series["description"]
      each_tuple = (org, repo, desc)
      Information.append(each_tuple)

import pandas as pd


pinned_repos = {'python': ['cpython', 'mypy', 'pythondotorg', 'peps', 'typeshed', 'devguide'],
'rust-lang': ['rust', 'cargo', 'rfcs'],
'golang': ['go'],
'mozilla': ['pdf.js', 'DeepSpeech', 'send', 'BrowserQuest', 'TTS', 'nunjucks'],
'sagemath': ['sage', 'website', 'publications', 'sage-shell-mode', 'sagecell', 'sagetex'],
'kubernetes': ['kubernetes', 'enhancements', 'community', 'website', 'test-infra', 'examples'],
'aws': ['aws-cli', 'serverless-application-model', 'aws-cdk', 'amazon-sagemaker-examples', 's2n-tls', 'aws-sdk-go-v2'],
'google': ['material-design-icons', 'guava', 'zx', 'styleguide', 'leveldb', 'googletest'],
'tensorflow': ['tensorflow', 'docs', 'community'],
'openai': ['openai-cookbook', 'whisper', 'evals', 'openai-python', 'tiktoken', 'openai-node'],
'zcash': ['zcash', 'halo2', 'librustzcash', 'zips', 'mpc', 'libsnark'],
'OffchainLabs': ['nitro', 'token-bridge-contracts', 'arbitrum-sdk', 'arbitrum-tutorials', 'arbitrum-token-bridge', 'arbitrum-docs'],
'ethereum-optimism': ['optimism', 'specs', 'docs', 'community-hub', 'OPerating-manual', 'ecosystem-contributions'],
'Layr-Labs': ['eigenlayer-contracts', 'incredible-squaring-avs', 'eigenda', 'eigenda-operator-setup', 'eigenlayer-cli', 'eigenlayer-middleware'],
'matter-labs': ['zksync-era', 'era-contracts', 'era-sync_vm', 'awesome-zero-knowledge-proofs'],
'solana-labs': ['solana-program-library', 'solana'],
'brave': ['brave-browser', 'brave-core', 'adblock-rust', 'goggles-quickstart'],
'filecoin-project': ['community', 'FIPs', 'lotus', 'rust-fil-proofs', 'builtin-actors', 'ref-fvm'],
'ipfs': ['specs', 'ipfs', 'ipfs-desktop', 'ipfs-companion', 'kubo', 'helia'],
'protocol': ['arg', 'research', 'research-grants', 'ResNetLab'],
'0xPolygon': ['polygon-edge', 'fx-portal', 'cdk-validium-node', 'chain-indexer-framework', 'polygon-docs', 'account-binary-search-tree'],
'cardano-foundation': ['CIPs'],
'near': ['nearcore', 'NEPs', 'core-contracts', 'near-api-js', 'create-near-app', 'near-cli-rs'],
'stellar': ['stellar-protocol', 'stellar-core', 'js-stellar-sdk', 'rs-soroban-sdk', 'soroban-rpc', 'soroban-cli'],
'dashpay': ['dash', 'platform', 'grovedb', 'tenderdash', 'dash-wallet', 'dashwallet-ios'],
'tezos': ['tezos-mirror'],
'algorand': ['go-algorand', 'js-algorand-sdk', 'pyteal', 'py-algorand-sdk', 'sandbox', 'go-algorand-sdk'], }

new_dict = {"facebookresearch": ["segment-anything", "fairseq", "detectron2", "faiss", "Detectron", "fastText"], "google-research": ["google-research"],"linux":["linux"]}
pinned_repos.update(new_dict)

for org, repos in pinned_repos.items():
    print(f'{org}\t{repos}')


Information=[]
for org, repos in pinned_repos.items():
    org_df = pd.read_csv(f"{org}.csv")
    for repo in repos:
      specific_row_series = org_df[org_df['name'] == repo].squeeze()
      desc=specific_row_series["description"]
      each_tuple = (org, repo, desc)
      Information.append(each_tuple)

!pip3 install -q openai

from openai import OpenAI

print(len(Information))

#############################################################
### without org name provided, feed in repo names and description

###results: not entirely based on original orgs
#############################################################

client = OpenAI(api_key='xxxxxxxxxxx')

instruction = '''Based on the content provided, group all repositories into some clusters and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for idx, item in enumerate(Information):
  prompt = prompt + f'{item[1]}:{item[2]}\n'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-4",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)

############################################################
### with org name provided

###results: based on original orgs
###########################################################

client = OpenAI(api_key='xxxxxxxxxx')

instruction = '''Based on the content provided, group all repositories into some clusters and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for idx, item in enumerate(Information):
  prompt = prompt + f'{item[1]}:{item[2]} and it is under organization named {item[0]}'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-4",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)

############################################################
###without org name and repo name provided

###results: not entirely based on original orgs, similar to feed in repos name and description
###########################################################



client = OpenAI(api_key='xxxxxxxxxxx')

instruction = '''Based on the content provided, group all repositories into some clusters, and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for idx, item in enumerate(Information):
  prompt = prompt + f'{item[2]}\n'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-4",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)

#########################################################
###with clustering instruction, with org name provided

###result: cluster based on original orgs
########################################################

client = OpenAI(api_key='xxxxxxxxxxxxxxxxxxxx')

instruction = '''Based on the content provided, group all repositories into some clusters based on primary technological domain or application area that each repository contributes to, instead of basing on organization names only, and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for idx, item in enumerate(Information):
  prompt = prompt + f'{item[1]}:{item[2]} and it is under organization named {item[0]}'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-4",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)