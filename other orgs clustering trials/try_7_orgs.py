# -*- coding: utf-8 -*-
"""try 7 orgs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16TbTA458Uzv3LCq0QqD-O6NKkmDxPXA8
"""

!pip3 install -q openai

from openai import OpenAI

import pandas as pd

# Load the CSV into a DataFrame
al = pd.read_csv("algorand.csv")

# Initialize an empty list to store the information feed
information_feed = []

# Iterate over each row in the DataFrame
for index, row in al.iterrows():
    # Create a string with the desired information
    feed = str(row["name"]) + " " + (str(row["description"]) if pd.notnull(row["description"]) else " ")# + (str(row["readme"]) if pd.notnull(row["readme"]) else " ")
    # Append the string to the information feed list
    information_feed.append(feed)

# Feed ChatGPT with all repo descriptions and instructions.

client = OpenAI(api_key='xxxxxx')

instruction = '''Based on the content provided, group all repositories into up to 6 clusters and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for i, desc in enumerate(information_feed):
  prompt = prompt + f'{desc}\n'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)

import pandas as pd

# Load the CSV into a DataFrame
al = pd.read_csv("cardano-foundation.csv")

# Initialize an empty list to store the information feed
information_feed = []

# Iterate over each row in the DataFrame
for index, row in al.iterrows():
    # Create a string with the desired information
    feed = str(row["name"]) + " " + (str(row["description"]) if pd.notnull(row["description"]) else " ")# + (str(row["readme"]) if pd.notnull(row["readme"]) else " ")
    # Append the string to the information feed list
    information_feed.append(feed)

# Feed ChatGPT with all repo descriptions and instructions.

client = OpenAI(api_key='xxxx')

instruction = '''Based on the content provided, group all repositories into up to 6 clusters and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for i, desc in enumerate(information_feed):
  prompt = prompt + f'{desc}\n'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)

import pandas as pd

# Load the CSV into a DataFrame
al = pd.read_csv("dashpay.csv")

# Initialize an empty list to store the information feed
information_feed = []

# Iterate over each row in the DataFrame
for index, row in al.iterrows():
    # Create a string with the desired information
    feed = str(row["name"]) + " " + (str(row["description"]) if pd.notnull(row["description"]) else " ")# + (str(row["readme"]) if pd.notnull(row["readme"]) else " ")
    # Append the string to the information feed list
    information_feed.append(feed)

# Feed ChatGPT with all repo descriptions and instructions.

client = OpenAI(api_key='xxxxx')

instruction = '''Based on the content provided, group all repositories into up to 6 clusters and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for i, desc in enumerate(information_feed):
  prompt = prompt + f'{desc}\n'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)

import pandas as pd

# Load the CSV into a DataFrame
al = pd.read_csv("zcash.csv")

# Initialize an empty list to store the information feed
information_feed = []

# Iterate over each row in the DataFrame
for index, row in al.iterrows():
    # Create a string with the desired information
    feed = str(row["name"]) + " " + (str(row["description"]) if pd.notnull(row["description"]) else " ")# + (str(row["readme"]) if pd.notnull(row["readme"]) else " ")
    # Append the string to the information feed list
    information_feed.append(feed)

# Feed ChatGPT with all repo descriptions and instructions.

client = OpenAI(api_key='xxxxx')

instruction = '''Based on the content provided, group all repositories into up to 6 clusters and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for i, desc in enumerate(information_feed):
  prompt = prompt + f'{desc}\n'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)

import pandas as pd

# Load the CSV into a DataFrame
al = pd.read_csv("stellar.csv")

# Initialize an empty list to store the information feed
information_feed = []

# Iterate over each row in the DataFrame
for index, row in al.iterrows():
    # Create a string with the desired information
    feed = str(row["name"]) + " " + (str(row["description"]) if pd.notnull(row["description"]) else " ")# + (str(row["readme"]) if pd.notnull(row["readme"]) else " ")
    # Append the string to the information feed list
    information_feed.append(feed)

# Feed ChatGPT with all repo descriptions and instructions.

client = OpenAI(api_key='xxxx')

instruction = '''Based on the content provided, group all repositories into up to 6 clusters and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for i, desc in enumerate(information_feed):
  prompt = prompt + f'{desc}\n'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)

import pandas as pd

# Load the CSV into a DataFrame
al = pd.read_csv("tezos.csv")

# Initialize an empty list to store the information feed
information_feed = []

# Iterate over each row in the DataFrame
for index, row in al.iterrows():
    # Create a string with the desired information
    feed = str(row["name"]) + " " + (str(row["description"]) if pd.notnull(row["description"]) else " ")# + (str(row["readme"]) if pd.notnull(row["readme"]) else " ")
    # Append the string to the information feed list
    information_feed.append(feed)

# Feed ChatGPT with all repo descriptions and instructions.

client = OpenAI(api_key='xxxxx')

instruction = '''Based on the content provided, group all repositories into up to 6 clusters and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for i, desc in enumerate(information_feed):
  prompt = prompt + f'{desc}\n'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)

import pandas as pd

# Load the CSV into a DataFrame
al = pd.read_csv("solana-labs.csv")

# Initialize an empty list to store the information feed
information_feed = []

# Iterate over each row in the DataFrame
for index, row in al.iterrows():
    # Create a string with the desired information
    feed = str(row["name"]) + " " + (str(row["description"]) if pd.notnull(row["description"]) else " ")# + (str(row["readme"]) if pd.notnull(row["readme"]) else " ")
    # Append the string to the information feed list
    information_feed.append(feed)

# Feed ChatGPT with all repo descriptions and instructions.

client = OpenAI(api_key='xxxxx')

instruction = '''Based on the content provided, group all repositories into up to 6 clusters and provide a short definition of each cluster. Note that each cluster should contain more than 1 repository. In addition, the topics of repositories in the cluster should be as similar as possible.The repositories are primarily software development repositories.'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it'''

messages = [
      {"role": "system", "content": instruction},
  ]

# Build the prompt to integrate all repo descriptions into it
prompt = ''

for i, desc in enumerate(information_feed):
  prompt = prompt + f'{desc}\n'

# prompt: 'these are ... repo 1 desc is ...; repo 2 ...'
messages.append({"role": "user", 'content': prompt})
completion = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=messages,
  seed = 3407
)

import pickle

with open('completion', 'wb') as f:
  pickle.dump(completion, f)

print(completion.choices[0].message.content)