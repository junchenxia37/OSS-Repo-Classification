[{"name": "abm1559", "desc": "Transaction markets in Python", "readme": "Agent-based simulation environment for EIP 1559. Notebooks Open research notebooks to present key ideas of EIP 1559 and fee markets. Introduction to EIP 1559 We present a brief introduction to the rationale behind EIP 1559 as well as simulate the dynamics of the mechanism, including the basefee. Stationary behaviour of EIP 1559 A good benchmark case to test fee market proposals is stationary demand. In this notebook, we simulate random waves of new users who have value and costs all drawn from the same distribution. Users decide whether to transact or not based on their values and costs. We show that in this environment, the basefee always settles to a stationary level that depends on the congestion of the chain, i.e., how large the demand is. Strategic users in EIP 1559 Before reaching stationarity, or when demand varies rapidly, the market endures transitionary periods where either too many users or too few decide to transact. When there are too few, the basefee naturally decreases. But when there are too many, users have an incentive to increase their premiums during this transitionary period, until sufficiently many users are discouraged by the basefee level, at which point being strategic is no longer helpful. We investigate this dynamics and briefly compare the efficiency in both strategic and non-strategic cases. The floating escalator: Combining 1559 and the escalator As shown by the previous notebook, strategic users in 1559 sometimes have the incentive to enter tip auctions when demand increases rapidly. The escalator is a proposal to automate in protocol the \"transaction resubmission\" pattern where a strategic user increases their bid over time until inclusion. Combined with 1559 to obtain a good default starting bid, the escalator could help users with various time preferences optimise their resubmission during demand shifts. In this introductory notebook, we present the behaviour of various user strategies and discuss their efficiency. The stable road to EIP 1559: Transitioning out of first-price auctions 1559 will be introduced by a soft transition out of the legacy behaviour, with legacy transactions cast into 1559 format by setting their parameters from the declared gas price. This notebook investigates first the behaviour of legacy users in an environment where price references are provided by distributional oracles. We observe the inefficiencies of the legacy, first-price auction-based systems: sticky prices leading to overpayment and \"bubbles\" driven by high-value users. Meanwhile the introduction of the basefee and basefee-following users (explored in previous notebooks) \"cools\" the market, reducing the gap between transaction fees and true market-clearing price. Publications Reijsbergen, D., Sridhar, S., Monnot, B., Leonardos, S., Skoulakis, S., & Piliouras, G. (2021). Transaction Fees on a Honeymoon: Ethereum's EIP-1559 One Month Later. arXiv preprint arXiv:2110.04753 . arXiv link Leonardos, S., Monnot, B., Reijsbergen, D., Skoulakis, S., & Piliouras, G. (2021). Dynamical Analysis of the EIP-1559 Ethereum Fee Market. arXiv preprint arXiv:2102.10567 . arXiv link Running the notebooks You can simply run the following commands in a terminal. If you prefer, use a virtual environment to install packages in a local folder. ```shell\ngit clone https://github.com/ethereum/abm1559.git\ncd abm1559 Optional: use a virtual environment python -m venv env Unix source env/bin/activate Windows .\\env\\Scripts\\activate pip install -r requirements.txt\njupyter lab\n```"}, {"name": "act", "desc": "Smart contract specification language", "readme": "Act Act is a formal specification language, designed to allow for the construction of an exhaustive,\nmathematically rigorous description of evm programs. Act allows diverse toolchains to interoperate\non a single specification, with each generating and exchanging different kinds of knowledge. It has\na built-in analysis engine that can automatically prove properties about the specification itself,\nas well as an integrated symbolic execution engine (based on hevm) that can prove equivalence\nbetween a specification and a given bytecode object. Finally, specifications can be exported into\nhigher level reasoning tools (e.g. theorem provers, economic analysis tooling), allowing for the\nverification of properties of almost arbitrary complexity, all with a proof chain right down to the\nbytecode level. It extends on the previous Act project. More in depth documentation can be found in The Act Book . Building With nix: sh\nnix build Developing Enter a nix-shell to get the dependencies of the project: sh\nnix develop you can then use cabal as normal: sh\ncd src\ncabal build # build\ncabal repl  # enter a repl instance to execute the unit tests: sh\nmake test # run all tests\ncd src && cabal v2-test # run haskell tests To update the project dependencies run: sh\nnix flake update"}, {"name": "aio-run-in-process", "desc": "Async friendly replacement for multiprocessing for asyncio or trio", "readme": "aio-run-in-process Simple aio friendly replacement for multiprocessing Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install aio-run-in-process Developer Setup If you would like to hack on aio-run-in-process, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/aio-run-in-process.git\ncd aio-run-in-process\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 aio_run_in_process/ tests/ -c \"clear; flake8 aio_run_in_process tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on aio-run-in-process failed'\" ../tests ../aio_run_in_process Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). To include changes made with each\nrelease, update \"docs/releases.rst\" with the changes, and apply commit directly to master \nbefore release. If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "aleth", "desc": "Aleth \u2013 Ethereum C++ client, tools and libraries", "readme": "Aleth \u2013 Ethereum C++ client, tools and libraries The collection of C++ libraries and tools for Ethereum,\nformerly known as cpp-ethereum project.\nThis includes the full Ethereum client aleth . \u26a0\ufe0f This project has been discontinued and is no longer maintained. Contact Chat in aleth channel on Gitter . Report bugs, issues or feature requests using GitHub issues . Usage The Ethereum Documentation site hosts the aleth homepage , which\nhas a Quick Start section. Operating system | Status\n---------------- | ----------\nUbuntu and macOS | Windows          | Install Download release binaries https://github.com/ethereum/aleth/releases Using docker images Aleth: bash\ndocker run ethereum/aleth --help Testeth: bash\ndocker run ethereum/testeth --help Building from source Get the source code Git and GitHub are used to maintain the source code. Clone the repository by: shell\ngit clone --recursive https://github.com/ethereum/aleth.git\ncd aleth The --recursive option is important. It orders git to clone additional\nsubmodules to build the project.\nIf you missed --recursive option, you are able to correct your mistake with command git submodule update --init . Install CMake CMake is used to control the build configuration of the project. Latest version of CMake is required\n(at the time of writing 3.9.3 is the minimum ).\nWe strongly recommend you to install CMake by downloading and unpacking the binary\ndistribution  of the latest version available on the CMake download page . The CMake package available in your operating system can also be installed\nand used if it meets the minimum version requirement. Alternative method The repository contains the scripts/install_cmake.sh script that downloads\na fixed version of CMake and unpacks it to the given directory prefix.\nExample usage: scripts/install_cmake.sh --prefix /usr/local . Build Configure the project build with the following command to create the build directory with the configuration. shell\nmkdir build; cd build  # Create a build directory.\ncmake ..               # Configure the project.\ncmake --build .        # Build all default targets. On Windows we support Visual Studio 2017, and 2019. You should generate a Visual Studio solution file ( .sln ) for the 64-bit architecture via the following command: Visual Studio 2017 : cmake .. -G \"Visual Studio 15 2017 Win64\" Visual Studio 2019 : cmake .. -G \"Visual Studio 16 2019\" -A x64 After the necessary dependencies have been downloaded and built and the solution has been generated, aleth.sln can be found in the build directory. Common Issues Building on Windows LINK : fatal error LNK1158: cannot run 'rc.exe' Rc.exe is the Microsoft Resource Compiler . It's distributed with the Windows SDK and is required for generating the Visual Studio solution file. It can be found in the following directory: %ProgramFiles(x86)%\\Windows Kits\\<OS major version>\\bin\\<OS full version>\\<arch>\\ If you hit this error, adding the directory to your path (and launching a new command prompt) should fix the issue. Contribute The current codebase is the work of many, many hands, with over 100 individual contributors over the course of its development. Our day-to-day development chat happens on the aleth Gitter channel. All contributions are welcome! We try to keep a list of tasks that are suitable\nfor newcomers under the tag help wanted .\nIf you have any questions, please do not hesitate to ask us about more information. Please read CONTRIBUTING and CODING_STYLE thoroughly before making alterations to the code base. All development goes in develop branch. Usage Note: The following is the output of ./aleth -h [--help] on Linux ```\nNAME:\n   aleth 1.7.2\nUSAGE:\n   aleth [options] WALLET USAGE:\n   account list                                List all keys available in wallet\n   account new                                 Create a new key and add it to wallet\n   account update [ | , ... ]    Decrypt and re-encrypt keys\n   account import [ | | ] Import keys from given source and place in wallet\n   wallet import Import a presale wallet CLIENT MODE (default):\n  --mainnet                               Use the main network protocol\n  --ropsten                               Use the Ropsten testnet\n  --test                                  Testing mode; disable PoW and provide test rpc interface\n  --config Configure specialised blockchain using given JSON information --ipc                                   Enable IPC server (default: on)\n  --ipcpath Set .ipc socket path (default: data directory)\n  --no-ipc                                Disable IPC server\n  --admin Specify admin session key for JSON-RPC (default: auto-generated and printed at start-up)\n  -K [ --kill ]                           Kill the blockchain first\n  -R [ --rebuild ]                        Rebuild the blockchain from the existing database\n  --rescue                                Attempt to rescue a corrupt database --import-presale Import a pre-sale key; you'll need to specify the password to this key\n  -s [ --import-secret ] Import a secret key into the key store\n  -S [ --import-session-secret ] Import a secret session into the key store\n  --master Give the master password for the key store; use --master \"\" to show a prompt\n  --password Give a password for a private key CLIENT TRANSACTING:\n  --ask Set the minimum ask gas price under which no transaction will be mined (default: 20000000000)\n  --bid Set the bid gas price to pay for transactions (default: 20000000000)\n  --unsafe-transactions  Allow all transactions to proceed without verification; EXTREMELY UNSAFE CLIENT NETWORKING:\n  -b [ --bootstrap ]              Connect to the default Ethereum peer servers (default unless --no-discovery used)\n  --no-bootstrap                  Do not connect to the default Ethereum peer servers (default only when --no-discovery is used)\n  -x [ --peers ] Attempt to connect to a given number of peers (default: 11)\n  --peer-stretch Give the accepted connection multiplier (default: 7)\n  --public-ip Force advertised public IP to the given IP (default: auto)\n  --listen-ip (: )       Listen on the given IP for incoming connections (default: 0.0.0.0)\n  --listen Listen on the given port for incoming connections (default: 30303)\n  -r [ --remote ] (: ) Connect to the given remote host (default: none)\n  --port Connect to the given remote port (default: 30303)\n  --network-id Only connect to other hosts with this network id\n  --allow-local-discovery         Include local addresses in the discovery process. Used for testing purposes.\n  --peerset Comma delimited list of peers; element format: type:enode://publickey@ipAddress[:port[?discport=port]]\n                                          Types:\n                                          default     Attempt connection when no other peers are available and pinning is disabled\n                                          required    Keep connected at all times Ports:\n                                      The first port argument is the tcp port used for direct communication among peers. If the second port\n                                      argument isn't supplied, the first port argument will also be the udp port used for node discovery.\n                                      If neither the first nor second port arguments are supplied, a default port of 30303 will be used for\n                                      both peer communication and node discovery. --no-discovery                  Disable node discovery; implies --no-bootstrap\n  --pin                           Only accept or connect to trusted peers CLIENT MINING:\n  -a [ --address ] Set the author (mining payout) address (default: auto)\n  -m [ --mining ] Enable mining; optionally for a specified number of blocks (default: off)\n  --extra-data arg                Set extra data for the sealed blocks BENCHMARKING MODE:\n  -M [ --benchmark ]           Benchmark for mining and exit\n  --benchmark-warmup Set the duration of warmup for the benchmark tests (default: 3)\n  --benchmark-trial Set the duration for each trial for the benchmark tests (default: 3)\n  --benchmark-trials Set the number of trials for the benchmark tests (default: 5) MINING CONFIGURATION:\n  -C [ --cpu ]                 When mining, use the CPU\n  -t [ --mining-threads ] Limit number of CPU/GPU miners to n (default: use everything available on selected platform)\n  --current-block Let the miner know the current block number at configuration time. Will help determine DAG size and required GPU memory\n  --disable-submit-hashrate    When mining, don't submit hashrate to node IMPORT/EXPORT MODES:\n  -I [ --import ] Import blocks from file\n  -E [ --export ] Export blocks to file\n  --from Export only from block n; n may be a decimal, a '0x' prefixed hash, or 'latest'\n  --to Export only to block n (inclusive); n may be a decimal, a '0x' prefixed hash, or 'latest'\n  --only Equivalent to --export-from n --export-to n\n  --format Set export format\n  --dont-check                Prevent checking some block aspects. Faster importing, but to apply only when the data is known to be valid\n  --download-snapshot Download Parity Warp Sync snapshot data to the specified path\n  --import-snapshot Import blockchain and state data from the Parity Warp Sync snapshot DATABASE OPTIONS:\n  --db (=leveldb)      Select database implementation. Available options are: leveldb, memorydb.\n  --db-path (=$HOME/.ethereum) Database path (for non-memory database options) VM OPTIONS:\n  --vm | (=legacy) Select VM implementation. Available options are: interpreter, legacy.\n  --evmc = EVMC option LOGGING OPTIONS:\n  -v [ --log-verbosity ] <0 - 4>        Set the log verbosity from 0 to 4 (default: 2).\n  --log-channels Space-separated list of the log channels to show (default: show all channels).\n                                        Channels: block blockhdr bq chain client debug discov error ethcap exec host impolite info net overlaydb p2pcap peer\n                                        rlpx rpc snap statedb sync timer tq trace vmtrace warn warpcap watch\n  --log-exclude-channels Space-separated list of the log channels to hide. --log-vmtrace                         Enable VM trace log (requires log-verbosity 4). GENERAL OPTIONS:\n  -d [ --data-dir ] Load configuration files and keystore from path (default: $HOME/.ethereum)\n  -V [ --version ]         Show the version and exit\n  -h [ --help ]            Show this help message and exit\n``` Tools The Aleth project includes the following tools in addition to the Aleth client:\n* aleth-bootnode : A C++ Ethereum discovery bootnode implementation\n* aleth-key : A rudimentary wallet\n* aleth-vm : An EVM bytecode runner tool\n* rlp : A RLP encoder/decoder tool\n* testeth : A consensus test generator/runner tool Mining This project is not suitable for Ethereum mining because the support for GPU mining\nhas been dropped some time ago including the ethminer tool. Use the ethminer tool from https://github.com/ethereum-mining/ethminer. Testing Details on how to run and debug the tests can be found here Documentation Internal documentation for developers . Outdated documentation for end users . License All contributions are made under the GNU General Public License v3 . See LICENSE ."}, {"name": "alethzero", "desc": "Former home of AlethZero, AlethOne and AlethFive (cpp-ethereum)", "readme": "Former home of AlethZero, AlethOne and AlethFive (cpp-ethereum) This repository was formerly the home of the Aleth C++ GUI applications for cpp-ethereum . Here is release announcement from when AlethOne and AlethZero were first released: AlethOne: Streamlined desktop client for mining AlethZero: Power-user desktop client These applications were discontinued because in each case the cost of maintenance ended up exceeding\nthe benefits which they were delivering to end-users: AlethFive was discontinued in February 2016 AlethOne was discontinued in March 2016 AlethZero was discontinued in July 2016 Our focus is now on HTML5-based GUI solutions such as remix , which\ncan be used within browser-solidity, Mist, Atom, Visual Studio Code, and other IDE integrations, rather than\nbuilding standalone C++ GUI applications. The final version of AlethFive was part of the webthree-umbrella-v1.1.4 release The final version of AlethOne was part of the webthree-umbrella-v1.2.2 release The final version of AlethZero was part of the webthree-umbrella-v1.2.9 release All of these releases were prior to the hard-fork of 20th July 2016 (at block #192000), so none of these\nreleases can be used with the currently active chain.  AlethFive was earlier yet, prior to Homestead."}, {"name": "alexandria", "desc": null, "readme": "Alexandria DHT Client for the Alexandria DHT network Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install alexandria Developer Setup If you would like to hack on alexandria, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/alexandria.git\ncd alexandria\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 alexandria/ tests/ -c \"clear; flake8 alexandria tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on alexandria failed'\" ../tests ../alexandria Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "annotated-spec", "desc": "Vitalik's annotated eth2 spec. Not intended to be \"the\" annotated spec; other documents like Ben Edgington's https://benjaminion.xyz/eth2-annotated-spec/ also exist. This one is intended to focus more on design rationale.", "readme": "Currently the following parts of the spec are available in annotated form: Phase 0 The Beacon Chain Beacon Chain Fork Choice Altair (Light client support, validator reward simplifications) Changes to the beacon chain Light client sync protocol Bellatrix (Merge) Beacon chain changes Fork choice (terminal PoW block verification) Capella (Withdrawals) Beacon chain changes (work in progress) Sharding Changes to the beacon chain"}, {"name": "async-service", "desc": "Lifecycle management for async applications", "readme": "async-service Lifecycle management for async applications Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install async-service Developer Setup If you would like to hack on async-service, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/async-service.git\ncd async-service\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 async_service/ tests/ -c \"clear; flake8 async_service tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on async-service failed'\" ../tests ../async_service Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "asyncio-cancel-token", "desc": "A cancelation pattern for asyncio applications", "readme": "asyncio-cancel-token Task cancellation pattern for asyncio applications. Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install asyncio-cancel-token Developer Setup If you would like to hack on asyncio-cancel-token, please check out the Ethereum Development Tactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/asyncio-cancel-token.git\ncd asyncio-cancel-token\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 cancel_token/ tests/ -c \"clear; flake8 cancel_token tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on asyncio-cancel-token failed'\" ../tests ../cancel_token Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "asyncio-run-in-process", "desc": "A simple asyncio friendly replacement for multiprocessing to run coroutines in a separate process.", "readme": "asyncio-run-in-process Simple asyncio friendly replacement for multiprocessing Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install asyncio-run-in-process Developer Setup If you would like to hack on asyncio-run-in-process, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/asyncio-run-in-process.git\ncd asyncio-run-in-process\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 asyncio_run_in_process/ tests/ -c \"clear; flake8 asyncio_run_in_process tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on asyncio-run-in-process failed'\" ../tests ../asyncio_run_in_process Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). To include changes made with each\nrelease, update \"docs/releases.rst\" with the changes, and apply commit directly to master \nbefore release. If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "awesome-remix", "desc": null, "readme": "Awesome Remix A curated list of Remix Project resources, tutorials & explanations List of content Remix URLs Remix Repositories Remix Plugin Repositories Remix Forums Documentation Tutorials/Blogs Miscellaneous Remix URLs Remix Online - https://remix.ethereum.org/ Remix Alpha - https://remix-alpha.ethereum.org/ Remix Beta - https://remix-beta.ethereum.org/ Remix Website - https://remix-project.org/ Remix Repositories Remix project - Remix IDE and Remix libraries Source Code. Remix website - Remix website. Remix desktop - Remix IDE desktop. Remix plugin - Remix plugin. Remix plugins directory - Remix plugins directory. Remix Alpha - Live deployment of the Remix IDE (alpha). Remix live - Live deployment of the Remix IDE. Remix Plugin Repositories Remix Script Runner - Plugin, responsible to run js/ts scripts on Remix IDE Remix LearnEth - Plugin to learn web3 development Remix Forums Remix Gitter - Remix gitter forum. Remix Workshop Gitter - Remix workshop gitter forum. Documentation Official doc - Remix official documentation. Tutorials/Blogs Publish your metadata and the source code to SWARM and IPFS [RemixIDE] Create a workshop for Solidity Low level interactions on Remix IDE First smart contract on Remix IDE Trust fund account on Remix IDE Create ERC20 without writing Solidity Solidity Smart Contract Tutorial With Building Real-World DAPP \u2014 Part 2: Create Your First Contract Miscellaneous Remix IDE server hosting - Host Ethereum's Remix-IDE on your own server."}, {"name": "beacon-APIs", "desc": "Collection of RESTful APIs provided by Ethereum Beacon nodes", "readme": "Ethereum Beacon APIs Collection of RESTful APIs provided by Ethereum Beacon nodes API browser: https://ethereum.github.io/beacon-APIs/ Outline This document outlines an application programming interface (API) which is exposed by a beacon node implementation of the Ethereum consensus layer specifications . The API is a REST interface, accessed via HTTP. The API should not, unless protected by additional security layers, be exposed to the public Internet as the API includes multiple endpoints which could open your node to denial-of-service (DoS) attacks through endpoints triggering heavy processing.\n Currently, the only supported return data type is JSON. The beacon node (BN) maintains the state of the beacon chain by communicating with other beacon nodes in the Ethereum network.\nConceptually, it does not maintain keypairs that participate with the beacon chain. The validator client (VC) is a conceptually separate entity which utilizes private keys\nto perform validator related tasks, called \"duties\", on the beacon chain.\n These duties include the production of beacon blocks and signing of attestations. The goal of this specification is to promote interoperability between various beacon node implementations. Render To render spec in browser you will need any http server to load index.html file\nin root of the repo. Python python -m http.server 8080 And api spec will render on http://localhost:8080 . NodeJs ```\nnpm install simplehttpserver -g OR yarn global add simplehttpserver simplehttpserver\n```\nAnd api spec will render on http://localhost:8000 . Usage Local changes will be observable if \"dev\" is selected in the \"Select a definition\" drop-down in the web UI. Users may need to tick the \"Disable Cache\" box in their browser's developer tools to see changes after modifying the source. Contributing Api spec is checked for lint errors before merge. To run lint locally, install linter with\n```\nnpm install -g @redocly/cli OR yarn global add @redocly/cli and run lint with redocly lint beacon-node-oapi.yaml\n``` Releasing Create and push tag Make sure info.version in beacon-node-oapi.yaml file is updated before tagging.  This will need to be a PR, and will get the release process started. CD will create github release and upload bundled spec file Create a second PR, containing the updated index.html . Also change back the info.version in beacon-node-api.yaml back to Dev The index.html file needs a new release entrypoint added to refer to the new release. Find the urls field, \n     and add the new release as the first entry in the list.\n     Entry should be in following format(replace <tag> with real tag name from step 1.): {url: \"./releases/<tag>/beacon-node-oapi.json\", name: \"<tag>\"},"}, {"name": "beacon-metrics", "desc": "Informative spec for beacon node metrics", "readme": "Ethereum Beacon metrics Discussion of beacon node metrics for Prometheus. License All code and generated test vectors are public domain under CC0"}, {"name": "beaconrunner", "desc": "Agent-based simulation environment for PoS Ethereum", "readme": "An agent-based model of Ethereum's Proof-of-Stake consensus layer . Beacon Runner in practice Notebooks using the current beaconrunner library. 05. Altair incentives + source Altair is a planned upgrade to the PoS consensus layer. We check that Altair incentives provide the expected rewards per validator by simulating the protocol for a few epochs. Early notebooks The beacon runner was built iteratively over several notebooks. Early notebooks use early iterations of the Beacon Runner codebase and will not function with the current code contained in this package. These early notebooks however provide background to PoS Ethereum concepts and to the general approach of our simulations. The code necessary to run them is provided in the source links. 01. Beacon Runner: A BeaconState cadCAD wrap + source This notebook introduces basic Ethereum PoS concepts and provides a \"centralised client\" implementation. We introduce the main duties of validators in PoS: producing blocks and attesting. In this implementation, the centralised client is the only one adding blocks to the beacon chain and attesting, thus it also has perfect view of the chain. This allows us to focus on the interplay between state (the state of the beacon chain) and policies (the duties performed by the centralised client). 02. Beacon Runner 2049: Liveness and inactivity leak + source The centralised client of the previous notebook was the only agent producing blocks and attestations. In this notebook, we introduce validators distributed over a peer-to-peer network, who exchange the blocks and attestations they produce. We assume the network is split in half, such that neither half is able to finalise the state of the beacon chain, focusing on the cryptoeconomic mechanism that allows finalisation to resume. Our implementation is still somewhat centralised, in the sense that all validators in the same half of the network have the same view of the chain (albeit a different view from the other half's). 03. Beacon Runner 2050: An agent-based model of PoS Ethereum + source We fully decentralise the model of the previous notebook by allowing each validator to have its own view of the chain. Additionally, we provide an interface to model the behaviour of validators, using a simple API. In this notebook, we implement honest validation and observe the progress of the chain. 04. Beacon Runner: Thunderdome + source We show that honest, protocol-following agents sometimes perform worse than agents who behave more prudently. This is the case when latency is bad enough that agents hedge their bets before taking action. Agents are modelled with the beacon runner validator API and simulated. Starting up You can simply run the following commands in a terminal. ```shell\ngit clone https://github.com/ethereum/beaconrunner.git\ncd beaconrunner Optional: use a virtual environment Python 3.8 is required python3.8 -m venv venv Unix source venv/bin/activate Windows .\\venv\\Scripts\\activate pip install -r requirements.txt\n``` Once you enter the shell, you can type in shell\njupyter lab General architecture The architecture is layered to make it simpler to extend individual layers. The tl;dr is that validatorlib is an \"intelligent\" wrap of the specs , network instantiates validators from validatorlib to place them on its network and the simulator helps move the simulation along, by specifying simulation transitions. specs We take the eth2.0 specs as our ground truth. We can export the specs to a python file using custom presets and configuration (mostly turning down the size of some of the data structures). Specs modifications Although our principle is to take the code as is and only \"wrap\" it around in an execution environment, we have brought the following changes in specs.py : Turn off crypto operations for performance improvement: Set bls.bls_active = False Turn off is_valid_indexed_attestation everywhere Turn off is_valid_merkle_branch in process_deposit Modify on_block to use store: Add state: BeaconState = None to the arguments. Add the following code block in the body: python\n    # Check the block is valid and compute the post-state\n    if state is None:\n        state = state_transition(pre_state, signed_block, True)\n    else:\n        process_block(state, signed_block.message) in place of python\n    # Check the block is valid and compute the post-state\n    state = state_transition(pre_state, signed_block, True) Validator interface validatorlib The specs obtained are mostly responsible for three tasks: Defining the state transition ( beacon-chain.md ). This is where rewards and penalties are applied and where blocks are processed to apply the state transition. Defining the honest validator behaviour ( validator.md ). In particular, this holds useful functions such as get_committee_assignment , which we can use in our interface to feed data to the validator. Defining the fork choice rule ( fork-choice.md ). Validators have knowledge of existing blocks and attestations, some of which are already included in the beacon chain, some of which only broadcasted on the p2p network. Based on this knowledge, validators decide which is the correct head of the chain. We use the Store object defined in the fork-choice.md file to hold this knowledge. In the beaconrunner library, the validatorlib.py file is the interface between our validator behaviours (held in beaconrunner/validators ) and the environment. All validators inherit from BRValidator , defined in validatorlib.py . This class has a store attribute, from which validators obtain the current head of the beacon chain, as well as a data attribute, which we use to store current validation information, such as their assignment to committees. The main role of this class is to provide up-to-date data to validator. For instance, in update_data , the validator reacts to a new event: Either a new block or a new attestation was received Or a new slot is reached In both cases, this warrants an update of the validator's data. When a new block is received, either that block builds on the current head, or it is a fork of the existing chain. In the latter case, this sometimes means that the validator assignment to committees has changed. We check whether these conditions are satisfied in update_data and call for a refresh of the get_committee_assignment . BRValidator also logs the history of play of validators, so that validators can refer back to it when performing their duties (\"have I already attested in this slot? history says yes...\") We also define honest_attest and honest_propose , which can be used by validators to build their behaviours (see Thunderdome for an example of how they are used). Validator behaviours beaconrunner/validators Validator behaviours (e.g., ASAPValidator ) follow a simple API. def <duty>(self, known_items) By calling self.data , a validator has access to its \"environment knowledge\": did they perform the duty already? how far into the slot are they? which is the current epoch? are they supposed to perform the duty? We follow the principle that a validator should not introspect anything else than this data attribute, in particular, not its store . Whenever a validator needs access to additional info, a \"translation\" should be made in BRValidator to have this info accessible in self.data (for instance, we don't want validator behaviours to call get_committee_assignment , they should be able to access up-to-date info in their data attribute instead). This makes for a cleaner separation as well as better performance, as we can cache results of expensive operations. known_items is fed from the network , these are the blocks and attestations on the p2p network that the validator knows about. It is used in honest_propose for instance, where a validator takes latest attestations and packages them in a block. network The network object is populated with subclasses of BRValidator which define the behaviour of various types of validators ( ASAP and Prudent behaviours are given in the current library). The network is responsible for propagating data over a simulated p2p network. Whenever a validator produces an item (a block, an attestation), it is sent on the network and disseminated over time to the other validators. simulator This class is responsible for implementing the simulation proper. It defines the steps in the simulate method: tick : move the environment \"clock\" by one step. We can the frequency is a parameter, with higher frequency => smaller time steps => more simulation steps. attest_policy : responsible for \"pinging\" the validators for their attestations. update_attestations : send the obtained attestations over the network. propose_policy : responsible for \"pinging\" the validators for their block. update_blocks : send the obtained blocks over the network. Most of the time, validators do not have anything to attest or propose, so the simulation proceeds. Docs Some documentation is available here ."}, {"name": "beacon_chain", "desc": null, "readme": "eth2.0 Beacon Chain Implements a proof of concept beacon chain for a sharded pos ethereum 2.0. Spec in progress can be found here . Installation Using a python3.6.* environment, run the following to install required libraries: pip install -e .[dev] NOTE: We suggest using virtualenv to sandbox your setup. Tests pytest tests Run with -s option for detailed log output Installation through Docker ```\nmake build make deploy\n``` Simple Serialize here"}, {"name": "bench", "desc": null, "readme": "Blockchain Sync A benchmarking utility for Ethereum clients. Usage ```\nnpm install install and configure a client, if necessary bin/run-bench [args] ``` The utility will attempt to connect the profiled client to a running \"master\" node and sync up from it. Options -e, --enode :         Enode address of a node to sync up with -d, --client-dir :    Client installation directory --client :            Name of the client to run --rm :                Remove the data directory before sync -h, --help :          Show instructions"}, {"name": "benchmarking", "desc": "Benchmarking data for EVM ops and precompiles", "readme": "Benchmarking This repository contains benchmarking data about the EVM implementations. The data is divided into raw/ which is the somewhat raw data provided by the various benchmarking frameworks used. processed/ which is (auto-generated) results from the raw data. scripts/ contains scripts and utilities to operate on the raw data. Format The benchmarking raw files should contain The actual benchmark data (duh) Info about processor and architecture"}, {"name": "bimini", "desc": null, "readme": "bimini An implementation of the Concise Streamable Serialization Scheme Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install bimini Developer Setup If you would like to hack on bimini, please check out the Ethereum Development Tactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/bimini.git\ncd bimini\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 bimini/ tests/ -c \"clear; flake8 bimini tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on bimini failed'\" ../tests ../bimini Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). To include changes made with each\nrelease, update \"docs/releases.rst\" with the changes, and apply commit directly to master \nbefore release. If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "blake2b-py", "desc": "Blake2b hashing in Rust with Python bindings.", "readme": "blake2b-py Blake2b hashing in Rust with Python bindings. Building/releasing To build and publish a release, follow these steps: Bump the version First, bump the package version with the included make target: bash\nmake bumpversion bump=patch The above invocation bumps the \"patch\" version of a semantic version number\n(\"x\" in \"1.2.x\").  Other valid version types are \"major\" and \"minor\".  The\nversion is bumped by modifying source files that contain the version number,\ncreating a new commit that includes those modifications, then tagging that\ncommit with the new version.  The new commit and tag are then pushed to the\nupstream repository. Building & Releasing Packages are build and distributed via Github Actions as soon as a tag is\npushed to the remote repository which is taken care of by the bumpversion command. Developing You'll need to have Maturin installed on your machine.\nCreate a virtual environment, and then you can do: sh\n$ pip install maturin\n$ maturin develop to install the dependencies. You may need to specify the MACOSX_DEPLOYMENT_TARGET environment variable to your version of MacOS. Run the tests Running make test_all will run all the tests."}, {"name": "blockies", "desc": "<1k library that generates blocky identicons", "readme": "Blockies A tiny library for generating identicons for Ethereum addresses. These are not meant to replace user profiles, but as security icons, to allow the user to more easily check if an address he wants to interact with is the correct one. The symmetrical aspect of the icons allow our brain see faces or objects , making the icon more recognizable. This also contains the HQX library, for optionally creating not-so-blocky icons (see sample below). Demo page Use ```javascript\nvar icon = blockies.create({ // All options are optional\n    seed: 'randstring', // seed used to generate icon data, default: random\n    color: '#dfe', // to manually specify the icon color, default: random\n    bgcolor: '#aaa', // choose a different background color, default: random\n    size: 15, // width/height of the icon in blocks, default: 8\n    scale: 3, // width/height of each block in pixels, default: 4\n    spotcolor: '#000' // each pixel has a 13% chance of being of a third color,\n    // default: random. Set to -1 to disable it. These \"spots\" create structures\n    // that look like eyes, mouths and noses.\n}); document.body.appendChild(icon); // icon is a canvas element\n``` In the above example the icon will be 15x15 blocks, and each block will be 3x3 pixels. The icon canvas will be 45x45 pixels. Notes The defaults of size 8 and scale 4 generate 32x32 pixel icons. Below are some standard sizes that work well. A size larger than 10 will start generating more noisy icons that don't ressemble much. 24x24 {size: 8, scale: 3} 50x50 {size: 5, scale: 10} Build node build All this does is minify blockies.js to blockies.min.js . License WTFPL"}, {"name": "bls12-381-tests", "desc": null, "readme": "BLS 12-381 tests This repository provides a test-suite for the BLS_SIG_BLS12381G2_XMD:SHA-256_SSWU_RO_POP_ ciphersuite (following draft 4 ),\nas used in Ethereum 2.0 BLS Signature APIs ,\nas well as common extensions such as signature-sets ( batch aggregate verification ) and serialization. The test suite is generated with python, and can be downloaded via the releases.\nWe suggest the following for integration into your testing pipeline: ```shell\nmkdir -p destination/bls-tests\nTESTS_VERSION=v0.1.0\nwget https://github.com/ethereum/bls12-381-tests/releases/download/${TESTS_VERSION}/bls_tests_json.tar.gz -O - | tar -xz -C destination/bls-tests bls_tests_yaml.tar.gz is also available: same tests, formatted as YAML ``` Resources IETF BLS Signature Scheme versions IETF BLS Signature Scheme draft 4 Finite Field Arithmetic Chapter 2 of Elliptic Curve Cryptography . Darrel Hankerson, Alfred Menezes, and Scott Vanstone Test format The BLS test suite runner has the following handlers: aggregate_verify aggregate fast_aggregate_verify batch_verify sign verify hash_to_G2 deserialization_G1 deserialization_G2 Test generation ```shell Create a virtual environment python -m venv venv Activate the environment source venv/bin/activate Install dependencies pip install -r requirements.txt Create output dir mkdir out Run test generator python main.py --output-dir=out --encoding=yaml\n``` License CC0 1.0 Universal, see LICENSE file."}, {"name": "browser-solidity", "desc": "Fomer location of remix-ide => https://github.com/ethereum/remix-ide", "readme": "browser-solidity This is the former repository of remix-ide (aka browser-solidity). Now available at https://github.com/ethereum/remix-ide"}, {"name": "btcrelay", "desc": "Ethereum contract for Bitcoin SPV: Live on https://etherscan.io/address/0x41f274c0023f83391de4e0733c609df5a124c3d4", "readme": "BTC Relay BTC Relay is an Ethereum contract for Bitcoin SPV.  The main functionality it provides are: verification of a Bitcoin transaction optionally relay the Bitcoin transaction to any Ethereum contract storage of Bitcoin block headers inspection of the latest Bitcoin block header stored in the contract BTC Relay contract address and ABI: mainnet testnet Morden The address and ABI is all that's needed to use BTC Relay, in addition to the API documentation below. API verifyTx(rawTransaction, transactionIndex, merkleSibling, blockHash) Verifies the presence of a transaction on the Bitcoin blockchain, primarily that the transaction is on Bitcoin's main chain and has at least 6 confirmations. rawTransaction - raw bytes of the transaction transactionIndex - transaction's index within the block, as int256 merkleSibling - array of the sibling hashes comprising the Merkle proof, as int256[] blockHash - hash of the block that contains the transaction, as int256 Returns uint256 * hash of the verified Bitcoin transaction\n* 0 if rawTransaction is exactly 64 bytes in length or fails verification Note: See examples/sampleCall.html including use of bitcoin-proof for constructing merkleSibling . relayTx(rawTransaction, transactionIndex, merkleSibling, blockHash, contractAddress) Verifies a Bitcoin transaction per verifyTx() and relays the verified transaction to the specified Ethereum contract. rawTransaction - raw bytes of the transaction transactionIndex - transaction's index within the block, as int256 merkleSibling - array of the sibling hashes comprising the Merkle proof, as int256[] blockHash - hash of the block that contains the transaction, as int256 contractAddress - address of the processor contract that will receive the verified Bitcoin transaction, as int256 The processor contract at contractAddress should have a function of signature processTransaction(bytes rawTransaction, uint256 transactionHash) returns (int256) and is what will be invoked by relayTx if the transaction passes\nverification.  For examples, see BitcoinProcessor.sol and testnetSampleRelayTx.html . Returns int256 * value returned by the processor contract's processTransaction function\n* or ERR_RELAY_VERIFY, see constants.se Note: Callers cannot be 100% certain when an ERR_RELAY_VERIFY occurs because\nit may also have been returned by processTransaction().  Callers should be\naware of the contract that they are relaying transactions to, and\nunderstand what the processor contract's processTransaction method returns. storeBlockHeader(blockHeader) Store a single block header if it is valid, such as a valid Proof-of-Work and the previous block it reference exists. blockHeader - raw bytes of the block header (not the hex string, but the actual bytes). Returns int256 * block height of the header if it was successfully stored\n* 0 otherwise bulkStoreHeader(bytesOfHeaders, numberOfHeaders) Store multiple block headers if they are valid. bytesOfHeaders - raw bytes of the block headers (not the hex string, but the actual bytes), with one following immediately the other. numberOfHeaders - int256 count of the number of headers being stored. Returns int256 * block height of the last header if all block headers were successfully stored\n* 0 if any of the block headers were not successfully stored Note: See deploy/relayTest/testBulkDeploy.yaml for an example of the data for storing multiple headers.  Also, to avoid exceeding Ethereum's block gas limit, a guideline is to store only 5 headers at time. getBlockHeader(blockHash) Get the 80 byte block header for a given blockHash .  A payment value of getFeeAmount(blockHash) must be provided in the transaction. blockHash - hash of the block as int256 Returns bytes * block header, always as 80 bytes (all zeros if header does not exist)\n* or 0 (as a single byte) if insufficient payment is provided getBlockHash(blockHeight) Get the block hash for a given blockHeight . blockHeight - height of the block as int256 .  Minimum value is 1 . Returns int256 * block hash\n* 0 if not found getAverageChainWork() Returns the difference between the chainWork of the latest block and the\n10th block prior. This is provided in case an Ethereum contract wants to use the chainWork\nor Bitcoin network difficulty (which can be derived) as a data feed. getBlockchainHead(), getLastBlockHeight(), others getBlockchainHead - returns the hash of the latest block, as int256 getLastBlockHeight - returns the block height of the latest block, as int256 See BitcoinRelayAbi.js for other APIs and testnetContractStatus.html for an example of calling some of them. Incentives The following APIs are described in Incentives for Relayers below. storeBlockWithFee() , changeFeeRecipient() , getFeeRecipient() , getFeeAmount() , getChangeRecipientFee() Examples Examples for how to use BTC Relay include: testnetSampleCall.html for calling verifyTx including use of bitcoin-proof for constructing merkleSibling . mainnet sampleCall.html for calling verifyTx (very similar to above.) testnetSampleRelayTx.html shows relayTx relaying a Bitcoin transaction from the frontend to an Ethereum contract. testnetContractStatus.html for calling other basic functions. How to use BTC Relay The easiest way to use BTC Relay is via relayTx because the ABI can remain on the frontend. testnetSampleRelayTx.html shows how a Bitcoin transaction from the frontend can be passed (relayed) to an Ethereum contract. See other examples for other ways to use BTC Relay and the docs for FAQ. Libs/utils Thanks to those who wrote these: https://github.com/rainbeam/solidity-btc-parser https://github.com/tjade273/BTCRelay-tools https://github.com/MrChico/verifyIPFS/blob/master/contracts/verifyIPFS.sol (hex to base58) Incentives for Relayers Relayers are those who submit block headers to BTC Relay.  To incentivize the community\nto be relayers, and thus allow BTC Relay to be autonomous and up-to-date with the\nBitcoin blockchain, Relayers can call storeBlockWithFee .  The Relayer will be the getFeeRecipient() for the block they submit, and when any transactions are verified\nin the block, or the header is retrieved via getBlockHeader , the Relayer will be\n rewarded with getFeeAmount() . To avoid a relayer R1 from setting excessive fees , it is possible for a relayer R2\nto changeFeeRecipient() .  R2 must specify a fee lower than what R1 specified, and\npay getChangeRecipientFee() to R1, but now R2 will be the getFeeRecipient() for the block\nand will earn all future getFeeAmount() . With this background, here are API details for incentives. storeBlockWithFee(blockHeader, fee) Store a single block header (like storeBlockHeader ) and\nset a fee that will be charged for verifications that use blockHeader . blockHeader - raw bytes of the block header (not the hex string, but the actual bytes). fee - int256 amount in wei. Returns int256 * block height of the header if it was successfully stored\n* 0 otherwise changeFeeRecipient(blockHash, fee, recipient) Set the fee and recipient for a given blockHash .  The call must have msg.value of at least getChangeRecipientFee() , and must also specify a fee lower than\nthe current getFeeAmount(blockHash) . blockHash - hash of the block as int256 . fee - int256 amount in wei. recipient - int256 address of the recipient of fees. Returns int256 * 1 if the fee and recipient were successfully set\n* 0 otherwise getFeeRecipient(blockHash) Get the address that receives the fees for a given blockHash . blockHash - hash of the block as int256 . Returns int256 * address of the recipient getFeeAmount(blockHash) Get the fee amount in wei for verifications using a given blockHash . blockHash - hash of the block as int256 . Returns int256 * amount of the fee in wei. getChangeRecipientFee() Get the amount of wei required that must be sent to BTC Relay when calling changeFeeRecipient . Returns int256 * amount of wei Development Requirements\n* Serpent * pyethereum (for tests)\n* pyepm (for deployment) Running tests Exclude slow tests: py.test test/ -s -m \"not slow\" Run slow tests without veryslow tests py.test test/ -s -m \"slow and not veryslow\" All tests: py.test test/ -s License See full MIT License including: THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE."}, {"name": "builder-specs", "desc": "Specification for the external block builders.", "readme": "Ethereum Builder API Specification The Builder API is an interface for consensus layer clients to source blocks\nbuilt by external entities. In this repository is the API specification along with specifications for actors in this ecosystem broken out by fork. Why? Block building is a specialized activity that requires high fixed costs to be\nan efficient validator. This creates an advantage for staking pools as they can\neffectively distribute the cost across many validators. Proposer-builder separation (PBS) fixes this by splitting the roles of a\nvalidator into block proposing and block building. However, PBS requires\nmodifications to the Beacon chain and will therefore not be possible at the\ntime of the merge. The Builder API is a temporary solution that requires higher trust assumptions\nthan PBS, but can be fully implemented without modification to the base\nprotocol. This is done by providing the proposer with a \"blind\" execution layer\nheader to incorporate into a block and a \"value\" amount which will be\ntransferred to the proposer once they create a block with the aforementioned\nheader. Once the proposer signs a block with the header, they are bound to the\nchoice (or risk being slashed due to equivocation). That allows the builder to\nreveal the blinded transactions without the possibility of the proposer\ntampering with them. This design is based on the original proposal for trusted external builders: \"MEV-Boost: Merge ready Flashbots Architecture\" . Builder software Users will typically connect their CL clients to builders with builder\nmultiplexers. Please see their respective repositories for more information: mev-boost mev-rs Contributing The API specification is checked for lint errors before merging pull requests. To run the linter locally, install it with: console\nnpm install -g @redocly/cli and then run it: console\nredocly lint builder-oapi.yaml Render API Specification To render spec in browser, you will simply need an HTTP server to load the index.html file in root of the repo. For example: console\npython -m http.server 8080 The spec will render at http://localhost:8080 . Usage Local changes will be observable if \"dev\" is selected in the \"Select a\ndefinition\" drop-down in the web UI. It may be necessary to tick the \"Disable Cache\" box in their browser's\ndeveloper tools to see changes after modifying the source. Releasing Create and push tag Make sure info.version in builder-oapi.yaml file is updated before\n     tagging. CI will create a github release and upload bundled spec file Add release entrypoint in index.html In SwaggerUIBundle configuration (inside index.html file), add another\nentry in urls field. Entry should be in following format (replace <tag> with real tag name from step 1.): javascript\n{ url: \"./releases/<tag>/builder-oapi.json\", name: \"<tag>\" },"}, {"name": "c-kzg-4844", "desc": "Minimal 4844 version of c-kzg", "readme": "C-KZG-4844 A minimal implementation of the Polynomial\nCommitments API for EIP-4844, written in C. Bindings While the core implementation is in C, bindings are available for various\nhigh-level languages, providing convenient wrappers around C functions. These\nbindings are intended to be used by Ethereum clients, to avoid re-implementation\nof crucial cryptographic functions. | Language | Link                                 |\n|----------|--------------------------------------|\n| C#       | README |\n| Go       | README |\n| Java     | README |\n| Nim      | README |\n| Node.js  | README |\n| Python   | README |\n| Rust     | README | Interface functions The C-KZG-4844 library provides implementations of the public KZG functions that\nare defined in the Polynomial Commitments specification. The aim is to align\nthese functions as closely as possible with the specification. blob_to_kzg_commitment compute_kzg_proof compute_blob_kzg_proof verify_kzg_proof verify_blob_kzg_proof verify_blob_kzg_proof_batch This library also provides functions for loading and freeing the trusted setup,\nwhich are not defined in the specification. These functions are intended to be\nexecuted once during the initialization process. As the name suggests, the trusted setup\nfile is\nconsidered to be trustworthy. load_trusted_setup load_trusted_setup_file free_trusted_setup Remarks Tests All the bindings are tested against the KZG reference\ntests ,\nwhich are defined in the consensus-spec-tests. Additionally, a suite of unit\ntests for internal C functions is located here . Parallelization The interface functions in C-KZG-4844 are single-threaded for simplicity, as\nimplementing multi-threading across multiple platforms can be complex. While\nperformance is important, these functions are already quite fast and efficient.\nFor instance, verify_blob_kzg_proof is expected to finish in under 3ms on most\nsystems. Batched verification When processing multiple blobs, verify_blob_kzg_proof_batch is more efficient\nthan calling verify_blob_kzg_proof individually. In CI tests, verifying 64\nblobs in batch is 53% faster per blob than verifying them individually. For a\nsingle blob, verify_blob_kzg_proof_batch calls verify_blob_kzg_proof , and\nthe overhead is negligible. Benchmarks C-KZG-4844 does not include C benchmarks; however, some bindings (Go, Java, and\nRust) have their own benchmarks. Including benchmarks in the bindings offers a\nmore realistic performance estimate, as C-KZG-4844 is not expected to be used\noutside the bindings. Security audit The source code of C-KZG-4844 was audited by Sigma\nPrime in June 2023. You can find the audit\nreport in the doc/audit/ directory. Why C? The primary reason for choosing C is that blst , the BLS12-381 signature library\nwe wanted to use, is mostly written in C. Rust was a viable alternative, but it\nhas some disadvantages. The C toolchain is ubiquitous, and it would be somewhat\nawkward for all the bindings to depend on another toolchain, such as Rust.\nCompared to Rust, C offers a lighter memory and binary footprint. Furthermore, C\nserves as the de facto language for FFI , so we could not\nhave completely avoided using C anyway."}, {"name": "cable", "desc": "Cable: CMake Bootstrap Library", "readme": "Cable Cable: CMake Bootstrap Library Cable is a set of CMake modules and scripts containing common patterns used\nin CMake-based C++ projects. The design goal is to be pragmatic rather than\ngeneric so the number of provided options is minimal. The Cable modules are\nindependent and it is easy to use them individually. Table of Contents Install Usage Maintainer License Install The suggested Cable location is cmake/cable relative to your project root directory. With cable.cmake script Copy cable.cmake script to your project.\nThen use it to download individual Cable CMake modules. bash\n./cable.cmake install CableBuildType As git subtree Adding a dependency project as a git subtree is just a copy of the source code\ndone in a bit more systematic way. If you are not familiar with managing dependencies with git subtree read the Git subtree: the alternative to Git submodule . To install sh\ngit remote add cable https://github.com/ethereum/cable\ngit subtree add --prefix cmake/cable cable master --squash To update sh\ngit subtree pull --prefix cmake/cable cable master --squash As git submodule Include the Cable library as git submodule in your project. sh\ngit submodule add https://github.com/ethereum/cable cmake/cable Usage Cable contains the bootstrap.cmake file that initializes the library.\nStart by including this file in your main CMakeLists.txt from the Cable \nsubmodule/subtree or any other location. The bootstrap.cmake must be included \nbefore the project() command. After that, you can include and use other\nCable modules. Example ```cmake\ncmake_minimum_required(VERSION 3.5) include(cmake/cable/bootstrap.cmake)\ninclude(CableBuildType) project(tothemoon) cable_set_build_type(DEFAULT RelWithDebInfo CONFIGURATION_TYPES Debug Release RelWithDebInfo)\n``` Maintainer Pawe\u0142 Bylica @chfast License Licensed under the Apache License, Version 2.0 ."}, {"name": "casper", "desc": "Casper contract, and related software and tests", "readme": "[Deprecated] Please refer to Ethereum 2.0 Specifications for the latest developments"}, {"name": "cbc-casper", "desc": null, "readme": "Casper CBC Branch    | Tests\n----------|------\nmaster    | develop   | A python implementation of a class of \"correct-by-construction\" consensus protocols . Currently, this includes Casper the Friendly Ghost (a blockchain consensus protocol) and Casper the Friendly Binary Consensus Protocol. Specifications for these protocols can be found here here , but the implementation and the spec may deviate from the spec, as they are still moving targets. Warning -- Codebase subject to substantial changes This pre v1.0 implementation is under active development and experimentation\nand might experience significant organizational and substantive changes.\nIf you use components of this codebase, expect breaking changes to be\nintroduced. That said, we will try to detail any breaking changes in subsequent releases. Requirements Python 3 ubuntu/debian: sudo apt-get install python3-dev python3-venv python3-tk OSX via Homebrew: brew install python3 Developer Setup If you would like to hack on cbc-casper or run the simulations yourself, setup your dev environment with: make install NOTE: If you prefer to manage venv explicitly, run a standard venv setup and\npip install using requirements.txt Run Simulations Standard Standard simulations are marked up for use as follows: make run-[binary | blockchain | concurrent | integer | order | sharding] Each protocol represents consensus on a different data structure. Optionally, you can add a message passing mode to each protocol. For example, make run-binary MODE=rrob There are currently three message passing modes: rand: each round, some randomly selected validators propagate their most recent message to other randomly selected validators, who then create new messages. rrob: each round, the creator of the last round's block sends it to the next receiver, who then creates a block. full: each round, all validators receive all other validators previous messages, and then all create messages. By default, a gif and associated images of the simulation will be saved in graphs/graph_num_0/ . These settings can be modified, along with the number of validators, the number of messages that propagate per round, and the report interval in the config.ini . Advanced Advanced simulations can be run with a little command line wizardy.\n- First ensure that you are using the virtual environment via: . venv/bin/activate - Simulations can then be run via casper.py . The following are example usages:\n``` get help and all options for casper.py python casper.py --help run a simulation with 100 validators and random message propagation python casper.py --protocol blockchain --msg-mode rand --validators 100 run a simulation without displaying the viewgraphs, but instead save them and create a GIF python casper.py --protocol blockchain --msg-mode rand --display false --save true run a simulation with 20 validators and 1000 rounds of round robin message propagation, reporting every 100 rounds python casper.py --protocol blockchain --msg-mode rrob --validators 6 --rounds 300 --report-interval 100 ``` Write Simulations COMING SOON... Run Tests To run all tests: make test To run a specific test, use (or the equivalent for whatever test you wish to run) make test TEST=tests/test_safety_oracle.py To run tests with visualizations: make test-with-reports Note: each view graph must be closed for the tests to continue running."}, {"name": "clef-ui", "desc": " UI Implementation for Clef, the geth-based signer", "readme": "Clef UI UI Implementation for Clef , the geth-based signer. It starts the signer binary as a subprocess, and communicates with the signer over standard input/output. The signer opens an external API to receive RPC request. Once a request comes in, the signer will then inform the UI via Standard I/O. Getting Started This UI uses a QT binding for Go to create the UI. To start building, you will first need to install thereceipe/qt , which comes with a CLI for compiling QT codes, and a WYSIWIG editor for QML. The installation process takes about 25 to 35 minutes. Environment Setup After installing thereceipe/qt , you will need to install the dependencies by running: cgo\nmake deps Since this is the first time you are building the UI, you will then need to compile all QT-related code by running the following. In the future, you will need to run this again if you change any QT-related code. cgo\nmake deploy You can then start the UI by running: cgo\nmake run License This is licensed under GNU General Public License v3.0"}, {"name": "clrfund", "desc": "Eth2 CLR project built on clr.fund", "readme": "clr.fund clr.fund is a permissionless and trust-minimized Quadratic Funding protocol. It uses Minimal Anti-Collusion Infrastructure ( MACI ) to protect against various forms of bribery and collusion with the use of zk-SNARKs . To protect from Sybil attacks it can use BrightID or a similar identity system. clr.fund runs a continuous sequence of Quadratic Funding rounds, where anyone is able to add public goods projects as funding \"recipients\", contribute funds to the matching pool (\"matching funds\"), and contribute funds to individual recipients. To ensure that only public goods are added as recipients clr.fund can use curation mechanism such as Kleros Curate . While clr.fund aims to be agnostic to the source of matching funds, it specifically aims to enable contributions from the following sources: Ethereum protocol rewards (Block rewards, transaction taxes, etc) Known and anonymous benefactors Benevolent protocols (MakerDAO, Burn Signal, etc) In order for their contributions to count towards matching, contributors must verify their uniqueness. The clr.fund smart contracts consist of a factory contract that deploys a new contract for each round. All matching funds are sent to the factory contract, while contribution funds are sent to the current round's contract. There are four roles in factory contract: Owner: This address (initially set to deployer) can set the address of coordinator, finalize a round by transferring matching funds to the current round contract, and set the token and round duration. Coordinator: This address is responsible for running the zk-SNARK computation on contributions to produce the relative percentages of matching funds that each recipient should receive. The coordinator can quit at any time, which invalidates the current round forcing the owner to start a new round and users to submit new MACI messages for their contributions. Without some advancement in oblivious computation, this Coordinator is necessarily a trusted party in this system (this is discussed more in the Limitations section). Contributor: Any address that contributes tokens to the funding round. Recipient: Any address that is registered as funding recipient. The clr.fund application can use any EVM-compatible chain as a backend. The application can be hosted on IPFS and can also run locally. For more details, see the sequence diagram and clr.fund constitution . Some helpful blogposts to explain the clr.fund project: https://blog.clr.fund/clr-fund-explained-pt-1/ https://blog.clr.fund/clr-fund-explained-pt-2/ https://blog.clr.fund/clr-fund-explained-pt-3/ Limitations There are various limitations in our current design; we discuss some of them here. Trusted Participants The need for several trusted parties is the biggest limitation in the current design. The owner could, and likely will, be replaced with a DAO or some other decision-making mechanism which could alleviate the trust concern for this role. However, without some breakthrough in oblivious computation, the zk-SNARK computations must necessarily be done by some trusted party who becomes a prime target for bribery as they are the only participant who can know the details of each contributor\u2019s contributions. Several solutions have been suggested, such as having the operator\u2019s private keys and computations happen inside of some trusted computing environment or wallfacer-esque isolation of the operator. But most just kick the trust-can down the road a little further. Single Token For simplicity's sake in the contract, the zk-SNARK, and the user interface, clr.fund selects an ERC20 token as it's native token (set by the contract owner), which is the only token that the funding round contract interacts with. This is an issue given our goal of being agnostic to the funding source. For example, block reward funding would be in ETH, while many users may want to contribute DAI or other ERC20 tokens. In a future version, we plan to address this by routing ETH and token contributions in anything other than the current native token through a DEX such as UniSwap . Documentation Running clr.fund instance Providing matching funds How to tally votes How to verify results Running the subgraph Deployment Development Install Node v12 with nvm sh\nnvm install 12\nnvm use 12 If using the M1 chip in Apple products, you need to use Node v16. sh\nnvm install 16\nnvm use 16 Install the dependencies ```sh\nyarn Along with the dependencies, git hooks are also installed. At the end of the installation, you will see the following line after a successful setup. husky - Git hooks installed\n``` Copy env for contracts sh\ncp contracts/.env.example contracts/.env    # adjust if necessary Copy env for the webapp sh\ncp vue-app/.env.example vue-app/.env    # adjust if necessary Start the frontend app in development mode (hot-code reloading, error reporting, etc.) In one terminal, init the hardhat node sh\nyarn start:node In a 2nd terminal you will need to run your graph node (more on this here ) ```sh go to the thegraph repo directory and init the node cd graph-node/docker\ndocker-compose up\n``` And finally, in a 3rd terminal ```sh this will complie and deploy the contracts + deploy the subgraph + build and run the vue app yarn start:dev\n``` Other useful scripts Compile the contracts sh\nyarn build:contracts Run unit tests sh\nyarn test Start the frontend sans a local blockchain sh\nyarn start:web Lint the files sh\nyarn lint Git hooks Pre-commit Prettier is executed on the staged files to keep a consistent format style\nacross the codebase. Pre-push yarn test:format and yarn test:web is going to be triggered to ensure that\nthe code is in good shape. As you can see, we are only checking the web (/vue-app) tests and not\nthe contracts ones. This is because there are not changes very often in the\n/contracts folder. However, if you do make a change in /contracts don't forget\nto run yarn test or yarn test:contracts . Tech stack resources /contracts Hardhat Openzeppelin /vue-app Vuex Vue class component Vuelidate Vue js modal Ethers Gun Visual Studio Code As a recommendation, use the Vetur extension.\nIt gives you some useful features for Vue like syntax highlights, autocomplete,\netc. Create a vetur.config.js file at the project root with the following content: ts\n/** @type {import('vls').VeturConfig} */\nmodule.exports = {\n  settings: {\n    'vetur.useWorkspaceDependencies': true,\n  },\n  projects: [\n    {\n      root: './vue-app',\n      package: './package.json',\n      tsconfig: './tsconfig.json',\n      globalComponents: ['./src/components/**/*.vue'],\n    },\n  ],\n}"}, {"name": "common", "desc": "Resources common to all Ethereum implementations", "readme": "common Resources common to all Ethereum implementations"}, {"name": "consensus-deployment-ansible", "desc": null, "readme": "Minimal ansible for Ethereum Testnets This repository is a minimal set of playbooks and inventories required to set up a Consensus Layer(CL) node and a Execution\nLayer (EL) node for use in testnets. Ansible Galaxy This repository uses ansible galaxy for some dependencies. You can fetch them using: sh\n./install_dependencies.sh Usage Fork this repository for your required devnet (Ideally it is a throwaway devnet) Modify the testnets/<name>/inventory/inventory.ini file with the correct tags and client distribution Generate the keys from the mnemonic by running the generate_keys.sh file (after exporting the mnemonic) If needed, modify the testnets/<name>/custom_config_data/ folder with the genesis.ssz and eth2_config.yaml Modify the testnets/<name>/inventory/group_vars/eth2client_<client_name>.yml if required Check the inventory with ansible-inventory -i testnets/<name>/inventory/dynamic.py --list Run the playbook to run all beacon nodes and validators with ansible-playbook -i testnets/<name>/inventory/dynamic.py playbooks/setup_beacon_and_validators_full.yml"}, {"name": "consensus-spec-tests", "desc": "Common tests for the Ethereum proof-of-stake consensus layer", "readme": "Ethereum Proof-of-Stake Consensus Spec Tests This repository contains test vectors for the Ethereum Proof-of-Stake Consensus Spec .\nOther types of testing (network, fuzzing, benchmarking, etc.) are currently a work in progress, and will be hosted in separate repositories.\nThe intention of this repository is to provide a solid base for Ethereum proof-of-stake clients (aka \"beacon nodes\") to consume as part of their unit-testing efforts around spec behavior. The tests are YAML files following the general testing format . The generators that are responsible for generating all of the spec tests can be found in ethereum/consensus-specs/test_generators . New tests can be added by creating a generator in the specs repository, or adding functionality to an existing generator.\nGenerators are small and easy to write, and can use the pythonized-spec to build expected test outputs: see documentation Note that this repository is growing over time as the spec evolves, and more test-generation code is being added.\nThe YAML test-vectors are tracked using Git LFS , \n to accommodate for large test vectors (Take execution-layer tests repository size as an example). License See LICENSE file."}, {"name": "consensus-specs", "desc": "Ethereum Proof-of-Stake Consensus Specifications", "readme": "Ethereum Proof-of-Stake Consensus Specifications To learn more about proof-of-stake and sharding, see the PoS documentation , sharding documentation and the research compendium . This repository hosts the current Ethereum proof-of-stake specifications. Discussions about design rationale and proposed changes can be brought up and discussed as issues. Solidified, agreed-upon changes to the spec can be made through pull requests. Specs Core specifications for Ethereum proof-of-stake clients can be found in specs . These are divided into features.\nFeatures are researched and developed in parallel, and then consolidated into sequential upgrades when ready. Stable Specifications | Seq. | Code Name | Fork Epoch | Specs |\n| - | - | - | - |\n| 0 | Phase0 | 0 | Core The beacon chain Deposit contract Beacon chain fork choice Additions Honest validator guide P2P networking Weak subjectivity |\n| 1 | Altair | 74240 | Core Beacon chain changes Altair fork Additions Light client sync protocol ( full node , light client , networking ) Honest validator guide changes P2P networking |\n| 2 | Bellatrix ( \"The Merge\" ) | 144896 | Core Beacon Chain changes Bellatrix fork Fork choice changes Additions Honest validator guide changes P2P networking |\n| 3 | Capella | 194048 | Core Beacon chain changes Capella fork Additions Light client sync protocol changes ( fork , full node , networking ) Validator additions P2P networking | In-development Specifications | Code Name or Topic | Specs | Notes |\n| - | - | - |\n| Deneb (tentative) | Core Beacon Chain changes Deneb fork Polynomial commitments Fork choice changes Additions Light client sync protocol changes ( fork , full node , networking ) Honest validator guide changes P2P networking |\n| Sharding (outdated) | Core Beacon Chain changes Additions P2P networking |\n| Custody Game (outdated) | Core Beacon Chain changes Additions Honest validator guide changes | Dependent on sharding |\n| Data Availability Sampling (outdated) | Core Core types and functions Fork choice changes Additions P2P Networking Sampling process | Dependent on sharding Technical explainer |\n| EIP-6110 | Core Beacon Chain changes EIP-6110 fork Additions Honest validator guide changes | Accompanying documents can be found in specs and include: SimpleSerialize (SSZ) spec Merkle proof formats General test format Additional specifications for client implementers Additional specifications and standards outside of requisite client functionality can be found in the following repos: Beacon APIs Engine APIs Beacon Metrics Design goals The following are the broad design goals for the Ethereum proof-of-stake consensus specifications:\n* to minimize complexity, even at the cost of some losses in efficiency\n* to remain live through major network partitions and when very large portions of nodes go offline\n* to select all components such that they are either quantum secure or can be easily swapped out for quantum secure counterparts when available\n* to utilize crypto and design techniques that allow for a large participation of validators in total and per unit time\n* to allow for a typical consumer laptop with O(C) resources to process/validate O(1) shards (including any system level validation such as the beacon chain) Useful external resources Design Rationale Phase 0 Onboarding Document Combining GHOST and Casper paper For spec contributors Documentation on the different components used during spec writing can be found here:\n* YAML Test Generators * Executable Python Spec, with Py-tests Online viewer of the latest release (latest master branch) Ethereum Consensus Specs Consensus spec tests Conformance tests built from the executable python spec are available in the Ethereum Proof-of-Stake Consensus Spec Tests repo. Compressed tarballs are available in releases ."}, {"name": "cpp-build-env", "desc": "Docker images for building C++ projects", "readme": null}, {"name": "cpp-dependencies", "desc": "download, compile && prepare cpp-ethereum dependencies for windows", "readme": "cpp-dependencies download, compile && prepare cpp-ethereum dependencies for windows Win32 - Debug Win32 - Release x64 - Debug x64 - Release Requirements git cmake 3.0 VisualStudio 2013 Community tar curl Run shell\nmain.bat"}, {"name": "cpp-dependencies-win64", "desc": "Prebuilt Windows 64-bit dependencies for C++.", "readme": null}, {"name": "cpp-ethash", "desc": null, "readme": ""}, {"name": "cpp-ethereum-cmake", "desc": "CMake support files for the C++ (Turbo) Ethereum projects", "readme": "cpp-ethereum-cmake CMake support files for the C++ (Turbo) Ethereum projects"}, {"name": "cryptography-research-website", "desc": "Ethereum Foundation Cryptography Research Website", "readme": "Ethereum Foundation Cryptography Research The Ethereum Foundation leads research into cryptographic protocols that are useful within\nthe greater Ethereum community and more generally. Cryptography is a key tool that enables\ngreater functionality, security, efficiency, and auditability in decentralized settings.\nWe are currently conducting research into verifiable delay functions, multiparty\ncomputation, vector commitments, and zero-knowledge proofs etc. We have a culture of open\nsource and no patents are put on any work that we produce. This repository holds the codebase to our website, crypto.ethereum.org Stack The main stack used in the project includes: Next.js . TypeScript . ChakraUI as component library. KaTeX to render LaTeX math syntax. Local development The project is bootstrapped with create-next-app , with a custom scaffolding. Getting Started First, run the development server: ```bash\nnpm run dev or yarn dev\n``` Open http://localhost:3000 with your browser to see the result. You can start editing the page by modifying pages/index.tsx . The page auto-updates as you edit the file. Project Structure The following list describes the main elements of the project structure: public : contains static assets like fonts and images. src : contains the source code. components : React components. components with state are directly located inside /components . layout : components used to contain and apply different layouts to different pages. UI : stateless (functional) components. pages : includes components that renders to pages and NextJS API Routes . posts : markdown blog posts. styles : css stylesheets. global.css : global stylesheet. theme : contains the Chakra UI custom theme , organized in foundations and components for better scaling. utils : utilitary stuff. constants.ts : this is the global constants file, containg URLs and lists of elements we use across the site. types.ts : contains the custom defined TypeScript types and interfaces. Markdown & LaTex support on blog posts Markdown Support for GitHub Flavored Markdown , which is a superset of CommonMark and adds supports to other features like tables. LaTeX The site uses KaTeX to render LaTeX/math and inside /research publications abstracts. LaTeX-rendering libs are not 100% compatible with LaTex yet, so please check the support table if you are having issues with some expression. How to add a new blog post The site supports both internal and external blog posts. Internal posts : to add a new one, just create a new markdown ( .md ) file under src/posts (make sure first this directory exists, otherwise create it first, under /src ). The name of the file should follow the kebab case convention, as it will be used to generate the url to the post. You also have to add some Front Matter metadata, like the post title , author(s) and date , which are required. Metadata example: ``` title: 'VDF Proving with SnarkPack'\ndescription 'Some awesome description for social media snippets, under 160 characters'\nauthor: 'Mary Maller'\ndate: '2022-03-16' ``` Post titles should be under 60 characters. Learn more on title tags . Post descriptions should be under 160 characters. Learn more on meta descriptions . External posts : you can also link to an external post from the /blog page by appending an object with the required data ( title , date , link ) to the externalLinks list from the src/pages/blog/index.tsx file. See the example below: const externalLinks = [\n  {\n    title: 'Ethereum Merge: Run the majority client at your own peril!',\n    date: '2022-03-24',\n    link: 'https://dankradfeist.de/ethereum/2022/03/24/run-the-majority-client-at-your-own-peril.html'\n  }\n]; How to add images to a local post Image files should be placed inside /public/images/ and the path to the image will be referenced as /images/${filename} . For example, we can insert the EF logo in a post by using ![EF logo](/images/ef-logo-bg-white.png \"EF logo\") Take into account that images are automatically centered, no need to add extra HTML. How to add footnotes to a local post Follow this syntax . How to deploy changes succesfully Locally : Make sure the site builds locally, otherwise the build will break and the new version of the site (e.g.: adding a new post) will not be generated. To be sure of this, run the yarn build command locally and check that you get no errors. On GitHub : check that the Deploy Preview passes succesfully. Bounties pages The source files ( .md ) for the bounties pages are located at /src/bounties-data-source . If you need to update the content from a certain bounty, just modify the corresponding file. LaTeX/math is also supported here. For a better organization, images used in bounties pages are placed inside /public/images/bounties/ and the path to the image have to be referenced as /images/bounties/${filename} (check /src/bounties-data-source/rsa/assumptions.md as example). How to add a new entry (Publication) on Research page The best way is to just follow the current Publication structure you can find in /src/pages/research.tsx and use any other existent entry as example. For publications that are not associated to a conference, just use the year prop, with a numeric value, like the example below: ```\n<Publication\n  title='Fast amortized KZG proofs'\n  authors='Dankrad Feist, Dmitry Khovratovich'\n  year={2023}\n  link='https://eprint.iacr.org/2023/033' In this note we explain how to compute n KZG proofs for a polynomial of degree d in\n      time superlinear of (n+d). Our technique is used in lookup arguments and vector\n      commitment schemes. ``` For publications associated to a conference, use the conference property instead, with a text value. Don't use year in this case, just include it as part of the conference value, as you can see in the example below: ```\n<Publication\n  title='Aggregatable subvector commitments for stateless cryptocurrencies'\n  authors='Alin Tomescu, Ittai Abraham, Vitalik Buterin, Justin Drake, Dankrad Feist, Dmitry\n  Khovratovich'\n  conference='SCN 2020.'\n  link='https://eprint.iacr.org/2020/527.pdf' An aggregatable subvector commitment (aSVC) scheme is a vector commitment (VC)\n      scheme that can aggregate multiple proofs into a single, small subvector proof. In\n      this paper, we formalize aSVCs and give a construction from constant-sized\n      polynomial commitments. Our construction is unique in that it has linear-sized\n      public parameters, it can compute all constant-sized proofs in quasilinear time, it\n      updates proofs in constant time and it can aggregate multiple proofs into a\n      constant-sized subvector proof. Furthermore, our concrete proof sizes are small due\n      to our use of pairing-friendly groups. We use our aSVC to obtain a payments-only\n      stateless cryptocurrency with very low communication and computation overheads.\n      Specifically, our constant-sized, aggregatable proofs reduce each block's proof\n      overhead to a single group element, which is optimal. Furthermore, our subvector\n      proofs speed up block verification and our smaller public parameters further reduce\n      block size. ``` How to add a new entry on Events page Follow the current Event structure you can find in /src/pages/events.tsx and use any other existent entry as example, like the example below: ```\n<Event\n  conference='Cryptographic Frontier 2022, Trondheim'\n  workshop='Open Problems in Decentralized Computation at Eurocrypt 2022'\n  url='https://sites.google.com/view/cryptographic-frontier-2022/' this workshop brings the most interesting and challenging open cryptographic questions\n  that Ethereum, Filecoin and other blockchain systems face, to the attention of academia.\n  We will cover a large spectrum of research topics, such as vector commitments, SNARKs,\n  shuffles, authenticated data structures and more. We will start the day with an update\n  on to the problems discussed at last year's workshop. ``` Be sure to provide a value for conference , workshop and the correct url . Notes Dates should follow the yyyy-mm-dd format (for both internal and external posts), like date: '2022-03-16' Blog posts are sorted automatically by date, regardless the order of insertion. Check the current sample posts on src/posts . Tutorials Learning NextJS To learn more about Next.js, take a look at the following resources: Next.js Documentation - learn about Next.js features and API. Learn Next.js - an interactive Next.js tutorial. Adding ChakraUI to a NextJS project This is a very clear and step-by-step guide on it. Learning ChakraUI We recommend checking the official docs ."}, {"name": "cryptopp", "desc": null, "readme": null}, {"name": "cthaeh", "desc": "A standalone application which serves the Ethereum JSON-RPC log filtering APIs", "readme": "cthaeh Stand alone application for serving the Ethereum JSON-RPC logging APIs Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install cthaeh Developer Setup If you would like to hack on cthaeh, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/cthaeh.git\ncd cthaeh\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 cthaeh/ tests/ -c \"clear; flake8 cthaeh tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on cthaeh failed'\" ../tests ../cthaeh Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "dapp-bin", "desc": "A place for all the \u00d0Apps to live", "readme": "dapp-bin A place for all the \u00d0Apps to live."}, {"name": "dapp-styles", "desc": null, "readme": "\u00d0app styles These styles give a simple basic layout for your \u00d0apps. Note: This is a very early stage of the package, not all elements are explained, or ready to use. Use it just to try. The Design The Ethereum Dapp design style is meant to ease the task of designing clear and good looking App interfaces. It uses as few images as possible for the UI and instead uses colors and icons for differentiating hierarchies. In order to make each Dapp unique and help the user quickly realize where he is even when navigating different instances of the same app, we use GeoPatterns in backgrounds when they refer to a unique instance of something. The fonts used are all open source, Source Sans, from Adobe which has a rich family and multiple styles and Montserrat for bold and strong titles. We also use a font for vector icons to ensure scalability and easy customization. Most apps are different variations of some simple elements: Use the header on the top with tabs, when your Dapp uses a few constant sections (ie. send and receive) Use the left sidebar when your Dapp has a large number of sources for content (ie. a list of chats) Use the right action bar for actions to be done with the current content Use Dapp-overflow if you want the sections to scroll independently and to remain fixed on the screen Setup CSS To use it as CSS file just link the css file from the dist/ folder. (No done yet.. sorry, compile yourself please) LESS To use it as less file, which would allow you to overwrite all constants \nfrom the constant.import.less and use the mixins from mixins.import.less .\nJust link the dapp-styles.less in your apps main LESS file. Meteor To use it in a Meteor app add the less package: $ meteor add less\n$ meteor add ethereum:dapp-styles Adn add the following to your main less file: @import '{ethereum:dapp-styles}/dapp-styles.less'; Screenshots These are early screenshots and many things are bound to change during development Usage A full layout consists of the following HTML elements: ```html ``` This gives you a basic flex box layout with a fixed header height and footer height, and a growable content area. Note: You can remove any part (header, footer, asides) of it and still have nice fitting containers. Using overflow auto in containers If you want the apps area to be maximal the window size and the content of your containers to be overflow: auto ,\njust add the dapp-overflow class to the dapp-header , dapp-content , dapp-footer , dapp-actionbar and/or dapp-aside containers and add the following to your main CSS file: css\nhtml, body {\n    height: 100%;\n} Development grid To show a HEX grid for element alignment just add the <div class=\"dapp-grid\"></div> element to your <body> tag. Mixins When you use the less version of the framework you will be able\nto use all its LESS mixins including the LESSHAT mixins (https://github.com/madebysource/lesshat, which are used by the dapp-styles) in your own LESS files. Containers To limit the width of you content use the .dapp-container class,\nwhich will center your content and limit it to a max width tof 960px (You can overwrite that with the @widthContainer variable). ```html ... ``` Grids All paddings and margins are based on a 32px by 18.4px grid. You can overwrite this grid by chaging the: @gridWidth @gridHeight variables. Additionally dapp-styles uses a grid system from Matthew Hartman. For fluid column layouts. For a full documentation see http://matthewhartman.github.io/base/docs/grid.html\nThe grid system is based on 12 columns and can be placed anywhere in you HTML. Note This grid system is not based on the @gridWidth and @gridHeight , as this are fluid columns. To create a simple grid use the row , col and col-x classes. ```html 1 11 1-2 11 1 1-2 ``` To change the column size for mobile and tablets you can use the following classes: .mobile-full sets column width to 100% and removes floats for mobile devices .tablet-full sets column width to 100% and removes floats for tablet devices .col-1-2 sets column width to 50% for all devices .col-1-3 sets column width to 33% for all devices .col-1-4 sets column width to 25% for all devices .col-3-4 sets column width to 75% for all devices .tablet-col-1-2 sets column width to 50% for tablet devices .tablet-col-1-3 sets column width to 33% for tablet devices .tablet-col-1-4 sets column width to 25% for tablet devices .tablet-col-3-4 sets column width to 75% for tablet devices .mobile-col-1-2 sets column width to 50% for mobile devices .mobile-col-1-3 sets column width to 33% for mobile devices .mobile-col-1-4 sets column width to 25% for mobile devices .mobile-col-3-4 sets column width to 75% for mobile devices Breakpoints To change change the break points overwrite the following variables: @widthContainer default: @gridWidth * 30; // 32px * 30 = 960px @widthTablet default: @gridWidth * 20; // 32px * 20 = 640px @widthMobile default: 100%; // mobile is everything below the @widthTablet breakpoint Elements TODO dapp-account-list A list of accounts with name and address. Either clickable, with the <button> tag, or as simple list. The a.dapp-identicon can be an image icon. (If you use the ethereum:elements Meteor package, you can use {{> dapp_identicon identity=address class=\"dapp-small\"}} ) The <span> is optional. Selected items need the <figure class=\"icon-check\"></figure> to show a checkmark. ```html My clickable account 0x343c98e2b6e49bc0fed722c2a269f3814ddd1533 My clickable selected account 0x343c98e2b6e49bc0fed722c2a269f3814ddd1533 My unclickable account 0x343c98e2b6e49bc0fed722c2a269f3814ddd1533 My unclickable selected account 0x343c98e2b6e49bc0fed722c2a269f3814ddd1533 ``` Menus To add a header or aside menu just add the follwowing structure to your .dapp-header or dapp-aside container: ```html Receive Send ``` Credits and ackowledgements Simple Line Icon fonts by Graphic Burguers"}, {"name": "ddht", "desc": "Python implementation of Discovery V5 Protocol", "readme": "Discovery V5 DHT Implementation of the P2P Discoveryv5 Protocol Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install ddht To run it: sh\nddht --help will tell you about the arguments ddht accepts. The LOGLEVEL environment\nvariable can be used to control which log messages are emitted. For example, to suppress\nunimportant messages from the Packer you can run: sh\nLOGLEVEL=WARNING:ddht.v5.packer.Packer ddht Developer Setup If you would like to hack on ddht, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/ddht.git\ncd ddht\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 ddht/ tests/ -c \"clear; flake8 ddht tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on ddht failed'\" ../tests ../ddht Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "deposit_contract", "desc": null, "readme": "[Deprecated] Deposit Contract in Eth 2.0 The contract has been moved to eth2.0-specs"}, {"name": "devcommon", "desc": "Common development infrastructure for Webthree stuff.", "readme": "devcommon Common development infrastructure for Webthree stuff."}, {"name": "devops-test-prater-redirect", "desc": null, "readme": "devops-test-prater-redirect"}, {"name": "devp2p", "desc": "Ethereum peer-to-peer networking specifications", "readme": "This repository contains specifications for the peer-to-peer networking protocols used by\nEthereum. The issue tracker here is for discussions of protocol changes. It's also OK to\nopen an issue if you just have a question. Protocol level security issues are valuable! Please report serious issues responsibly\nthrough the Ethereum Foundation Bounty Program . We have several specifications for low-level protocols: Ethereum Node Records DNS Node Lists Node Discovery Protocol v4 Node Discovery Protocol v5 RLPx protocol The repository also contains specifications of many RLPx-based application-level protocols: Ethereum Wire Protocol (eth/68) Ethereum Snapshot Protocol (snap/1) Light Ethereum Subprotocol (les/4) Parity Light Protocol (pip/1) Ethereum Witness Protocol (wit/0) The Mission devp2p is a set of network protocols which form the Ethereum peer-to-peer network.\n'Ethereum network' is meant in a broad sense, i.e. devp2p isn't specific to a particular\nblockchain, but should serve the needs of any networked application associated with the\nEthereum umbrella. We aim for an integrated system of orthogonal parts, implemented in multiple programming\nenvironments. The system provides discovery of other participants throughout the Internet\nas well as secure communication with those participants. The network protocols in devp2p should be easy to implement from scratch given only the\nspecification, and must work within the limits of a consumer-grade Internet connection. We\nusually design protocols in a 'specification first' approach, but any specification\nproposed must be accompanied by a working prototype or implementable within reasonable\ntime. Relationship with libp2p The libp2p project was started at about the same time as devp2p and seeks to be a\ncollection of modules for assembling a peer-to-peer network from modular components.\nQuestions about the relationship between devp2p and libp2p come up rather often. It's hard to compare the two projects because they have different scope and are designed\nwith different goals in mind. devp2p is an integrated system definition that wants to\nserve Ethereum's needs well (although it may be a good fit for other applications, too)\nwhile libp2p is a collection of programming library parts serving no single application in\nparticular. That said, both projects are very similar in spirit and devp2p is slowly adopting parts of\nlibp2p as they mature. Implementations devp2p is part of most Ethereum clients. Implementations include: C#: Nethermind https://github.com/NethermindEth/nethermind C++: Aleth https://github.com/ethereum/aleth C: Breadwallet https://github.com/breadwallet/breadwallet-core Elixir: Exthereum https://github.com/exthereum/ex_wire Go: go-ethereum/geth https://github.com/ethereum/go-ethereum Java: Tuweni RLPx library https://github.com/apache/incubator-tuweni/tree/master/rlpx Java: Besu https://github.com/hyperledger/besu JavaScript: EthereumJS https://github.com/ethereumjs/ethereumjs-devp2p Kotlin: Tuweni Discovery library https://github.com/apache/incubator-tuweni/tree/master/devp2p Nim: Nimbus nim-eth https://github.com/status-im/nim-eth Python: Trinity https://github.com/ethereum/trinity Ruby: Ciri https://github.com/ciri-ethereum/ciri Ruby: ruby-devp2p https://github.com/cryptape/ruby-devp2p Rust: rust-devp2p https://github.com/rust-ethereum/devp2p Rust: openethereum https://github.com/openethereum/openethereum Rust: reth https://github.com/paradigmxyz/reth WireShark dissectors are available here: https://github.com/ConsenSys/ethereum-dissectors"}, {"name": "diary", "desc": "Archive of The Ethereum Developer logs by Jeffrey Wilcke", "readme": "The Ethereum Developer Logs Week 07 Latest entries Week 05 Week 04 Week 02 Week 01 2016"}, {"name": "discv4-crawl", "desc": null, "readme": "discv4-crawl Background Geth now ships with an implementation of EIP-1459 . This EIP defines a way to put devp2p node lists behind a DNS name. There are a couple of things worth knowing about this system: EIP-1459 is intended to be a replacement for hard-coded bootstrap node lists that we maintain in Ethereum clients.\nThis is a centralized system where all nodes configured with a certain name resolve subdomains of the name find bootstrap nodes.\nThe node list is signed with a key which will be hard-coded into the client (i.e. geth) and which we should keep in a secure place. To create suitable bootstrap node lists for all common networks, we have devised a scheme where software crawls the discovery DHT, then creates a list of all found nodes in JSON format. The crawler software can filter this list and has a built-in deployer that can install the DNS records. You can read the DNS Discovery Setup Guide for more information about the discovery DHT crawler. Description This repository contains the scripts used to automatically generate the list of nodes that are published to the multiple DNS zones. The node list is also automatically pushed to this repository. Running with docker Environment variables Name | Default | Description\n-----| ------- | ------- CRAWL_GIT_REPO | https://github.com/skylenet/discv4-dns-lists.git | Git repository used to clone and push the node list CRAWL_GIT_BRANCH | master | Git branch used for the fetch and push CRAWL_GIT_PUSH | false | When set to true , it will push the node lists to the git repository CRAWL_GIT_USER | crawler | Git username. Will appear in the commit messages. CRAWL_GIT_EMAIL | crawler@localhost | Git email address. Will appear in the commit messages. CRAWL_DNS_DOMAIN | nodes.example.local | DNS domain suffix used for the directory structure CRAWL_TIMEOUT | 30m | The time spent crawling the discovery DHT CRAWL_INTERVAL | 300 | Interval, in seconds, between multiple executions. CRAWL_RUN_ONCE | false | Set to true if you only want to run the execution once. CRAWL_DNS_SIGNING_KEY | /secrets/key.json | Path to the signing key. Won't sign if the file doesn't exist. CRAWL_DNS_PUBLISH_ROUTE53 | false | Publish the TXT records to a DNS zone on AWS Route53 ROUTE53_ZONE_ID | | Route53 DNS zone identifier. This is the zone where the records will be published to.\n`AWS_ACCESS_KEY_ID` | | AWS access key AWS_SECRET_ACCESS_KEY | | AWS secret access key\n`CRAWL_DNS_PUBLISH_CLOUDFLARE` | `false` | Publish the TXT records to a DNS zone on Cloudflare\n`CLOUDFLARE_API_TOKEN`| | API token used for the Cloudflare API CLOUDFLARE_ZONE_ID | ` | Cloudflare DNS zone identifier. This is the zone where the records will be published to. INFLUXDB_METRICS_ENABLED | false | Set to true if you want to send metrics to InfluxDB INFLUXDB_URL | http://localhost:8086 | Address of the InfluxDB API INFLUXDB_DB | metrics | Database name INFLUXDB_USER | user | Username for InfluxDB INFLUXDB_PASSWORD | password | Password for InfluxDB PROMETHEUS_METRICS_ENABLED | true | Enable prometheus metrics endpoint PROMETHEUS_METRICS_LISTEN | 0.0.0.0:9100` | Server listening Building the image sh\n$ docker build -t discv4-crawl . Run examples Run the list generation and push the results to git via SSH: sh\n$ docker run -it \\\n    -v \"$HOME/.ssh/crawler:/root/.ssh\" \\  # Needed if you use git via SSH\n    -v \"$HOME/secrets/secret-signing-key.json:/secrets/key.json\" \\ # Only needed if you want to sign the node lists\n    -e CRAWL_TIMEOUT=10m \\ # Specify your custom timeout\n    -e CRAWL_GIT_REPO=git@github.com:skylenet/discv4-dns-lists.git \\ # Use SSH instead of HTTPS\n    -e CRAWL_GIT_PUSH=true \\ # Specify that we want to push the changes\n    skylenet/discv4-crawl"}, {"name": "discv4-dns-lists", "desc": null, "readme": "discv4-dns-lists This repository contains EIP-1459 node lists built by the go-ethereum devp2p\ntool. These lists are published to the ethdisco.net DNS name. The nodes in the lists are found by crawling the Ethereum node discovery DHT. The entire\noutput of the crawl is available in the all.json file. We create lists for specific\nblockchain networks by filtering all.json according to the \"eth\" ENR entry value provided by each node. If you want your node in the list, simply run your client and make sure it is reachable\nthrough discovery. The crawler will pick it up and sort it into the right list\nautomatically."}, {"name": "distributed-validator-specs", "desc": "Ethereum Distributed Validator Specifications", "readme": "Ethereum Distributed Validator Specification Distributed Validators (DV) are a technique for distributing the job of an Ethereum validator among a set of distributed nodes in order to improve resilience (safety, liveness, or both) as compared to running a validator client on a single machine. Introduction Motivation Traditional Validator Client Setup Ethereum validators participate in the proof-of-stake (PoS) protocol by signing messages (such as blocks or attestations) using their staking private key. The staking key is accessible only by the validator client software, which schedules the creation & signing of messages according to the duties assigned to the validator. Some risks involved in a traditional validator client setup are:\n- The staking private key resides in one location. If an adversary gains access to this key, it can create conflicting messages that result in slashing of the validator's deposit.\n    - Stakers who do not operate their own validator need to hand over their staking private key to the operator. They must trust the operator for the security of their staking private key.\n- If the validator client software is unable to create timely messages to perform validator duties, the validator suffers an inactivity leak that reduces its balance.\n    - This could happen due to causes such as software crashes, loss of network connection, hardware faults, etc.\n- If the Beacon Node to which the validator client is connected has a fault, a validator may end up following a minority fork resulting it appearing to be offline to the rest of the PoS protocol. Distributed Validator Protocol The Distributed Validator protocol presents a solution to mitigate the risks & concerns associated with traditional, single Validator Client setups. In addition, this protocol can be used to enable advanced staking setups such as decentralized staking pools. Basic Concepts Note : Refer to the glossary for an explanation of new terms introduced in the Distributed Validator specifications. The two fundamental concepts behind Distributed Validators are:\n- consensus : the responsibilities of a single validator are split among several co-validators, who must work together to reach agreement on how to vote before signing any message.\n- M-of-N threshold signatures : the validator's staking key is split into N pieces and each of the co-validators holds a share. When at least M of the co-validators reach consensus on how to vote, they each sign the message with their share and a combined signature can be reconstructed from the shares. Ethereum proof-of-stake uses the BLS signature scheme, in which the private keys can be M-of-N secret-shared (using Shamir secret sharing) to implement M-of-N threshold signatures. By combining a suitable (safety-favouring) consensus algorithm with an M-of-N threshold signature scheme, the DV protocol ensures that agreement is backed up by cryptography and at least M co-validators agree about any decision. Resources Formal specification and verification The formal specification and verification of the Distributed Validator technology are currently being developed here . Implementations The following are existing implementations of Distributed Validator technology (but not necessarily implementations of this specification). python-ssv : A proof-of-concept implementation of the distributed validator protocol in Python that interacts with the Prysm Ethereum client . ssv : A Go implementation of the DV protocol that interacts with the Prysm Ethereum client . charon : An HTTP middleware client in Go that implements the DV protocol. Documents Distributed Validator Architecture Video Introduction General Architecture This specification presents a way to implement Distributed Validator Client software as middleware between the Beacon Node (BN) and a Remote Signer (RS) :\n- all communication between the BN and RS is managed by the DVC in order for it to provide the additional DV functionality.\n- the BN & RS are unaware of the presence of the DVC, i.e., they think they are connected to each other as usual. Assumptions We assume N total nodes and an M-of-N threshold signature scheme. For general compatibility with BFT consensus protocols, we assume that M = ceil(2 * N / 3) . This specification assumes some leader-based safety-favoring consensus protocol for the Co-Validators to decide on signing upon the same attestation/block. We assume that the consensus protocol runs successfully with M correct nodes, no more than F = (N-1)/3 Byzantine nodes and no more than N - M - F fail-stop nodes out of N total nodes. We assume the usual prerequisites for safe operation of the Validator Client, such as an up-to-date anti-slashing database, correct system clock, etc. We disregard the voting on the \"correct\" Ethereum fork for now - this functionality will be added in a future update. Desired Guarantees Safety (against key theft) : The Validator's staking private key is secure unless security is compromised at more than M of the N Co-Validators. Safety (against slashing) : Under the assumption of an asynchronous network, the Validator is never slashed unless more than 1/3rd of the Co-Validators are Byzantine. Under the assumption of a synchronous network, the Validator is never slashed unless more than 2/3rds of the Co-Validators are Byzantine. Liveness : The protocol will eventually produce a new attestation/block under partially synchronous network unless more than 1/3rd of the Co-Validators are Byzantine. Specification Technical details about the specification are described in src/dvspec/ ."}, {"name": "docker-pyeth-dev", "desc": "Simple pyethapp development environment", "readme": "Deprecated We are moving the development to the new spec . As an alternative, please try Casper using Harmony"}, {"name": "dopple", "desc": "Dopple: JSON-RPC Proxy Server", "readme": "Dopple HTTP proxy to Unix Socket based JSON-RPC servers Installation sh\npip install dopple Use sh\ndopple ~/.ethereum/geth.ipc http://127.0.0.1:8545 Alternatively, dopple can be invoked as a pure script without installation: sh\n./dopple/dopple.py ~/.ethereum/geth.ipc http://127.0.0.1:8545 These values above are the default ones too. If they match your current configuration, they can be ommitted. Check out --help option for more information. Read more in the documentation on ReadTheDocs . View the change log . License Apache-2.0 Developer Setup If you would like to hack on dopple, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/dopple.git\ncd dopple\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 dopple/ tests/ -c \"clear; flake8 dopple tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on dopple failed'\" ../tests ../dopple Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "economic-modeling", "desc": null, "readme": ""}, {"name": "ecp", "desc": "Ethereum chain parser", "readme": "Ethereum chain parser E thereum C hain P arser listens for Ethereum (block) chain events and turns them into MongoDB\nrecords (currently). This could be easily extended to allow importing to\nvarious database formats. These records can be accessed from a third client application. It's currently being used for the Ethereum chain explorer. This is still pre-Alpha software, not ready for production."}, {"name": "EIP-Bot", "desc": "A collection of bots that make life easier on editors", "readme": "EIP Linting Bot This Github Actions integrated bot lints EIPs and provides feedback for authors; its goal is to catch simple problems, notify the relevant individuals to review, and merge simple changes automatically. Usage ```yml\non:\n  workflow_run:\n    workflows:\n      - Auto Review Bot Trigger\n    types:\n      - completed name: Auto Review Bot\njobs:\n  auto-review-bot:\n    runs-on: ubuntu-latest\n    name: Run\n    steps:\n      - name: Fetch PR Number\n        uses: dawidd6/action-download-artifact@6765a42d86407a3d532749069ac03705ad82ebc6\n        with:\n          name: pr-number\n          workflow: auto-review-trigger.yml\n          run_id: ${{ github.event.workflow_run.id }} - name: Save PR Number\n    id: save-pr-number\n    run: echo \"::set-output name=pr::$(cat pr-number.txt)\"\n\n  - name: Checkout\n    uses: actions/checkout@2541b1294d2704b0964813337f33b291d3f8596b\n    with:\n      repository: ethereum/EIPs # Default, but best to be explicit here\n      ref: master\n\n  - name: Setup Node.js Environment\n    uses: actions/setup-node@2fddd8803e2f5c9604345a0b591c3020ee971a93\n    with:\n      node-version: 16\n\n  - name: Auto Review Bot\n    id: auto-review-bot\n    uses: ethereum/EIP-Bot@1e1bb6a58e02d28e9afa9462b00a518d9b47860e # dist\n    with:\n      GITHUB-TOKEN: ${{ secrets.TOKEN }}\n      PR_NUMBER: ${{ steps.save-pr-number.outputs.pr }}\n      CORE_EDITORS: '@MicahZoltu,@lightclient,@axic,@gcolvin,@SamWilsn,@Pandapip1'\n      ERC_EDITORS: '@lightclient,@axic,@SamWilsn,@Pandapip1'\n      NETWORKING_EDITORS: '@MicahZoltu,@lightclient,@axic,@SamWilsn'\n      INTERFACE_EDITORS: '@lightclient,@axic,@SamWilsn,@Pandapip1'\n      META_EDITORS: '@lightclient,@axic,@gcolvin,@SamWilsn,@Pandapip1'\n      INFORMATIONAL_EDITORS: '@lightclient,@axic,@gcolvin,@SamWilsn,@Pandapip1'\n      MAINTAINERS: '@alita-moore,@mryalamanchi'\n\n  - name: Enable Auto-Merge\n    uses: reitermarkus/automerge@a25ea0de41019ad13380d22e01db8f5638f1bcdc\n    with:\n      token: ${{ secrets.TOKEN }}\n      pull-request: ${{ steps.save-pr-number.outputs.pr }}\n\n  - name: Submit Approval\n    uses: hmarr/auto-approve-action@24ec4c8cc344fe1cdde70ff37e55ace9e848a1d8\n    with:\n      github-token: ${{ secrets.TOKEN }}\n      pull-request-number: ${{ steps.save-pr-number.outputs.pr }} ``` Contributing Standard Practices Function Naming This library uses concepts that may appear strange, require... : functions that start with require are used to guarantee it responds with the resource you're looking for or else it will error assert... : functions that start with assert are used to test something and if that test fails it'll respond with some kind of error message string. This is where the errors that the bot tells the author comes from. ...Purifier : functions that end in purifier are used to purify test results, they help to keep the logic of assertions clean and handle cross error dependencies like the fact that if you change the status you need an editor approval, but then once you actually get that approval we don't want to show the error for changing the status (i.e. if (changedStatus && !approvedByEditor) { return error } else if (changedStatus && approvedByEditor) { return } ). These practices are applied to make things easier to understand. If you're not careful, then the logic can get tangled very quick, and then it's really hard to read and change things. Testing This bot employs two types of tests functional integration A functional test is your standard unit test. Take a small function and test its behavior thoroughly. You don't need anything more than jest to do this, and your code should be organized such that the sub functions are abstracted and tested. It also uses dependency injection for this reason (it's typically easier to mock that way). Everything should have unit tests. An integration test is a test that considers the behavior as a whole. In this bot, we mock a network response from the github api using nock . When you do this for every network request you're able to get a snapshot and test the whole's behavior. All integration tests were once bugs that were fixed, so if you implement a feature you don't need to add an integration test. It's easier to manage this way, and it serves the purpose of reducing code regression. Integration tests tend to be brittle because of the number of different facets. So the code uses several homebrewed tools to maximize reliability. Feel free to share ideas on how to improve testing procedures. Getting Started Requirements node package manager (npm) Github Token Forked Repo nodejs Quick Start (npm run it) npm run it runs the bot end to end; which means you can integrate and test with github directly. It uses the typescript built script so don't forget to build that by using npm run build or npm run watch . Download your forked EIPS repo Create a Github Token Create a PR in your forked repo doing anything, I recommend just editing a couple lines in an already existing EIPs Create a .env variable in the root dir with the following information defined: ```\nGITHUB_TOKEN = NODE_ENV = development PULL_NUMBER = BASE_SHA = HEAD_SHA = REPO_OWNER_NAME = REPO_NAME = EIPs\nGITHUB_REPOSITORY = /EIPs\n``` npm run build && npm run it Quick Start (npm run mock) npm run mock is a tool built for writing integration tests, but it can also be used to develop. npm run mock uses the saved network data of previous pull requests and states of those pull requests. Try this by mocking pull 3670 .. Clone this repo Setup your local environment (requires node > 14.x): npm install Create a .env variable in the root dir with the following information: ```\nGITHUB_TOKEN = anything PULL_NUMBER = 3670\nREPO_OWNER_NAME = ethereum\nREPO_NAME = EIPs\nGITHUB_REPOSITORY = ethereum/EIPs\nEVENT_TYPE = pull_request_target\n``` Then run the mock npm run mock You should get a response like the following ```bash\nalitamoore@Alitas-MBP EIP-Bot % npm run mock auto-merge-eip@1.0.0 mock /Users/alitamoore/ethereum/EIP-Bot\nNODE_ENV=MOCK node -r dotenv/config build/src/index.js failed to pass tests with the following errors:\n        - File with name EIPS/eip-3670.md is new and new files must be reviewed\n        - This PR requires review from one of [@micahzoltu, @lightclient, @arachnid, @cdetrio, @souptacular, @vbuterin, @nicksavers, @wanderer, @gcolvin]\n::error::failed to pass tests with the following errors:%0A     - File with name EIPS/eip-3670.md is new and new files must be reviewed%0A      - This PR requires review from one of [@micahzoltu, @lightclient, @arachnid, @cdetrio, @souptacular, @vbuterin, @nicksavers, @wanderer, @gcolvin]\nnpm ERR! code ELIFECYCLE\nnpm ERR! errno 1\nnpm ERR! auto-merge-eip@1.0.0 mock: NODE_ENV=MOCK node -r dotenv/config build/src/index.js npm ERR! Exit status 1\nnpm ERR!\nnpm ERR! Failed at the auto-merge-eip@1.0.0 mock script.\nnpm ERR! This is probably not a problem with npm. There is likely additional logging output above. npm ERR! A complete log of this run can be found in:\nnpm ERR!     /Users/alitamoore/.npm/_logs/2021-07-25T06_43_54_229Z-debug.log\n``` In this case, an error was expected because the bug in question was if the editors were mentioned if a status error occurred (if the status wasn't one of the allowed types) Troubleshooting When I run it, I'm getting unexplainable errors with my github requests. Github limits the number of requests from a given IP, this may be avoidable if you only use the octokit but a VPN also works just fine Code Style Guidelines (in no particular order) This repo is a living repo, and it will grow with the EIP drafting and editing process. It's important to maintain code quality. Define every type (including octokit) Make clean and clear error messages Avoid abstraction Use enums as much as possible Explanations of Style Guidelines A couple things to keep in mind if you end up making changes to this 1. Define every type Define every type, no any types. The time it takes to define a type now will save you or someone else later a lot of time. If you make assumptions about types, protect those assumptions (throw exception if they are false). Sometimes Octokit types can be difficult to index, but it's important that whenever possible the types are defined and assumptions protected. 2. Make clean and clear error messages This bot has a single goal: catch simple mistakes automatically and save the editors time. So clear error messages that allow the PR author to change it themselves are very important. 3. Avoid Abstraction Only abstract if necessary, keep things in one file where applicable; other examples of okay abstraction are types, regex, and methods used more than 3 times. Otherwise, it's often cleaner to just re-write things. ```javascript\n// DON'T DO THIS\n** src/lib.ts **\nexport const baz = () => \"baz\" ** src/foo.ts **\nimport { baz } from \"./lib\"\nexport const foo = () => baz(); ** src/bar.ts **\nimport { baz } from \"./lib\"\nexport const bar = () => baz(); // DO THIS\n** src/foo.ts **\nconst baz = () => \"baz\"\nexport const foo = () => baz(); ** src/bar.ts **\nconst baz = () => \"baz\"\nexport const bar = () => baz();\n``` 4. Always use enum when defining restricted string types In short, enums make code easier to read, trace, and maintain. But here's a brief info if you haven't worked with them before typescript\nenum EnumFoo {\n  bar = \"BAR\",\n  baz = \"BAZ\"\n}\ntype Foo = \"BAR\" | \"BAZ\"; Inline declaration is maintained typescript\nconst foo: EnumFoo;\nconst bar: Foo;\n// foo and bar both must be either \"BAR\" or \"BAZ\" Use case is slightly different typescript\nconst foo: EnumFoo = EnumFoo.baz; // you can't directly assign \"BAZ\"\nconst bar: Foo = \"BAZ\"; But comparisons are maintained typescript\n// taking variables from above\n(\"BAZ\" === foo) === (\"BAZ\" === bar) &&\n  (\"BAZ\" === EnumFoo.baz) === (\"BAZ\" === \"BAZ\"); In addition to the above use case and string eradication it centralizes the strings to be matched so they can be easily changed. So, making life much easier if you wanted to change the names of statuses on an EIP."}, {"name": "eip-review-bot", "desc": "Request reviewers for EIP modifications", "readme": "eip-review-bot Automatically request reviewers for the ethereum/EIPs repository."}, {"name": "EIPs", "desc": "The Ethereum Improvement Proposal repository", "readme": "Ethereum Improvement Proposals (EIPs) ATTENTION : The EIPs repository has recently undergone a separation of ERCs and EIPs. ERCs are now accessible at https://github.com/ethereum/ercs . All new ERCs and updates to existing ones must be directed at this new repository. The editors apologize for this inconvenience. The goal of the EIP project is to standardize and provide high-quality documentation for Ethereum itself and conventions built upon it. This repository tracks past and ongoing improvements to Ethereum in the form of Ethereum Improvement Proposals (EIPs). EIP-1 governs how EIPs are published. The status page tracks and lists EIPs, which can be divided into the following categories: Core EIPs are improvements to the Ethereum consensus protocol. Networking EIPs specify the peer-to-peer networking layer of Ethereum. Interface EIPs standardize interfaces to Ethereum, which determine how users and applications interact with the blockchain. ERCs specify application layer standards, which determine how applications running on Ethereum can interact with each other. Meta EIPs are miscellaneous improvements that nonetheless require some sort of consensus. Informational EIPs are non-standard improvements that do not require any form of consensus. Before you write an EIP, ideas MUST be thoroughly discussed on Ethereum Magicians or Ethereum Research . Once consensus is reached, thoroughly read and review EIP-1 , which describes the EIP process. Please note that this repository is for documenting standards and not for help implementing them. These types of inquiries should be directed to the Ethereum Stack Exchange . For specific questions and concerns regarding EIPs, it's best to comment on the relevant discussion thread of the EIP denoted by the discussions-to tag in the EIP's preamble. If you would like to become an EIP Editor, please read EIP-5069 . Preferred Citation Format The canonical URL for an EIP that has achieved draft status at any point is at https://eips.ethereum.org/ . For example, the canonical URL for EIP-1 is https://eips.ethereum.org/EIPS/eip-1 . Consider any document not published at https://eips.ethereum.org/ as a working paper. Additionally, consider published EIPs with a status of \"draft\", \"review\", or \"last call\" to be incomplete drafts, and note that their specification is likely to be subject to change. Validation and Automerging All pull requests in this repository must pass automated checks before they can be automatically merged: eip-review-bot determines when PRs can be automatically merged ^1 EIP-1 rules are enforced using eipw ^2 HTML formatting and broken links are enforced using HTMLProofer ^2 Spelling is enforced with CodeSpell ^2 False positives sometimes occur. When this happens, please submit a PR editing .codespell-whitelist and ONLY .codespell-whitelist Markdown best practices are checked using markdownlint ^2 It is possible to run the EIP validator locally: sh\ncargo install eipv\neipv <INPUT FILE / DIRECTORY> Build the status page locally Install prerequisites Open Terminal. Check whether you have Ruby 3.1.4 installed. Later versions are not supported . sh\n   ruby --version If you don't have Ruby installed, install Ruby 3.1.4. Install Bundler: sh\n   gem install bundler Install dependencies: sh\n   bundle install Build your local Jekyll site Bundle assets and start the server: sh\n   bundle exec jekyll serve Preview your local Jekyll site in your web browser at http://localhost:4000 . More information on Jekyll and GitHub Pages here ."}, {"name": "eipv", "desc": "Ethereum Improvement Proposal Validator", "readme": "EIP validator Superseded by eipw An engine which ensures Ethereum Improvement\nProposals meet certain requirements. Getting Started To install eipv and validate the EIPs repository: console\ngit clone https://github.com/lightclient/eipv.git\ncargo install --path=eipv eipv\neipv /path/to/EIPS Requirements This tracks what eipv can validate. [x] Preamble starts with --- [x] Preamble ends with --- [x] Preamble includes all required fields: eip title description author discussions-to created status type category (iff type == \"Standards Track\") [x] Preamble does not include any unknown fields [ ] Preamble fields are properly formed: [x] Each field is of the shape {field}: {value}\\n [x] eip is an unsigned integer [x] title is a string whose length is less than 44 characters [x] author is a comma-separated string of author information which has\n  three possible shapes: Name only: John A. Doe Name and email: John A. Doe <john@doe.com> Name and Github username: John A. Doe (@johndoe) [x] discussions-to is a URL where discussions regarding the EIP should be\n  directed [ ] discussions-to does not point to a PR [x] status is one of the following string values: draft last call accepted final abandoned rejected superseded [x] type is one of the following string values: standards track informational meta [x] category is one of the following string values: core networking interface erc [x] last-call-deadline is a date value [x] created is a date value [x] updated is a comma-separated list of date values [x] requires is a comma-separated list of EIP numbers in ascending order [x] withdrawal-reason is a string [ ] EIP numbers listed as required exist [ ] The EIP body includes the required sections in the following order: Abstract Motivation Specification Rationale Backwards Compatibility Test Cases Implementations Security Considerations Copyright Waiver [ ] The Abstract section is no longer than 200 words [ ] The Copyright Waiver section contains only the following string: Copyright and related rights waived via CC0. [ ] The EIP body does not include any unclosed brackets or parentheses\n  outside of code snippets [ ] File name is of form eip-N.md , where N coresponds to the EIP's assigned number [ ] URLs to other EIPs are relative links [x] No trailing whitespace in preamble"}, {"name": "eipw", "desc": null, "readme": "eipw The EIP validator that's one more than eipv . ```\nUSAGE:\n    eipw [OPTIONS] [SOURCES]... ARGS: ...    Files and/or directories to check OPTIONS:\n        --format Output format [default: text] [possible values: text, json]\n    -h, --help                Print help information\n        --lints Additional lints to enable\n        --list-lints          List all available lints\n        --no-default-lints    Do not enable the default lints\n``` Demo Example EIP ```markdown eip: 2\ndescription: A really short example of an EIP.\ntitle: Sample of an EIP\nauthor: Sam Wilson (@SamWilsn)\ndiscussions-to: https://example.com/\nstatus: Living\ntype: Meta\ncreated: 2022-06-30 Specification Implementers of this EIP must... Abstract This is an abstract!\n``` Output error[markdown-order-section]: section `Specification` must come after `Motivation`\n  --> /tmp/demo.md\n   |\n12 | ## Specification\n   |\nerror[preamble-order]: preamble header `description` must come after `title`\n --> /tmp/demo.md\n  |\n3 | description: A really short example of an EIP.\n  | Lints | id                                  | Description                                                                                   |\n|-------------------------------------|-----------------------------------------------------------------------------------------------|\n| markdown-html-comments | There are no HTML comments in review-ready EIPs                                               |\n| markdown-json-cite | All csl-json code blocks adhere to the correct schema.                                      |\n| markdown-link-first | First mention of an EIP must be a link.                                                       |\n| markdown-link-status | EIPs linked in the body have statuses further along than the current proposal.                |\n| markdown-order-section | There are no extra sections and the sections are in the correct order.                        |\n| markdown-re-eip-dash | Other EIPs are referenced using EIP-X, not EIPX or EIP X.                                     |\n| markdown-re-erc-dash | Other ERCs are referenced using ERC-X, not ERCX or ERC X.                                     |\n| markdown-refs | ERCs are referenced using ERC-X, while other proposals use EIP-X.                             |\n| markdown-rel-links | All URLs in the page are relative.                                                            |\n| markdown-req-section | Required sections are present in the body of the proposal.                                    |\n| preamble-author | The author header is correctly formatted, and there is at least one GitHub user listed.       |\n| preamble-date-created | The created header is a date.                                                               |\n| preamble-date-last-call-deadline | The last-call-deadline header is a date.                                                    |\n| preamble-discussions-to | The discussions-to header is a valid URL.                                                   |\n| preamble-eip | The eip header is a non-negative integer.                                                   |\n| preamble-enum-category | The category header is a recognized value.                                                  |\n| preamble-enum-status | The status header is a recognized value.                                                    |\n| preamble-enum-type | The type header is a recognized value.                                                      |\n| preamble-file-name | The file name reflects the EIP number.                                                        |\n| preamble-len-description | The description header isn't too long.                                                      |\n| preamble-len-title | The title header isn't too long.                                                            |\n| preamble-len-requires | The requires header has at least one item.                                                  |\n| preamble-list-author | The author header is a correctly formatted comma-separated list.                            |\n| preamble-list-requires | The requires header is a correctly formatted comma-separated list.                          |\n| preamble-no-dup | There are no duplicate headers.                                                               |\n| preamble-order | The preamble headers are in the correct order.                                                |\n| preamble-re-description | The description doesn't contain \"standard\" or similar words.                                  |\n| preamble-re-description-colon | The description doesn't contain any \":\" characters.                                           |\n| preamble-re-description-eip-dash | EIPs referenced in the description header use a dash.                                       |\n| preamble-re-description-erc-dash | ERCs referenced in the description header use a dash.                                       |\n| preamble-re-discussions-to | The discussions-to header points to Ethereum Magicians                                      |\n| preamble-re-title | The title doesn't contain \"standard\" or similar words.                                        |\n| preamble-re-title-colon | The title doesn't contain any \":\" characters.                                                 |\n| preamble-re-title-eip-dash | EIPs referenced in the title header use a dash.                                             |\n| preamble-re-title-erc-dash | ERCs referenced in the title header use a dash.                                             |\n| preamble-refs-description | ERCs referenced in the description header use the ERC- prefix.                            |\n| preamble-refs-title | ERCs referenced in the title header use the ERC- prefix.                                  |\n| preamble-req | All required preamble headers are present.                                                    |\n| preamble-req-category | The category header is present only when required.                                          |\n| preamble-req-last-call-deadline | The last-call-deadline header is present only when required.                                |\n| preamble-req-withdrawal-reason | The withdrawal-reason header is present only when required.                                 |\n| preamble-requires-ref-description | Proposals mentioned in the description header appear in the requires header.              |\n| preamble-requires-ref-title | Proposals mentioned in the title header appear in the requires header.                    |\n| preamble-requires-status | EIPs listed in requires have statuses further along than the current proposal.              |\n| preamble-trim | There is no extra whitespace around preamble fields.                                          |\n| preamble-uint-requires | The requires header is a sorted list of non-negative integers.                              | JavaScript / WebAssembly eipw-lint-js packages eipw as an npm package, for use in JavaScript / TypeScript. You can find the package on npm . Building & Publishing bash\ncd eipw-lint-js\nwasm-pack test --node\nwasm-pack build -t nodejs\nwasm-pack publish -t nodejs"}, {"name": "eipw-action", "desc": "Action for executing eipw, the EIP validator", "readme": "eipw-action A GitHub Action for running eipw , an Ethereum Improvement Proposal linter. Usage Here's an example workflow (so it would go in .github/workflows/ci.yml or similar): ```yaml\non:\n  pull_request: name: ci jobs:\n  check:\n    name: Check\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3.0.2\n      - uses: ethereum/eipw-action@dist\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n``` Building & Deploying bash\nnpm install         # Grab dependencies.\nnpm run build       # Compile TypeScript and create bundle.\ngit add .\ngit commit\ngit push            # Make the new build available."}, {"name": "eip_validator", "desc": null, "readme": "EIP validator Validation rules Mandatory fields eip title author type category (conditional on type) status created Optional fields discussions-to layer replaces requires resolution review-period-end superseded-by updated Mandatory values status must be 'Draft', 'Last Call', 'Accepted', 'Final', 'Active', 'Abandoned', 'Deferred', 'Rejected', or 'Superseded' Prerequisite ruby Setup gem install eip_validator Usage (command line) ruby\neip_validator INPUT_FILES Usage (as a lib) ```ruby\nrequire 'eip_validator EipValidator::Runner.run \n``` Example ```\n$eip_validator  ~/src/EIPs/EIPS/*[0-9].md Warning: /Users/makoto/src/EIPs/EIPS/eip-158.md      unknown attribute 'superseded-by' for EipValidator::Validator.\nWarning: /Users/makoto/src/EIPs/EIPS/eip-615.md      unknown attribute 'edited' for EipValidator::Validator. total:51, valid:49, invalid:0, errors:2\n    statuses: [[\"Final\", 29], [\"Draft\", 17], [\"Accepted\", 2], [\"Active\", 1]]\n    types: [[\"Meta\", 6], [\"Standards Track\", 42], [\"Standard Track\", 1]]\n    categories: [[nil, 6], [\"Core\", 23], [\"ERC\", 11], [\"Interface\", 5], [\"Networking\", 4]]\n    layers: [[nil, 47], [\"Applications\", 1], [\"Process\", 1]] ``` Running tests bundle exec rspec Releasing new gem gem bump --version patch|minor|major\nbundle exec rake release"}, {"name": "emacs-solidity", "desc": "The official solidity-mode for EMACS", "readme": null}, {"name": "ens-namehash-py", "desc": "A python implementation of the namehash algorithm from EIP137 ", "readme": "ENS Namehash This package is an implementation of the namehash algorithm from EIP137 . Quickstart Install the package: bash\n$ pip install ens-namehash Hash some names! ```python from namehash import namehash\nnamehash('')\n... b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\nnamehash('eth')\n... b'\\x93\\xcd\\xebp\\x8buE\\xdcf\\x8e\\xb9(\\x01v\\x16\\x9d\\x1c3\\xcf\\xd8\\xedo\\x04i\\n\\x0b\\xcc\\x88\\xa9?\\xc4\\xae'\nnamehash('foo.eth')\n... b'\\xde\\x9b\\t\\xfd|_\\x90\\x1e#\\xa3\\xf1\\x9f\\xec\\xc5H(\\xe9\\xc8HS\\x98\\x01\\xe8e\\x91\\xbd\\x98\\x01\\xb0\\x19\\xf8O'\n```"}, {"name": "ens-registrar-dapp", "desc": "Registrar DApp for the Ethereum Name Service", "readme": "Ethereum Name Service Registrar DApp This app allows you to register a .eth domain name, for use in ethereum decentralized applications and compatible blockchain browsers. Check ens.domains for more information about the ENS. Try the app: registrar.ens.domains How to run it cd app\nmeteor npm install\nmeteor Deploying to github pages A static copy of the app is kept at registrar.ens.domains . The page reflects whatever is kept at the docs folder in the master branch. So to update the static site, create a working branch and execute these: cd app\nmeteor-build-client ../docs --path \"\"\ncd ..\ngit add . Then commit all and make a Pull Request to master."}, {"name": "ERCs", "desc": "The Ethereum Request for Comment repository ", "readme": "Ethereum Request for Comments (ERCs) Please note that ERCs were recently separated from the EIPs repo. The goal of ERCs is to standardize and provide high-quality documentation for the Ethereum application layer. This repository tracks past and ongoing improvements application standards in the form of ERCs. EIP-1 governs how EIPs and ERCs are published. The status page tracks and lists both EIPs and ERCs, which can be divided into the following categories: Core EIPs are improvements to the Ethereum consensus protocol. Networking EIPs specify the peer-to-peer networking layer of Ethereum. Interface EIPs standardize interfaces to Ethereum, which determine how users and applications interact with the blockchain. ERCs specify application layer standards, which determine how applications running on Ethereum can interact with each other. Meta EIPs are miscellaneous improvements that nonetheless require some sort of consensus. Informational EIPs are non-standard improvements that do not require any form of consensus. Before you write an ERC, ideas MUST be thoroughly discussed on Ethereum Magicians or Ethereum Research . Once consensus is reached, thoroughly read and review EIP-1 , which describes the EIP/ERC process. Please note that this repository is for documenting standards and not for help implementing them. These types of inquiries should be directed to the Ethereum Stack Exchange . For specific questions and concerns regarding ERCs, it's best to comment on the relevant discussion thread of the ERC denoted by the discussions-to tag in the ERC's preamble. If you would like to become an EIP Editor, please read EIP-5069 . Preferred Citation Format The canonical URL for an ERC that has achieved draft status at any point is at https://eips.ethereum.org/ . For example, the canonical URL for EIP-1 is https://eips.ethereum.org/EIPS/eip-1 . Consider any document not published at https://eips.ethereum.org/ as a working paper. Additionally, consider published EIPs with a status of \"draft\", \"review\", or \"last call\" to be incomplete drafts, and note that their specification is likely to be subject to change."}, {"name": "esp-website", "desc": "Website for the Ethereum Foundation's Ecosystem Support Program (ESP):", "readme": "Ethereum Ecosystem Support Program The Ethereum Ecosystem Support Program exists to provide both financial and non-financial support to projects and entities within the greater Ethereum community, in order to accelerate the growth of the ecosystem. The Ecosystem Support Program is an expansion of the original Ethereum Grants Program which mainly focused on financial support. Our focus is on deploying our resources where they will have the biggest impact. This repository holds the codebase to our website, esp.ethereum.foundation Stack The main stack used in the project includes: Next.js . TypeScript . ChakraUI as component library. react-hook-form to validate forms. Framer Motion to animate buttons. ESLint and Prettier for linting and code formatting. Local development The project is bootstrapped with create-next-app , with a custom scaffolding. Getting Started First, run the development server: ```bash\nnpm run dev or yarn dev\n``` Open http://localhost:3000 with your browser to see the result. You can start editing the page by modifying pages/index.tsx . The page auto-updates as you edit the file. API routes can be accessed on http://localhost:3000/api/hello . This endpoint can be edited in pages/api/hello.ts . The pages/api directory is mapped to /api/* . Files in this directory are treated as API routes instead of React pages. testing w/hCaptcha locally We can use hCaptcha testing keys (already defined on .env.local.example ) to be able to test forms locally. Project Structure The following list describes the main elements of the project structure: public : contains static assets like fonts and images. src : contains the source code. components : React components. components with state are directly located inside /components . forms : components used in forms. api.ts : this file contains the api fetching logic details used when submitting the forms data. layout : components used to contain and apply different layouts to different pages. UI : stateless (functional) components. hooks : custom hooks. middlewares : custom middlewares (required for captcha input validation). pages : includes components that renders to pages and NextJS API Routes . theme : contains the Chakra UI custom theme , organized in foundations and components for better scaling. utils constants.ts : this is the global constants file (we have another one for specific form constants ), containing URLs and lists of elements we use across the site. global.css : global stylesheet. types.ts : contains the custom defined TypeScript types and interfaces. Salesforce Integration For the custom integration with the Salesforce API, we rely on the JSforce library. Some operations are not documented and were the result of lots of googling, SO and Github issues scanning . The Salesforce API field names (listed on types.ts ) are defined in Salesforce for each corresponding object (Lead, Contract, etc). Connected App To enable a custom API integration with Salesforce, you need to create a Connected App . You'll need an account with admin permissions. Go to Setup > App Manager > New connected app to create a new one. Configuration Check that your Connected App is configured with the following parameters Callback URL: https://salesforce.com Selected OAuth Scopes: Manage user data via APIs (api) Manage user data via Web browsers (web) Perform requests at any time (refresh_token, offline_access) Connected App policies: IP Relaxation: Relax IP Restrictions Permitted Users: All users may self-authorized Refresh Token Policy: Refresh token is valid until revoked Common issues Some common issues regarding Salesforce data types Picklist : if you get the error Error 'bad value for restricted picklist field' appears when a record is created when creating a new record, try disabling the 'Restrict picklist to the values defined in the value set' option for the corresponding field. Checkbox : besides how you're handling this input on the UI (e.g.: a radio button), Salesforce expects the value to be a boolean ( true , false ), so remember to convert the string before submitting the data. When adding new Grants Check that the hardwired string value of Proactive_Community_Grants_Round__c is defined on Salesforce, otherwise submission will fail. Grantees List data source The data published in the Latest Grantees list is being pulled from a Google Spreadsheet maintained by the ESP Team. This document uses Markdown syntax as it's also being used as source for other pages. To accomplish that, we publish the content of the document as CSV and then render it in the LatestGranteesList component. This includes some parsing work, from CSV to JSON and then rendering the Markdown. This process happens server-side only, on build time , so the resulting page is completely static. Tutorials Learning NextJS To learn more about Next.js, take a look at the following resources: Next.js Documentation - learn about Next.js features and API. Learn Next.js - an interactive Next.js tutorial. Adding ChakraUI to a NextJS project This is a very clear and step-by-step guide on it. Learning ChakraUI We recommend checking the official docs ."}, {"name": "eth-abi", "desc": "Ethereum ABI utilities for python", "readme": "Ethereum Contract Interface (ABI) Utility Python utilities for working with Ethereum ABI definitions, especially encoding and decoding Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npython -m pip install eth-abi Developer Setup If you would like to hack on eth-abi, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-abi.git\ncd eth-abi\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-account", "desc": "Account abstraction library for web3.py", "readme": "eth-account Sign Ethereum transactions and messages with local private keys Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npython -m pip install eth-account Developer Setup If you would like to hack on eth-account, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-account.git\ncd eth-account\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\" To run the integration test cases, you need to install node and the custom cli tool as follows: sh\napt-get install -y nodejs  # As sudo\n./tests/integration/js-scripts/setup_node_v20.sh  # As sudo\ncd tests/integration/js-scripts\nnpm install -g .  # As sudo Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-bloom", "desc": "An implementation of the Ethereum bloom filter.", "readme": "eth-bloom A python implementation of the bloom filter used by Ethereum. This library and repository was previously located at https://github.com/pipermerriam/ethereum-bloom.  It was transferred to the Ethereum foundation github in November 2017 and renamed to eth-bloom .  The PyPi package was also renamed from ethereum-bloom to `eth-bloom. Read more in the documentation below. View the change log . For more information on what Ethereum Bloom Filters are see here . Quickstart sh\npython -m pip install eth-bloom Usage The BloomFilter object ```python from eth_bloom import BloomFilter\nb = BloomFilter()\nb'a value' in b  # check whether a value is present\nFalse\nb.add(b'a value')  # add a single value\nb'a value' in b\nTrue\nint(b)  # cast to an integer\n3458628712844765018311492773359360516229024449585949240367644166080576879632652362184119765613545163153674691520749911733485693171622325900647078772681584616740134230153806267998022370194756399579977294154062696916779055028045657302214591620589415314367270329881298073237757853875497241510733954508399863880080986777555986663988492288946856978031023631618215522505971170427986911575695114157059398791122395379400594948096\nbin(b)  # cast to a binary string\n'0b100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000'\n``` You can also add an iterable of items to a bloom filter. ```python b = BloomFilter()\nb'value-a' in b\nFalse\nb'value-b' in b\nFalse\nb.extend([b'value-a', b'value-b'])\nb'value-a' in b\nTrue\nb'value-b' in b\nTrue\n``` You can initialize a bloom filter from an iterable of byte strings. ```python b = BloomFilter.from_iterable([b'value-a', b'value-b'])  # initialize from an iterable of values.\nb'value-a' in b\nTrue\nb'value-b' in b\nTrue\n``` You can initialize a bloom filter from the integer representation of the bloom bits. ```python b = BloomFilter(3458628712844765018311492773359360516229024449585949240367644166080576879632652362184119765613545163153674691520749911733485693171622325900647078772681584616740134230153806267998022370194756399579977294154062696916779055028045657302214591620589415314367270329881298073237757853875497241510733954508399863880080986777555986663988492288946856978031023631618215522505971170427986911575695114157059398791122395379400594948096)\nb'a value' in b\nTrue\n``` You can also merge bloom filters ```python from eth_bloom import BloomFilter\nb1 = BloomFilter()\nb2 = BloomFilter()\nb1.add(b'a')\nb1.add(b'common')\nb2.add(b'b')\nb2.add(b'common')\nb'a' in b1\nTrue\nb'b' in b1\nFalse\nb'common' in b1\nTrue\nb'a' in b2\nFalse\nb'b' in b2\nTrue\nb'common' in b2\nTrue\nb3 = b1 + b2  # using addition\nb'a' in b3\nTrue\nb'b' in b3\nTrue\nb'common' in b3\nTrue\nb4 = b1 | b2  # or using bitwise or\nb'a' in b4\nTrue\nb'b' in b4\nTrue\nb'common' in b4\nTrue\nb1 |= b2  # or using in-place operations (works with += too)\nb'a' in b1\nTrue\nb'b' in b1\nTrue\nb'common' in b1\nTrue\n``` Developer Setup If you would like to hack on eth-bloom, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-bloom.git\ncd eth-bloom\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-enr", "desc": "Ethereum Name Record (ENR) library for Python", "readme": "Ethereum Name Record (ENR) library for Python Python library for ENR (EIP-778) records Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install eth-enr Developer Setup If you would like to hack on eth-enr, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-enr.git\ncd eth-enr\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 eth_enr/ tests/ -c \"clear; flake8 eth_enr tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on eth-enr failed'\" ../tests ../eth_enr Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-hash", "desc": "The Ethereum hashing function, keccak256, sometimes (erroneously) called sha256 or sha3", "readme": "eth-hash The Ethereum hashing function, keccak256, sometimes (erroneously) called sha3 Note: the similarly named pyethash has a completely different use: it generates proofs of work. This is a low-level library, intended to be used internally by other Ethereum tools.\nIf you're looking for a convenient hashing tool, check out eth_utils.keccak() which will be a little friendlier, and provide access to other helpful utilities. Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npython -m pip install \"eth-hash[pycryptodome]\" ```py from eth_hash.auto import keccak\nkeccak(b'')\nb\"\\xc5\\xd2F\\x01\\x86\\xf7#<\\x92~}\\xb2\\xdc\\xc7\\x03\\xc0\\xe5\\x00\\xb6S\\xca\\x82';{\\xfa\\xd8\\x04]\\x85\\xa4p\"\n``` See the docs for more about choosing and installing backends. Developer Setup If you would like to hack on eth-hash, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-hash.git\ncd eth-hash\npython -m virtualenv venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-keyfile", "desc": "Tools for handling the encrypted keyfile format used to store private keys.", "readme": "eth-keyfile A library for handling the encrypted keyfiles used to store ethereum private keys This library and repository was previously located at https://github.com/pipermerriam/ethereum-keyfile.  It was transferred to the Ethereum foundation github in November 2017 and renamed to eth-keyfile .  The PyPi package was also renamed from ethereum-keyfile to eth-keyfile . Read more in the documentation below. View the change log . Quickstart sh\npython -m pip install eth-keyfile Documentation eth_keyfile.load_keyfile(path_or_file_obj) --> keyfile_json Takes either a filesystem path represented as a string or a file object and\nreturns the parsed keyfile json as a python dictionary. ```python from eth_keyfile import load_keyfile\nload_keyfile('path/to-my-keystore/keystore.json')\n{\n    \"crypto\" : {\n        \"cipher\" : \"aes-128-ctr\",\n        \"cipherparams\" : {\n            \"iv\" : \"6087dab2f9fdbbfaddc31a909735c1e6\"\n        },\n        \"ciphertext\" : \"5318b4d5bcd28de64ee5559e671353e16f075ecae9f99c7a79a38af5f869aa46\",\n        \"kdf\" : \"pbkdf2\",\n        \"kdfparams\" : {\n            \"c\" : 262144,\n            \"dklen\" : 32,\n            \"prf\" : \"hmac-sha256\",\n            \"salt\" : \"ae3cd4e7013836a3df6bd7241b12db061dbe2c6785853cce422d148a624ce0bd\"\n        },\n        \"mac\" : \"517ead924a9d0dc3124507e3393d175ce3ff7c1e96529c6c555ce9e51205e9b2\"\n    },\n    \"id\" : \"3198bc9c-6672-5ab3-d995-4942343ae5b6\",\n    \"version\" : 3\n}\n``` eth_keyfile.create_keyfile_json(private_key, password, kdf=\"pbkdf2\", work_factor=None, salt_size=16) --> keyfile_json Takes the following parameters: private_key : A bytestring of length 32 password : A bytestring which will be the password that can be used to decrypt the resulting keyfile. kdf : The key derivation function.  Allowed values are pbkdf2 and scrypt .  By default, pbkdf2 will be used. work_factor : The work factor which will be used for the given key derivation function.  By default 1000000 will be used for pbkdf2 and 262144 for scrypt . salt_size : Salt size in bytes. Returns the keyfile json as a python dictionary. ```python private_key = b'\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01'\ncreate_keyfile_json(private_key, b'foo')\n{\n    \"address\" : \"1a642f0e3c3af545e7acbd38b07251b3990914f1\",\n    \"crypto\" : {\n        \"cipher\" : \"aes-128-ctr\",\n        \"cipherparams\" : {\n            \"iv\" : \"6087dab2f9fdbbfaddc31a909735c1e6\"\n        },\n        \"ciphertext\" : \"5318b4d5bcd28de64ee5559e671353e16f075ecae9f99c7a79a38af5f869aa46\",\n        \"kdf\" : \"pbkdf2\",\n        \"kdfparams\" : {\n            \"c\" : 262144,\n            \"dklen\" : 32,\n            \"prf\" : \"hmac-sha256\",\n            \"salt\" : \"ae3cd4e7013836a3df6bd7241b12db061dbe2c6785853cce422d148a624ce0bd\"\n        },\n        \"mac\" : \"517ead924a9d0dc3124507e3393d175ce3ff7c1e96529c6c555ce9e51205e9b2\"\n    },\n    \"id\" : \"3198bc9c-6672-5ab3-d995-4942343ae5b6\",\n    \"version\" : 3\n}\n``` eth_keyfile.decode_keyfile_json(keyfile_json, password) --> private_key Takes the keyfile json as a python dictionary and the password for the keyfile,\nreturning the decoded private key. ```python keyfile_json = {\n...     \"crypto\" : {\n...         \"cipher\" : \"aes-128-ctr\",\n...         \"cipherparams\" : {\n...             \"iv\" : \"6087dab2f9fdbbfaddc31a909735c1e6\"\n...         },\n...         \"ciphertext\" : \"5318b4d5bcd28de64ee5559e671353e16f075ecae9f99c7a79a38af5f869aa46\",\n...         \"kdf\" : \"pbkdf2\",\n...         \"kdfparams\" : {\n...             \"c\" : 262144,\n...             \"dklen\" : 32,\n...             \"prf\" : \"hmac-sha256\",\n...             \"salt\" : \"ae3cd4e7013836a3df6bd7241b12db061dbe2c6785853cce422d148a624ce0bd\"\n...         },\n...         \"mac\" : \"517ead924a9d0dc3124507e3393d175ce3ff7c1e96529c6c555ce9e51205e9b2\"\n...     },\n...     \"id\" : \"3198bc9c-6672-5ab3-d995-4942343ae5b6\",\n...     \"version\" : 3\n... }\ndecode_keyfile_json(keyfile_json, b'foo')\nb'\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01'\n``` eth_keyfile.extract_key_from_keyfile(path_or_file_obj, password) --> private_key Takes a filesystem path represented by a string or a file object and the\npassword for the keyfile.  Returns the private key as a bytestring. ```python extract_key_from_keyfile('path/to-my-keystore/keyfile.json', b'foo')\nb'\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01'\n``` Developer Setup If you would like to hack on eth-keyfile, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-keyfile.git\ncd eth-keyfile\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-keys", "desc": "A common API for Ethereum key operations.", "readme": "eth-keys Common API for Ethereum key operations This library and repository was previously located at https://github.com/pipermerriam/ethereum-keys.  It was transferred to the Ethereum foundation github in November 2017 and renamed to eth-keys .  The PyPi package was also renamed from ethereum-keys to eth-keys . Read more in the documentation below. View the change log . Quickstart sh\npython -m pip install eth-keys ```python from eth_keys import keys\npk = keys.PrivateKey(b'\\x01' * 32)\nsignature = pk.sign_msg(b'a message')\npk\n'0x0101010101010101010101010101010101010101010101010101010101010101'\npk.public_key\n'0x1b84c5567b126440995d3ed5aaba0565d71e1834604819ff9c17f5e9d5dd078f70beaf8f588b541507fed6a642c5ab42dfdf8120a7f639de5122d47a69a8e8d1'\nsignature\n'0xccda990dba7864b79dc49158fea269338a1cf5747bc4c4bf1b96823e31a0997e7d1e65c06c5bf128b7109e1b4b9ba8d1305dc33f32f624695b2fa8e02c12c1e000'\npk.public_key.to_checksum_address()\n'0x1a642f0E3c3aF545E7AcBD38b07251B3990914F1'\nsignature.verify_msg(b'a message', pk.public_key)\nTrue\nsignature.recover_public_key_from_msg(b'a message') == pk.public_key\nTrue\n``` Documentation KeyAPI(backend=None) The KeyAPI object is the primary API for interacting with the eth-keys libary.  The object takes a single optional argument in its constructor which\ndesignates what backend will be used for eliptical curve cryptography\noperations.  The built-in backends are: eth_keys.backends.NativeECCBackend : A pure python implementation of the ECC operations. eth_keys.backends.CoinCurveECCBackend : Uses the coincurve library for ECC operations. By default, eth-keys will try to use the CoinCurveECCBackend ,\nfalling back to the NativeECCBackend if the coincurve library is not\navailable. Note: The coincurve library is not automatically installed with eth-keys and must be installed separately. The backend argument can be given in any of the following forms. Instance of the backend class The backend class String with the dot-separated import path for the backend class. ```python from eth_keys import KeyAPI\nfrom eth_keys.backends import NativeECCBackend These are all the same keys = KeyAPI(NativeECCBackend)\nkeys = KeyAPI(NativeECCBackend())\nkeys = KeyAPI('eth_keys.backends.NativeECCBackend') Or for the coincurve base backend keys = KeyAPI('eth_keys.backends.CoinCurveECCBackend')\n``` The backend can also be configured using the environment variable ECC_BACKEND_CLASS which should be set to the dot-separated python import path\nto the desired backend. ```python import os\nos.environ['ECC_BACKEND_CLASS'] = 'eth_keys.backends.CoinCurveECCBackend'\n``` KeyAPI.ecdsa_sign(message_hash, private_key) -> Signature This method returns a signature for the given message_hash , signed by the\nprovided private_key . message_hash : must be a byte string of length 32 private_key : must be an instance of PrivateKey KeyAPI.ecdsa_verify(message_hash, signature, public_key) -> bool Returns True or False based on whether the provided signature is a valid\nsignature for the provided message_hash and public_key . message_hash : must be a byte string of length 32 signature : must be an instance of Signature public_key : must be an instance of PublicKey KeyAPI.ecdsa_recover(message_hash, signature) -> PublicKey Returns the PublicKey instances recovered from the given signature and message_hash . message_hash : must be a byte string of length 32 signature : must be an instance of Signature KeyAPI.private_key_to_public_key(private_key) -> PublicKey Returns the PublicKey instances computed from the given private_key instance. private_key : must be an instance of PublicKey Common APIs for PublicKey , PrivateKey and Signature There is a common API for the following objects. PublicKey PrivateKey Signature Each of these objects has all of the following APIs. obj.to_bytes() : Returns the object in it's canonical bytes serialization. obj.to_hex() : Returns a text string of the hex encoded canonical representation. KeyAPI.PublicKey(public_key_bytes) The PublicKey class takes a single argument which must be a bytes string with length 64. Note that there are two other common formats for public keys: 65 bytes with a leading \\x04 byte\nand 33 bytes starting with either \\x02 or \\x03 . To use the former with the PublicKey object,\nremove the first byte. For the latter, refer to PublicKey.from_compressed_bytes . The following methods are available: PublicKey.from_compressed_bytes(compressed_bytes) -> PublicKey This classmethod returns a new PublicKey instance computed from its compressed representation. compressed_bytes must be a byte string of length 33 starting with \\x02 or \\x03 . PublicKey.from_private(private_key) -> PublicKey This classmethod returns a new PublicKey instance computed from the\ngiven private_key . private_key may either be a byte string of length 32 or an instance of the KeyAPI.PrivateKey class. PublicKey.recover_from_msg(message, signature) -> PublicKey This classmethod returns a new PublicKey instance computed from the\nprovided message and signature . message must be a byte string signature must be an instance of KeyAPI.Signature PublicKey.recover_from_msg_hash(message_hash, signature) -> PublicKey Same as PublicKey.recover_from_msg except that message_hash should be the Keccak\nhash of the message . PublicKey.verify_msg(message, signature) -> bool This method returns True or False based on whether the signature is a valid\nfor the given message. PublicKey.verify_msg_hash(message_hash, signature) -> bool Same as PublicKey.verify_msg except that message_hash should be the Keccak\nhash of the message . PublicKey.to_compressed_bytes() -> bytes Returns the compressed representation of this public key. PublicKey.to_address() -> text Returns the hex encoded ethereum address for this public key. PublicKey.to_checksum_address() -> text Returns the ERC55 checksum formatted ethereum address for this public key. PublicKey.to_canonical_address() -> bytes Returns the 20-byte representation of the ethereum address for this public key. KeyAPI.PrivateKey(private_key_bytes) The PrivateKey class takes a single argument which must be a bytes string with length 32. The following methods and properties are available PrivateKey.public_key This property holds the PublicKey instance coresponding to this private key. PrivateKey.sign_msg(message) -> Signature This method returns a signature for the given message in the form of a Signature instance message must be a byte string. PrivateKey.sign_msg_hash(message_hash) -> Signature Same as PrivateKey.sign except that message_hash should be the Keccak\nhash of the message . KeyAPI.Signature(signature_bytes=None, vrs=None) The Signature class can be instantiated in one of two ways. signature_bytes : a bytes string with length 65. vrs : a 3-tuple composed of the integers v , r , and s . Note: If using the signature_bytes to instantiate, the byte string should be encoded as r_bytes | s_bytes | v_bytes where | represents concatenation. r_bytes and s_bytes should be 32 bytes in length. v_bytes should be a single byte \\x00 or \\x01 . Signatures are expected to use 1 or 0 for their v value. The following methods and properties are available Signature.v This property returns the v value from the signature as an integer. Signature.r This property returns the r value from the signature as an integer. Signature.s This property returns the s value from the signature as an integer. Signature.vrs This property returns a 3-tuple of (v, r, s) . Signature.verify_msg(message, public_key) -> bool This method returns True or False based on whether the signature is a valid\nfor the given public key. message : must be a byte string. public_key : must be an instance of PublicKey Signature.verify_msg_hash(message_hash, public_key) -> bool Same as Signature.verify_msg except that message_hash should be the Keccak\nhash of the message . Signature.recover_public_key_from_msg(message) -> PublicKey This method returns a PublicKey instance recovered from the signature. message : must be a byte string. Signature.recover_public_key_from_msg_hash(message_hash) -> PublicKey Same as Signature.recover_public_key_from_msg except that message_hash should be the Keccak hash of the message . Exceptions eth_api.exceptions.ValidationError This error is raised during instantaition of any of the PublicKey , PrivateKey or Signature classes if their constructor parameters are\ninvalid. eth_api.exceptions.BadSignature This error is raised from any of the recover or verify methods involving\nsignatures if the signature is invalid. Developer Setup If you would like to hack on eth-keys, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-keys.git\ncd eth-keys\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-net-intelligence-api", "desc": "Ethereum Network Intelligence API \"Classic\"", "readme": "Ethereum Network Intelligence API \"Classic\" [![Build Status][travis-image]][travis-url] [![dependency status][dep-image]][dep-url] This is the backend service which runs along with ethereum and tracks the network status, fetches information through JSON-RPC and connects through WebSockets to eth-netstats (Ethereum Network Stats \"Classic\") to feed information. For full install instructions please read the wiki . Prerequisite eth, geth or pyethapp node npm Installation on an Ubuntu EC2 Instance Fetch and run the build shell. This will install everything you need: latest ethereum - CLI from develop branch (you can choose between eth or geth), node.js, npm & pm2. bash\nbash <(curl https://raw.githubusercontent.com/ethereum/eth-net-intelligence-api/master/bin/build.sh) Installation as docker container (optional) There is a Dockerfile in the root directory of the repository. Please read through the header of said file for\ninstructions on how to build/run/setup. Configuration instructions below still apply. Configuration Configure the app modifying app.json json\n\"env\":\n    {\n        \"NODE_ENV\"        : \"production\", // tell the client we're in production environment\n        \"RPC_HOST\"        : \"localhost\", // eth JSON-RPC host\n        \"RPC_PORT\"        : \"8545\", // eth JSON-RPC port\n        \"LISTENING_PORT\"  : \"30303\", // eth listening port (only used for display)\n        \"INSTANCE_NAME\"   : \"\", // whatever you wish to name your node\n        \"CONTACT_DETAILS\" : \"\", // add your contact details here if you wish (email/skype)\n        \"WS_SERVER\"       : \"wss://rpc.ethstats.net\", // path to eth-netstats WebSockets api server\n        \"WS_SECRET\"       : \"see http://forum.ethereum.org/discussion/2112/how-to-add-yourself-to-the-stats-dashboard-its-not-automatic\", // WebSockets api server secret used for login\n        \"VERBOSITY\"       : 2 // Set the verbosity (0 = silent, 1 = error, warn, 2 = error, warn, info, success, 3 = all logs)\n    } Run Run it using pm2: bash\npm2 start app.json Then run app.js: bash\nnode app.js Use ctrl+c to stop the process. Updating To update the API client use the following command: bash\n~/bin/www/bin/update.sh It will stop the current netstats client processes, automatically detect your ethereum implementation and version, update it to the latest develop build, update netstats client and reload the processes."}, {"name": "eth-netstats", "desc": "Ethereum Network Stats \"Classic\"", "readme": "Ethereum Network Stats \"Classic\" Eth-Netstats \"Classic\" is a visual interface for tracking ethereum network status. It uses WebSockets to receive stats from running nodes and output them through an Angular interface. It is the front-end implementation for eth-net-intelligence-api . Other implementations of Eth-Netstats can be found at: - Alethio EthStats - G\u00f6rli EthStats Prerequisite node npm Installation Make sure you have node.js and npm installed. Clone the repository and install the dependencies bash\ngit clone https://github.com/ethereum/eth-netstats\ncd eth-netstats\nnpm install\nsudo npm install -g grunt-cli Build the resources NetStats features two versions: the full version and the lite version. In order to build the static files you have to run grunt tasks which will generate dist or dist-lite directories containing the js and css files, fonts and images. To build the full version run bash\ngrunt To build the lite version run bash\ngrunt lite If you want to build both versions run bash\ngrunt all Run bash\nnpm start see the interface at http://localhost:3000 In order to receive stats from running nodes the web socket password needs to be provided bash\nWS_SECRET=<secret> npm start where <secret> is the value specified in the app.json file in the eth-net-intelligence-api directory. Running these tools concurrently with an etherium node will display the node on the eth-netstats interface. Receiving Stats From an Ethereum Node Follow the instructions for installing and running The Ethereum Network Intelligence API . Make sure to edit the app.json file with the appropriate information. In particular: Confirm the correct configuration for the RPC_PORT and CONFIGURATION_PORT . The defaults are \"8545\" and \"30303\" respectively. INSTANCE_NAME is the name your Ethereum node appears as in the front end. WS_SERVER is the IP address and port (3000 is default). As mentioned earlier WS_SECRET needs to match the environmental variable provided when running npm start . The Ethereum Network Intelligence API should be run concurrently with the Ethereum client of your choice. More information on running Ethereum node can be found here ."}, {"name": "eth-orm", "desc": "SQLAlchemy models and utilities for loading the Ethereum blockchain into a relational database", "readme": "eth-orm SQLAlchemy models and utilities for loading the Ethereum blockchain into a relational data model Read more in the documentation on ReadTheDocs . View the change log . Quickstart Clone the repository and install from source. sh\npip install -e . Developer Setup If you would like to hack on eth-orm, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-orm.git\ncd eth-orm\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 eth_orm/ tests/ -c \"clear; flake8 eth_orm tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on eth-orm failed'\" ../tests ../eth_orm Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-portal", "desc": "A collection of utilities related to Ethereum's Portal Network", "readme": "Portal Network Tools A collection of utilities related to Ethereum's Portal Network Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install eth-portal Developer Setup If you would like to hack on eth-portal, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-portal.git\ncd eth-portal\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 eth_portal/ tests/ -c \"clear; flake8 eth_portal tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on eth-portal failed'\" ../tests ../eth_portal Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-rlp", "desc": "STUB", "readme": "eth-rlp RLP definitions for common Ethereum objects in Python Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npython -m pip install eth-rlp Developer Setup If you would like to hack on eth-rlp, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-rlp.git\ncd eth-rlp\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-tester", "desc": "Tool suite for testing ethereum applications.", "readme": "eth-tester Tools for testing Ethereum applications Read more in the documentation below. View the change log . Quick Start sh\npython -m pip install eth-tester ```python from eth_tester import EthereumTester\nt = EthereumTester()\nt.get_accounts()\n('0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf',\n '0x2B5AD5c4795c026514f8317c7a215E218DcCD6cF',\n '0x6813Eb9362372EEF6200f3b1dbC3f819671cBA69',\n '0x1efF47bc3a10a45D4B230B5d10E37751FE6AA718',\n '0xe1AB8145F7E55DC933d51a18c793F901A3A0b276',\n '0xE57bFE9F44b819898F47BF37E5AF72a0783e1141',\n '0xd41c057fd1c78805AAC12B0A94a405c0461A6FBb',\n '0xF1F6619B38A98d6De0800F1DefC0a6399eB6d30C',\n '0xF7Edc8FA1eCc32967F827C9043FcAe6ba73afA5c',\n '0x4CCeBa2d7D2B4fdcE4304d3e09a1fea9fbEb1528') t.get_balance('0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf')\n1000000000000000000000000 t.send_transaction({\n...     'from': '0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf',\n...     'to': '0x2B5AD5c4795c026514f8317c7a215E218DcCD6cF',\n...     'gas': 30000,\n...     'value': 1,\n...     'max_fee_per_gas': 1000000000,\n...     'max_priority_fee_per_gas': 1000000000,\n...     'chain_id': 131277322940537,\n...     'access_list': (\n...         {\n...             'address': '0xde0b295669a9fd93d5f28d9ec85e40f4cb697bae',\n...             'storage_keys': (\n...                 '0x0000000000000000000000000000000000000000000000000000000000000003',\n...                 '0x0000000000000000000000000000000000000000000000000000000000000007',\n...             )\n...         },\n...         {\n...             'address': '0xbb9bc244d798123fde783fcc1c72d3bb8c189413',\n...             'storage_keys': ()\n...         },\n...     )\n... })\n'0xc20b90af87bc65c3d748cf0a1fa54f3a86ffc94348e0fd91a70f1c5ba6ef4109' t.get_transaction_by_hash('0xc20b90af87bc65c3d748cf0a1fa54f3a86ffc94348e0fd91a70f1c5ba6ef4109')\n{'type': '0x2',\n 'hash': '0xc20b90af87bc65c3d748cf0a1fa54f3a86ffc94348e0fd91a70f1c5ba6ef4109',\n 'nonce': 0,\n 'block_hash': '0x28b95514984b0abbd91d88f1a542eaeeb810c24e0234e09891b7d6b3f94f47ed',\n 'block_number': 1,\n 'transaction_index': 0,\n 'from': '0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf',\n 'to': '0x2B5AD5c4795c026514f8317c7a215E218DcCD6cF',\n 'value': 1,\n 'gas': 30000,\n 'data': '0x',\n 'r': 60071646517429056848243893841817235885102606421189844318110381014348740252962,\n 's': 55731679314783756278323646144996847004593793888590884914350251538533006990589,\n 'v': 0,\n 'chain_id': 131277322940537,\n 'max_fee_per_gas': 1000000000,\n 'max_priority_fee_per_gas': 1000000000,\n 'access_list': ({'address': '0xde0B295669a9FD93d5F28D9Ec85E40f4cb697BAe',\n   'storage_keys': ('0x0000000000000000000000000000000000000000000000000000000000000003',\n    '0x0000000000000000000000000000000000000000000000000000000000000007')},\n  {'address': '0xBB9bc244D798123fDe783fCc1C72d3Bb8C189413',\n   'storage_keys': ()}),\n 'gas_price': 1000000000} t.get_transaction_receipt('0xc20b90af87bc65c3d748cf0a1fa54f3a86ffc94348e0fd91a70f1c5ba6ef4109')\n{'transaction_hash': '0xc20b90af87bc65c3d748cf0a1fa54f3a86ffc94348e0fd91a70f1c5ba6ef4109',\n 'transaction_index': 0,\n 'block_number': 1,\n 'block_hash': '0x28b95514984b0abbd91d88f1a542eaeeb810c24e0234e09891b7d6b3f94f47ed',\n 'cumulative_gas_used': 29600,\n 'gas_used': 29600,\n 'effective_gas_price': 1000000000,\n 'contract_address': None,\n 'logs': (),\n 'type': '0x2',\n 'status': 1}\n``` Documentation Input and output data formats The ethereum tester library strictly enforces the following input formats and\ntypes. Hexadecimal values must be text (not byte) strings.  The 0x prefix is optional. Any address which contains mixed-case alpha characters will be validated as a checksummed address as specified by EIP-55 32-byte hashes must be hexadecimal encoded. Numeric values must be in their integer representation. Similarly, ethereum tester ensures that return values conform to similar rules. 32-byte hashes will be returned in their hexadecimal encoded representation. Addresses will be returned in their hexadecimal representation and EIP55 checksummed. Numeric values will be returned as integers. Block Numbers Any block_number parameter will accept the following string values. 'latest' : for the latest mined block. 'pending' : for the current un-mined block. 'earliest' : for the genesis block. 'safe' : for the last block that has passed 2/3 of attestations post-merge. 'finalized' : for the last finalized block post-merge. Note: These must be text strings (not byte stringS) eth_tester.EthereumTester API Instantiation eth_tester.EthereumTester(backend=None, validator=None, normalizer=None, auto_mine_transactions=True, fork_blocks=None) The EthereumTester object is the sole API entrypoint.  Instantiation of this\nobject accepts the following parameters. backend : The chain backend being used.  See the chain backends validator : The validator being used.  See the validators normalizer : The normalizer being used.  See the normalizers auto_mine_transactions : If truthy transactions will be automatically mined at the time they are submitted.  See enable_auto_mine_transactions and disable_auto_mine_transactions . fork_blocks : configures which block numbers the various network hard fork rules will be activated.  See fork-rules ```python from eth_tester import EthereumTester\nt = EthereumTester()\nt ``` Fork Rules Ethereum tester uses the Paris (PoS) fork rules, starting at block 0. Time Travel The chain can only time travel forward in time. EthereumTester.time_travel(timestamp) The timestamp must be an integer, strictly greater than the current timestamp\nof the latest block. Note: Time traveling will result in a new block being mined. Mining Manually mining blocks can be done with the following API.  The coinbase parameter of these methods must be a hexadecimal encoded address. EthereumTester.mine_blocks(num_blocks=1, coinbase=ZERO_ADDRESS) Mines num_blocks new blocks, returning an iterable of the newly mined block hashes. EthereumTester.mine_block(coinbase=ZERO_ADDRESS) Mines a single new block, returning the mined block's hash. Auto-mining transactions By default, all transactions are mined immediately.  This means that each transaction you send will result in a new block being mined, and that all blocks will only ever have at most a single transaction.  This behavior can be controlled with the following methods. EthereumTester.enable_auto_mine_transactions() Turns on auto-mining of transactions. EthereumTester.disable_auto_mine_transactions() Turns off auto-mining of transactions. Accounts The following API can be used to interact with account data.  The account parameter in these methods must be a hexadecimal encode address. EthereumTester.get_accounts() Returns an iterable of the accounts that the tester knows about.  All accounts\nin this list will be EIP55 checksummed. ```python t.get_accounts()\n('0x82A978B3f5962A5b0957d9ee9eEf472EE55B42F1',\n '0x7d577a597B2742b498Cb5Cf0C26cDCD726d39E6e',\n ...\n '0x90F0B1EBbbA1C1936aFF7AAf20a7878FF9e04B6c')\n``` EthereumTester.add_account(private_key, password=None) Adds a new account for the given private key.  Returns the hex encoded address\nof the added account. ```python t.add_account('0x58d23b55bc9cdce1f18c2500f40ff4ab7245df9a89505e9b1fa4851f623d241d')\n'0xdc544d1aa88ff8bbd2f2aec754b1f1e99e1812fd'\n``` By default, added accounts are unlocked and do not have a password.  If you\nwould like to add an account which has a password, you can supply the password\nas the second parameter. ```python t.add_account('0x58d23b55bc9cdce1f18c2500f40ff4ab7245df9a89505e9b1fa4851f623d241d', 'my-secret')\n'0xdc544d1aa88ff8bbd2f2aec754b1f1e99e1812fd'\n``` EthereumTester.unlock_account(account, password, unlock_seconds=None) Unlocks the given account if the provided password matches. Raises a ValidationError if: The account is not known. The password does not match. The account was created without a password. ```python t.unlock_account('0xdc544d1aa88ff8bbd2f2aec754b1f1e99e1812fd', 'my-secret')\n``` By default, accounts will be unlocked indefinitely.  You can however unlock an\naccount for a specified amount of time by providing the desired duration in\nseconds. ```python unlock for 1 hour. t.unlock_account('0xdc544d1aa88ff8bbd2f2aec754b1f1e99e1812fd', 'my-secret', 60 * 60)\n``` EthereumTester.lock_account(account) Locks the provided account. Raises a ValidationError if: The account is not known The account does not have a password. EthereumTester.get_balance(account) -> integer Returns the balance, in wei, for the provided account. ```python t.get_balance('0x82A978B3f5962A5b0957d9ee9eEf472EE55B42F1')\n1000004999999999999999999\n``` EthereumTester.get_nonce(account) -> integer Returns the nonce for the provided account. ```python t.get_nonce('0x82A978B3f5962A5b0957d9ee9eEf472EE55B42F1')\n1\n``` EthereumTester.get_code(account) -> hex string Returns the code for the given account. ```python t.get_code('0x82A978B3f5962A5b0957d9ee9eEf472EE55B42F1')\n\"0x\"\n``` Blocks, Transactions, and Receipts EthereumTester.get_transaction_by_hash(transaction_hash) -> transaction-object Returns the transaction for the given hash, raising a TransactionNotFound exception if the\ntransaction cannot be found. ```python t.get_transaction_by_hash('0x21ae665f707e12a5f1bb13ef8c706b65cc5accfd03e7067ce683d831f51122e6')\n{'type': '0x2',\n 'hash': '0x21ae665f707e12a5f1bb13ef8c706b65cc5accfd03e7067ce683d831f51122e6',\n 'nonce': 0,\n 'block_hash': '0x810731efeb7498fc0ac3bc7c72a71571b672c9fdbfbfd8b435f483e368e8ef7e',\n 'block_number': 1,\n 'transaction_index': 0,\n 'from': '0x2B5AD5c4795c026514f8317c7a215E218DcCD6cF',\n 'to': '0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf',\n 'value': 1337,\n 'gas': 21000,\n 'data': '0x',\n 'r': 1713666669454033023988006960017431058214051587080823768269189498559514600280,\n 's': 32003859822305799628524852194521134173285969678963273753063458725692016415033,\n 'v': 0,\n 'chain_id': 131277322940537,\n 'max_fee_per_gas': 2000000000,\n 'max_priority_fee_per_gas': 500000000,\n 'access_list': (),\n 'gas_price': 1375000000}\n``` Note: For unmined transaction, transaction_index , block_number and block_hash will all be None . EthereumTester.get_block_by_number(block_number, full_transactions=False) -> block-object Returns the block for the given block_number .  See block\nnumbers for named block numbers you can use.  If full_transactions is truthy, then the transactions array will be populated\nwith full transaction objects as opposed to their hashes. Raises BlockNotFound if a block for the given number\ncannot be found. ```python t.get_block_by_number(1)\n{'number': 1,\n 'hash': '0xd481955268d1f3db58ee61685a899a35e33e8fd35b9cc0812f85b9f06757140e',\n 'parent_hash': '0x5be984ab842071903ee443a5dee92603bef42de35b4e10928e753f7e88a7163a',\n 'nonce': '0x0000000000000000',\n 'sha3_uncles': '0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347',\n 'logs_bloom': 0,\n 'transactions_root': '0xef1e11d99f7db22fd93c6a10d44753d4a93e9f6ecb2f1e5030a0a91f1d3b07ac',\n 'receipts_root': '0x611e48488cf80b4c31f01ad45b6ebea533a68255a6d0240d434d9366a3582010',\n 'state_root': '0x9ce568dcaa6f130d733b333304f2c26a19334ed328a7eb9bb31707306381ba65',\n 'coinbase': '0x0000000000000000000000000000000000000000',\n 'difficulty': 0,\n 'total_difficulty': 0,\n 'mix_hash': '0x0000000000000000000000000000000000000000000000000000000000000000',\n 'size': 751,\n 'extra_data': '0x0000000000000000000000000000000000000000000000000000000000000000',\n 'gas_limit': 3141592,\n 'gas_used': 29600,\n 'timestamp': 1633669276,\n 'transactions': ('0xc20b90af87bc65c3d748cf0a1fa54f3a86ffc94348e0fd91a70f1c5ba6ef4109',),\n 'uncles': (),\n 'base_fee_per_gas': 875000000}\n``` EthereumTester.get_block_by_hash(block_hash, full_transactions=True) -> block-object Returns the block for the given block_hash .  The full_transactions parameter behaves the same as in get_block_by_number . Raises BlockNotFound if a block for the given hash\ncannot be found. ```python t.get_block_by_hash('0x0f50c8ea0f67ce0b7bff51ae866159edc443bde87de2ab26010a15b777244ddd')\n{'number': 1,\n 'hash': '0xd481955268d1f3db58ee61685a899a35e33e8fd35b9cc0812f85b9f06757140e',\n 'parent_hash': '0x5be984ab842071903ee443a5dee92603bef42de35b4e10928e753f7e88a7163a',\n 'nonce': '0x0000000000000000',\n 'sha3_uncles': '0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347',\n 'logs_bloom': 0,\n 'transactions_root': '0xef1e11d99f7db22fd93c6a10d44753d4a93e9f6ecb2f1e5030a0a91f1d3b07ac',\n 'receipts_root': '0x611e48488cf80b4c31f01ad45b6ebea533a68255a6d0240d434d9366a3582010',\n 'state_root': '0x9ce568dcaa6f130d733b333304f2c26a19334ed328a7eb9bb31707306381ba65',\n 'coinbase': '0x0000000000000000000000000000000000000000',\n 'difficulty': 0,\n 'total_difficulty': 0,\n 'mix_hash': '0x0000000000000000000000000000000000000000000000000000000000000000',\n 'size': 751,\n 'extra_data': '0x0000000000000000000000000000000000000000000000000000000000000000',\n 'gas_limit': 3141592,\n 'gas_used': 29600,\n 'timestamp': 1633669276,\n 'transactions': ('0xc20b90af87bc65c3d748cf0a1fa54f3a86ffc94348e0fd91a70f1c5ba6ef4109',),\n 'uncles': (),\n 'base_fee_per_gas': 875000000}\n``` EthereumTester.get_transaction_receipt(transaction_hash) Returns the receipt for the given transaction_hash , raising TransactionNotFound if no transaction can be\nfound for the given hash. ```python t.get_transaction_receipt('0x9a7cc8b7accf54ecb1901bf4d0178f28ca457bb9f9c245692c0ca8fabef08d3b')\n {'block_hash': '0x878f779d8bb25b25fb78fc16b8d64d70a5961310ef1689571aec632e9424290c',\n 'block_number': 2,\n 'contract_address': None,\n 'cumulative_gas_used': 23154,\n 'gas_used': 23154,\n 'logs': ({'address': '0xd6F084Ee15E38c4f7e091f8DD0FE6Fe4a0E203Ef',\n   'block_hash': '0x878f779d8bb25b25fb78fc16b8d64d70a5961310ef1689571aec632e9424290c',\n   'block_number': 2,\n   'data': '0x',\n   'log_index': 0,\n   'topics': (\n    '0xf70fe689e290d8ce2b2a388ac28db36fbb0e16a6d89c6804c461f65a1b40bb15',\n    '0x0000000000000000000000000000000000000000000000000000000000003039'),\n   'transaction_hash': '0x9a7cc8b7accf54ecb1901bf4d0178f28ca457bb9f9c245692c0ca8fabef08d3b',\n   'transaction_index': 0,\n   'type': 'mined'},),\n 'transaction_hash': '0x9a7cc8b7accf54ecb1901bf4d0178f28ca457bb9f9c245692c0ca8fabef08d3b',\n 'transaction_index': 0}\n``` Receipts for unmined transactions will have all of block_hash , block_number and transaction_index set to None . Receipts for transactions which create a contract will have the created contract address in the contract_address field. Transaction Sending A transaction is a formatted as a dictionary with the following keys and\nvalues. from : The address of the account sending the transaction (hexadecimal string). to : The address of the account the transaction is being sent to.  Empty string should be used to trigger contract creation (hexadecimal string). gas : Sets the gas limit for transaction execution (integer). value : The amount of ether in wei that should be sent with the transaction (integer). data : The data for the transaction (hexadecimal string). chain_id : The integer id for the chain the transaction is meant to interact with. In addition to the above, the following parameters are added based on the type of transaction being sent: Legacy transactions gas_price : Sets the price per unit of gas in wei that will be paid for transaction execution (integer). Access list transactions (EIP-2930) gas_price : Sets the price per unit of gas in wei that will be paid for transaction execution (integer). access_list (optional): Specifies accounts and storage slots expected to be accessed, based on the transaction, in order to\n  gain a discount on the gas for those executions (see quickstart example for usage). Dynamic fee transactions (EIP-1559) max_fee_per_gas : Sets the maximum fee per unit of gas in wei that will be paid for transaction execution (integer). max_priority_fee_per_gas : Sets the fee per unit of gas in wei that is sent to the coinbase address as an incentive for including the transaction (integer). access_list (optional): Specifies accounts and storage slots expected to be accessed, based on the transaction, in order to\n  gain a discount on the gas for those executions (see quickstart example for usage). Methods EthereumTester.send_transaction(transaction) -> transaction_hash Sends the provided transaction object, returning the transaction_hash for\nthe sent transaction. EthereumTester.call(transaction, block_number='latest') Executes the provided transaction object at the evm state from the block\ndenoted by the block_number parameter, returning the resulting bytes return\nvalue from the evm. EthereumTester.estimate_gas(transaction) Executes the provided transaction object, measuring and returning the gas\nconsumption. EthereumTester.get_fee_history(block_count=1, newest_block='latest', reward_percentiles=[]) Return the historical gas information for the number of blocks specified as the block_count starting from newest_block .\nNote that specifying reward_percentiles has no effect on the response and so reward will always return an empty list. Logs and Filters EthereumTester.create_block_filter() -> integer Creates a new filter for newly mined blocks.  Returns the filter_id which can\nbe used to retrieve the block hashes for the mined blocks. ```python filter_id = t.create_block_filter()\nfilter_id = t.create_block_filter()\nt.mine_blocks(3)\nt.get_only_filter_changes(filter_id)\n('0x07004287f82c1a7ab15d7b8baa03ac14d7e9167ab74e47e1dc4bd2213dd18431',\n '0x5e3222c506585e1202da08c7231afdc5e472c777c245b822f44f141d335c744a',\n '0x4051c3ba3dcca95da5db1be38e44f5b47fd1a855ba522123e3254fe3f8e271ea')\nt.mine_blocks(2)\nt.get_only_filter_changes(filter_id)\n('0x6649c3a7cb3c7ede3a4fd10ae9dd63775eccdafe39ace5f5a9ae81d360089fba',\n '0x04890a08bca0ed2f1496eb29c5dc7aa66014c85377c6d9d9c2c315f85204b39c')\nt.get_all_filter_logs(filter_id)\n('0x07004287f82c1a7ab15d7b8baa03ac14d7e9167ab74e47e1dc4bd2213dd18431',\n '0x5e3222c506585e1202da08c7231afdc5e472c777c245b822f44f141d335c744a',\n '0x4051c3ba3dcca95da5db1be38e44f5b47fd1a855ba522123e3254fe3f8e271ea',\n '0x6649c3a7cb3c7ede3a4fd10ae9dd63775eccdafe39ace5f5a9ae81d360089fba',\n '0x04890a08bca0ed2f1496eb29c5dc7aa66014c85377c6d9d9c2c315f85204b39c')\n``` EthereumTester.create_pending_transaction_filter() -> integer Creates a new filter for pending transactions.  Returns the filter_id which\ncan be used to retrieve the transaction hashes for the pending transactions. ```python filter_id = t.create_pending_transaction_filter()\nt.send_transaction({...})\n'0x07f20bf9586e373ac914a40e99119c4932bee343d89ba852ccfc9af1fd541566'\nt.send_transaction({...})\n'0xff85f7751d132b66c03e548e736f870797b0f24f3ed41dfe5fc628eb2cbc3505'\nt.get_only_filter_changes(filter_id)\n('0x07f20bf9586e373ac914a40e99119c4932bee343d89ba852ccfc9af1fd541566',\n '0xff85f7751d132b66c03e548e736f870797b0f24f3ed41dfe5fc628eb2cbc3505')\nt.send_transaction({...})\n'0xb07801f7e8b1cfa52b64271fa2673c4b8d64cc21cdbc5fde51d5858c94c2d26a'\nt.get_only_filter_changes(filter_id)\n('0xb07801f7e8b1cfa52b64271fa2673c4b8d64cc21cdbc5fde51d5858c94c2d26a',)\nt.get_all_filter_logs(filter_id)\n('0x07f20bf9586e373ac914a40e99119c4932bee343d89ba852ccfc9af1fd541566',\n '0xff85f7751d132b66c03e548e736f870797b0f24f3ed41dfe5fc628eb2cbc3505',\n '0xb07801f7e8b1cfa52b64271fa2673c4b8d64cc21cdbc5fde51d5858c94c2d26a')\n``` EthereumTester.create_log_filter(from_block=None, to_block=None, address=None, topics=None) -> integer Creates a new filter for logs produced by transactions.  The parameters for\nthis function can be used to filter the log entries. ```python filter_id = t.create_log_filter()\nt.send_transaction({...})  # something that produces a log entry\n'0x728bf75fc7d23845f328d2223df7fe9cafc6e7d23792457b625d5b60d2b22b7c'\nt.send_transaction({...})  # something that produces a log entry\n'0x63f5b381ffd09940ce22c45a3f4e163bd743851cb6b4f43771fbf0b3c14b2f8a'\nt.get_only_filter_changes(filter_id)\n({'address': '0xd6F084Ee15E38c4f7e091f8DD0FE6Fe4a0E203Ef',\n  'block_hash': '0x68c0f318388003b652eae334efbed8bd345c469bd0ca77469183fc9693c23e13',\n  'block_number': 11,\n  'data': '0x',\n  'log_index': 0,\n  'topics': ('0xf70fe689e290d8ce2b2a388ac28db36fbb0e16a6d89c6804c461f65a1b40bb15',\n   '0x0000000000000000000000000000000000000000000000000000000000003039'),\n  'transaction_hash': '0x728bf75fc7d23845f328d2223df7fe9cafc6e7d23792457b625d5b60d2b22b7c',\n  'transaction_index': 0,\n  'type': 'mined'},\n {'address': '0xd6F084Ee15E38c4f7e091f8DD0FE6Fe4a0E203Ef',\n  'block_hash': '0x07d7e46be6f9ba53ecd4323fb99ec656e652c4b14f4b8e8a244ee7f997464725',\n  'block_number': 12,\n  'data': '0x',\n  'log_index': 0,\n  'topics': ('0xf70fe689e290d8ce2b2a388ac28db36fbb0e16a6d89c6804c461f65a1b40bb15',\n   '0x0000000000000000000000000000000000000000000000000000000000010932'),\n  'transaction_hash': '0x63f5b381ffd09940ce22c45a3f4e163bd743851cb6b4f43771fbf0b3c14b2f8a',\n  'transaction_index': 0,\n  'type': 'mined'})\n``` EthereumTester.delete_filter(filter_id) Removes the filter for the provided filter_id .  If no filter is found for the\ngiven filter_id , raises FilterNotFound . EthereumTester.get_only_filter_changes(filter_id) -> transaction_hash or block_hash or log_entry Returns all new values for the provided filter_id that have not previously\nbeen returned through this API.  Raises FilterNotFound if no filter is found for the given filter_id . EthereumTester.get_all_filter_logs(filter_id) -> transaction_hash or block_hash or log_entry Returns all values for the provided filter_id . Raises FilterNotFound if no filter is found for the given filter_id . Snapshots and Resetting EthereumTester.take_snapshot() -> snapshot_id Takes a snapshot of the current chain state and returns the snapshot id. EthereumTester.revert_to_snapshot(snapshot_id) Reverts the chain to the chain state associated with the given snapshot_id .\nRaises SnapshotNotFound if no snapshot is known\nfor the given id. Errors and Exceptions eth_tester.exceptions.TransactionNotFound Raised in cases where a transaction cannot be found for the provided transaction hash. eth_tester.exceptions.BlockNotFound Raised in cases where a block cannot be found for either a provided number or\nhash. eth_tester.exceptions.FilterNotFound Raised in cases where a filter cannot be found for the provided filter id. eth_tester.exceptions.SnapshotNotFound Raised in cases where a snapshot cannot be found for the provided snapshot id. Backends Ethereum tester is written using a pluggable backend system. Backend Dependencies Ethereum tester does not install any of the dependencies needed to use the\nvarious backends by default.  You can however install ethereum tester with the\nnecessary dependencies using the following method. bash\n$ python -m pip install eth-tester[<backend-name>] You should replace <backend-name> with the name of the desired testing\nbackend.  Available backends are: py-evm : PyEVM (alpha) (experimental) Selecting a Backend You can select which backend in a few different ways. The most direct way is to manually pass in the backend instance you wish to\nuse. ```python from eth_tester import EthereumTester, MockBackend\nt = EthereumTester(backend=MockBackend())\n``` Ethereum tester also supports configuration using the environment variable ETHEREUM_TESTER_CHAIN_BACKEND .  This should be set to the import path for the\nbackend class you wish to use. Available Backends Ethereum tester can be used with the following backends. MockBackend PyEVM (experimental) MockBackend This backend has limited functionality.  It cannot perform any VM computations.\nIt mocks out all of the objects and interactions. ```python from eth_tester import EthereumTester, MockBackend\nt = EthereumTester(MockBackend())\n``` PyEVM (experimental) WARNING Py-EVM is experimental and should not be relied on for mission critical testing at this stage. Uses the experimental Py-EVM library. ```python from eth_tester import EthereumTester, PyEVMBackend\nt = EthereumTester(PyEVMBackend())\n``` PyEVM Genesis Parameters and State If you need to specify custom genesis parameters and state, you can build your own parameters dict to use instead of the default\nwhen initializing a backend.  Only default values can be overridden or a ValueError will be raised. ``` Default Genesis Parameters default_genesis_params = {\n    \"coinbase\": GENESIS_COINBASE,\n    \"difficulty\": GENESIS_DIFFICULTY,\n    \"extra_data\": GENESIS_EXTRA_DATA,\n    \"gas_limit\": GENESIS_GAS_LIMIT,\n    \"mix_hash\": GENESIS_MIX_HASH,\n    \"nonce\": GENESIS_NONCE,\n    \"receipt_root\": BLANK_ROOT_HASH,\n    \"timestamp\": int(time.time()),\n    \"transaction_root\": BLANK_ROOT_HASH,\n}\n``` To generate a genesis parameters dict with an overridden parameters, pass a genesis_overrides dict \\\nto PyEVM.generate_genesis_params . ```python from eth_tester import PyEVMBackend, EthereumTester genesis_overrides = {'gas_limit': 4500000}\ncustom_genesis_params = PyEVMBackend.generate_genesis_params(overrides=genesis_overrides) Generates the following dict : custom_genesis_params = { \"coinbase\": GENESIS_COINBASE, \"difficulty\": GENESIS_DIFFICULTY, \"extra_data\": GENESIS_EXTRA_DATA, \"gas_limit\": 4500000    # <<< Overridden Value <<< \"mix_hash\": GENESIS_MIX_HASH, \"nonce\": GENESIS_NONCE, \"receipt_root\": BLANK_ROOT_HASH, \"timestamp\": int(time.time()), \"transaction_root\": BLANK_ROOT_HASH, } ``` Then pass the generated custom_genesis_params dict to the backend's __init__ ```python from eth_tester import PyEVMBackend, EthereumTester\npyevm_backend = PyEVMBackend(genesis_parameters=custom_genesis_params)\nt = EthereumTester(backend=pyevm_backend)\n``` Similarly to genesis_parameters , override the genesis state by passing in an overrides dict to PyEVMBackend.generate_genesis_state . Optionally, provide num_accounts to set the number of accounts. For more control on which accounts the backend generates, use the from_mnemonic() classmethod. Give it\na mnemonic (and optionally the number of accounts) and it will use that information to generate the accounts.\nOptionally, provide a genesis_state_overrides dict to adjust the genesis_state . ```python from eth_tester import PyEVMBackend, EthereumTester\nfrom eth_utils import to_wei\nfrom hexbytes import HexBytes pyevm_backend = PyEVMBackend.from_mnemonic(\n   'test test test test test test test test test test test junk',\n   genesis_state_overrides={'balance': to_wei(1000000, 'ether')}\n)\nt = EthereumTester(backend=pyevm_backend)\nprint(t.get_accounts()[0])  # Outputs 0x1e59ce931B4CFea3fe4B875411e280e173cB7A9C\nprint(t.get_balance('0x1e59ce931B4CFea3fe4B875411e280e173cB7A9C'))  # Outputs 1000000000000000000000000\n``` NOTE: The same state is applied to all generated test accounts. ``` Default Account Genesis State default_account_state = {\n    'balance': to_wei(1000000, 'ether'),\n    'storage': {},\n    'code': b'',\n    'nonce': 0,\n}\n``` For Example, to create 3 test accounts, each with a balance of 100 ETH each: ```python from eth_tester import EthereumTester, PyEVMBackend\n from eth_utils import to_wei state_overrides = {'balance': to_wei(100, 'ether')}\ncustom_genesis_state = PyEVMBackend.generate_genesis_state(overrides=state_overrides, num_accounts=3) Then pass the generated custom_genesis_state dict to the backend's __init__ pyevm_backend = PyEVMBackend(genesis_state=custom_genesis_state)\nt = EthereumTester(backend=pyevm_backend)\n``` Implementing Custom Backends The base class eth_tester.backends.base.BaseChainBackend is the recommended\nbase class to begin with if you wish to write your own backend. Details on implementation are beyond the scope of this document. Data Formats Ethereum tester uses two formats for data. The normal format is the data format the is expected as input arguments to all EthereumTester methods as well as the return types from all method calls. The canonical format is the data format that is used internally by the backend class. Ethereum tester enforces strict validation rules on these formats. Canonical Formats The canonical format is intended for low level handling by backends. 32 byte hashes: bytes of length 32 Arbitrary length strings: bytes Addresses: bytes of length 20 Integers: int Array Types: tuple Normal Formats The normal format is intended for use by end users. 32 byte hashes: 0x prefixed hexadecimal encoded text strings (not byte strings) Arbitrary length strings: 0x prefixed hexadecimal encoded text strings (not byte strings) Addresses: 0x prefixed and EIP55 checksummed hexadecimal encoded text strings (not byte strings) Integers: int Array Types: tuple Normalization and Validation Beware! Here there be dragons...  This section of the documentation is only\nrelevant if you intend to build tooling on top of this library. The ethereum tester provides strong guarantees that backends can be swapped out\nseamlessly without effecting the data formats of both the input arguments and\nreturn values.  This is accomplished using a two-step process of strict normalization and validation . All inputs to the methods of the EthereumTester are first validated then\nnormalized to a canonical format.  Return values are put through this process\nas well, first validating the data returned by the backend, and then\nnormalizing it from the canonical format to the normal form before being\nreturned. Normalization The EthereumTester delegates normalization to whatever normalizer was\npassed in during instantiation.  If no value was provided, the default\nnormalizer will be used from eth_tester.normalization.default.DefaultNormalizer . The specifics of this object are beyond the scope of this document. Validation The EthereumTester delegates validation to whatever validator was\npassed in during instantiation.  If no value was provided, the default\nvalidator will be used from eth_tester.validation.default.DefaultValidator . The specifics of this object are beyond the scope of this document. Use with Web3.py See the web3.py documentation for\ninformation on the EthereumTester provider which integrates with this\nlibrary. Developer Setup If you would like to hack on eth-tester, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-tester.git\ncd eth-tester\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-typeshed", "desc": "Typing stubs for python ethereum codebase static type checking.", "readme": null}, {"name": "eth-typing", "desc": "Python types for type hinting commonly used ethereum types", "readme": "eth-typing Common type annotations for ethereum python packages. Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npython -m pip install eth-typing Developer Setup If you would like to hack on eth-typing, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-typing.git\ncd eth-typing\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Network ChainIds A list of ChainId constants reside in the eth-typing/networks.py file. This list should be kept\nin sync with the network list available on chainid.network . To keep the list up to date, run the following command: sh\npython update_network_chain_ids.py This will remove the original networks file and output a new file with the new networks added. Check that the output file is correct and that constants are defined as expected. If\nthe shortName contains special characters it may not work as a constant variable name.\nThe script should be updated to transform names into valid constants as new cases occur. Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-utils", "desc": "Utility functions for working with ethereum related codebases.", "readme": "Ethereum Utilities Common utility functions for python code that interacts with Ethereum Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npython -m pip install eth-utils Developer Setup If you would like to hack on eth-utils, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/eth-utils.git\ncd eth-utils\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Update Networks The list of networks resides in the JSON file under eth_utils/__json/eth_networks.json.\nThis file is used to initialize Networks, which can be used to obtain network\ninformation with a chain ID. Run the script to update the JSON file with the response from the remote list. sh\npython update_networks.py If there are new networks they will appear in the JSON file. After checking the updates,\nopen a PR to make them available in a new release. Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "eth-wiki", "desc": "Ethereum Wiki", "readme": "Eth.wiki :no_entry_sign: no longer actively maintained :no_entry_sign: Eth.wiki is a now largely outdated collection of resources explaining the state-of-the-art in Ethereum circa 2020. The material in this repository has been updated and migrated to ethereum.org. This repository is due to be archived shortly. Please visit ethereum.org instead for current Ethereum information! Looking to contribute to Ethereum documentation? Check out the ethereum.org repo: https://github.com/ethereum/ethereum-org-website"}, {"name": "eth-wiki-test", "desc": "wiki.js Wiki Test by Hudson", "readme": "eth-wiki wiki.js Wiki Test by Hudson"}, {"name": "eth2-client-tests", "desc": null, "readme": "[DEPRECATED] Ethereum 2.0 tests Note: this repository has been deprecated in favor of https://github.com/ethereum/eth2.0-spec-tests. This repository contains a series of sanity tests to be built against Ethereum 2.0 clients. tester The tester program connects to an existing Genesis server and deploys, maintains and tests a testnet. See https://www.github.com/Whiteblock/genesis to set up a testnet server. Check genesis is available locally tester genesis up Create a testnet tester genesis tesnet --blockchain [prysm|artemis|lighthouse] Optionally, you can indicate a file to store the testnet ID. tester genesis tesnet --blockchain [prysm|artemis|lighthouse] -f out Check all nodes in the testnet can serve traffic on a port tester network --testnet <testnetId> Chains supported | Name     | Image                           |\n|----------|---------------------------------|\n|Prysm     |dockerfiles/prysm.Dockerfile     |\n|Artemis   |dockerfiles/artemis.Dockerfile   |\n|Lighthouse|dockerfiles/lighthouse.Dockerfile|\n|Lodestar  |dockerfiles/lodestar.Dockerfile  | Contributing See the TODO file for possible contributions."}, {"name": "eth2.0-onboarding", "desc": "Additional eth2 documents and explanations to aid onboarding", "readme": null}, {"name": "eth2.0-pm", "desc": "ETH2.0 project management", "readme": "[DEPRECATED] ETH2.0 Project Management WARNING: This repo is now deprecated in favor of unification with the https://github.com/ethereum/pm/ repo. Please see this other repo for calls, notes, and other project management items Interop Standards This repo hosts a collection of standards to aid in client interoperability testing. Previous ETH2.0 Implementers Calls \u2116  | Date                             | Notes          | Recording            |\n--- | -------------------------------- | -------------- | -------------------- |\n75 | Thu, Nov 4th, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video |\n68|Thu, Jul 15, 2021 1400UTC| agenda \\| notes \\| reddit | video 67 | Thu, July 1st, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video |\n66 | Thu, Jun 17rd, 2020 14:00 UTC  | agenda \\| notes \\| no reddit | video |\n65| Thu, Jun 3, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 64|||||\n63|||||\n62|||||\n61|||||\n60|||||\n59|||||\n58|||||\n57|||||\n56|||||\n55| Thu, Jan 14, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 54|||||\n53| Thu, Dec 2, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 52|||||\n51|||||\n50| Thu, Oct 15, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 49|||||\n48|||||\n47|||||\n46|||||\n45|||||\n44|||||\n43|||||\n42|||||\n41| Thu, Jun 11, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 40| Thu, May 28, 2020 14:00 UTC  | agenda \\| notes \\| reddit |\n39| Thu, May 14, 2020 14:00 UTC  | agenda \\| notes \\| reddit |\n38| Thu, Apr 23, 2020 14:00 UTC  | agenda \\| notes \\| reddit |\n37| Thu, Apr 09, 2020 14:00 UTC  | agenda \\| notes \\| reddit |\n36| Thu, Mar 26, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 35| Thu, Mar 3, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 34| Thu, Feb 27, 2020 14:00 UTC   | agenda \\| notes \\| reddit | video 33| Thu Feb 06, 2020 14:00 UTC    | agenda \\| notes \\| reddit | video 32| Thu, Jan 23, 2020 14:00 UTC      | agenda \\| notes \\| reddit | video 31| Thu, Jan 09, 2020 14:00 UTC      | agenda \\| notes \\| reddit | video 30| Thu, Dec 19, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 29| Thu, Dec 5, 2019 14:00 UTC     | agenda \\| notes \\| no reddit | video 28| Thu, Nov 21, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 27| Thu, Nov 7, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 26| Thu, Oct 24, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 25| Thu, Sep 9, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 24| Thu, Aug 29, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 23| Thu, Aug 15, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 22| Thu, Jul 25, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 21| Thu, Jul 11, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 20| Thu, Jun 13, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 19| Thu, Jun 13, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 18| Thu, May 23, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 17| Thu, May 02, 2019 14:00 UTC      | agenda \\| no notes \\| no reddit | video 16| Thu, Apr 18, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 15| Thu, Mar 28, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 14| Thu, Mar 14, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 13| Thu, Feb 28, 2019 14:00 UTC      | agenda \\| notes \\| no reddit  | video 12| Thu, Feb 14, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 11| Thu, Jan 31, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 10| Thu, Jan 17, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 9| Thu, Jan 03, 2019 14:00 UTC       | agenda \\| notes \\| reddit | video 8| Thu, Dec 13, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 7| Thu, Nov 29, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 6| Thu, Nov 15, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 5| Thu, Oct 11, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 4| Thu, Sept 27, 2018 14:00 UTC     | agenda \\| notes \\| reddit | video 3| Thu, Sept 13, 2018 14:00 UTC     | agenda \\| notes \\| reddit | video 2| Thu, Aug 30, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 1| Thu, Aug 16, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 0| Thu, Aug 02, 2018 14:00 UTC       | agenda \\| notes \\| reddit | video"}, {"name": "eth2.0-test-generators", "desc": null, "readme": "Eth2.0 Test Generators This repository contains generators that build tests for Eth 2.0 clients. The test files themselves can be found in ethereum/eth2.0-tests . Whenever a release is made, the new tests are automatically built and eth2TestGenBot commits the changes to the test repository. How to add a new test generator In order to add a new test generator that builds New Tests , put it in a new directory new_tests at the root of this repository. Next, add a new target $(TEST_DIR)/new_tests to the makefile , specifying the commands that build the test files. Note that new_tests is also the name of the directory in which the tests will appear in the tests repository later. Also, add the new target as a dependency to the all target. Finally, add any linting or testing commands to the circleci config file if desired to increase code quality. All of this should be done in a pull request to the master branch. To deploy new tests to the testing repository, create a release tag with a new version number on Github. Increment the major version to indicate a change in the general testing format or the minor version if a new test generator has been added. Otherwise, just increment the patch version. How to remove a test generator If a test generator is not needed anymore, undo the steps described above and make a new release. In addition, remove the generated tests in the eth2.0-tests repository by opening a PR there."}, {"name": "eth2.0-tests", "desc": "[DEPRECATED] Common tests for all Eth2.0 implementations", "readme": "[DEPRECATED] Eth 2.0 test vectors generators Starting at v0.6.0 of the eth2.0 spec, this repo has been deprecated in favor of https://github.com/ethereum/eth2.0-spec-tests. All subsequent test vectors will be released to the new repo. This repository contains common test vectors for Eth2.0 implementations. The tests are YAML files following the general testing format . Each set of tests is located in its own directory at the root of the repository. The generators that are responsible for most of the tests can be found in ethereum/eth2.0-test-generators . To add or update handwritten tests, please open a pull request here. For automatically generated tests, please follow the steps described here . License Similar to Eth 2.0 specifications, all code and generated test vectors\nare public domain under CC0"}, {"name": "ethash", "desc": null, "readme": "Ethash For details on this project, please see the Ethereum wiki:\nhttps://github.com/ethereum/wiki/wiki/Ethash Coding Style for C++ code: Follow the same exact style as in cpp-ethereum Coding Style for C code: The main thing above all is code consistency. Tabs for indentation. A tab is 4 spaces Try to stick to the K&R ,\n  especially for the C code. Keep the line lengths reasonable. No hard limit on 80 characters but don't go further\n  than 110. Some people work with multiple buffers next to each other.\n  Make them like you :)"}, {"name": "ethbot", "desc": null, "readme": "Ethereum Documentation Generator Available parsers jsdoc for JSDoc comments doxygen for C/C++ projects marked for GitHub flavoured Markdown Installation Clone the repository Install node packages: npm install Configure environment: mongoUrl (ex. mongodb://mongouser:mongopass@10.20.30.40:27017/ethereum-docs ) port (ex. 3001 ) projects (ex. $(cat ~/projects.json) ) wikis (ex. $(cat ~/wikis.json) ) Install required CLI tools doxygen xsltproc Run application: node main.js Example ~/projects.json {\n  \"libweb3jsonrpc\": {\n    \"secret\": \"1wRsEGIQeMEIKTr8\",\n    \"parser\": \"jsdoc\",\n    \"summary\": {\n      \"name\": \"Web3 JSON RPC\"\n    }\n  },\n  \"libweb3core\": {\n    \"secret\": \"JFwSGnXeSvDmhV9I\",\n    \"parser\": \"doxygen\",\n    \"summary\": {\n      \"name\": \"Web3 Core\"\n    }\n  }\n} Example ~/wikis.json {\n  \"ethereum-wiki\": {\n    \"secret\": \"uDwnQQStuj6IOsnj\",\n    \"parser\": \"marked\",\n    \"summary\": {\n      \"name\": \"Ethereum Wiki\"\n    }\n  }\n}"}, {"name": "ethdev-site", "desc": null, "readme": null}, {"name": "ethendance", "desc": null, "readme": null}, {"name": "ethereum-binaries", "desc": "Fast, easy and secure Ethereum binary management", "readme": "Ethereum Binaries \ud83d\udd25 This project has been deprecated and will no longer be maintained. \ud83d\udd25 Fast, easy and secure Ethereum binary management. [X] \ud83c\udf81 Package Extraction [x] \ud83d\udd10 Binary Verification [x] \u2668\ufe0f Runtime Detection \ud83d\udc0d [X] \ud83d\udc33 Docker Support [X] \u23f0 Lifecycle Events [ IPC_READY | SYNCED | STOPPED ... ] [x] \u2601\ufe0f Auto Update [x] \u26a1 Caching [x] \ud83d\udc19 Version Management [x] \ud83c\udf08 Multi Client Support Docs Documentation is available at github.io/ethereum-binaries Supported Clients & Binaries Geth Prysm Puppeth ZoKrates Supported clients can be referenced by their name and used directly. For all other binaries see Extension Intro Binaries are an integral part of the Ethereum ecosystem. There are many amazing tools (Clef, ZoKrates, Puppeth, ...) that go even beyond the different client implementations (Geth, Prysm, Besu, Nethermind, ...).\nHowever, managing them can be a very complex task. There are no standards for how binaries are distributed and you might find Docker images, binaries hosted on (GitHub, Azure, Bintray, AWS), or even have to build them from source yourself by installing the respective toolchains first and learning about language specific details.\nMoreover, important steps such as binary verification with e.g. GPG are often skipped because it is too complex or inconvenient.\nInteracting with these binaries, e.g. from a script file when they are running inside a container creates a whole new set of challenges.\nThe goal of this library is to create a unified interface to download, configure and interact with Ethereum binaries so that it's more about the what and less about how . Installation shell\nnpm install -g ethbinary Quickstart \ud83d\ude80 shell\nethbinary geth@latest --goerli Will download the latest version of geth and start geth with a connection to the goerli testnet: Examples CLI ```shell\nethbinary list //example: returns [ 'besu', 'ewasm', 'geth', 'prysm' ] ethbinary download geth // will display version selector\nethbinary download geth@1.9.10 // short-hand specifier\nethbinary download geth --clientVersion 1.9.10 // equivalent to above syntax ethbinary exec geth@latest \"version\" // the command MUST be one string for the parser to work\nethbinary exec geth@latest \"account new\" // is auto-attached to terminal so that stdin for password works\nethbinary exec geth --clientVersion latest \"account new\" // verbose syntax ethbinary start geth // will start latest geth version with mainnet connection (geth default)\nethbinary start geth --goerli\nethbinary start geth@1.9.10 --goerli\n``` Module Minimal Start / Stop javascript\nconst { getClient } = require('ethbinary')\nconst geth = await getClient('geth')\nawait geth.start('--goerli')\nawait geth.stop() ethers + ethbinary = \u2764\ufe0f Ipc Provider ```javascript\nconst { getClient, CLIENT_STATE  } = require('ethbinary')\nconst ethers = require('ethers') const geth = await getClient('geth')\nawait geth.start(['--goerli'])\nawait geth.whenState(CLIENT_STATE.IPC_READY)\nconst provider = new ethers.providers.IpcProvider(geth.ipc)\nconst network = await provider.getNetwork() // network { name: 'goerli', chainId: 5, ensAddress: '0x00000000000C2E074eC69A0dFb2997BA6C7d2e1e' }\n// send tx, interact with or deploy contracts here...\nawait geth.stop()\n``` HTTP RPC Server javascript\nconst geth = await getClient('geth')\n// note that --http is new syntax for deprecated --rpc\nawait geth.start(['--dev', '--http'])\nawait geth.whenState(CLIENT_STATE.HTTP_RPC_READY)\nconst provider = new ethers.providers.JsonRpcProvider(geth.rpcUrl)\nconst network = await provider.getNetwork() // network { chainId: 1337, name: 'unknown' }\nawait geth.stop() Multi Client API javascript\nconst { default: cm } = require('ethbinary') // get the client manager instance\nconst clientId = await cm.getClient('geth')\nawait cm.startClient(clientId, 'latest', ['--goerli'])\nawait cm.stopClient(clientId) More Examples check out the other examples Binary Types There are different types of binaries / programs that all require different implementation and interaction strategies.\nAn attempt to classify them based on interactivity might look like this: Services Services or daemons are binaries that are started as background processes. They usually don't require interaction . geth for example can be started as a service. Interaction with the service is happening in this case only via the separate HTTP/IPC RPC API or not at all. The interaction pattern is: javascript\nservice.start()\nservice.whenState(/*rpc ready*/)\n// do something with API\nservice.stop() // optional Wizards / Assistants / REPL Wizards are programs that prompt the user interactively for input and perform operations in between those prompts or after they've received a full configuration processing all responses.\nread\u2013eval\u2013print loop (REPL) programs fall into this category because they constantly require user input and perform actions only after interaction. puppeth for example is an interactive wizard. The interaction pattern is: Full user-interaction javascript\nconst puppeth = await getClient('puppeth')\nawait puppeth.start({\n  stdio: 'inherit' // pass control to terminal: user interacts via stdin & stdout \n}) Automation javascript\nconst puppeth = await getClient('puppeth')\nawait puppeth.start()\nawait puppeth.whenState(log => log.includes('Please specify a network name ')) // parse logs to determine custom state\nawait puppeth.input('my-network-name') // write response to stdin\nawait puppeth.whenState(/*...*/) // wait again\nawait puppeth.input(/*...*/) // respond again Servers Programs that offer functionality via an API to users or other programs are called servers for simplicity.\nThe calling program is called the client in the traditional client-server-model. ethbinary takes the client role when it is interacting with other programs and performing calls to their API. The ZoKrates compiler is an example for a program that receives a single command, processes it and returns a result. The interaction pattern is: javascript\nconst zokrates = await getClient('zokrates')\nfs.writeFileSync(path.join(__dirname, 'test.zok'),   `\ndef main(private field a, field b) -> (field):\n  field result = if a * a == b then 1 else 0 fi\n  return result\n`)\nawait zokrates.execute(`compile -i ${SHARED_DATA}/test.zok`) \nawait zokrates.execute(`setup`) \nawait zokrates.execute('compute-witness -a 337 113569') \nawait zokrates.execute('generate-proof') \nawait zokrates.execute(`export-verifier`) \nawait zokrates.execute(`cp ./verifier.sol ${SHARED_DATA}`, { useBash: true, useEntrypoint: false }) Where a sequence of commands ins executed with .execute Hybrid Of course, some binaries can implement multiple behaviors and act as a service, execute commands and provide server functionality. geth is such an example: geth account new - issues a command which can also be interactive e.g. ask for password geth will start the service Extension ethbinary was created with extension in mind.\nIf your client is not (yet) supported, chances are good you can still make use of this module and benefit from all of its helpers: Some ad-hoc integrations will just magically work out of the box (more likely, if your project follows best practices). Some integrations require a little extra work. This is an example how a GitHub hosted binary can be added on the fly in case it's not available: typescript\nconst cm = new SingleClientManager()\nconst clientConfig = { \n  name: 'prysm.validator', \n  repository: 'https://github.com/prysmaticlabs/prysm', \n  isPackaged: false,\n  filter: ({ fileName }) => fileName.includes('validator')\n}\nconst validator = await cm.getClient(clientConfig, {\n  version: '1.0.0-alpha.6',\n}) This is the same example, written in a rather verbose but detailed style (e.g. during development): ```typescript\nconst cm = new SingleClientManager() // let's assume prysm is not supported..\n// we add a new (minimal) config first \n// see docs or ./client-plugins for available configurations and properties\ncm.addClientConfig({\n  name: 'prysm.validator',\n  repository: 'github:prysmaticlabs/prysm' // or 'https://github.com/prysmaticlabs/prysm'\n  // dockerimage: 'gcr.io/prysmaticlabs/prysm/validator', // <= if it's a dockerized client\n}) // now, we can already use methods like getClient, getClientVersions etc..\n// most of the time we are done here. but let's try a manual integration\n// prysm binaries are not packaged, but uploaded as raw binaries\n// we opt-out of the packaged binary flow with packagesOnly: false and take care of release assets ourselves\n// we will now get all release assets from the prysm github repository, ordered by latest version\nconst versions = await cm.getClientVersions({\n  packagesOnly: false // prysm binaries are not packaged => return raw assets\n}) // prysm assets contain .sig, .sha256, .exe files among other things\n// if we want the latest binary we can just search e.g. for the first file with .exe or no extension \n// but let's say there is a bug in the .beta.8 so we search for .beta.6\nconst latest = versions.find(release => {\n  const ext = getFileExtension(release.fileName)\n  const hasBinaryExtension = (ext === undefined || ext === '.exe')\n  return hasBinaryExtension && release.fileName.includes('validator') && release.version === '1.0.0-alpha.6'\n}) // here, we could check our cache if the binary already exists...\nconst clientPath = path/to/${latest.fileName} // to keep our dependency footprint small we can use the re-exported ethpkg module\n// which is the package manager used internally by ethbinary to manage (find, download, extract, verify...) assets\nconst data = await ethpkg.download(latest.location, onProgress)\nfs.writeFileSync(clientPath, data, {\n  mode: parseInt('754', 8) // make sure binary is executable\n}) // almost done: we create a client instance based on the binary \nconst validator = await cm.getBinaryClient(clientPath) // that's it - we can now interact with a lifecycle managed binary :tada: \nconst version = await validator.execute( --version )\nconst result = await validator.execute( accounts create -keystore-path \"${__dirname}\" --password=\"${password}\" )\n// ... ``` Events ethbinary uses a an event listener mechanism to be notified about the different events during binary preparation.\nMost of the subroutines have 2-3 event(stage)s: started , progress , finished An event log for a binary download might look like this: javascript\nresolve_package_started // api request is made + cache is checked\nfetching_release_list_started // api response is processed: json / xml parsing\nfetching_release_list_finished // remote releases are merged with cached releases\nfilter_release_list_started // invalid releases are removed, version + platform info is extracted, custom filter functions are applied\nsort_releases_started // releases are sorted by semver version & release date\nsort_releases_finished\nfilter_release_list_finished\nresolve_package_finished // the latest release info is available\ndownload_started // the asset for the latest release are downloaded\ndownload_progress\ndownload_finished\nextraction_started // the binary is detected inside the package and the binary or all contents are extracted \nextraction_progreess\nextraction_finished"}, {"name": "ethereum-buildbot", "desc": "Ethereum Buildbot", "readme": "Ethereum Buildbot This project contains the configuration for the Ethereum Buildbot Changes to this repository are automatically deployed once they are pushed to GitHub. Please open a pull request unless you really know what you are doing. Configuration / Development This is to create a local installation of buildbot for development purposes or to test changes to the buildbot's configurations. Start by cloning this repository locally and follow the steps below for your platform. git clone https://github.com/ethereum/ethereum-buildbot.git\ncd ethereum-buildbot Ubuntu Install Docker using the official documentation . Following the \"Docker-maintained Package Installation\" is recommended, as opposed to the \"Ubuntu-maintained Package Installation\". Make sure you have pip installed, then install the requirements: sudo apt-get install python-dev\nwget https://bootstrap.pypa.io/get-pip.py\nsudo python get-pip.py\nsudo pip install -r requirements.txt OSX Install Docker and boot2docker using Homebrew: brew install docker boot2docker Install requirements: pip install -r requirements.txt Common installation steps Generate a new sqlite database: buildbot upgrade-master . Copy every .sample file to their respective filename without the .sample extension. Edit each file with your desired credentials and configurations if you plan on running the buildbot in a production environment, otherwise you can keep the default not-so-secret secret password. Verify that your installation should work with: buildbot checkconfig You should get Config file is good! from the last step. Run buildbot checkconfig after making changes, especially before pushing changes or making pull requests. This will catch syntax errors and will notify you if you missed something in your buildbot configurations. Note: For local testing, you'll need to change the WebStatus' http_port in status.py to something else than the SSL configurations, typically 8010 . You should now be able to start your buildmaster instance with: buildbot start . Your buildmaster should now be accessible at http://localhost:8010 Buildslaves configuration This part can get quite complex, make sure you have your thinking cap well adjusted, grab a coffee and be ready for a lot of tinkering. You've been warned. Remember installing Docker earlier on? This is where it comes into play. Make sure Docker is running and well configured. On OSX, you need to run boot2docker up and follow the instructions about environment variables. On Ubuntu, make sure docker info mentions it is using AUFS (you'll see Storage Driver: aufs ). Create a test buildslave, we'll call it testslave and put it in a folder with the same name: buildslave create-slave testslave localhost testslave secret That test buildslave will be used to create the other buildslaves using Docker containers. On OSX, you can use that same technique to create a native OSX buildslave, just give it a different name or use osx for the currently configured buildslave name. Be careful as this will affect your main system since it is not running in a container. Open builders.py and look for the # Buildslave builders section. Add your testslave to the slavenames parameter of the builder of your choice, or all the buildslave builders. Save your change and reconfigure your buildmaster with: buildbot reconfig . You can now start your buildslave with: buildslave start testslave It should attach itself to your buildmaster. Once you have at least one instance of our testslave running and attached, you should see the builder become available in the waterfall. Trigger a forced build and enjoy the first run fail on a missing buildbot.tac . This is where tinkering really gets taken to a whole new level. You'll need to enter the failing container and set the appropriate values in the right buildbot.tac file at the right location. First, note your host's IP under Docker using ifconfig to find Docker's network interface. You need this to tell the buildslave we're trying to create to connect to your host's buildmaster. Click on the stdio link of the failing step, and note the second line that should look like: in dir /home/your_username/ethereum-buildbot/testslave/build-buildslave-cpp-one/build Move to that folder: cd /home/your_username/ethereum-buildbot/testslave/build-buildslave-cpp-one/build Copy the failing buildslave's buildbot.tac.sample to buildbot.tac : cp cpp-ethereum-buildslave/buildbot.tac.sample cpp-ethereum-buildslave/buildbot.tac Edit the buildbot.tac file with your favorite editor: vim cpp-ethereum-buildslave/buildbot.tac Set buildmaster_host to your previously noted host IP. Make sure slavename and passwd also correspond to the buildslave you're trying to create. Rinse and repeat for every buildslave. Useful tricks Enter a running container with: docker exec -ti CONTAINER_NAME bash Contributing Make sure you have a local installation of the Ethereum Buildbot to test your changes, since any modification can greatly affect many builders and processes, and even bring the whole buildmaster to a halt if changes are blindly pushed to the repository. Pull requests are always welcome and recommended for any modification."}, {"name": "ethereum-client-binaries", "desc": "These were Ethereum client binaries in 2018", "readme": "Archival Notice This repository is an archive. Please see https://ethereum.org/ and specifically the https://ethereum.org/en/developers/docs/nodes-and-clients/ for actual information on clients. Original README.md ethereum-client-binaries Download Ethereum client binaries for your OS. When you wish to run a local Ethereum client node it would be beneficial to first \nscan for existing node client binaries on the machine and then download \nappropriate client binaries if none found. This package does both. It is structured so that it can be optionally be used in conjunction with a UI, \ne.g. if one wishes to allow a user to select the client software they wish to \ndownload. Features:\n* Configurable client types (Geth, Eth, Parity, etc)\n* Security: Binary sanity checks, URL regex checks, SHA256 hash checks\n* Can scan and download to specific folders\n* Logging can be toggled on/off at runtime\n* Can be integrated into Electron.js apps Installation shell\nnpm install --save ethereum-client-binaries Usage Config object First a config object needs to be defined. This specifies the possible clients \nand the platforms they support. For example, a config object which specifies the Geth client for only 64-bit Linux platforms and the Parity client for only 32-bit Windows platforms might be: js\nconst config = {\n  \"clients\": {\n    \"Geth\": {\n      \"platforms\": {\n        \"linux\": {\n          \"x64\": {\n            \"download\": {\n              \"url\": \"https://geth.com/latest.tgz\",\n              \"type\": \"tar\",\n              \"bin\": \"geth-linux-x64\",\n              \"sha256\": \"8359e8e647b168dbd053ec56438ab4cea8d76bd5153d681d001c5ce1a390401c\",\n            },\n            \"bin\": \"geth\",\n            \"commands\": {\n              \"sanity\": {\n                \"args\": [\"version\"],\n                \"output\": [ \"Geth\", \"1.4.12\" ]\n              }                \n            }\n          },\n        }\n      }\n    },\n    \"Parity\": {\n      \"platforms\": {\n        \"win\": {\n          \"ia32\": {\n            \"download\": {\n              \"url\": \"https://parity.com/latest.zip\",\n              \"type\": \"zip\"\n            },\n            \"bin\": \"parity\",\n            \"commands\": {\n              \"sanity\": {\n                \"args\": [\"version\"],\n                \"output\": [ \"Parity\", \"11.0\" ]\n              }                \n            }\n          },\n        }\n      }      \n    }\n  }\n} Every client must specify one or more platforms, each of which must specify \none or more architectures. Supported platforms are as documented for Node's process.platform except that mac is used instead of darwin and win is used instead of win32 . Supported architectures are as documented for Node's process.arch . Each platform-arch entry needs to specify a bin key which holds the name of the executable on the system, a download key which holds info on where the binary can be downloaded from if needed, and a commands key which holds information on different kinds of commands that can be run against the binary. The download key holds the download url , the type of archive being downloaded, and - optionally - the filename of the binary ( bin ) inside the archive in case it differs from the expected filename of the binary. As a security measure, a sha256 key equalling the SHA256 hash calculation of the downloadable file may be provided, in which the downloaded file's hash is tested \nfor equality with this value. The sanity command is mandatory and is a way to check a found binary to ensure that is is actually a valid client binary and not something else. In the above config the sanity command denotes that running geth version should return output containing both Geth and 1.4.12 . Now we can construct a Manager with this config: ```js\nconst Manager = require('ethereum-client-binaries').Manager; // construct\nconst mgr =  new Manager(config);\n``` Note: If no config is provided then the default config ( src/config.json ) gets used. Scanning for binaries Initialising a manager tells it to scan the system for available binaries: js\n// initialise (scan for existing binaries on system)\nmgr.init()\n.then(() => {\n  console.log( 'Client config: ', mgr.clients );\n})\n.catch(process.exit); Let's say the current platform is linux with an x64 architecture, and that geth has been resolved successfully to /usr/local/bin/geth , the mgr.clients property will look like: js\n/*\n[\n  {\n    id: 'Geth',\n    state: {\n      available: true,\n    },\n    platforms: { .... same as original ... }\n    activeCli: {\n      \"download\": {\n        \"url\": \"https://geth.com/latest.tgz\",\n        \"type\": \"tar\"\n      },\n      \"bin\": \"geth\",\n      \"commands\": {\n        \"sanity\": {\n          \"args\": [\"version\"],\n          \"output\": [ \"Geth\", \"1.4.12\" ]\n        }                \n      },\n      fullPath: '/usr/local/bin/geth'\n    }\n  }\n]\n*/ The state.available property is the key property to check. If false then state.failReason will also be set. There are currently two possible values for state.failReason : notFound - a binary with matching name ( geth in above example) could not be found. sanityCheckFail - a binary with matching name was found, but it failed the sanity check when executed. The activeCli.fullPath property denotes the full path to the resolved client binary - this is only valid if state.available is true . NOTE: The Parity client isn't present in mgr.clients shown above because there is no linux-x64 entry specified in the Parity config shown earlier. Thus, only possible clients (as per the original config) will be present in mgr.clients . Scan additional folders By default the manager only scan the system PATH for available binaries, i.e. it doesn't do a full-disk scan. You can specify additional folders to scan using the folders option: js\nmgr.init({\n  folders: [\n    '/path/to/my/folder/1',\n    '/path/to/my/folder/2'\n  ]\n})\n.then(...)\n.catch(...) This features is useful if you have previously downloaded the client binaries elsewhere or you already know that client binaries will be located within specific folders. Download client binaries Client binaries can be downloaded whether already available on the system or not. The downloading mechanism supports downloading and unpacking ZIP and TAR files. The initial config object specifies where a package can be downloaded from, e.g: js\n\"download\": {\n  \"url\": \"https://geth.com/latest.tgz\",\n  \"type\": \"tar\"\n}, To perform the download, specify the client id: js\nmgr.download(\"Geth\")\n.then(console.log)\n.catch(console.error); The returned result will be an object which looks like: js\n{\n  downloadFolder: /* where archive got downloaded */,\n  downloadFile: /* the downloaded archive file */,\n  unpackFolder: /* folder archive was unpacked to */,\n  client: {\n    id: 'Geth',\n    state: {...},\n    platforms: {...},\n    activeCli: {...},\n  }\n} The client entry in the returned info will be the same as is present for the given client within the mgr.clients property (see above). After downloading and unpacking the client binary the sanity check is run against it to check that it is indeed the required binary, which means that the client's state.available and state.failReason keys will be updated with the results. Download to specific folder By default the client binary archive will be downloaded to a temporarily created folder. But you can override this using the downloadFolder option: js\nmgr.download(\"Geth\", {\n  downloadFolder: '/path/to/my/folder'\n})\n.then(...)\n.catch(...) If download and unpacking is successful the returned object will look something like: js\n{\n  downloadFolder: '/path/to/my/folder',\n  downloadFile: '/path/to/my/folder/archive.tgz',\n  unpackFolder: '/path/to/my/folder/unpacked',\n} The next time you initialise the manager you can pass in /path/to/my/folder/unpacked as an additional folder to scan for binaries in: js\nmgr.init({\n  folders: [\n    `/path/to/my/folder/unpacked`\n  ]\n}); URL regular expression (regex) check Even though you can check the SHA 256 hash of the downloaded package (as shown \n  above) you may additionally wish to ensure that the download URL points to \na domain you control. This is important if for example you are obtaining the \ninitial JSON config object from a remote server. This is how you use it: js\nmgr.download(\"Geth\", {\n  urlRegex: /^https:\\/\\/ethereum.org\\/.+$/\n})\n.then(...)\n.catch(...) The above regex states that ONLY download URLs beginning with https://ethereum.org/ are valid and allowed. Logging By default internal logging is silent. But you can turn on logging at any time by setting the logger property: js\nmgr.logger = console;    /* log everything to console */ The supplied logger object must have 3 methods: info, warn and error. If any one of these methods isn't provided then the built-in method (i.e. silent method) get used. For example: js\n// let's output only the error messages\nmgr.logger = {\n  error: console.error.bind(console)\n} Development To build and run the tests: shell\n$ npm install\n$ npm test Contributions Contributions welcome - see CONTRIBUTING.md License MIT - see LICENSE.md"}, {"name": "ethereum-console", "desc": "Commandline console for Ethereum nodes", "readme": "ethereum-console Commandline console for Ethereum nodes. ethconsole connects to a running Ethereum node via IPC/WS/HTTP\nand provides an interactive javascript console containing the web3 (1.x) object with admin extensions. Note that the admin/debug additions are not yet official and may change over time. Run $ ethconsole --help for help. Installation / Usage $ npm install -g ethereum-console\n...\n\n$ ethconsole\nETHEREUM CONSOLE\nConnecting to node at /Users/xyz/Library/Ethereum/geth.ipc\n... Connection successful!\n\nUse the \"web3\" object to interact.\nYou can find the documentation here: http://web3js.readthedocs.io/en/1.0/\n\n\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\nNetwork: MAIN\nCurrent block: 5285047 [0x8a22bd], March 19th 2018, 20:46:37\n\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\u039e\n\n> web3.admin.nodeInfo()\n... CPP Ethereum Test Interface ethconsole provides access to the cpp-ethereum test interface, which can\nbe used to test smart contracts that depend on timing and blocks being\nmined. # Install the development version of cpp-ethereum on Ubuntu:\n# sudo add-apt-repository -y ppa:ethereum/ethereum-qt\n# sudo add-apt-repository -y ppa:ethereum/ethereum\n# sudo add-apt-repository -y ppa:ethereum/ethereum-dev\n# sudo apt-get -y update\n# sudo apt-get -y install eth\n#\n# Start eth in test-mode using data directory /tmp/test \n$ eth --test -d /tmp/test &\n# Wait for it to start up...\n# Run the example:\n$ ethconsole /tmp/test/geth.ipc cppTestExample.js These testing interfaces exist in cpp-ethereum: web3.test.setChainParams({}, cb(err, bool))\n    set chain parameters using the json chain description\n    you can use the function chainParams() from the cppTestExample.js to create such a description\nweb3.test.mineBlocks(x, cb(err, bool))\n    start mining and stop again after exactly x blocks\nweb3.test.modifyTimestamp(x, cb(err, bool))\n    set the timestamp of the current block to x\nweb3.test.rewindToBlock(x, cb(err, bool))\n    rewind the blockchain to block number x\nweb3.test.addBlock(x, cb(err, bool)\n    inject an RLP-encoded block"}, {"name": "ethereum-dockers", "desc": "Docker images for Ethereum", "readme": "ethereum-dockers Dockerfiles for the buildslaves only. Use those provided by each project for end-user containers."}, {"name": "ethereum-docs", "desc": null, "readme": "Ethereum Docs Website Installation Clone the repository Run meteor: meteor Deployment Install Meteor Up globally: npm install -g mup Create a mup.json file Run mup setup Run mup deploy Example of the mup.json file: {\n  \"servers\": [\n    {\n      \"host\": \"10.20.30.40\",\n      \"username\": \"ubuntu\",\n      \"pem\": \"~/.ssh/ethereum.pem\",\n      \"env\": {}\n    }\n  ],\n  \"setupMongo\": false,\n  \"appName\": \"ethereum-docs\",\n  \"app\": \"~/Projects/Ethereum/ethereum-docs\",\n  \"env\": {\n    \"PORT\": 80,\n    \"ROOT_URL\": \"http://10.20.30.40\",\n    \"MONGO_URL\": \"mongodb://mongouser:mongopass@10.20.30.40:27017/ethereum-docs\"\n  },\n  \"deployCheckWaitTime\": 15,\n  \"enableUploadProgressBar\": true\n}"}, {"name": "ethereum-foundation-website", "desc": "Ethereum.foundation is the primary website for the Ethereum Foundation.", "readme": "This is a Next.js project bootstrapped with create-next-app . Getting Started First, run the development server: ```bash\nnpm run dev or yarn dev\n``` Open http://localhost:3000 with your browser to see the result. You can start editing the page by modifying pages/index.tsx . The page auto-updates as you edit the file. API routes can be accessed on http://localhost:3000/api/hello . This endpoint can be edited in pages/api/hello.ts . The pages/api directory is mapped to /api/* . Files in this directory are treated as API routes instead of React pages. Learn More To learn more about Next.js, take a look at the following resources: Next.js Documentation - learn about Next.js features and API. Learn Next.js - an interactive Next.js tutorial. You can check out the Next.js GitHub repository - your feedback and contributions are welcome! Deploy on Vercel The easiest way to deploy your Next.js app is to use the Vercel Platform from the creators of Next.js. Check out our Next.js deployment documentation for more details."}, {"name": "ethereum-org", "desc": "[ARCHIVED] ethereum.org website from 2016-2019. See https://github.com/ethereum/ethereum-org-website for current version.", "readme": "Homestead Release This repository contains the Homestead Release of the ethereum.org website. Prerequisite node npm Installation Make sure you have node.js and npm installed. Clone the repository and install the dependencies bash\ngit clone https://github.com/ethereum/ethereum-org\ncd ethereum-org\nnpm install\nnpm install -g grunt-cli Build static resources bash\ngrunt Run bash\nnpm start see the interface at http://localhost:3000 Publish latest master to GitHub Pages git checkout gh-pages\ngit merge master\ngrunt build\ngit commit -am \"Updated build\"\ngit push origin gh-pages"}, {"name": "ethereum-org-fork", "desc": "Ethereum.org is a primary online resource for the Ethereum community.", "readme": "\ud83d\udc4b Welcome to ethereum.org! This is the repo for the ethereum.org website, a resource for the Ethereum community. The site's purpose is to \u201cBe the best portal to Ethereum for our growing global community\" - read more about what this means here . ethereum.org is being improved and changed over time through the contributions of community members who submit content, give feedback, or volunteer their time to manage its evolution. If you\u2019re interested in helping to improve ethereum.org , find out how to contribute . Looking for the Ethereum blockchain's code? If you're looking for the Ethereum blockchain itself, there is no single repo. Instead, Ethereum has multiple implementations of the protocol written in different programming languages for security and diversity. Check out the different implementations Table of contents How to contribute Translation Program The ethereum.org website stack Website conventions / best practices How to contribute This project follows the all-contributors specification. Contributions of any kind are welcome! 1. Submit an issue Create a new issue . Comment on the issue (if you'd like to be assigned to it) - that way our team can assign the issue to you . More information on the issue creation process, and expectations around creating issues can be found here . 2. Fork the repository (repo) If you're not sure, here's how to fork the repo . 3. Set up your local environment (optional) If you're ready to contribute and create your PR, it will help to set up a local environment so you can see your changes. Set up your development environment Clone your fork If this is your first time forking our repo, this is all you need to do for this step: sh\ngit clone git@github.com:[your_github_handle]/ethereum-org-website.git && cd ethereum-org-website If you've already forked the repo, you'll want to ensure your fork is configured and that it's up to date. This will save you the headache of potential merge conflicts. To configure your fork : sh\ngit remote add upstream https://github.com/ethereum/ethereum-org-website.git To sync your fork with the latest changes : sh\ngit checkout dev\ngit fetch upstream\ngit merge upstream/dev Install dependencies We recommend using a node manager to use multiple node versions in your system. We use Volta . In case you don't use a manager or you use nvm , you can check the currently supported versions under the \"volta\" section on our package.json file. sh\nyarn 4. Make awesome changes! Create new branch for your changes sh\ngit checkout -b new_branch_name Start developing! sh\nyarn start Open this directory in your favorite text editor / IDE, and see your changes live by visiting localhost:8000 from your browser Pro Tip: Explore scripts within package.json for more build options Get faster local builds by building only one language. E.g. in your .env file, set BUILD_LOCALES=en to build the content only in English By default the script will build all the languages (complete list in data/translations.json ) and will ignore the /docs and /tutorials folders. To control this behavior you can play with the BUILD_LOCALES and IGNORE_CONTENT env variables. Check out .env.example to read more about them. Commit and prepare for pull request (PR). In your PR commit message, reference the issue it resolves (see how to link a commit message to an issue using a keyword ). sh\ngit commit -m \"brief description of changes [Fixes #1234]\" Push to your GitHub account sh\ngit push 5. Local development with lambda functions There may be times where you develop features that make external API requests to other services. For these we write lambda functions to obfuscate API keys. To use an existing function locally you don't need to do anything. Just check that you have set the necessary ENV variables in the .env file. To create a new function, you will need to create two files: One in src/lambda where the logic will live. These are the ones that will be deployed to Netlify. These functions follow this format . One in src/api that will be just a wrapper around the previous one in order to be compatible with Gatsby functions. More on the Gatsby docs for the format they follow. Typically, you will develop and test functions in the Gatsby context, by running yarn start . In case you want to test them as if you were in a Netlify env, you can install the Netlify CLI and run netlify dev --framework=gatsby . 6. Submit your PR After your changes are committed to your GitHub fork, submit a pull request (PR) to the dev branch of the ethereum/ethereum-org-website repo In your PR description, reference the issue it resolves (see linking a pull request to an issue using a keyword ) ex. Updates out of date content [Fixes #1234] Gatsby Cloud (our hosting service for build previews) deploys all PRs to a publicly accessible preview URL, e.g.: Confirm your GC preview deploy looks & functions as expected Why not say hi and draw attention to your PR in our discord server ? 7. Wait for review The website team reviews every PR See how decisions are made on content changes Acceptable PRs will be approved & merged into the dev branch Learn more about how we review pull requests here . 8. Release master is continually synced to Netlify and will automatically deploy new commits to ethereum.org Learn more about how we deploy the site here You can view the history of releases , which include PR highlights Claim your POAP! What is POAP? The Proof of Attendance Protocol is a dapp that distributes badges in the form of ERC-721 tokens to prove you participated in an event. More on POAPs . ethereum.org 2022 Contributor POAP If you have committed any changes in 2022 so far that were merged into our repo, you have a POAP waiting! This includes our dedicated translators on Crowdin \ud83d\udc46 To claim your Contributor POAP, join our Discord server and paste a link to your contribution in the #\ud83e\udd47 | poaps channel A member of our team will verify the request and DM you with a personalized link to claim your own freshly minted POAP collectible! To help with verification we request GitHub contributors connect their GitHub account with their Discord account (Discord > Settings > Connections > GitHub). Crowdin contributors will be verified directly through Crowdin by our team. GitPOAP If you've made at least one contribution and that gets merged into ethereum.org, GitPOAP will also auto recognize it and let you mint a unique contributor POAP. More on GitPOAP . If you haven't contributed yet and would like to earn a POAP to show your loyalty to the Ethereum space, head over to the issues tab to get started! Contributors Thanks goes to these wonderful people ( emoji key ): ExodusActual \ud83c\udf0d Anna Karpi\u0144ska \ud83c\udf0d 8bitp \ud83d\udd8b Rousos Alexandros \ud83d\udd8b EvanVanNessEth \ud83d\udd8b JesseAbram \ud83d\udd8b Lililashka \ud83c\udfa8 \ud83d\udc1b vrde \ud83d\udd8b Richard McSorley \ud83d\udcbb Alejandro Santander \ud83d\udd8b Jason Carver \ud83d\udd8b Chaitanya Potti \ud83d\udd8b chriseth \ud83d\udd8b \ud83d\udc40 Craig Williams \ud83d\udd8b Damian Rusinek \ud83d\udd8b Danny Ryan \ud83d\udd8b \ud83d\udc40 Franco Zeoli \ud83d\udd8b \ud83d\udc40 Guy Lando \ud83d\udd8b James Connolly \ud83d\udd8b Jacob Burden \ud83d\udd8b joshorig \ud83d\udd8b mariapaulafn \ud83d\udd8b Mart\u00edn \ud83d\udd8b Mattias Nystrom \ud83d\udd8b nabetse \ud83d\udd8b Nick Savers \ud83d\udd8b Nina Breznik \ud83d\udd8b Ven Gist \ud83d\udd8b Paul Fletcher-Hill \ud83d\udd8b Phil \ud83d\udd8b R\u00e9mi Pr\u00e9vost \ud83d\udd8b Shane \ud83d\udd8b Andrey Petrov \ud83d\udd8b \ud83e\udd14 \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f Santiago Palladino \ud83d\udd8b \ud83e\udd14 Tim Beiko \ud83d\udd8b \ud83d\udc40 Wanseob Lim \ud83d\udd8b \ud83c\udf0d Wil Barnes \ud83d\udd8b Aniket \ud83d\udd8b Chris Chinchilla \ud83d\udd8b George Spasov \ud83d\udd8b Pierrick TURELIER \ud83d\udcbb Solexplorer \ud83d\udd8b Sunghee Lee \ud83d\udd8b awallendahl \ud83d\udd8b Boris Mann \ud83d\udd8b carumusan \ud83d\udd8b econoar \ud83d\udd8b Gustavo Esquinca \ud83d\udd8b Javier Tarazaga \ud83d\udd8b Kendall Cole \ud83d\udd8b Brendan Lee \ud83d\udd8b Mahesh Murthy \ud83d\udd8b Patrick Gallagher \ud83d\udd8b Ali Abbas \ud83d\udd8b wtf \ud83d\udcbb \ud83d\udc40 \ud83d\ude87 Aleksandr Sobolev \ud83d\udd8b Zak Cole \ud83d\udd8b Bogdan Habic \ud83d\udd8b Nick Sawinyh \ud83d\udd8b Miguel Angel Gordi\u00e1n \ud83d\udcbb Eswara Sai \ud83d\udcbb ethers \ud83d\udd8b \ud83e\udd14 Felipe Faraggi \ud83d\udd8b \ud83c\udf0d \ud83e\udd14 \ud83d\udc40 Maurelian \ud83d\udcbb \ud83d\udc40 \ud83d\udd8b CPSTL \ud83d\udd8b \ud83d\udc40 \ud83d\udcd6 Hudson Jameson \ud83d\udd8b \ud83d\udcd6 Shayan Eskandari \ud83d\udcbb \ud83c\udf0d \ud83d\udcd6 Lukas S\u00e4gesser \ud83d\udcbb Virgil Griffith \ud83d\udd8b Eugene Aseev \ud83d\udd8b Jannis Pohlmann \ud83d\udd8b think-in-universe \ud83d\udcbb \ud83d\udd8b Josh Stark \ud83d\udd8b \ud83d\udc40 \ud83d\udcc6 Alan Woo \ud83d\udcbb \ud83c\udfa8 Manank Patni \ud83d\udd8b Rog\u00e9rio Ara\u00fajo \ud83c\udf0d Natacha Souza \ud83c\udf0d sorumfactory \ud83c\udf0d \ud83d\udcc6 \ud83d\udd8b \ud83d\udc1b Sam Richards \ud83d\udcbb \ud83d\udd8b \ud83d\udcd6 \ud83d\udcc6 Antonio Della Porta \ud83d\udcbb Abhimanyu Shekhawat \ud83d\udd8b William Entriken \ud83d\udd8b \ud83d\udcd6 Sangphil Kim \ud83c\udf0d peijie \ud83c\udf0d Jokyash \ud83c\udf0d Pedro Rivera \ud83c\udf0d Gabriele Rigo \ud83c\udf0d Tilen Dr\u017ean \ud83c\udf0d jJosko1986 \ud83c\udf0d ECN \ud83c\udf0d Damiano Azzolini \ud83c\udf0d matteopey \ud83c\udf0d Hun Ryu \ud83c\udf0d nake13 \ud83c\udf0d alexiskefalas \ud83c\udf0d Behrad Khodayar \ud83c\udf0d Frankaus \ud83c\udf0d hacktar \ud83d\udcbb \ud83c\udf0d Jaroslav Macej \ud83c\udf0d Eman Herawy \ud83c\udf0d \ud83d\udcbb \ud83e\udd14 \ud83d\udcd6 Bellinas \ud83c\udf0d Alexander Cherkashin \ud83c\udf0d Enoch Mbaebie \ud83c\udf0d inlak16 \ud83c\udf0d Bob Jiang \ud83c\udf0d Suhun Kim \ud83c\udf0d Jean Zundel \ud83c\udf0d Hachemi \ud83c\udf0d hanzoh \ud83c\udf0d Vincent Le Gallic \ud83c\udf0d Enigmatic331 \ud83d\udd8b Ganesh Prasad Kumble \ud83d\udd8b \ud83c\udf0d Pandiyaraja Ramamoorthy \ud83d\udd8b \ud83c\udf0d Archan Roychoudhury \ud83d\udd8b \ud83c\udf0d SAI PRASHANTH VUPPALA \ud83d\udd8b \ud83c\udf0d Sayid Almahdy \ud83c\udf0d jeedani \ud83c\udf0d Akira \ud83c\udf0d karansinghgit \ud83d\udcbb Marc Garreau \ud83d\udd8b \ud83e\udd14 \ud83d\udc1b mul53 \ud83d\udcbb Apoorv Lathey \ud83d\udcbb Ken Sato \ud83d\udd8b Sesamestrong \ud83d\udcbb ChrisK \ud83d\udd8b Stefan van As \ud83d\udd8b Gr\u00e9goire Jeanmart \ud83d\udd8b nysxah \ud83d\udd8b Rachel \ud83d\udd8b wschwab \ud83d\udcbb \ud83d\udd8b Edson Ayllon \ud83d\udd8b \ud83e\udd14 Peteris Erins \ud83d\udd8b jimmyshi \ud83d\udd8b Jefte Costa \ud83c\udf0d \ud83d\udcbb Jinho Jang \ud83d\udd8b Julien Klepatch \ud83d\udd8b Yaz Khoury \ud83d\udd8b Yos Riady \ud83d\udd8b Andrew Cohen \ud83d\udc1b Wesley van Heije \ud83d\udd8b gr0uch0dev \ud83d\udd8b sooyoung \ud83d\udd8b Adria Massanet \ud83d\udd8b Alex Singh \ud83c\udfa8 Carl Fairclough \ud83c\udfa8 \ud83d\udcbb \ud83d\udc1b Kaven C \ud83d\udd8b Markus Hatvan \ud83d\udcbb Evans Tucker \ud83d\udd8b Adina Cretu \ud83c\udf0d tvanepps \ud83d\udc1b \ud83d\udd8b Victor Guyard \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f Abhranil Das \ud83d\udc1b Ahmet Emin Ko\u00e7al \ud83c\udf0d Aqeel \ud83e\udd14 Linda Xie \ud83d\udc40 \ud83d\udd8b Ian Eck \ud83d\udc40 \ud83d\udd8b Chris Waring \ud83d\udcbb \ud83e\udd14 Ev \ud83e\udd14 \ud83d\udc1b \ud83d\udd8b Ivan Martinez \ud83d\udd8b Sebastian T F \ud83d\udcbb Anett Rolikova \ud83d\udd8b Pooja Ranjan \ud83d\udd8b sassal \ud83d\udd8b Robert Zaremba \ud83d\udd8b Tas \ud83e\udd14 \ud83d\udd8b Sylvain Pace \ud83d\udcbb Sina Habibian \ud83e\udd14 Dennison Bertram \ud83e\udd14 Artur Gontijo \ud83e\udd14 \ud83d\udd8b ethjoe \ud83d\udd8b \ud83d\udc40 cooganb \ud83e\udd14 drequinox \ud83d\udd8b Tarun Gupta \ud83d\udd8b Jamie Pitts \ud83e\udd14 \ud83d\udd8b Chris Seifert \ud83d\udc1b John Craig \ud83d\udcbb Noam Eppel \ud83d\udc1b Jacob Willemsma \ud83d\udd8b Alex \ud83e\udd14 Paul Razvan Berg \ud83d\udd8b ph5500 \ud83d\udd8b \ud83d\udcbb John Monarch \ud83d\udd8b Shadab Khan \ud83d\udcbb ryancreatescopy \ud83d\udcd6 \ud83d\udcbb \ud83c\udfa8 \ud83d\udc1b \ud83e\udd14 \ud83d\udc40 \ud83d\udd8b Hammad Jutt \ud83d\udd8b Becaz \ud83e\udd14 Caos \ud83d\udd8b codingsh \ud83d\udcbb Artem \ud83d\udd8b Cristian Espinoza Garner \ud83d\udd8b Daniel Schlabach \ud83d\udd8b Marius van der Wijden \ud83d\udd8b \ud83e\udd14 Markus Waas \ud83d\udd8b Keith Yeung \ud83d\udcbb Jordan Lyall \ud83d\udd8b elanh \ud83d\udd8b Mohamed Hayibor \ud83d\udd8b Conor Svensson \ud83d\udd8b Aranha \ud83d\udcbb Jung Sup (James) Yoo \ud83c\udf0d Veit Progl \ud83e\udd14 jcamilli \ud83d\udd8b Martin Holst Swende \ud83d\udc1b Steven Gilbert \ud83d\udd8b Sacha Saint-Leger \ud83d\udd8b Griffin Ichiba Hotchkiss \ud83d\udd8b \ud83d\udcd6 Scott Bigelow \ud83d\udd8b Harikrishnan Mulackal \ud83d\udd8b Matthieu Caneill \ud83d\udd8b Arjuna Sky Kok \ud83d\udc1b Brian Gu \ud83d\udd8b Gon\u00e7alo Hora de Carvalho \ud83d\udc1b M\u00e1rio Havel \ud83d\udd8b JosefJ \ud83d\udd8b Christoph Burgdorf \ud83e\udd14 slipperybeluga \ud83e\udd14 David Liu \ud83d\udd8b shreyashariharan3 \ud83d\udd8b Adri\u00e1n Calvo \ud83d\udd8b daviroo \ud83d\udd8b Wim Notredame \ud83d\udcbb vasa \ud83d\udd8b Franziska Heintel \ud83d\udd8b Muhammad Umair Irshad \ud83d\udd8b Nazzareno Massari \ud83d\udd8b Mayemene Fomene Jean Vladimir \ud83d\udc1b \ud83d\udd8b Yahsin Huang \ud83d\udd8b \ud83c\udf0d James Zaki \ud83d\udd8b Greg Lang \ud83d\udd8b Matt Voska \ud83d\udc1b mustafa \ud83d\udd8b Paul Wackerow \ud83d\udcbb \ud83d\udc1b \ud83d\udcd6 \ud83c\udfa8 Attaphong Rattanaveerachanon \ud83d\udc1b \ud83d\udd8b LoinLiao \ud83d\udd8b DrMad92 \ud83d\udc1b Patricio Palladino \ud83d\udc40 \ud83e\udd14 David Murdoch \ud83d\udc40 MashhoodIjaz \ud83d\udc1b \ud83d\udd8b Dan Nolan \ud83d\udd8b \ud83d\udcd6 Marek Kirejczyk \ud83d\udd8b Jon Cursi \ud83d\udd8b James Farrell \ud83d\udc1b \ud83d\udd8b Xavi Arias Segu\u00ed \ud83d\udc1b \ud83d\udd8b ANKIT_PAL \ud83d\udcbb \u0130smail Kerim Cem \ud83d\udc1b Joanne \ud83d\udd8b michael60634 \ud83d\udc1b \ud83e\udd14 Andrei Maiboroda \ud83d\udd8b Anki \ud83d\udd8b Michelle Plur \ud83d\udc1b PAAlmasi \ud83d\udd8b Ben Edgington \ud83d\udc1b \ud83d\udd8b alexsantee \ud83d\udc1b \ud83d\udd8b peth-yursick \ud83d\udd8b Alwin Stockinger \ud83d\udc1b \ud83d\udd8b Roberto Henr\u00edquez Perozo \ud83d\udd8b strykerin \ud83d\udd8b jddxf \ud83d\udc1b \ud83d\udd8b LucasRoorda \ud83d\udd8b Mihir Luthra \ud83d\udd8b tentodev \ud83d\udd8b \ud83d\udc1b MiZiet \ud83d\udd8b Vaibhav Chopra \ud83d\udd8b Lakshman Sankar \ud83d\udc1b \ud83d\udd8b hewigovens \ud83d\udd8b \ud83d\udc1b DragonDev1906 \ud83d\udc1b \ud83d\udd8b Ryan Ghods \ud83d\udd8b Oliver \ud83d\udd8b Kristiyan \ud83d\udc1b \ud83d\udcbb Matthieu Riou \ud83d\udd8b pansay \ud83d\udd8b \ud83d\udc1b eirtscience \ud83d\udd8b Francis Lewis \ud83d\udc1b \ud83d\udd8b baub \ud83d\udd8b \ud83d\udc1b lamone \ud83d\udd8b Sean O'Connor \ud83d\udd8b Tara Rowell \ud83d\udd8b Aleksi Cohen \ud83d\udc1b \ud83d\udd8b Kartikaya Gupta (kats) \ud83d\udc1b \ud83d\udd8b siddhantkharode \ud83d\udd8b \ud83d\udc1b Renan Dincer \ud83d\udc1b \ud83d\udd8b Zhangyuan Nie \ud83d\udc1b \ud83d\udd8b Patrick Collins \ud83d\udd8b Sant Deleon \ud83d\udcbb Martin Huschenbett \ud83d\udd8b \ud83d\udc1b Kalle Moen \ud83d\udc1b \ud83d\udd8b Vitaly \ud83d\udcbb Nikolay Yushkevich \ud83d\udd8b darkwater4213 \ud83d\udc1b \ud83d\udd8b Akash Nimare \ud83d\udd8b Dave Mackey \ud83d\udd8b Emanuel Tesa\u0159 \ud83d\udd8b DeFiDude \ud83d\udc1b Austin Griffith \ud83d\udd8b Chase Manning \ud83d\udc1b \ud83d\udd8b Colin Steil \ud83d\udd8b MonarthS \ud83d\udcbb Adam Dry \ud83d\udc1b \ud83d\udd8b Nikolai Vavilov \ud83d\udc1b \ud83d\udd8b Katie \ud83d\udc1b \ud83d\udd8b comeToThinkOfEth \ud83d\udc1b catsnackattack \ud83d\udc1b Maurycy \ud83d\udd8b Igor Papandinas \ud83d\udc1b \ud83d\udcbb \ud83d\udd8b Tahir Alvi \ud83e\udd14 amirmehdi \ud83d\udc1b \ud83d\udd8b Dan Dadybaev \ud83d\udd8b Finley \ud83e\udd14 nobd \ud83d\udd8b Alexander Sadovskyi \ud83d\udd8b Ethan Sarif-Kattan \ud83d\udc1b \ud83d\udd8b C.J. Kozarski \ud83d\udd8b Yakko Majuri \ud83d\udcbb John Adler \ud83d\udd8b \ud83d\udc1b Just some guy \ud83d\udd8b \ud83d\udcd6 Vedvardhan \ud83d\udd8b \ud83d\udc1b Yussuf Elarif \ud83d\udc1b David Awad \ud83d\udd8b Alex Beregszaszi \ud83d\udd8b Adam Goth \ud83d\udc1b \ud83d\udd8b Anurag Pal \ud83d\udcbb \ud83d\udcd6 Vishal Pratap Singh \ud83d\udcbb qbzzt \ud83d\udd8b \ud83e\udd14 Ewa Kowalska \ud83d\udd8b Aheesh \ud83d\udd8b tophersjones \ud83d\udd8b Andrew Yang \ud83d\udd8b $hoot->Pairs \ud83d\udd8b NilsKaden \ud83d\udcbb Stuart Reynolds \ud83e\udd14 Gwenael Le Bodic \ud83d\udd8b Anurag Verma \ud83d\udc1b \ud83d\udcbb Nikolai Golub \ud83d\udd8b Elliot Lee \ud83d\udd8b \ud83d\udc1b Viktor Garske \ud83d\udc1b \ud83d\udd8b Kristjan Grm \ud83d\udd8b Mac L \ud83d\udd8b Bruce MacDonald \ud83d\udd8b Ronnie Sherfey \ud83d\udcbb Ali Rahman \ud83d\udd8b Erik Vandeputte \ud83d\udd8b \ud83d\udc1b TM Lee \ud83d\udc1b mic0des \ud83d\udcbb Hakeem Almidan \ud83d\udd8b \ud83d\udcbb Julien Rioux \ud83d\udd8b Justin Chow \ud83d\udd8b Gabi \ud83d\udd8b Rohit Gopal \ud83d\udc1b Jordan Overbye \ud83d\udc1b \ud83d\udcbb Peter LaFontaine \ud83d\udc1b \ud83d\udd8b Joshua Welsh \ud83d\udc1b Robert Dosa \ud83d\udd8b SatoshiMiracle \ud83d\udc1b James Boyle \ud83e\udd14 \ud83d\udd8b Kevin Ziechmann \ud83d\udc1b Evan \ud83d\udd8b ETHorHIL \ud83d\udd8b shashvatshah9 \ud83d\udd8b slightlyfloating \ud83d\udc1b Luis Miranda \ud83d\udc1b Alex Ismodes \ud83d\udd8b Joshua \ud83d\udc1b \ud83d\udcbb Ensar Yusuf Y\u0131lmaz \ud83d\udc1b Leo Guti\u00e9rrez Ram\u00edrez \ud83d\udc1b Abdul Malik \ud83d\udc1b Jay Welsh \ud83d\udc1b linkastic \ud83d\udd8b Chan Jing Hong \ud83d\udd8b Ozora Ogino \ud83d\udd8b \ud83c\udf0d Ikko Ashimine \ud83d\udc1b \ud83d\udd8b \ud83d\udcd6 \ud83c\udf0d Cameron Honis \ud83d\udc1b Chirag Shetty \ud83d\udc1b Michael Bianco \ud83d\udc1b Tom Robiquet \ud83d\udcbb Stanislav Bezkorovainyi \ud83d\udd8b Rootul Patel \ud83d\udc1b Zachary DeRose \ud83d\udd8b Arshan Khanifar \ud83d\udc1b David Schnurr \ud83d\udd8b Kevin Leffew \ud83d\udd8b Pierre Grimaud \ud83d\udc1b Jack Clancy \ud83d\udd8b Justin Spradlin \ud83d\udc1b \ud83d\udd8b Aditya Anand M C \ud83d\udd8b James Dixon \ud83d\udd8b Vasu Manhas \ud83d\udc1b jp_aulet \ud83d\udcbb manojmsrit \ud83e\udd14 David Kim \ud83d\udd8b Bhavish Yalamanchi \ud83d\udd8b awg0013-PR \ud83d\udd8b Devin \ud83d\udd8b Dave \ud83e\udd14 Rafael Matias \ud83d\udc1b \ud83d\udd8b Colman Glagovich \ud83d\udd8b endorphin \ud83d\udd8b Nebali \ud83d\udd8b Shubh Agrawal \ud83d\udd8b cth0604 \ud83d\udcbb zjpetersen \ud83d\udc1b frankie224 \ud83d\udc1b Alexandru Turcanu \ud83d\udd8b Brett \ud83d\udd8b Jo\u00e3o Monteiro \ud83d\udd8b \ud83d\udc1b Arun Lodhi \ud83d\udd8b Tim \ud83d\udd8b Vitaliy Hayda \ud83d\udc1b \ud83d\udd8b Ayushman Singh Chauhan \ud83d\udc1b \ud83d\udd8b Keqi Huang \ud83d\udc1b \ud83d\udd8b davidplutus \ud83e\udd14 Karthickmerk \ud83e\udd14 Sihong \ud83d\udcbb AmirAliM \ud83d\udd8b Rub3cula \ud83d\udd8b Pawe\u0142 Urbanek \ud83d\udd8b Aditya Dhir \ud83d\udc1b Ammar Husain \ud83d\udd8b \ud83d\udc1b miiiguel \ud83d\udd8b Uttam Singh \ud83d\udc1b Chase Wright \ud83d\udd8b Bic \ud83d\udd8b devELIOper \ud83d\udd8b \ud83d\udc1b Vadym Barda \ud83d\udd8b Leo Cu\u00e9llar \ud83d\udd8b \ud83d\udcbb \ud83d\udc1b pheeque \ud83d\udc1b \ud83d\udd8b Jeremy Musighi \ud83d\udd8b tbollinger \ud83d\udc1b Ryan Grunest \ud83d\udd8b Aniket Raj \ud83d\udd8b Kamil Zarzycki \ud83c\udf0d \ud83d\udd8b Filip Martinsson \ud83d\udd8b zeroservices \ud83d\udc1b LukaK \ud83d\udd8b \ud83e\udd14 Luke Ingalls \ud83d\udd8b cstradtman \ud83d\udc1b G Surendar Thina \ud83d\udd8b Scott Dodge \ud83d\udc1b Artur Cygan \ud83d\udc1b Rory \ud83d\udc1b Connor Mann \ud83d\udc1b Phanindra \ud83d\udd8b kwsorensen \ud83d\udd8b Theo Pack \ud83d\udc1b kirati-su \ud83e\udd14 oliver renwick \ud83e\udd14 \ud83d\udc1b Pankaj Patil \ud83d\udd8b esale \ud83d\udc1b RaynHarr \ud83d\udd8b \ud83d\udcd6 n4rsil \ud83d\udd8b John Bishop \ud83d\udd8b robriks \ud83d\udc1b \ud83d\udcc6 \ud83d\udcac \ud83d\udcd6 Nishant Chandla \ud83d\udcbb \ud83d\udc1b @paulapivat \ud83d\udd8b Graeme Blackwood \ud83d\udc1b il3ven \ud83d\udcbb Hayden Briese \ud83d\udc1b Trevor French \ud83d\udd8b Antonio Sanso \ud83d\udcd6 Siddharth S \ud83d\udcd6 \ud83d\udc1b jbgwu \ud83d\udcd6 ethosdev \ud83d\udd8b \ud83d\udcd6 Joseph Schiarizzi \ud83d\udd8b Rodney Olav C Melby \ud83d\udd8b Raman \ud83d\udd8b Roeland Werring \ud83d\udc1b Stan Kladko \ud83d\udcd6 Jared Flomen \ud83d\udcd6 \ud83d\udc1b Joseph Wallace \ud83d\udc1b Ahmed Prusevic \ud83d\udcbb Matt \ud83d\udd8b ytrezq \ud83d\udcd6 Ricky \ud83d\udc1b smudgil \ud83d\udd8b Don Cross \ud83d\udcd6 Jackson Taylor \ud83e\udd14 MrBrain295 \ud83d\udc1b \ud83d\udcd6 \ud83e\udd14 \ud83d\udd8b SafePalWallet \ud83d\udd8b Vishal Vaddadhi \ud83d\udd8b Matt Kula \ud83d\udc1b Hamza Shahzad \ud83d\udcbb \ud83d\udc1b Mukul Kolpe \ud83d\udcbb \ud83d\udc1b \ud83d\udcd6 Corwin Smith \ud83d\udcbb spiolat \ud83d\udcd6 hosyminh95 \ud83d\udcd6 Chiara Wilden \ud83e\udd14 \ud83d\udcd6 DanhPTHTech \ud83d\udcd6 James Hooper \ud83d\udc1b \ud83d\udcd6 Christopher Hegre \ud83d\udcd6 Najeeb Nabwani \ud83d\udcd6 Alexander Goncalves \ud83d\udcd6 Gabe Casalett \ud83d\udcd6 waynedyer12 \ud83d\udcd6 tap (pts.eth) \ud83d\udd8b James Morgan \ud83e\udd14 Sharon Wang \ud83d\udc1b \ud83d\udcd6 Enrique Jose  Avila Asapche \ud83e\udd14 Gianni Alessandroni \ud83d\udcd6 Raj Shekhar Bhardwaj \ud83d\udcd6 \ud83e\udd14 joakimengerstam \ud83d\udcd6 Nikita Drozd \ud83d\udc1b \ud83d\udcd6 \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f Scott \ud83c\udfa8 \ud83d\udc1b Stefan Sathianathen \ud83d\udcd6 Miroslav Lehotsky \ud83d\udcd6 Remco \ud83d\udcd6 Shailendra Shukla \ud83d\udcd6 Skylar Weaver \ud83d\udcd6 \ud83d\udd8b agorismlabs \ud83e\udd14 Tanishq Sharma \ud83e\udd14 Mark Strefford \ud83d\udc1b Andrzej W\u00f3dkiewicz \ud83d\udcd6 Hugo \ud83d\udd8b Joseph Harris \ud83d\udcd6 Ozgur \ud83d\udcd6 Alec Dilanchian \ud83d\udcd6 Horacio Bertorello \ud83d\udcd6 m4sterbunny \ud83d\udcd6 \u611a\u6307\u5bfc \ud83d\udcd6 Ray Jasson \ud83d\udcd6 Calvin Storoschuk \ud83d\udc1b \ud83d\udcbb Clashinm \ud83d\udcd6 james-prysm \ud83e\udd14 William Buck \ud83d\udcd6 metalocal \ud83d\udc1b \ud83d\udcd6 Himanshu Singh \ud83d\udc1b \ud83d\udcd6 \ud83e\udd14 Andrew B Coathup \ud83d\udcd6 \ud83d\udc1b Andrew Gallagher \ud83d\udd8b \ud83d\udcbb Phat Nguyen Luu \ud83d\udcd6 Andreas Sofos \ud83d\udcbb Felipe Selmo \ud83d\udcd6 Bingwei Qin \ud83d\udcd6 Mikko Ohtamaa \ud83e\udd14 \ud83d\udcd6 Kabilan \ud83e\udd14 Colin Steidtmann \ud83d\udd8b \ud83d\udc1b SNikhill \ud83d\udcbb SlashHash \ud83e\udd14 Harsh Mathur \ud83d\udd8b pranav desai \ud83d\udd8b Luk\u00e1\u0161 Kotol \ud83d\udcd6 Nick Carbone \ud83d\udcd6 Ashwin Nair \ud83d\udcbb Julian Ste \ud83d\udcbb \ud83d\udcd6 \ud83d\udd8b Pranay Reddy \ud83d\udcbb marc \ud83d\udcd6 Mariano Baragiola \ud83d\udcd6 under3415 \ud83e\udd14 Gaurav Kumar Shah \ud83e\udd14 Hubert Sikorski \ud83d\udcd6 Corey Rice \ud83d\udcd6 Ezenwankwo Gabriel \ud83d\udcd6 Thomas Lisankie \ud83d\udcd6 \ud83d\udc1b Tyler Ilunga \ud83d\udcd6 Kasia Kosturek \ud83d\udcd6 solarpunklabs \ud83e\udd14 aakhtar3 \ud83d\udcd6 Shreyas Londhe \ud83d\udd8b Tim Beccue \ud83d\udd8b Robert Joseph Wayne \ud83d\udcd6 \ud83d\udd8b pdesmondflynn \ud83d\udd8b Daniel Damilola Obiokeke \ud83d\udd8b mpj \ud83d\udd8b \ud83d\udcd6 Hung Doan \ud83d\udc1b Pawe\u0142 Wilczy\u0144ski \ud83c\udf0d joaoMpf \ud83c\udf0d Bhaskar Kashyap \ud83d\udcd6 \ud83d\udd8b bleesherman \ud83d\udd8b \ud83d\udcd6 Robert Miller \ud83d\udd8b Florian Sesser \ud83d\udcd6 xianxiongwang \ud83d\udcd6 Slava Shirokov \ud83d\udcd6 BenOfTheBlockchain \ud83e\udd14 0xngmi \ud83d\udcd6 Shivam Rajput \ud83d\udcd6 Raymond \ud83d\udcbb Justin Johnson \ud83d\udcd6 SA KSH AM \ud83d\udd8b Samrat \ud83d\udd8b Justin Shaw \ud83d\udd8b \ud83d\udcbb \ud83d\udcd6 \ud83e\udd14 meoww-bot \ud83d\udcd6 Philip Vu \ud83d\udcd6 Conner Jensen \ud83d\udcd6 Jhaymes \ud83e\udd14 daniel sieradski \ud83d\udcd6 bgillcode \ud83d\udcd6 \ud83d\udcbb Cameron Fink \ud83d\udcd6 \ud83e\udd14 Venom \ud83d\udcd6 JulienM \ud83d\udcbb Jem Mawson \ud83d\udcd6 Mislav \ud83d\udcbb \ud83d\udcd6 Justin Hunter \ud83d\udcd6 Enton Biba \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f Oriol Serra \ud83d\udc1b \ud83e\udd14 Nicolas LARCHE \ud83d\udc1b A. Tyler Benson \ud83d\udcd6 Derek\u5468\u671d\u6656 \ud83d\udcd6 \ud83c\udf0d Damian Schenkelman \ud83d\udcd6 Hendrik Eeckhaut \ud83d\udcd6 \ud83d\udcbb Susannah Evans \ud83d\udcd6 Minimalist Optimalist \ud83d\udc1b vluna \ud83d\udcbb \ud83d\udc1b \ud83d\udd8b Arghya Biswas \ud83d\udcbb abhi-go \ud83d\udcd6 Franco Victorio \ud83d\udcd6 \ud83d\udc1b Kevin Jones \ud83d\udcbb \ud83d\udc1b \ud83d\udd8b Shubhankar Kanchan Gupta \ud83d\udc1b \ud83d\udcbb Vishvanathan K \ud83d\udcd6 Alexander Gryaznov \ud83e\udd14 Pablo Pettinari \ud83d\udcd6 \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f Celetra \ud83d\udc1b \ud83d\udcd6 sharadseth \ud83d\udcd6 Mariah \ud83d\udd8b Amadou Crookes \ud83d\udd8b \ud83d\udcd6 Nathan Woodruff \ud83e\udd14 Andrey Azimov \ud83d\udcd6 Anita Diamond \ud83d\udcd6 ismaventuras \ud83d\udcd6 \ud83c\udf0d Jhonny \ud83d\udcd6 Matthieu SCARSET \ud83d\udcd6 zhanxin \ud83c\udf0d \ud83d\udcd6 Geoff Hull \ud83d\udcd6 Austin Burke \ud83d\udcd6 Richard Rodrigues \ud83d\udcd6 \ud83c\udf0d Samnang Chhun \ud83d\udcd6 Tanvir Ahmed \ud83d\udcd6 Joris Zierold \ud83d\udcd6 \ud83e\udd14 selfwithin \ud83e\udd14 \ud83d\udcd6 Jonathan Joshua \ud83d\udcd6 Patrick Aljord \ud83d\udcd6 decifer \ud83e\udd14 aghArdeshir \ud83d\udcbb Michael Connell \ud83d\udd8b \ud83d\udcbb Ahmed Mustafa Malik \ud83d\udcbb Gamaliel 'Yel' Padillo \ud83d\udcd6 Kumar Kalyan \ud83d\udc1b \ud83d\udcd6 \ud83d\udcbb \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f 0xdie \ud83d\udcd6 Taimoor Ali \ud83d\udcd6 \ud83d\udc1b Andrej \ud83d\udcd6 \ud83d\udd8b Pascal Marco Caversaccio \ud83d\udcd6 \ud83d\udd8b kennethcassel \ud83d\udcd6 BrysonXiao \ud83d\udd8b Discord #8528 \ud83d\udd8b Ned Rockson \ud83d\udcd6 Tommaso Tosi \ud83d\udcd6 Kamil \ud83d\udc1b Mert \ud83d\udcd6 \ud83d\udc1b Naman Bhalla \ud83d\udcd6 Kirk \ud83d\udc1b juliangeissler \ud83d\udcd6 \ud83d\udc1b \ud83d\udcbb Garric G. Nahapetian \ud83d\udd8b Dmitriy Fishman \ud83d\udcd6 neozapatista \ud83d\udcd6 Factral \ud83c\udf0d \ud83d\udcd6 \ud83d\udc1b \ud83d\udcbb elshigori \ud83d\udcd6 EarthMan \ud83c\udf0d \ud83d\udcd6 mohan-chinnappan-n \ud83e\udd14 Nicola Bonsi \ud83e\udd14 Yusuf Elnady \ud83d\udd8b Aryan Keluskar \ud83d\udcbb Ling \ud83d\udd8b S\u00f8ren Rood \ud83d\udcbb \ud83d\udcd6 \ud83e\udd14 Tanmay Nagepatil \ud83e\udd14 Brandon Harden \ud83d\udd8b Snigdha Singh \ud83d\udcd6 SW \ud83d\udcd6 Aaron Chen \ud83e\udd14 Qazal Samani \ud83d\udcd6 yash \ud83e\udd14 Isaac Beale \ud83d\udcd6 \ud83d\udc1b Bal Krishna Jha \ud83d\udcd6 mradziwon \ud83d\udcbb \ud83d\udc1b mmilenkovic \ud83d\udcd6 \ud83e\udd14 Fernando Guevara \ud83d\udcd6 Jose Manuel Garcia Rivas \ud83e\udd14 PolySages \ud83d\udc1b \ud83d\udcd6 Zainab Hasan \ud83d\udcd6 \ud83e\udd14 Marcos Dedeu \ud83d\udcd6 Sunit Roy \ud83d\udc1b Gabriel Garcia \ud83d\udcd6 Tiago Yonamine \ud83d\udcd6 Erik Hunter \ud83d\udcd6 lingzhong \ud83d\udcd6 \ud83d\udc1b Yash Kamal Chaturvedi \ud83d\udcd6 EtherWorld \ud83d\udcd6 Stefan Ignjatovi\u0107 \ud83d\udcd6 Iheb Haboubi \ud83d\udc1b Hursit Tarcan \ud83d\udcbb pabloped \ud83d\udcd6 \ud83c\udf0d ilkererkek \ud83d\udcd6 Filippo Tarpini \ud83d\udcd6 saif-11bit \ud83d\udcd6 Sasha Shpota \ud83d\udcd6 Erik Bj\u00e4reholt \ud83d\udcd6 \ud83d\udcbb tomasbanik \ud83d\udcd6 Aditya Agarwal \ud83d\udcd6 Gerard Sans \ud83d\udd8b Cheah Chu Yeow \ud83d\udd8b Yan Luiz \ud83d\udd8b Alexandre Chabrolin \ud83d\udd8b Sergey Danilovich \ud83d\udd8b \ud83d\udcd6 Marcelo Rodriguez \ud83d\udd8b \ud83d\udcbb Anna \ud83d\udd8b Justin Traglia \ud83d\udd8b bitmateus \ud83d\udd8b Roberto Carboni \ud83d\udd8b K\u039eVIN K\u039elch\u039e\u27e0 \ud83d\udd8b Sa\u00efd Ibrihen \ud83d\udd8b Rob Dawson \ud83d\udd8b Ahmed Ashour \ud83d\udcd6 Nick Johnson \ud83d\udcd6 \u5434\u6cfd\u5eb7 \ud83d\udcd6 \ud83c\udf0d Nick Gaski \ud83d\udcd6 Rahul \ud83e\udd14 \ud83d\udcd6 \ud83d\udd8b Francisco J. Moreno \ud83c\udf0d \ud83d\udcd6 Zach \ud83d\udd8b bestpilotingalaxy \ud83d\udcd6 Afr Schoe \ud83d\udcbb \ud83d\udcd6 jamongeon1 \ud83d\udcd6 Jay \ud83d\udcbb Arnaud Spanneut \ud83c\udf0d yuliyu123 \ud83c\udf0d Jack \ud83c\udf0d Jason Manoloudis \ud83d\udcd6 Medzhidov-Omardibir \ud83d\udcd6 ApoGrs \ud83e\udd14 Mohammed Sadiq \ud83d\udcd6 Sahil sen \ud83d\udcd6 Collin K Cusce \ud83d\udcd6 \ud83e\udd14 hma23 \ud83e\udd14 \ud83d\udcd6 Karan Kaira \ud83d\udcd6 \ud83d\udcbb ReDrawn \ud83d\udcd6 Oskar Mendel \ud83d\udcbb thewild-being \ud83e\udd14 Mihrac Cerrahoglu \ud83e\udd14 smartcontracts \ud83d\udcd6 \ud83d\udc1b Samay Lakhani \ud83d\udcd6 vdusart \ud83d\udcd6 \ud83d\udcbb \ud83c\udf0d wd021 \ud83d\udcd6 \ud83d\udcbb Max Roslow \ud83d\udcd6 \ud83c\udf0d tnkrxyz \ud83d\udcd6 Nuno Loureiro \ud83d\udcbb \ud83c\udfa8 polarpunklabs \ud83d\udcd6 Neographer \ud83d\udcd6 Voll \ud83d\udcd6 SurpriseMF3000 \ud83d\udcd6 \ud83d\udcbb htimsk \ud83d\udccb George Zhang \ud83d\udcd6 Nitin Rajesh \ud83d\udcd6 Rakesh Hotker \ud83d\udcd6 S\u00e9bastien Dan \ud83d\udcd6 Sakshi \ud83d\udcd6 Anshi \ud83d\udcd6 mikoto-studio \ud83d\udd8b Arhat \ud83d\udd8b \ud83d\udcd6 php4fan \ud83d\udc1b Kaiser Pister \ud83d\udcd6 \ud83d\udcbb Marc-Antoine Thevenet \ud83d\udcd6 Alan Toa \ud83d\udd27 Christopher Pearce \ud83d\udcd6 Yuta Kurotaki \ud83d\udcd6 Claudio2000 \ud83d\udcd6 \ud83d\udcbb Tomas Pasiecznik \ud83d\udcbb Xiangxi Guo (Ryan) \ud83d\udc1b Andile Mchunu \ud83d\udcd6 Noah \ud83d\udcd6 Adrian Li \ud83d\udcd6 Konstantinos Penlidis \ud83d\udcd6 Hunter Sandlin \ud83d\udcd6 Chris Boesch \ud83e\udd14 Nhan Vo \ud83d\udcd6 \ud83c\udf0d devtooligan \ud83d\udcd6 \ud83d\udcbb \ud83e\udd14 Thomas \ud83d\udcd6 Patrice Lamarque \ud83d\udcd6 \ud83e\udd14 \ud83d\udc1b sell50 \ud83d\udcd6 Manuel Peralta \ud83d\udcd6 Riely \ud83d\udcd6 \ud83c\udf0d Jasper \ud83d\udd8b Ryan Higdn \ud83d\udc1b \ud83d\udcd6 Eni-G \ud83d\udcd6 B01AND \ud83d\udcd6 Ashwin Ramaswami \ud83d\udcd6 Albert Lie Adrian \ud83d\udcd6 Ishaan Parmar \ud83d\udcbb \ud83c\udfa8 \ud83e\udd14 Tarun Batra \ud83d\udcd6 \ud83d\udc1b Max \ud83d\udcd6 \ud83d\udc1b Luozhu \ud83d\udcd6 \ud83e\udd14 Yash Sharma \ud83d\udcd6 cryptochrome \ud83e\udd14 \ud83d\udc1b Argan Wang \ud83d\udcd6 \ud83c\udf0d Tim Mustafin \ud83e\udd14 superphiz \ud83d\udcd6 \ud83e\udd14 seanlakers \ud83e\udd14 Jason Yan \ud83d\udcd6 \ud83c\udf0d mradkov \ud83d\udcd6 Bienvenido Rodriguez \ud83d\udcd6 \ud83e\udd14 Sora Nature \ud83d\udcd6 Joseph Schiarizzi \ud83d\udcd6 Gustavo Silva \ud83d\udc1b Samarth Saxena \ud83d\udcd6 Baihao \ud83d\udcd6 \ud83d\udc1b \ud83d\udcbb Steve Goodman \ud83d\udcd6 booklearner \ud83d\udcd6 moretimeL \ud83d\udd8b SuperDelphi \ud83d\udd8b \ud83c\udf0d \ud83d\udc1b \ud83d\udcd6 chadlohrli \ud83d\udd8b Julius Degesys \ud83d\udcd6 Nicol\u00e1s Quiroz \ud83d\udcbb \ud83d\udc1b wolz-CODElife \ud83d\udcd6 Mina Essam \ud83e\udd14 GNONG \ud83d\udcd6 Sina Pilehchiha \ud83d\udcd6 thefrenchbrazilianguy \ud83d\udcd6 Anish Gupta \ud83d\udcd6 Matthew \ud83d\udcd6 Justyna Broniszewska \ud83d\udcd6 Elyanil Liranzo-Castro \ud83d\udcd6 Lichu Acu\u00f1a \ud83d\udcd6 Takamasa Arakawa \ud83d\udcbb \ud83d\udc1b skaunov \ud83d\udcd6 Paul Cowgill \ud83d\udcd6 zjiekai \ud83d\udcd6 wii u \ud83e\udd14 MonsieurDMA \ud83d\udcd6 fennar01 \ud83e\udd14 \ud83d\udcd6 William \ud83d\udcbb motemotech \ud83d\udcbb mousticke.eth \ud83d\udcbb brightiron \ud83d\udcbb oleksandrkovalskiy \ud83d\udcd6 yoshikouki \ud83d\udcd6 \ud83e\udd14 Graz Network \ud83d\udcd6 \ud83c\udf0d Cryptoversidad \ud83d\udcd6 Disconnect3d \ud83d\udcd6 \ud83d\udc1b Seth Ariel Green \ud83d\udcd6 \ud83d\udd8b Luisa Calixto \ud83d\udcd6 \ud83d\udd8b theanneli \ud83d\udcd6 Deric | Alchemy \ud83d\udcd6 Ahmetbasli \ud83d\udcd6 Jordi Pascual \ud83c\udf0d \ud83d\udc1b \ud83d\udcd6 Amith KK \ud83d\udcd6 \ud83d\udc1b Arpit Ingle \ud83e\udd14 Gourav Singh Rawat \ud83d\udcd6 \ud83e\udd14 mempirate \ud83d\udcd6 \ud83d\udc1b Barukimang \ud83d\udcd6 Kaan Uzdo\u011fan \ud83d\udcd6 Colin Kennedy \ud83d\udcd6 XOF \ud83d\udcd6 \ud83c\udf0d \ud83d\udc1b Manu kashyap \ud83d\udcd6 Zhou Yang \ud83d\udcd6 tree \ud83d\udcd6 Stephen Fluin \ud83d\udcd6 hakuta \ud83d\udcd6 MiloBowman \ud83d\udcd6 tadeo \ud83d\udcd6 Jorge Santana \ud83d\udd8b rolodexter \ud83d\udcd6 RanchHowards \ud83d\udcd6 \ud83d\udc1b Deyan Shotev \ud83d\udcbb Pranesh A S \ud83d\udcd6 \ud83d\udc1b shir22 \ud83d\udcd6 \ud83d\udc1b Nikita Verkhovin \ud83d\udc1b Pushkar Verma \ud83d\udcd6 \ud83e\udd14 Vincent Weisser \ud83d\udcd6 Kosuke Ogawa \ud83d\udcd6 \ud83d\udc1b Fatih Eren Erol \ud83d\udcd6 Oli Lalonde \ud83d\udcd6 gingerheart86 \ud83d\udcd6 Naveen Kumar \ud83d\udcd6 Cam Sweeney \ud83d\udcd6 moyed \ud83d\udcd6 shelleyolivia \ud83d\udcd6 \ud83e\udd14 Sandy \ud83d\udcd6 NachoRoizman \ud83d\udcd6 Iv\u00e1n Miragaya \ud83d\udcbb Jakub Sm\u00e9kal \ud83d\udcd6 Tony Chen \ud83d\udcd6 metalc \ud83d\udcd6 Tuongg2312 \ud83d\udcd6 \u039erik Saunier \ud83d\udcd6 Artem Vorotnikov \ud83d\udd8b \ud83d\udcc6 \ud83d\udcac Liam Arzola \ud83d\udc1b shao \ud83d\udcd6 \ud83c\udf0d Hiroyuki Naito \ud83d\udcd6 AlehN \ud83d\udcd6 Varun Shenoy \ud83d\udc1b Alessandro Baffa \ud83d\udcd6 \ud83d\udc1b John Grant \ud83d\udcd6 gorondan \ud83d\udcd6 Pruthviraj Jadhav \ud83d\udcd6 Oscar Barajas Tavares \ud83d\udcd6 Samuel Akinosho \ud83d\udcd6 \ud83d\udcbb Odair Augusto Trujillo Orozco \ud83d\udcd6 \ud83e\udd14 Unforkable \ud83d\udcd6 Rodrigo vasquez \ud83d\udcd6 \ud83e\udd14 Michael McCallam \ud83d\udcd6 Polina G. \ud83d\udcd6 Neeraj Gahlot \ud83d\udcd6 \ud83d\udc1b Kostas \ud83d\udcd6 rogueassasin1729 \ud83d\udcd6 Pandapip1 \ud83d\udcd6 \ud83e\udd14 Aldi Zhupani \ud83d\udc1b \ud83d\udcbb linhuatan \ud83d\udcd6 Hugh \ud83d\udcd6 Kim Kwangtae \ud83d\udd8b \ud83e\udd14 tobi4021 \ud83d\udcd6 Haochen Song \ud83d\udcd6 \ud83c\udf0d N Fx \ud83d\udcd6 \ud83c\udf0d samsara \ud83d\udcd6 \ud83d\udc1b \ud83c\udf0d greefea \ud83d\udcd6 parotax \ud83d\udcd6 Loc Nguyen \ud83d\udd8b north-vanhooser \ud83d\udcd6 othaime-en \ud83d\udcbb Cronos \ud83d\udcd6 \ud83c\udf0d Micah Zoltu \ud83d\udcd6 Ivan Aracki \ud83e\udd14 \u5c60\u866b\u5c11\u5e74 \ud83d\udcd6 \ud83c\udf0d Ramandeep \ud83e\udd14 Vlad Kokhan \ud83d\udcd6 \ud83c\udf0d Phill \ud83d\udd8b \ud83d\udcd6 \ud83d\udcbb cam \ud83d\udc1b \ud83d\udcd6 calumtomeny \ud83d\udcd6 robertu \ud83d\udcd6 \ud83c\udf0d Lorena De Leon Salazar \ud83c\udf0d James Adams \ud83d\udcd6 Eric Chen \ud83d\udcd6 Van De Biao \ud83d\udcd6 Sourav Suman \ud83e\udd14 Ivan Pavi\u010di\u0107 \ud83d\udcd6 \ud83d\udc1b tommy \ud83d\udcd6 \ud83c\udf0d Martin Yung \ud83d\udcbb \ud83c\udf0d Pankaj Jagtap \ud83d\udcd6 nulun \ud83d\udcbb Denllay \ud83d\udcd6 \ud83c\udf0d yalexis.eth \ud83d\udcd6 Ahmad Bitar \ud83d\udcd6 Carl Lippert \ud83d\udcd6 Tymek Majewski \ud83d\udcd6 Cryptolibertarian.id \ud83d\udcd6 browny \ud83e\udd14 \ud83d\udcbb \ud83d\udc1b Marius Kj\u00e6rstad \ud83e\udd14 Scott Fitsimones \ud83d\udcd6 Paul Lechocki \ud83d\udcd6 justalike \ud83d\udcd6 grayliquid \ud83d\udcd6 MohammadHosein Masoon \ud83d\udcd6 Patoshi \ud83d\udcd6 June Clarke \ud83d\udcd6 \u83f2\u5229 \ud83d\udcd6 DamitusThyYeetus123 \ud83d\udcd6 matusame \ud83c\udf0d Lohan \ud83d\udcbb Marcella \ud83d\udcbb Leon Todd \ud83d\udcd6 Ladislas Fontaine \ud83d\udcd6 Yash Yadav \ud83d\udcd6 barro \ud83d\udcd6 Master7130 \ud83d\udcbb Lude15 \ud83e\udd14 Luke Fan \ud83d\udcd6 TABASCO \ud83d\udcd6 d1onys1us \ud83d\udcd6 Thibaut \ud83d\udcd6 Miguel \ud83d\udcbb Ray Zhu \ud83d\udcd6 Lucca Benedetti \ud83d\udcd6 Mac Morgan \ud83d\udcd6 \ud83d\udc1b Aksa12 \ud83d\udcbb Aniruddha Sil \ud83d\udcd6 \ud83d\udcbb \u2661 \ud83d\udcd6 Luis Sebastian Urrutia Fuentes \ud83d\udcbb jakubalsoori \ud83d\udcd6 Wenceslas Sanchez \ud83d\udcd6 Marcus Escobedo \ud83d\udcd6 fr33dr4g0n \ud83e\udd14 Ritesh Singh \ud83d\udcd6 Simon Letort \ud83d\udcd6 AidanPine \ud83d\udcbb christy-pdx \ud83d\udd8b Medard Mandane \ud83d\udcd6 Dave Lucia \ud83d\udcd6 Lo\u00efc Albertin \ud83d\udcd6 Mille Codex \ud83d\udcd6 Gift Opia \ud83d\udcbb Dhiraj Gagrai \ud83d\udcbb KurtMerbeth \ud83d\udd8b Sai Leela Rahul Pujari \ud83d\udd8b SkyWarrior123 \ud83d\udd8b Yashovardhan Agrawal \ud83d\udd23 cheeky-gorilla \ud83d\udc1b Noah Page \ud83d\udcd6 steph \ud83d\udcbb Daniel Park \ud83d\udcd6 knititwearit \ud83e\udd14 Ryan Smith \ud83d\udcd6 Vaishnavi Joshi \ud83d\udcd6 Jamie Barrett \ud83d\udcbb Renato \ud83d\udd8b \ud83c\udf0d Francisco \ud83d\udcd6 Franklin Ohaegbulam \ud83d\udcbb Soos3D \ud83d\udcd6 Minho Ryang \ud83d\udcbb Sebastian Supreme \ud83e\udd14 \ud83c\udf0d \ud83d\udcbb Awosise Oluwaseun \ud83d\udcd6 Muhammad Ahmad \ud83d\udcbb Oliver \ud83d\udcd6 Jiwon Park \ud83d\udcd6 Zandt Lavish \ud83d\udcd6 sushthecoda \ud83d\udcd6 Lucas Martin Calderon \ud83d\udcd6 crypto8893 \ud83d\udd8b Victor Patru \ud83d\udcbb wishee \ud83d\udcd6 Harshil Gupta \ud83d\udcd6 Vanshika Srivastava \ud83e\udd14 Shariq Anwar \ud83d\udcbb Giorgio Nocera \ud83d\udcd6 Dmitry Alexeev \ud83d\udd8b Alex \ud83d\udcd6 benlazzero \ud83d\udcbb Ankit Singh \ud83d\udcbb mhairimcalpine \ud83d\udd8b William Doom \ud83d\udcd6 AsheBarrett \ud83c\udf0d Hitishaa \ud83d\udcd6 Shiv Rustagi \ud83d\udcd6 Douglas Makey Mendez Molero \ud83d\udcbb Amit Gaikwad \ud83d\udcbb Eridian \ud83d\udcd6 Bobby Galli \ud83d\udcd6 flanagansteve \ud83d\udcd6 Owen Hwang \ud83d\udcd6 Andreas Florath \ud83d\udcd6 Daniel Coffman \ud83d\udcd6 AMIT KUMAR MISHRA \ud83d\udcd6 Saksham Thapa \ud83d\udc1b Vijayendra Gaur \ud83d\udcd6 Andr\u00e1s Novosz\u00e1th \ud83d\udcd6 Sahil Aujla \ud83d\udcd6 Olaf Tomalka \ud83d\udcd6 Abhiram G P \ud83d\udcbb Amine E. \ud83d\udcd6 Roshan R Chandar \ud83d\udcd6 mossow \ud83d\udcd6 yujingwei \ud83d\udcd6 Daniel Olshansky \ud83d\udcd6 \ud83e\udd14 aguzmant103 \ud83d\udcd6 Soheil \ud83d\udcbb metadiver.eth \ud83d\udcbb Jacob \ud83e\udd14 \ud83d\udcd6 Sam Padilla \ud83d\udcd6 Chen Quan \ud83d\udcd6 \ud83c\udf0d Marcelo T. dos Santos \ud83d\udcbb NoahSchick \ud83e\udd14 Joey \ud83d\udd8b AnnaNodes \ud83d\udd8b Yash Jagtap \ud83d\udd8b Gast\u00f3n Zanitti \ud83d\udd8b Dan \ud83d\udd8b Elizabeth Bassey \ud83d\udd8b mihaic01 \ud83d\udd8b qiuhaohao \ud83d\udd8b damilola debel \ud83d\udd8b Sarat Angajala \ud83d\udcd6 questions \ud83d\udcc6 \ud83d\udcac machin3boy \ud83d\udd8b nethan \ud83d\udd8b Jithil P Ponnan \ud83d\udcd6 \ud83d\udcbb chocolatesuit \ud83d\udd8b Apinan Yogaratnam \ud83d\udd8b trevorsc19 \ud83d\udd8b ImThour \ud83d\udcbb Nenad Vitorovi\u0107 \ud83d\udd8b danierod \ud83d\udcbb siddtheone \ud83d\udd8b Shawki Sukkar \ud83d\udd8b Harpal Jadeja \ud83d\udcbb Zion \ud83d\udd8b Andriy Zhuk \ud83d\udd8b gooser.eth \ud83d\udd8b feibowei \ud83d\udd8b Mesquita Oliveira \ud83d\udcd6 Juan Jos\u00e9 Giraldo \ud83d\udd8b Ash@metaschool \ud83d\udd8b Tom Rutten \ud83d\udd8b Chawye Hsu \ud83d\udcd6 Mateus Pimenta \ud83d\udd8b ezal \ud83d\udc1b Jarrod Watts \ud83d\udd8b Miao \ud83d\udcbb Jiatu Liu \ud83d\udd8b DeUETH \ud83d\udd8b erin-at-work \ud83d\udd8b 0xAA \ud83d\udd8b changwu \ud83d\udd8b yj \ud83d\udd8b megatheikal \ud83d\udc1b Stephen Guo \ud83c\udf0d F. Eugene Aumson \ud83d\udc1b \ud83d\udd8b Roshan \ud83d\udd8b \ud83d\udcbb Maxime Dessez \ud83d\udc1b \ud83c\udf0d Tyler-233 \ud83c\udf0d \ud83d\udd8b neodaoist \ud83d\udd8b Atharva Deosthale \ud83d\udd8b Kartik Chopra \ud83d\udd8b Bibash Tandon \ud83d\udd8b Vaibhav Tevatia \ud83d\udcbb cnn-rnn \ud83e\udd14 Sahitya Roy \ud83e\udd14 KeeCoin \ud83e\udd14 Seungwook Chi \ud83d\udd8b 0xx92 \ud83d\udd8b altinocoelho \ud83d\udd8b viac92 \ud83d\udd8b DongXi Huang \ud83d\udd8b Suraj Anand \ud83d\udd8b Mwitah \ud83d\udd8b Tuckson \ud83d\udd8b Akamig \ud83d\udd8b Peace Ojemeh \ud83d\udd8b woseK \ud83d\udd8b \ud83d\udc1b Gunal \ud83d\udd8b chinaman123 \ud83e\udd14 Alex \ud83d\udcd6 \ud83d\udc1b Matthew \ud83d\udc1b \ud83d\udcd6 gokhan \ud83d\udc1b Adri \ud83d\udd8b Sherry.Du \ud83d\udd8b Francesco Ciulla \ud83d\udd8b blazingrome \ud83d\udd8b Etan Kissling \ud83d\udd8b kritik sah \ud83d\udc1b Fuliggine \ud83d\udd8b Omsify \ud83d\udc1b 0xMimir \ud83d\udd8b Bilal \ud83d\udd8b Ilan \ud83d\udd8b umede \ud83d\udd8b Tamino \ud83d\udd8b Katherine Champagne \ud83d\udd8b Marcos Gonz\u00e1lez \ud83d\udcd6 Natalino Picone \ud83d\udd8b Hammad Saaedi \ud83d\udd8b Shaunak Nagrecha \ud83d\udc1b Kevin Schwindt \ud83d\udd8b Robert \ud83d\udd8b obsidian \ud83d\udd8b Fekry Aiad \ud83e\udd14 Wilson Wu \ud83d\udcd6 VAS \ud83d\udcd6 Costanza \ud83d\udcd6 joao \ud83d\udcd6 Eugene \ud83d\udd8b D\u00e1niel G\u00f6rbe \ud83d\udcd6 s-crypt \ud83d\udd8b iwantanode \ud83d\udd8b shak58 \ud83d\udd8b Muhammad Altabba \ud83d\udd8b Darigov Research \ud83d\udd8b SHUBHAM SHARMA \ud83e\udd14 paulallensuxs \ud83d\udd8b Pseudomata \ud83d\udcbb CodeDragonVN \ud83d\udd8b SamiAlHassan \ud83d\udd8b NaijaCoderGirl \ud83d\udd8b Konstantin Zolotarev \ud83d\udd8b vuittont60 \ud83d\udd8b Golden Ite \ud83d\udd8b Erlangshen219 \ud83d\udd8b AyDeveloper \ud83d\udd8b jeremyfritzen \ud83d\udd8b Zheng Fu \ud83d\udcbb xiaolou86 \ud83d\udd8b aztecEagle22 \ud83d\udd8b QIAN \ud83d\udd8b This project follows the all-contributors specification. Contributions of any kind welcome! Join our Discord server We have a space to discuss all things ethereum.org \u2013 share your ideas or just say hi over on Discord ."}, {"name": "ethereum-org-next", "desc": null, "readme": "This is a Next.js project bootstrapped with create-next-app . Getting Started First, run the development server: ```bash\nnpm run dev or yarn dev or pnpm dev\n``` Open http://localhost:3000 with your browser to see the result. You can start editing the page by modifying pages/index.tsx . The page auto-updates as you edit the file. API routes can be accessed on http://localhost:3000/api/hello . This endpoint can be edited in pages/api/hello.ts . The pages/api directory is mapped to /api/* . Files in this directory are treated as API routes instead of React pages. This project uses next/font to automatically optimize and load Inter, a custom Google Font. Learn More To learn more about Next.js, take a look at the following resources: Next.js Documentation - learn about Next.js features and API. Learn Next.js - an interactive Next.js tutorial. You can check out the Next.js GitHub repository - your feedback and contributions are welcome! Deploy on Vercel The easiest way to deploy your Next.js app is to use the Vercel Platform from the creators of Next.js. Check out our Next.js deployment documentation for more details."}, {"name": "ethereum-org-website", "desc": "Ethereum.org is a primary online resource for the Ethereum community.", "readme": "\ud83d\udc4b Welcome to ethereum.org! This is the repo for the ethereum.org website, a resource for the Ethereum community. The site's purpose is to \u201cBe the best portal to Ethereum for our growing global community\" - read more about what this means here . ethereum.org is being improved and changed over time through the contributions of community members who submit content, give feedback, or volunteer their time to manage its evolution. If you\u2019re interested in helping to improve ethereum.org , find out how to contribute . Looking for the Ethereum blockchain's code? If you're looking for the Ethereum blockchain itself, there is no single repo. Instead, Ethereum has multiple implementations of the protocol written in different programming languages for security and diversity. Check out the different implementations Table of contents How to contribute Translation Program The ethereum.org website stack Website conventions / best practices How to contribute This project follows the all-contributors specification. Contributions of any kind are welcome! 1. Submit an issue Create a new issue . Comment on the issue (if you'd like to be assigned to it) - that way our team can assign the issue to you . More information on the issue creation process, and expectations around creating issues can be found here . 2. Fork the repository (repo) If you're not sure, here's how to fork the repo . 3. Set up your local environment (optional) If you're ready to contribute and create your PR, it will help to set up a local environment so you can see your changes. Set up your development environment Clone your fork If this is your first time forking our repo, this is all you need to do for this step: sh\ngit clone git@github.com:[your_github_handle]/ethereum-org-website.git && cd ethereum-org-website If you've already forked the repo, you'll want to ensure your fork is configured and that it's up to date. This will save you the headache of potential merge conflicts. To configure your fork : sh\ngit remote add upstream https://github.com/ethereum/ethereum-org-website.git To sync your fork with the latest changes : sh\ngit checkout dev\ngit fetch upstream\ngit merge upstream/dev Install dependencies We recommend using a node manager to use multiple node versions in your system. We use Volta . In case you don't use a manager or you use nvm , you can check the currently supported versions under the \"volta\" section on our package.json file. sh\nyarn 4. Make awesome changes! Create new branch for your changes sh\ngit checkout -b new_branch_name Start developing! sh\nyarn start Open this directory in your favorite text editor / IDE, and see your changes live by visiting localhost:8000 from your browser Pro Tip: Explore scripts within package.json for more build options Get faster local builds by building only one language. E.g. in your .env file, set BUILD_LOCALES=en to build the content only in English By default the script will build all the languages (complete list in data/translations.json ) and will ignore the /docs and /tutorials folders. To control this behavior you can play with the BUILD_LOCALES and IGNORE_CONTENT env variables. Check out .env.example to read more about them. Commit and prepare for pull request (PR). In your PR commit message, reference the issue it resolves (see how to link a commit message to an issue using a keyword ). sh\ngit commit -m \"brief description of changes [Fixes #1234]\" Push to your GitHub account sh\ngit push 5. Local development with lambda functions There may be times where you develop features that make external API requests to other services. For these we write lambda functions to obfuscate API keys. To use an existing function locally you don't need to do anything. Just check that you have set the necessary ENV variables in the .env file. To create a new function, you will need to create two files: One in src/lambda where the logic will live. These are the ones that will be deployed to Netlify. These functions follow this format . One in src/api that will be just a wrapper around the previous one in order to be compatible with Gatsby functions. More on the Gatsby docs for the format they follow. Typically, you will develop and test functions in the Gatsby context, by running yarn start . In case you want to test them as if you were in a Netlify env, you can install the Netlify CLI and run netlify dev --framework=gatsby . 6. Submit your PR After your changes are committed to your GitHub fork, submit a pull request (PR) to the dev branch of the ethereum/ethereum-org-website repo In your PR description, reference the issue it resolves (see linking a pull request to an issue using a keyword ) ex. Updates out of date content [Fixes #1234] Gatsby Cloud (our hosting service for build previews) deploys all PRs to a publicly accessible preview URL, e.g.: Confirm your GC preview deploy looks & functions as expected Why not say hi and draw attention to your PR in our discord server ? 7. Wait for review The website team reviews every PR See how decisions are made on content changes Acceptable PRs will be approved & merged into the dev branch Learn more about how we review pull requests here . 8. Release master is continually synced to Netlify and will automatically deploy new commits to ethereum.org Learn more about how we deploy the site here You can view the history of releases , which include PR highlights Claim your POAP! What is POAP? The Proof of Attendance Protocol is a dapp that distributes badges in the form of ERC-721 tokens to prove you participated in an event. More on POAPs . ethereum.org 2022 Contributor POAP If you have committed any changes in 2022 so far that were merged into our repo, you have a POAP waiting! This includes our dedicated translators on Crowdin \ud83d\udc46 To claim your Contributor POAP, join our Discord server and paste a link to your contribution in the #\ud83e\udd47 | poaps channel A member of our team will verify the request and DM you with a personalized link to claim your own freshly minted POAP collectible! To help with verification we request GitHub contributors connect their GitHub account with their Discord account (Discord > Settings > Connections > GitHub). Crowdin contributors will be verified directly through Crowdin by our team. GitPOAP If you've made at least one contribution and that gets merged into ethereum.org, GitPOAP will also auto recognize it and let you mint a unique contributor POAP for the specific year. More on GitPOAP . If you haven't contributed yet and would like to earn a POAP to show your loyalty to the Ethereum space, head over to the issues tab to get started! Contributors Thanks goes to these wonderful people ( emoji key ): ExodusActual \ud83c\udf0d Anna Karpi\u0144ska \ud83c\udf0d 8bitp \ud83d\udd8b Rousos Alexandros \ud83d\udd8b EvanVanNessEth \ud83d\udd8b JesseAbram \ud83d\udd8b Lililashka \ud83c\udfa8 \ud83d\udc1b vrde \ud83d\udd8b Richard McSorley \ud83d\udcbb Alejandro Santander \ud83d\udd8b Jason Carver \ud83d\udd8b Chaitanya Potti \ud83d\udd8b chriseth \ud83d\udd8b \ud83d\udc40 Craig Williams \ud83d\udd8b Damian Rusinek \ud83d\udd8b Danny Ryan \ud83d\udd8b \ud83d\udc40 Franco Zeoli \ud83d\udd8b \ud83d\udc40 Guy Lando \ud83d\udd8b James Connolly \ud83d\udd8b Jacob Burden \ud83d\udd8b joshorig \ud83d\udd8b mariapaulafn \ud83d\udd8b Mart\u00edn \ud83d\udd8b Mattias Nystrom \ud83d\udd8b nabetse \ud83d\udd8b Nick Savers \ud83d\udd8b Nina Breznik \ud83d\udd8b Ven Gist \ud83d\udd8b Paul Fletcher-Hill \ud83d\udd8b Phil \ud83d\udd8b R\u00e9mi Pr\u00e9vost \ud83d\udd8b Shane \ud83d\udd8b Andrey Petrov \ud83d\udd8b \ud83e\udd14 \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f Santiago Palladino \ud83d\udd8b \ud83e\udd14 Tim Beiko \ud83d\udd8b \ud83d\udc40 Wanseob Lim \ud83d\udd8b \ud83c\udf0d Wil Barnes \ud83d\udd8b Aniket \ud83d\udd8b Chris Chinchilla \ud83d\udd8b George Spasov \ud83d\udd8b Pierrick TURELIER \ud83d\udcbb Solexplorer \ud83d\udd8b Sunghee Lee \ud83d\udd8b awallendahl \ud83d\udd8b Boris Mann \ud83d\udd8b carumusan \ud83d\udd8b econoar \ud83d\udd8b Gustavo Esquinca \ud83d\udd8b Javier Tarazaga \ud83d\udd8b Kendall Cole \ud83d\udd8b Brendan Lee \ud83d\udd8b Mahesh Murthy \ud83d\udd8b Patrick Gallagher \ud83d\udd8b Ali Abbas \ud83d\udd8b wtf \ud83d\udcbb \ud83d\udc40 \ud83d\ude87 Aleksandr Sobolev \ud83d\udd8b Zak Cole \ud83d\udd8b Bogdan Habic \ud83d\udd8b Nick Sawinyh \ud83d\udd8b Miguel Angel Gordi\u00e1n \ud83d\udcbb Eswara Sai \ud83d\udcbb ethers \ud83d\udd8b \ud83e\udd14 Felipe Faraggi \ud83d\udd8b \ud83c\udf0d \ud83e\udd14 \ud83d\udc40 Maurelian \ud83d\udcbb \ud83d\udc40 \ud83d\udd8b CPSTL \ud83d\udd8b \ud83d\udc40 \ud83d\udcd6 Hudson Jameson \ud83d\udd8b \ud83d\udcd6 Shayan Eskandari \ud83d\udcbb \ud83c\udf0d \ud83d\udcd6 Lukas S\u00e4gesser \ud83d\udcbb Virgil Griffith \ud83d\udd8b Eugene Aseev \ud83d\udd8b Jannis Pohlmann \ud83d\udd8b think-in-universe \ud83d\udcbb \ud83d\udd8b Josh Stark \ud83d\udd8b \ud83d\udc40 \ud83d\udcc6 Alan Woo \ud83d\udcbb \ud83c\udfa8 Manank Patni \ud83d\udd8b Rog\u00e9rio Ara\u00fajo \ud83c\udf0d Natacha Souza \ud83c\udf0d sorumfactory \ud83c\udf0d \ud83d\udcc6 \ud83d\udd8b \ud83d\udc1b Sam Richards \ud83d\udcbb \ud83d\udd8b \ud83d\udcd6 \ud83d\udcc6 Antonio Della Porta \ud83d\udcbb Abhimanyu Shekhawat \ud83d\udd8b William Entriken \ud83d\udd8b \ud83d\udcd6 Sangphil Kim \ud83c\udf0d peijie \ud83c\udf0d Jokyash \ud83c\udf0d Pedro Rivera \ud83c\udf0d Gabriele Rigo \ud83c\udf0d Tilen Dr\u017ean \ud83c\udf0d jJosko1986 \ud83c\udf0d ECN \ud83c\udf0d Damiano Azzolini \ud83c\udf0d matteopey \ud83c\udf0d Hun Ryu \ud83c\udf0d nake13 \ud83c\udf0d alexiskefalas \ud83c\udf0d Behrad Khodayar \ud83c\udf0d Frankaus \ud83c\udf0d hacktar \ud83d\udcbb \ud83c\udf0d Jaroslav Macej \ud83c\udf0d Eman Herawy \ud83c\udf0d \ud83d\udcbb \ud83e\udd14 \ud83d\udcd6 Bellinas \ud83c\udf0d Alexander Cherkashin \ud83c\udf0d Enoch Mbaebie \ud83c\udf0d inlak16 \ud83c\udf0d Bob Jiang \ud83c\udf0d Suhun Kim \ud83c\udf0d Jean Zundel \ud83c\udf0d Hachemi \ud83c\udf0d hanzoh \ud83c\udf0d Vincent Le Gallic \ud83c\udf0d Enigmatic331 \ud83d\udd8b Ganesh Prasad Kumble \ud83d\udd8b \ud83c\udf0d Pandiyaraja Ramamoorthy \ud83d\udd8b \ud83c\udf0d Archan Roychoudhury \ud83d\udd8b \ud83c\udf0d SAI PRASHANTH VUPPALA \ud83d\udd8b \ud83c\udf0d Sayid Almahdy \ud83c\udf0d jeedani \ud83c\udf0d Akira \ud83c\udf0d karansinghgit \ud83d\udcbb Marc Garreau \ud83d\udd8b \ud83e\udd14 \ud83d\udc1b mul53 \ud83d\udcbb Apoorv Lathey \ud83d\udcbb Ken Sato \ud83d\udd8b Sesamestrong \ud83d\udcbb ChrisK \ud83d\udd8b Stefan van As \ud83d\udd8b Gr\u00e9goire Jeanmart \ud83d\udd8b nysxah \ud83d\udd8b Rachel \ud83d\udd8b wschwab \ud83d\udcbb \ud83d\udd8b Edson Ayllon \ud83d\udd8b \ud83e\udd14 Peteris Erins \ud83d\udd8b jimmyshi \ud83d\udd8b Jefte Costa \ud83c\udf0d \ud83d\udcbb Jinho Jang \ud83d\udd8b Julien Klepatch \ud83d\udd8b Yaz Khoury \ud83d\udd8b Yos Riady \ud83d\udd8b Andrew Cohen \ud83d\udc1b Wesley van Heije \ud83d\udd8b gr0uch0dev \ud83d\udd8b sooyoung \ud83d\udd8b Adria Massanet \ud83d\udd8b Alex Singh \ud83c\udfa8 Carl Fairclough \ud83c\udfa8 \ud83d\udcbb \ud83d\udc1b Kaven C \ud83d\udd8b Markus Hatvan \ud83d\udcbb Evans Tucker \ud83d\udd8b Adina Cretu \ud83c\udf0d tvanepps \ud83d\udc1b \ud83d\udd8b Victor Guyard \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f Abhranil Das \ud83d\udc1b Ahmet Emin Ko\u00e7al \ud83c\udf0d Aqeel \ud83e\udd14 Linda Xie \ud83d\udc40 \ud83d\udd8b Ian Eck \ud83d\udc40 \ud83d\udd8b Chris Waring \ud83d\udcbb \ud83e\udd14 Ev \ud83e\udd14 \ud83d\udc1b \ud83d\udd8b Ivan Martinez \ud83d\udd8b Sebastian T F \ud83d\udcbb Anett Rolikova \ud83d\udd8b Pooja Ranjan \ud83d\udd8b sassal \ud83d\udd8b Robert Zaremba \ud83d\udd8b Tas \ud83e\udd14 \ud83d\udd8b Sylvain Pace \ud83d\udcbb Sina Habibian \ud83e\udd14 Dennison Bertram \ud83e\udd14 Artur Gontijo \ud83e\udd14 \ud83d\udd8b ethjoe \ud83d\udd8b \ud83d\udc40 cooganb \ud83e\udd14 drequinox \ud83d\udd8b Tarun Gupta \ud83d\udd8b Jamie Pitts \ud83e\udd14 \ud83d\udd8b Chris Seifert \ud83d\udc1b John Craig \ud83d\udcbb Noam Eppel \ud83d\udc1b Jacob Willemsma \ud83d\udd8b Alex \ud83e\udd14 Paul Razvan Berg \ud83d\udd8b ph5500 \ud83d\udd8b \ud83d\udcbb John Monarch \ud83d\udd8b Shadab Khan \ud83d\udcbb ryancreatescopy \ud83d\udcd6 \ud83d\udcbb \ud83c\udfa8 \ud83d\udc1b \ud83e\udd14 \ud83d\udc40 \ud83d\udd8b Hammad Jutt \ud83d\udd8b Becaz \ud83e\udd14 Caos \ud83d\udd8b codingsh \ud83d\udcbb Artem \ud83d\udd8b Cristian Espinoza Garner \ud83d\udd8b Daniel Schlabach \ud83d\udd8b Marius van der Wijden \ud83d\udd8b \ud83e\udd14 Markus Waas \ud83d\udd8b Keith Yeung \ud83d\udcbb Jordan Lyall \ud83d\udd8b elanh \ud83d\udd8b Mohamed Hayibor \ud83d\udd8b Conor Svensson \ud83d\udd8b Aranha \ud83d\udcbb Jung Sup (James) Yoo \ud83c\udf0d Veit Progl \ud83e\udd14 jcamilli \ud83d\udd8b Martin Holst Swende \ud83d\udc1b Steven Gilbert \ud83d\udd8b Sacha Saint-Leger \ud83d\udd8b Griffin Ichiba Hotchkiss \ud83d\udd8b \ud83d\udcd6 Scott Bigelow \ud83d\udd8b Harikrishnan Mulackal \ud83d\udd8b Matthieu Caneill \ud83d\udd8b Arjuna Sky Kok \ud83d\udc1b Brian Gu \ud83d\udd8b Gon\u00e7alo Hora de Carvalho \ud83d\udc1b M\u00e1rio Havel \ud83d\udd8b JosefJ \ud83d\udd8b Christoph Burgdorf \ud83e\udd14 slipperybeluga \ud83e\udd14 David Liu \ud83d\udd8b shreyashariharan3 \ud83d\udd8b Adri\u00e1n Calvo \ud83d\udd8b daviroo \ud83d\udd8b Wim Notredame \ud83d\udcbb vasa \ud83d\udd8b Franziska Heintel \ud83d\udd8b Muhammad Umair Irshad \ud83d\udd8b Nazzareno Massari \ud83d\udd8b Mayemene Fomene Jean Vladimir \ud83d\udc1b \ud83d\udd8b Yahsin Huang \ud83d\udd8b \ud83c\udf0d James Zaki \ud83d\udd8b Greg Lang \ud83d\udd8b Matt Voska \ud83d\udc1b mustafa \ud83d\udd8b Paul Wackerow \ud83d\udcbb \ud83d\udc1b \ud83d\udcd6 \ud83c\udfa8 Attaphong Rattanaveerachanon \ud83d\udc1b \ud83d\udd8b LoinLiao \ud83d\udd8b DrMad92 \ud83d\udc1b Patricio Palladino \ud83d\udc40 \ud83e\udd14 David Murdoch \ud83d\udc40 MashhoodIjaz \ud83d\udc1b \ud83d\udd8b Dan Nolan \ud83d\udd8b \ud83d\udcd6 Marek Kirejczyk \ud83d\udd8b Jon Cursi \ud83d\udd8b James Farrell \ud83d\udc1b \ud83d\udd8b Xavi Arias Segu\u00ed \ud83d\udc1b \ud83d\udd8b ANKIT_PAL \ud83d\udcbb \u0130smail Kerim Cem \ud83d\udc1b Joanne \ud83d\udd8b michael60634 \ud83d\udc1b \ud83e\udd14 Andrei Maiboroda \ud83d\udd8b Anki \ud83d\udd8b Michelle Plur \ud83d\udc1b PAAlmasi \ud83d\udd8b Ben Edgington \ud83d\udc1b \ud83d\udd8b alexsantee \ud83d\udc1b \ud83d\udd8b peth-yursick \ud83d\udd8b Alwin Stockinger \ud83d\udc1b \ud83d\udd8b Roberto Henr\u00edquez Perozo \ud83d\udd8b strykerin \ud83d\udd8b jddxf \ud83d\udc1b \ud83d\udd8b LucasRoorda \ud83d\udd8b Mihir Luthra \ud83d\udd8b tentodev \ud83d\udd8b \ud83d\udc1b MiZiet \ud83d\udd8b Vaibhav Chopra \ud83d\udd8b Lakshman Sankar \ud83d\udc1b \ud83d\udd8b hewigovens \ud83d\udd8b \ud83d\udc1b DragonDev1906 \ud83d\udc1b \ud83d\udd8b Ryan Ghods \ud83d\udd8b Oliver \ud83d\udd8b Kristiyan \ud83d\udc1b \ud83d\udcbb Matthieu Riou \ud83d\udd8b pansay \ud83d\udd8b \ud83d\udc1b eirtscience \ud83d\udd8b Francis Lewis \ud83d\udc1b \ud83d\udd8b baub \ud83d\udd8b \ud83d\udc1b lamone \ud83d\udd8b Sean O'Connor \ud83d\udd8b Tara Rowell \ud83d\udd8b Aleksi Cohen \ud83d\udc1b \ud83d\udd8b Kartikaya Gupta (kats) \ud83d\udc1b \ud83d\udd8b siddhantkharode \ud83d\udd8b \ud83d\udc1b Renan Dincer \ud83d\udc1b \ud83d\udd8b Zhangyuan Nie \ud83d\udc1b \ud83d\udd8b Patrick Collins \ud83d\udd8b Sant Deleon \ud83d\udcbb Martin Huschenbett \ud83d\udd8b \ud83d\udc1b Kalle Moen \ud83d\udc1b \ud83d\udd8b Vitaly \ud83d\udcbb Nikolay Yushkevich \ud83d\udd8b darkwater4213 \ud83d\udc1b \ud83d\udd8b Akash Nimare \ud83d\udd8b Dave Mackey \ud83d\udd8b Emanuel Tesa\u0159 \ud83d\udd8b DeFiDude \ud83d\udc1b Austin Griffith \ud83d\udd8b Chase Manning \ud83d\udc1b \ud83d\udd8b Colin Steil \ud83d\udd8b MonarthS \ud83d\udcbb Adam Dry \ud83d\udc1b \ud83d\udd8b Nikolai Vavilov \ud83d\udc1b \ud83d\udd8b Katie \ud83d\udc1b \ud83d\udd8b comeToThinkOfEth \ud83d\udc1b catsnackattack \ud83d\udc1b Maurycy \ud83d\udd8b Igor Papandinas \ud83d\udc1b \ud83d\udcbb \ud83d\udd8b Tahir Alvi \ud83e\udd14 amirmehdi \ud83d\udc1b \ud83d\udd8b Dan Dadybaev \ud83d\udd8b Finley \ud83e\udd14 nobd \ud83d\udd8b Alexander Sadovskyi \ud83d\udd8b Ethan Sarif-Kattan \ud83d\udc1b \ud83d\udd8b C.J. Kozarski \ud83d\udd8b Yakko Majuri \ud83d\udcbb John Adler \ud83d\udd8b \ud83d\udc1b Just some guy \ud83d\udd8b \ud83d\udcd6 Vedvardhan \ud83d\udd8b \ud83d\udc1b Yussuf Elarif \ud83d\udc1b David Awad \ud83d\udd8b Alex Beregszaszi \ud83d\udd8b Adam Goth \ud83d\udc1b \ud83d\udd8b Anurag Pal \ud83d\udcbb \ud83d\udcd6 Vishal Pratap Singh \ud83d\udcbb qbzzt \ud83d\udd8b \ud83e\udd14 Ewa Kowalska \ud83d\udd8b Aheesh \ud83d\udd8b tophersjones \ud83d\udd8b Andrew Yang \ud83d\udd8b $hoot->Pairs \ud83d\udd8b NilsKaden \ud83d\udcbb Stuart Reynolds \ud83e\udd14 Gwenael Le Bodic \ud83d\udd8b Anurag Verma \ud83d\udc1b \ud83d\udcbb Nikolai Golub \ud83d\udd8b Elliot Lee \ud83d\udd8b \ud83d\udc1b Viktor Garske \ud83d\udc1b \ud83d\udd8b Kristjan Grm \ud83d\udd8b Mac L \ud83d\udd8b Bruce MacDonald \ud83d\udd8b Ronnie Sherfey \ud83d\udcbb Ali Rahman \ud83d\udd8b Erik Vandeputte \ud83d\udd8b \ud83d\udc1b TM Lee \ud83d\udc1b mic0des \ud83d\udcbb Hakeem Almidan \ud83d\udd8b \ud83d\udcbb Julien Rioux \ud83d\udd8b Justin Chow \ud83d\udd8b Gabi \ud83d\udd8b Rohit Gopal \ud83d\udc1b Jordan Overbye \ud83d\udc1b \ud83d\udcbb Peter LaFontaine \ud83d\udc1b \ud83d\udd8b Joshua Welsh \ud83d\udc1b Robert Dosa \ud83d\udd8b SatoshiMiracle \ud83d\udc1b James Boyle \ud83e\udd14 \ud83d\udd8b Kevin Ziechmann \ud83d\udc1b Evan \ud83d\udd8b ETHorHIL \ud83d\udd8b shashvatshah9 \ud83d\udd8b slightlyfloating \ud83d\udc1b Luis Miranda \ud83d\udc1b Alex Ismodes \ud83d\udd8b Joshua \ud83d\udc1b \ud83d\udcbb Ensar Yusuf Y\u0131lmaz \ud83d\udc1b Leo Guti\u00e9rrez Ram\u00edrez \ud83d\udc1b Abdul Malik \ud83d\udc1b Jay Welsh \ud83d\udc1b linkastic \ud83d\udd8b Chan Jing Hong \ud83d\udd8b Ozora Ogino \ud83d\udd8b \ud83c\udf0d Ikko Ashimine \ud83d\udc1b \ud83d\udd8b \ud83d\udcd6 \ud83c\udf0d Cameron Honis \ud83d\udc1b Chirag Shetty \ud83d\udc1b Michael Bianco \ud83d\udc1b Tom Robiquet \ud83d\udcbb Stanislav Bezkorovainyi \ud83d\udd8b Rootul Patel \ud83d\udc1b Zachary DeRose \ud83d\udd8b Arshan Khanifar \ud83d\udc1b David Schnurr \ud83d\udd8b Kevin Leffew \ud83d\udd8b Pierre Grimaud \ud83d\udc1b Jack Clancy \ud83d\udd8b Justin Spradlin \ud83d\udc1b \ud83d\udd8b Aditya Anand M C \ud83d\udd8b James Dixon \ud83d\udd8b Vasu Manhas \ud83d\udc1b jp_aulet \ud83d\udcbb manojmsrit \ud83e\udd14 David Kim \ud83d\udd8b Bhavish Yalamanchi \ud83d\udd8b awg0013-PR \ud83d\udd8b Devin \ud83d\udd8b Dave \ud83e\udd14 Rafael Matias \ud83d\udc1b \ud83d\udd8b Colman Glagovich \ud83d\udd8b endorphin \ud83d\udd8b Nebali \ud83d\udd8b Shubh Agrawal \ud83d\udd8b cth0604 \ud83d\udcbb zjpetersen \ud83d\udc1b frankie224 \ud83d\udc1b Alexandru Turcanu \ud83d\udd8b Brett \ud83d\udd8b Jo\u00e3o Monteiro \ud83d\udd8b \ud83d\udc1b Arun Lodhi \ud83d\udd8b Tim \ud83d\udd8b Vitaliy Hayda \ud83d\udc1b \ud83d\udd8b Ayushman Singh Chauhan \ud83d\udc1b \ud83d\udd8b Keqi Huang \ud83d\udc1b \ud83d\udd8b davidplutus \ud83e\udd14 Karthickmerk \ud83e\udd14 Sihong \ud83d\udcbb AmirAliM \ud83d\udd8b Rub3cula \ud83d\udd8b Pawe\u0142 Urbanek \ud83d\udd8b Aditya Dhir \ud83d\udc1b Ammar Husain \ud83d\udd8b \ud83d\udc1b miiiguel \ud83d\udd8b Uttam Singh \ud83d\udc1b Chase Wright \ud83d\udd8b Bic \ud83d\udd8b devELIOper \ud83d\udd8b \ud83d\udc1b Vadym Barda \ud83d\udd8b Leo Cu\u00e9llar \ud83d\udd8b \ud83d\udcbb \ud83d\udc1b pheeque \ud83d\udc1b \ud83d\udd8b Jeremy Musighi \ud83d\udd8b tbollinger \ud83d\udc1b Ryan Grunest \ud83d\udd8b Aniket Raj \ud83d\udd8b Kamil Zarzycki \ud83c\udf0d \ud83d\udd8b Filip Martinsson \ud83d\udd8b zeroservices \ud83d\udc1b LukaK \ud83d\udd8b \ud83e\udd14 Luke Ingalls \ud83d\udd8b cstradtman \ud83d\udc1b G Surendar Thina \ud83d\udd8b Scott Dodge \ud83d\udc1b Artur Cygan \ud83d\udc1b Rory \ud83d\udc1b Connor Mann \ud83d\udc1b Phanindra \ud83d\udd8b kwsorensen \ud83d\udd8b Theo Pack \ud83d\udc1b kirati-su \ud83e\udd14 oliver renwick \ud83e\udd14 \ud83d\udc1b Pankaj Patil \ud83d\udd8b esale \ud83d\udc1b RaynHarr \ud83d\udd8b \ud83d\udcd6 n4rsil \ud83d\udd8b John Bishop \ud83d\udd8b robriks \ud83d\udc1b \ud83d\udcc6 \ud83d\udcac \ud83d\udcd6 Nishant Chandla \ud83d\udcbb \ud83d\udc1b @paulapivat \ud83d\udd8b Graeme Blackwood \ud83d\udc1b il3ven \ud83d\udcbb Hayden Briese \ud83d\udc1b Trevor French \ud83d\udd8b Antonio Sanso \ud83d\udcd6 Siddharth S \ud83d\udcd6 \ud83d\udc1b jbgwu \ud83d\udcd6 ethosdev \ud83d\udd8b \ud83d\udcd6 Joseph Schiarizzi \ud83d\udd8b Rodney Olav C Melby \ud83d\udd8b Raman \ud83d\udd8b Roeland Werring \ud83d\udc1b Stan Kladko \ud83d\udcd6 Jared Flomen \ud83d\udcd6 \ud83d\udc1b Joseph Wallace \ud83d\udc1b Ahmed Prusevic \ud83d\udcbb Matt \ud83d\udd8b ytrezq \ud83d\udcd6 Ricky \ud83d\udc1b smudgil \ud83d\udd8b Don Cross \ud83d\udcd6 Jackson Taylor \ud83e\udd14 MrBrain295 \ud83d\udc1b \ud83d\udcd6 \ud83e\udd14 \ud83d\udd8b SafePalWallet \ud83d\udd8b Vishal Vaddadhi \ud83d\udd8b Matt Kula \ud83d\udc1b Hamza Shahzad \ud83d\udcbb \ud83d\udc1b Mukul Kolpe \ud83d\udcbb \ud83d\udc1b \ud83d\udcd6 Corwin Smith \ud83d\udcbb spiolat \ud83d\udcd6 hosyminh95 \ud83d\udcd6 Chiara Wilden \ud83e\udd14 \ud83d\udcd6 DanhPTHTech \ud83d\udcd6 James Hooper \ud83d\udc1b \ud83d\udcd6 Christopher Hegre \ud83d\udcd6 Najeeb Nabwani \ud83d\udcd6 Alexander Goncalves \ud83d\udcd6 Gabe Casalett \ud83d\udcd6 waynedyer12 \ud83d\udcd6 tap (pts.eth) \ud83d\udd8b James Morgan \ud83e\udd14 Sharon Wang \ud83d\udc1b \ud83d\udcd6 Enrique Jose  Avila Asapche \ud83e\udd14 Gianni Alessandroni \ud83d\udcd6 Raj Shekhar Bhardwaj \ud83d\udcd6 \ud83e\udd14 joakimengerstam \ud83d\udcd6 Nikita Drozd \ud83d\udc1b \ud83d\udcd6 \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f Scott \ud83c\udfa8 \ud83d\udc1b Stefan Sathianathen \ud83d\udcd6 Miroslav Lehotsky \ud83d\udcd6 Remco \ud83d\udcd6 Shailendra Shukla \ud83d\udcd6 Skylar Weaver \ud83d\udcd6 \ud83d\udd8b agorismlabs \ud83e\udd14 Tanishq Sharma \ud83e\udd14 Mark Strefford \ud83d\udc1b Andrzej W\u00f3dkiewicz \ud83d\udcd6 Hugo \ud83d\udd8b Joseph Harris \ud83d\udcd6 Ozgur \ud83d\udcd6 Alec Dilanchian \ud83d\udcd6 Horacio Bertorello \ud83d\udcd6 m4sterbunny \ud83d\udcd6 \u611a\u6307\u5bfc \ud83d\udcd6 Ray Jasson \ud83d\udcd6 Calvin Storoschuk \ud83d\udc1b \ud83d\udcbb Clashinm \ud83d\udcd6 james-prysm \ud83e\udd14 William Buck \ud83d\udcd6 metalocal \ud83d\udc1b \ud83d\udcd6 Himanshu Singh \ud83d\udc1b \ud83d\udcd6 \ud83e\udd14 Andrew B Coathup \ud83d\udcd6 \ud83d\udc1b Andrew Gallagher \ud83d\udd8b \ud83d\udcbb Phat Nguyen Luu \ud83d\udcd6 Andreas Sofos \ud83d\udcbb Felipe Selmo \ud83d\udcd6 Bingwei Qin \ud83d\udcd6 Mikko Ohtamaa \ud83e\udd14 \ud83d\udcd6 Kabilan \ud83e\udd14 Colin Steidtmann \ud83d\udd8b \ud83d\udc1b SNikhill \ud83d\udcbb SlashHash \ud83e\udd14 Harsh Mathur \ud83d\udd8b pranav desai \ud83d\udd8b Luk\u00e1\u0161 Kotol \ud83d\udcd6 Nick Carbone \ud83d\udcd6 Ashwin Nair \ud83d\udcbb Julian Ste \ud83d\udcbb \ud83d\udcd6 \ud83d\udd8b Pranay Reddy \ud83d\udcbb marc \ud83d\udcd6 Mariano Baragiola \ud83d\udcd6 under3415 \ud83e\udd14 Gaurav Kumar Shah \ud83e\udd14 Hubert Sikorski \ud83d\udcd6 Corey Rice \ud83d\udcd6 Ezenwankwo Gabriel \ud83d\udcd6 Thomas Lisankie \ud83d\udcd6 \ud83d\udc1b Tyler Ilunga \ud83d\udcd6 Kasia Kosturek \ud83d\udcd6 solarpunklabs \ud83e\udd14 aakhtar3 \ud83d\udcd6 Shreyas Londhe \ud83d\udd8b Tim Beccue \ud83d\udd8b Robert Joseph Wayne \ud83d\udcd6 \ud83d\udd8b pdesmondflynn \ud83d\udd8b Daniel Damilola Obiokeke \ud83d\udd8b mpj \ud83d\udd8b \ud83d\udcd6 Hung Doan \ud83d\udc1b Pawe\u0142 Wilczy\u0144ski \ud83c\udf0d joaoMpf \ud83c\udf0d Bhaskar Kashyap \ud83d\udcd6 \ud83d\udd8b bleesherman \ud83d\udd8b \ud83d\udcd6 Robert Miller \ud83d\udd8b Florian Sesser \ud83d\udcd6 xianxiongwang \ud83d\udcd6 Slava Shirokov \ud83d\udcd6 BenOfTheBlockchain \ud83e\udd14 0xngmi \ud83d\udcd6 Shivam Rajput \ud83d\udcd6 Raymond \ud83d\udcbb Justin Johnson \ud83d\udcd6 SA KSH AM \ud83d\udd8b Samrat \ud83d\udd8b Justin Shaw \ud83d\udd8b \ud83d\udcbb \ud83d\udcd6 \ud83e\udd14 meoww-bot \ud83d\udcd6 Philip Vu \ud83d\udcd6 Conner Jensen \ud83d\udcd6 Jhaymes \ud83e\udd14 daniel sieradski \ud83d\udcd6 bgillcode \ud83d\udcd6 \ud83d\udcbb Cameron Fink \ud83d\udcd6 \ud83e\udd14 Venom \ud83d\udcd6 JulienM \ud83d\udcbb Jem Mawson \ud83d\udcd6 Mislav \ud83d\udcbb \ud83d\udcd6 Justin Hunter \ud83d\udcd6 Enton Biba \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f Oriol Serra \ud83d\udc1b \ud83e\udd14 Nicolas LARCHE \ud83d\udc1b A. Tyler Benson \ud83d\udcd6 Derek\u5468\u671d\u6656 \ud83d\udcd6 \ud83c\udf0d Damian Schenkelman \ud83d\udcd6 Hendrik Eeckhaut \ud83d\udcd6 \ud83d\udcbb Susannah Evans \ud83d\udcd6 Minimalist Optimalist \ud83d\udc1b vluna \ud83d\udcbb \ud83d\udc1b \ud83d\udd8b Arghya Biswas \ud83d\udcbb abhi-go \ud83d\udcd6 Franco Victorio \ud83d\udcd6 \ud83d\udc1b Kevin Jones \ud83d\udcbb \ud83d\udc1b \ud83d\udd8b Shubhankar Kanchan Gupta \ud83d\udc1b \ud83d\udcbb Vishvanathan K \ud83d\udcd6 Alexander Gryaznov \ud83e\udd14 Pablo Pettinari \ud83d\udcd6 \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f Celetra \ud83d\udc1b \ud83d\udcd6 sharadseth \ud83d\udcd6 Mariah \ud83d\udd8b Amadou Crookes \ud83d\udd8b \ud83d\udcd6 Nathan Woodruff \ud83e\udd14 Andrey Azimov \ud83d\udcd6 Anita Diamond \ud83d\udcd6 ismaventuras \ud83d\udcd6 \ud83c\udf0d Jhonny \ud83d\udcd6 Matthieu SCARSET \ud83d\udcd6 zhanxin \ud83c\udf0d \ud83d\udcd6 Geoff Hull \ud83d\udcd6 Austin Burke \ud83d\udcd6 Richard Rodrigues \ud83d\udcd6 \ud83c\udf0d Samnang Chhun \ud83d\udcd6 Tanvir Ahmed \ud83d\udcd6 Joris Zierold \ud83d\udcd6 \ud83e\udd14 selfwithin \ud83e\udd14 \ud83d\udcd6 Jonathan Joshua \ud83d\udcd6 Patrick Aljord \ud83d\udcd6 decifer \ud83e\udd14 aghArdeshir \ud83d\udcbb Michael Connell \ud83d\udd8b \ud83d\udcbb Ahmed Mustafa Malik \ud83d\udcbb Gamaliel 'Yel' Padillo \ud83d\udcd6 Kumar Kalyan \ud83d\udc1b \ud83d\udcd6 \ud83d\udcbb \ufe0f\ufe0f\ufe0f\ufe0f\u267f\ufe0f 0xdie \ud83d\udcd6 Taimoor Ali \ud83d\udcd6 \ud83d\udc1b Andrej \ud83d\udcd6 \ud83d\udd8b Pascal Marco Caversaccio \ud83d\udcd6 \ud83d\udd8b kennethcassel \ud83d\udcd6 BrysonXiao \ud83d\udd8b Discord #8528 \ud83d\udd8b Ned Rockson \ud83d\udcd6 Tommaso Tosi \ud83d\udcd6 Kamil \ud83d\udc1b Mert \ud83d\udcd6 \ud83d\udc1b Naman Bhalla \ud83d\udcd6 Kirk \ud83d\udc1b juliangeissler \ud83d\udcd6 \ud83d\udc1b \ud83d\udcbb Garric G. Nahapetian \ud83d\udd8b Dmitriy Fishman \ud83d\udcd6 neozapatista \ud83d\udcd6 Factral \ud83c\udf0d \ud83d\udcd6 \ud83d\udc1b \ud83d\udcbb elshigori \ud83d\udcd6 EarthMan \ud83c\udf0d \ud83d\udcd6 mohan-chinnappan-n \ud83e\udd14 Nicola Bonsi \ud83e\udd14 Yusuf Elnady \ud83d\udd8b Aryan Keluskar \ud83d\udcbb Ling \ud83d\udd8b S\u00f8ren Rood \ud83d\udcbb \ud83d\udcd6 \ud83e\udd14 Tanmay Nagepatil \ud83e\udd14 Brandon Harden \ud83d\udd8b Snigdha Singh \ud83d\udcd6 SW \ud83d\udcd6 Aaron Chen \ud83e\udd14 Qazal Samani \ud83d\udcd6 yash \ud83e\udd14 Isaac Beale \ud83d\udcd6 \ud83d\udc1b Bal Krishna Jha \ud83d\udcd6 mradziwon \ud83d\udcbb \ud83d\udc1b mmilenkovic \ud83d\udcd6 \ud83e\udd14 Fernando Guevara \ud83d\udcd6 Jose Manuel Garcia Rivas \ud83e\udd14 PolySages \ud83d\udc1b \ud83d\udcd6 Zainab Hasan \ud83d\udcd6 \ud83e\udd14 Marcos Dedeu \ud83d\udcd6 Sunit Roy \ud83d\udc1b Gabriel Garcia \ud83d\udcd6 Tiago Yonamine \ud83d\udcd6 Erik Hunter \ud83d\udcd6 lingzhong \ud83d\udcd6 \ud83d\udc1b Yash Kamal Chaturvedi \ud83d\udcd6 EtherWorld \ud83d\udcd6 Stefan Ignjatovi\u0107 \ud83d\udcd6 Iheb Haboubi \ud83d\udc1b Hursit Tarcan \ud83d\udcbb pabloped \ud83d\udcd6 \ud83c\udf0d ilkererkek \ud83d\udcd6 Filippo Tarpini \ud83d\udcd6 saif-11bit \ud83d\udcd6 Sasha Shpota \ud83d\udcd6 Erik Bj\u00e4reholt \ud83d\udcd6 \ud83d\udcbb tomasbanik \ud83d\udcd6 Aditya Agarwal \ud83d\udcd6 Gerard Sans \ud83d\udd8b Cheah Chu Yeow \ud83d\udd8b Yan Luiz \ud83d\udd8b Alexandre Chabrolin \ud83d\udd8b Sergey Danilovich \ud83d\udd8b \ud83d\udcd6 Marcelo Rodriguez \ud83d\udd8b \ud83d\udcbb Anna \ud83d\udd8b Justin Traglia \ud83d\udd8b bitmateus \ud83d\udd8b Roberto Carboni \ud83d\udd8b K\u039eVIN K\u039elch\u039e\u27e0 \ud83d\udd8b Sa\u00efd Ibrihen \ud83d\udd8b Rob Dawson \ud83d\udd8b Ahmed Ashour \ud83d\udcd6 Nick Johnson \ud83d\udcd6 \u5434\u6cfd\u5eb7 \ud83d\udcd6 \ud83c\udf0d Nick Gaski \ud83d\udcd6 Rahul \ud83e\udd14 \ud83d\udcd6 \ud83d\udd8b Francisco J. Moreno \ud83c\udf0d \ud83d\udcd6 Zach \ud83d\udd8b bestpilotingalaxy \ud83d\udcd6 Afr Schoe \ud83d\udcbb \ud83d\udcd6 jamongeon1 \ud83d\udcd6 Jay \ud83d\udcbb Arnaud Spanneut \ud83c\udf0d yuliyu123 \ud83c\udf0d Jack \ud83c\udf0d Jason Manoloudis \ud83d\udcd6 Medzhidov-Omardibir \ud83d\udcd6 ApoGrs \ud83e\udd14 Mohammed Sadiq \ud83d\udcd6 Sahil sen \ud83d\udcd6 Collin K Cusce \ud83d\udcd6 \ud83e\udd14 hma23 \ud83e\udd14 \ud83d\udcd6 Karan Kaira \ud83d\udcd6 \ud83d\udcbb ReDrawn \ud83d\udcd6 Oskar Mendel \ud83d\udcbb thewild-being \ud83e\udd14 Mihrac Cerrahoglu \ud83e\udd14 smartcontracts \ud83d\udcd6 \ud83d\udc1b Samay Lakhani \ud83d\udcd6 vdusart \ud83d\udcd6 \ud83d\udcbb \ud83c\udf0d wd021 \ud83d\udcd6 \ud83d\udcbb Max Roslow \ud83d\udcd6 \ud83c\udf0d tnkrxyz \ud83d\udcd6 Nuno Loureiro \ud83d\udcbb \ud83c\udfa8 polarpunklabs \ud83d\udcd6 Neographer \ud83d\udcd6 Voll \ud83d\udcd6 SurpriseMF3000 \ud83d\udcd6 \ud83d\udcbb htimsk \ud83d\udccb George Zhang \ud83d\udcd6 Nitin Rajesh \ud83d\udcd6 Rakesh Hotker \ud83d\udcd6 S\u00e9bastien Dan \ud83d\udcd6 Sakshi \ud83d\udcd6 Anshi \ud83d\udcd6 mikoto-studio \ud83d\udd8b Arhat \ud83d\udd8b \ud83d\udcd6 php4fan \ud83d\udc1b Kaiser Pister \ud83d\udcd6 \ud83d\udcbb Marc-Antoine Thevenet \ud83d\udcd6 Alan Toa \ud83d\udd27 Christopher Pearce \ud83d\udcd6 Yuta Kurotaki \ud83d\udcd6 Claudio2000 \ud83d\udcd6 \ud83d\udcbb Tomas Pasiecznik \ud83d\udcbb Xiangxi Guo (Ryan) \ud83d\udc1b Andile Mchunu \ud83d\udcd6 Noah \ud83d\udcd6 Adrian Li \ud83d\udcd6 Konstantinos Penlidis \ud83d\udcd6 Hunter Sandlin \ud83d\udcd6 Chris Boesch \ud83e\udd14 Nhan Vo \ud83d\udcd6 \ud83c\udf0d devtooligan \ud83d\udcd6 \ud83d\udcbb \ud83e\udd14 Thomas \ud83d\udcd6 Patrice Lamarque \ud83d\udcd6 \ud83e\udd14 \ud83d\udc1b sell50 \ud83d\udcd6 Manuel Peralta \ud83d\udcd6 Riely \ud83d\udcd6 \ud83c\udf0d Jasper \ud83d\udd8b Ryan Higdn \ud83d\udc1b \ud83d\udcd6 Eni-G \ud83d\udcd6 B01AND \ud83d\udcd6 Ashwin Ramaswami \ud83d\udcd6 Albert Lie Adrian \ud83d\udcd6 Ishaan Parmar \ud83d\udcbb \ud83c\udfa8 \ud83e\udd14 Tarun Batra \ud83d\udcd6 \ud83d\udc1b Max \ud83d\udcd6 \ud83d\udc1b Luozhu \ud83d\udcd6 \ud83e\udd14 Yash Sharma \ud83d\udcd6 cryptochrome \ud83e\udd14 \ud83d\udc1b Argan Wang \ud83d\udcd6 \ud83c\udf0d Tim Mustafin \ud83e\udd14 superphiz \ud83d\udcd6 \ud83e\udd14 seanlakers \ud83e\udd14 Jason Yan \ud83d\udcd6 \ud83c\udf0d mradkov \ud83d\udcd6 Bienvenido Rodriguez \ud83d\udcd6 \ud83e\udd14 Sora Nature \ud83d\udcd6 Joseph Schiarizzi \ud83d\udcd6 Gustavo Silva \ud83d\udc1b Samarth Saxena \ud83d\udcd6 Baihao \ud83d\udcd6 \ud83d\udc1b \ud83d\udcbb Steve Goodman \ud83d\udcd6 booklearner \ud83d\udcd6 moretimeL \ud83d\udd8b SuperDelphi \ud83d\udd8b \ud83c\udf0d \ud83d\udc1b \ud83d\udcd6 chadlohrli \ud83d\udd8b Julius Degesys \ud83d\udcd6 Nicol\u00e1s Quiroz \ud83d\udcbb \ud83d\udc1b wolz-CODElife \ud83d\udcd6 Mina Essam \ud83e\udd14 GNONG \ud83d\udcd6 Sina Pilehchiha \ud83d\udcd6 thefrenchbrazilianguy \ud83d\udcd6 Anish Gupta \ud83d\udcd6 Matthew \ud83d\udcd6 Justyna Broniszewska \ud83d\udcd6 Elyanil Liranzo-Castro \ud83d\udcd6 Lichu Acu\u00f1a \ud83d\udcd6 Takamasa Arakawa \ud83d\udcbb \ud83d\udc1b skaunov \ud83d\udcd6 Paul Cowgill \ud83d\udcd6 zjiekai \ud83d\udcd6 wii u \ud83e\udd14 MonsieurDMA \ud83d\udcd6 fennar01 \ud83e\udd14 \ud83d\udcd6 William \ud83d\udcbb motemotech \ud83d\udcbb mousticke.eth \ud83d\udcbb brightiron \ud83d\udcbb oleksandrkovalskiy \ud83d\udcd6 yoshikouki \ud83d\udcd6 \ud83e\udd14 Graz Network \ud83d\udcd6 \ud83c\udf0d Cryptoversidad \ud83d\udcd6 Disconnect3d \ud83d\udcd6 \ud83d\udc1b Seth Ariel Green \ud83d\udcd6 \ud83d\udd8b Luisa Calixto \ud83d\udcd6 \ud83d\udd8b theanneli \ud83d\udcd6 Deric | Alchemy \ud83d\udcd6 Ahmetbasli \ud83d\udcd6 Jordi Pascual \ud83c\udf0d \ud83d\udc1b \ud83d\udcd6 Amith KK \ud83d\udcd6 \ud83d\udc1b Arpit Ingle \ud83e\udd14 Gourav Singh Rawat \ud83d\udcd6 \ud83e\udd14 mempirate \ud83d\udcd6 \ud83d\udc1b Barukimang \ud83d\udcd6 Kaan Uzdo\u011fan \ud83d\udcd6 Colin Kennedy \ud83d\udcd6 XOF \ud83d\udcd6 \ud83c\udf0d \ud83d\udc1b Manu kashyap \ud83d\udcd6 Zhou Yang \ud83d\udcd6 tree \ud83d\udcd6 Stephen Fluin \ud83d\udcd6 hakuta \ud83d\udcd6 MiloBowman \ud83d\udcd6 tadeo \ud83d\udcd6 Jorge Santana \ud83d\udd8b rolodexter \ud83d\udcd6 RanchHowards \ud83d\udcd6 \ud83d\udc1b Deyan Shotev \ud83d\udcbb Pranesh A S \ud83d\udcd6 \ud83d\udc1b shir22 \ud83d\udcd6 \ud83d\udc1b Nikita Verkhovin \ud83d\udc1b Pushkar Verma \ud83d\udcd6 \ud83e\udd14 Vincent Weisser \ud83d\udcd6 Kosuke Ogawa \ud83d\udcd6 \ud83d\udc1b Fatih Eren Erol \ud83d\udcd6 Oli Lalonde \ud83d\udcd6 gingerheart86 \ud83d\udcd6 Naveen Kumar \ud83d\udcd6 Cam Sweeney \ud83d\udcd6 moyed \ud83d\udcd6 shelleyolivia \ud83d\udcd6 \ud83e\udd14 Sandy \ud83d\udcd6 NachoRoizman \ud83d\udcd6 Iv\u00e1n Miragaya \ud83d\udcbb Jakub Sm\u00e9kal \ud83d\udcd6 Tony Chen \ud83d\udcd6 metalc \ud83d\udcd6 Tuongg2312 \ud83d\udcd6 \u039erik Saunier \ud83d\udcd6 Artem Vorotnikov \ud83d\udd8b \ud83d\udcc6 \ud83d\udcac Liam Arzola \ud83d\udc1b shao \ud83d\udcd6 \ud83c\udf0d Hiroyuki Naito \ud83d\udcd6 AlehN \ud83d\udcd6 Varun Shenoy \ud83d\udc1b Alessandro Baffa \ud83d\udcd6 \ud83d\udc1b John Grant \ud83d\udcd6 gorondan \ud83d\udcd6 Pruthviraj Jadhav \ud83d\udcd6 Oscar Barajas Tavares \ud83d\udcd6 Samuel Akinosho \ud83d\udcd6 \ud83d\udcbb Odair Augusto Trujillo Orozco \ud83d\udcd6 \ud83e\udd14 Unforkable \ud83d\udcd6 Rodrigo vasquez \ud83d\udcd6 \ud83e\udd14 Michael McCallam \ud83d\udcd6 Polina G. \ud83d\udcd6 Neeraj Gahlot \ud83d\udcd6 \ud83d\udc1b Kostas \ud83d\udcd6 rogueassasin1729 \ud83d\udcd6 Pandapip1 \ud83d\udcd6 \ud83e\udd14 Aldi Zhupani \ud83d\udc1b \ud83d\udcbb linhuatan \ud83d\udcd6 Hugh \ud83d\udcd6 Kim Kwangtae \ud83d\udd8b \ud83e\udd14 tobi4021 \ud83d\udcd6 Haochen Song \ud83d\udcd6 \ud83c\udf0d N Fx \ud83d\udcd6 \ud83c\udf0d samsara \ud83d\udcd6 \ud83d\udc1b \ud83c\udf0d greefea \ud83d\udcd6 parotax \ud83d\udcd6 Loc Nguyen \ud83d\udd8b north-vanhooser \ud83d\udcd6 othaime-en \ud83d\udcbb Cronos \ud83d\udcd6 \ud83c\udf0d Micah Zoltu \ud83d\udcd6 Ivan Aracki \ud83e\udd14 \u5c60\u866b\u5c11\u5e74 \ud83d\udcd6 \ud83c\udf0d Ramandeep \ud83e\udd14 Vlad Kokhan \ud83d\udcd6 \ud83c\udf0d Phill \ud83d\udd8b \ud83d\udcd6 \ud83d\udcbb cam \ud83d\udc1b \ud83d\udcd6 calumtomeny \ud83d\udcd6 robertu \ud83d\udcd6 \ud83c\udf0d Lorena De Leon Salazar \ud83c\udf0d James Adams \ud83d\udcd6 Eric Chen \ud83d\udcd6 Van De Biao \ud83d\udcd6 Sourav Suman \ud83e\udd14 Ivan Pavi\u010di\u0107 \ud83d\udcd6 \ud83d\udc1b tommy \ud83d\udcd6 \ud83c\udf0d Martin Yung \ud83d\udcbb \ud83c\udf0d Pankaj Jagtap \ud83d\udcd6 nulun \ud83d\udcbb Denllay \ud83d\udcd6 \ud83c\udf0d yalexis.eth \ud83d\udcd6 Ahmad Bitar \ud83d\udcd6 Carl Lippert \ud83d\udcd6 Tymek Majewski \ud83d\udcd6 Cryptolibertarian.id \ud83d\udcd6 browny \ud83e\udd14 \ud83d\udcbb \ud83d\udc1b Marius Kj\u00e6rstad \ud83e\udd14 Scott Fitsimones \ud83d\udcd6 Paul Lechocki \ud83d\udcd6 justalike \ud83d\udcd6 grayliquid \ud83d\udcd6 MohammadHosein Masoon \ud83d\udcd6 Patoshi \ud83d\udcd6 June Clarke \ud83d\udcd6 \u83f2\u5229 \ud83d\udcd6 DamitusThyYeetus123 \ud83d\udcd6 matusame \ud83c\udf0d Lohan \ud83d\udcbb Marcella \ud83d\udcbb Leon Todd \ud83d\udcd6 Ladislas Fontaine \ud83d\udcd6 Yash Yadav \ud83d\udcd6 barro \ud83d\udcd6 Master7130 \ud83d\udcbb Lude15 \ud83e\udd14 Luke Fan \ud83d\udcd6 TABASCO \ud83d\udcd6 d1onys1us \ud83d\udcd6 Thibaut \ud83d\udcd6 Miguel \ud83d\udcbb Ray Zhu \ud83d\udcd6 Lucca Benedetti \ud83d\udcd6 Mac Morgan \ud83d\udcd6 \ud83d\udc1b Aksa12 \ud83d\udcbb Aniruddha Sil \ud83d\udcd6 \ud83d\udcbb \u2661 \ud83d\udcd6 Luis Sebastian Urrutia Fuentes \ud83d\udcbb jakubalsoori \ud83d\udcd6 Wenceslas Sanchez \ud83d\udcd6 Marcus Escobedo \ud83d\udcd6 fr33dr4g0n \ud83e\udd14 Ritesh Singh \ud83d\udcd6 Simon Letort \ud83d\udcd6 AidanPine \ud83d\udcbb christy-pdx \ud83d\udd8b Medard Mandane \ud83d\udcd6 Dave Lucia \ud83d\udcd6 Lo\u00efc Albertin \ud83d\udcd6 Mille Codex \ud83d\udcd6 Gift Opia \ud83d\udcbb Dhiraj Gagrai \ud83d\udcbb KurtMerbeth \ud83d\udd8b Sai Leela Rahul Pujari \ud83d\udd8b SkyWarrior123 \ud83d\udd8b Yashovardhan Agrawal \ud83d\udd23 cheeky-gorilla \ud83d\udc1b Noah Page \ud83d\udcd6 steph \ud83d\udcbb Daniel Park \ud83d\udcd6 knititwearit \ud83e\udd14 Ryan Smith \ud83d\udcd6 Vaishnavi Joshi \ud83d\udcd6 Jamie Barrett \ud83d\udcbb Renato \ud83d\udd8b \ud83c\udf0d Francisco \ud83d\udcd6 Franklin Ohaegbulam \ud83d\udcbb Soos3D \ud83d\udcd6 Minho Ryang \ud83d\udcbb Sebastian Supreme \ud83e\udd14 \ud83c\udf0d \ud83d\udcbb Awosise Oluwaseun \ud83d\udcd6 Muhammad Ahmad \ud83d\udcbb Oliver \ud83d\udcd6 Jiwon Park \ud83d\udcd6 Zandt Lavish \ud83d\udcd6 sushthecoda \ud83d\udcd6 Lucas Martin Calderon \ud83d\udcd6 crypto8893 \ud83d\udd8b Victor Patru \ud83d\udcbb wishee \ud83d\udcd6 Harshil Gupta \ud83d\udcd6 Vanshika Srivastava \ud83e\udd14 Shariq Anwar \ud83d\udcbb Giorgio Nocera \ud83d\udcd6 Dmitry Alexeev \ud83d\udd8b Alex \ud83d\udcd6 benlazzero \ud83d\udcbb Ankit Singh \ud83d\udcbb mhairimcalpine \ud83d\udd8b William Doom \ud83d\udcd6 AsheBarrett \ud83c\udf0d Hitishaa \ud83d\udcd6 Shiv Rustagi \ud83d\udcd6 Douglas Makey Mendez Molero \ud83d\udcbb Amit Gaikwad \ud83d\udcbb Eridian \ud83d\udcd6 Bobby Galli \ud83d\udcd6 flanagansteve \ud83d\udcd6 Owen Hwang \ud83d\udcd6 Andreas Florath \ud83d\udcd6 Daniel Coffman \ud83d\udcd6 AMIT KUMAR MISHRA \ud83d\udcd6 Saksham Thapa \ud83d\udc1b Vijayendra Gaur \ud83d\udcd6 Andr\u00e1s Novosz\u00e1th \ud83d\udcd6 Sahil Aujla \ud83d\udcd6 Olaf Tomalka \ud83d\udcd6 Abhiram G P \ud83d\udcbb Amine E. \ud83d\udcd6 Roshan R Chandar \ud83d\udcd6 mossow \ud83d\udcd6 yujingwei \ud83d\udcd6 Daniel Olshansky \ud83d\udcd6 \ud83e\udd14 aguzmant103 \ud83d\udcd6 Soheil \ud83d\udcbb metadiver.eth \ud83d\udcbb Jacob \ud83e\udd14 \ud83d\udcd6 Sam Padilla \ud83d\udcd6 Chen Quan \ud83d\udcd6 \ud83c\udf0d Marcelo T. dos Santos \ud83d\udcbb NoahSchick \ud83e\udd14 Joey \ud83d\udd8b AnnaNodes \ud83d\udd8b Yash Jagtap \ud83d\udd8b Gast\u00f3n Zanitti \ud83d\udd8b Dan \ud83d\udd8b Elizabeth Bassey \ud83d\udd8b mihaic01 \ud83d\udd8b qiuhaohao \ud83d\udd8b damilola debel \ud83d\udd8b Sarat Angajala \ud83d\udcd6 questions \ud83d\udcc6 \ud83d\udcac machin3boy \ud83d\udd8b nethan \ud83d\udd8b Jithil P Ponnan \ud83d\udcd6 \ud83d\udcbb chocolatesuit \ud83d\udd8b Apinan Yogaratnam \ud83d\udd8b trevorsc19 \ud83d\udd8b ImThour \ud83d\udcbb Nenad Vitorovi\u0107 \ud83d\udd8b danierod \ud83d\udcbb siddtheone \ud83d\udd8b Shawki Sukkar \ud83d\udd8b Harpal Jadeja \ud83d\udcbb Zion \ud83d\udd8b Andriy Zhuk \ud83d\udd8b gooser.eth \ud83d\udd8b feibowei \ud83d\udd8b Mesquita Oliveira \ud83d\udcd6 Juan Jos\u00e9 Giraldo \ud83d\udd8b Ash@metaschool \ud83d\udd8b Tom Rutten \ud83d\udd8b Chawye Hsu \ud83d\udcd6 Mateus Pimenta \ud83d\udd8b ezal \ud83d\udc1b Jarrod Watts \ud83d\udd8b Miao \ud83d\udcbb Jiatu Liu \ud83d\udd8b DeUETH \ud83d\udd8b erin-at-work \ud83d\udd8b 0xAA \ud83d\udd8b changwu \ud83d\udd8b yj \ud83d\udd8b megatheikal \ud83d\udc1b Stephen Guo \ud83c\udf0d F. Eugene Aumson \ud83d\udc1b \ud83d\udd8b Roshan \ud83d\udd8b \ud83d\udcbb Maxime Dessez \ud83d\udc1b \ud83c\udf0d Tyler-233 \ud83c\udf0d \ud83d\udd8b neodaoist \ud83d\udd8b Atharva Deosthale \ud83d\udd8b Kartik Chopra \ud83d\udd8b Bibash Tandon \ud83d\udd8b Vaibhav Tevatia \ud83d\udcbb cnn-rnn \ud83e\udd14 Sahitya Roy \ud83e\udd14 KeeCoin \ud83e\udd14 Seungwook Chi \ud83d\udd8b 0xx92 \ud83d\udd8b altinocoelho \ud83d\udd8b viac92 \ud83d\udd8b DongXi Huang \ud83d\udd8b Suraj Anand \ud83d\udd8b Mwitah \ud83d\udd8b Tuckson \ud83d\udd8b Akamig \ud83d\udd8b Peace Ojemeh \ud83d\udd8b woseK \ud83d\udd8b \ud83d\udc1b Gunal \ud83d\udd8b chinaman123 \ud83e\udd14 Alex \ud83d\udcd6 \ud83d\udc1b Matthew \ud83d\udc1b \ud83d\udcd6 gokhan \ud83d\udc1b Adri \ud83d\udd8b Sherry.Du \ud83d\udd8b Francesco Ciulla \ud83d\udd8b blazingrome \ud83d\udd8b Etan Kissling \ud83d\udd8b kritik sah \ud83d\udc1b Fuliggine \ud83d\udd8b Omsify \ud83d\udc1b 0xMimir \ud83d\udd8b Bilal \ud83d\udd8b Ilan \ud83d\udd8b umede \ud83d\udd8b Tamino \ud83d\udd8b Katherine Champagne \ud83d\udd8b Marcos Gonz\u00e1lez \ud83d\udcd6 Natalino Picone \ud83d\udd8b Hammad Saaedi \ud83d\udd8b Shaunak Nagrecha \ud83d\udc1b Kevin Schwindt \ud83d\udd8b Robert \ud83d\udd8b obsidian \ud83d\udd8b Fekry Aiad \ud83e\udd14 Wilson Wu \ud83d\udcd6 VAS \ud83d\udcd6 Costanza \ud83d\udcd6 joao \ud83d\udcd6 Eugene \ud83d\udd8b D\u00e1niel G\u00f6rbe \ud83d\udcd6 s-crypt \ud83d\udd8b iwantanode \ud83d\udd8b shak58 \ud83d\udd8b Muhammad Altabba \ud83d\udd8b Darigov Research \ud83d\udd8b SHUBHAM SHARMA \ud83e\udd14 paulallensuxs \ud83d\udd8b Pseudomata \ud83d\udcbb CodeDragonVN \ud83d\udd8b SamiAlHassan \ud83d\udd8b NaijaCoderGirl \ud83d\udd8b Konstantin Zolotarev \ud83d\udd8b vuittont60 \ud83d\udd8b Golden Ite \ud83d\udd8b Erlangshen219 \ud83d\udd8b AyDeveloper \ud83d\udd8b jeremyfritzen \ud83d\udd8b Zheng Fu \ud83d\udcbb xiaolou86 \ud83d\udd8b aztecEagle22 \ud83d\udd8b QIAN \ud83d\udd8b SanShi2023 \ud83d\udd8b Krishang Shah \ud83d\udcbb Vu Vo \ud83d\udd8b Tim - o2Stake \ud83d\udd8b Benedikt Wagner \ud83d\udd8b Tarun Mohandas Daryanani \ud83d\udd8b Shubh \ud83d\udd8b This project follows the all-contributors specification. Contributions of any kind welcome! Join our Discord server We have a space to discuss all things ethereum.org \u2013 share your ideas or just say hi over on Discord ."}, {"name": "ethereum-ppa", "desc": "Ethereum PPA configurations", "readme": null}, {"name": "ethereum-python-project-template", "desc": "Template for new Python Ethereum repositories", "readme": "Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npython -m pip install <PYPI_NAME> Developer Setup If you would like to hack on , please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/<REPO_NAME>.git\ncd <REPO_NAME>\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "ethereum-react-components", "desc": "Ethereum Components Library in React", "readme": "Ethereum React Components A library of frequently used Ethereum components. This project leverages material-ui and is intended for use within apps that also use material-ui. All available components can be found in the project storybook . The bleeding edge ( dev branch) gets published here . WARNING: this lib is not production ready. All component APIs are in exploratory phases and strict semantic versioning is not yet enforced. Installation yarn add ethereum-react-components Usage ```\nimport { Identicon } from 'ethereum-react-components'; ``` See the project storybook for detailed documentation. Note that this storybook uses the Source Sans Pro font. You'll need to import and apply this font (or another font of your choosing) in your own project. Contributing There are many ways to get involved with this project. Get started here . Development Clone & Storybook git clone https://github.com/ethereum/ethereum-react-components.git\ncd ethereum-react-components\nyarn\nyarn storybook Workflow Mind the component style checklist . Use eslint in your editor or via command line: yarn lint:watch . Make conventional commits . Local Testing While in development, yarn link allows for testing this library on another local project without publishing to npm. cd ethereum-react-components\nyarn link\ncd my/project/with/ethereum/components\nyarn link ethereum-react-components"}, {"name": "ethereum.org", "desc": "[ARCHIVED] Ethereum website from 2015", "readme": "Ethereum.org site The main Ethereum website built with Meteor . Find out more: https://ethereum.org http://wiki.ethdev.com Admin In order for admin to work you'll need to set up a default admin user. To do that add a setting file e.g config/settings.json (must be gitignored) with the contents similar to: json\n{\n  \"DEFAULT_ADMIN_ACCOUNT\": \"<email>:<password>\"\n} Then start Meteor with meteor --settings config/settings.json"}, {"name": "ethereumj", "desc": "DEPRECATED! Java implementation of the Ethereum yellowpaper. For JSON-RPC and other client features check Ethereum Harmony", "readme": "Welcome to ethereumj :no_entry: Deprecated :no_entry: This project is not supported anymore. If you have any question or would like to contribute find us on Gitter . About EthereumJ is a pure-Java implementation of the Ethereum protocol. For high-level information about Ethereum and its goals, visit ethereum.org . The ethereum white paper provides a complete conceptual overview, and the yellow paper provides a formal definition of the protocol. We keep EthereumJ as thin as possible. For JSON-RPC support and other client features check Ethereum Harmony . Running EthereumJ Adding as a dependency to your Maven project: <dependency>\n     <groupId>org.ethereum</groupId>\n     <artifactId>ethereumj-core</artifactId>\n     <version>1.12.0-RELEASE</version>\n   </dependency> or your Gradle project: repositories {\n       mavenCentral()\n       jcenter()\n       maven { url \"https://dl.bintray.com/ethereum/maven/\" }\n   }\n   implementation \"org.ethereum:ethereumj-core:1.9.+\" As a starting point for your own project take a look at https://github.com/ether-camp/ethereumj.starter Building an executable JAR git clone https://github.com/ethereum/ethereumj\ncd ethereumj\ncp ethereumj-core/src/main/resources/ethereumj.conf ethereumj-core/src/main/resources/user.conf\nvim ethereumj-core/src/main/resources/user.conf # adjust user.conf to your needs\n./gradlew clean fatJar\njava -jar ethereumj-core/build/libs/ethereumj-core-*-all.jar Running from command line: ``` git clone https://github.com/ethereum/ethereumj\ncd ethereumj\n./gradlew run [-PmainClass= ]\n``` Optional samples to try: ./gradlew run -PmainClass=org.ethereum.samples.BasicSample\n./gradlew run -PmainClass=org.ethereum.samples.FollowAccount\n./gradlew run -PmainClass=org.ethereum.samples.PendingStateSample\n./gradlew run -PmainClass=org.ethereum.samples.PriceFeedSample\n./gradlew run -PmainClass=org.ethereum.samples.PrivateMinerSample\n./gradlew run -PmainClass=org.ethereum.samples.TestNetSample\n./gradlew run -PmainClass=org.ethereum.samples.TransactionBomb For snapshot builds: Please, note, snapshots are not stable and are currently in development! If you still want to try it: Add https://oss.jfrog.org/libs-snapshot/ as a repository to your build script Add a dependency on org.ethereum:ethereumj-core:${VERSION} , where ${VERSION} is of the form 1.13.0-SNAPSHOT . Example: <repository>\n    <id>jfrog-snapshots</id>\n    <name>oss.jfrog.org</name>\n    <url>https://oss.jfrog.org/libs-snapshot/</url>\n    <snapshots><enabled>true</enabled></snapshots>\n</repository>\n<!-- ... -->\n<dependency>\n   <groupId>org.ethereum</groupId>\n   <artifactId>ethereumj-core</artifactId>\n   <version>1.13.0-SNAPSHOT</version>\n</dependency> Importing project to IntelliJ IDEA: ``` git clone https://github.com/ethereum/ethereumj\ncd ethereumj\ngradlew build ``\n  IDEA: \n* File -> New -> Project from existing sources\u2026\n* Select ethereumj/build.gradle\n* Dialog \u201cImport Project from gradle\u201d: press \u201cOK\u201d\n* After building run either org.ethereum.Start , one of org.ethereum.samples.*` or create your own main. Configuring EthereumJ For reference on all existing options, their description and defaults you may refer to the default config ethereumj.conf (you may find it in either the library jar or in the source tree ethereum-core/src/main/resources ) \nTo override needed options you may use one of the following ways: \n* put your options to the <working dir>/config/ethereumj.conf file\n* put user.conf to the root of your classpath (as a resource) \n* put your options to any file and supply it via -Dethereumj.conf.file=<your config> , accepts several configs, separated by comma applied in provided order: -Dethereumj.conf.file=<config1>,<config2> * programmatically by using SystemProperties.CONFIG.override*() * programmatically using by overriding Spring SystemProperties bean Note that don\u2019t need to put all the options to your custom config, just those you want to override. Special thanks YourKit for providing us with their nice profiler absolutely for free. YourKit supports open source projects with its full-featured Java Profiler.\nYourKit, LLC is the creator of YourKit Java Profiler and YourKit .NET Profiler ,\ninnovative and intelligent tools for profiling Java and .NET applications. Contact Chat with us via Gitter License ethereumj is released under the LGPL-V3 license ."}, {"name": "ethsim", "desc": "Simulation/emulation utilities for Ethereum.", "readme": "Ethereum Simulation Working Group This repo captures the discussions, notes, minutes, test plans, and code frameworks for simulators, emulators, and platforms for testing Ethereum 1x and 2x technologies. The document that hosts all the information currently is here . Current status: Last meeting was held Dec 7; minutes are linked through the above doc with next steps.\nNext meeting, TBD."}, {"name": "evmc", "desc": "EVMC \u2013 Ethereum Client-VM Connector API", "readme": "EVMC Ethereum Client-VM Connector API The EVMC is the low-level ABI between Ethereum Virtual Machines (EVMs) and\nEthereum Clients. On the EVM side it supports classic EVM1 and ewasm .\nOn the Client-side it defines the interface for EVM implementations\nto access Ethereum environment and state. Usage Documentation Please visit the documentation . Languages support | Language                      | Supported Versions   | Supported Compilers          | Feature Support   |\n|-------------------------------|----------------------|------------------------------|-------------------|\n| C | C99, C11             | GCC 8+, clang 9+, MSVC 2017+ | Host- and VM-side |\n| C++ | C++17                | GCC 8+, clang 9+, MSVC 2017+ | Host- and VM-side |\n| Go (bindings) | 1.11+ (with modules) |                              | Host-side only    |\n| Rust (bindings) \u00b9 | 2018 edition         | 1.47.0 and newer             | VM-side only      |\n| Java (bindings) \u00b2 | 11                   |                              | Host-side only    | \u2191 Rust support is limited and not complete yet, but it is mostly functional already. Breaking changes are possible at this stage. \u2191 Java support is in progress and the interface remains in flux. Breaking changes are possible at this stage. Testing tools evmc run ( tools/evmc ) \u2014 executes bytecode in any EVMC-compatible VM implementation. evmc-vmtester ( tools/vmtester ) \u2014 can test any EVM implementation for compatibility with EVMC. evm-test ( evmone \u2192 test/unittests ) \u2014 allows running the collection of evmone 's unit tests on any EVMC-compatible EVM implementation. evmone-fuzzer ( evmone \u2192 test/fuzzer ) \u2014 differential fuzzer for EVMC-compatible EVM implementations. Related projects EVMs aleth-interpreter Daytona eip1962-evmc (EIP-2003 style precompile) evmjit evmone Hera Hera.rs ssvm-evmc Clients aleth core-geth (in progress) evmc-js go-ethereum (in progress) nim-evmc pyevm (in progress) pyethereum (abandoned) rust-ssvm (Rust Host-side) silkworm Solidity (for integration testing) turbo-geth Maintainers Alex Beregszaszi @axic Pawe\u0142 Bylica @chfast See also the list of EVMC Authors . Contributing Talk with us on the EVMC Gitter chat . License Licensed under the Apache License, Version 2.0 . Internal Making new release Update CHANGELOG.md , put the release date, update release link. git add CHANGELOG.md . Tag new release: bumpversion --allow-dirty prerel . Prepare CHANGELOG for next release: add unreleased section and link. git add CHANGELOG.md . Start new release series: bumpversion --allow-dirty --no-tag minor ."}, {"name": "evmcodegen", "desc": "A synthetic evm bytecode generation library and cmdline utility to fuzz the ethereum stack machine", "readme": "evmcodegen Ever wanted to generate and manipulate ethereum evm bytecode? This is your chance. Use various strategies to generate Instructions, fix the stack layout, fix jump addresses, balance the stack and manipulate the code before serializing Instruction objects to bytecode. library ```python\nimport evmdasm import distribution and random codegen strategy from evmcodegen.distributions import EVM_CATEGORY\nfrom evmcodegen.generators.distribution import GaussDistrCodeGen import main codegen class from evmcodegen.codegen import CodeGen prepare random number generators for stack arg generator Rnd is just a utility class providing random byte and number generators. see codegen.py VALUEMAP ={\n    evmdasm.argtypes.Address: lambda: Rnd.byte_sequence(20),\n    evmdasm.argtypes.Word: lambda: Rnd.byte_sequence(32),\n    evmdasm.argtypes.Timestamp: lambda: Rnd.byte_sequence(4),\n    evmdasm.argtypes.Data: lambda: Rnd.byte_sequence(Rnd.uni_integer(0, Rnd.opcode())),\n    evmdasm.argtypes.CallValue: lambda: Rnd.uni_integer(0,1024),\n    evmdasm.argtypes.Gas: lambda: Rnd.uni_integer(0,1024),\n    evmdasm.argtypes.Length: lambda: Rnd.small_memory_length_1024(),\n    evmdasm.argtypes.MemOffset: lambda: Rnd.small_memory_length_1024(),\n    evmdasm.argtypes.Index256: lambda: Rnd.uni_integer(1,256),\n    evmdasm.argtypes.Index64: lambda: Rnd.uni_integer(1,64),\n    evmdasm.argtypes.Index32: lambda: Rnd.length_32(),\n    evmdasm.argtypes.Byte: lambda: Rnd.byte_sequence(1),\n    evmdasm.argtypes.Bool: lambda: Rnd.byte_sequence(1),\n    evmdasm.argtypes.Value: lambda: Rnd.uni_integer(),\n    #evmdasm.argtypes.Label: lambda: 0xc0fefefe,  # this is handled by fix_code_layout (fix jumps)\n} create random number generator rnd_codegen = GaussDistrCodeGen(distribution=EVM_CATEGORY) generate code, fix stack arguments, make jumps land on jumpdests, fix stack balance evmcode = CodeGen()\\\n            .generate(generator=rnd_codegen, length=None, min_gas=20)\\\n            .fix_stack_arguments(valuemap=VALUEMAP)\\\n            .fix_jumps().fix_stack_balance() print evmcode as string print(\"0x%s\" % evmcode.assemble().as_hexstring) disassemble and print listing print(evmcode.reassemble().instructions.as_string) print some stats print(CodeGen.stats(evmcode))\n``` cmdline python -m evmcodegen [--disassemble] [--count 1] [--stats] ```\nUsage: main .py [options] Options:\n  -h, --help            show this help message and exit\n  -v VERBOSITY, --verbosity=VERBOSITY\n                        available loglevels:\n                        critical,fatal,error,warning,warn,info,debug,notset\n                        [default: critical]\n  -g GENERATOR, --generator=GENERATOR\n                        select generator (default: DistrCategory)\n  -d, --disassemble     show disassembly\n  -c COUNT, --count=COUNT\n                        number of evmcodes to generate\n  -m MIN_GAS, --min-gas=MIN_GAS\n                        generate instructions consuming at least this amount\n                        of gas\n  -l LENGTH, --length=LENGTH\n                        instructions per generated code\n  -s, --stats           show statistics\n  -b, --balance         balance the stack\n``` ``` > python3 -m evmcodegen --disassemble --stats 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\nPUSH2 4e7e\nPUSH8 4fb87cc2d90eda34\nPUSH8 16ddb46d033b432f\nAND \nPUSH24 e1183a7c67c851296d5e7665ca56e7dd2158341bdb43fac7\nPUSH1 af\nPUSH2 0348\nPUSH2 0154\nPUSH2 02dc\nPUSH20 f9be0ce6ff661facc3be2288534765a056c1ac81\nPUSH2 0169\nDELEGATECALL \nPUSH15 8d4b95ce3bd940e60687688ec7d9b6\nPUSH24 1bb0d8b79e269479c5828966eb6449d66f267a8524933020\nPUSH3 d35abc\nPUSH29 9b12b8365060660f8462edfefc847086df38ccd44a9d262a1dd50555b8\nPUSH10 2e2eddd62e1cbb07c9a6\nPUSH12 9a237026291f95884b8fe266\nPUSH20 544d46c8936bea177da53e3c1312bda38f4f3ba0\nPUSH9 f5e8a91c3bc73e6709\nPUSH27 f9f36c4e149ef38103c0552d7e092461a137d5c499717f923f5f2f\nPUSH6 b6f992507ee1\nPUSH29 0b6c470b9a437ad922daacd9285ef18b6edd4eab3613ab326052e3c802\nPUSH9 e0b0d6226bb814137a\nPUSH11 c1987fc7638244c9442b47\nPUSH7 d5a92878349dd8\nDUP14 \nPUSH8 b6eef9a072a2abcd\nPUSH8 a13f347c0bb49209\nEXP \nPUSH23 7b52cecf065119c1819a817d07ee8cc663a26ec09c089b\nPUSH9 2696cf5a850c1df195\nPUSH16 e90bff18d0ff36bfa6f2cc25b1b60849\nPUSH20 dacbe5081a45f170b8743ed31da4d868e7932dd6\nPUSH19 c767f9ac5e9d68488912397af74cf68c291efe\nPUSH14 95e3d53d0037474e40edd89d6800\nPUSH22 6622c06f5860c016f8a9bbddb445a54a6ea769cc97d7\nPUSH20 82e2f2409561485dbfc9d3932cdd0fb9eac8151d\nPUSH8 05bb89ddcd62ce98\nPUSH19 95c6dd56a8576d09e0cf2c6f3cc6fdf304d8f4\nPUSH15 402e6f145a4c4a18e3cbeb7d6e687c\nSWAP10 \nPUSH32 c1efa359cdbae6d6e94c6744813fce07d2a7f3383cddb72a4c2023a8f9b13f21\nPUSH1 11\nBYTE \nPUSH8 2eff1825f5f63a70\nPUSH1 38\nSHL \nPUSH31 c873b9effc596d42b79b14c4cef32881f60d56d1b91327bd9f6a028fb7f368\nPUSH8 7d1cfb92b27e2c45\nPUSH8 cddfd280cc1ddbe0\nSDIV \n...\nSTATICCALL \nCOINBASE \nPUSH20 9cba807568347e5961cb20eb6d5ac5c517d1b1ba\nEXTCODEHASH \nTIMESTAMP \nPUSH8 8cc5a9a8559d62dd\nPUSH1 1f\nSHR \nPUSH1 94\nPUSH2 02ab\nPUSH2 012e\nRETURNDATACOPY \nPUSH17 dbe9912934546369d4fe0456b8803cd705\nPUSH6 7f3106a3296e\nPUSH20 a0365bd4c56f602c9dc86e6fb463ea620a2c8d1c\nPUSH7 808445edb91b0a\nPUSH29 dc37a19e53f67443b7a1d28bbc667564d7285290bb13386d4b3534fee0\nPUSH28 71dbff2e1517a9b683117fa4645ef4a27a34e2ed8185ce0728db1d66\nPUSH2 3d65\nPUSH26 64a4387d9055bd70c895a6cdaf54a91945b458484ebe31fe2009\nPUSH31 d7b3ef906a9c0587b2d5685068a02eeb5d9dfab58944395740ce9352e08165\nPUSH2 ce8a\nPUSH21 d246aaa50986a88b1d1815e57de99f561797bcb761\nPUSH3 e3f560\nPUSH13 782319a4a4ce987d0473089f3a\nPUSH13 f79cdbf90ca3d2565d6c28abf6\nPUSH9 2f91b479cf057be413\nPUSH5 0d040aa68a\nSWAP15 \nGASPRICE \nPUSH1 d3\nPUSH2 0398\nMSTORE8 \nPUSH1 bb\nPUSH2 037b\nPUSH2 03dc\nCODECOPY \nPUSH2 0311\nPUSH1 9e\nPUSH2 01fa\nCREATE \nPUSH2 0121\nCALLDATALOAD \nNUMBER \nGASLIMIT \nPUSH8 d29285d598771b76\nPUSH8 678095dd15c5b4d4\nEXP \nPUSH8 06b21551f575a900\nPUSH8 e7d5f31066f0e57f\nNOT \nTIMESTAMP \nPUSH8 66051882168d0fda\nPUSH8 09c72bb059af1152\nSMOD \nPUSH8 a2913d2a3f11d2a2\nPUSH8 018e38a9fe15777d\nOR \nPUSH1 48\nPUSH2 0360\nPUSH2 037e\nPUSH2 02dd\nPUSH20 5756dc7853ef4a0bf5d88a584c89d21f8cb7674c\nPUSH2 0166\nDELEGATECALL \nDIFFICULTY \nPUSH8 42d17729f9065c78\nPUSH8 5ae94f0d406ad0ac\nPUSH8 5b3643b96d798483\nADDMOD \nPUSH1 9b\nBLOCKHASH \nPOP \nPUSH32 7d7137625160f3a8731f403a44de517fc969f5bc85e457eba3a976ec54d16cf4\nPUSH2 029f\nSSTORE \nPUSH2 03ca\nPUSH2 0288\nPUSH1 42\nPUSH2 021d\nPUSH2 0166\nPUSH20 f64c07d6a59b6a4e97b59e8785538b8930ecf3cb\nPUSH2 0366\nCALL \nPUSH1 6d\nSLOAD \nNUMBER \nPUSH8 2b82ebee5ee95b4d\nPUSH8 791796333915124b\nSIGNEXTEND \nPUSH8 e5662a85c090a55c\nPUSH8 9b4a669012e1d94a\nNOT \nPUSH2 0128\nPUSH2 0375\nPUSH2 03af\nCODECOPY \nPUSH32 ca08f1ec73c60f7e3e40abb074716f2e3d3a3ac58411be8de97c194b50e20fbf\nPUSH2 0185\nSSTORE \n========stats==========\ninstructions: 2566\ngas (all instructions: 496028\nPUSH8                | 16.250974%\nPUSH2                | 12.081060%\nPUSH1                | 6.157443%\nPUSH20               | 3.078722%\nPUSH4                | 1.831645%\nPUSH5                | 1.831645%\nPUSH15               | 1.831645%\nPUSH16               | 1.792673%\nPUSH19               | 1.753702%\nPUSH29               | 1.753702%\nPUSH22               | 1.675760%\nPUSH7                | 1.597818%\nPUSH27               | 1.597818%\nPUSH30               | 1.597818%\nPUSH25               | 1.558846%\nPUSH31               | 1.519875%\nPUSH3                | 1.480904%\nPUSH6                | 1.480904%\nPUSH28               | 1.363991%\nPUSH10               | 1.286048%\nPUSH14               | 1.286048%\nPUSH11               | 1.247077%\nPUSH12               | 1.247077%\nPUSH24               | 1.247077%\nPUSH26               | 1.247077%\nPUSH9                | 1.208106%\nPUSH13               | 1.169135%\nPUSH17               | 1.169135%\nPUSH18               | 1.130164%\nPUSH21               | 1.091193%\nPUSH23               | 1.091193%\nPUSH32               | 1.052221%\nEXP                  | 0.740452%\nMULMOD               | 0.623539%\nSHL                  | 0.623539%\nJUMPDEST             | 0.623539%\nBYTE                 | 0.506625%\nOR                   | 0.467654%\nSHR                  | 0.467654%\nDIV                  | 0.428683%\nADD                  | 0.389712%\nNOT                  | 0.389712%\nCREATE               | 0.389712%\nMUL                  | 0.350740%\nSUB                  | 0.350740%\nSDIV                 | 0.350740%\nSMOD                 | 0.350740%\nADDMOD               | 0.350740%\nSAR                  | 0.350740%\nNUMBER               | 0.350740%\nSIGNEXTEND           | 0.311769%\nXOR                  | 0.311769%\nGASPRICE             | 0.311769%\nDIFFICULTY           | 0.311769%\nSLOAD                | 0.311769%\nSSTORE               | 0.311769%\nCALL                 | 0.311769%\nMOD                  | 0.272798%\nAND                  | 0.272798%\nCODECOPY             | 0.272798%\nEXTCODESIZE          | 0.272798%\nEXTCODECOPY          | 0.272798%\nRETURNDATASIZE       | 0.272798%\nGASLIMIT             | 0.272798%\nDUP7                 | 0.272798%\nSWAP13               | 0.272798%\nCODESIZE             | 0.233827%\nEXTCODEHASH          | 0.233827%\nBLOCKHASH            | 0.233827%\nCOINBASE             | 0.233827%\nMLOAD                | 0.233827%\nDUP10                | 0.233827%\nSWAP16               | 0.233827%\nCALLCODE             | 0.233827%\nSTATICCALL           | 0.233827%\nADDRESS              | 0.194856%\nORIGIN               | 0.194856%\nCALLDATASIZE         | 0.194856%\nTIMESTAMP            | 0.194856%\nPOP                  | 0.194856%\nMSTORE8              | 0.194856%\nSWAP10               | 0.194856%\nSWAP11               | 0.194856%\nSWAP12               | 0.194856%\nCREATE2              | 0.194856%\nREVERT               | 0.194856%\nCALLER               | 0.155885%\nCALLVALUE            | 0.155885%\nJUMP                 | 0.155885%\nJUMPI                | 0.155885%\nPC                   | 0.155885%\nGAS                  | 0.155885%\nDUP11                | 0.155885%\nDUP13                | 0.155885%\nDUP14                | 0.155885%\nDUP16                | 0.155885%\nSWAP1                | 0.155885%\nSWAP6                | 0.155885%\nSWAP7                | 0.155885%\nSWAP8                | 0.155885%\nDELEGATECALL         | 0.155885%\nSTOP                 | 0.116913%\nCALLDATALOAD         | 0.116913%\nRETURNDATACOPY       | 0.116913%\nMSTORE               | 0.116913%\nMSIZE                | 0.116913%\nDUP2                 | 0.116913%\nDUP4                 | 0.116913%\nDUP5                 | 0.116913%\nDUP8                 | 0.116913%\nDUP15                | 0.116913%\nSWAP2                | 0.116913%\nSWAP4                | 0.116913%\nSWAP5                | 0.116913%\nSWAP9                | 0.116913%\nSELFDESTRUCT         | 0.116913%\nLT                   | 0.077942%\nSHA3                 | 0.077942%\nCALLDATACOPY         | 0.077942%\nDUP1                 | 0.077942%\nDUP6                 | 0.077942%\nDUP9                 | 0.077942%\nSWAP3                | 0.077942%\nSWAP14               | 0.077942%\nUNOFFICIAL_DUP       | 0.077942%\nUNOFFICIAL_SWAP      | 0.077942%\nRETURN               | 0.077942%\nGT                   | 0.038971%\nISZERO               | 0.038971%\nBALANCE              | 0.038971%\nDUP3                 | 0.038971%\nSWAP15               | 0.038971%\nLOG1                 | 0.038971%\nLOG3                 | 0.038971%\nLOG4                 | 0.038971%\nUNOFFICIAL_PUSH      | 0.038971% ```"}, {"name": "evmdasm", "desc": "A lightweight ethereum evm bytecode instruction registry, disassembler and evmcode manipulation library", "readme": "evmdasm A lightweight ethereum evm bytecode instruction registry, disassembler and evmcode manipulation library. This library is meant for providing a static interface and registry for EVM opcodes and instructions. The idea is to keep it as lightweight as possible especially when it comes to dependencies or high level features. e.g. The ethereum-dasm project - a kind of high level disassembler with static/dynamic analysis features - relies on the registry and base disassembling functionality provided by evmdasm . More information --> Wiki Projects building on evmdasm :\n* :trophy: https://github.com/ethereum/evmlab\n* :trophy: https://github.com/tintinweb/ethereum-dasm\n* :trophy: https://github.com/tintinweb/evmcodegen Setup from pypi ``` > python3 -m pip install evmdasm ``` from source ``` > python3 setup.py install ```"}, {"name": "evmjit", "desc": "The Ethereum EVM JIT", "readme": "The Ethereum EVM JIT EVM JIT is a library for just-in-time compilation of Ethereum EVM code.\nIt can be used to substitute classic interpreter-like EVM Virtual Machine in Ethereum client. Maintainers NOTE: This project is not maintained. Do not use it for anything important. Looking for maintainers! Please state your interest here. Build The EVMJIT project uses CMake tool to configure the build and depends only on the LLVM library.\nLLVM installation is not needed, because CMake will download and build LLVM from source.\nHowever, LLVM requires Python interpreter to be built. sh\ngit submodule update --init --recursive\nmkdir build\ncd build\ncmake ..\ncmake --build . --config RelWithDebInfo Options Options to evmjit library can be passed by environmental variable, e.g. EVMJIT=\"-help\" testeth --jit ."}, {"name": "evmlab", "desc": "Utilities for interacting with the Ethereum virtual machine", "readme": "EVM lab utilities This package contains various tools to interact with the Ethereum virtual machine. Please refer to the Wiki for more information and howto's. Installation From source: Consider creating a virtualenv. #> virtualenv -p python3 .env3\n#> . .env3/bin/activate\n#> python3 -m pip install -r requirements.txt\n#> python3 setup.py install\n#> python3 -m evmlab  # verify installation From PIP: #> python3 -m pip install evmlab[consolegui,abidecoder,docker]\n#> python3 -m evmlab  # verify installation EVMLab comes with a commandline utility that can be invoked by calling python3 -m evmlab <subcommand> <args> Running it The easiest way to get it working is to use a docker image. docker build . -t evmlab && docker run -it evmlab The docker image should also be available at hub.docker.com, as an automated build: docker pull holiman/evmlab && docker run -it holiman/evmlab"}, {"name": "evmone", "desc": "Fast Ethereum Virtual Machine implementation", "readme": "evmone Fast Ethereum Virtual Machine implementation evmone is a C++ implementation of the Ethereum Virtual Machine (EVM). \nCreated by members of the Ipsilon (ex- Ewasm ) team, the project aims for clean, standalone EVM implementation \nthat can be imported as an execution module by Ethereum Client projects. \nThe codebase of evmone is optimized to provide fast and efficient execution of EVM smart contracts. Characteristic of evmone Exposes the EVMC API. Requires C++20 standard. The intx library is used to provide 256-bit integer precision. The ethash library is used to provide Keccak hash function implementation\n   needed for the special KECCAK256 instruction. Contains two interpreters: Baseline (default) Advanced (select with the advanced option) Baseline Interpreter Provides relatively straight-forward but efficient EVM implementation. Performs only minimalistic JUMPDEST analysis. Advanced Interpreter The indirect call threading is the dispatch method used -\n   a loaded EVM program is a table with pointers to functions implementing virtual instructions. The gas cost and stack requirements of block of instructions is precomputed \n   and applied once per block during execution. Performs extensive and expensive bytecode analysis before execution. Usage As geth plugin evmone implements the EVMC API for Ethereum Virtual Machines.\nIt can be used as a plugin replacing geth's internal EVM. But for that a modified\nversion of geth is needed. The Ewasm 's fork\nof go-ethereum provides binary releases of geth with EVMC support . Next, download evmone from Releases . Start the downloaded geth with --vm.evm option pointing to the evmone shared library. bash\ngeth --vm.evm=./libevmone.so Building from source To build the evmone EVMC module (shared library), test, and benchmark: Fetch the source code: git clone --recursive https://github.com/ethereum/evmone\n   cd evmone Configure the project build and dependencies:\n   ##### Linux / OSX cmake -S . -B build -DEVMONE_TESTING=ON ##### Windows cmake -S . -B build -DEVMONE_TESTING=ON -G \"Visual Studio 16 2019\" -A x64 Build: cmake --build build --parallel Run the unit tests or benchmarking tool: build/bin/evmone-unittests\n   build/bin/evmone-bench test/evm-benchmarks/benchmarks Precompiles Ethereum Precompiled Contracts ( precompiles for short) are not directly supported by evmone. However, there are options to enable limited precompiles support for testing. The test/state/precompiles_stub.json contains\n   precompiles execution results for inputs commonly used in tests.\n   You can use the precompiles STUB by setting the environment variable EVMONE_PRECOMPILES_STUB=./test/state/precompiles_stub.json . The CMake option EVMONE_PRECOMPILES_SILKPRE=1 enables building of\n   the silkpre third party library with the implementation of the precompiles.\n   This library also requires GMP (e.g. libgmp-dev) library for building and execution. Tools evm-test The evm-test executes a collection of unit tests on \nany EVMC-compatible Ethereum Virtual Machine implementation.\nThe collection of tests comes from the evmone project. bash\nevm-test ./evmone.so Docker Docker images with evmone are available on Docker Hub:\nhttps://hub.docker.com/r/ethereum/evmone. Having the evmone shared library inside a docker is not very useful on its own,\nbut the image can be used as the base of another one or you can run benchmarks \nwith it. bash\ndocker run --entrypoint evmone-bench ethereum/evmone /src/test/benchmarks EVM Object Format (EOF) support evmone supports EOFv1. Since EOF validation is done once during deploy-time, evmone does not revalidate during execution of bytecode. To force EOF revalidation, you can use the validate_eof option, example: evmc run --vm libevmone.so,validate_eof --rev 13 \"EF00\" References Efficient gas calculation algorithm for EVM Maintainer Pawe\u0142 Bylica @chfast License Licensed under the Apache License, Version 2.0 ."}, {"name": "execution-apis", "desc": "Collection of APIs provided by Ethereum execution layer clients ", "readme": "Execution API Specification JSON-RPC View the spec The Ethereum JSON-RPC is a standard collection of methods that all execution\nclients implement. It is the canonical interface between users and the network.\nThis interface allows downstream tooling and infrastructure to treat different\nEthereum clients as modules that can be swapped at will. Contributing Please see the contributors guide in docs/making-changes.md for general information about the process of standardizing new API methods and\nmaking changes to existing ones. Information on test generation can be found\nin tests/README.md The specification itself is written in OpenRPC . Refer to the OpenRPC\nspecification and the JSON schema specification to get started. Building The specification is split into multiple files to improve readability. The \nspec can be compiled into a single document as follows: console\n$ npm install\n$ npm run build\nBuild successful. This will output the file openrpc.json in the root of the project. This file\nwill have all schema #ref s resolved. Testing There are several mechanisms for testing specification contributions and client\nconformance. First is the OpenRPC validator . It performs some basic syntactic\nchecks on the generated specification. console\n$ npm install\n$ npm run lint\nOpenRPC spec validated successfully. Next is speccheck . This tool validates the test cases in the tests directory against the specification. console\n$ go install github.com/lightclient/rpctestgen/cmd/speccheck@latest\n$ speccheck -v\nall passing. The spell checker ensures the specification is free of spelling errors. console\n$ pip install pyspelling\n$ pyspelling -c spellcheck.yaml\nSpelling check passed :) Finally, the test cases in the tests/ directory may be run against individual\nexecution client using the [ hive ] simulator rpc-compat .\nPlease see the documentation in the aforementioned repositories for more\ninformation. GraphQL View the spec EIP-1767 proposed a GraphQL schema for interacting with Ethereum clients. Since then Besu and Geth have implemented the interface. This repo contains a live specification to integrate changes to the protocol as well as other improvements into the GraphQL schema. Generation The schema in this repo is generated by issuing a meta GraphQL query against a live node. This can be done as follows: console\n$ npm run graphql:schema Testing A script is included in the source code which reads and validates the given schema to be a valid one. It is recommended to perform this check after modifying the schema by: console\n$ npm run graphql:validate License This repository is licensed under CC0 ."}, {"name": "execution-spec-tests", "desc": "A Python framework and collection of test cases to generate test vectors for Ethereum execution clients", "readme": "Execution Spec Tests ethereum/execution-spec-tests is both a collection of test cases and a framework implemented in Python to generate tests for Ethereum execution clients. The framework collects and executes the test cases in order to generate test fixtures (JSON) which can be consumed by any execution client to verify their implementation of ethereum/execution-specs . The fixtures, which define state transition and block tests, are generated by the framework using one of the t8n command-line tools that are provided by most execution clients, see below for an overview of the supported t8n tools. ```mermaid title: Test Fixture Generation with execution-spec-tests flowchart LR\n  style C stroke:#333,stroke-width:2px\n  style D stroke:#333,stroke-width:2px\n  style G stroke:#F9A825,stroke-width:2px\n  style H stroke:#F9A825,stroke-width:2px subgraph \"ethereum/go-ethereum, ...\"\n    C[ evm t8n \\nexternal executable]\n  end subgraph ethereum/solidity\n    D[ solc \\nexternal executable]\n  end subgraph ethereum/EIPs\n    E( EIPS/EIP-*.md \\nSHA digest via Github API)\n  end subgraph \"ethereum/execution-spec-tests\"\n    A( ./tests/* / .py \\nPython Test Cases)\n    B([ $ fill ./tests/ \\nPython Framework])\n  end subgraph Test Fixture Consumers\n    subgraph ethereum/hive\n      G([ $ hive ... \\nGo Test Framework])\n    end\n    H([Client executables])\n  end C <-.-> B D <-.-> B\n  A --> B\n  E <-.-> |retrieve latest spec version\\ncheck tested spec version| B\n  B -->|output| F( ./fixtures/* / .json \\nJSON Test Fixtures)\n  F -->|input| G\n  F -->|input| H\n``` The generated test fixtures can be used: Directly by client teams' test frameworks, and, In the integration tests executed in the ethereum/hive framework. Transition Tool Support The following transition tools are supported by the framework: | Client | \"t8n\" Tool | Tracing Support |\n| -------| ---------- | --------------- |\n| ethereum/evmone | evmone-t8n | Yes |\n| ethereum/execution-specs | ethereum-spec-evm | Yes |\n| ethereum/go-ethereum | evm t8n | Yes |\n| hyperledger/besu | evm t8n-server | No |\n| status-im/nimbus-eth1 | t8n | Yes | Upcoming EIP Development Generally, specific t8n implementations and branches must be used when developing tests for upcoming EIPs. We use named reference tags to point to the specific version of the t8n implementation that needs to be used fill the tests. All current tags, their t8n implementation and branch they point to, are listed in evm-config.yaml . Getting Started Prerequisites The following requires a Python 3.10, 3.11 or 3.12 installation. Quick Start This guide installs stable versions of the required external (go-ethereum) evm and solc executables and will only enable generation of test fixtures for features deployed to mainnet. In order to generate fixtures for features under active development, you can follow the steps below and then follow the additional steps in the online doc . Ensure go-ethereum's evm tool and solc ( 0.8.20 , 0.8.21 , 0.8.22 supported) are in your path. Either build the required versions, or alternatively: console\nsudo add-apt-repository -y ppa:ethereum/ethereum\nsudo apt-get update\nsudo apt-get install ethereum solc More help: geth installation doc . solc installation doc . Help for other platforms is available in the online doc . Clone the execution-spec-tests repo and install its dependencies (it's recommended to use a virtual environment for the installation): console\n   git clone https://github.com/ethereum/execution-spec-tests\n   cd execution-spec-tests\n   python3 -m venv ./venv/\n   source ./venv/bin/activate\n   pip install -e '.[docs,lint,test]' Verify the installation: Explore test cases: console\n   fill --collect-only Expected console output: Execute the test cases (verbosely) in the ./tests/berlin/eip2930_access_list/test_acl.py module: console\nfill -v tests/berlin/eip2930_access_list/test_acl.py Expected console output: Check: The versions of the evm and solc tools are as expected (your versions may differ from those in the highlighted box). The corresponding fixture file has been generated: console\n   head fixtures/berlin/eip2930_access_list/acl/access_list.json Usage More information on how to obtain and use the released test fixtures can be found here . For further help with working with this codebase, see the online documentation : Learn useful command-line flags . Execute tests for features under development via the --from=FORK1 and --until=FORK2 flags. Optional: Configure VS Code to auto-format Python code and execute tests within VS Code . Implement a new test case, see Writing Tests . Coverage The available test cases can be browsed in the Test Case Reference doc . Contributing Contributions and feedback are welcome. Please see the online documentation for this repository's coding standards and help on implementing new tests. License This project is licensed under the MIT License - see the LICENSE file for details."}, {"name": "execution-specs", "desc": "Specification for the Execution Layer. Tracking network upgrades.", "readme": "Ethereum Execution Client Specifications Description This repository contains the specifications related to the Ethereum execution client, specifically the pyspec and specifications for network upgrades . The JSON-RPC API specification can be found in a separate repository. Ethereum Protocol Releases | Version and Code Name | Block No. | Released | Incl EIPs | Specs | Blog |\n|-----------------------|-----------|----------|-----------|-------|-------|\n| Cancun | TBD | TBD | TBD | Specification | TBD |\n| Shanghai | 17034870 | 2023-04-12 (1681338455) | EIP-3651 EIP-3855 EIP-3860 EIP-4895 | Specification | Blog |\n| Paris | 15537394 | 2022-09-15 | EIP-3675 EIP-4399 | Specification | Blog |\n| Gray Glacier | 15050000 | 2022-06-30 | EIP-5133 | Specification | Blog |\n| Arrow Glacier | 13773000 | 2021-12-09 | EIP-4345 | Specification | Blog |\n| London | 12965000 |  2021-08-05 | EIP-1559 EIP-3198 EIP-3529 EIP-3541 EIP-3554 | Specification | Blog |\n| Berlin | 12244000 | 2021-04-15 | EIP-2565 EIP-2929 EIP-2718 EIP-2930 | ~ HFM-2070 ~ Specification | Blog |\n| Muir Glacier | 9200000 | 2020-01-02 | EIP-2384 | HFM-2387 | Blog |\n| Istanbul | 9069000 | 2019-12-07 | EIP-152 EIP-1108 EIP-1344 EIP-1884 EIP-2028 EIP-2200 | HFM-1679 | Blog | Petersburg | 7280000 | 2019-02-28 | EIP-145 EIP-1014 EIP-1052 EIP-1234 | HFM-1716 | Blog |\n| Constantinople | 7280000 | 2019-02-28 | EIP-145 EIP-1014 EIP-1052 EIP-1234 EIP-1283 | HFM-1013 | Blog |\n| Byzantium | 4370000 | 2017-10-16 | EIP-100 EIP-140 EIP-196 EIP-197 EIP-198 EIP-211 EIP-214 EIP-649 EIP-658 | HFM-609 | Blog |\n| Spurious Dragon | 2675000 | 2016-11-22 | EIP-155 EIP-160 EIP-161 EIP-170 | HFM-607 | Blog |\n| Tangerine Whistle | 2463000 | 2016-10-18 | EIP-150 | HFM-608 | Blog |\n| DAO Fork | 1920000 | 2016-07-20 |  | HFM-779 | Blog |\n| DAO Wars | aborted | aborted |  |  | Blog |\n| Homestead | 1150000 | 2016-03-14 | EIP-2 EIP-7 EIP-8 | HFM-606 | Blog |\n| Frontier Thawing | 200000 | 2015-09-07 | | | Blog |\n| Frontier | 1 | 2015-07-30 | | | Blog | Note: Starting with Paris, updates are no longer rolled out based on block numbers. Paris was enabled once proof-of-work Total Difficulty reached 58750000000000000000000. As of Shanghai (at 1681338455), upgrade activation is based on timestamps. Some clarifications were enabled without protocol releases: | EIP | Block No. |\n|-----|-----------|\n| EIP-2681 | 0 |\n| EIP-3607 | 0 | Execution Specification (work-in-progress) The execution specification is a python implementation of Ethereum that prioritizes readability and simplicity. It will accompanied by both narrative and API level documentation of the various components written in markdown and rendered using docc... Rendered specification Usage The Ethereum specification is maintained as a Python library, for better integration with tooling and testing. Requires Python 3.10+ Building Building the documentation is most easily done through tox : bash\n$ tox -e doc The path to the generated HTML will be printed to the console. License The Ethereum Execution Layer Specification code is licensed under the Creative Commons Zero v1.0 Universal ."}, {"name": "fe", "desc": "Emerging smart contract language for the Ethereum blockchain.", "readme": "Fe is an emerging smart contract language for the Ethereum blockchain. NOTE: The larger part of the master branch will be replaced with the brand-new implementation, which is currently under development in the fe-v2 branch. Please refer to the branch if you kindly contribute to Fe Overview Fe is a statically typed language for the Ethereum Virtual Machine (EVM). It is inspired by Rust and easy to learn -- especially for new developers entering the Ethereum ecosystem. Features & Goals Bounds and overflow checking Decidability by limitation of dynamic program behavior More precise gas estimation (as a consequence of decidability) Static typing Pure function support Restrictions on reentrancy Static looping Module imports Standard library Usage of YUL IR to target both EVM and eWASM WASM compiler binaries for enhanced portability and in-browser compilation of\n  Fe contracts Implementation in a powerful, systems-oriented language (Rust) with strong safety guarantees to reduce risk of compiler bugs Additional information about design goals and background can be found in the official announcement . Language Specification We aim to provide a full language specification that should eventually be used to formally verify the correctness of the compiler. A work in progress draft of the specification can be found here . Progress Fe development is still in its early stages. We have a basic Roadmap for 2021 that we want to follow. We generally try to drive the development by working through real world use cases. Our next goal is to provide a working Uniswap implementation in Fe which will help us to advance and form the language. Fe had its first alpha release January 2021 and is now following a monthly release cycle. Getting started Build the compiler Or download the binary release To compile Fe code: Run fe path/to/fe_source.fe Fe creates a directory output in the current working directory that contains the compiled binary and abi. Run fe --help to explore further options. Examples The following is a simple contract implemented in Fe. ```fe\nstruct Signed {\n    pub book_msg: String<100>\n} contract GuestBook {\n    messages: Map<address, String<100>> pub fn sign(mut self, mut ctx: Context, book_msg: String<100>) {\n    self.messages[ctx.msg_sender()] = book_msg\n    ctx.emit(Signed(book_msg: book_msg))\n}\n\npub fn get_msg(self, addr: address) -> String<100> {\n    return self.messages[addr].to_mem()\n} }\n``` A lot more working examples can be found in our test fixtures directory . The most advanced example that we can provide at this point is an implementation of the Uniswap-V2 core contracts . Community Twitter: @official_fe Chat: Discord License The Fe implementation is split into several crates. Crates that depend on the\nsolidity compiler (directly or indirectly) are licensed GPL-3.0-or-later. This\nincludes the fe CLI tool, yulc, driver, tests, and test-utils. The remaining crates are licensed Apache-2.0. This includes the parser,\nanalyzer, mir, abi, and common."}, {"name": "fellowship-program-website", "desc": "Website for the Ethereum Foundation's Fellowship Program:", "readme": "Ethereum Foundation Fellowship Program The Ethereum Foundation Fellowship Program is an opportunity to experiment with using Ethereum to help solve pressing social, economic, and environmental challenges in developing countries. This repository holds the codebase to our website, fellowship.ethereum.foundation Local development Set up your development environment Clone this project ```\n$ git clone git@github.com:ethereum/fellowship-program-website.git && cd fellowship-program-website ``` Install dependencies $ yarn Start developing! yarn develop Learning Gatsby Full documentation for Gatsby lives on the website . Here are some places to start: For most developers, we recommend starting with our in-depth tutorial for creating a site with Gatsby . It starts with zero assumptions about your level of ability and walks through every step of the process. To dive straight into code samples, head to our documentation . In particular, check out the Guides , API Reference , and Advanced Tutorials sections in the sidebar."}, {"name": "foundation-archived", "desc": "[ARCHIVED] ethereum.foundation", "readme": "foundation / master Server setup Linux/Debian/Ubuntu Ensure you have an updated version of nodejs and npm installed. Ubuntu repos often contain an old version, so it's recommend to use a more up-to-date repo . If you already had nodejs installed and need it updated, make sure to sudo apt-get update && sudo apt-get upgrade . Otherwise a sudo apt-get install nodejs npm should be sufficient. Mac brew install node Windows Install node from http://nodejs.org/download/ and open the node command prompt. Assuming nodejs/npm is correctly installed, the next step is to install gulp with sudo npm -g install gulp . Project setup npm install && gulp build This will install all dependencies and compile the site to ./build/ (or whatever is defined as basePaths.dest in gulpfile.js). To instruct gulp to compile for production, pass --prod and possibly gulp bundle to compress it into a zip. For example: gulp build --prod && gulp bundle Or use the default dev task, which launches a local live-reload server for preview: gulp"}, {"name": "frontier-guide", "desc": null, "readme": "Ethereum Frontier Guide Welcome to the Frontier! The Frontier is the first live release of the Ethereum network. As such you are entering uncharted territory and you are invited to test the grounds and explore. There is a lot of danger, there may still be undiscovered traps, there may be ravaging bands of pirates waiting to attack you, but there also is vast room for opportunities. In order to navigate the Frontier, you\u2019ll need to use the command line. If you are not comfortable using it, we strongly advise you to step back, watch from a distance for a while and wait until more user friendly tools are made available. Remember, there are no safety nets and for everything you do here, you are mostly on your own."}, {"name": "fuzzertests", "desc": "Ethereum statetests generated through libfuzzer", "readme": null}, {"name": "fv-blog", "desc": "Formal verification blog", "readme": "Formal verifcation blog Hello! This repo is adapted from the solidity blog which in turn inherits from the EF blog . Welcome to GitHub Pages You can use the editor on GitHub to maintain and preview the content for your website in Markdown files. Whenever you commit to this repository, GitHub Pages will run Jekyll to rebuild the pages in your site, from the content in your Markdown files. Markdown Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for ```markdown\nSyntax highlighted code block Header 1 Header 2 Header 3 Bulleted List Numbered List Bold and Italic and Code text Link and ``` For more details see GitHub Flavored Markdown . Jekyll Themes Your Pages site will use the layout and styles from the Jekyll theme you have selected in your repository settings . The name of this theme is saved in the Jekyll _config.yml configuration file. Support or Contact Having trouble with Pages? Check out our documentation or contact support and we\u2019ll help you sort it out."}, {"name": "gav", "desc": "Need Gav to do something? File an issue.", "readme": null}, {"name": "genesis_block_generator", "desc": null, "readme": "Genesis block generator Run as follows: bash\n$ python mk_genesis_block.py --extradata <hash_from_#1028201> > genesis.json"}, {"name": "geth-website", "desc": "This was a temporary home for the new Geth website", "readme": "Geth website This repository is no longer active and was archived. Development of the go-ethereum website continues on the website branch of the go-ethereum Github repository . Please see contribution guidelines here . Thanks!"}, {"name": "gethkey", "desc": null, "readme": "gethkey This is a temporarily solution to extract private keys from the old key store on the current olympic test net. This will only work for clients that have old keys (geth <v0.9.20). Usage: gethkey <address> <export_file> Installation: Installation assumes you have godep installed git clone https://github.com/ethereum/gethkey.git\ncd gethkey\ngodep go install"}, {"name": "GitSync", "desc": "Synchronization of Ethereum GitHub repos to other git hosting services", "readme": "Git Sync Project This project aims to demonstrate how Ethereum community repos and issues hosted on GitHub can be easily restored on another similar service, whether commercial of self-hosted. Resources Project website Project repo - (you are here!) links to resources, coordination and feedback GitSync codebase - scripts used to perform syncs and fetching of issues Issues archive - JSON containing GitHub issues and comments for selected repositories Frequently Asked Questions Which repos are sync'd? \ud83d\udc49  See the list of Sync'd Repositories . Where are these repos sync'd to? \ud83d\udc49  We currently sync repos to a test account on Bitbucket: https://bitbucket.org/ethereum-base/ . How do I submit my Ethereum-related repo to Git Sync? \ud83d\udc49  Please read the instructions on the Submit My Repo page. What are the qualifications for inclusion of my repo in Git Sync? \ud83d\udc49  The policy about inclusion are detailed on the Submit My Repo page. Where do I ask questions or point out problems? \ud83d\udc49  Please submit an issue on the project repo and one of the maintainers will reply."}, {"name": "glados", "desc": "Portal network monitoring application.", "readme": "Glados Network health monitoring tool for the Portal Network Project Overview The project is split up into a few different crates. glados-core : Contains shared code that is shared by the other crates. glados-web : The web application that serves the HTML dashboard glados-monitor : The long running system processes that pull in chain data and audit the portal network. Technology Choices sea-orm - ORM and database migrations.  The entity and migration crates are sea-orm conventions. axum - Web framework for serving HTML. askama - Templating for HTML pages. web3 - For querying an Ethereum provider for chain data tokio - Async runtime. tracing - Structured logging For our database, we use SQLite for local development and Postgres for production. Architecture The rough shape of Glados is as follows: The glados-monitor crate implements a long running process which continually follows the tip of the chain, and computes the ContentID/ContentKey values for new content as new blocks are added to the canonical chain.  These values are inserted into a relational database (SQLite for local dev, Postgres for production). A second long running process (that has not yet been written) then queries the database for content that it will then \"audit\" to determine whether the content can be successfully retrieved from the network.  The audit process will use the Portal Network JSON-RPC api to query the portal network for the given content and then record in the database whether the content could be successfully retrieved.  The database is structured such that a piece of content can be audited many times, giving a historical view over the lifetime of the content showing times when it was or was not available. The glados-web crate implements a web application to display information from the database about the audits.  The goal is to have a dashboard that provides a single high level overview of the network health, as well as the ability to drill down into specific pieces of content to see the individual audit history. Running Things For specific examples, see the SETUP_GUIDE.md . Quick Deploy via Docker: See the DOCKER_GUIDE.md Basics When using SQLite you can use an ephemeral in-memory database or one persisted to disk.  This value is referred to as the DATABASE_URL in memory: sqlite::memory: persistent: sqlite:////absolute/path/to/db.sqlite In most cases, you will want to set the environment variable RUST_LOG to enable some level of debug level logs. RUST_LOG=glados_monitor=debug is a good way to only enable the debug logs for a specific crate/namespace. Running glados-monitor The glados-monitor crate can be run as follows to populate a local database with content ids. The CLI needs a DATABASE_URL to know what relational database to connect to, as well as an HTTP_PROVIDER_URI to connect to an Ethereum JSON-RPC provider (not a portal node). $ cargo run -p glados-monitor -- --database-url <DATABASE_URL> follow-head --provider-url <HTTP_PROVIDER_URI> For example, if an Ethereum execution client is running on localhost port 8545: $ cargo run -p glados-monitor -- --database-url sqlite::memory: follow-head --provider-url http://127.0.0.1:8545 Importing the pre-merge accumulators The pre-merge epoch accumulators can be found here: https://github.com/njgheorghita/portal-accumulators They can be imported with this command $ cargo run -p glados-monitor -- --database-url <DATABASE_URL> import-pre-merge-accumulators --path /path/to/portal-accumulators/bridge_content Running glados-web The CLI needs a DATABASE_URL to know what relational database to connect to, as well as the IPC_PATH which is an absolute path to an IPC socket for a portal client exposing the portal network JSON-RPC api. This has only been tested using the trin portal network client. $ cargo run -p glados-web -- --database-url DATABASE_URL You should then be able to view the web application at http://127.0.0.1:3001/ in your browser."}, {"name": "go-build", "desc": "Build scripts for Ethereum Go", "readme": "go-build Build scripts for Ethereum Mist. OS X Install all build dependencies. brew install go gmp readline npm install -g appdmg go get -u github.com/ethereum/go-ethereum/cmd/mist Open build.py and edit the (macdeployqt) paths. python build.py If everything went ok you should now have a Mist.dmg file in your current folder. Windows Install all build dependencies. Golang 1.2 or higher (32-bit required) Install Git and Mercurial MinGW32 (add X:\\MinGW\\bin directory to your  PATH) Use mingw32-get to install gmp packages Install Qt5 for Windows 32-bit MinGW (5.2.1 at the moment of writing) Install pkg-config somewhere in your PATH. (read the instructions here) Install NSIS After all these things have been satisfied go get -u github.com/ethereum/go-ethereum/cmd/mist Once the compilation is completed you can create a setup binary.\n- Edit build.bat and change qtPath and mingwPath to the paths of your installed versions.\n- right-click the nsi file and select \"Compile NSIS Script\". If everything went well you should now have a windows-setup file. Troubleshooting Now it will be a miracle if the windows build works in one go.\nSo here are some possible solutions for things that can go wrong: Expected unqualified-id qopenglversionfunctions.h:785:43: error: expected unqualified-id before ')' token\n     void (QOPENGLF_APIENTRYP MemoryBarrier)(GLbitfield barriers); See this ticket for a couple of solutions. pkg-config path pkg-config might complain about the config path. Setup an environment value PKG_CONFIG_PATH and set it to C:\\Qt\\Qt5.2.1\\5.2.1\\mingw48_32\\lib\\pkgconfig . Adopted to your QT version. If there are any build problems please create an issue."}, {"name": "go-casper", "desc": null, "readme": null}, {"name": "go-ethereum", "desc": "Official Go implementation of the Ethereum protocol", "readme": "Go Ethereum Official Golang execution layer implementation of the Ethereum protocol. Automated builds are available for stable releases and the unstable master branch. Binary\narchives are published at https://geth.ethereum.org/downloads/. Building the source For prerequisites and detailed build instructions please read the Installation Instructions . Building geth requires both a Go (version 1.19 or later) and a C compiler. You can install\nthem using your favourite package manager. Once the dependencies are installed, run shell\nmake geth or, to build the full suite of utilities: shell\nmake all Executables The go-ethereum project comes with several wrappers/executables found in the cmd directory. |  Command   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n| :--------: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| geth | Our main Ethereum CLI client. It is the entry point into the Ethereum network (main-, test- or private net), capable of running as a full node (default), archive node (retaining all historical state) or a light node (retrieving data live). It can be used by other processes as a gateway into the Ethereum network via JSON RPC endpoints exposed on top of HTTP, WebSocket and/or IPC transports. geth --help and the CLI page for command line options. |\n| clef | Stand-alone signing tool, which can be used as a backend signer for geth .                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n| devp2p | Utilities to interact with nodes on the networking layer, without running a full blockchain.                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n| abigen | Source code generator to convert Ethereum contract definitions into easy-to-use, compile-time type-safe Go packages. It operates on plain Ethereum contract ABIs with expanded functionality if the contract bytecode is also available. However, it also accepts Solidity source files, making development much more streamlined. Please see our Native DApps page for details.                                  |\n| bootnode | Stripped down version of our Ethereum client implementation that only takes part in the network node discovery protocol, but does not run any of the higher level application protocols. It can be used as a lightweight bootstrap node to aid in finding peers in private networks.                                                                                                                                                                                                                                               |\n| evm | Developer utility version of the EVM (Ethereum Virtual Machine) that is capable of running bytecode snippets within a configurable environment and execution mode. Its purpose is to allow isolated, fine-grained debugging of EVM opcodes (e.g. evm --code 60ff60ff --debug run ).                                                                                                                                                                                                                                               |\n| rlpdump | Developer utility tool to convert binary RLP ( Recursive Length Prefix ) dumps (data encoding used by the Ethereum protocol both network as well as consensus wise) to user-friendlier hierarchical representation (e.g. rlpdump --hex CE0183FFFFFFC4C304050583616263 ).                                                                                                                                                                                | Running geth Going through all the possible command line flags is out of scope here (please consult our CLI Wiki page ),\nbut we've enumerated a few common parameter combos to get you up to speed quickly\non how you can run your own geth instance. Hardware Requirements Minimum: CPU with 2+ cores 4GB RAM 1TB free storage space to sync the Mainnet 8 MBit/sec download Internet service Recommended: Fast CPU with 4+ cores 16GB+ RAM High-performance SSD with at least 1TB of free space 25+ MBit/sec download Internet service Full node on the main Ethereum network By far the most common scenario is people wanting to simply interact with the Ethereum\nnetwork: create accounts; transfer funds; deploy and interact with contracts. For this\nparticular use case, the user doesn't care about years-old historical data, so we can\nsync quickly to the current state of the network. To do so: shell\n$ geth console This command will:\n * Start geth in snap sync mode (default, can be changed with the --syncmode flag),\n   causing it to download more data in exchange for avoiding processing the entire history\n   of the Ethereum network, which is very CPU intensive.\n * Start the built-in interactive JavaScript console ,\n   (via the trailing console subcommand) through which you can interact using web3 methods (note: the web3 version bundled within geth is very old, and not up to date with official docs),\n   as well as geth 's own management APIs .\n   This tool is optional and if you leave it out you can always attach it to an already running geth instance with geth attach . A Full node on the G\u00f6rli test network Transitioning towards developers, if you'd like to play around with creating Ethereum\ncontracts, you almost certainly would like to do that without any real money involved until\nyou get the hang of the entire system. In other words, instead of attaching to the main\nnetwork, you want to join the test network with your node, which is fully equivalent to\nthe main network, but with play-Ether only. shell\n$ geth --goerli console The console subcommand has the same meaning as above and is equally\nuseful on the testnet too. Specifying the --goerli flag, however, will reconfigure your geth instance a bit: Instead of connecting to the main Ethereum network, the client will connect to the G\u00f6rli\n   test network, which uses different P2P bootnodes, different network IDs and genesis\n   states. Instead of using the default data directory ( ~/.ethereum on Linux for example), geth will nest itself one level deeper into a goerli subfolder ( ~/.ethereum/goerli on\n   Linux). Note, on OSX and Linux this also means that attaching to a running testnet node\n   requires the use of a custom endpoint since geth attach will try to attach to a\n   production node endpoint by default, e.g., geth attach <datadir>/goerli/geth.ipc . Windows users are not affected by\n   this. Note: Although some internal protective measures prevent transactions from\ncrossing over between the main network and test network, you should always\nuse separate accounts for play and real money. Unless you manually move\naccounts, geth will by default correctly separate the two networks and will not make any\naccounts available between them. Configuration As an alternative to passing the numerous flags to the geth binary, you can also pass a\nconfiguration file via: shell\n$ geth --config /path/to/your_config.toml To get an idea of how the file should look like you can use the dumpconfig subcommand to\nexport your existing configuration: shell\n$ geth --your-favourite-flags dumpconfig Note: This works only with geth v1.6.0 and above. Docker quick start One of the quickest ways to get Ethereum up and running on your machine is by using\nDocker: shell\ndocker run -d --name ethereum-node -v /Users/alice/ethereum:/root \\\n           -p 8545:8545 -p 30303:30303 \\\n           ethereum/client-go This will start geth in snap-sync mode with a DB memory allowance of 1GB, as the\nabove command does.  It will also create a persistent volume in your home directory for\nsaving your blockchain as well as map the default ports. There is also an alpine tag\navailable for a slim version of the image. Do not forget --http.addr 0.0.0.0 , if you want to access RPC from other containers\nand/or hosts. By default, geth binds to the local interface and RPC endpoints are not\naccessible from the outside. Programmatically interfacing geth nodes As a developer, sooner rather than later you'll want to start interacting with geth and the\nEthereum network via your own programs and not manually through the console. To aid\nthis, geth has built-in support for a JSON-RPC based APIs ( standard APIs and geth specific APIs ).\nThese can be exposed via HTTP, WebSockets and IPC (UNIX sockets on UNIX based\nplatforms, and named pipes on Windows). The IPC interface is enabled by default and exposes all the APIs supported by geth ,\nwhereas the HTTP and WS interfaces need to manually be enabled and only expose a\nsubset of APIs due to security reasons. These can be turned on/off and configured as\nyou'd expect. HTTP based JSON-RPC API options: --http Enable the HTTP-RPC server --http.addr HTTP-RPC server listening interface (default: localhost ) --http.port HTTP-RPC server listening port (default: 8545 ) --http.api API's offered over the HTTP-RPC interface (default: eth,net,web3 ) --http.corsdomain Comma separated list of domains from which to accept cross origin requests (browser enforced) --ws Enable the WS-RPC server --ws.addr WS-RPC server listening interface (default: localhost ) --ws.port WS-RPC server listening port (default: 8546 ) --ws.api API's offered over the WS-RPC interface (default: eth,net,web3 ) --ws.origins Origins from which to accept WebSocket requests --ipcdisable Disable the IPC-RPC server --ipcapi API's offered over the IPC-RPC interface (default: admin,debug,eth,miner,net,personal,txpool,web3 ) --ipcpath Filename for IPC socket/pipe within the datadir (explicit paths escape it) You'll need to use your own programming environments' capabilities (libraries, tools, etc) to\nconnect via HTTP, WS or IPC to a geth node configured with the above flags and you'll\nneed to speak JSON-RPC on all transports. You\ncan reuse the same connection for multiple requests! Note: Please understand the security implications of opening up an HTTP/WS based\ntransport before doing so! Hackers on the internet are actively trying to subvert\nEthereum nodes with exposed APIs! Further, all browser tabs can access locally\nrunning web servers, so malicious web pages could try to subvert locally available\nAPIs! Operating a private network Maintaining your own private network is more involved as a lot of configurations taken for\ngranted in the official networks need to be manually set up. Defining the private genesis state First, you'll need to create the genesis state of your networks, which all nodes need to be\naware of and agree upon. This consists of a small JSON file (e.g. call it genesis.json ): json\n{\n  \"config\": {\n    \"chainId\": <arbitrary positive integer>,\n    \"homesteadBlock\": 0,\n    \"eip150Block\": 0,\n    \"eip155Block\": 0,\n    \"eip158Block\": 0,\n    \"byzantiumBlock\": 0,\n    \"constantinopleBlock\": 0,\n    \"petersburgBlock\": 0,\n    \"istanbulBlock\": 0,\n    \"berlinBlock\": 0,\n    \"londonBlock\": 0\n  },\n  \"alloc\": {},\n  \"coinbase\": \"0x0000000000000000000000000000000000000000\",\n  \"difficulty\": \"0x20000\",\n  \"extraData\": \"\",\n  \"gasLimit\": \"0x2fefd8\",\n  \"nonce\": \"0x0000000000000042\",\n  \"mixhash\": \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n  \"parentHash\": \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n  \"timestamp\": \"0x00\"\n} The above fields should be fine for most purposes, although we'd recommend changing\nthe nonce to some random value so you prevent unknown remote nodes from being able\nto connect to you. If you'd like to pre-fund some accounts for easier testing, create\nthe accounts and populate the alloc field with their addresses. json\n\"alloc\": {\n  \"0x0000000000000000000000000000000000000001\": {\n    \"balance\": \"111111111\"\n  },\n  \"0x0000000000000000000000000000000000000002\": {\n    \"balance\": \"222222222\"\n  }\n} With the genesis state defined in the above JSON file, you'll need to initialize every geth node with it prior to starting it up to ensure all blockchain parameters are correctly\nset: shell\n$ geth init path/to/genesis.json Creating the rendezvous point With all nodes that you want to run initialized to the desired genesis state, you'll need to\nstart a bootstrap node that others can use to find each other in your network and/or over\nthe internet. The clean way is to configure and run a dedicated bootnode: shell\n$ bootnode --genkey=boot.key\n$ bootnode --nodekey=boot.key With the bootnode online, it will display an enode URL that other nodes can use to connect to it and exchange peer information. Make sure to\nreplace the displayed IP address information (most probably [::] ) with your externally\naccessible IP to get the actual enode URL. Note: You could also use a full-fledged geth node as a bootnode, but it's the less\nrecommended way. Starting up your member nodes With the bootnode operational and externally reachable (you can try telnet <ip> <port> to ensure it's indeed reachable), start every subsequent geth node pointed to the bootnode for peer discovery via the --bootnodes flag. It will\nprobably also be desirable to keep the data directory of your private network separated, so\ndo also specify a custom --datadir flag. shell\n$ geth --datadir=path/to/custom/data/folder --bootnodes=<bootnode-enode-url-from-above> Note: Since your network will be completely cut off from the main and test networks, you'll\nalso need to configure a miner to process transactions and create new blocks for you. Running a private miner In a private network setting a single CPU miner instance is more than enough for\npractical purposes as it can produce a stable stream of blocks at the correct intervals\nwithout needing heavy resources (consider running on a single thread, no need for multiple\nones either). To start a geth instance for mining, run it with all your usual flags, extended\nby: shell\n$ geth <usual-flags> --mine --miner.threads=1 --miner.etherbase=0x0000000000000000000000000000000000000000 Which will start mining blocks and transactions on a single CPU thread, crediting all\nproceedings to the account specified by --miner.etherbase . You can further tune the mining\nby changing the default gas limit blocks converge to ( --miner.targetgaslimit ) and the price\ntransactions are accepted at ( --miner.gasprice ). Contribution Thank you for considering helping out with the source code! We welcome contributions\nfrom anyone on the internet, and are grateful for even the smallest of fixes! If you'd like to contribute to go-ethereum, please fork, fix, commit and send a pull request\nfor the maintainers to review and merge into the main code base. If you wish to submit\nmore complex changes though, please check up with the core devs first on our Discord Server to ensure those changes are in line with the general philosophy of the project and/or get\nsome early feedback which can make both your efforts much lighter as well as our review\nand merge procedures quick and simple. Please make sure your contributions adhere to our coding guidelines: Code must adhere to the official Go formatting guidelines (i.e. uses gofmt ). Code must be documented adhering to the official Go commentary guidelines. Pull requests need to be based on and opened against the master branch. Commit messages should be prefixed with the package(s) they modify. E.g. \"eth, rpc: make trace configs optional\" Please see the Developers' Guide for more details on configuring your environment, managing project dependencies, and\ntesting procedures. Contributing to geth.ethereum.org For contributions to the go-ethereum website , please checkout and raise pull requests against the website branch.\nFor more detailed instructions please see the website branch README or the contributing page of the website. License The go-ethereum library (i.e. all code outside of the cmd directory) is licensed under the GNU Lesser General Public License v3.0 ,\nalso included in our repository in the COPYING.LESSER file. The go-ethereum binaries (i.e. all code inside of the cmd directory) are licensed under the GNU General Public License v3.0 , also\nincluded in our repository in the COPYING file."}, {"name": "go-verkle", "desc": "A go implementation of Verkle trees", "readme": "go-verkle A Go implementation of Verkle Tree datastructure defined in the spec . Test & Benchmarks To run the tests and benchmarks, run the following commands: bash\n$ go test ./... To run the benchmarks: bash\ngo test ./... -bench=. -run=none -benchmem Security If you find any security vulnerability, please don't open a GH issue and contact repo owners directly. LICENSE License ."}, {"name": "grants-advisors", "desc": "Resources for advisors to the Ethereum Foundation Grants program", "readme": "grants-advisors Resources for advisors to the Ethereum Foundation Grants program"}, {"name": "grid", "desc": "[DEPRECATED] Download, configure, and run Ethereum nodes and tools", "readme": "## DEPRECATED\nThis project is not supported anymore. Ethereum Grid Grid is a desktop application that allows you to securely download, configure and use various clients and tools in the Ethereum ecosystem. Download the latest version . See this introductory post to learn more about the motivations behind the project. Release announcements and tutorials are released on the project Medium publication . Development This repo is the hosting application for Grid UI . Quick Start Install and run Grid UI: git clone https://github.com/ethereum/grid-ui.git\ncd grid-ui\nyarn && yarn start Install and run Grid: git clone https://github.com/ethereum/grid.git\ncd grid\nyarn && yarn start:dev Dev Mode yarn start:dev The developer mode will try to load grid UI from a locally running web server on port 3080 . Debugging Enable debug logging to console with DEBUG=geth-js yarn start:dev . More namespaces will be added over time and listed here. We would appreciate contributions in adding more throughout our modules. Production Mode yarn start:prod In production mode, a bundled app can be loaded from either fs or a remote location such as Grid UI's GitHub releases. Release Process See the developer guide here . Landing page development guide See instructions at /docs . Contributing There are many ways to get involved with this project. Get started here ."}, {"name": "grid-ui", "desc": "**DEPRECATED** UI for Ethereum Grid", "readme": ":no_entry: Deprecated :no_entry: This project is not supported anymore. Ethereum Grid Grid is a desktop application that allows you to securely download, configure and use various clients and tools in the Ethereum ecosystem. Download the latest version . See this introductory post to learn more about the motivations behind the project. Release announcements and tutorials are released on the project Medium publication . Development This repo is the web application hosted by Grid . Quick Start Clone, install dependencies, and start the application: git clone https://github.com/ethereum/grid-ui.git\ncd grid-ui\nyarn && yarn start This will serve the application at localhost:3080 , but little can be done without the Grid electron wrapper: git clone https://github.com/ethereum/grid.git\ncd grid\nyarn && yarn start:dev Contributing There are many ways to get involved with this project. Get started here ."}, {"name": "guide", "desc": "Docs", "readme": "TurboEthereum Guide This book is intended as a practical user guide for the \"Turbo\" Ethereum software distribution, originally named after the language in which it is written, C++. TurboEthereum is a large distribution of software including a number of diverse tools. This book begins with the installation instructions, before proceeding to introductions, walk-throughs and references for the various tools that make up TurboEthereum. The full software suite of TurboEthereum includes: AlethOne ( alethone , \"A1\") The mainline Ethereum desktop miner. It connects and syncs to the Ethereum network and lets you mine, and send transactions. It will also let you do pool mining. AlethZero ( alethzero , \"AZ\") The power-user Ethereum client. It connects and syncs to the Ethereum network and lets you mine, make transactions, run DApps and inspect the blockchain. It has plugins to allow arbitrary extension. ++eth ( eth ) The mainline CLI Ethereum client. Run it in the background and it will connect to the Ethereum network; you can mine, make transactions and inspect the blockchain. Mix ( mix ) The integrated development environment for DApp authoring. Quickly prototype and debug decentralised applications on the Ethereum platform. ethkey A key/wallet management tool for Ethereum keys. This lets you add, remove and change your keys as well as cold wallet device -friendly transaction inspection and signing. ethminer A standalone miner. This can be used to check how fast you can mine and will mine for you in concert with eth , geth and pyethereum . ethvm The Ethereum virtual machine emulator. You can use this to run EVM code. solc The Solidity compiler. You can use this to compile Solidity programs into assembly or machine code. rlp An serialisation/deserialisation tool for the Recursive Length Prefix format."}, {"name": "hevm", "desc": "symbolic EVM evaluator", "readme": "hevm The hevm project is an implementation of the Ethereum virtual machine (EVM) made specifically for\nsymbolic execution, unit testing and debugging of smart contracts. The hevm command line program\ncan symbolically execute smart contracts, run unit tests, interactively debug contracts while\nshowing the Solidity source, or run arbitrary EVM code. Computations can be performed using local\nstate set up in a dapp testing harness, or fetched on demand from live networks using rpc calls. It was originally developed as part of the dapptools project, and was forked to this repo by the formal methods team at the Ethereum Foundation in August\n2022. Documentation & Support User facing documentation can be found in the hevm book . We have a public matrix chat room here . Installation Static Binaries Static binaries for x86 linux and macos are available for each release . These binaries expect to be able to find the\nfollowing programs on PATH : git solc z3 cvc5 nixpkgs hevm is available in nixpkgs , and can be installed via: flakes: nix profile install nixpkgs#haskellPackages.hevm legacy: nix-env -iA haskellPackages.hevm nix flakes hevm can be installed directly from the main branch of this repo via the following command: nix profile install github:ethereum/hevm to install a specific commit you can run: nix profile install github:ethereum/hevm/<COMMIT_ID> Development We use nix to manage project dependencies. To start hacking on hevm you should first install\nnix . Once nix is installed you can run nix-shell (or nix develop if you use flakes) from the repo\nroot to enter a development shell containing all required dev dependencies. If you use direnv , then you can run direnv allow , and the shell will be automatically\nentered each time you cd in the project repo. Once in the shell you can use the usual cabal commands to build and test hevm: ```\n$ cabal build          # build the hevm library\n$ cabal build exe:hevm # build the cli binary\n$ cabal build test     # build the test binary\n$ cabal build bench    # build the benchmarks $ cabal repl lib:hevm  # enter a repl for the library\n$ cabal repl exe:hevm  # enter a repl for the cli\n$ cabal repl test      # enter a repl for the tests\n$ cabal repl bench     # enter a repl for the benchmarks $ cabal run hevm       # run the cli binary\n$ cabal run test       # run the test binary\n$ cabal run bench      # run the benchmarks run the cli binary with profiling enabled $ cabal run --enable-profiling hevm -- +RTS -s -p -RTS run the test binary with profiling enabled $ cabal run --enable-profiling test -- +RTS -s -p -RTS run the benchmarks with profiling enabled $ cabal run --enable-profiling bench -- +RTS -s -p -RTS\n``` A high level overview of the architecture can be found in architecture.md ."}, {"name": "hexbytes", "desc": "Python `bytes` subclass that decodes hex, with a readable console output", "readme": "HexBytes Python bytes subclass that decodes hex, with a readable console output Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npythom -m pip install hexbytes ```py convert from bytes to a prettier representation at the console HexBytes(b\"\\x03\\x08wf\\xbfh\\xe7\\x86q\\xd1\\xeaCj\\xe0\\x87\\xdat\\xa1'a\\xda\\xc0 \\x01\\x1a\\x9e\\xdd\\xc4\\x90\\x0b\\xf1;\")\nHexBytes('0x03087766bf68e78671d1ea436ae087da74a12761dac020011a9eddc4900bf13b') HexBytes accepts the hex string representation as well, ignoring case and 0x prefixes hb = HexBytes('03087766BF68E78671D1EA436AE087DA74A12761DAC020011A9EDDC4900BF13B')\nHexBytes('0x03087766bf68e78671d1ea436ae087da74a12761dac020011a9eddc4900bf13b') get the first byte: hb[0]\n3 show how many bytes are in the value len(hb)\n32 cast back to the basic bytes type bytes(hb)\nb\"\\x03\\x08wf\\xbfh\\xe7\\x86q\\xd1\\xeaCj\\xe0\\x87\\xdat\\xa1'a\\xda\\xc0 \\x01\\x1a\\x9e\\xdd\\xc4\\x90\\x0b\\xf1;\"\n``` Developer Setup If you would like to hack on hexbytes, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:carver/hexbytes.git\ncd hexbytes\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "hive", "desc": "Ethereum end-to-end test harness", "readme": "hive - Ethereum end-to-end test harness Hive is a system for running integration tests against Ethereum clients. Ethereum Foundation maintains two public Hive instances to check for consensus, p2p and\nblockchain compatibility: eth1 consensus, graphql and p2p tests are on https://hivetests.ethdevops.io Engine API integration and rpc tests are on https://hivetests2.ethdevops.io To read more about hive, please check the documentation . Trophies If you find a bug in your client implementation due to this project, please be so kind as\nto add it here to the trophy list. It could help prove that hive is indeed a useful tool\nfor validating Ethereum client implementations. go-ethereum: Genesis chain config couldn't handle present but empty settings: #2790 Data race between remote block import and local block mining: #2793 Downloader didn't penalize incompatible forks harshly enough: #2801 Nethermind: Bug in p2p with bonding nodes algorithm found by Hive: #1894 Difference in return value for 'r' parameter in getTransactionByHash: #2372 CREATE/CREATE2 behavior when account already has max nonce #3698 Blake2 performance issue with non-vectorized code #3837 Contributions This project takes a different approach to code contributions than your usual FOSS project\nwith well ingrained maintainers and relatively few external contributors. It is an\nexperiment. Whether it will work out or not is for the future to decide. We follow the Collective Code Construction Contract (C4) , code contribution model,\nas expanded and explained in The ZeroMQ Process . The core idea being that\nany patch that successfully solves an issue (bug/feature) and doesn't break any existing\ncode/contracts must be optimistically merged by maintainers. Followup patches may be used\nfor additional polishes \u2013 and patches may even be outright reverted if they turn out to\nhave a negative impact \u2013 but no change must be rejected based on personal values. License The hive project is licensed under the GNU General Public License v3.0 . You can\nfind it in the COPYING file."}, {"name": "homebrew-ethereum", "desc": "Homebrew Tap for Ethereum", "readme": "homebrew-ethereum Homebrew Tap for Ethereum Important note: reporting issues with any of these brews should be done at their respective repositories ( Go client and Solidity ). Installation brew tap ethereum/ethereum Go client brew install ethereum Solidity To install the latest release: brew install solidity To install the latest 0.7.x release: brew install solidity@7 To install the latest 0.6.x release: brew install solidity@6 To install the latest 0.5.x release: brew install solidity@5 To install the latest 0.4.x release: brew install solidity@4 Note: the older releases are not maintained indefinitely, but are provided as a convenience. Running Go client geth Solidity solc Development Get the latest development version with the --devel flag. Go client brew reinstall ethereum --devel Current branches Go:\n* --devel is on develop branch\n* normal install is on master branch Upgrading brew update && brew upgrade Minor updates Go client brew update && brew reinstall ethereum Versions List available versions with: ls -l /usr/local/Cellar/ethereum If you have other versions installed, you can switch with: brew switch ethereum <version> Or follow this StackOverflow answer These brews can be installed via the raw GitHub URLs, or by cloning this\nrepository locally with brew tap ethereum/ethereum . You can also install binary\nbottles directly with brew install <bottle_url> , see cpt-obvious for previous builds. Troubleshooting Use --verbose to get more info while installing. Make sure to update XCode and the command line tools. Run brew update and brew upgrade Fix what the brew doctor says. Reinstall dependencies: brew reinstall boost --c++11 --with-python Make changes to /usr/local/Library/Taps/ethereum/homebrew-ethereum/ethereum.rb Reinstall with brew reinstall ethereum.rb (send a pull request!) Take a walk Note that the ethereum keg exists in homebrew-core . It's not always up to date in homebrew-core and you might want to prioritise the version from this tap. To do this, you can pin this tap by running the following command: shell\nbrew tap-pin ethereum/ethereum Patching First cd /Library/Caches/Homebrew/ethereum--git/ and make your changes. Then git diff > shiny.patch , copy/paste the content of your patch under __END__ of ethereum.rb and replace the def patches block with: def patches\n  DATA\nend If you want to submit your change, save your patch in a gist, add your option 'shiny-option', 'Shiny description' and the URL to your gist in the patches block and submit a pull request. Make sure to send a pull request to Ethereum also!"}, {"name": "homestead-guide", "desc": null, "readme": null}, {"name": "hunter-cache", "desc": null, "readme": "Hunter Cache Hunter Package Manager Cache for Ethereum C++ projects. See documentation ."}, {"name": "interfaces", "desc": "Interface Specifications inside Ethereum", "readme": "Ethereum Interfaces This repository contains information about / specifications of interfaces between\ndifferent components of the Ethereum ecosystem and tests for those specifications. This includes (but is not limited to): the ABI the RPC specification the EVM-C interface"}, {"name": "jenkins-docker", "desc": "Docker official jenkins repo", "readme": "Official Jenkins Docker image The Jenkins Continuous Integration and Delivery server. This is a fully functional Jenkins server, based on the Long Term Support release\nhttp://jenkins-ci.org/ Usage docker run -p 8080:8080 -p 50000:50000 jenkins This will store the workspace in /var/jenkins_home. All Jenkins data lives in there - including plugins and configuration.\nYou will probably want to make that a persistent volume (recommended): docker run -p 8080:8080 -p 50000:50000 -v /your/home:/var/jenkins_home jenkins This will store the jenkins data in /your/home on the host.\nEnsure that /your/home is accessible by the jenkins user in container (jenkins user - uid 1000) or use -u some_other_user parameter with docker run . You can also use a volume container: docker run --name myjenkins -p 8080:8080 -p 50000:50000 -v /var/jenkins_home jenkins Then myjenkins container has the volume (please do read about docker volume handling to find out more). Backing up data If you bind mount in a volume - you can simply back up that directory\n(which is jenkins_home) at any time. This is highly recommended. Treat the jenkins_home directory as you would a database - in Docker you would generally put a database on a volume. If your volume is inside a container - you can use docker cp $ID:/var/jenkins_home command to extract the data, or other options to find where the volume data is.\nNote that some symlinks on some OSes may be converted to copies (this can confuse jenkins with lastStableBuild links etc) For more info check Docker docs section on Managing data in containers Setting the number of executors You can specify and set the number of executors of your Jenkins master instance using a groovy script. By default its set to 2 executors, but you can extend the image and change it to your desired number of executors : ``` executors.groovy Jenkins.instance.setNumExecutors(5)\n``` and Dockerfile FROM jenkins\nCOPY executors.groovy /usr/share/jenkins/ref/init.groovy.d/executors.groovy Attaching build executors You can run builds on the master (out of the box) but if you want to attach build slave servers: make sure you map the port: -p 50000:50000 - which will be used when you connect a slave agent. Here is an example docker container you can use as a build server with lots of good tools installed - which is well worth trying. Passing JVM parameters You might need to customize the JVM running Jenkins, typically to pass system properties or tweak heap memory settings. Use JAVA_OPTS environment \nvariable for this purpose : docker run --name myjenkins -p 8080:8080 -p 50000:50000 --env JAVA_OPTS=-Dhudson.footerURL=http://mycompany.com jenkins Configuring logging Jenkins logging can be configured through a properties file and java.util.logging.config.file Java property.\nFor example: mkdir data\ncat > data/log.properties <<EOF\nhandlers=java.util.logging.ConsoleHandler\njenkins.level=FINEST\njava.util.logging.ConsoleHandler.level=FINEST\nEOF\ndocker run --name myjenkins -p 8080:8080 -p 50000:50000 --env JAVA_OPTS=\"-Djava.util.logging.config.file=/var/jenkins_home/log.properties\" -v `pwd`/data:/var/jenkins_home jenkins Passing Jenkins launcher parameters Argument you pass to docker running the jenkins image are passed to jenkins launcher, so you can run for sample : docker run jenkins --version This will dump Jenkins version, just like when you run jenkins as an executable war. You also can define jenkins arguments as JENKINS_OPTS . This is usefull to define a set of arguments to pass to jenkins launcher as you\ndefine a derived jenkins image based on the official one with some customized settings. The following sample Dockerfile uses this option\nto force use of HTTPS with a certificate included in the image ```\nFROM jenkins:1.565.3 COPY https.pem /var/lib/jenkins/cert\nCOPY https.key /var/lib/jenkins/pk\nENV JENKINS_OPTS --httpPort=-1 --httpsPort=8083 --httpsCertificate=/var/lib/jenkins/cert --httpsPrivateKey=/var/lib/jenkins/pk\nEXPOSE 8083\n``` You can also change the default slave agent port for jenkins by defining JENKINS_SLAVE_AGENT_PORT in a sample Dockerfile. FROM jenkins:1.565.3\nENV JENKINS_SLAVE_AGENT_PORT 50001 or as a parameter to docker, docker run --name myjenkins -p 8080:8080 -p 50001:50001 --env JENKINS_SLAVE_AGENT_PORT=50001 jenkins Installing more tools You can run your container as root - and install via apt-get, install as part of build steps via jenkins tool installers, or you can create your own Dockerfile to customise, for example: ```\nFROM jenkins if we want to install via apt USER root\nRUN apt-get update && apt-get install -y ruby make more-thing-here\nUSER jenkins # drop back to the regular jenkins user - good practice\n``` In such a derived image, you can customize your jenkins instance with hook scripts or additional plugins. \nFor this purpose, use /usr/share/jenkins/ref as a place to define the default JENKINS_HOME content you\nwish the target installation to look like : FROM jenkins\nCOPY plugins.txt /usr/share/jenkins/ref/\nCOPY custom.groovy /usr/share/jenkins/ref/init.groovy.d/custom.groovy\nRUN /usr/local/bin/plugins.sh /usr/share/jenkins/ref/plugins.txt When jenkins container starts, it will check JENKINS_HOME has this reference content, and copy them there if required. It will not override such files, so if you upgraded some plugins from UI they won't be reverted on next start. Also see JENKINS-24986 For your convenience, you also can use a plain text file to define plugins to be installed (using core-support plugin format) pluginID:version\nanotherPluginID:version And in derived Dockerfile just invoke the utility plugin.sh script FROM jenkins\nCOPY plugins.txt /usr/share/jenkins/plugins.txt\nRUN /usr/local/bin/plugins.sh /usr/share/jenkins/plugins.txt Upgrading All the data needed is in the /var/jenkins_home directory - so depending on how you manage that - depends on how you upgrade. Generally - you can copy it out - and then \"docker pull\" the image again - and you will have the latest LTS - you can then start up with -v pointing to that data (/var/jenkins_home) and everything will be as you left it. As always - please ensure that you know how to drive docker - especially volume handling! Questions? Jump on irc.freenode.net and the #jenkins room. Ask!"}, {"name": "js-ethereum-cryptography", "desc": "Every cryptographic primitive needed to work on Ethereum, for the browser and Node.js", "readme": "ethereum-cryptography Audited pure JS library containing all Ethereum-related cryptographic primitives. Included algorithms, implemented with just 5 noble & scure dependencies: Hashes: SHA256, keccak-256, RIPEMD160, BLAKE2b KDFs: PBKDF2, Scrypt CSPRNG (Cryptographically Secure Pseudorandom Number Generator) secp256k1 elliptic curve BIP32 HD Keygen BIP39 Mnemonic phrases AES Encryption April 2023 update: v2.0 is out, switching noble-secp256k1 to noble-curves ,\nwhich changes re-exported api of secp256k1 submodule.\nThere have been no other changes. January 2022 update: v1.0 has been released. We've rewritten the library from\nscratch and audited it. It became 6x smaller: ~5,000 lines of\ncode instead of ~24,000 (with all deps); 650KB instead of 10.2MB.\n5 dependencies by 1 author are now used, instead of 38 by 5 authors. Check out Upgrading section and an article about the library: A safer, smaller, and faster Ethereum cryptography stack . Usage Use NPM / Yarn in node.js / browser: ```bash NPM npm install ethereum-cryptography Yarn yarn add ethereum-cryptography\n``` See browser usage for information on using the package with major Javascript bundlers. It is\ntested with Webpack, Rollup, Parcel and Browserify . This package has no single entry-point, but submodule for each cryptographic\nprimitive. Read each primitive's section of this document to learn how to use\nthem. The reason for this is that importing everything from a single file will lead to\nhuge bundles when using this package for the web. This could be avoided through\ntree-shaking, but the possibility of it not working properly on one of the supported bundlers is too high. ```js\n// Hashes\nimport { sha256 } from \"ethereum-cryptography/sha256.js\";\nimport { keccak256 } from \"ethereum-cryptography/keccak.js\";\nimport { ripemd160 } from \"ethereum-cryptography/ripemd160.js\";\nimport { blake2b } from \"ethereum-cryptography/blake2b.js\"; // KDFs\nimport { pbkdf2Sync } from \"ethereum-cryptography/pbkdf2.js\";\nimport { scryptSync } from \"ethereum-cryptography/scrypt.js\"; // Random\nimport { getRandomBytesSync } from \"ethereum-cryptography/random.js\"; // AES encryption\nimport { encrypt } from \"ethereum-cryptography/aes.js\"; // secp256k1 elliptic curve operations\nimport { secp256k1 } from \"ethereum-cryptography/secp256k1.js\"; // BIP32 HD Keygen, BIP39 Mnemonic Phrases\nimport { HDKey } from \"ethereum-cryptography/hdkey.js\";\nimport { generateMnemonic } from \"ethereum-cryptography/bip39/index.js\";\nimport { wordlist } from \"ethereum-cryptography/bip39/wordlists/english.js\"; // utilities\nimport { hexToBytes, toHex, utf8ToBytes } from \"ethereum-cryptography/utils.js\";\n``` Hashes: SHA256, keccak-256, RIPEMD160, BLAKE2b typescript\nfunction sha256(msg: Uint8Array): Uint8Array;\nfunction sha512(msg: Uint8Array): Uint8Array;\nfunction keccak256(msg: Uint8Array): Uint8Array;\nfunction ripemd160(msg: Uint8Array): Uint8Array;\nfunction blake2b(msg: Uint8Array, outputLength = 64): Uint8Array; Exposes following cryptographic hash functions: SHA2 (SHA256, SHA512) keccak-256 variant of SHA3 (also keccak224 , keccak384 ,\nand keccak512 ) RIPEMD160 BLAKE2b ```js\nimport { sha256 } from \"ethereum-cryptography/sha256.js\";\nimport { sha512 } from \"ethereum-cryptography/sha512.js\";\nimport { keccak256, keccak224, keccak384, keccak512 } from \"ethereum-cryptography/keccak.js\";\nimport { ripemd160 } from \"ethereum-cryptography/ripemd160.js\";\nimport { blake2b } from \"ethereum-cryptography/blake2b.js\"; sha256(Uint8Array.from([1, 2, 3])) // Can be used with strings\nimport { utf8ToBytes } from \"ethereum-cryptography/utils.js\";\nsha256(utf8ToBytes(\"abc\")) // If you need hex\nimport { bytesToHex as toHex } from \"ethereum-cryptography/utils.js\";\ntoHex(sha256(utf8ToBytes(\"abc\")))\n``` KDFs: PBKDF2, Scrypt ts\nfunction pbkdf2(password: Uint8Array, salt: Uint8Array, iterations: number, keylen: number, digest: string): Promise<Uint8Array>;\nfunction pbkdf2Sync(password: Uint8Array, salt: Uint8Array, iterations: number, keylen: number, digest: string): Uint8Array;\nfunction scrypt(password: Uint8Array, salt: Uint8Array, N: number, p: number, r: number, dkLen: number, onProgress?: (progress: number) => void): Promise<Uint8Array>;\nfunction scryptSync(password: Uint8Array, salt: Uint8Array, N: number, p: number, r: number, dkLen: number, onProgress?: (progress: number) => void)): Uint8Array; The pbkdf2 submodule has two functions implementing the PBKDF2 key\nderivation algorithm in synchronous and asynchronous ways. This algorithm is\nvery slow, and using the synchronous version in the browser is not recommended,\nas it will block its main thread and hang your UI. The KDF supports sha256 and sha512 digests. The scrypt submodule has two functions implementing the Scrypt key\nderivation algorithm in synchronous and asynchronous ways. This algorithm is\nvery slow, and using the synchronous version in the browser is not recommended,\nas it will block its main thread and hang your UI. Encoding passwords is a frequent source of errors. Please read these notes before using these submodules. js\nimport { pbkdf2 } from \"ethereum-cryptography/pbkdf2.js\";\nimport { utf8ToBytes } from \"ethereum-cryptography/utils.js\";\n// Pass Uint8Array, or convert strings to Uint8Array\nconsole.log(await pbkdf2(utf8ToBytes(\"password\"), utf8ToBytes(\"salt\"), 131072, 32, \"sha256\")); js\nimport { scrypt } from \"ethereum-cryptography/scrypt.js\";\nimport { utf8ToBytes } from \"ethereum-cryptography/utils.js\";\nconsole.log(await scrypt(utf8ToBytes(\"password\"), utf8ToBytes(\"salt\"), 262144, 8, 1, 32)); CSPRNG (Cryptographically strong pseudorandom number generator) ts\nfunction getRandomBytes(bytes: number): Promise<Uint8Array>;\nfunction getRandomBytesSync(bytes: number): Uint8Array; The random submodule has functions to generate cryptographically strong\npseudo-random data in synchronous and asynchronous ways. Backed by crypto.getRandomValues in browser and by crypto.randomBytes in node.js. If backends are somehow not available, the module would throw an error and won't work, as keeping them working would be insecure. js\nimport { getRandomBytesSync } from \"ethereum-cryptography/random.js\";\nconsole.log(getRandomBytesSync(32)); secp256k1 curve ts\nfunction getPublicKey(privateKey: Uint8Array, isCompressed = true): Uint8Array;\nfunction sign(msgHash: Uint8Array, privateKey: Uint8Array): { r: bigint; s: bigint; recovery: number };\nfunction verify(signature: Uint8Array, msgHash: Uint8Array, publicKey: Uint8Array): boolean\nfunction getSharedSecret(privateKeyA: Uint8Array, publicKeyB: Uint8Array): Uint8Array;\nfunction utils.randomPrivateKey(): Uint8Array; The secp256k1 submodule provides a library for elliptic curve operations on\nthe curve secp256k1. For detailed documentation, follow README of noble-curves , which the module uses as a backend. secp256k1 private keys need to be cryptographically secure random numbers with\ncertain characteristics. If this is not the case, the security of secp256k1 is\ncompromised. We strongly recommend using utils.randomPrivateKey() to generate them. js\nimport { secp256k1 } from \"ethereum-cryptography/secp256k1.js\";\n(async () => {\n  // You pass either a hex string, or Uint8Array\n  const privateKey = \"6b911fd37cdf5c81d4c0adb1ab7fa822ed253ab0ad9aa18d77257c88b29b718e\";\n  const messageHash = \"a33321f98e4ff1c283c76998f14f57447545d339b3db534c6d886decb4209f28\";\n  const publicKey = secp256k1.getPublicKey(privateKey);\n  const signature = secp256k1.sign(messageHash, privateKey);\n  const isSigned = secp256k1.verify(signature, messageHash, publicKey);\n})(); We're also providing a compatibility layer for users who want to upgrade\nfrom tiny-secp256k1 or secp256k1 modules without hassle.\nCheck out secp256k1 compatibility layer . BIP32 HD Keygen Hierarchical deterministic (HD) wallets that conform to BIP32 standard.\nAlso available as standalone package scure-bip32 . This module exports a single class HDKey , which should be used like this: ```ts\nimport { HDKey } from \"ethereum-cryptography/hdkey.js\";\nconst hdkey1 = HDKey.fromMasterSeed(seed);\nconst hdkey2 = HDKey.fromExtendedKey(base58key);\nconst hdkey3 = HDKey.fromJSON({ xpriv: string }); // props\n[hdkey1.depth, hdkey1.index, hdkey1.chainCode];\nconsole.log(hdkey2.privateKey, hdkey2.publicKey);\nconsole.log(hdkey3.derive(\"m/0/2147483647'/1\"));\nconst sig = hdkey3.sign(hash);\nhdkey3.verify(hash, sig);\n``` Note: chainCode property is essentially a private part\nof a secret \"master\" key, it should be guarded from unauthorized access. The full API is: ```ts\nclass HDKey {\n  public static HARDENED_OFFSET: number;\n  public static fromMasterSeed(seed: Uint8Array, versions: Versions): HDKey;\n  public static fromExtendedKey(base58key: string, versions: Versions): HDKey;\n  public static fromJSON(json: { xpriv: string }): HDKey; readonly versions: Versions;\n  readonly depth: number = 0;\n  readonly index: number = 0;\n  readonly chainCode: Uint8Array | null = null;\n  readonly parentFingerprint: number = 0; get fingerprint(): number;\n  get identifier(): Uint8Array | undefined;\n  get pubKeyHash(): Uint8Array | undefined;\n  get privateKey(): Uint8Array | null;\n  get publicKey(): Uint8Array | null;\n  get privateExtendedKey(): string;\n  get publicExtendedKey(): string; derive(path: string): HDKey;\n  deriveChild(index: number): HDKey;\n  sign(hash: Uint8Array): Uint8Array;\n  verify(hash: Uint8Array, signature: Uint8Array): boolean;\n  wipePrivateData(): this;\n} interface Versions {\n  private: number;\n  public: number;\n}\n``` The hdkey submodule provides a library for keys derivation according to BIP32 . It has almost the exact same API than the version 1.x of hdkey from cryptocoinjs ,\nbut it's backed by this package's primitives, and has built-in TypeScript types.\nIts only difference is that it has to be used with a named import.\nThe implementation is loosely based on hdkey, which has MIT License . BIP39 Mnemonic Seed Phrase ts\nfunction generateMnemonic(wordlist: string[], strength: number = 128): string;\nfunction mnemonicToEntropy(mnemonic: string, wordlist: string[]): Uint8Array;\nfunction entropyToMnemonic(entropy: Uint8Array, wordlist: string[]): string;\nfunction validateMnemonic(mnemonic: string, wordlist: string[]): boolean;\nasync function mnemonicToSeed(mnemonic: string, passphrase: string = \"\"): Promise<Uint8Array>;\nfunction mnemonicToSeedSync(mnemonic: string, passphrase: string = \"\"): Uint8Array; The bip39 submodule provides functions to generate, validate and use seed\nrecovery phrases according to BIP39 . Also available as standalone package scure-bip39 . js\nimport { generateMnemonic } from \"ethereum-cryptography/bip39/index.js\";\nimport { wordlist } from \"ethereum-cryptography/bip39/wordlists/english.js\";\nconsole.log(generateMnemonic(wordlist)); This submodule also contains the word lists defined by BIP39 for Czech, English,\nFrench, Italian, Japanese, Korean, Simplified and Traditional Chinese, and\nSpanish. These are not imported by default, as that would increase bundle sizes\ntoo much. Instead, you should import and use them explicitly. The word lists are exported as a wordlist variable in each of these submodules: ethereum-cryptography/bip39/wordlists/czech.js ethereum-cryptography/bip39/wordlists/english.js ethereum-cryptography/bip39/wordlists/french.js ethereum-cryptography/bip39/wordlists/italian.js ethereum-cryptography/bip39/wordlists/japanese.js ethereum-cryptography/bip39/wordlists/korean.js ethereum-cryptography/bip39/wordlists/simplified-chinese.js ethereum-cryptography/bip39/wordlists/spanish.js ethereum-cryptography/bip39/wordlists/traditional-chinese.js AES Encryption ts\nfunction encrypt(msg: Uint8Array, key: Uint8Array, iv: Uint8Array, mode = \"aes-128-ctr\", pkcs7PaddingEnabled = true): Promise<Uint8Array>;\nfunction decrypt(cypherText: Uint8Array, key: Uint8Array, iv: Uint8Array, mode = \"aes-128-ctr\", pkcs7PaddingEnabled = true): Promise<Uint8Array>; The aes submodule contains encryption and decryption functions implementing\nthe Advanced Encryption Standard algorithm. Encrypting with passwords AES is not supposed to be used directly with a password. Doing that will\ncompromise your users' security. The key parameters in this submodule are meant to be strong cryptographic\nkeys. If you want to obtain such a key from a password, please use a key derivation function like pbkdf2 or scrypt . Operation modes This submodule works with different block cipher modes of operation . If you are using this module in a new\napplication, we recommend using the default. While this module may work with any mode supported by OpenSSL, we only test it\nwith aes-128-ctr , aes-128-cbc , and aes-256-cbc . If you use another module\na warning will be printed in the console. We only recommend using aes-128-cbc and aes-256-cbc to decrypt already\nencrypted data. Padding plaintext messages Some operation modes require the plaintext message to be a multiple of 16 . If\nthat isn't the case, your message has to be padded. By default, this module automatically pads your messages according to PKCS#7 .\nNote that this padding scheme always adds at least 1 byte of padding. If you\nare unsure what anything of this means, we strongly recommend you to use\nthe defaults. If you need to encrypt without padding or want to use another padding scheme,\nyou can disable PKCS#7 padding by passing false as the last argument and\nhandling padding yourself. Note that if you do this and your operation mode\nrequires padding, encrypt will throw if your plaintext message isn't a\nmultiple of 16 . This option is only present to enable the decryption of already encrypted data.\nTo encrypt new data, we recommend using the default. How to use the IV parameter The iv parameter of the encrypt function must be unique, or the security\nof the encryption algorithm can be compromised. You can generate a new iv using the random module. Note that to decrypt a value, you have to provide the same iv used to encrypt\nit. How to handle errors with this module Sensitive information can be leaked via error messages when using this module.\nTo avoid this, you should make sure that the errors you return don't\ncontain the exact reason for the error. Instead, errors must report general\nencryption/decryption failures. Note that implementing this can mean catching all errors that can be thrown\nwhen calling on of this module's functions, and just throwing a new generic\nexception. Example usage ```js\nimport { encrypt } from \"ethereum-cryptography/aes.js\";\nimport { hexToBytes, utf8ToBytes } from \"ethereum-cryptography/utils.js\"; console.log(\n  encrypt(\n    utf8ToBytes(\"message\"),\n    hexToBytes(\"2b7e151628aed2a6abf7158809cf4f3c\"),\n    hexToBytes(\"f0f1f2f3f4f5f6f7f8f9fafbfcfdfeff\")\n  )\n);\n``` Browser usage Rollup setup Using this library with Rollup requires the following plugins: @rollup/plugin-commonjs @rollup/plugin-node-resolve These can be used by setting your plugins array like this: js\n  plugins: [\n    commonjs(),\n    resolve({\n      browser: true,\n      preferBuiltins: false,\n    }),\n  ] Legacy secp256k1 compatibility layer Warning: use secp256k1 instead. This module is only for users who upgraded\nfrom ethereum-cryptography v0.1. It could be removed in the future. The API of secp256k1-compat is the same as secp256k1-node : js\nimport { createPrivateKeySync, ecdsaSign } from \"ethereum-cryptography/secp256k1-compat\";\nconst msgHash = Uint8Array.from(\n  \"82ff40c0a986c6a5cfad4ddf4c3aa6996f1a7837f9c398e17e5de5cbd5a12b28\",\n  \"hex\"\n);\nconst privateKey = createPrivateKeySync();\nconsole.log(Uint8Array.from(ecdsaSign(msgHash, privateKey).signature)); Missing cryptographic primitives This package intentionally excludes the cryptographic primitives necessary\nto implement the following EIPs: EIP 196: Precompiled contracts for addition and scalar multiplication on the elliptic curve alt_bn128 EIP 197: Precompiled contracts for optimal ate pairing check on the elliptic curve alt_bn128 EIP 198: Big integer modular exponentiation EIP 152: Add Blake2 compression function F precompile Feel free to open an issue if you want this decision to be reconsidered, or if\nyou found another primitive that is missing. Upgrading Upgrading from 1.0 to 2.0: secp256k1 module was changed massively:\n  before, it was using noble-secp256k1 1.7 ;\n  now it uses safer noble-curves . Please refer\n  to upgrading section from curves README .\n  Main changes to keep in mind: a) sign now returns Signature instance\n  b) recoverPublicKey got moved onto a Signature instance node.js 14 and older support was dropped. Upgrade to node.js 16 or later. Upgrading from 0.1 to 1.0: Same functionality , all old APIs remain the same except for the breaking changes: We return Uint8Array from all methods that worked with Buffer before. Buffer has never been supported in browsers, while Uint8Array s are supported natively in both\nbrowsers and node.js. We target runtimes with bigint support,\nwhich is Chrome 67+, Edge 79+, Firefox 68+, Safari 14+, node.js 10+. If you need to support older runtimes, use ethereum-cryptography@0.1 If you've used secp256k1 , rename it to secp256k1-compat ```js\nimport { sha256 } from \"ethereum-cryptography/sha256.js\"; // Old usage\nconst hasho = sha256(Buffer.from(\"string\", \"utf8\")).toString(\"hex\"); // New usage\nimport { toHex } from \"ethereum-cryptography/utils.js\";\nconst hashn = toHex(sha256(\"string\")); // If you have Buffer module and want to preserve it:\nconst hashb = Buffer.from(sha256(\"string\"));\nconst hashbo = hashb.toString(\"hex\");\n``` Security Audited by Cure53 on Jan 5, 2022. Check out the audit PDF & URL . License ethereum-cryptography is released under The MIT License (MIT) Copyright (c) 2021 Patricio Palladino, Paul Miller, ethereum-cryptography contributors See LICENSE file. hdkey is loosely based on hdkey ,\nwhich had MIT License Copyright (c) 2018 cryptocoinjs"}, {"name": "js-team-organization", "desc": "EF JavaScript Team Organisation", "readme": "EF JavaScript Team Organisation Organisational repository of the Ethereum Foundation JavaScript team. The team currently encompasses the following projects: Ethers.js EthereumJS See our roadmap for an overview on what we are up to and use\nour public Discord server if you want to reach out. If you have a suggestion on how we can improve team organization, technical\nprocedures or project interoperability feel free to open an issue or join an\nexisting discussion."}, {"name": "keymanager-APIs", "desc": "Collection of RESTful APIs provided by Ethereum consensus keymanagers", "readme": "Ethereum keymanager APIs Warning: Super fresh repo, expect rapid iteration and breaking changes Collection of RESTful APIs provided by Ethereum consensus keymanagers API browser: https://ethereum.github.io/keymanager-APIs/ Outline This document outlines an application programming interface (API) which is exposed by a validator client implementation\nwhich aims to facilitate validator management tools without sacrificing security. The API is a REST interface, accessed via HTTP. The API should not, unless protected by additional security layers,\nbe exposed to the public Internet as the API includes multiple endpoints which can control the state of a deployed validator (e.g. Exits, etc).\nCurrently, the only supported return data type is JSON. The validator client (VC) maintains private information-related validators such as keys and an anti-slashing database.\nA VC is also in charge of signing messages related to validation duties (e.g. Attestations, and Beacon Blocks) as well as state changes (e.g. Exits). The goal of this specification is to promote interoperability between various validator client implementations to aid in the creation of common validator management tools\nsuch as GUIs, alerts, etc. Client Support Learn about the Consensus Validator Clients that implement these APIs on the Ethereum.org v1 APIS | Validator Client/Remote Managers | local keymanager | remote keymanager | fee recipient | gas limit  | graffiti |\n| -------------------------------- | ---------------- | ----------------- | ------------- | ---------- | -------- |\n| Prysm                            | production       | production        | production    | production | -        |\n| Teku                             | production       | production        | production    | production | -        |\n| Lighthouse                       | v2.1.2           | v2.3.0            | v2.4.0        | v3.0.0     | -        |\n| Nimbus                           | production       | production        | 22.7.0        | -          | -        |\n| Lodestar                         | v0.35.0          | v0.40.0           | v1.2.0        | v1.2.0     | v1.12.0  |\n| Web3signer                       | production       | N/A               | N/A           | N/A        | N/A      | Use Cases High-level information on how each API endpoint is used are listed in the Use-cases Doc Flows Further detail on expected behavior and error states of the APIs are listed in the Flows Doc Running API Browser Locally To render the spec in a browser you will need an HTTP server to serve the index.html file.\nRendering occurs client-side in JavaScript, so no changes are required to the HTML file between\nedits. Python python2 -m SimpleHTTPServer 8080 The API spec will render on http://localhost:8080 . NodeJs ```\nnpm install simplehttpserver -g OR yarn global add simplehttpserver simplehttpserver\n``` The API spec will render on http://localhost:8000 . Contributing The API spec is linted for issues before PRs are merged. To run the linter locally, install spectral : ```\nnpm install -g @stoplight/spectral OR yarn global add @stoplight/spectral\n``` and run with spectral lint keymanager-oapi.yaml Releasing Create and push a tag Make sure info.version in keymanager-oapi.yaml file is updated before tagging. CD will create github release and upload bundled spec file Add release entrypoint in index.html In SwaggerUIBundle configuration (inside index.html file), add another entry in \"urls\" field (SwaggerUI will load first item as default).\nEntries should be in the following format (replace <tag> with the real tag name from step 1): javascript\n         {url: \"https://github.com/ethereum/keymanager-APIs/releases/download/<tag>/keymanager-oapi.yaml\", name: \"<tag>\"},"}, {"name": "kzg-ceremony", "desc": "Resources and documentation related to the ongoing Ethereum KZG Ceremony.", "readme": "Summary The KZG Ceremony is a coordinated public ritual which will provide a cryptographic foundation for Ethereum scaling initiatives. From the specs repo: The ceremony takes place between participants and the sequencer. Participants are the entities that contribute their secret randomness to the final output \ud835\udf0f s. The role of the sequencer is to act as the common point of interaction for all participants as well as verifying participants' contribution as the ceremony progresses. The ceremony is designed to have the following characteristics: wide ecosystem participation browser accessible a meaningful narrative in a simple interface easy to audit transcript The best place to follow along is the KZG Ceremony channel in the Ethereum R&D Discord or the bridged telegram channel - DM one of the contributors to be added to either. Resources KZG Ceremony FAQ How do trusted setups work? EIP-4844 Proto-Danksharding FAQ KZG polynomial commitments KZG Ceremony Timeline Spec Repo Frontend Repo Audits SECBIT Spec + Implementation Audit - Aug 2022 Sigma Prime Sequencer Audit - Jan 2023 Client Implementations There are a number of independent implementations interested Ceremony participants can try to run locally, will have a variety of different features. (no guarantees on the quality or completeness!) CLI Interfaces | Implementation | BLS Library | Language | License| Author| Notes |\n| :- | :- | :- | :- | :- | :- |\n| Chotto | blst ( jblst ) | Java | Apache 2.0 | Stefan Bratanov (@StefanBratanov) ||\n| go-kzg-ceremony-client | gnark-crypto| Go | MIT| Ignacio Hagopian (@jsign)| Features: transcript verification, using additional external sources of entropy, eg. drand network, an arbitrary URL provided by the user. Note: double signing not supported due to lack of hash-to-curve in gnark. |\n| eth-KZG-ceremony-alt | kilic | Go | GPL-3.0| Arnaucube (@arnaucube)| \n| Towers of Pau | blst | Go | MIT| Daniel Knopik (@dknopik), Marius van der Wijden (@MariusVanDerWijden) | Linux only, no signatures. |\n| cpp-kzg-ceremony-client | blst | C++ | AGPL-3.0 | Patrice Vignola (@PatriceVignola) | Features: BLS/ECDSA signing, transcript verification, Linux/Windows/MacOS support |\n| czg-keremony | noble-curves | JavaScript | MIT | JoonKyo Kim (@rootwarp),  HyungGi Kim (@kim201212) |  |\n| kzg-ceremony-client | blst | C# | MIT | Alexey (@flcl42), CheeChyuan (@chee-chyuan), Michal (@mpzajac), Jorge (@jmederosalvarado), Prince (@prix0007) | | Browser Interfaces | Interface| BLS Library | License | Author | IPFS| Repository| Notes|\n| :- | :- | :- | :- | :- | :- | :- |\n| ZKParty Frontend | Arkworks|| Several | latest.kzgceremony.eth | trusted-setup-frontend | References the latest version of the interface, which departs from the audited version in minor ways |\n| ZKParty Frontend (Audit Commit) | Arkworks| | Several | [1] audit.kzgceremony.eth | trusted-setup-frontend | The exact interface which Sigma Prime audited in November 2022. May have minor bugs or differences from the latest version above. docker instructions |\n| Doge KZG | gnark | MIT | Andrew Davis (@Savid) | [2] | dogekzg | \ud83d\udc36| audit: QmevfvaP3nR5iMncWKa55B2f5mUgTAw9oDjFovD3XNrJTV doge: QmRs83zAU1hEnPHeeSKBUa58kLiWiwkjG3rJCmB8ViTcSU BLS Libraries | Library| Language | License | Audit |\n| :- | :- | :- | :- |\n| blst | C & assembly | Apache 2.0| Audit Report , [WIP] Formal Verification |\n| Arkworks | Rust | Apache 2.0, MIT | | \n| gnark-crypto | Go & assembly| Apache 2.0| Audit Report |\n| kilic | Go | Apache 2.0| |\n| Herumi BLS | C++ & assembly | modified BSD | Technical Assessment |\n| Constantine | Nim | Apache 2.0 | |\n| py_ecc | Python | MIT | |\n| matterlabs/EIP1962 | Rust | Apache 2.0 | |\n| noble-curves | TypeScript/JS | MIT | | Special Contributions April 1-16 2023 was the Special Contribution Period for the KZG Ceremony. This allowed participants to contribute in ways that may not have been possible in the Open Contribution period. While the Ceremony only needs a single honest participant to provide a secure output, Special Contributions provide additional assurances beyond a standard entropy contribution: computing over the entropy in an isolated environment (eg. on an airgapped machine, wiping and physically destroying hardware) means it's unlikely for a malicious entity to have extracted the entropy at any point detailed documentation (explore links below) attached to real reputations are unlikely to all have been coopted or faked by a malicious coordinating entity. The records are available for future observers to explore. different hardware and software limits correlated risk differentiated entropy generation (eg. measuring an explosion) prevents the Ceremony output being compromised by some failure in the regular entropy generation (eg. the hosted interface) contributions involving large groups of people are harder to fake than those with only one person This post is a public record of the Special Contributions with information on methodology, where to find them in the transcript, and links to documenting media. 00 - Cryptosat 01 - The KZG Marble Machine 02 - Mr. Moloch's Ephemeral Album II 03 - Dog Dinner Dance Dynamics 04 - CZG-Keremony - a pure JS KZG ceremony client 05 - Improvised Theatre 06 - A Calculating Car 07 - A noisy city 08 - Exothermic Entropy 09 - The Sferic Project 10 - The Great Belgian Beer Entropy Caper 11 - KZGamer - summoning Dankshard with a dice-tower 12 - Catropy 13 - srsly - an iOS KZG Ceremony client Media | Title | Venue | Participants | Release Date |\n| :- | :-- | :--| --: |\n| KZG Ceremony Duo Summons The Ethereum Road Map | The Defiant | Tegan Kline, Carl Beekhuizen, Trent Van Epps | April 2023|\n| Episode 262: Ethereum\u2019s KZG Ceremony with Trent & Carl | Zero Knowledge | Anna Rose, Kobi Gurkan, Carl Beekhuizen, Trent Van Epps | Feb 2023|\n| Ethereum's KZG Ceremony | Bankless | David Hoffman, Trent Van Epps, Carl Beekhuizen | Jan 2023 | \n| Peep an EIP - KZG Ceremony | EthCatHerders | Pooja Ranjan, Carl Beekhuizen | Jan 2023 | \n| Ethereum Foundation \u2013 EIP-4844 & KZG Ceremony | Epicenter | Friederike Ernst, Trent Van Epps, Carl Beekhuizen| Jan 2023 |\n| Building the KZG Ceremony | PSE Learn and Share | Nico Serrano, Geoff Lamperd | Dec 2022 |\n| The KZG Ceremony - or How I Learnt to Stop Worrying and Love Trusted Setups | Devcon | Carl Beekhuizen | Oct 2022 | Public Calls | Call # |Link | Date |\n| -: | -: | -: |\n|1 | Agenda/Recording |June 9 2022 |\n|2 | Agenda/Recording | June 23 2022 |\n|3 | Agenda/Recording |July 7 2022 |\n|4 | Agenda/Recording | July 21 2022 |\n|5 | Agenda/Recording | Aug 4 2022 |\n|6 | Agenda/Recording |Aug 18 2022 |\n|7 | Agenda/Recording |Sept 1 2022 |\n|8 | Agenda/Recording | Sept 15 2022 |\n|9 | Agenda/Recording | Sept 29 2022 |"}, {"name": "kzg-ceremony-sequencer", "desc": null, "readme": null}, {"name": "kzg-ceremony-specs", "desc": "Specs for Ethereum's KZG Powers of Tau Ceremony", "readme": "Powers of Tau Specification These documents comprise a specification for Ethereum's Powers of Tau (PoT) setup for use in KZG commitments in EIP-4844 (Proto-Danksharding) and ultimately Full Danksharding . The ceremony takes place between participants and the sequencer . Participants are the entities that contribute their secret randomness to the final output $\\tau$ s. The role of the sequencer is to act as the common point of interaction for all participants as well as verifying participants' contribution as the ceremony progresses. Table of contents 10,000 ft Overview Cryptography BLS SDK Contributions Object Definitions Sequencer Requirements Contributor Qualification Contribution Queuing API Definition (Open API + JSON Schema) Participant/Client Requirements API Lifecycle Initialization 10,000 ft Overview We are performing a ceremony to generate Powers of Tau for KZG proofs on Ethereum. The output of the ceremony consists of 4 (distinct) sets of Powers of Tau each with a different maximum power:\n1. $([\\tau_1^0]_1, [\\tau_1^1]_1, \\dots, [\\tau_1^{2^{12}-1}]_1])$, $([\\tau_1^0]_2, [\\tau_1^1]_2, \\dots, [\\tau_1^{64}]_2])$\n2. $([\\tau_2^0]_1, [\\tau_2^1]_1, \\dots, [\\tau_2^{2^{13}-1}]_1])$, $([\\tau_2^0]_2, [\\tau_2^1]_2, \\dots, [\\tau_2^{64}]_2])$\n3. $([\\tau_3^0]_1, [\\tau_3^1]_1, \\dots, [\\tau_3^{2^{14}-1}]_1])$, $([\\tau_3^0]_2, [\\tau_3^1]_2, \\dots, [\\tau_3^{64}]_2])$\n4. $([\\tau_4^0]_1, [\\tau_4^1]_1, \\dots, [\\tau_4^{2^{15}-1}]_1])$, $([\\tau_4^0]_2, [\\tau_4^1]_2, \\dots, [\\tau_4^{64}]_2])$ BLS Cryptography Due to a lack of standardisation for a complete API for BLS curves, we define our own in BLS.md . Contributions Due to the simplicity of this PoT setup, the full contribution is sent as a json file between the sequencer & participants. This allows the use of a RESTful API between the two. See contribution documentation for\nthe contribution format requirements. Initialization The ceremony is initialized to initialContribution.json ."}, {"name": "kzg-ceremony-verifier", "desc": null, "readme": "KZG Ceremony Verifier Description This is a tool for verifying the output of the Ethereum KZG Ceremony as well as transforming the output into a usable form for the various KZG libraries. Installation Clone the repository and navigate to its directory: bash\ngit clone git@github.com:ethereum/kzg-ceremony-verifier.git\ncd kzg-ceremony-verifier Build the project: bash\ncargo build --release Normal Usage Run the executable from the target/release directory. bash\n./target/release/kzg-ceremony-verifier This will download the transcript from the sequencer, verify all the powers, check the contribution witnesses. If the above succeeds, it will save the ceremony output to ./output_setups/trusted_setup_#.json . Advanced Usage Command-Line Arguments The executable can be customised by supplying CLI arguments. bash\n./target/release/kzg-ceremony-verifier [OPTIONS] ```text\n--url Specifies the URL from which to download the transcript.\nDefault: https://seq.ceremony.ethereum.org/info/current_state --transcript-path Specifies the path to save the downloaded transcript.\nDefault: transcript.json --output-folder Specifies the folder to save the individual setups after verification.\nDefault: ./output_setups --ceremony-sizes Specifies the sizes of the ceremonies in the format 'ceremony1_g1_size,ceremony1_g2_size ceremony2_g1_size,ceremony2_g2_size ...'.\nDefault: 4096,65 8192,65 16384,65 32768,65 ```"}, {"name": "lahja", "desc": "Lahja is a generic multi process event bus implementation written in Python 3.6+ to enable lightweight inter-process communication, based on non-blocking asyncio", "readme": "Lahja Documentation hosted by ReadTheDocs DISCLAIMER: This is alpha state software. Expect bugs. Lahja is a generic event bus implementation written in Python 3.6+ that enables lightweight inter-process communication, based on non-blocking asynchronous IO What is this for? Lahja is tailored around one primary use case: enabling multi process Python applications to communicate via events between processes using non-blocking APIs\nbased on asyncio or trio. Key facts: non-blocking APIs using asynchronous IO (asyncio / trio) lightweight with zero dependencies simple to use easy multicasting of events (one event, many independent receivers) easy event routing (e.g route event X only to certain receivers) multiple consuming APIs to adapt to different use cases and styles Developer Setup If you would like to hack on lahja, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone https://github.com/ethereum/lahja\ncd lahja\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 lahja/ tests/ -c \"clear; flake8 lahja tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on lahja failed'\" ../tests ../lahja Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "langlab", "desc": null, "readme": "Ethereum Language Lab This repository contains an MPS project for experimenting with languages for Ethereum. Prerequisites/Install Install MPS 2017.2 from http://jetbrains.com/mps Run ./gradlew setup Run ./gradlew"}, {"name": "legacytests", "desc": null, "readme": "Ethereum Legacy Consensus Tests Legacy tests for all clients to test against. Test execution tool: https://github.com/ethereum/retesteth"}, {"name": "leveldb", "desc": "Bitcoin's LevelDB branch", "readme": "leveldb: A key-value store\nAuthors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com) The code under this directory implements a system for maintaining a\npersistent key/value store. See doc/index.html for more explanation.\nSee doc/impl.html for a brief overview of the implementation. The public interface is in include/*.h.  Callers should not include or\nrely on the details of any other header files in this package.  Those\ninternal APIs may be changed without warning. Guide to header files: include/db.h\n    Main interface to the DB: Start here include/options.h\n    Control over the behavior of an entire database, and also\n    control over the behavior of individual reads and writes. include/comparator.h\n    Abstraction for user-specified comparison function.  If you want\n    just bytewise comparison of keys, you can use the default comparator,\n    but clients can write their own comparator implementations if they\n    want custom ordering (e.g. to handle different character\n    encodings, etc.) include/iterator.h\n    Interface for iterating over data. You can get an iterator\n    from a DB object. include/write_batch.h\n    Interface for atomically applying multiple updates to a database. include/slice.h\n    A simple module for maintaining a pointer and a length into some\n    other byte array. include/status.h\n    Status is returned from many of the public interfaces and is used\n    to report success and various kinds of errors. include/env.h\n    Abstraction of the OS environment.  A posix implementation of\n    this interface is in util/env_posix.cc include/table.h\ninclude/table_builder.h\n    Lower-level modules that most clients probably won't use directly"}, {"name": "libethereum", "desc": "Former home of libethereum (part of cpp-ethereum)", "readme": "Former home of libethereum (part of cpp-ethereum) cpp-ethereum is the Ethereum C++ client. This repository was a sub-module used within the webthree-umbrella repo between October 2015 and August 2016. The code formerly developed in this repo has been merged back into cpp-ethereum as of August 2016. Please do not create pull-requests against this repository.  It is no longer in-use."}, {"name": "libsnark", "desc": "C++ library for zkSNARKs", "readme": "libsnark: a C++ library for zkSNARK proofs Authors The libsnark library is developed by the SCIPR Lab project and contributors\nand is released under the MIT License (see the LICENSE file). Copyright (c) 2012-2014 SCIPR Lab and contributors (see AUTHORS file). [TOC] Overview This library implements zkSNARK schemes, which are a cryptographic method\nfor proving/verifying, in zero knowledge, the integrity of computations. A computation can be expressed as an NP statement, in forms such as the following: \"The C program foo , when executed, returns exit code 0 if given the input bar and some additional input qux .\" \"The Boolean circuit foo is satisfiable by some input qux .\" \"The arithmetic circuit foo accepts the partial assignment bar , when extended into some full assignment qux .\" \"The set of constraints foo is satisfiable by the partial assignment bar , when extended into some full assignment qux .\" A prover who knows the witness for the NP statement (i.e., a satisfying input/assignment) can produce a short proof attesting to the truth of the NP statement. This proof can be verified by anyone, and offers the following properties. Zero knowledge: the verifier learns nothing from the proof beside the truth of the statement (i.e., the value qux , in the above examples, remains secret). Succinctness: the proof is short and easy to verify. Non-interactivity: the proof is a string (i.e. it does not require back-and-forth interaction between the prover and the verifier). Soundness: the proof is computationally sound (i.e., it is infeasible to fake a proof of a false NP statement). Such a proof system is also called an argument . Proof of knowledge: the proof attests not just that the NP statement is true, but also that the\n    prover knows why (e.g., knows a valid qux ). These properties are summarized by the zkSNARK acronym, which stands for Zero-Knowledge Succinct Non-interactive ARgument of Knowledge (though zkSNARKs are also knows as succinct non-interactive computationally-sound zero-knowledge proofs of knowledge ).\nFor formal definitions and theoretical discussions about these, see\n[BCCT12], [BCIOP13], and the references therein. The libsnark library currently provides a C++ implementation of: General-purpose proof systems: A preprocessing zkSNARK for the NP-complete language \"R1CS\"\n    ( Rank-1 Constraint Systems ), which is a language that is similar to arithmetic\n    circuit satisfiability. A preprocessing SNARK for a language of arithmetic circuits, \"BACS\"\n   ( Bilinear Arithmetic Circuit Satisfiability ). This simplifies the writing\n   of NP statements when the additional flexibility of R1CS is not needed.\n   Internally, it reduces to R1CS. A preprocessing SNARK for the language \"USCS\"\n   ( Unitary-Square Constraint Systems ). This abstracts and implements the core\n   contribution of [DFGK14] A preprocessing SNARK for a language of Boolean circuits, \"TBCS\"\n   ( Two-input Boolean Circuit Satisfiability ). Internally, it reduces to USCS.\n   This is much more  efficient than going through R1CS. ADSNARK, a preprocessing SNARKs for proving statements on authenticated\n   data, as described in [BBFR15]. Proof-Carrying Data (PCD). This uses recursive composition of SNARKs, as\n   explained in [BCCT13] and optimized in [BCTV14b]. Gadget libraries (gadgetlib1 and gadgetlib2) for constructing R1CS\n    instances out of modular \"gadget\" classes. Examples of applications that use the above proof systems to prove\n    statements about: Several toy examples. Execution of TinyRAM machine code, as explained in [BCTV14a] and\n   [BCGTV13]. (Such machine code can be obtained, e.g., by compiling from C.)\n   This is easily adapted to any other Random Access Machine that satisfies a\n   simple load-store interface. A scalable for TinyRAM using Proof-Carrying Data, as explained in [BCTV14b] Zero-knowldge cluster MapReduce, as explained in [CTV15]. The zkSNARK construction implemented by libsnark follows, extends, and\noptimizes the approach described in [BCTV14], itself an extension of\n[BCGTV13], following the approach of [BCIOP13] and [GGPR13]. An alternative\nimplementation of the basic approach is the Pinocchio system of [PGHR13].\nSee these references for discussions of efficiency aspects that arise in\npractical use of such constructions, as well as security and trust\nconsiderations. This scheme is a preprocessing zkSNARK ( ppzkSNARK ): before proofs can be\ncreated and verified, one needs to first decide on a size/circuit/system\nrepresenting the NP statements to be proved, and run a generator algorithm to\ncreate corresponding public parameters (a long proving key and a short\nverification key). Using the library involves the following high-level steps: Express the statements to be proved as an R1CS (or any of the other\n    languages above, such as arithmetic circuits, Boolean circuits, or TinyRAM).\n    This is done by writing C++ code that constructs an R1CS, and linking this code\n    together with libsnark Use libsnark's generator algorithm to create the public parameters for this\n    statement (once and for all). Use libsnark's prover algorithm to create proofs of true statements about\n    the satisfiability of the R1CS. Use libsnark's verifier algorithm to check proofs for alleged statements. The NP-complete language R1CS The ppzkSNARK supports proving/verifying membership in a specific NP-complete\nlanguage: R1CS ( rank-1 constraint systems ). An instance of the language is\nspecified by a set of equations over a prime field F, and each equation looks like:\n                   < A, (1,X) > * < B , (1,X) > = < C, (1,X) >\nwhere A,B,C are vectors over F, and X is a vector of variables. In particular, arithmetic (as well as boolean) circuits are easily reducible to\nthis language by converting each gate into a rank-1 constraint. See [BCGTV13]\nAppendix E (and \"System of Rank 1 Quadratic Equations\") for more details about this. Elliptic curve choices The ppzkSNARK can be instantiated with different parameter choices, depending on\nwhich elliptic curve is used. The libsnark library currently provides three\noptions: \"edwards\":\n   an instantiation based on an Edwards curve, providing 80 bits of security. \"bn128\":\n   an instantiation based on a Barreto-Naehrig curve, providing 128\n   bits of security. The underlying curve implementation is\n   [ate-pairing], which has incorporated our patch that changes the\n   BN curve to one suitable for SNARK applications. This implementation uses dynamically-generated machine code for the curve\n    arithmetic. Some modern systems disallow execution of code on the heap, and\n    will thus block this implementation. For example, on Fedora 20 at its default settings, you will get the error zmInit ERR:can't protect when running this code. To solve this,\nrun sudo setsebool -P allow_execheap 1 to allow execution,\nor use make CURVE=ALT_BN128 instead. \"alt_bn128\":\n   an alternative to \"bn128\", somewhat slower but avoids dynamic code generation. Note that bn128 requires an x86-64 CPU while the other curve choices\nshould be architecture-independent; see portability . Gadget libraries The libsnark library currently provides two libraries for conveniently constructing\nR1CS instances out of reusable \"gadgets\". Both libraries provide a way to construct\ngadgets on other gadgets as well as additional explicit equations. In this way,\ncomplex R1CS instances can be built bottom up. gadgetlib1 This is a low-level library which expose all features of the preprocessing\nzkSNARK for R1CS. Its design is based on templates (as does the ppzkSNARK code)\nto efficiently support working on multiple elliptic curves simultaneously. This\nlibrary is used for most of the constraint-building in libsnark, both internal\n(reductions and Proof-Carrying Data) and examples applications. gadgetlib2 This is an alternative library for constructing systems of polynomial equations\nand, in particular, also R1CS instances. It is better documented and easier to\nuse than gadgetlib1, and its interface does not use templates. However, fewer\nuseful gadgets are provided. Security The theoretical security of the underlying mathematical constructions, and the\nrequisite assumptions, are analyzed in detailed in the aforementioned research\npapers. **\nThis code is a research-quality proof of concept, and has not\nyet undergone extensive review or testing. It is thus not suitable,\nas is, for use in critical or production systems.\n** Known issues include the following: The ppzkSNARK's generator and prover exhibit data-dependent running times\n  and memory usage. These form timing and cache-contention side channels,\n  which may be an issue in some applications. Randomness is retrieved from /dev/urandom, but this should be\n  changed to a carefully considered (depending on system and threat\n  model) external, high-quality randomness source when creating\n  long-term proving/verification keys. Build instructions The libsnark library relies on the following: C++ build environment GMP for certain bit-integer arithmetic libprocps for reporting memory usage GTest for some of the unit tests So far we have tested these only on Linux, though we have been able to make the library work,\nwith some features disabled (such as memory profiling or GTest tests), on Windows via Cygwin\nand on Mac OS X. (If you succeed in achieving more complete ports of the library, please\nlet us know!) See also the notes on portability below. For example, on a fresh install of Ubuntu 14.04, install the following packages: $ sudo apt-get install build-essential git libgmp3-dev libprocps3-dev libgtest-dev python-markdown libboost-all-dev libssl-dev Or, on Fedora 20: $ sudo yum install gcc-c++ make git gmp-devel procps-ng-devel gtest-devel python-markdown Run the following, to fetch dependencies from their GitHub repos and compile them.\n(Not required if you set CURVE to other than the default BN128 and also set NO_SUPERCOP=1 .) $ ./prepare-depends.sh Then, to compile the library, tests, profiling harness and documentation, run: $ make To create just the HTML documentation, run $ make doc and then view the resulting README.html (which contains the very text you are reading now). To create Doxygen documentation summarizing all files, classes and functions,\nwith some (currently sparse) comments, install the doxygen and graphviz packages, then run $ make doxy (this may take a few minutes). Then view the resulting doxygen/index.html . Using libsnark as a library To develop an application that uses libsnark, you could add it within the libsnark directory tree and adjust the Makefile, but it is far better to build libsnark as a (shared or static) library. You can then write your code in a separate directory tree, and link it against libsnark. To build just the shared object library libsnark.so , run: $ make lib To build just the static library libsnark.a , run: $ make lib STATIC=1 Note that static compilation requires static versions of all libraries it depends on.\nIt may help to minize these dependencies by appending CURVE=ALT_BN128 NO_PROCPS=1 NO_GTEST=1 NO_SUPERCOP=1 . On Fedora 21, the requisite \nlibrary RPM dependencies are then: boost-static glibc-static gmp-static libstdc++-static openssl-static zlib-static\n boost-devel glibc-devel gmp-devel gmp-devel libstdc++-devel openssl-devel openssl-devel . To build and install the libsnark library: $ make install PREFIX=/install/path This will install libsnark.so into /install/path/lib ; so your application should be linked using -L/install/path/lib -lsnark . It also installs the requisite headers into /install/path/include ; so your application should be compiled using -I/install/path/include . In addition, unless you use NO_SUPERCOP=1 , libsupercop.a will be installed and should be linked in using -lsupercop . Building on Windows using Cygwin Install Cygwin using the graphical installer, including the g++ , libgmp and git packages. Then disable the dependencies not easily supported under CygWin,\nusing: $ make NO_PROCPS=1 NO_GTEST=1 NO_DOCS=1 Building on Mac OS X On Mac OS X, install GMP from MacPorts ( port install gmp ). Then disable the\ndependencies not easily supported under CygWin, using: $ make NO_PROCPS=1 NO_GTEST=1 NO_DOCS=1 MacPorts does not write its libraries into standard system folders, so you\nmight need to explicitly provide the paths to the header files and libraries by\nappending CXXFLAGS=-I/opt/local/include LDFLAGS=-L/opt/local/lib to the line\nabove. Similarly, to pass the paths to ate-pairing you would run INC_DIR=-I/opt/local/include LIB_DIR=-L/opt/local/lib ./prepare-depends.sh instead of ./prepare-depends.sh above. Tutorials libsnark includes a tutorial, and some usage examples, for the high-level API. src/gadgetlib1/examples1 contains a simple example for constructing a\n  constraint system using gadgetlib1. src/gadgetlib2/examples contains a tutorial for using gadgetlib2 to express\n  NP statements as constraint systems. It introduces basic terminology, design\n  overview, and recommended programming style. It also shows how to invoke\n  ppzkSNARKs on such constraint systems. The main file, tutorial.cpp , builds\n  into a standalone executable. src/zk_proof_systems/ppzksnark/r1cs_ppzksnark/profiling/profile_r1cs_ppzksnark.cpp constructs a simple constraint system and runs the ppzksnark. See below for how to\n   run it. Executing profiling example The command $ src/zk_proof_systems/ppzksnark/r1cs_ppzksnark/profiling/profile_r1cs_ppzksnark 1000 10 Fr exercises the ppzkSNARK (first generator, then prover, then verifier) on an\nR1CS instance with 1000 equations and an input consisting of 10 field elements. (If you get the error zmInit ERR:can't protect , see the discussion above .) The command $ src/zk_proof_systems/ppzksnark/r1cs_ppzksnark/profiling/profile_r1cs_ppzksnark 1000 10 bytes does the same but now the input consists of 10 bytes. Build options The following flags change the behavior of the compiled code. make FEATUREFLAGS='-Dname1 -Dname2 ...' Override the active conditional #define names (you can see the default at the top of the Makefile).\n The next bullets list the most important conditionally-#defined features.\n For example, make FEATUREFLAGS='-DBINARY_OUTPUT' enables binary output and disables the default\n assembly optimizations and Montgomery-representation output. define BINARY_OUTPUT In serialization, output raw binary data (instead of decimal, when not set). make CURVE=choice / define CURVE_choice (where choice is one of: \n     ALT_BN128, BN128, EDWARDS, MNT4, MNT6) Set the default curve to one of the above (see elliptic curve choices ). make DEBUG=1 / define DEBUG Print additional information for debugging purposes. make LOWMEM=1 / define LOWMEM Limit the size of multi-exponentiation tables, for low-memory platforms. make NO_DOCS=1 Do not generate HTML documentation, e.g. on platforms where Markdown is not easily available. make NO_PROCPS=1 Do not link against libprocps. This disables memory profiling. make NO_GTEST=1 Do not link against GTest. The tutorial and test suite of gadgetlib2 tutorial won't be compiled. make NO_SUPERCOP=1 Do not link against SUPERCOP for optimized crypto. The ADSNARK executables will not be built. make MULTICORE=1 Enable parallelized execution of the ppzkSNARK generator and prover, using OpenMP.\n This will utilize all cores on the CPU for heavyweight parallelizabe operations such as\n FFT and multiexponentiation. The default is single-core. To override the maximum number of cores used, set the environment variable OMP_NUM_THREADS at runtime (not compile time), e.g., OMP_NUM_THREADS=8 test_r1cs_sp_ppzkpc . It defaults\n to the autodetected number of cores, but on some devices, dynamic core management confused\n OpenMP's autodetection, so setting OMP_NUM_THREADS is necessary for full utilization. define NO_PT_COMPRESSION Do not use point compression.\nThis gives much faster serialization times, at the expense of ~2x larger\nsizes for serialized keys and proofs. define MONTGOMERY_OUTPUT (on by default) Serialize Fp elements as their Montgomery representations. If this\noption is disabled then Fp elements are serialized as their\nequivalence classes, which is slower but produces human-readable\noutput. make PROFILE_OP_COUNTS=1 / define PROFILE_OP_COUNTS Collect counts for field and curve operations inside static variables\nof the corresponding algebraic objects. This option works for all\ncurves except bn128. define USE_ASM (on by default) Use unrolled assembly routines for F[p] arithmetic and faster heap in\nmulti-exponentiation. (When not set, use GMP's mpn_* routines instead.) define USE_MIXED_ADDITION Convert each element of the proving key and verification key to\naffine coordinates. This allows using mixed addition formulas in\nmultiexponentiation and results in slightly faster prover and\nverifier runtime at expense of increased proving time. make PERFORMANCE=1 Enables compiler optimizations such as link-time optimization, and disables debugging aids.\n(On some distributions this causes a plugin needed to handle lto object link error and undefined reference s, which can be remedied by AR=gcc-ar make ... .) Not all combinations are tested together or supported by every part of the codebase. Portability libsnark is written in fairly standard C++11. However, having been developed on Linux on x86-64 CPUs, libsnark has some limitations\nwith respect to portability. Specifically: libsnark's algebraic data structures assume little-endian byte order. Profiling routines use clock_gettime and readproc calls, which are Linux-specific. Random-number generation is done by reading from /dev/urandom , which is\n   specific to Unix-like systems. libsnark binary serialization routines (see BINARY_OUTPUT above) assume\n   a fixed machine word size (i.e. sizeof(mp_limb_t) for GMP's limb data type).\n   Objects serialized in binary on a 64-bit system cannot be de-serialized on\n   a 32-bit system, and vice versa.\n   (The decimal serialization routines have no such limitation.) libsnark requires a C++ compiler with good C++11 support. It has been\n   tested with g++ 4.7, g++ 4.8, and clang 3.4. On x86-64, we by default use highly optimized assembly implementations for some\n   operations (see USE_ASM above). On other architectures we fall back to a\n   portable C++ implementation, which is slower. Tested configurations include: Debian jessie with g++ 4.7 on x86-64 Debian jessie with clang 3.4 on x86-64 Fedora 20/21 with g++ 4.8.2/4.9.2 on x86-64 and i686 Ubuntu 14.04 LTS with g++ 4.8 on x86-64 Ubuntu 14.04 LTS with g++ 4.8 on x86-32, for EDWARDS and ALT_BN128 curve choices Debian wheezy with g++ 4.7 on ARM little endian (Debian armel port) inside QEMU, for EDWARDS and ALT_BN128 curve choices Windows 7 with g++ 4.8.3 under Cygwin 1.7.30 on x86-64 with NO_PROCPS=1, NO_GTEST=1 and NO_DOCS=1, for EDWARDS and ALT_BN128 curve choices Mac OS X 10.9.4 (Mavericks) with Apple LLVM version 5.1 (based on LLVM 3.4svn) on x86-64 with NO_PROCPS=1, NO_GTEST=1 and NO_DOCS=1 Directory structure The directory structure of the libsnark library is as follows: src/ --- main C++ source code, containing the following modules: algebra/ --- fields and elliptic curve groups common/ --- miscellaneous utilities gadgetlib1/ --- gadgetlib1, a library to construct R1CS instances gadgets/ --- basic gadgets for gadgetlib1 gadgetlib2/ --- gadgetlib2, a library to construct R1CS instances qap/ --- quadratic arithmetic program domains/ --- support for fast interpolation/evaluation, by providing\n  FFTs and Lagrange-coefficient computations for various domains relations/ --- interfaces for expressing statement (relations between instances and witnesses) as various NP-complete languages constraint_satisfaction_problems/ --- R1CS and USCS languages circuit_satisfaction_problems/ ---  Boolean and arithmetic circuit satisfiability languages ram_computations/ --- RAM computation languages zk_proof_systems --- interfaces and implementations of the proof systems reductions --- reductions between languages (used internally, but contains many examples of building constraints) Some of these module directories have the following subdirectories: ... examples/ --- example code and tutorials for this module tests/ --- unit tests for this module In particular, the top-level API examples are at src/r1cs_ppzksnark/examples/ and src/gadgetlib2/examples/ . depsrc/ --- created by prepare_depends.sh for retrieved sourcecode and local builds of external code\n  (currently: [ate-pairing], and its dependency xbyak). depinst/ --- created by prepare_depends.sh and Makefile for local installation of locally-compiled dependencies. doxygen/ --- created by make doxy and contains a Doxygen summary of all files, classes etc. in libsnark. Further considerations Multiexponentiation window size The ppzkSNARK's generator has to solve a fixed-base multi-exponentiation\nproblem.  We use a window-based method in which the optimal window size depends\non the size of the multiexponentiation instance and the platform. On our benchmarking platform (a 3.40 GHz Intel Core i7-4770 CPU), we have\ncomputed for each curve optimal windows, provided as\n\"fixed_base_exp_window_table\" initialization sequences, for each curve; see X_init.cpp for X=edwards,bn128,alt_bn128. Performance on other platforms may not be optimal (but probably not be far off).\nFuture releases of the libsnark library will include a tool that generates\noptimal window sizes. References [BBFR15] ADSNARK: nearly practical and privacy-preserving proofs on authenticated data ,\n  Michael Backes, Manuel Barbosa, Dario Fiore, Raphael M. Reischuk,\n  IEEE Symposium on Security and Privacy (Oakland) 2015 [BCCT12] From extractable collision resistance to succinct non-Interactive arguments of knowledge, and back again ,\n  Nir Bitansky, Ran Canetti, Alessandro Chiesa, Eran Tromer,\n  Innovations in Computer Science (ITCS) 2012 [BCCT13] Recursive composition and bootstrapping for SNARKs and proof-carrying data Nir Bitansky, Ran Canetti, Alessandro Chiesa, Eran Tromer,\n  Symposium on Theory of Computing (STOC) 13 [BCGTV13] SNARKs for C: Verifying Program Executions Succinctly and in Zero Knowledge ,\n  Eli Ben-Sasson, Alessandro Chiesa, Daniel Genkin, Eran Tromer, Madars Virza,\n  CRYPTO 2013 [BCIOP13] Succinct Non-Interactive Arguments via Linear Interactive Proofs ,\n  Nir Bitansky, Alessandro Chiesa, Yuval Ishai, Rafail Ostrovsky, Omer Paneth,\n  Theory of Cryptography Conference 2013 [BCTV14a] Succinct Non-Interactive Zero Knowledge for a von Neumann Architecture ,\n  Eli Ben-Sasson, Alessandro Chiesa, Eran Tromer, Madars Virza,\n  USENIX Security 2014 [BCTV14b] Scalable succinct non-interactive arguments via cycles of elliptic curves ,\n  Eli Ben-Sasson, Alessandro Chiesa, Eran Tromer, Madars Virza,\n  CRYPTO 2014 [CTV15] Cluster computing in zero knowledge ,\n  Alessandro Chiesa, Eran Tromer, Madars Virza,\n  Eurocrypt 2015 [DFGK14] Square span programs with applications to succinct NIZK arguments ,\n  George Danezis, Cedric Fournet, Jens Groth, Markulf Kohlweiss,\n  ASIACCS 2014 [GGPR13] Quadratic span programs and succinct NIZKs without PCPs ,\n  Rosario Gennaro, Craig Gentry, Bryan Parno, Mariana Raykova,\n  EUROCRYPT 2013 [ate-pairing] High-Speed Software Implementation of the Optimal Ate Pairing over Barreto-Naehrig Curves ,\n  MITSUNARI Shigeo, TERUYA Tadanori [PGHR13] Pinocchio: Nearly Practical Verifiable Computation ,\n  Bryan Parno, Craig Gentry, Jon Howell, Mariana Raykova,\n  IEEE Symposium on Security and Privacy (Oakland) 2013"}, {"name": "libweb3core", "desc": "Former home of libweb3core (part of cpp-ethereum)", "readme": "Former home of libweb3core (part of cpp-ethereum) cpp-ethereum is the Ethereum C++ client. This repository was a sub-module used within the webthree-umbrella repo between October 2015 and August 2016. The code formerly developed in this repo has been merged back into cpp-ethereum as of August 2016. Please do not create pull-requests against this repository.  It is no longer in-use."}, {"name": "libwhisper", "desc": "Ultra-private messaging and signalling system.", "readme": "libwhisper Ultra-private messaging and signalling system."}, {"name": "local-testnet", "desc": "Run a full Ethereum network from genesis in the local machine", "readme": "Local Ethereum Testnet Run a full Ethereum network from genesis in the local machine. The network run by this projects uses lighthouse and geth as the consensus client and execution client respectively. We try to make the network as similar to the mainnet as possible, so that people can use this repository as the documentation on how to start\ntheir own network. In order to do so, we try to write as little code as possible and use only bash scripts to run only well-known softwares. In addition, we use some\nJavaScript and web3.js so that we can easily manage JSON objects and interact with the Ethereum nodes. Install Dependencies You can follow the follwing instructions to install the dependencies. You can omit some instructions if you prefer to install them in other ways.\n```bash Install geth and bootnode sudo add-apt-repository -y ppa:ethereum/ethereum\nsudo apt-get update\nsudo apt-get install -y ethereum Install Rust curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource \"$HOME/.cargo/env\" Install lighthouse and lcli sudo apt-get install -y git gcc g++ make cmake pkg-config llvm-dev libclang-dev clang protobuf-compiler\ngit clone https://github.com/sigp/lighthouse.git\ncd lighthouse\ngit checkout stable\nmake\nmake install-lcli Install Node.js sudo apt-get install -y nodejs npm Install jq sudo apt-get install -y jq\n``` Run the network bash\ngit clone https://github.com/ppopth/local-testnet.git\ncd local-testnet\n./run.sh By default, the number of nodes will be 4 and the number of validators will be 80. You can change them by setting the environment variables. bash\nNODE_COUNT=2 VALIDATOR_COUNT=10 ./run.sh Note: If you make the NODE_COUNT and VALIDATOR_COUNT too high, you probably need to change TERMINAL_TOTAL_DIFFICULTY and GENESIS_DELAY in vars.env as well. Please read the comment in vars.env for more detail. If you want to specify the paths for your own geth and lighthouse binaries, you can do so by setting GETH_CMD and LIGHTHOUSE_CMD environment variables. bash\nGETH_CMD=~/repos/go-ethereum/build/bin/geth \\\nLIGHTHOUSE_CMD=~/repos/lighthouse/target/release/lighthouse \\\n./run.sh How the network works When you run ./run.sh , the followings happen in order. Ethereum accounts are generated for each node using the command geth account new , so there will be NODE_COUNT accounts in total. Execution layer genesis file is generated at ./data/execution/genesis.json . Geth directories of each node are initialized with the previously generated gnesis file. Start a boot node of the execution layer p2p network. Start Geth instances of all NODE_COUNT nodes. Start a Geth instance of a special node called \"signer\". At this point, there will be NODE_COUNT Geth nodes, a boot node, and the \"signer\" Geth node running. They form a network and they can discover\neach other using the boot node. The network is now a fully functioning Ethereum network, but its underlying consensus protocol is a Proof-of-Authority (PoA) protocol,\nnot the desired Proof-of-Stake (PoS) protocol. (You can try sending a transactoin at this stage, if you want) In case you're curious, \"signer\" is a dedicated node used as the only block-proposing authority of the Proof-of-Stake protocol. The next steps are about turning the network into the Proof-of-Stake one. Deploy the deposit contract using one of the PoA nodes. Generate the key pairs of all VALIDATOR_COUNT validators using staking-deposit-cli . Sending the deposits to the deposit contract for all the validators using one of the PoA nodes. Consensus layer genesis file is generated at ./data/consensus/genesis.ssz . Assign the validators to the NODE_COUNT nodes. Every node will have approximately the same number of validators. Start a boot node of the consensus layer p2p network. Start Lighthouse instances of all NODE_COUNT nodes. At this point, everything is ready to transition to the Proof-of-Stake. Using the default configuration, you will have to wait around 5 minutes since you start the network until it fully transitions to the Proof-of-Stake. Inspect the logs The following logs are the significant ones.\n* ./data/signer/ethereum/geth.log - which is the Geth log of the \"signer\" node.\n* ./data/node{id}/ethereum/geth.log - which is the Geth log of the id'th node of the NODE_COUNT nodes.\n* ./data/node{id}/lighthouse/beacon_node.log - which is the Lighthouse beacon_node log of the id'th node of the NODE_COUNT nodes.\n* ./data/node{id}/lighthouse/validator_client.log - which is the Lighthouse validator_client log of the id'th node of the NODE_COUNT nodes. When the network has fully transitioned to the Proof-of-Stake, the log in ./data/node{id}/lighthouse/beacon_node.log should show the following. ``\nJan 06 10:09:53.501 INFO Synced                                  slot: 71, block: 0xfa3e\u2026e9bb, epoch: 2, finalized_epoch: 0, finalized_root: 0x68ea\u20268fbd, exec_hash: n/a, peers: 3, service: slot_notifier\nJan 06 10:09:53.504 INFO Ready for the merge                     current_difficulty: 159, terminal_total_difficulty: 160, service: slot_notifier\nJan 06 10:09:55.037 INFO New block received                      root: 0x60c2d96ce0d90e08686900df41966e34afd467e5d93527046435f284fe139333, slot: 72\nJan 06 10:09:55.044 INFO \n    ,,,         ,,,                                               ,,,         ,,,\n  ;\"   ^;     ;'   \",                                           ;\"   ^;     ;'   \",\n  ;    s$$$$$$$s     ;                                          ;    s$$$$$$$s     ;\n  ,  ss$$$$$$$$$$s  ,'  ooooooooo.    .oooooo.   .oooooo..o     ,  ss$$$$$$$$$$s  ,'\n  ;s$$$$$$$$$$$$$$$ 888 Y88. d8P' Y8b d8P' Y8     ;s$$$$$$$$$$$$$$$\n  $$$$$$$$$$$$$$$$$$     888   .d88'888      888Y88bo.          $$$$$$$$$$$$$$$$$$\n $$$$P\"\"Y$$$Y\"\"W$$$$$    888ooo88P' 888      888 \"Y8888o.     $$$$P\"\"Y$$$Y\"\"W$$$$$\n $$$$  p\"LFG\"q  $$$$$    888        888      888 \"Y88b    $$$$  p\"LFG\"q  $$$$$\n $$$$  .$$$$$.  $$$$     888 88b    d88'oo     .d8P    $$$$  .$$$$$.  $$$$\n  $$DcaU$$$$$$$$$$      o888o        `Y8bood8P' 8\"\"88888P'      $$DcaU$$$$$$$$$$\n    \"Y$$$\" \"$$$Y\"                                                 \"Y$$$\" \"$$$Y\"\n        \"$b.$$\"                                                       \"$b.$$\" .o.                   .   o8o                         .                 .o8\n  .888.                .o8   `\"'                       .o8                \"888\n .8\"888.     .ooooo. .o888oooooo oooo    ooo .oooo.  .o888oo .ooooo.  .oooo888\n.8' `888.   d88' `\"Y8  888  `888  `88.  .8' `P  )88b   888  d88' `88bd88' `888 .88ooo8888.  888        888   888 88..8'   .oP\"888   888  888ooo888888   888\n  .8' 888. 888   .o8  888 . 888 888'   d8(  888   888 .888    .o888   888\n o88o     o8888o Y8bod8P'  \"888\"o888o 8' Y888\"\"8o  \"888\" Y8bod8P' Y8bod88P\" , service: beacon\nJan 06 10:09:55.044 INFO Proof of Stake Activated                slot: 72, service: beacon\nJan 06 10:09:55.044 INFO                                         Terminal POW Block Hash: 0xc2bc20ed0a3903d9e93dbd31abbc867a0a7c38240cb6a194575fdd5bcb466e12, service: beacon\nJan 06 10:09:55.044 INFO                                         Merge Transition Block Root: 0x60c2d96ce0d90e08686900df41966e34afd467e5d93527046435f284fe139333, service: beacon\nJan 06 10:09:55.044 INFO                                         Merge Transition Execution Hash: 0xede8bfd80096085da44b8954aa071ca3d82eced8c4c2bd57941b0a4b616bc456, service: beacon\nJan 06 10:09:56.502 INFO Synced                                  slot: 72, block: 0x60c2\u20269333, epoch: 2, finalized_epoch: 0, finalized_root: 0x68ea\u20268fbd, exec_hash: 0xede8\u2026c456 (verified), peers: 3, service: slot_notifier\n``` Try sending a transaction Save the following file as send.js ```js\nconst net = require('net');\nconst Web3 = require('web3');\nconst web3 = new Web3('./data/node1/ethereum/geth.ipc', net); const recipient = process.argv[2]; (async function() {\n    const accounts = await web3.eth.getAccounts(); console.log(\"Before the transaction:\");\nconsole.log(accounts[0], \"has\", await web3.eth.getBalance(accounts[0]));\nconsole.log(recipient, \"has\", await web3.eth.getBalance(recipient));\n\nawait web3.eth.sendTransaction({\n    from: accounts[0],\n    to: recipient,\n    value: '500000000000000000000000000',\n    gas: 42000,\n    gasPrice: '14000000000',\n});\n\nconsole.log(\"After the transaction:\");\nconsole.log(accounts[0], \"has\", await web3.eth.getBalance(accounts[0]));\nconsole.log(recipient, \"has\", await web3.eth.getBalance(recipient)); })(); Run the following to send a transaction. This can take a while, so be patient. $ NODE_PATH=./web3/node_modules node send.js $(cat ./data/node2/ethereum/address)\nBefore the transaction:\n0x7CC1c30f38606C767d6F930Ef82E51571Da15015 has 1000000000000000000000000000\n0x1f7702a321566a68Cd6edD20b55f7Fe8641c8344 has 1000000000000000000000000000\nAfter the transaction:\n0x7CC1c30f38606C767d6F930Ef82E51571Da15015 has 499999999999706000000000000\n0x1f7702a321566a68Cd6edD20b55f7Fe8641c8344 has 1500000000000000000000000000\n```"}, {"name": "mantis-apache2", "desc": "A Scala based client for Ethereum and Ethereum Classic.", "readme": "Mantis - Scala Client for Ethereum Classic, The Daedalus Release In this release Mantis the new Ethereum Classic client produced by the Grothendieck Team has been integrated with the Daedalus wallet. This integration puts the Daedalus wallet management\nsoftware into the hands of Ethereum Classic users, giving them a safe way to create, manage and backup their wallets. This version has been tested on recent versions of Windows and macOS The Daedalus bundle contains a JVM, so no pre installed jvm is required. This makes it easier to install than the command line version. Status - Release 1.0 Continuous Integration Build Status Unit Test Code Coverage Status This version of the code supports CPU mining peer discovery fast sync (download a recent state trie snapshot and all blocks, this is the default behaviour) bootstrap sync (download a database for mantis preloaded with a recent version of the block chain, highly recommended ) regular sync (download and execute every transaction in every block in the chain, this can be very slow - not recommended) JSON RPC API (useful for console and Mist integration) Morden testnet and private network ethminer miner integration (allows mantis to mine blocks with ethminer ) Installers for Windows and macOS To make the installation process as accessible as possible, we have created fully automated installers for windows and macOS. the installer will install Daedalus wallet, install the Mantis client, set up an SSL connection between the two. it will then download a bootstrap database in order to synchronise the Ethereum Classic blockchain. it will check the finger print of the downloaded database in order to prevent MITM attacks. then it will start up both the wallet and the mantis node and begin syncing. until the node is synced no transactions can be made. when Daedalus is closed down it will also stop the mantis node. uninstall using the OS 'Add/Remove' feature Note that the download and extract process could take up to 60 minutes depending on available network and disk resources! For more details on configuration and functionality check out our wiki (also at wiki ) Download the client and bootstrap files The latest release can be downloaded from here The bootstrap database files can be downloaded from here Command line version To access the command line version of this release go to daedalus-cli Building the client Prerequisites to build JDK 1.8 (download from java.com ) sbt ( download sbt ) Build the client As an alternative to downloading the client build the client from source. First of all sbt-verify is used in order to check the validity of the downloaded libraries checksums. sbt-verify can be downloaded from our read only repository by typing git clone  https://github.com/input-output-hk/sbt-verify Then in order to make sbt-verify available to our build type cd sbt-verify\nsbt publishLocal This installs the sbt-verify library to your local repository. After installing the sbt-verify library to your local repository checkout this repository from github and then type sbt dist in the root of the project. This creates a distribution zip. Feedback Feedback gratefully received through the Ethereum Classic Forum (http://forum.ethereumclassic.org/) Known Issues There is a list of known issues in the 'RELEASE' file located in the root of the installation."}, {"name": "merge-testnet-verifier", "desc": "Merge Testnet module to probe and verify certain aspects of the testnet during its lifetime.", "readme": "Merge Testnet Verifier Performs a continuous verification of a Merge (Execution-Consensus) testnet and validates the final health by measuring and comparing a set of given metrics Post-Merge. Command Line Arguments --client Execution/Beacon client URL endpoint to check for the client's status in the form: ,http:// : .\nParameter can appear multiple times for multiple clients. --ttd Terminal Total Difficulty of the Testnet. --override-verifications Specifies the path to a verifications YML file to override the default verifications. --extra-verifications Specifies the path to a verifications YML file to be added to the default verifications. --ttd-epoch-limit Max number of epochs to wait for the TTD to be reached.\nDisable timeout: 0.\nDefault: 5 --verif-epoch-limit Max number of epochs to wait for successful verifications after the merge has occurred.\nDisable timeout: 0.\nDefault: 5 Verifications YML File Format The verifications file is a YML formatted file that contains a list of all verifications to be performed during the testnet's runtime. Each verification element contains the following fields (all mandatory unless specified otherwise): - VerificationName, string Name of the verification, which will be printed on the output to help identify when the verification fails. - ClientLayer, string Layer from which the verification data will be obtained -- only accepts \"Execution\" or \"Beacon\" values thus far. - PostMerge, bool Whether the verification data should only be gathered after the merge has occurred (true) or during all the testnet's runtime (false). - MetricName, string Metric to be collected which then will be aggregated and compared to obtain the verification's outcome. Only one data point of this metric will be collected per block/slot. See Supported Metrics section. - AggregateFunction, string Aggregation function used to produce a single value that can be compared in the PassCriteria. See Supported Aggregate Functions section. - AggregateFunctionValue, string, optional Optional aggregate value used for some of the aggregation functions. - PassCriteria, string Comparison criteria used to determine a successful verification. See Supported Pass Criterias secion. - PassValue, string Pass value used in the PassCriteria comparison. Supported Metrics Execution Layer - ExecutionBlockCount Number of execution blocks produced. - ExecutionBaseFee BaseFee Value of the block header. - ExecutionGasUsed Total gas used of the block header. - ExecutionDifficulty Difficulty value of the block header. - ExecutionMixHash MixHash value of the block header. - ExecutionUnclesHash Uncles hash value of the block header. - ExecutionNonce Nonce value of the block header. Beacon Layer - BeaconBlockCount Number of beacon blocks produced -- can only be 0 or 1 per slot. - FinalizedEpoch Number of times the finalized_epoch value in the finality_checkpoints changes values; 1 if the finalized_epoch value changes, 0 if the value is the same as the previous slot. - JustifiedEpoch Number of times the justified_epoch value in the finality_checkpoints changes values; 1 if the justified_epoch value changes, 0 if the value is the same as the previous slot. - EpochAttestationPerformance Attestation performance throughout the Epoch. Currently can only be obtained if a Lighthouse client is provided, since it uses the validator_inclusion endpoint and it's calculated by getting the ratio between previous_epoch_head_attesting_gwei and previous_epoch_active_gwei . - EpochTargetAttestationPerformance Target attestation performance throughout the Epoch. Currently can only be obtained if a Lighthouse client is providedm, since it uses the validator_inclusion endpoint and it's calculated by getting the ratio between previous_epoch_target_attesting_gwei and previous_epoch_active_gwei . - SyncParticipationCount Sync participation per slot -- Set bit count of sync_committee_bits - SyncParticipationPercentage Sync participation percentage per slot -- Set bit count of sync_committee_bits divided by the SYNC_COMMITTEE_SIZE value of the spec. Supported Aggregate Functions - CountEqual (Requires AggregateFunctionValue): Count all the values equal to AggregateFunctionValue. - CountUnequal (Requires AggregateFunctionValue): Count all the values not equal to AggregateFunctionValue. - Average Arithmetic mean of all the data points obtained -- 0 when no data points were obtained. - Sum Sum of all the data points obtained. - Min Minimum value of all data points obtained. - Max Maximum value of all data points obtained. - Percentage Percentage (0 - 100) of all data points that are greater than zero. Supported Aggregate Functions - MinimumValue Minimum value that the aggregated value can have in order for the verification to be successful. - MaximumValue Maximum value that the aggregated value can have in order for the verification to be successful. Default Verifications See default_verifications.yml"}, {"name": "meteor-dapp-catalog", "desc": null, "readme": "\u00d0app Catalog Development Start an eth node using the following,\nor open the http://localhost:3000 in mist , mix or alethzero $ eth -j -b // for a mining node: $ eth -j -b -f -n no -m yes Start your app using meteor $ cd ethereum-dapp-whisper-client/app\n$ meteor Go to http://localhost:3000 Deployment To create a build version of your app run: $ meteor build ../dist\n$ cd ../dist\n$ tar zxvf app.tar.gz Copy the app folder, .js and .css from bundle/programs/web.browser/ to your dist folder and ... The rest has to figured out yet, depending on the Mist/Swarm hosting"}, {"name": "meteor-dapp-wallet", "desc": "This is an archived repository of one of the early Ethereum wallets.", "readme": "Ethereum Wallet \u00d0app The Ethereum wallet. PLEASE NOTE: This wallet is not yet officially released,\nand can contain severe bugs! Please use at your own risk. Install If you don't have Meteor : $ curl https://install.meteor.com/ | sh Install npm dependencies: $ cd meteor-dapp-wallet/app\n$ npm install Development Start a geth node: $ geth --ws --wsorigins \"http://localhost:3000\" --unlock <your account> Run dev server: $ cd meteor-dapp-wallet/app\n$ meteor Navigate to http://localhost:3000 Deployment To create a build: $ npm install -g meteor-build-client\n$ cd meteor-dapp-wallet/app\n$ npm install\n$ meteor-build-client ../build --path \"\" This will generate the files in the ../build folder. Navigating to index.html will start the app, but you will need to serve it over a local server like MAMP . To deploy to the wallet.ethereum.org site, execute these commands: $ git checkout gh-pages\n$ git merge develop\n$ cd app\n$ meteor-build-client ../build --path \"/\" And push (or PR) your changes to the gh-pages branch. Gas usage statistics Deploy original wallet: 1 230 162 Deploy wallet stub: 184 280 Simple Wallet transaction: 64 280 Multisig Wallet transaction below daily limit: 79 280 Multisig Wallet transaction above daily limit: 171 096 1 Multisig confirmation: 48 363"}, {"name": "meteor-dapp-whisper-chat-client", "desc": null, "readme": "Whisper Chat Client \u00d0app Development Start an geth node and and the app using meteor and open http://localhost:3000 in your browser: $ geth --rpccorsdomain \"http://localhost:3000\" --rpc --shh --unlock <your account> Start your app using meteor $ cd meteor-dapp-wallet/app\n$ meteor Go to http://localhost:3000 Deployment To create a build version of your app run: // install meteor-build-client\n$ npm install -g meteor-build-client\n\n// bundle dapp\n$ cd meteor-dapp-wallet/app\n$ meteor-build-client ../build --path \"\" This will generate the files in the ../build folder. Double click the index.html to start the app. To make routing work properly you need to build it using: $ meteor-build-client ../build And start a local server which points with its document root into the ../build folder,\nso that you can open the app using http://localhost:80/ The Whisper chat app The collections used are: User - contains the users identities (persistet via localStorage) Users - contains collected identities and usernames (persistet via localStorage) Chats - contains the chats (persistet via localStorage) Messages - contains the messages, which belong to chats (persistet via localStorage) Invitations - contains temporarily store inviations The web3 object is created in client/lib/thirdpartyConfig.js . The whole whisper protocol integration can be found in the client/whisperConnection.js .\nRemoving it won't break app, just cut the connection to whisper.\nSome helper functions for whisper can be found at client/lib/helpers/WhisperHelperFunctions.js . This dapp uses the ethereum:elements package. Protocol specs The following specs need to be transfered as stringified JSON in the payload. You can also send messages to a chatroom by simply providing the correct chatroom topic including the whisper-chat-client topic.\nThe user will then appear as anonymous: web3.shh.post({\n    \"topic\": ['whisper-chat-client', 'ethereum'],\n    \"payload\": 'Hello world',\n    \"ttl\": 100,\n    \"priority\": 1000\n}); Invite to a group chat ```js\n// Topics\n[\n    'whisper-chat-client',\n    '0x34556456..' // the user to invite\n] // TO and FROM parameters\nto: '0x34556456..' // the user to invite,\nfrom: '0x12344...' // Payload\n{\n    type: 'invite',\n    chat: 'ethereum', // chat topic\n    name: 'My Chatroom',\n    from: {\n        identity: '0x12344...', // the current user identity, if you set a from in the whisper shh.post() it will be used instead\n        name: 'Mr. X'\n    },\n    // the users invited\n    data: [{\n        identity: '0x345345345..',\n        name: 'user x'\n    },\n    {\n        identity: '0x67554345..',\n        name: 'user y'\n    }]\n}\n``` Invite to a private chat ```js\n// Topics\n[\n    'whisper-chat-client',\n    '0x34556456..' // the user to invite\n] // TO and FROM parameters\nto: '0x34556456..' // the user to invite,\nfrom: '0x12344...' // required // Payload\n{\n    type: 'invite',\n    privateChat: true,\n    from: {\n        identity: '0x12344...', // the current user identity, if you set a from in the whisper shh.post() it will be used instead\n        name: 'Mr. X'\n    }\n}\n``` Send message ```js\n// Topics\n[\n    'whisper-chat-client',\n    'ethereum' // the chats topic or HEX user identity for private chats\n] // TO and FROM parameters\nto: '0x34556456..' // only for private chats\nfrom: '0x12344...' // Payload\n{\n    type: 'message',\n    id: '231rewf23', // the unique id of the message\n    chat: 'ethereum', // the parent chats topic. For private chats the identity of the user\n    topic: 'my topic', // the topic set for the chat, to filter chats with many participants. Has nothing to do with whisper topics\n    timestamp: 145788999,\n    from: {\n        identity: '0x4324234..', // the current user identity, if you set a from in the whisper shh.post() it will be used instead\n        name: 'my username'\n    },\n    message: 'Hello its me!'\n}\n``` Edit message Will only be allowed for messages which are less than 1 hour old. ```js\n// Topics\n[\n    'whisper-chat-client',\n    'ethereum' // the chats topic or HEX user identity for private chats\n] // TO and FROM parameters\nto: '0x34556456..' // only for private chats\nfrom: '0x12344...' // Payload\n{\n    type: 'edit',\n    id: '231rewf23', // the unique id of the message\n    chat: 'ethereum', // the parent chats topic. For private chats the identity of the user\n    timestamp: 145788999,\n    from: {\n        identity: '0x4324234..', // the current user identity, if you set a from in the whisper shh.post() it will be used instead\n        name: 'my username'\n    },\n    topic: 'my new topic', // the changed topic\n    message: 'my edited message' // the changed message\n}\n``` Notifications ```js\n// Topics\n[\n    'whisper-chat-client',\n    'ethereum' // the chats topic or HEX user identity for private chats\n] // TO and FROM parameters\nto: '0x34556456..' // only for private chats\nfrom: '0x12344...' // Payload\n{\n    type: 'notification',\n    message: 'invitation',\n    id: '231rewf23', // the unique id of the message\n    chat: 'ethereum', // the parent chats topic. For private chats the identity of the user\n    timestamp: 145788999,\n    from: {\n        identity: Whisper.getIdentity().identity,\n        name: Whisper.getIdentity().name\n    },\n    data: 'some data, see below'\n}\n``` There are currently three types of notifications implemented: invitation will list all the users the user has invited into the group chat\n    The data property should contain the identities and usernames: js\n[{\n    identity: '0x345345345..',\n    name: 'user x'\n},\n{\n    identity: '0x67554345..',\n    name: 'user y'\n}] topicChanged will tell the other participants about a change of the users personal (non-whisper) topic\n    The data property should contain the new topic name e.g. my new topic chatNameChanged will tell the other users that the group chat name has changed.\n    The data property should contain the new chat name e.g. Hello kitty fans .\n    All users will then update their group chat name accordingly. (Everybody can change the group chat name)"}, {"name": "meteor-ethereum-networkinfo", "desc": "Meteor package to extract and expose Ethereum network information", "readme": "Meteor package - Ethereum network info Waits for a web3 connection and then extracts network info. It fetches the Genesis block information and places it into a \nPromise - NetworkInfoPromise - for use throughout your application. It also provides a proxy wrapper class for Mongo collections \nwhich ensures that network id is stored for each document in the collection, \nallowing you store data by network . Installation $ meteor add hiddentao:ethereum-networkinfo Usage Use the extracted network information via the Promise: ```js\nNetworkInfo.promise.then(function(networkInfo) {\n  console.log(info); / type: 'main',\n  uniqueId: 'fb25ce3f...',\n  genesis: {...}, /\n})\n``` To network -ify a collection do: js\nMyCollection = new NetworkInfo.ProxyCollection(\n  new Mongo.Collection('mydata')\n); You can then use all the normal Meteor collection methods on the returned object."}, {"name": "meteor-package-accounts", "desc": null, "readme": "Ethereum accounts Provides you with an EthAccounts collection, where balances are automatically updated.\nAdditionally the accounts are persisted in localstorage. If the ethereum node removes accounts,\nthe EthAccounts collection will set the deactivated: true property to these accounts and hide them from normal queries. If the Accounts should reapear in the node (e.g. the user importet those, or mist allwed them access), they will be available again,\nincluding all the extra properties you've set. Note don't use the EthAccounts collection to add your own custom accounts as a reload of your application,\nor any change in web3.eth.accounts would hide them. Installation $ meteor add ethereum:accounts Usage Initialize Accounts on the start of your application, as soon as you have a ethereum connection: js\nEthAccounts.init(); Then simply use the global EthAccounts object like any other minimongo collection.\nIt provides the .find() , .findOne() , .findAll() , .update() , .updateAll() and .remove() functions e.g.: ```js\n// Get all active accounts\nvar myAccounts = EthAccounts.find().fetch(); [\n  {\n    \"_id\": \"2Zd3Z9XQrc7iN7Ci3\"\n    \"address\": \"0x343c98e2b6e49bc0fed722c2a269f3814ddd1533\",\n    \"balance\": \"18260939861619682985678\",\n    \"name\": \"Coinbase\",\n  }\n] // or\nvar myPrimaryAccount = EthAccounts.findOne({name: 'Coinbase'});\n``` If you want to get truly all accounts including the deactivated ones use: ```js\nvar allAccounts = EthAccounts.findAll().fetch(); [\n  {\n    \"_id\": \"2Zd3Z9XQrc7iN7Ci3\"\n    \"address\": \"0x343c98e2b6e49bc0fed722c2a269f3814ddd1533\",\n    \"balance\": \"18260939861619682985678\",\n    \"name\": \"Coinbase\",\n  },\n  {\n    \"_id\": \"56sbC8dggbYstmN2o\",\n    \"address\": \"0x990ccf8a0de58091c028d6ff76bb235ee67c1c39\",\n    \"balance\": \"0\",\n    \"name\": \"0x990ccf8a0de58091c028d6ff76bb235ee67c1c39\",\n    \"deactivated\": true\n  }\n]\n``` If you want to update a deactivated account use: js\nEthAccounts.updateAll({address: \"0x990ccf8a0de58091c028d6ff76bb235ee67c1c39\"}, {name: 'XYZ'}}); If you manually want to activate an account to make it visible call: js\nEthAccounts.updateAll(\n  { address: \"0x990ccf8a0de58091c028d6ff76bb235ee67c1c39\" },\n  { $unset: { deactivated: \"\" } }\n);"}, {"name": "meteor-package-blocks", "desc": null, "readme": "Ethereum blocks Provides you with an EthBlocks collection, which stores the last 50 blocks. You can query blocks like any other Meteor collection. Installation $ meteor add ethereum:blocks Usage Initialize Blocks on the start of your application, as soon as you have a ethereum connection: js\nEthBlocks.init(); Last block To get the latest block use: js\nEthBlocks.latest; Note this property is reactive, so it will re-run your reactive functions, e.g. when used in template helpers. In case you want to update the latest block you can change properties as follows: js\nEthBlocks.latest = { hash: \"12345\" }; This would only change the hash property of the latest block, but leave all other properties as is. Current gas price Additionally all blocks get the current gasprice add: js\nEthBlocks.latest.gasPrice; // '1136672632018' (wei) Detecting forks You can call Blocks.detectFork(callback) to detect chain re-organisation (forks), while your applications is running.\nThis detection, is checking the new incoming blocks parentHash , with the last known block you have. Note The fork detection can currently be wrong, when you're importing blocks, as they can come in different orders. js\nEthBlocks.detectFork(function(oldBlock, newBlock) {\n  // this callback will be fired with the old block we knew and the new block.\n}); Note you can call EthBlocks.detectFork(cb) mutliple times, to add multiple callbacks. Clear all stored blocks If you switch to a chain, which has a lower block number EthBlocks will reset your interally cache of the last 50 blocks.\nIf you want to do that manually call: js\nEthBlocks.clear();"}, {"name": "meteor-package-elements", "desc": null, "readme": "Ethereum elements A collection of basic Meteor templates/components to make dapps faster to build. Its recommended to use these elements along with the \u00d0app styles . You can find a demo here . Installation $ meteor add ethereum:elements Usage The following elements can be use anywhere in your dapp. Additionally this package exposes the following packages: ethereum:tools , which gives you EthTools . frozeman:template-var , which gives you the TemplateVar.set()/.get() functions which can be used to get values from the select account, or address input element. Note that these packages will only be exposed to your client part of your dapp,\nif you want to use e.g. EthTools on the server side add the package manually using $ meteor add ethereum:tools . Identicon Shows an identicon. You can add the class dapp-tiny , dapp-small , dapp-medium to make it smaller. Default size is to 64px. html\n{{> dapp_identicon identity='0x922a519ac926f69856fcfc1b2b8b846cfb3f6b4e' class=\"dapp-small\"}} Additionally you can provide a URL, which the identicon will link to. html\n{{> dapp_identicon identity='0x922a519ac926f69856fcfc1b2b8b846cfb3f6b4e' link=\"/mypath/\"}} Address Input Creates a input field, with an identicon, which will change based on the input value. You can add the class dapp-large to make it a larger input. html\n{{> dapp_addressInput placeholder=\"0x000000..\" value=\"0x1234...\"}} Setting size By passing class=\"dapp-large\" you can have a larger version of the input: html\n{{> dapp_addressInput placeholder=\"0x000000..\" class=\"dapp-large\"}} Additional Properties are: autofocus=\"true\" disabled=\"true\" Getting values reactively Getting the value using TemplateVar you can grap the templates reactive var using: ```js\nTemplateVar.getFrom('.my-container-element .dapp-address-input', 'value');\n// 0xe5f2f0a5ff3f889856c85b3a255501d1d291467d // or when used in an event\n'change .dapp-address-input input': function(e) {\n    var value = TemplateVar.getFrom(e.currentTarget, 'value');\n}\n``` Note The value won't be set until the content of the input is valid. Data Textarea Creates a textarea field, which only accepts HEX data as input. You can add the class dapp-large to make it a larger input. html\n{{> dapp_dataTextarea cols=\"20\" rows=\"4\" value=\"0x1234\"}} Setting size By passing class=\"dapp-large\" you can have a larger version of the input: html\n{{> dapp_dataTextarea class=\"dapp-large\"}} Additional Properties are: autofocus=\"true\" disabled=\"true\" Getting values reactively Getting the value using TemplateVar you can grap the templates reactive var using: ```js\nTemplateVar.getFrom('.my-container-element .dapp-data-textarea', 'value');\n// 0x1bff2 // or when used in an event\n'change textarea.dapp-data-textarea': function(e) {\n    var value = TemplateVar.getFrom(e.currentTarget, 'value');\n}\n``` Note The value won't be set until the content of the textarea is valid. Select account Creates a select, which can allow to select accounts. The provided array needs to have at least the follwing properties: js\nvar myAccounts = [\n  {\n    type: \"account\",\n    name: \"My Account 1\",\n    balance: \"1000000000000000000\", // in wei\n    address: \"0x922a519ac926f69856fcfc1b2b8b846cfb3f6b4e\"\n  },\n  {\n    name: \"My Other Address\",\n    balance: \"324567543200000013456\", // in wei\n    address: \"0x1f93d965f60faee1085a93e99562945c1bd97be0\"\n  }\n]; html\n{{> dapp_selectAccount accounts=myAccounts}} This element works also well with the ethereum:accounts package, which provides you with EthAccounts.find().fetch() to get all current accounts. Setting size By passing class=\"dapp-large\" you can have a larger version of the select box: html\n{{> dapp_selectAccount accounts=myAccounts class=\"dapp-large\"}} Show icon If you add the showAccountTypes=true property it will show a key unicode icon for all accounts with the type='account' property (set for EthAccounts accounts). html\n{{> dapp_selectAccount accounts=myAccounts showAccountTypes=true}} Getting values reactively Getting the value using TemplateVar you can grap the templates reactive var using: ```js\nTemplateVar.getFrom('.my-container-element .dapp-select-account', 'value'); // or when used in an event\n'change .dapp-select-account select': function(e) {\n    var value = TemplateVar.getFrom(e.currentTarget, 'value');\n}\n``` Gas price selection This element allows you users to adjust the fee (gas * gas price) of a transaction, and gives you back either the gasInWei or the selected gasPrice . You need to provide a gas estimation which you can get using e.g. web3.eth.estimateGas({from: .., to: .., data: ..}) or myContract.myMethod.estimateGas({from: ..}) and the tool will display whats the current medium gas price based on the given gasPrice * your gas usage estimation. The user then can adjust the fee up and down by a factor of ~1.8. Hint : To get the gas price reactivly you can use the ethereum:blocks package's EthBlocks.latest.gasPrice and pass it to the gasPrice property. html\n{{> dapp_selectGasPrice gas=21000 gasPrice=50000000000 unit=\"ether\"}} Note : If you don't set the unit property it will use EthTools.getUnit() , like the {{> dapp_formatBalance}} element. Getting values reactively To get the gasInWei (gas * adjusted gas price) or the adjusted gasPrice use: ```js\nTemplateVar.getFrom('.my-container-element .dapp-select-gas-price', 'gasPrice');\n// \"56258440003\" ~ 56 gwei // or the total fee when providing a estimated gas usage of 21000 TemplateVar.getFrom('.my-container-element .dapp-select-gas-price', 'gasInWei');\n// \"1181427240063000\" which is \"0.001181427240063\" ether // or when used in an event\n'change .dapp-select-gas-price input': function(e) {\n    var value = TemplateVar.getFrom(e.currentTarget, 'gasInWei');\n}\n``` Localization The element can replace the - and + texts below the range selection using the tap:i18n package.\nIf the TAPi18n helper is available it will use TAPi18n.__('elements.selectGasPrice.high') and TAPi18n.__('elements.selectGasPrice.low') for the texts. Modals Just place a modal placeholder before the closing body tag. html\n{{> dapp_modalPlaceholder}} Render without route Render the modal: ```js\nEthElements.Modal.show(\"myContentTemplate\"); // Or EthElements.Modal.show({\n  template: \"myContentTemplate\",\n  data: {\n    myData: \"some data\"\n  }\n});\n``` Additional options: closeable - Prevents the default behaviour, which closes the modal when the overlay is clicked. class - A class, which will be add to the modal section element js\nEthElements.Modal.show(\"myContentTemplate\", {\n  closeable: false,\n  class: \"my-modal-class\"\n}); Navigate to a path on close. This will only work when the kadira:flow-router or iron:router package is installed: js\nEthElements.Modal.show(\"myContentTemplate\", { closePath: \"/dashboard\" }); Close modal js\nEthElements.Modal.hide(); Modal Question The question modal is a modal content template, which can be used to display a text and allow OK and Cancel options. You basically just can pass a text , ok and/or cancel property as a data context to set callbacks, which will be fired when the button is pressed. Additional you can: Set the ok or cancel property to true , it will just close the modal without any action. Pass false or leave the ok or cancel property empty and it won't show that buttons. js\nEthElements.Modal.question({\n  text: \"Do you want to ...\",\n  ok: function() {\n    // do something on ok\n  },\n  cancel: true // simply show th cancel button and close the modal on click\n}); Using a template Instead of passing a text you can also pass a template, which will be shown above the ok/cancel buttons js\nEthElements.Modal.question({\n  template: \"myTemplate\",\n  data: {\n    my: \"template data\"\n  },\n  ok: function() {\n    // do something on ok\n  },\n  cancel: function() {\n    // do something on cancel\n  }\n}); Close question modal js\nEthElements.Modal.hide(); Additional you can pass the same options as the modal as the second parameter: js\nEthElements.Modal.question(\n  {\n    text: \"Alright?\",\n    ok: function() {\n      // do something on ok\n    }\n  },\n  {\n    closeable: false\n  }\n); Localization The modal question can use the tap:i18n package for the ok and cancel button texts.\nIf the TAPi18n helper is available it will use TAPi18n.__('buttons.ok') and TAPi18n.__('buttons.cancel') for the buttons."}, {"name": "meteor-package-tools", "desc": null, "readme": "Ethereum tools A set of helper functions for ethereum dapps. See here for a demo of the template helpers . Installation You can either add it as a Meteor package using: $ Meteor add ethereum:tools or add link to the ethtools.js in your HTML. Usage This package provides formating and converting functionality. When using the EthTools.ticker it will call the cryptocompare.com public API every 30s to retrive price information for ether.\nWhen used as a Meteor package, the following units are possible for some methods: - `btc`\n- `usd`\n- `eur`\n- `cad`\n- `gbp`\n- `jpy`\n- And all ether units ('ether', 'finney', 'wei', etc) Note As non-meteor package you can only use the ether units. EthTools.ticker EthTools.ticker.start();\nEthTools.ticker.findOne(unit) Note This is only available when used as a Meteor package. To start polling for ticker prices run EthTools.ticker.start() It gives you the latest price for ether based on the kraken.com public API . EthTools.ticker is a reactive collection, so when used in a reactive function it will re-run this function when the price is updated. The ticker will be updated every 30 seconds. Methods Its a normal Meteor collection start(options) - starts the polling for the ticker, the options object can be an object with {extraParams: 'mydata'} to be added to the ticker polling call findOne(unit) - returns an object with the price of the unit find().fetch() - returns all available price ticker units Returns Object js\n{\n    _id: 'btc',\n    price: '0.02000'\n} Example ```js\nvar usd = EthTools.ticker.findOne(\"usd\"); if (usd) console.log(usd.price); // \"2.0000\"\n``` EthTools.setLocale EthTools.setLocale(locale) Set the locale to display numbers differently in other countries.\nThis functions lets EthTools.formatBalance() and EthTools.formatNumber() reactivly re-run, to show the new format. Parameters locale ( String ) - the locale to set Returns String - the set locale e.g. en Example js\nEthTools.setLocale(\"de\");\nEthTools.formatNumber(2000, \"0,0.00\");\n// 2 000,00 EthTools.setUnit EthTools.setUnit(unit) Note This is only available when used as a Meteor package. Reactivly sets a unit used as default unit, when no unit is passed to other EthTools methods.\nAnd also persists it in localstorage so its the same when you reload you app. Default is unit ether . Parameters unit ( String ) - the unit to set, see Usage for more Returns Boolean - TRUE if the unit is an allowed unit and could be set Example ```js\nEthTools.setUnit(\"btc\"); Tracker.autorun(function() {\n  var amount = EthTools.formatBalance(\"23000000000000000000\", \"0,0.0[00] unit\");\n  // amount = \"0.287 btc\"\n});\n``` EthTools.getUnit EthTools.getUnit() Note This is only available when used as a Meteor package. Reactivly gets the current set default unit, used byt other EthTools methods when no unit was passed.\nAnd also persists it in localstorage so its the same when you reload you app. Default is unit ether . Parameters none Returns String - the current default unit. Example ```js\nEthTools.setUnit(\"btc\"); Tracker.autorun(function() {\n  var unit = EthTools.getUnit();\n  // unit === 'btc'\n});\n``` EthTools.formatNumber EthTools.formatNumber(number, format) Formats any number using numeral.js , e.g. \"0,0.00[0000]\" . Parameters number ( String|Number ) - the number to format format ( String ) - the format see numeral.js for examples, e.g. \"0,0.00[0000]\" Returns String - the formated number. Example js\nvar finney = EthTools.formatNumber(2000, \"0,0.00\");\n// finney = '2,000.00' Format number template helper Usage html\n{{dapp_formatNumber \"1000000133\" \"0,0.00[0000]\"}} EthTools.formatBalance EthTools.formatBalance(wei, format, unit) Formats a number of wei into any other ethereum unit and other currencies (see Usage ). Default is unit ether . The format property follows the numeral.js formatting, e.g. \"0,0.00[0000]\" .\nAdditionally you can add \"unit\" or \"UNIT\" (for uppercase) to display the unit after or before the number the number. Additionally this function uses the reactive EthTools.getUnit() variable, when no unit was given.\nYou can then reactivly change the unit using EthTools.setUnit('finney') Parameters wei ( String|Number ) - the amount of wei to convert and format format ( String ) - the format see numeral.js for examples, e.g. \"0,0.00[0000]\" . unit ( String ) - (optional) the unit to convert the given wei amount to, if not given it will use EthTools.getUnit() Returns String - the formated balance. Example js\nvar amount = EthTools.formatBalance(\n  112345676543212345,\n  \"0,0.0[00] unit\",\n  \"finney\"\n);\n// amount = \"112.346 finney\" Format balances template helper Usage html\n{{dapp_formatBalance \"1000000133\" \"0,0.00[0000]\" \"ether\"}} If you leave the last value it will use EthTools.getUnit() , as reactive localstorage variable. html\n{{dapp_formatBalance \"1000000133\" \"0,0.00\"}} Use then EthTools.setUnit(finney') to change the unit and displayed balances. EthTools.toWei EthTools.toWei(number, unit) Formats an amount of any supported unit (see Usage ) into wei. Default is unit ether . Additionally this function uses the reactive EthTools.getUnit() variable, when no unit was given.\nYou can then reactivly change the unit using EthTools.setUnit('finney') Parameters number ( String|Number ) - the number of a unit, see Usage for more unit ( String ) - the unit of the given number Returns String - the number in wei. Example js\nvar wei = EthTools.toWei(23, \"btc\");\n// wei = \"80000000000000000000\""}, {"name": "mining", "desc": null, "readme": null}, {"name": "mist", "desc": "[DEPRECATED] Mist. Browse and use \u00d0apps on the Ethereum network.", "readme": "Mist Browser [Deprecated] Mist and Ethereum Wallet have been deprecated. See the announcement and view the migration guide . The Mist browser is the tool of choice to browse and use \u00d0apps. For the Mist API see MISTAPI.md . This repository is also the Electron host for the Meteor-based wallet dapp . Help and troubleshooting In order to get help regarding Mist or Ethereum Wallet: Please check the Mist troubleshooting guide . Go to our Gitter channel to connect with the community for instant help. Search for similar issues and potential help. Or create a new issue and provide as much information as you can to recreate your problem. How to contribute Contributions via Pull Requests are welcome. You can see where to help looking for issues with the Enhancement or Bug labels. We can help guide you towards the solution. You can also help by responding to issues . Sign up on CodeTriage and it'll send you gentle notifications with a configurable frequency. It is a nice way to help while learning. Installation If you want to install the app from a pre-built version on the release page , you can simply run the executable after download. For updating, simply download the new version and copy it over the old one (keep a backup of the old one if you want to be sure). Linux .zip installs In order to install from .zip files, please install libgconf2-4 first: bash\napt-get install libgconf2-4 Config folder The data folder for Mist depends on your operating system: Windows %APPDATA%\\Mist macOS ~/Library/Application\\ Support/Mist Linux ~/.config/Mist Development For development, a Meteor server assists with live reload and CSS injection. Once a Mist version is released the Meteor frontend part is bundled using the meteor-build-client npm package to create pure static files. Dependencies To run mist in development you need: Node.js v7.x (use the preferred installation method for your OS) Meteor javascript app framework Yarn package manager Install the latter ones via: bash\n$ curl https://install.meteor.com/ | sh\n$ curl -o- -L https://yarnpkg.com/install.sh | bash Initialization Now you're ready to initialize Mist for development: bash\n$ git clone https://github.com/ethereum/mist.git\n$ cd mist\n$ git submodule update --init --recursive\n$ yarn Run Mist For development we start the interface with a Meteor server for auto-reload etc. Start the interface in a separate terminal window: bash\n$ yarn dev:meteor In the original window you can then start Mist with: bash\n$ cd mist\n$ yarn dev:electron NOTE: Client binaries (e.g. geth ) specified in clientBinaries.json will be checked during every startup and downloaded if out-of-date, binaries are stored in the config folder . NOTE: use --help to display available options, e.g. --loglevel debug (or trace ) for verbose output Run the Wallet Start the wallet app for development, in a separate terminal window: bash\n$ yarn dev:meteor In another terminal: bash\n$ cd my/path/meteor-dapp-wallet/app && meteor --port 3050 In the original window you can then start Mist using wallet mode: bash\n$ cd mist\n$ yarn dev:electron --mode wallet Connect your own node This is useful if you are already running your own node or would like to connect with a private or development network. bash\n$ yarn dev:electron --rpc path/to/geth.ipc Passing options to Geth You can pass command-line options directly to Geth by prefixing them with --node- in\nthe command-line invocation: bash\n$ yarn dev:electron --mode mist --node-rpcport 19343 --node-networkid 2 The --rpc Mist option is a special case. If you set this to an IPC socket file\npath then the --ipcpath option automatically gets set, i.e.: bash\n$ yarn dev:electron --rpc path/to/geth.ipc ...is the same as doing... bash\n$ yarn dev:electron --rpc /my/geth.ipc --node-ipcpath /path/to/geth.ipc Creating a local private net If you would like to quickly set up a local private network on your computer, run: bash\ngeth --dev Look for the IPC path in the resulting geth output, then start Mist with: bash\n$ yarn dev:electron --rpc path/to/geth.ipc Deployment Our build system relies on gulp and electron-builder . Dependencies Cross-platform builds require additional dependencies needed by Electron Builder. Please follow their instructions for up to date dependency information. Generate packages To generate the binaries for Mist run: bash\n$ yarn build:mist To generate the Ethereum Wallet: bash\n$ yarn build:wallet The generated binaries will be under dist_mist/release or dist_wallet/release . Starting from 0.11.0, both Ethereum Wallet and Mist ships with a meteor-dapp-wallet instance (https://github.com/ethereum/meteor-dapp-wallet). Options platform To build binaries for specific platforms (default: all available) use the following flags: bash\n$ yarn build:mist --mac      # mac\n$ yarn build:mist --linux    # linux\n$ yarn build:mist --win      # windows skipTasks When building a binary, you can optionally skip some tasks \u2014 generally for testing purposes. bash\n$ yarn build:mist --mac --skipTasks=build-interface,release-dist Checksums Prints the SHA-256 checksums of the distributables. It expects installer/zip files to be in the generated folders e.g. dist_mist/release bash\n$ yarn task checksums [--wallet] Tasks found in gulpfile.js and gulpTasks/ Any other gulp task can be run using yarn task . bash\n$ yarn task clean-dist Testing Tests run using Spectron , a webdriver.io runner built for Electron. First make sure to build Mist with: bash\n$ yarn build:mist Then run the tests: bash\n$ yarn test:unit:once\n$ yarn test:e2e Note: Integration tests are not yet supported on Windows."}, {"name": "mix", "desc": "The Mix Ethereum Dapp Development Tool", "readme": "Mix The Mix Ethereum Dapp Development Tool Mix is an IDE that allows developers to build and deploy contracts and decentralized applications on top of the Ethereum blockchain. it includes: Source code editor for Solidity (contract - backend) and HTML/JS (frontend) Solidity source code debugger Blockchain editor Internal RPC server (allows debugging transactions/calls created from the web3 JavaScript API) Dapp/Contract deployment (deploying to test or live chain) Mix has been discontinued. We are now focusing on remix ( https://github.com/ethereum/remix ) which will provide soon the same level of functionality as mix. \nRemix is in the early stage (alpha version). it only provides VM debugging for now.\nRemix has already been integrated with browser solidity \n( https://ethereum.github.io/browser-solidity/#version=soljson-latest.js ). You can use it right now. But as remix is still alpha, i would not recommend to use it as a production tool. please wait for further announcements.\nThanks and i hope you will enjoy playing with remix! \nFeel free to join the gitter channel https://gitter.im/ethereum/remix and share your thoughts with us. Download binaries:\n    https://github.com/ethereum/mix/releases Build from source:\n    http://www.ethdocs.org/en/latest/ethereum-clients/cpp-ethereum/building-from-source/"}, {"name": "moon-browser", "desc": "Moon-Browser was a browser for decentralized applications in 2016", "readme": "Archival Notice This repository is archived. Please check out https://ethereum.org/en/dapps/ to learn more about Dapps. Moon-Browser A browser implementation of the Moon Engine: an ultra-lightweight, formally verified kernel for decentralized applications (DApps). Note: this is repository is not the formally verified engine, but a lightweight (300kb minified) demo of the same DAppSpec in HTML5. The engine itself will be a native Idris binary, and is planned to be released in 2018. Installation Install go-ipfs from https://ipfs.io/ipns/dist.ipfs.io/#go-ipfs npm install npm run build Run Open app/index.html in your favorite browser."}, {"name": "moon-lang", "desc": "Minimal code-interchange format", "readme": "Moon Moon is an minimal, JIT-compilable, portable and secure code-interchange format. It is: Safe: Moon isolates logic from side-effects, allowing you to securely run code from untrusted sources. Fast: when compiled to JS, it beats popular libs by a large margin . Compact: Moon has a canonical binary format for very small bundles. Decentralized: Moon imports are hash-addressed, recursively resolved from IPFS . Small: this entire implementation, for example, is a 7.5K JS file (gzipped). Formally, Moon is just untyped \u03bb-calculus extended with numbers, strings and maps. Usage / Examples Running code To evaluate some code, simply use Moon.run() : ```javascript\nconst Moon = require(\"moon-lang\")(); const program = maximum = array =>\n    (for 0\u00a0(get array \"length\") 0 index => result =>\n      value = (get array (stn index))\n      (if (gtn value result)\n        value\n        result))\n  (maximum [1\u00a07\u00a06\u00a09\u00a05\u00a02\u00a08]) ; console.log(Moon.run(program));\n``` This is safe to do no matter the code contents, because Moon runs fully sandboxed. Compiling Moon to a native function You can also JIT-compile it to fast native functions: ```javascript\nconst Moon = require(\"moon-lang\")(); const factorial = Moon.parse( n =>\n  (for 1\u00a0(add n 1) 1\u00a0i => result =>\n    (mul i result)) ); console.log(factorial(4));\n``` Decompiling a native function to Moon And the other way around: ```javascript\nconst Moon = require(\"moon-lang\")(); const pair = Moon.parse(\"a => b => [a b]\"); console.log(Moon.stringify(pair(1)));\n``` Loading code from IPFS Moon can recursivelly import hash-addressed terms from IPFS: ```javascript\nconst Moon = require(\"moon-lang\")(); (async () => { const sum = Moon.parse(await Moon.imports(`n =>\n    // Imports array library from IPFS\n    List = zb2rha9PW5Wnvhvz1n7pxXFZoMzeD3NxKYdZUHgxEsbhW8B4D\n    reduce = (List \"foldr\")\n    range = (List \"range\") (reduce (add) 0 (range 0\u00a0n)) `)); console.log(sum(5000000)); })();\n``` Saving code to IPFS It can also easily publish those terms: ```javascript\nconst Moon = require(\"moon-lang\")(); (async () => { const cid = await Moon.save(\"x => (mul x 2)\");\n  console.log(cid); const double = Moon.parse(await Moon.imports(cid));\n  console.log(double(7)); })();\n``` Performing side-effects (IO) Moon itself is pure, but it can perform side-effective computations by injecting the effects from the host language. To avoid the \"callback-hell\", you can use Moon's monadic notation: ```javascript\ndo = zb2rhkLJtRQwHz9e5GjiQkBtjL2SzZZByogr1uNZFyzJGA9dX askPowerLevel = loop@ lazy =>\n  | power =< (do \"prompt\" \"What is your power level? \")\n    (if (gtn (stn power) 9000)\n      | (do \"print\" \"No, it is not.\")>\n        (loop 0)\n      | (do \"print\" \"Ah, that's cute!\")>\n        (do \"stop\")) (askPowerLevel 0)\n``` You can run the code above using moon-tool : bash\nmoon runio zb2rhjR4sMEiMQ9m9bNCnavSUjEDzUvSrtAhuJStRWHcvNzb8 Optimizing code Use # to fully inline an expression. Use {fast:true} option (faster, only tradeoff is it can't be decompiled). Don't use recursive algorithms (map, reduce, etc.) directly on arrays; convert to churh-lists to enable fusion. ```javascript\n(async () => { // Notice the hash (#): it fully inlines an expression, making it 8x faster.\nconst dotCode = # x0 => y0\u00a0=> z0 => x1 => y1 => z1 =>\n  Array = zb2rhYmsjmQuJivUtDRARcobLbApVQZE1CwqhfnbBxmYuGpXx\n  a = [x0 y0\u00a0z0]\n  b = [x1 y1\u00a0z1]\n  (Array \"sum\" (Array \"zipWith\" (mul) a\u00a0b)) ; // Also, use {fast:true}\nconst dot = Moon.parse(await Moon.imports(dotCode), {fast:true}); // Call it a ton of times\nvar dots = 0;\nfor (var i =\u00a00; i < 1000000; ++i) {\n  dots += dot(1)(2)(3)(4)(5)(6);\n}\nconsole.log(dots); // Check the difference on the output\nconsole.log(Moon.compile(await Moon.imports(dotCode))); })();\n``` Exporting Moon libs to npm See this repository. CLI Check out moon-tool . TODO Time limit option"}, {"name": "moon-tool", "desc": "Command-lite tool for Moon-lang", "readme": "moon-tool Command-line tool for Moon-lang . Allows you to: Run expressions and files from the command-line; Load/save expressions and files to IPFS; Pack/unpack, compile to JS, etc... Installing bash\nnpm i -g moon-tool Usage Inline execution: bash\nmoon run '(add 1\u00a02)'        -- output: 3\nmoon run 'x=4\u00a0y=2 [x y]'    -- output: [4 2]\nmoon run '((x => [x x]) 3)' -- output: [3\u00a03] File execution: bash\necho '\"Hello\"' >> hi.moon\nmoon run hi -- output: \"Hello\" Saving to IPFS: bash\nmoon save 'x => (add x 1)'\n-- output: zb2rhoKHTgNBYJDnzaBn8uaCpKuX9iGpsc2hpLdE2k2YTD1jH After you save an expression, you may use its hash inside other expressions: moon run recursively imports IPFS hashes. Loading from IPFS: bash\nmoon load zb2rhoKHTgNBYJDnzaBn8uaCpKuX9iGpsc2hpLdE2k2YTD1jH\n-- output: x => (add x 1) Updating IPFS imports: If you modify a file and save it to IPFS, all files that import it will keep using the old version, because Moon guarantees that a file's behavior doesn't change if its contents don't change. This can be very annoying when you just want to update a file which is imported in many places. To amend that, moon-tool provides the replace command, which allows you to change the contents of a file, save it to IPFS and recursivelly update all imports that refer to the old version. Example: ```bash creates a helloworld.moon file which imports a hello.moon file $ echo \"\\\"hello\\\"\" > hello.moon $ echo \"[$(moon save hello) \\\"world\\\"]\" > helloworld.moon Prints and runs both files $ cat hello.moon\n\"hello\" $ moon run hello\n\"hello\" $ cat helloworld.moon\n[zb2rhfsstEj5riwMdMpKep4h1MmCXTzKYrucQJ6TEqRCRRxAw \"world\"] $ moon run helloworld\n[\"hello\" \"world\"] Rewrites hello.moon 's contents $ moon replace hello.moon \"\\\"hola\\\"\"\nzb2rhfsstEj5riwMdMpKep4h1MmCXTzKYrucQJ6TEqRCRRxAw -> zb2rhf5uqM37QCXN8VMTXYPDA2XB2w1fwHzy91CjWovJmVGUW (hello.moon)\nzb2rhiNoCanP5qCJeePx5zEyp8EBp9tBgGrEmQJ1K7ZKNSena -> zb2rhkikpZPfJGvJJ2wyUSTe9W4zeKBJHuaSrfpFBpbH18M3N (helloworld.moon) Prints and runs both files again $ cat hello.moon\n\"hola\" $ moon run hello\n\"hola\" $ cat helloworld.moon\n[zb2rhf5uqM37QCXN8VMTXYPDA2XB2w1fwHzy91CjWovJmVGUW \"world\"] $ moon run helloworld\n[\"hola\" \"world\"] Notice helloworld.moon changed accourdingly. ``` You can also replace arbitrary expressions: moon replace \"some_regex\" \"new_value\" Note moon replace modifies your files, so use it carefully. Running with side-effects: bash\nmoon runIO 'ask => end => (ask \"prompt\" \"Hi!\" then => (end 0))' Moon is pure, but you can still peform side-effects by evaluating computations in a side-effective language. The runIO command does that with default side-effects. Compiling to JavaScript: bash\nmoon compile 'x => (mul x 10)'"}, {"name": "natspec.js", "desc": "Javascript Library used to evaluate natspec expressions", "readme": "natspec.js Javascript Library used to evaluate natspec expressions Usage It exposes global object natspec with method evaluateExpression . ```javascript\nvar natspec = require('natspec'); var natspecExpression = \"Will multiply a by 7 and return a * 7 .\";\nvar call = {\n    method: 'multiply',\n    abi: abi,\n    transaction: transaction\n}; var evaluatedExpression = natspec.evaluateExpression(natspecExpression, call);\nconsole.log(evaluatedExpression); // \"Will multiply 4 by 7 and return 28.\"\n``` More examples are available here . Building bash\nnpm run-script build Testing (mocha) bash\nnpm test Testing (go) bash\ngo test Wiki Ethereum Natural Specification Format Natspec Example"}, {"name": "news", "desc": null, "readme": null}, {"name": "node-crawler", "desc": "Attempts to crawl the Ethereum network of valid Ethereum execution nodes and visualizes them in a nice web dashboard.", "readme": "Ethereum Node Crawler Crawls the network and visualizes collected data. This repository includes backend, API and frontend for Ethereum network crawler. Backend is based on devp2p tool. It tries to connect to discovered nodes, fetches info about them and creates a database. API software reads raw node database, filters it, caches and serves as API. Frontend is a web application which reads data from the API and visualizes them as a dashboard. Features: Advanced filtering, allows you to add filters for a customized dashboard Drilldown support, allows you to drill down the data to find interesting trends Network upgrade readiness overview Responsive mobile design Contribute Project is still in an early stage, contribution and testing is welcomed. You can run manually each part of the software for development purposes or deploy whole production ready stack with Docker. Frontend Development For local development with debugging, remoting, etc: Copy .env into .env.local and replace the variables. And then npm install then npm start Run tests to make sure the data processing is working good. npm test Production To deploy this web app: Build the production bits by npm install then npm run build the contents will be located in build folder. Use your favorite web server, in this example we will be using nginx. The nginx config for that website could be which proxies the api to endpoint /v1 .\n   Review the frontent/nginx.conf file for an example. Backend API The API is using 2 databases. 1 of them is the raw data from the crawler and the other one is the API database.\nData will be moved from the crawler DB to the API DB regularly by this binary.\nMake sure to start the crawler before the API if you intend to run them together during development. Dependencies golang sqlite3 Development go run ./cmd/crawler Production Build the assembly into /usr/bin go build ./cmd/cralwer -o /usr/bin/node-crawler Create a system user for running the application useradd --system --create-home --home-dir /var/lib/node-crawler node-crawler Make sure database is in /var/lib/node-crawler/crawler.db Create a systemd service in /etc/systemd/system/node-crawler.service :\n   ```\n   [Unit]\n   Description = eth node crawler api\n   Wants       = network-online.target\n   After       = network-online.target [Service]\n   User       = node-crawler\n   ExecStart  = /usr/bin/node-crawler api --crawler-db /var/lib/node-crawler/crawler.db --api-db /var/lib/node-crawler/api.db\n   Restart    = on-failure\n   RestartSec = 3\n   TimeoutSec = 300 [Install]\n   WantedBy = multi-user.target 1. Then enable it and start it. systemctl enable node-crawler\n   systemctl start node-crawler\n   systemctl status node-crawler\n   ``` Crawler Dependencies golang sqlite3 Country location GeoLite2-Country.mmdb file from https://dev.maxmind.com/geoip/geolite2-free-geolocation-data?lang=en you will have to create an account to get access to this file Development go run ./cmd/crawler Run crawler using crawl command. go run ./cmd/crawler crawl Production Build crawler and copy the binary to /usr/bin . go build ./cmd/crawler -o /usr/bin/node-crawler Create a systemd service similarly to above API example. In executed command, override default settings by pointing crawler database to chosen path and setting period to write crawled nodes.\nIf you want to get the country that a Node is in you have to specify the location the geoIP database as well. No GeoIP node-crawler crawl --timeout 10m --crawler-db /path/to/database With GeoIP node-crawler crawl --timeout 10m --crawler /path/to/database --geoipdb GeoLite2-Country.mmdb Docker setup Production build of preconfigured software stack can be easily deployed with Docker. To achieve this, clone this repository and access docker directory. Make sure you have Docker and docker-compose tools installed. The docker compose uses a local ./data directory to store the database and GeoIP file.\nIt's best to create this directory and add the GeoIP file before starting the system.\nYou can read the ./docker-compose.yml file for more details. docker-compose up Developing with Nix Nix is a package manager and system configuration tool\nand language for reproducible, declarative, and reliable systems. The Nix Flake in this repo contains all the\ndependencies needed to build the frontend and crawler. The flake.lock file locks the commit which the package manager uses to build\nthe packages. Essentially locking the dependencies in time, not in version. To update the lock file, use nix flake update --commit-lock-file this will\nupdate the git commits in the lock file, and commit the new lock file with a\nnice, standard commit message which shows the change in commit hashes for each\ninput. To activate the development environment with all the packages available, you\ncan use the command nix develop . To automate this process, you can use direnv with use flake in your .envrc . You can learn\nmore about Nix and direnv here . Deploying with NixOS Nix is a package manager and system configuration tool\nand language for reproducible, declarative, and reliable systems. The Nix Flake in this repo also contains a\nNixOS module for configuring and deploying the node-crawler, API, and Nginx. There is just a little bit of extra configuration which is needed to bring\neverything together. An example production configuration: Your NixOS flake.nix : ```nix\n{\n  inputs = {\n    nixpkgs.url = \"github:NixOS/nixpkgs/nixos-unstable\";\n    node-crawler.url = \"github:ethereum/node-crawler\";\n  };\n  outputs = {\n    nixpkgs,\n    node-crawler,\n  }:\n  {\n    nixosConfigurations = {\n      crawlerHostName = nixpkgs.lib.nixosSystem {\n        specialArgs = {\n          inherit node-crawler\n        };\n        modules = [\n          ./configuration.nix node-crawler.nixosModules.nodeCrawler\n    ];\n  };\n}; };\n}\n``` Your example configuration.nix : ```nix\n{ node-crawler, ... }: {\n  # Add the overlay from the node-crawler flake\n  # to get the added packages.\n  nixpkgs.overlays = [\n    node-crawler.overlays.default\n  ]; # It's a good idea to have your firewall\n  # enabled. Make sure you have SSH allowed\n  # so you don't lock yourself out. The openssh\n  # service should do this by default.\n  networking = {\n    firewall = {\n      enable = true;\n      allowedTCPPorts = [\n        80\n        443\n      ];\n    };\n  }; services = {\n    nodeCrawler = {\n      enable = true;\n      hostName = \"server hostname\";\n      nginx = {\n        forceSSL = true;\n        enableACME = true;\n      };\n    }; # Needed for the node crawler to get the country\n# of the crawled IP address.\ngeoipupdate = {\n  enable = true;\n  settings = {\n    EditionIDs = [\n      \"GeoLite2-Country\"\n    ];\n    AccountID = account_id;\n    LicenseKey = \"location of licence key on server\";\n  };\n}; }; # Needed to enable ACME for automatic SSL certificate\n  # creation for Nginx.\n  security.acme = {\n    acceptTerms = true;\n    defaults.email = \"admin+acme@example.com\";\n  };\n}\n```"}, {"name": "node-ethereum", "desc": "[DEPRECATED] a simple standalone or embeddable Ethereum client written for Node.js", "readme": "node-ethereum [DEPRECATED] this is being broken into micro-services, Like - node blockchain server Install git clone https://github.com/ethereum/node-ethereum cd ./node-ethereum npm install . Run ./bin/neth Embed javacsript\n App = require('../')\n app = new App();\n app.start(function(){\n  console.log(\"Ethereum has started\");\n });"}, {"name": "nodemonitor", "desc": "A little node monitoring utility", "readme": "Node monitor This is a little tool to keep track on a set of nodes, \nand see if they keep in step or if they go out of consensus. Usage Copy the config.example.toml into a config.toml file and fill in the required information with Docker: docker run -d --name nodemonitor -p 8080:8080 -v <path-to-config.toml>/config.toml:/config.toml holiman/nodemonitor:latest /config.toml Access the webpage by navigating to http://localhost:8080 Dashboard It shows a neat little dashboard, where 'interesting' points of differing opinions are shown: Metrics It also has support for pushing metrics to influxdb , so you can get nice charts and \nalerts from all/any node which supports basic set of standard rpc methods."}, {"name": "oyente", "desc": "The project has been moved to this new repo https://github.com/melonproject/oyente", "readme": "Oyente Note: The project has been moved to the new repo https://github.com/melonproject/oyente Quick Start A container with the dependencies set up and the blockchain snapshot installed can be found here . To open the container, install docker and run: docker pull hrishioa/oyente && docker run -i -t hrishioa/oyente To evaluate the greeter contract inside the container, run: cd /home/oyente/oyente && source ../dependencies/venv/bin/activate && python oyente.py greeter.sol and you are done! Dependencies solc and disasm from go-ethereum z3 Theorem Prover Evaluating Ethereum Contracts python oyente.py <contract filename> And that's it! Run python oyente.py --help for a list of options. Paper The accompanying paper explaining the bugs detected by the tool can be found here . Miscellaneous Utilities A collection of the utilities that were developed for the paper are in misc_utils . Use them at your own risk - they have mostly been disposable. generate-graphs.py - Contains a number of functions to get statistics from contracts. get_source.py - The get_contract_code function can be used to retrieve contract source from EtherScan transaction_scrape.py - Contains functions to retrieve up-to-date transaction information for a particular contract. Benchmarks Note: This is an improved version of the tool used for the paper. Benchmarks are not for direct comparison. To run the benchmarks, it is best to use the docker container as it includes the blockchain snapshot necessary.\nIn the container, run batch_run.py after activating the virtualenv. Results are in results.json once the benchmark completes. The benchmarks take a long time and a lot of RAM in any but the largest of clusters, beware. Some analytics regarding the number of contracts tested, number of contracts analysed etc. is collected when running this benchmark. Known Issues If you encounter the unhashable instance error, please add the following to your class AstRef(Z3PPObject): in /usr/lib/python2.7/dist-packages/z3.py : def __hash__(self):\n        return self.hash() The latest version of Z3 does support this, but some previous version does not."}, {"name": "plasma", "desc": null, "readme": "plasma"}, {"name": "play", "desc": "playproject", "readme": "(deprecated) => visit https://github.com/playproject-io instead"}, {"name": "pm", "desc": "Project Management: Meeting notes and agenda items", "readme": "Ethereum Project Management Repository This repository is used for project management for various initiatives affecting the Ethereum protocol. The main use of this repository is for the Execution and Consensus Layer AllCoreDevs meetings. It is also used for Breakout Rooms on various protocol-related topics, whose agendas can be found under the Issues page. This Google Calendar also tracks upcoming protocol meetings. AllCoreDevs Meetings Overview Purpose AllCoreDevs is a weekly meeting held by the Ethereum development community to discuss technical issues and coordinate work on the Ethereum protocol. The meetings are attended by core contributors from various organizations. During the call, participants discuss potential protocol changes, testing and other related issues. On one week, the focus of the call is on Ethereum's consensus layer (i.e. proof-of-stake, the Beacon Chain, etc.) and on alternate weeks, the focus of the call is on Ethereum's execution layer (i.e. the EVM, gas schedules, etc.). The calls are streamed and saved on the @EthereumProtocol YouTube channel . Agendas The agendas for calls are tracked in the Issues tab of this repository. To add an item to an agenda, simply add a comment to one of the agenda issues. Anyone is welcome to add an item to the agenda as long as it follows these guidelines: The topic is technical in nature. The topic involves the Ethereum protocol at a low-level. This means Ethereum applications and ERCs are generally not allowed as topics, unless their mention relates to protocol changes. The topic should not be philosophical. The core developer meetings are not meant to decide philosophical contentious issues that should be decided by the community. There are exceptions to this, but generally these topics distract from more productive technical discuss Ethereum Magicians forum is a better venue for such discussions. Who Can Attend Protocol developers, researchers and EIP authors are invited to attend the meetings. Generally every Ethereum client is represented as well as key members of testing and security teams, and independent core contributors. Sometimes non-core contributors with particular expertise on a topic are invited on to discuss a specific agenda item. If you feel you would contribute to the meetings by your attendance please reach out to Tim Beiko . Who Facilitates the Meetings Early in Ethereum's history, (2015-fall 2016) George Hallam facilitated the AllCoreDevs meetings. Starting in fall 2016, Hudson Jameson took over the meetings. In early 2018 Lane Rettig joined to help facilitate meetings, handle recordings, and publish notes. Today, Tim Beiko and Danny Ryan respectively facilitate the execution and consensus layer AllCoreDevs meetings. Breakout Rooms are usually chaired by the expert/champion for the topic at hand. The Ethereum Cat Herders provide full transcripts for AllCoreDevs meetings, as well as some Breakout Rooms. The meetings are independent of any organization. However, Danny Ryan & Tim Beiko are contractors for the Ethereum Foundation and the Ethereum Foundation pays for the video-conference software used in the meetings. Livestreaming instruction for the meetings can be found here . Previous AllCoreDevs Meetings Execution Layer | \u2116   | Date                                 | Agenda                                              | Notes                                                                                                                                                                    | Recording                                                                          |\n| --- | ------------------------------------ | --------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------- |\n| 175 | November 23, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 174 | November 09, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 173 | October 26, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 172 | October 12, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 171 | September 28, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 168 | August 17, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 166 | July 20, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 165 | July 6, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 164 | June 22, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 163 | June 8, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 162 | May 25, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 161 | April 13, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 160 | April 13, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 159 | April 13, 2023, 14:00-15:30 UTC       | agenda | notes \\| Twitter | Video | 158 | Mar 30, 2023, 14:00-15:30 UTC         | agenda | notes \\| Twitter | Video | 157 | Mar 16, 2023, 14:00-15:30 UTC         | agenda | notes \\| Twitter | Video | 156 | Mar 2, 2023, 14:00-15:30 UTC         | agenda | notes \\| Twitter | Video | 155 | Feb 16, 2023, 14:00-15:30 UTC         | agenda | notes \\| Twitter | Video | 154 | February 9, 2023, 14:00 UTC         | agenda | notes \\| Twitter | Video | 153 | January 19, 2023, 14:00-15:30 UTC         | agenda | notes \\| Twitter | Video | 152 | January 5, 2023, 14:00-15:30 UTC         | agenda | notes \\| Twitter | Video | 151 | December 8, 2022, 14:00 UTC         | agenda | notes \\| Twitter | Video | 150 | November 24, 2022, 14:00 UTC         | agenda | notes \\| Twitter | Video | 149 | November 10, 2022, 14:00 UTC         | agenda | notes \\| Twitter | Video | 148 | October 27, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 147 | September 15, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 146 | September 1, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 145 | Thursday  August 18, 14:00 UTC          | agenda | notes \\| Twitter | video | 144 | August 4, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 143 | July 21, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 142 |July 8, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 141 | June 24, 2022, 14:00 UTC          | agenda | notes | video | 140 | Jun 10, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 139 | May 27, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 137 | April 29, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 136 | April 15, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 134 | March 18, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 133 | March 4, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 132 | February 18, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 131 | February 4, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 130 | January 21, 2022, 14:00 UTC          | agenda | notes \\| Twitter | video | 129 | January 7, 2022, 14:00 UTC         | agenda | notes \\| Twitter | video | 128 | December 10, 2021, 14:00 UTC          | agenda | notes \\| Twitter | video | 127 | November 26, 2021, 14:00 UTC          | agenda | notes \\| Twitter | video |\n| 126 | November 12, 2021, 14:00 UTC          | agenda | notes \\| Twitter | video |\n| 125 | October 29, 2021, 14:00 UTC          | agenda | notes \\| Twitter | video |\n| 124 | October 15, 2021, 14:00 UTC          | agenda | notes \\| Twitter | video |\n| 123 | October 1, 2021, 14:00 UTC       | agenda | notes \\| Twitter | video |\n| 121 | September 03,  2021, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 122 | Friday 17 September, 14:00 UTC       | agenda | notes \\| Twitter | video |\n| 120 | Friday 20 August at 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 119 | Friday 6 August at 14:00 UTC         | agenda | notes \\| Twitter | video |\n| 118 | Friday 23 July at 14:00 UTC          | agenda | notes \\| Twitter | video |\n| 117 | Friday 09 July at 14:00 UTC          | agenda | notes \\| Twitter | video |\n| 116 | Friday 25 June at 14:00 UTC          | agenda | notes \\| Twitter | video |\n| 115 | Friday 11 June at 14:00 UTC          | agenda | notes \\| Twitter | video |\n| 114 | Friday 28 May at 14:00 UTC           | agenda | notes \\| Twitter | video |\n| 113 | Thursday 14 May at 13:00 UTC         | agenda | notes \\| Twitter | video |\n| 112 | Thursday 30 April 2021, 13:00UTC     | agenda | notes \\| Twitter | video |\n| 111 | Friday 23 April 2021, 14:00UTC       | agenda | notes \\| Twitter | video |\n| 110 | Friday April 16th, 2021, 14:00 UTC   | agenda | notes \\| Twitter | video |\n| 109 | Friday 02 Apr 2021, 14:00UTC         | agenda | notes \\| Twitter | video |\n| 108 | Friday 19 Mar 2021, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 107 | Friday 05 Mar 2021, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 106 | Friday 19 Feb 2021, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 105 | Friday 05 Feb 2021, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 104 | Friday 22 Jan 2021, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 103 | Friday 8 Jan 2021, 14:00 UTC         | agenda | notes \\| Twitter | video |\n| 102 | Friday 11 Dec 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 101 | Friday 27 Nov 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 100 | Friday 13 Nov 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 99  | Friday 30 Oct 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 98  | Friday 16 Oct 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 97  | Friday 02 Oct 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 96  | Friday 18 Sep 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 95  | Friday 04 Sep 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 94  | Friday 21 Aug 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 93  | Friday 07 Aug 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 92  | Friday 24 July 2020, 14:00 UTC       | agenda | notes \\| Twitter | video |\n| 91  | Friday 10 July 2020, 14:00 UTC       | agenda | notes \\| Twitter | video |\n| 90  | Friday 26 June 2020, 14:00 UTC       | agenda | notes \\| Twitter | video |\n| 89  | Friday 12 June 2020, 14:00 UTC       | agenda | notes \\| Twitter | video |\n| 88  | Friday 29 May 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 87  | Friday 15 May 2020, 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 86  | Friday 1 May 2020, 14:00 UTC         | agenda | notes \\| Twitter | video |\n| 85  | Friday 17 April 2020, 14:00 UTC      | agenda | notes \\| Twitter | video |\n| 84  | Friday 3 April 2020, 14:00 UTC       | agenda | notes \\| Twitter | video |\n| 83  | Friday 20 March 2020, 14:00 UTC      | agenda | notes \\| Twitter | video |\n| 82  | Friday 6 March 2020, 14:00 UTC       | agenda | notes \\| Twitter | video |\n| 81  | Friday 21 February 2020, 14:00 UTC   | agenda | notes \\| Twitter | video |\n| 80  | Friday, February 7, 2020 14:00 UTC   | agenda | notes \\| Twitter | video |\n| 79  | Friday, January 24, 2020 14:00 UTC   | agenda | notes \\| Twitter | video |\n| 78  | Friday, January 10, 2020 14:00 UTC   | agenda | notes \\| Twitter | video |\n| 77  | Friday, December 13, 2019, 14:00 UTC | agenda | notes \\| Twitter | video |\n| 76  | Friday, November 29, 2019 14:00 UTC  | agenda | notes \\| Twitter | video |\n| 75  | Friday, November 15, 2019 14:00 UTC  | agenda | notes \\| Twitter | video |\n| 74  | Friday, November 1, 2019 14:00 UTC   | agenda | notes \\| Twitter | video |\n| 73  | Friday, October 25, 2019 14:00 UTC   | agenda | notes \\| Twitter | video |\n| 72  | Friday, October 4, 2019 14:00 UTC    | agenda | notes \\| Twitter | video |\n| 71  | Friday, September 20, 2019 14:00 UTC | agenda | notes \\| Twitter | video |\n| 70  | Friday, September 6, 2019 14:00 UTC  | agenda | notes \\| Twitter | video |\n| 69  | Friday, August 23, 2019 14:00 UTC    | agenda | notes \\| Twitter | video |\n| 68  | Thursday, August 15, 2019 22:00 UTC  | agenda | notes | video |\n| 67  | Friday, August 2, 2019 06:00 UTC     | agenda | notes \\| Twitter | video |\n| 66  | Friday, July 26, 2019 14:00 UTC      | agenda | notes \\| Twitter | video |\n| 65  | Friday, July 19, 2019 22:00 UTC      | agenda | notes \\| Twitter | video |\n| 64  | Friday, July 5, 2019 06:00 UTC       | agenda | notes \\| Twitter | video |\n| 63  | Friday, June 21, 2019 14:00 UTC      | agenda | notes \\| Twitter | video |\n| 62  | Fri, May 24, 2019 14:00 UTC          | agenda | notes \\| Twitter | video |\n| 61  | Fri, May 10, 2019 14:00 UTC          | agenda | notes \\| Twitter | video |\n| 60  | Fri, April 26, 2019 14:00 UTC        | agenda | notes | video |\n| 59  | Fri, April 12, 2019 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 58  | Fri, March 29, 2019 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 57  | Fri, March 15, 2019 14:00 UTC        | agenda | notes \\| Twitter | video |\n| 56  | Fri, March 1, 2019 14:00 UTC         | agenda | notes | video |\n| 55  | Fri, February 15, 2019 14:00 UTC     | agenda | notes | video |\n| 54  | Fri, February 1, 2019 14:00 UTC      | agenda | notes | video |\n| 53  | Fri, January 18, 2019 14:00 UTC      | agenda | notes | video |\n| 52  | Fri, January 4, 2019 14:00 UTC       | agenda | notes | video |\n| 51  | Fri, December 7, 2018 14:00 UTC      | agenda | notes | video |\n| 1X  | Fri, November 30, 2018 14:00 UTC     | agenda | notes | not recorded                                                                       |\n| 50  | Fri, November 23, 2018 14:00 UTC     | agenda | notes | video |\n| 49  | Fri, November 9, 2018 14:00 UTC      | agenda | notes | video |\n| C2  | Fri, October 19, 2018 14:00 UTC      | agenda | notes | video |\n| 48  | Fri, October 12, 2018 14:00 UTC      | agenda | notes | video |\n| 47  | Fri, September 28, 2018 14:00 UTC    | agenda | notes | video |\n| 46  | Fri, September 14, 2018 14:00 UTC    | agenda | notes | video |\n| C1  | Fri, August 31, 2018 14:00 UTC       | agenda | None                                                                                                                                                                     | video |\n| 45  | Fri, August 24, 2018 14:00 UTC       | agenda | notes | video |\n| 44  | Fri, August 10, 2018 14:00 UTC       | agenda | notes | video |\n| 43  | Fri, July 27, 2018 14:00 UTC         | agenda | notes \\| reddit | video |\n| 42  | Fri, July 13, 2018 14:00 UTC         | agenda | notes | video |\n| 41  | Fri, June 29, 2018 14:00 UTC         | agenda | notes | video |\n| 40  | Fri, June 15, 2018 14:00 UTC         | agenda | notes | video |\n| 39  | Fri, June 1, 2018 14:00 UTC          | agenda | notes | video |\n| 38  | Fri, May 18, 2018 14:00 UTC          | agenda | notes | video |\n| 37  | Fri, April 20, 2018 14:00 UTC        | agenda | notes | video |\n| 36  | Fri, April 6, 2018 14:00 UTC         | agenda | notes | video |\n| 35  | Fri, March 23, 2018 14:00 UTC        | agenda | notes | video |\n| 34  | Fri, February 23, 2018 14:00 UTC     | agenda | notes \\| reddit | video |\n| 33  | Fri, February 9, 2018 14:00 UTC      | agenda | video |\n| 32  | Fri, January 26, 2018 14:00 UTC      | agenda | video |\n| 31  | Fri, January 12, 2018 14:00 UTC      | agenda | notes \\| reddit | video |\n| 30  | Fri, December 15, 2017 14:00 UTC     | agenda | notes | video |\n| 29  | Fri, December 1, 2017 14:00 UTC      | agenda | notes | video |\n| 28  | Fri, November 17, 2017 14:00 UTC     | agenda | notes | video |\n| 27  | Fri, October 20, 2017 14:00 UTC      | agenda | None                                                                                                                                                                     | video |\n| 26  | Fri, October 6, 2017 14:00 UTC       | agenda | None                                                                                                                                                                     | video |\n| 25  | Fri, September 22, 2017 14:00 UTC    | agenda | notes | video |\n| 24  | Fri, September 8, 2017 14:00 UTC     | agenda | notes | video |\n| 23  | Fri, August 25, 2017 14:00 UTC       | agenda | notes | video |\n| 22  | Fri, August 11, 2017 14:00 UTC       | agenda | notes | video |\n| 21  | Fri, July 28, 2017 14:00 UTC         | agenda | notes | video |\n| 20  | Fri, July 14, 2017 14:00 UTC         | agenda | notes | video |\n| 19  | Fri, June 30, 2017 14:00 UTC         | agenda | notes | video |\n| 18  | Fri, June 16, 2017 14:00 UTC         | agenda | notes | video |\n| 17  | Fri, June 3, 2017 14:00 UTC          | agenda | None                                                                                                                                                                     | video |\n| 16  | Fri, May 19, 2017 14:00 UTC          | agenda | notes | video |\n| 15  | Fri, May 5, 2017 14:00 UTC           | agenda | notes | not recorded                                                                       |\n| 14  | Fri, April 21, 2017 14:00 UTC        | agenda | notes | video |\n| 13  | Fri, April 7, 2017 14:00 UTC         | agenda | notes | video |\n| 12  | Fri, March 17, 2017 14:00 UTC        | agenda | notes | video |\n| 11  | Fri, March 3, 2017 14:00 UTC         | agenda | notes | video |\n| 10  | Fri, February 10, 2017 14:00 UTC     | agenda | notes | video |\n| 9   | Wed, January 25, 2017 14:00 UTC      | agenda | notes | video |\n| 8   | Fri, October 28, 2016 13:00 UTC      | agenda | notes | not recorded                                                                       |\n| 7   | Fri, September 2, 2016               | None                                                | notes | not recorded                                                                       |\n| ?   | Mon, May 2, 2016                     | None                                                | notes | not recorded                                                                       |\n| 2   | Fri, January 1, 2016                 | None                                                | notes | not recorded                                                                       |\n| 1   | Mon, November 30, 2015               | None                                                | notes | not recorded                                                                       |\n| 0   | ??                                   | None                                                | notes | not recorded                                                                       | Perma-archived Meetings The audio files of the Previous Meetings are stored permanently on Permacast . Consensus Layer Note: given the recent transition from the eth2.0-pm repository , some of the links below may be broken. \u2116  | Date                             | Notes          | Recording            |\n--- | -------------------------------- | -------------- | -------------------- |\n122| Thursday 2023/11/16 at 14:00 UTC | agenda \\| notes \\| no reddit | video 121| Thursday 2023/11/02 at 14:00 UTC | agenda \\| notes \\| no reddit | video 120| Thursday 2023/6/29 at 14:00 UTC | agenda \\| notes \\| no reddit | video 119| Thursday 2023/6/29 at 14:00 UTC | agenda \\| notes \\| no reddit | video 118| Thursday 2023/6/29 at 14:00 UTC | agenda \\| notes \\| no reddit | video 117| Thursday 2023/6/29 at 14:00 UTC | agenda \\| notes \\| no reddit | video 116| Thursday 2023/6/29 at 14:00 UTC | agenda \\| notes \\| no reddit | video 115| Thursday 2023/6/29 at 14:00 UTC | agenda \\| notes \\| no reddit | video 114| Thursday 2023/6/29 at 14:00 UTC | agenda \\| notes \\| no reddit | video 113| Thursday 2023/6/29 at 14:00 UTC | agenda \\| notes \\| no reddit | video 112| Thursday 2023/6/29 at 14:00 UTC | agenda \\| notes \\| no reddit | video 111| Thursday 2023/6/15 at 14:00 UTC | agenda \\| notes \\| no reddit | video 109| Thursday 2023/5/18 at 14:00 UTC | agenda \\| notes \\| no reddit | video 108| Thursday 2023/5/4 at 14:00 UTC | agenda \\| notes \\| no reddit | video 107| Thursday 2023/4/20 at 14:00 UTC | agenda \\| notes \\| no reddit | video 106| Thursday 2023/4/6 at 14:00 UTC | agenda \\| notes \\| no reddit | video 105| Thursday 2023/2/23 at 14:00 UTC | agenda \\| notes \\| no reddit | video 104| Thursday 2023/3/9 at 14:00 UTC | agenda \\| notes \\| no reddit | video 103| Thursday 2023/2/23 at 14:00 UTC | agenda \\| notes \\| no reddit | video 102| February 9, 2023, 14:00 UTC | agenda \\| notes \\| no reddit | video 101| Thursday 2022/12/15 at 14:00 UTC | agenda \\| notes \\| no reddit | video 100| Thursday 2022/12/15 at 14:00 UTC | agenda \\| notes \\| no reddit | video 99| Thursday 2022/12/1 at 14:00 UTC | agenda \\| notes \\| no reddit | video 98| Thursday 2022/11/17 at 14:00 UTC | agenda \\| notes \\| no reddit | video 97| Thursday 2022/11/3 at 14:00 UTC | agenda \\| notes \\| no reddit | video 96| Thursday 2022/9/22 at 14:00 UTC | agenda \\| notes \\| no reddit | video 95| Thursday 2022/9/8 at 14:00 UTC | agenda \\| notes \\| no reddit | video 94| Thursday 2022/8/25 at 14:00 UTC | agenda \\| notes \\| no reddit | video 93| Thursday 2022/8/11 at 14:00 UTC | agenda \\| notes \\| no reddit | video 92| Thursday 2022/7/28 at 14:00 UTC | agenda \\| notes \\| no reddit | video 91| Thursday 2022/7/14 at 14:00 UTC | agenda \\| notes \\| no reddit | video 90| Thursday 2022/6/30 at 14:00 UTC | agenda \\| notes \\| no reddit | video 89| Thursday 2022/6/16 at 14:00 UTC | agenda \\| notes \\| no reddit | video 88|Thu, May 19, 2022 1400UTC | agenda \\| notes \\| no reddit | video 87|Thu, May 19, 2022 1400UTC | agenda \\| notes \\| no reddit | video 86|Thursday 2022/5/5 at 14:00 UTC | agenda \\| notes \\| no reddit | video 85|Thu, April 4, 2022 1400UTC | agenda \\| notes \\| no reddit | video 84|Thu, March 24, 2022 1400UTC| agenda \\| notes \\| reddit | video 83|Thu, March 10, 2022 1400UTC| agenda \\| notes \\| reddit | video 81|Thu, Feb 10, 2022 1400UTC| agenda \\| notes \\| reddit | video 80|Thur, Jan 27, 2022 14:00UTC| agenda \\| notes \\| reddit | video 79|Thu, Jan 13, 2022 1400UTC| agenda \\| notes \\| reddit | video 78|Thu, Dec 16, 2021 1400UTC| agenda \\| notes \\| reddit | No recording\n77|Thu, Dec 2, 2021 1400UTC| agenda \\| notes \\| reddit | video 76|Thu, Nov 18, 2021 1400UTC| agenda \\| notes \\| reddit | video 75|Thu, Nov 4, 2021 1400UTC| agenda \\| notes \\| reddit | video 74|Thu, Oct 21, 2021 1400UTC| agenda \\| notes \\| reddit | video 73|Thu, Sept 23, 2021 1400UTC| agenda \\| notes \\| reddit | video 72|Thu, Sept 9, 2021 1400UTC| agenda \\| notes \\| reddit | video 71|Thu, August 26, 2021 1400UTC| agenda \\| notes \\| reddit | video 70|Thu, August 12, 2021 1400UTC| agenda \\| notes \\| reddit | video 69|Thu, July 29, 2021 1400UTC| agenda \\| notes \\| reddit | video 68|Thu, Jul 15, 2021 1400UTC| agenda \\| notes \\| reddit | video 67 | Thu, July 1st, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video |\n66 | Thu, Jun 17rd, 2020 14:00 UTC  | agenda \\| notes \\| no reddit | video |\n65| Thu, Jun 3, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 64| Thu, May 20, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 63| Thu, May 6, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 62| Thu, April 22, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 61| Thu, April 8, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 60| Thu, March 25, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 59|Thu, March 11, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 58|Thu, February 25, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 57|Thu, February 11, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 56|Thu, Jan 28, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 55| Thu, Jan 14, 2021 14:00 UTC  | agenda \\| notes \\| no reddit | video 54|Thu, Dec 17, 2020 14:00 UTC  | agenda \\| notes \\| no reddit | video 53| Thu, Dec 2, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 52| Thu, Nov 12, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 51|Thu, Oct 29, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 50| Thu, Oct 15, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 49|Thu, Oct 1, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 48|Thu, Sept 17, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 47|Thu, Sept 3, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 46|Thu, August 20, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 45|Thu, August 8, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 44|Thu, July 23, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 43|Thu, July 9, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 42|Thu, June 25, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 41| Thu, Jun 11, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 40| Thu, May 28, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 39| Thu, May 14, 2020 14:00 UTC  | agenda \\| notes \\| reddit |\n38| Thu, Apr 23, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 37| Thu, Apr 09, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 36| Thu, Mar 26, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 35| Thu, Mar 3, 2020 14:00 UTC  | agenda \\| notes \\| reddit | video 34| Thu, Feb 27, 2020 14:00 UTC   | agenda \\| notes \\| reddit | video 33| Thu Feb 06, 2020 14:00 UTC    | agenda \\| notes \\| reddit | video 32| Thu, Jan 23, 2020 14:00 UTC      | agenda \\| notes \\| reddit | video 31| Thu, Jan 09, 2020 14:00 UTC      | agenda \\| notes \\| reddit | video 30| Thu, Dec 19, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 29| Thu, Dec 5, 2019 14:00 UTC     | agenda \\| notes \\| no reddit | video 28| Thu, Nov 21, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 27| Thu, Nov 7, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 26| Thu, Oct 24, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 25| Thu, Sep 9, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 24| Thu, Aug 29, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 23| Thu, Aug 15, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 22| Thu, Jul 25, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 21| Thu, Jul 11, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 20| Thu, Jun 13, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 19| Thu, Jun 13, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 18| Thu, May 23, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 17| Thu, May 02, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 16| Thu, Apr 18, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 15| Thu, Mar 28, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 14| Thu, Mar 14, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 13| Thu, Feb 28, 2019 14:00 UTC      | agenda \\| notes \\| no reddit  | video 12| Thu, Feb 14, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 11| Thu, Jan 31, 2019 14:00 UTC      | agenda \\| notes \\| no reddit | video 10| Thu, Jan 17, 2019 14:00 UTC      | agenda \\| notes \\| reddit | video 9| Thu, Jan 03, 2019 14:00 UTC       | agenda \\| notes \\| reddit | video 8| Thu, Dec 13, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 7| Thu, Nov 29, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 6| Thu, Nov 15, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 5| Thu, Oct 11, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 4| Thu, Sept 27, 2018 14:00 UTC     | agenda \\| notes \\| reddit | video 3| Thu, Sept 13, 2018 14:00 UTC     | agenda \\| notes \\| reddit | video 2| Thu, Aug 30, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 1| Thu, Aug 16, 2018 14:00 UTC      | agenda \\| notes \\| reddit | video 0| Thu, Aug 02, 2018 14:00 UTC       | agenda \\| notes \\| reddit | video"}, {"name": "populus", "desc": "The Ethereum development framework with the most cute animal pictures", "readme": "THIS LIBRARY IS NO LONGER MAINTAINED Brownie might be what you're looking for"}, {"name": "portal-accumulators", "desc": null, "readme": "final block included in master acc: 15537393 final master acc. root hash: 0x8eac399e24480dce3cfe06f4bdecba51c6e5d0c46200e3e8611a0b44a3a69ff9 Index epoch_index.txt index of epoch # -> epoch hash bridge_content/ epoch accumulators & master accumulator encoded according to the bridge-client spec eg. content_key (filename) -> binary encoded ssz bytes representation (file)"}, {"name": "portal-blog", "desc": null, "readme": "Portal Network Blog This is the source repository for the Portal Network blog hosted at https://blog.ethportal.net Adding posts Option A: Clone the repository and create a feature branch. PR from your branch into main Option B: Fork the repository and PR from your fork to main Prepare your development environment by navigating to your project directory and: npm i next react react-dom nextra nextra-theme-blog If you want to add a post to the blog, you should add a page to pages/posts .\nThe page should be a markdown file, and it should begin with the following frontmatter: ``` title: date: description: tag: author: < your name / handle> ``` The tags should describe the theme of the post. Try to re-use tags from previous posts where possible. No other changes are required, as files in pages/posts are automatically detected and added to the feed on the front page. Add the page by PR to the main branch. Check the changes locally using npm run dev"}, {"name": "portal-hive", "desc": "Portal Network end-to-end test harness", "readme": "portal-hive - Portal network end-to-end test harness forked from ethereum Hive Hive is a system for running integration tests against Portal Network clients.\n- Test results can be seen on https://portal-hive.ethdevops.io/ To read more about hive, please check the documentation . License The hive project is licensed under the GNU General Public License v3.0 . You can\nfind it in the COPYING file."}, {"name": "portal-network-specs", "desc": "Official repository for specifications for the Portal Network", "readme": "The Portal Network This specification is a work-in-progress and should be considered preliminary. Introduction The Portal Network is an in progress effort to enable lightweight protocol access by resource constrained devices.  The term \"portal\" is used to indicate that these networks provide a view into the protocol but are not critical to the operation of the core Ethereum protocol. The Portal Network is comprised of multiple peer-to-peer networks which together provide the data and functionality necessary to expose the standard JSON-RPC API .  These networks are specially designed to ensure that clients participating in these networks can do so with minimal expenditure of networking bandwidth, CPU, RAM, and HDD resources. The term 'Portal Client' describes a piece of software which participates in these networks. Portal Clients typically expose the standard JSON-RPC API. Motivation The Portal Network is focused on delivering reliable, lightweight, and decentralized access to the Ethereum protocol. Prior Work on the \"Light Ethereum Subprotocol\" (LES) The term \"light client\" has historically referred to a client of the existing DevP2P based LES network.  This network is designed using a client/server architecture.  The LES network has a total capacity dictated by the number of \"servers\" on the network.  In order for this network to scale, the \"server\" capacity has to increase.  This also means that at any point in time the network has some total capacity which if exceeded will cause service degradation across the network.  Because of this the LES network is unreliable when operating near capacity. Architecture The Portal Network is built upon the Discover V5 protocol and operates over the UDP transport. The Discovery v5 protocol allows building custom sub-protocols via the use of the built in TALKREQ and TALKRESP message. The Portal Network is divided into the following sub-protocols. Execution State Network Execution History Network Execution Transaction Gossip Network Execution Canonical Indices Network Each of these sub-protocols is designed to deliver a specific unit of functionality.  Most portal clients will participate in all of these sub-protocols in order to deliver the full JSON-RPC API.  Each sub-protocol however is designed to be independent of the others, allowing clients the option of only participating in a subset of them if they wish. All of the sub-protocols in the Portal Network establish their own overlay DHT that is managed independent of the base Discovery V5 DHT. Terminology The term \"sub-protocol\" is used to denote an individual protocol within the Portal Network. The term \"network\" is used contextually to refer to either the overall set of multiple protocols that comprise the Portal Network or an individual sub-protocol within the Portal Network. Design Principles Each of the Portal Network sub-protocols follows these design principles. Isolation Participation in one network should not require participation in another network. Distribution of Responsibility Normal operation of the network should result in a roughly even spread of responsibility across the individual nodes in the network. Tunable Resource Requirements Individual nodes should be able to control the amount of machine resources (HDD/CPU/RAM) they provide to the network These design principles are aimed at ensuring that participation in the Portal Network is feasible even on resource constrained devices. The JSON-RPC API The following JSON-RPC API endpoints are directly supported by the portal network and exposed by portal clients. eth_getBlockByHash eth_getBlockByNumber eth_getBlockTransactionCountByHash eth_getBlockTransactionCountByNumber eth_getUncleCountByBlockHash eth_getUncleCountByBlockNumber eth_blockNumber eth_call eth_estimateGas eth_getBalance eth_getStorageAt eth_getTransactionCount eth_getCode eth_sendRawTransaction eth_getTransactionByHash eth_getTransactionByBlockHashAndIndex eth_getTransactionByBlockNumberAndIndex eth_getTransactionReceipt In addition to these endpoints, the following endpoints can be exposed by portal clients through the data available through the portal network. eth_syncing The following endpoints can be exposed by portal clients as they require no access to execution layer data. eth_protocolVersion eth_chainId eth_coinbase eth_accounts eth_gasPrice eth_feeHistory eth_newFilter TODO: explain complexity. eth_newBlockFilter eth_newPendingTransactionFilter eth_uninstallFilter eth_getFilterChanges eth_getFilterLogs eth_getLogs TODO: explain complexity eth_mining eth_hashrate eth_getWork eth_submitWork eth_submitHashrate eth_sign eth_signTransaction JSON-RPC Specs Bridge Nodes The term \"bridge node\" refers to portal clients which, in addition to participating in the sub-protocols, also inject data into the Portal Network. Any client with valid data may participate as a bridge node. From the perspective of the protocols underlying the Portal Network there is nothing special about bridge nodes. The planned architecture for bridge nodes is to pull data from the standard JSON-RPC API of a Full Node and \"push\" this data into their respective networks within the Portal Network. Network Functionality State Network: Accounts and Contract Storage The State Network facilitates on-demand retrieval of the Ethereum \"state\" data.  This includes: Reading account balances or nonce values Retrieving contract code Reading contract storage values The responsibility for storing the underlying \"state\" data should be evenly distributed across the nodes in the network.  Nodes must be able to choose how much state they want to store.  The data is distributed in a manner that allows nodes to determine the appropriate nodes to query for any individual piece of state data.  When retrieving state data, a node should be able to validate the response using a recent header from the header chain. The network will be dependent on receiving new and updated state for new blocks. Full \"bridge\" nodes acting as benevolent state providers are responsible for bringing in this data from the main network. The network should be able to remain healthy even with a small number of bridge nodes.  As new data enters the network, nodes are able to validate the data using a recent header from the header chain. Querying and reading data from the network should be fast enough for human-driven wallet operations, like estimating the gas for a transaction or reading state from a contract. History Network: Headers, Blocks, and Receipts The History Network facilitates on-demand retrieval of the history of the Ethereum chain.  This includes: Headers Block bodies Receipts The responsibility for storing this data should be evenly distributed across the nodes in the network.  Nodes must be able to choose how much history data they want to store.  The data is distributed in a manner that allows nodes to determine the appropriate nodes to query for any individual piece of history data. Participants in this network are assumed to have access to the canonical header chain. All data retrieved from the history network is addressed by block hash.  Headers retrieved from this network can be validated to match the requested block hash.  Block Bodies and Receipts retrieved from this network can be validated against the corresponding header fields. All data retrieved from the history network can be immediately verified by the requesting node. For block headers, the requesting node always knows the expected hash of the requested data and can reject responses with an incorrect hash.  For block bodies and receipts, the requesting node is expected to have the corresponding header and can reject responses that do not validate against the corresponding header fields. Canonical Transaction Index Network: Transactions by Hash The Canonical Transaction Index Network facilitates retrieval of individual transactions by their hash. The responsibility for storing the records that make up this should be evenly distributed across the nodes in the network.  Nodes must be able to choose how many records from this index they wish to store.  The records must be distributed across the network in a manner that allows nodes to determine the appropriate nodes to query for an individual record. Transaction information returned from this network includes a merkle proof against the Header.transactions_trie for validation purposes. Transaction Gossip Network: Sending Transactions The Transaction Gossip Network facilitates broadcasting new transactions for inclusion in a future block. Nodes in this network must be able to limit how much of the transaction pool they wish to process and gossip. The goal of the transaction gossip network is to make sure nodes can broadcast transaction such that they are made available to miners for inclusion in a future block. Transactions which are part of this network's gossip are able to be validated without access to the Ethereum state. This is accomplished by bundling a proof which includes the account balance and nonce for the transaction sender.  This validation is required to prevent DOS attacks. This network is a pure gossip network and does not implement any form of content lookup or retrieval. Network Specifications uTP over DiscoveryV5 State Network Prior work: https://ethresear.ch/t/scalable-gossip-for-state-network/8958/4 Chain History Network Prior work: https://notes.ethereum.org/oUJE4ZX2Q6eMOgEMiQPkpQ?view Prior Python proof-of-concept: https://github.com/ethereum/ddht/tree/341e84e9163338556cd48dd2fcfda9eedec3eb45 This POC should NOT be considered representative of the end goal.  It incorporates mechanisms that aren't likely to be apart of the actual implementation, specifically the \"advertisement\" system which proved to be a big bottleneck, as well as the SSZ merkle root system which was a workaround for large data transfer which we now intend to solve with uTP. Transaction Gossip Network : Spec is preliminary Prior work: https://ethresear.ch/t/scalable-transaction-gossip/8660 Canonical Transaction Index Network Spec is preliminary. Network design borrows heavily from history network."}, {"name": "portal-spec-tests", "desc": null, "readme": "portal-spec-tests Ethereum Portal Network Spec Tests Test files should be written in YAML as they provide comments and greater readability"}, {"name": "portal-website", "desc": null, "readme": "Portal Network docs This site is bootstrapped using Nextra (docs theme). To build locally run pnpm install\npnpm dev from the project root."}, {"name": "pos-evolution", "desc": "Evolution of the Ethereum Proof-of-Stake Consensus Protocol", "readme": null}, {"name": "profiling", "desc": null, "readme": null}, {"name": "public-attacknets", "desc": "Public attacknets available for eth2", "readme": "[DEPRECATED] Public eth2 attacknets Note: This attacknet program has been deprecated in favor of the more\ngeneral eth2 bounty program . All previous\nbounty types in this repo qualify in the new program. Please use\neth2bounty@ethereum.org for responsible disclosure. All previous trophies will be ported to the long standing eth2 bounty\nprogram. This repository tracks public \"attacknets\" maintained by the EF. [DEPRECATED] Multi-client beta-1 attacknet A multi-client beta-1 attacknet composed of three\nclients is up with multiple tiers of bounties (up to $15k!). Read more for details about configuration, rules, and rewards. Attacknet directory structure Each attacknet is contained within it's own sub-directory within ./attacknets . Within the attacknet directory, a README.md is provided with human\nreadable, high-level configuration as well as the rules and any rewards\nassociated with the attacknet. The attacknet directory also provides configuration files that might be useful\nin running clients and connecting to the network. prysm_config.yaml -- is a YAML configuration file that can be ingested by\n  the Prysm client via the --chain-config-file commandline flag teku_config.yaml -- is a YAML configuration file that can be ingested by\n  the Teku client via the --network commandline flag lighthouse -- is the testnet configuration directory that can be\n  ingested by the Lighthouse client via the --testnet-dir commandline flag General rules In addition to attacknet specific rules provided for in each attacknet. The\nfollowing are the general rules for the program. [ Note : This program is in beta-0 and all rules are subject to change without prior notice]. The Ethereum Foundation is solely responsible for judging the attack and deciding on rewards The Ethereum Foundation may reward \"honorable mention\" rewards of any\n  denomination for interesting effects induced on testnets that do not\n  necessarily meet the stated goal Awards can be redeemed in ETH or DAI Eth2 client teams are eligible to participate only on attacknets that do not contain their specific client How to report All claims on attacknet rewards must be reported as an issue in this repo. Please follow this reporting structure to aid in prompt review: If succeeded in a testnet goal and want to make a claim on the reward, prefix the name of the Issue/PR with \"[ {ATTACK_NET_NAME} Reward]\"\n  Use this template for convenience. If want to share something interesting achieved outside of the goal, prefix the name of the Issue/PR with \"[ {ATTACK_NET_NAME} Issue]\"\n  Use this template for convenience. Use the following structure for the body of the Issue/PR Description : High-level description of the attack [1 sentence] Attack scenario : More detailed description of the attack scenario and how it was carried out [1 to 3 sentences] Impact : Describe the effect had on the attacknet [1 to 2 sentences] Details : Very specific details about the attack including the specific slots/epochs where it can be observed Privacy The Ethereum Foundation is not responsible for any private information that might\nbe leaked as a result of this program. In the event that the reporting of an attack does leak private information\n(e.g. logs from a testnet containing IP addresses), we ask that you withhold any such information in the public report.\nInstead, please note that there are additional accompanying resources to be shared,\nand the attacknet evaluators will be in touch. Important legal information We give explicit permission to attack these attacknets over the internet. This attacknet program is an experimental and discretionary rewards program for\nour active Ethereum community to encourage and reward those who are helping\nto improve the platform. It is not a competition. You should know that we can\ncancel the program at any time, and rewards are at the sole discretion of Ethereum Foundation.\nIn addition, we are not able to issue rewards to individuals who are on sanctions\nlists or who are in countries on sanctions lists (e.g. North Korea, Iran, etc).\nYou are responsible for all taxes. All rewards are subject to applicable law.\nFinally, your testing must not violate any law or compromise any data that is not yours. Getting started Running clients with custom config files For each attacknet, a README.md and configuration files are provided to allow\nfor easy running of clients. Note that a prysm_config.yaml , teku_config.yaml , and lighthouse directory\nare provided for each testnet regardless of the constituent clients making up\nthe testnet. These are configuration files that you can use to run lighthouse,\nprysm, and/or teku on each testnet. To run lighthouse , in addition to normal\nconfiguration commandline flags, use the following:\n* --testnet-dir {LIGHTHOUSE_TESTNET_DIR} where LIGHTHOUSE_TESTNET_DIR is the lighthouse directory found within the specific attacknet To run prysm , in addition to normal\nconfiguration commandline flags, use the following:\n* --chain-config-file {PRYSM_CONFIG_FILE} where PRYSM_CONFIG_FILE is the prysm_config.yaml file found within the specific attacknet\n* --deposit-contract {DEPOSIT_CONTRACT_ADDR} where DEPOSIT_CONTRACT_ADDR is\n  the 0x prefixed deposit contract address found in the specific attacknet\n  README.md\n* --contract-deployment-block {DEPOSIT_CONTRACT_DEPLOY_NUMBER} where DEPOSIT_CONTRACT_DEPLOY_NUMBER is\n  the block number at which the deposit contract was deployed, found in the attacknet README.md\n* --custom-genesis-delay {GENESIS_DELAY} where GENESIS_DELAY is\n  the genesis delay param found in the attacknet README.md To run teku , in addition to normal configuration\ncommandline flags, use the following:\n* --network {TEKU_CONFIG_FILE} where TEKU_CONFIG_FILE is the teku_config.yaml file found within the specific attacknet\n* --eth1-deposit-contract-address {DEPOSIT_CONTRACT_ADDR} where DEPOSIT_CONTRACT_ADDR is\n  the 0x prefixed deposit contract address found in the specific attacknet\n  README.md Rumor -- Eth2 interactive shell @protolambda maintains rumor ,\nan eth2 interactive shell for dynamically interacting with eth2 networks and data. Check out the rumor README for basic\ndocumentation. We expect this tool to be invaluable in getting started,\nunderstanding networks, and constructing attacks. Trophies \ud83c\udfc6 Here we immortalize, for all time, the successful attacks conducted by 1337 h4x0rz. You, too, can achieve perpetual fame and glory. Read some code, run some nodes, and break some nets. | User | Attacknet | Attack | Reward |\n| ------------- | ---------- | ----------- | ---------- |\n| @jrhea | prysm-attack-0 | DoS Attack on Prysm via Golang stdlib exploit stops finality | $5k (USD) |\n| @holiman | prysm-attack-0 | Remote crash nodes over p2p | ~~$5k (USD)~~ No reward, EF Security Team |\n| @AlexSSD7 | prysm-attack-0 | L4 Distributed Denial of Service attack stops finality | $5k (USD) |\n| @jrhea | teku-attack-0 | DoS Attack on Teku Stops Finality | $5k (USD) |\n| @jrhea | lighthouse-attack-0 | Network agent crashes lighthouse discovery | $1k (USD) |\n| @tintinweb | teku-attack-0 | DoS Attack on Teku via gossipsub | $5k (USD) |\n| @atoulme | teku-attack-0 | DoS Attack: UDP random 46 bytes packets | $5k (USD) |\n| @atoulme | teku-attack-0 | Crash discovery service with malformed WHOAREYOU packet | $5k (USD) | Deprecated attacknets Single-client beta-0 attacknets beta-0 attacknets are deprecated. All nodes are have been disabled\nand attacks/rewards are no longer eligible."}, {"name": "public-disclosures", "desc": null, "readme": "Ethereum Foundation Vulnerability Disclosures Through its Bug Bounty Program, which allows the Ethereum Foundation (EF) to coordinate and cross-check vulnerabilities across clients, the EF currently accepts vulnerability reports for Nimbus, Teku, Lighthouse, Prysm, Lodestar, Go Ethereum, Nethermind, Erigon and Besu. While, for example, the Go Ethereum Team have a public Vulnerability disclosure page (parts of which is being used here) and have published vulnerability disclosures for quite some time already, there has not been a coordinated publishing of vulnerabilities for all clients under the scope of the Bug Bounty Program. Since the creation of the Execution Layer Bug Bounty Program and the Consensus Layer Bug Bounty Program , the EF has paid out rewards for many reported vulnerabilities. Most of the vulnerabilities were not previously disclosed publicly, but we have now been publishing vulnerabilities on GitHub , up until the latest hard fork on each layer. We aim to further improve the disclosure process, while also attempting to find an appropriate balance between confidentiality and transparency when disclosing vulnerability reports public moving forward: Execution Layer Disclosures Consensus Layer Disclosures About disclosures Traditionally in software, it is expected for security vulnerabilities to be immediately announced, thus giving operators an opportunity to take protective measure against attackers. Vulnerabilities typically take two forms:\n1. Vulnerabilities that, if exploited, harm the software operator. In the case of an execution layer client or consensus layer client, examples would be:\n    * A bug that allow remote reading or writing of OS files\n    * Remote command execution\n    * Bugs that leak cryptographic keys\n2. Vulnerabilities that, if exploited, harm the Ethereum Network. In the case of the execution layer or consensus layer, examples would be:\n    * Consensus vulnerabilities which may cause a chain split\n    * Denial-of-service during block processing, whereby a malicious transaction could cause the execution or consensus-portion of the network to crash\n    * Denial-of-service via p2p networking, whereby portions of the network could be made inaccessible due to crashes or resource consumption In most cases so far, vulnerabilities in the execution or consensus layer have been of the second type in which the health of the network is the primary concern rather than individual node operators. Why silent patches In the case of Ethereum, node operators often require a long lead time (weeks, months) to update software even for a scheduled hard fork. If a release publicly contains important consensus or DoS fixes, an attacker may attempt to execute the public vulnerability before operators have adequate time to upgrade. Delaying a potential attacker by obfuscating a vulnerability fix contained in a release in an effort to gain heard immunity in many cases is worth the temporary loss of transparency. The primary goal for the EF in managing this program is the health of the Ethereum network as a whole. Thus, the decision as to when to publish details about a serious vulnerability boils down to minimizing the risk and/or impact of discovery and exploitation. Ethereum Foundation Public Disclosure Timelines The Ethereum Foundation aims to publicly disclose bugs reported through its bug bounty program in 90 days. There may be cases, such as if a vulnerability is being actively exploited in production, in which the EF may opt to disclose a reported vulnerability sooner or later than 90 days depending on circumstances surrounding the vulnerability. In addition, the EF will always communicate and discuss plans with the affected client teams prior to a public disclosure so an optimal course of action is taken with respect to all affected software. Ethereum Foundation Vulnerability Catalogue The Ethereum Foundation maintains a list of publicly disclosed vulnerabilities and incident reports for targets within the bug bounty program. The list of publicly disclosed vulnerabilities and incidents can be accessed at https://github.com/ethereum/public-disclosures/. Vulnerability Disclosure Process Reports received through the Ethereum Bug Bounty Program are evaluated, cross-checked, and then shared with affected client teams. The Ethereum Foundation also requests that vulnerabilities found by client teams or vulnerabilities reported directly to client teams are sent to the EF through each client team's preferred method of contact. The EF requests such a notification to be able to evaluate if the vulnerability affects other clients in the ecosystem and to assist with coordination/communication efforts with the client team(s). The EF will not disclose the vulnerability to other client teams or third parties prior to the public disclosure with the exception if a client is also found to be affected by the same vulnerability. The process is split into five phases: 1. Discovery phase A vulnerability may be discovered and reported in one of many ways:\n- Discovered by a member of a client team\n- Discovered by the Ethereum Foundation\n- Discovered by a third party and reported directly to the client team\n- Discovered by a third party and reported through the Ethereum Bug Bounty Program 2. Cross-Check phase In the event that the vulnerability is reported through the Ethereum Foundation's Bug Bounty Program, by the Ethereum Foundation directly, or forwarded by a client team, the EF will cross-check to evaluate if other client software is vulnerable to the same issue. 3. Preparation and testing phase The Ethereum Foundation will remain in active communication with the client team(s) as the team(s) privately prepares a fix for the vulnerabily. Generally, these fixes are hidden through various means to obfuscate that there is a vulnerability being patched. 4. Release phase Client teams normally use their coordination channels such as Twitter, Discord, Reddit and Blogs to inform about the new update being available. The Ethereum Foundation will reach out to inform relevant stakeholders where feasible and necessary, such as maintainers of critical libraries and services. 5. Public Disclosure phase The Ethereum Foundations aims to disclose vulnerabilities no longer than 90 days after the initial report by adding it to the Ethereum Foundation Vulnerability Catalogue, preferably in collaboration with the affected client team(s). If you think you\u2019ve found a security vulnerability or any bug, please submit a bug report to the execution layer or consensus layer bug bounty program! \ud83d\udc9c\ud83e\udd84"}, {"name": "py-evm", "desc": "A Python implementation of the Ethereum Virtual Machine", "readme": "Python Implementation of the Ethereum protocol Py-EVM Py-EVM is an implementation of the Ethereum protocol in Python. It contains the low level\nprimitives for the original proof-of-work (POW), (formerly known as Ethereum 1.0) chain\nas well as emerging support for the proof-of-stake (POS) (formerly known as Ethereum 2.0) spec. Goals Py-EVM aims to eventually become the defacto Python implementation of the Ethereum protocol,\nenabling a wide array of use cases for both public and private chains. In particular Py-EVM aims to: be a reference implementation of the Ethereum POW and POS implementations in one of the most widely used and understood languages, Python. be easy to understand and modifiable have clear and simple APIs come with solid, friendly documentation deliver the low level primitives to build various clients on top (including full and light clients) be highly flexible to support both research as well as alternate use cases like private chains. Quickstart sh\npython -m pip install py-evm Get started in 5 minutes Documentation Check out the documentation on our official website Developer Setup If you would like to hack on py-evm, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup sh\ngit clone git@github.com:ethereum/py-evm.git\ncd py-evm\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). Want to help? Want to file a bug, contribute some code, or improve documentation? Excellent! Read up on our\nguidelines for contributing and then check out one of our issues that are labeled Good First Issue ."}, {"name": "py-geth", "desc": "Python wrapping for running Go-Ethereum as a subprocess", "readme": "py-geth Python wrapper around running geth as a subprocess System Dependency This library requires the geth executable to be present. If managing your own bundled version of geth, set the path to the binary using the GETH_BINARY environment variable. Installation Installation bash\npython -m pip install py-geth Quickstart To run geth connected to the mainnet ```python from geth import LiveGethProcess\ngeth = LiveGethProcess()\ngeth.start()\n``` Or a private local chain for testing.  These require you to give them a name. ```python from geth import DevGethProcess\ngeth = DevGethProcess('testing')\ngeth.start()\n``` By default the DevGethProcess sets up test chains in the default datadir used by geth .  If you would like to change the location for these test\nchains, you can specify an alternative base_dir . ```python geth = DevGethProcess('testing', '/tmp/some-other-base-dir/')\ngeth.start()\n``` Each instance has a few convenient properties. ```python geth.data_dir\n\"~/.ethereum\"\ngeth.rpc_port\n8545\ngeth.ipc_path\n\"~/.ethereum/geth.ipc\"\ngeth.accounts\n['0xd3cda913deb6f67967b99d67acdfa1712c293601']\ngeth.is_alive\nFalse\ngeth.is_running\nFalse\ngeth.is_stopped\nFalse\ngeth.start()\ngeth.is_alive\nTrue  # indicates that the subprocess hasn't exited\ngeth.is_running\nTrue  # indicates that start() has been called (but stop() hasn't)\ngeth.is_stopped\nFalse\ngeth.stop()\ngeth.is_alive\nFalse\ngeth.is_running\nFalse\ngeth.is_stopped\nTrue\n``` When testing it can be nice to see the logging output produced by the geth process. py-geth provides a mixin class that can be used to log the stdout\nand stderr output to a logfile. ```python from geth import LoggingMixin, DevGethProcess\nclass MyGeth(LoggingMixin, DevGethProcess):\n...     pass\ngeth = MyGeth()\ngeth.start()\n``` All logs will be written to logfiles in ./logs/ in the current directory. The underlying geth process can take additional time to open the RPC or IPC\nconnections, as well as to start mining if it needs to generate the DAG.  You\ncan use the following interfaces to query whether these are ready. ```python geth.is_rpc_ready\nTrue\ngeth.wait_for_rpc(timeout=30)  # wait up to 30 seconds for the RPC connection to open\ngeth.is_ipc_ready\nTrue\ngeth.wait_for_ipc(timeout=30)  # wait up to 30 seconds for the IPC socket to open\ngeth.is_dag_generated\nTrue\ngeth.is_mining\nTrue\ngeth.wait_for_dag(timeout=600)  # wait up to 10 minutes for the DAG to generate.\n``` The DAG functionality currently only applies to the DAG for epoch 0. Installing specific versions of geth This feature is experimental and subject to breaking changes. Versions of geth dating back to v1.11.0 can be installed using py-geth .\nSee install.py for\nthe current list of supported versions. Installation can be done via the command line: bash\n$ python -m geth.install v1.13.10 Or from python using the install_geth function. ```python from geth import install_geth\ninstall_geth('v1.13.10')\n``` The installed binary can be found in the $HOME/.py-geth directory, under your\nhome directory.  The v1.13.10 binary would be located at $HOME/.py-geth/geth-v1.13.10/bin/geth . About DevGethProcess The DevGethProcess is designed to facilitate testing.  In that regard, it is\npreconfigured as follows. A single account is created and allocated 1 billion ether. All APIs are enabled on both rpc and ipc interfaces. Account 0 is unlocked Networking is configured to not look for or connect to any peers. The networkid of 1234 is used. Verbosity is set to 5 (DEBUG) Mining is enabled with a single thread. The RPC interface tries to bind to 8545 but will find an open port if this\n  port is not available. The DevP2P interface tries to bind to 30303 but will find an open port if this\n  port is not available. Gotchas If you are running with mining enabled, which is default for DevGethProcess ,\nthen you will likely need to generate the DAG manually.  If you do not, then\nit will auto-generate the first time you run the process and this takes a\nwhile. To generate it manually: sh\n$ geth makedag 0 ~/.ethash This is especially important in CI environments like Travis-CI where your\nprocess will likely timeout during generation. Development Clone the repository: shell\n$ git clone git@github.com:ethereum/py-geth.git Next, run the following from the newly-created py-geth directory: sh\n$ python -m pip install -e \".[dev]\" Running the tests You can run the tests with: sh\npytest tests Developer Setup If you would like to hack on py-geth, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/py-geth.git\ncd py-geth\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\" Adding Support For New Geth Versions There is an automation script to facilitate adding support for new geth versions: update_geth.py To add support for a geth version, run the following line from the py-geth directory, substituting\nthe version for the one you wish to add support for. Note that the v in the versioning is\noptional. shell\n$ python update_geth.py v1_10_9 To introduce support for more than one version, pass in the versions in increasing order,\nending with the latest version. shell\n$ python update_geth.py v1_10_7 v1_10_8 v1_10_9 Always review your changes before committing as something may cause this existing pattern to change at some point.\nIt is best to compare the git difference with a previous commit that introduced support for a new geth version to make\nsure everything looks good."}, {"name": "py-hdwallet", "desc": null, "readme": "py-hdwallet HD wallet generator. WARNING: THIS PACKAGE HAS NOT BEEN PEER REVIEWED OR AUDITED.  USE AT YOUR OWN RISK!!!! Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install py-hdwallet Developer Setup If you would like to hack on py-hdwallet, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:davesque/py-hdwallet.git\ncd py-hdwallet\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 hdwallet/ tests/ -c \"clear; flake8 hdwallet tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on py-hdwallet failed'\" ../tests ../hdwallet Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). To include changes made with each\nrelease, update \"docs/releases.rst\" with the changes, and apply commit directly to master \nbefore release. If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "py-snappy", "desc": "A pure python implementation of the Snappy compression algorithm.", "readme": "py-snappy A pure python implementation of the Snappy compression algorithm Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install py-snappy Developer Setup If you would like to hack on py-snappy, please check out the Ethereum Development Tactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/py-snappy.git\ncd py-snappy\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 py_snappy/ tests/ -c \"clear; flake8 py_snappy tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on py-snappy failed'\" ../tests ../py_snappy Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). To include changes made with each\nrelease, update \"docs/releases.rst\" with the changes, and apply commit directly to master \nbefore release. If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "py-solc", "desc": "Python wrapper around the solc Solidity compiler.", "readme": "py-solc Python wrapper around the solc Solidity compiler. Dependency This library requires the solc executable to be present. Only versions >=0.4.2 are supported and tested though this library may work\nwith other versions. solc installation instructions Quickstart Installation sh\npip install py-solc Development Clone the repository and then run: sh\npip install -e . -r requirements-dev.txt Running the tests You can run the tests with: sh\npy.test tests Or you can install tox to run the full test suite. Releasing Pandoc is required for transforming the markdown README to the proper format to\nrender correctly on pypi. For Debian-like systems: apt install pandoc Or on OSX: sh\nbrew install pandoc To release a new version: sh\nbumpversion $$VERSION_PART_TO_BUMP$$\ngit push && git push --tags\nmake release How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, use bumpversion and specify which part to bump,\nlike bumpversion minor or bumpversion devnum . If you are in a beta version, bumpversion stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like bumpversion --new-version 4.0.0-alpha.1 devnum Standard JSON Compilation Use the solc.compile_standard function to make use the [standard-json] compilation feature. Solidity Documentation for Standard JSON input and ouptup format ``` from solc import compile_standard\ncompile_standard({\n...     'language': 'Solidity',\n...     'sources': {'Foo.sol': 'content': \"....\"},\n... })\n{\n    'contracts': {...},\n    'sources': {...},\n    'errors': {...},\n}\ncompile_standard({\n...     'language': 'Solidity',\n...     'sources': {'Foo.sol': 'urls': [\"/path/to/my/sources/Foo.sol\"]},\n... }, allow_paths=\"/path/to/my/sources\")\n{\n    'contracts': {...},\n    'sources': {...},\n    'errors': {...},\n}\n``` Legacy Combined JSON compilation ```python from solc import compile_source, compile_files, link_code\ncompile_source(\"contract Foo { function Foo() {} }\")\n{\n    'Foo': {\n        'abi': [{'inputs': [], 'type': 'constructor'}],\n        'code': '0x60606040525b5b600a8060126000396000f360606040526008565b00',\n        'code_runtime': '0x60606040526008565b00',\n        'source': None,\n        'meta': {\n            'compilerVersion': '0.3.5-9da08ac3',\n            'language': 'Solidity',\n            'languageVersion': '0',\n        },\n    },\n}\ncompile_files([\"/path/to/Foo.sol\", \"/path/to/Bar.sol\"])\n{\n    'Foo': {\n        'abi': [{'inputs': [], 'type': 'constructor'}],\n        'code': '0x60606040525b5b600a8060126000396000f360606040526008565b00',\n        'code_runtime': '0x60606040526008565b00',\n        'source': None,\n        'meta': {\n            'compilerVersion': '0.3.5-9da08ac3',\n            'language': 'Solidity',\n            'languageVersion': '0',\n        },\n    },\n    'Bar': {\n        'abi': [{'inputs': [], 'type': 'constructor'}],\n        'code': '0x60606040525b5b600a8060126000396000f360606040526008565b00',\n        'code_runtime': '0x60606040526008565b00',\n        'source': None,\n        'meta': {\n            'compilerVersion': '0.3.5-9da08ac3',\n            'language': 'Solidity',\n            'languageVersion': '0',\n        },\n    },\n}\nunlinked_code = \"606060405260768060106000396000f3606060405260e060020a6000350463e7f09e058114601a575b005b60187f0c55699c00000000000000000000000000000000000000000000000000000000606090815273__TestA _ _ _ _ _____90630c55699c906064906000906004818660325a03f41560025750505056\"\nlink_code(unlinked_code, {'TestA': '0xd3cda913deb6f67967b99d67acdfa1712c293601'})\n... \"606060405260768060106000396000f3606060405260e060020a6000350463e7f09e058114601a575b005b60187f0c55699c00000000000000000000000000000000000000000000000000000000606090815273d3cda913deb6f67967b99d67acdfa1712c29360190630c55699c906064906000906004818660325a03f41560025750505056\"\n``` Setting the path to the solc binary You can use the environment variable SOLC_BINARY to set the path to your solc binary. Installing the solc binary This feature is experimental and subject to breaking changes. Any of the following versions of solc can be installed using py-solc on the\nlisted platforms. v0.4.1 (linux) v0.4.2 (linux) v0.4.6 (linux) v0.4.7 (linux) v0.4.8 (linux/osx) v0.4.9 (linux) v0.4.11 (linux/osx) v0.4.12 (linux/osx) v0.4.13 (linux/osx) v0.4.14 (linux/osx) v0.4.15 (linux/osx) v0.4.16 (linux/osx) v0.4.17 (linux/osx) v0.4.18 (linux/osx) v0.4.19 (linux/osx) v0.4.20 (linux/osx) v0.4.21 (linux/osx) v0.4.22 (linux/osx) v0.4.23 (linux/osx) v0.4.24 (linux/osx) v0.4.25 (linux/osx) Installation can be done via the command line: bash\n$ python -m solc.install v0.4.25 Or from python using the install_solc function. ```python from solc import install_solc\ninstall_solc('v0.4.25')\n``` The installed binary can be found under your home directory.  The v0.4.25 binary would be located at $HOME/.py-solc/solc-v0.4.25/bin/solc .  Older linux\ninstalls will also require that you set the environment variable LD_LIBRARY_PATH=$HOME/.py-solc/solc-v0.4.25/bin Import path remappings solc provides path aliasing allow you to have more reusable project configurations. You can use this like: ```\nfrom solc import compile_source, compile_files, link_code compile_files([source_file_path], import_remappings=[\"zeppeling=/my-zeppelin-checkout-folder\"])\n``` More information about solc import aliasing"}, {"name": "py-ssz", "desc": "Python implementation of the Simple Serialize encoding and decoding", "readme": "py-ssz Python implementation of the Simple Serialization encoding and decoding Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npython -m pip install ssz Developer Setup If you would like to hack on py-ssz, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/py-ssz.git\ncd py-ssz\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "py-trie", "desc": "Python library which implements the Ethereum Trie structure.", "readme": "Python Implementation of the Ethereum Trie structure This library and repository was previously located at pipermerriam/py-trie . It was transferred to the Ethereum foundation GitHub in\nNovember 2017 and renamed to py-trie . Installation sh\npython -m pip install trie Developer Setup If you would like to hack on py-trie, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/py-trie.git\ncd py-trie\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Running the tests You can run the tests with: sh\ngit submodule update --init --recursive\npytest tests Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, bumpversion stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like bumpversion --new-version 4.0.0-alpha.1 devnum Usage ```python from trie import HexaryTrie\nt = HexaryTrie(db={})\nt.root_hash\nb'V\\xe8\\x1f\\x17\\x1b\\xccU\\xa6\\xff\\x83E\\xe6\\x92\\xc0\\xf8n[H\\xe0\\x1b\\x99l\\xad\\xc0\\x01b/\\xb5\\xe3c\\xb4!'\nt.set(b'my-key', b'some-value')\nt.get(b'my-key')\nb'some-value'\nt.exists(b'another-key')\nFalse\nt.set(b'another-key', b'another-value')\nt.exists(b'another-key')\nTrue\nt.delete(b'another-key')\nt.exists(b'another-key')\nFalse\n``` You can also use it like a dictionary. ```python from trie import HexaryTrie\nt = HexaryTrie(db={})\nt.root_hash\nb'V\\xe8\\x1f\\x17\\x1b\\xccU\\xa6\\xff\\x83E\\xe6\\x92\\xc0\\xf8n[H\\xe0\\x1b\\x99l\\xad\\xc0\\x01b/\\xb5\\xe3c\\xb4!'\nt[b'my-key'] = b'some-value'\nt[b'my-key']\nb'some-value'\nb'another-key' in t\nFalse\nt[b'another-key']  = b'another-value'\nb'another-key' in t\nTrue\ndel t[b'another-key']\nb'another-key' in t\nFalse\n``` Traversing (inspecting trie internals) ```python from trie import HexaryTrie\nt = HexaryTrie(db={})\nt.root_hash\nb'V\\xe8\\x1f\\x17\\x1b\\xccU\\xa6\\xff\\x83E\\xe6\\x92\\xc0\\xf8n[H\\xe0\\x1b\\x99l\\xad\\xc0\\x01b/\\xb5\\xe3c\\xb4!'\nt[b'my-key'] = b'some-value'\nt[b'my-other-key']  = b'another-value' Look at the root node: root_node = t.traverse(())\nroot_node\nHexaryTrieNode(sub_segments=((0x6, 0xd, 0x7, 0x9, 0x2, 0xd, 0x6),), value=b'', suffix=(), raw=[b'\\x16\\xd7\\x92\\xd6', b'\\xb4q\\xb8h\\xec\\x1c\\xe1\\xf4\\\\x88\\xda\\xb4\\xc1\\xc2n\\xbaw\\xd0\\x9c\\xf1\\xacV\\xb4Dk\\xa7\\xe6\\xd7qf\\xc2\\x82']) the root node is an extension down, because the first 7 nibbles are the same between the two keys Let's walk down to the child of that extension prefix6d792d6 = t.traverse(root_node.sub_segments[0])\nprefix6d792d6\nHexaryTrieNode(sub_segments=((0xb,), (0xf,)), value=b'', suffix=(), raw=[b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', [b' ey', b'some-value'], b'', b'', b'', [b' ther-key', b'another-value'], b'']) A branch node separates the second nibbles of b'k' and b'o': 0xb and 0xf Notice the position of the children in the 11th and 15th index Another way to get there without loading the root node from the database is using traverse_from: assert t.traverse_from(root_node, root_node.sub_segments[0]) == prefix6d792d6 Embedded nodes can be traversed to the same way as nodes stored in the database: t.traverse(root_node.sub_segments[0] + (0xb,))\nHexaryTrieNode(sub_segments=(), value=b'some-value', suffix=(0x6, 0x5, 0x7, 0x9), raw=[b' ey', b'some-value']) This leaf node includes the suffix (the rest of the key, in nibbles, that haven't been traversed, just b'ey': 0x6579 ``` Walking a full trie To walk through the full trie (for example, to verify that all node bodies are present in the database),\nuse HexaryTrieFog and the traversal API above. For example: ```python from trie import HexaryTrie\nt = HexaryTrie(db={})\nt.root_hash\nb'V\\xe8\\x1f\\x17\\x1b\\xccU\\xa6\\xff\\x83E\\xe6\\x92\\xc0\\xf8n[H\\xe0\\x1b\\x99l\\xad\\xc0\\x01b/\\xb5\\xe3c\\xb4!'\nt[b'my-key'] = b'some-value'\nt[b'my-other-key']  = b'another-value'\nt[b'your-key'] = b'your-value'\nt[b'your-other-key'] = b'your-other-value'\nt.root_hash\nb'\\xf8\\xdd\\xe4\\x0f\\xaa\\xf4P7\\xfa$\\xfde>\\xec\\xb4i\\x00N\\xa3)\\xcf\\xef\\x80\\xc4YU\\xe8\\xe7\\xbf\\xa89\\xd5' Initialize a fog object to track unexplored prefixes in a trie walk from trie.fog import HexaryTrieFog\nempty_fog = HexaryTrieFog() At the beginning, the unexplored prefix is (), which means that none of the trie has been explored prefix = empty_fog.nearest_unknown()\n() So we start by exploring the node at prefix () -- which is the root node: node = t.traverse(prefix)\nHexaryTrieNode(sub_segments=((0x6,), (0x7,)), value=b'', suffix=(), raw=[b'', b'', b'', b'', b'', b'', b\"\\x03\\xd2vk\\x85\\xce\\xe1\\xa8\\xdb'F\\x8c\\xe5\\x15\\xc6\\n+M:th\\xa1\\\\xb13\\xcc\\xe8\\xd0\\x1d\\xa7\\xa8U\", b\"\\x1b\\x8d'\\xb3\\x99(yX\\xaa\\x96C!\\xba'X \\xbb|\\xa6,\\xb5V!\\xd3\\x1a\\x05\\xe5\\xbf\\x02\\xa3fR\", b'', b'', b'', b'', b'', b'', b'', b'', b'']) and mark the root as explored, while defining the unexplored children: level1fog = empty_fog.explore(prefix, node.sub_segments) Now the unexplored prefixes are the keys starting with the four bits 6 and the four bits 7. All other keys are known to not exist (and so have been explored) level1fog\nHexaryTrieFog So we continue exploring. The fog helps choose which prefix to explore next: level1fog.nearest_unknown()\n(0x6,) We can also look for the nearest unknown key to a particular target prefix = level1fog.nearest_unknown((8, 1))\n(0x7,)\nnode7 = node.traverse(prefix)\nHexaryTrieNode(sub_segments=((0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6),), value=b'', suffix=(), raw=[b'\\x00\\x96\\xf7W\"\\xd6', b\"\\xe2\\xe2oN\\xe1\\xf8\\xda\\xc1\\x8c\\x03\\x92'\\x93\\x805\\xad-\\xef\\x07_\\x0ePV\\x1f\\xb5/lVZ\\xc6\\xc1\\xf9\"]) We found an extension node, and mark it in the fog For simpliticy, we'll start clobbering the fog variable fog = level1fog.explore(prefix, node7.sub_segments)\nHexaryTrieFog Let's explore the next branch node and see what's left prefix = fog.nearest_unknown((7,))\n(0x7, 0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6)\nnode796f75722d6 = t.traverse(prefix)\nHexaryTrieNode(sub_segments=((0xb,), (0xf,)), value=b'', suffix=(), raw=[b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', [b' ey', b'your-value'], b'', b'', b'', [b' ther-key', b'your-other-value'], b'']) Notice that the branch node inlines the values, but the fog and annotated node ignore them for now fog = fog.explore(prefix, node796f75722d6.sub_segments)\nHexaryTrieFog Index keys may not matter for some use cases, so we can leave them out entirely, like nearest_unknown(). There's one more feature to consider: we can look directionally to the right of an index for the nearest prefix. prefix = fog.nearest_right((0x7, 0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xc))\n(0x7, 0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xf) That same index key would give a closer prefix to the left if direction didn't matter (See the difference in the very last nibble) fog.nearest_unknown((0x7, 0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xc))\n(0x7, 0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xb) So we traverse to this last embedded leaf node at prefix a_leaf_node = t.traverse(prefix)\nHexaryTrieNode(sub_segments=(), value=b'your-other-value', suffix=(0x7, 0x4, 0x6, 0x8, 0x6, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xb, 0x6, 0x5, 0x7, 0x9), raw=[b' ther-key', b'your-other-value']) we mark the prefix as fully explored like so: fog = fog.explore(prefix, a_leaf_node.sub_segments)\nHexaryTrieFog Notice that sub_segments was empty, and the prefix has disappeared from our list of unexplored prefixes So far we have dealt with an un-changing trie, but what if it is modified while we are working on it? del t[b'your-other-key']\nt[b'your-key-rebranched'] = b'your-value'\nt.root_hash\nb'\"\\xc0\\xcaQ\\xa7X\\x08E\\xb5\"A\\xde\\xbfY\\xeb\"XY\\xb1O\\x034=\\x04\\x06\\xa9li\\xd8\\x92\\xadP' The unexplored prefixes we have before might not exist anymore. They might: 1. have been deleted entirely, in which case, we will get a blank node, and need no special treatment 2. lead us into the middle of a leaf or extension node, which makes things tricky prefix = fog.nearest_unknown((8,))\n(0x7, 0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xb)\nt.traverse(prefix)\nTraversedPartialPath: Could not traverse through HexaryTrieNode(sub_segments=((0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xb, 0x6, 0x5, 0x7, 0x9),), value=b'', suffix=(), raw=[b'\\x19our-key', b'f\\xbe\\x88\\x8f#\\xd5\\x15-8\\xc0\\x1f\\xfb\\xf7\\x8b=\\x98\\x86 \\xec\\xdeK\\x07\\xc8\\xbf\\xa7\\x93\\xfa\\x9e\\xc1\\x89@\\x00']) at (0x7,), only partially traversed with: (0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xb) Let's drill into what this means: - We fully traversed to a node at prefix (7,) - We tried to traverse into the rest of the prefix - We only got part-way through the extension node: (0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xb) - The extension node full sub-segment is actually: (0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xb, 0x6, 0x5, 0x7, 0x9) So what do we do about it? Catch the exception, and explore with the fog slightly differently from trie.exceptions import TraversedPartialPath\nlast_exception = None\ntry:\n      t.traverse(prefix)\n    except TraversedPartialPath as exc:\n      last_exception = exc We can now continue exploring the children of the extension node, by using an attribute on the exception: sub_segments = last_exception.simulated_node.sub_segments\n((0x6, 0x5, 0x7, 0x9),) Note that this sub-segment now carries us the rest of the way to the child of the node that we only partially traversed into. This \"simulated_node\" is created by slicing the extension node in two: the first extension node having the path that we (partially) traversed, and the second extension node being the child of that parent, which continues on to point to the child of the original extension. If the exception is raised on a leaf node, then the leaf node is sliced into an extension and another shorter leaf node. fog = fog.explore(prefix, sub_segments)\nHexaryTrieFog So now we can pick up where we left off, traversing to the child of the extension node, and so on. prefix = fog.nearest_unknown((8,))\n(0x7, 0x9, 0x6, 0xf, 0x7, 0x5, 0x7, 0x2, 0x2, 0xd, 0x6, 0xb, 0x6, 0x5, 0x7, 0x9) The following will not raise a TraversedPartialPath exception, because we know that a node was at the path, and the trie hasn't changed: t.traverse(prefix)\nHexaryTrieNode(sub_segments=((0x2,),), value=b'your-value', suffix=(), raw=[b'', b'', [b'=rebranched', b'your-value'], b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'your-value']) etc... ``` Note : traverse() will access the database for every node from the root to the target node. If navigating a large trie, consider using TrieFrontierCache and HexaryTrie.traverse_from() to minimize database lookups. See the tests in tests/test_hexary_trie_walk.py for some examples. BinaryTrie Note: One drawback of Binary Trie is that one key can not be the prefix of another key . For example,\nif you already set the value value1 with key key1 , you can not set another value with key key or key11 and the like. BinaryTrie branch and witness helper functions ```python from trie import BinaryTrie\nfrom trie.branches import (\n    check_if_branch_exist,\n    get_branch,\n    if_branch_valid,\n    get_witness_for_key_prefix,\n)\nt = BinaryTrie(db={})\nt.root_hash\nb\"\\xc5\\xd2F\\x01\\x86\\xf7#<\\x92~}\\xb2\\xdc\\xc7\\x03\\xc0\\xe5\\x00\\xb6S\\xca\\x82';{\\xfa\\xd8\\x04]\\x85\\xa4p\"\nt.set(b'key1', b'value1')\nt.set(b'key2', b'value2')\n``` Now Trie looks like this: root --->  (kvnode, *common key prefix*)\n                         |\n                         |\n                         |\n                    (branchnode)\n                     /         \\\n                    /           \\\n                   /             \\\n(kvnode, *remain kepath*)(kvnode, *remain kepath*)\n            |                           |\n            |                           |\n            |                           |\n  (leafnode, b'value1')       (leafnode, b'value2') ```python check_if_branch_exist function check_if_branch_exist(t.db, t.root_hash, b'key')\nTrue\ncheck_if_branch_exist(t.db, t.root_hash, b'key1')\nTrue\ncheck_if_branch_exist(t.db, t.root_hash, b'ken')\nFalse\ncheck_if_branch_exist(t.db, t.root_hash, b'key123')\nFalse get_branch function get_branch(t.db, t.root_hash, b'key1')\n(b'\\x00\\x82\\x1a\\xd9^L|38J\\xed\\xf31S\\xb2\\x97A\\x8dy\\x91RJ\\x92\\xf5ZC\\xb4\\x99T&;!\\x9f\\xa9!\\xa2\\xfe;', b\"\\x01*\\xaccxH\\x89\\x08}\\x93|\\xda\\xb9\\r\\x9b\\x82\\x8b\\xb2Y\\xbc\\x10\\xb9\\x88\\xf40\\xef\\xed\\x8b'\\x13\\xbc\\xa5\\xccYGb\\xc2\\x8db\\x88lPs@)\\x86v\\xd7B\\xf7\\xd3X\\x93\\xc9\\xf0\\xfd\\xae\\xe0`j#\\x0b\\xca;\\xf8\", b'\\x00\\x11\\x8aEL3\\x839E\\xbd\\xc4G\\xd1xj\\x0fxWu\\xcb\\xf6\\xf3\\xf2\\x8e7!M\\xca\\x1c/\\xd7\\x7f\\xed\\xc6', b'\\x02value1')\n``` Node started with b'\\x00' , b'\\x01' and b'\\x02' are kvnode, branchnode and leafnode respectively. ```python get_branch(t.db, t.root_hash, b'key')\n(b'\\x00\\x82\\x1a\\xd9^L|38J\\xed\\xf31S\\xb2\\x97A\\x8dy\\x91RJ\\x92\\xf5ZC\\xb4\\x99T&;!\\x9f\\xa9!\\xa2\\xfe;',)\nget_branch(t.db, t.root_hash, b'key123') # InvalidKeyError\nget_branch(t.db, t.root_hash, b'key5') # there is still branch for non-exist key\n(b'\\x00\\x82\\x1a\\xd9^L|38J\\xed\\xf31S\\xb2\\x97A\\x8dy\\x91RJ\\x92\\xf5ZC\\xb4\\x99T&;!\\x9f\\xa9!\\xa2\\xfe;',) if_branch_valid function v = t.get(b'key1')\nb = get_branch(t.db, t.root_hash, b'key1')\nif_branch_valid(b, t.root_hash, b'key1', v)\nTrue\nv = t.get(b'key5') # v should be None\nb = get_branch(t.db, t.root_hash, b'key5')\nif_branch_valid(b, t.root_hash, b'key5', v)\nTrue\nv = t.get(b'key1')\nb = get_branch(t.db, t.root_hash, b'key2')\nif_branch_valid(b, t.root_hash, b'key1', v) # KeyError\nif_branch_valid([], t.root_hash, b'key1', v) # AssertionError get_witness_for_key_prefix function get_witness_for_key_prefix(t.db, t.root_hash, b'key1') # equivalent to get_branch(t.db, t.root_hash, b'key1') (b'\\x00\\x82\\x1a\\xd9^L|38J\\xed\\xf31S\\xb2\\x97A\\x8dy\\x91RJ\\x92\\xf5ZC\\xb4\\x99T&;!\\x9f\\xa9!\\xa2\\xfe;', b\"\\x01*\\xaccxH\\x89\\x08}\\x93|\\xda\\xb9\\r\\x9b\\x82\\x8b\\xb2Y\\xbc\\x10\\xb9\\x88\\xf40\\xef\\xed\\x8b'\\x13\\xbc\\xa5\\xccYGb\\xc2\\x8db\\x88lPs@)\\x86v\\xd7B\\xf7\\xd3X\\x93\\xc9\\xf0\\xfd\\xae\\xe0 j#\\x0b\\xca;\\xf8\", b'\\x00\\x11\\x8aEL3\\x839E\\xbd\\xc4G\\xd1xj\\x0fxWu\\xcb\\xf6\\xf3\\xf2\\x8e7!M\\xca\\x1c/\\xd7\\x7f\\xed\\xc6', b'\\x02value1')\nget_witness_for_key_prefix(t.db, t.root_hash, b'key') # this will include additional nodes of b'key2'\n(b'\\x00\\x82\\x1a\\xd9^L|38J\\xed\\xf31S\\xb2\\x97A\\x8dy\\x91RJ\\x92\\xf5ZC\\xb4\\x99T&;!\\x9f\\xa9!\\xa2\\xfe;', b\"\\x01*\\xaccxH\\x89\\x08}\\x93|\\xda\\xb9\\r\\x9b\\x82\\x8b\\xb2Y\\xbc\\x10\\xb9\\x88\\xf40\\xef\\xed\\x8b'\\x13\\xbc\\xa5\\xccYGb\\xc2\\x8db\\x88lPs@)\\x86v\\xd7B\\xf7\\xd3X\\x93\\xc9\\xf0\\xfd\\xae\\xe0 j#\\x0b\\xca;\\xf8\", b'\\x00\\x11\\x8aEL3\\x839E\\xbd\\xc4G\\xd1xj\\x0fxWu\\xcb\\xf6\\xf3\\xf2\\x8e7!M\\xca\\x1c/\\xd7\\x7f\\xed\\xc6', b'\\x02value1', b'\\x00\\x10O\\xa9\\x0b\\x1c!_`<\\xb5^\\x98D\\x89\\x17\\x148\\xac\\xda&\\xb3P\\xf6\\x06[\\x1b9\\xc09\\xbas\\x85\\xf5', b'\\x02value2')\nget_witness_for_key_prefix(t.db, t.root_hash, b'') # this will return the whole trie\n```"}, {"name": "py-wasm", "desc": "A python implementation of the web assembly interpreter", "readme": "py-wasm A python implementation of the web assembly interpreter Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install py-wasm Developer Setup If you would like to hack on py-wasm, please check out the Ethereum Development Tactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/py-wasm.git\ncd py-wasm\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 wasm/ tests/ -c \"clear; flake8 wasm tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on py-wasm failed'\" ../tests ../wasm Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). To include changes made with each\nrelease, update \"docs/releases.rst\" with the changes, and apply commit directly to master \nbefore release. If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\" Development and Testing The test suite in this library is run using pytest . sh\npytest tests/ Part of the test suite includes the spec tests from the official Web Assembly\nspec.  These are found under ./tests/spec . It is often useful to view logging output when running tests.  This can be done with: sh\npytest tests/spec/ --log-cli-level=debug When trying to diagnose a specific failure in a spec test it can be useful to\nrun the tests in a branch that is currently passing, capture the logging\noutput, and then compare it to the logging output of the test in the failing\nbranch.  In order to make it easier to get the relevant logging output, you can\nuse the flag --stop-after-command-line=123 where 123 is the line for the\nfailing command.  The full command would look something like: sh\npytest tests/spec/ --log-cli-level=debug --stop-after-command-line=123 -k f32.wast This sets the logging output to DEBUG level, stops the test suite after it\npasses command line 123 and only runs the spec tests from the f32.wast spec\ntest file. There are a few spec tests that take noticeably longer than the others.  You\ncan omit these from the test run by adding the flag --skip-slow-spec ."}, {"name": "pydevp2p", "desc": "Python Implementation of the Ethereum P2P stack", "readme": null}, {"name": "pyethapp", "desc": null, "readme": null}, {"name": "pyethereum", "desc": "Next generation cryptocurrency network", "readme": "PyEthereum has been Deprecated This project is no longer supported.  You might try Py-EVM"}, {"name": "pyethsaletool", "desc": null, "readme": "Sale documents: Intended use of revenue \u0110\u039eV plan White paper Yellow paper Terms and conditions Ether Product Purchase Agreement Notes: Purchase minimum is 0.01 BTC Soft purchase maximum is 3000000000 ETH; this script enforces 1500 BTC. If your purchase is larger, contact largepurchases@ethereum.org Please don't try to purchase ether directly into a contract address that you intend to create post-genesis. We know that at least some of you are clever enough to try this, but we take no responsibility for what happens when we change the protocol or the way that contract addresses are generated. Additionally, right now contract addresses depend on sender address and nonce only, so you're not really getting any extra security. Be sure not to lose your wallet or your password. Modern psychological understanding of human memory suggests that coming up with a new password in your head and then not using it for the six months before genesis will likely lead to you forgetting the password, so consider writing the password down. DON'T LOSE YOUR WALLET OR YOUR PASSWORD DON'T LOSE YOUR WALLET OR YOUR PASSWORD DON'T LOSE YOUR WALLET OR YOUR PASSWORD Instructions: python pyethsaletool.py genwallet , enter a password and email Make sure you write down the password or otherwise keep it safe, and make sure you backup your wallet file (saved at ethwallet.json by default, you can use -w to save it somewhere else) Send BTC into the intermediate address provided Use python pyethsaletool.py finalize to send the BTC from the intermediate address to the exodus Alternative cold wallet setup: Install pyethereum on a cold wallet device Use cat /dev/urandom | head -c 1000 | pyethtool -b sha3 > priv.key on the CWD to make a private key cat priv.key | pyethtool -s privtoaddr to get your address Copy the address to an online laptop, and switch to the laptop for the remaining steps python pyethsaletool.py genwallet , enter a password and email Make sure you write down the password or otherwise keep it safe, and make sure you backup your wallet file (saved at ethwallet.json by default, you can use -w to save it somewhere else) Send BTC into the intermediate address provided python pyethsaletool.py finalize <addr> , substituting <addr> with the address generated on the CWD Additional instructions: To recover the private key of your BTC intermediate address, use python pyethsaletool.py getbtcprivkey To show your BTC intermediate address, use python pyethsaletool.py getbtcaddress To recover your ETH privkey, use python pyethsaletool.py getethprivkey To show your ETH address, use python pyethsaletool.py getethaddress Use -w /path/to/wallet.json if you want to point to a specific wallet file or save your wallet at a specific location"}, {"name": "pyeth_keys", "desc": null, "readme": ""}, {"name": "pyrlp", "desc": "The python RLP serialization library", "readme": "pyrlp A package for Recursive Length Prefix encoding and decoding Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npython -m pip install rlp Developer Setup If you would like to hack on pyrlp, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/pyrlp.git\ncd pyrlp\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "pytest-asyncio-network-simulator", "desc": "Pluggin for Pytest for testing asyncio applications using a mocked networking layer", "readme": "pytest-asyncio-network-simulator A plugin for pytest which simulates the network in various asyncio APIs\nsuch that rather than opening and communicating over sockets, communcation\nhappens directly in memory. Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install pytest-asyncio-network-simulator Developer Setup If you would like to hack on pytest-asyncio-network-simulator , please check out the Ethereum Development Tactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/pytest-asyncio-network-simulator.git\ncd pytest-asyncio-network-simulator\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 asyncio_network_simulator/ tests/ -c \"clear; flake8 asyncio_network_simulator tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on pytest-asyncio-network-simulator failed'\" ../tests ../asyncio_network_simulator Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "pytest-ethereum", "desc": null, "readme": "pytest-ethereum Pytest library for ethereum projects. Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install pytest-ethereum Developer Setup If you would like to hack on pytest-ethereum, please check out the Ethereum Development Tactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/pytest-ethereum.git\ncd pytest-ethereum\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 pytest_ethereum/ tests/ -c \"clear; flake8 pytest_ethereum tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on pytest-ethereum failed'\" ../tests ../pytest_ethereum Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "py_ecc", "desc": "Python implementation of ECC pairing and bn_128 and bls12_381 curve operations", "readme": "py_ecc Elliptic curve crypto in python including secp256k1, alt_bn128, and bls12_381. Warning : This library contains some experimental codes that have NOT been audited. Read more in the documentation below. View the change log Quickstart sh\npython -m pip install py_ecc BLS Signatures py_ecc implements the IETF BLS draft standard v4 as per the inter-blockchain standardization agreement. The BLS standards specify different ciphersuites which each have different functionality to accommodate various use cases. The following ciphersuites are available from this library: G2Basic also known as BLS_SIG_BLS12381G2_XMD:SHA-256_SSWU_RO_NUL_ G2MessageAugmentation also known as BLS_SIG_BLS12381G2_XMD:SHA-256_SSWU_RO_AUG_ G2ProofOfPossession also known as BLS_SIG_BLS12381G2_XMD:SHA-256_SSWU_RO_POP_ Basic Usage ```python\nfrom py_ecc.bls import G2ProofOfPossession as bls_pop private_key = 5566\npublic_key = bls_pop.SkToPk(private_key) message = b'\\xab' * 32  # The message to be signed Signing signature = bls_pop.Sign(private_key, message) Verifying assert bls_pop.Verify(public_key, message, signature)\n``` Aggregating Signatures ```python\nprivate_keys = [3, 14, 159]\npublic_keys = [bls_pop.SkToPk(key) for key in private_keys]\nsignatures = [bls_pop.Sign(key, message) for key in private_keys] Aggregating agg_sig = bls_pop.Aggregate(signatures) Verifying signatures over the same message. Note this is only safe if Proofs of Possession have been verified for each of the public keys beforehand. See the BLS standards for why this is the case. assert bls_pop.FastAggregateVerify(public_keys, message, agg_sig)\n``` Multiple Aggregation ```python\nmessages = [b'\\xaa' * 42, b'\\xbb' * 32, b'\\xcc' * 64]\nsignatures = [bls_pop.Sign(key, message) for key, message in zip(private_keys, messages)]\nagg_sig = bls_pop.Aggregate(signatures) Verify aggregate signature with different messages assert bls_pop.AggregateVerify(public_keys, messages, agg_sig)\n``` Developer Setup If you would like to hack on py_ecc, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Documentation We use pre-commit to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith make lint . If you need to make a commit that skips the pre-commit checks, you\ncan do so with git commit --no-verify . Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/py_ecc.git\ncd py_ecc\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install Release setup To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "py_pairing", "desc": "Elliptic curve operations, including pairings", "readme": "Implements optimal ate pairings over the bn_128 curve."}, {"name": "rayonism", "desc": "DEPRECATED", "readme": "Deprecated For the latest Merge work, see ethereum/consensus-specs and ethereum/execution-specs Rayonism Specs Rayonism Merge Spec : What to implement for merge testnets Eth2.0 specs : The Eth2.0 specs for Merge and Sharding upgrades. Meta Spec : High-level overview, rough plans, updates Resources Rayonism.io : Project description and F.A.Q. Mergenet tutorial : How to configure your own mergenet, step by step Merge Devnet setup guide : High-level testnet configuration description Merge testnet 0 : Specifics for first devnet Shard node design doc (soon) Additions welcome, open a PR! Testnets Example devnet The 1-day devnet (soon) The 1-week devnet (soon) License CC0 1.0 Universal, see LICENSE file."}, {"name": "remix", "desc": "This has been moved to https://github.com/ethereum/remix-project", "readme": "The project has been moved to https://github.com/ethereum/remix-project Remix is a suite of tools that helps smart contract development, compilation, testing & deployment. These tools also works as a core of native plugins of Remix IDE. Remix IDE is an IDE for Solidity dApp developers, powered by Remix. The Remix IDE repository is available here , and an online version is available at https://remix.ethereum.org. For more, check out the Remix IDE documentation . Remix Modules Remix is built out of several different modules. Here is the brief description. remix-analyzer : Perform static analysis on Solidity smart contracts to check security vulnerabilities and bad development practices remix-astwalker : Parse solidity AST (Abstract Syntax Tree) remix-debug : Debug Ethereum transactions. It provides several controls that allow stepping over the trace and seeing the current state of a selected step. remix-solidity : Load a Solidity compiler from provided URL and compile the contract using loaded compiler and return the compilation details remix-lib : Common place for libraries being used across multiple modules remix-tests : Unit test Solidity smart contracts. It works as a plugin & as CLI both remix-url-resolver : Provide helpers for resolving the content from external URL ( including github, swarm, ipfs etc.). remixd : Allow accessing local filesystem from Remix IDE by running a daemon Each module generally has their own npm package and test suite, as well as basic documentation in their respective README s. Usage of modules as plugin is well documented here . Contributing Everyone is very welcome to contribute on the codebase of Remix. Please reach us in Gitter in case of any query/feedback/suggestion. For more information on the contributing procedure, see CONTRIBUTING.md ."}, {"name": "remix-desktop", "desc": "Remix IDE desktop", "readme": "Remix Desktop Remix Desktop is an Electron version of Remix IDE.  It works on Linux, Windows, & Macs. Like the name says, it is a desktop app - so it you can seamlessly access files on your computer's filesystem. To find out more about Remix IDE - please go to ethereum/remix-project - or to see it in action, go to remix.ethereum.org . Download To download Remix Desktop, see releases: https://github.com/ethereum/remix-desktop/releases Differences between Remix Desktop & Remix IDE - the web app Accessing your hard drive Remix IDE - the web app works in a browser and without using remixd , it cannot access your computer's file system. Whereas with Remix Desktop accessing your filesystem is easy. Saving and accessing files saved on your computer are the big advantage of Remix Desktop. In Remix Desktop, you select a folder from the File menu (File -> Open Folder) to make it the active folder in the File Explorers' workspace.  Go to File -> Open Folder to select. Version control & folder capacity With Remix Desktop, version control is just like it would be with any other desktop IDE. Similarly the size of a workspace folder is limited by your computer's hard drive.  In Remix IDE - the web app, the size of a workspace folder is limited by the size of the browser's local storage. There are techniques for putting version control in the browser (like using remixd or the DGIT plugin), but these are work-arounds to inherent limitations of a browser. Deploying to a public testnet with Injected Web3 & Metamask Remix Desktop does not have access to the Metamask - the browser plugin - so deploying to a public chain currently involves using the Wallet Connect plugin.  In contrast, Remix IDE - the web app has easy access to the Metamask browser plugin. Updates to Remix IDE & Updates to Remix Desktop Please check subscribe to our Twitter feed @EthereumRemix - so we can prompt you to download the latest version.  Remix Desktop is a wrapper of Remix IDE so Remix Desktop will automatically grab the latest version of Remix IDE.  You only need to download the new releases of Remix Desktop.  We also post announcements in our gitter chat: https://gitter.im/ethereum/remix Where to go to for help Please post your questions to: https://gitter.im/ethereum/remix Reporting issues For posting issues - you can alert us in the gitter chat - or post the issue to this repo."}, {"name": "remix-ide", "desc": "Documentation for Remix IDE", "readme": "Remix This repository contain only Remix's official Read the Docs documentation source code. Documentation is available here . If looking for Remix IDE codebase, it has been moved to https://github.com/ethereum/remix-project About Remix Project Remix Project is a platform for development tools that use a plugin architecture. It encompasses sub-projects including Remix Plugin Engine, Remix Libraries, and of course Remix IDE. Remix IDE is an open source web and desktop application. It fosters a fast development cycle and has a rich set of plugins with intuitive GUIs. Remix is used for the entire journey of contract development with Solidity language as well as a playground for learning and teaching Ethereum. Start developing using Remix on browser, visit: https://remix.ethereum.org For desktop version, see releases: https://github.com/ethereum/remix-desktop/releases Remix libraries work as a core of native plugins of Remix IDE. Read more about libraries here Build Steps to build this project as as: pip3 install sphinx sphinx_rtd_theme\npip3 install myst-parser\ngit clone https://github.com/ethereum/remix-ide.git\ncd docs/\nmake html Go to docs/_build/html and open index.html on the browser. Contributing We wholeheartedly welcome everyone to contribute. Suggestions, issues, queries and feedbacks are our pleasure. Please reach us on Gitter in case of any query. The site is internationalized.  Do not make any corrections to .po or .pot files.  These get handled in our translation management platform.  To help with the translation of our documentation, please visit https://crowdin.com/project/remix-translation. To help with our translations of Remix's UI, please visit https://crowdin.com/project/remix-ui."}, {"name": "remix-live", "desc": "Live deployment of the remix IDE", "readme": "Automatic build Built website from 20e46d086 . See https://github.com/ethereum/remix-ide/ for details.\nTo use an offline copy, download remix-20e46d086.zip ."}, {"name": "remix-live-alpha", "desc": "Live deployment of the remix IDE (alpha)", "readme": "Automatic build Built website from 01cdaa484 . See https://github.com/ethereum/remix-ide/ for details.\nTo use an offline copy, download remix-01cdaa484.zip ."}, {"name": "remix-live-beta", "desc": null, "readme": "Remix Remix is a browser-based compiler and IDE that enables users to build Ethereum contracts with Solidity language and to debug transactions. To try it out, visit https://remix.ethereum.org . https://github.com/ethereum/remix-ide/releases also gives others ways to use Remix locally. Please check it out. Remix consists of many modules and in this repository you will find the Remix IDE (aka. Browser-Solidity). Offline Usage The gh-pages branch has always the latest stable build of Remix. It also contains a ZIP file with the entire build. Download it to use offline. Note: It contains the latest release of Solidity available at the time of the packaging. No other compiler versions are supported. INSTALLATION: Install npm and node.js (see https://docs.npmjs.com/getting-started/installing-node), then do: Remix-ide has been published as an npm module: bash\nnpm install remix-ide -g\nremix-ide Or if you want to clone the github repository ( wget need to be installed first) : ```bash\ngit clone https://github.com/ethereum/remix-ide.git\ngit clone https://github.com/ethereum/remix.git # only if you plan to link remix and remix-ide repositories and develop on it. cd remix  # only if you plan to link remix and remix-ide repositories and develop on it.\nnpm install  # only if you plan to link remix and remix-ide repositories and develop on it.\nnpm run bootstrap  # only if you plan to link remix and remix-ide repositories and develop on it. cd remix-ide\nnpm install\nnpm run setupremix  # only if you plan to link remix and remix-ide repositories and develop on it.\nnpm start\n``` DEVELOPING: Run npm start and open http://127.0.0.1:8080 in your browser. Then open your text editor and start developing.\nThe browser will automatically refresh when files are saved. Most of the the time working with other modules (like debugger etc.) hosted in the Remix repository is not needed. Troubleshooting building Some things to consider if you have trouble building the package: Make sure that you have the correct version of node , npm and nvm . You can find the version that is tested on Travis CI by looking at the log in the build results . Run: bash\nnode --version\nnpm --version\nnvm --version In Debian based OS such as Ubuntu 14.04LTS you may need to run apt-get install build-essential . After installing build-essential run npm rebuild . Unit Testing Register new unit test files in test/index.js .\nThe tests are written using tape . Run the unit tests via: npm test For local headless browser tests run npm run test-browser (requires Selenium to be installed - can be done with npm run selenium-install ) Running unit tests via npm test requires at least node v7.0.0 Browser Testing To run the Selenium tests via Nightwatch: Build Remix IDE and serve it: npm run build && npm run serve # starts web server at localhost:8080 Make sure Selenium is installed npm run selenium-install # don't need to repeat Run a selenium server npm run selenium Run all the tests npm run nightwatch_local_firefox or npm run nightwatch_local_chrome Or run a specific test case: - npm run nightwatch_local_ballot\n\n- npm run nightwatch_local_libraryDeployment\n\n- npm run nightwatch_local_solidityImport\n\n- npm run nightwatch_local_recorder\n\n- npm run nightwatch_local_transactionExecution\n\n- npm run nightwatch_local_staticAnalysis\n\n- npm run nightwatch_local_signingMessage\n\n- npm run nightwatch_local_console\n\n- npm run nightwatch_local_remixd # remixd needs to be run NOTE: the ballot tests suite requires to run ganache-cli locally. the remixd tests suite requires to run remixd locally. the gist tests suite requires specifying a github access token in .env file . gist_token = <token> note that this token should have permission to create a gist. Usage as a Chrome Extension If you would like to use this as a Chrome extension, you must either build it first or pull from the gh-pages branch, both described above.\nAfter that, follow these steps: Browse to chrome://extensions/ Make sure 'Developer mode' has been checked Click 'Load unpacked extension...' to pop up a file-selection dialog Select your remix-ide folder Documentation To see details about how to use Remix for developing and/or debugging Solidity contracts, please see our documentation page"}, {"name": "remix-plugin", "desc": null, "readme": "Remix Plugin Remix plugin is a universal plugin system written in Typescript. It provides an extendable engine that simplifies communication between multiple internal or external sources. This repository manages multiple projects related to remix plugins. It's divided into two main categories : \n- Engine: A library to manage communication between plugins. \n- Plugin: A library to create an external plugin. Engine The core component of the engine is the @remixproject/engine library. It can be extended to run in different environments. | Name                                                                     | Latest Version       | Next Version\n| ------------------------------------------------------------------------ | :------------------: | :------------------:\n| @remixproject/engine | | | @remixproject/engine-vscode | | | @remixproject/engine-web | | | @remixproject/engine-node | | To create a new environment connector, check out @remixproject/engine . Plugin The core component of the plugin is the @remixproject/plugin library. It can be extended to run in different environments. | Name                                                                     | Latest Version       | Next Version\n| ------------------------------------------------------------------------ | :------------------: | :------------------:\n| @remixproject/plugin | | | @remixproject/plugin-vscode | | | @remixproject/plugin-iframe | | | @remixproject/plugin-webview | | | @remixproject/plugin-child-process | | To create a new environment connector, check out @remixproject/plugin . API Remix plugin offers a set of common APIs for plugins to implement. This set of APIs is used in remix-ide , therefore every plugin running inside remix-ide should be able to run in an engine that implements these APIs. | Name                               | Latest Version       | Next Version\n| ---------------------------------- | :------------------: | :------------------:\n| @remixproject/plugin-api | | The first goal of remix plugin is to enable a plugin to work in the envrionments of multiple engines. If a plugin has dependancies on other plugins, each engine must implement these dependancies. Contribute Setup git clone https://github.com/ethereum/remix-plugin.git\ncd remix-plugin\nnpm install See dependancy graph To better understand the project structure, you can display a dependancy graph with: npm run dep-graph Open your browser on http://localhost:4211/ . Build This uses nx's affected:build to only update what has been changes since last build. npm run build Build a specific project npx nx build ${projectName} --with-deps Example for engine-vscode : npx nx build engine-vscode --with-deps Test This uses nx's affected:test to only update what has been changes since last test. npm test Publish This uses lerna to deploy all the packages with a new version: npm run deploy:latest OR npm run deploy:next"}, {"name": "remix-plugins-directory", "desc": "Remix plugins directory", "readme": "Remix Plugins Directory This repository hosts a plugins directory.\nThe directory is used by Remix IDE for loading the list of available plugins. Getting started with plugin development Read all about getting started with plugin development and guidelines on how to make it work for you https://remix-plugins-directory.readthedocs.io/en/latest/ # Conditions for adding a new plugin The plugin should work on both light and dark theme types. The best would be to check them before approving any change or any new plugin. No svg file is acceptable as a plugin icon for security reasons. We recommend using webp or png formats. Profile json should contain as much info as possible. Having a short, reasonable description as well as the link to docs and the repo will improve the onboarding of users Maintained by Remix should be added to plugins 100% controlled by the Remix team only. # Community Feel free to join our discord server if you have any questions Join Remix Discord Server"}, {"name": "remix-project", "desc": "Remix is a browser-based compiler and IDE that enables users to build Ethereum contracts with Solidity language and to debug transactions.", "readme": "Remix Project [![CircleCI](https://img.shields.io/circleci/build/github/ethereum/remix-project?logo=circleci)](https://circleci.com/gh/ethereum/remix-project)\n[![Documentation Status](https://readthedocs.org/projects/remix-ide/badge/?version=latest)](https://remix-ide.readthedocs.io/en/latest/index.html)\n[![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&logo=github)](https://github.com/ethereum/remix-project/blob/master/CONTRIBUTING.md)\n[![GitHub contributors](https://img.shields.io/github/contributors/ethereum/remix-project?style=flat&logo=github)](https://github.com/ethereum/remix-project/blob/master/CONTRIBUTING.md)\n[![Awesome Remix](https://img.shields.io/badge/Awesome--Remix-resources-green?logo=awesomelists)](https://github.com/ethereum/awesome-remix)\n![GitHub](https://img.shields.io/github/license/ethereum/remix-project)\n[![Discord](https://img.shields.io/badge/join-discord-brightgreen.svg?style=flat&logo=discord)](https://discord.gg/mh9hFCKkEq)\n[![Twitter Follow](https://img.shields.io/twitter/follow/ethereumremix?style=flat&logo=twitter&color=green)](https://twitter.com/ethereumremix) Remix Project Remix Project is a rich toolset including Remix IDE, a comprehensive smart contract development tool. The Remix Project also includes Remix Plugin Engine and Remix Libraries which are low-level tools for wider use. Remix IDE Remix IDE is used for the entire journey of contract development by users of any knowledge level. It fosters a fast development cycle and has a rich set of plugins with intuitive GUIs. The IDE comes in 2 flavors and a VSCode extension: Remix Online IDE , see: https://remix.ethereum.org :point_right: Supported browsers: Firefox v100.0.1 & Chrome v101.0.4951.64. No support for Remix's use on tablets or smartphones or telephones. Remix Desktop IDE , see releases: https://github.com/ethereum/remix-desktop/releases VSCode extension , see: Ethereum-Remix Remix libraries Remix libraries are essential for Remix IDE's native plugins. Read more about libraries here Offline Usage The gh-pages branch of remix-live always has the latest stable build of Remix. It contains a ZIP file with the entire build. Download it to use offline. Note: It contains the latest supported version of Solidity available at the time of the packaging. Other compiler versions can be used online only. Setup Install Yarn and Node.js . See Guide for NodeJs and Yarn install Supported versions: bash\n\"engines\": {\n    \"node\": \"^20.0.0\",\n    \"npm\": \"^6.14.15\"\n  } Install Nx CLI globally to enable running nx executable commands . bash\nyarn global add nx Clone the GitHub repository ( wget need to be installed first): bash\ngit clone https://github.com/ethereum/remix-project.git * Build and Run remix-project : Move to project directory: cd remix-project Install dependencies: yarn install or simply run yarn Build Remix libraries: yarn run build:libs Build Remix project: yarn build Build and run project server: yarn serve . Optionally, run yarn serve:hot to enable hot module reload for frontend updates. Open http://127.0.0.1:8080 in your browser to load Remix IDE locally. Go to your text editor and start developing. The browser will automatically refresh when files are saved. Production Build To generate react production builds for remix-project. bash\nyarn run build:production Build can be found in remix-project/dist/apps/remix-ide directory. bash\nyarn run serve:production Production build will be served by default to http://localhost:8080/ or http://127.0.0.1:8080/ Docker: Prerequisites: \n* Docker (https://docs.docker.com/desktop/)\n* Docker Compose (https://docs.docker.com/compose/install/) Run with docker If you want to run the latest changes that are merged into the master branch then run: docker pull remixproject/remix-ide:latest\ndocker run -p 8080:80 remixproject/remix-ide:latest If you want to run the latest remix-live release run. docker pull remixproject/remix-ide:remix_live\ndocker run -p 8080:80 remixproject/remix-ide:remix_live Run with docker-compose: To run locally without building you only need docker-compose.yaml file and you can run: docker-compose pull\ndocker-compose up -d Then go to http://localhost:8080 and you can use your Remix instance. To fetch the docker-compose file without cloning this repo run: curl https://raw.githubusercontent.com/ethereum/remix-project/master/docker-compose.yaml > docker-compose.yaml Troubleshooting If you have trouble building the project, make sure that you have the correct version of node , npm and nvm . Also, ensure Nx CLI is installed globally. Run: bash\nnode --version\nnpm --version\nnvm --version In Debian-based OS such as Ubuntu 14.04LTS, you may need to run apt-get install build-essential . After installing build-essential , run npm rebuild . Unit Testing Run the unit tests using library name like: nx test <project-name> For example, to run unit tests of remix-analyzer , use nx test remix-analyzer Browser Testing To run the Selenium tests via Nightwatch: Install Selenium for the first time: yarn run selenium-install Run a selenium server: yarn run selenium Build & Serve Remix: yarn serve Run all the end-to-end tests: for Firefox: yarn run nightwatch_local_firefox , or for Google Chrome: yarn run nightwatch_local_chrome - Run a specific test case instead, use a command like this: - yarn run nightwatch_local_ballot The package.json file contains a list of all the tests you can run. NOTE: The ballot tests suite requires running ganache locally. The remixd tests suite requires running remixd locally. The gist tests suite requires specifying a GitHub access token in .env file . gist_token = <token> // token should have permission to create a gist Using 'select_test' for locally running specific tests There is a script to allow selecting the browser and a specific test to run: yarn run select_test You need to have selenium running the IDE running optionally have remixd or ganache running Splitting tests with groups Groups can be used to group tests in a test file together. The advantage is you can avoid running long test files when you want to focus on a specific set of tests within a test file.x These groups only apply to the test file, not across all test files. So for example group1 in the ballot is not related to a group1 in another test file. Running a group only runs the tests marked as belonging to the group + all the tests in the test file that do not have a group tag. This way you can have tests that run for all groups, for example, to perform common actions. There is no need to number the groups in a certain order. The number of the group is arbitrary. A test can have multiple group tags, this means that this test will run in different groups. You should write your tests so they can be executed in groups and not depend on other groups. To do this you need to: Add a group to tag to a test, they are formatted as #group followed by a number: so it becomes #group1, #group220, #group4. Any number will do. You don't have to do it in a specific order. 'Should generate test file #group1': function (browser: NightwatchBrowser) {\n    browser.waitForElementPresent('*[data-id=\"verticalIconsKindfilePanel\"]') add '@disabled': true to the test file you want to split: module.exports = {\n  '@disabled': true,\n  before: function (browser: NightwatchBrowser, done: VoidFunction) {\n    init(browser, done) // , 'http://localhost:8080', false)\n  }, - change package JSON to locally run all group tests: \"nightwatch_local_debugger\": \"yarn run build:e2e && nightwatch --config dist/apps/remix-ide-e2e/nightwatch.js dist/apps/remix-ide-e2e/src/tests/debugger_*.spec.js --env=chrome\", run the build script to build the test files if you want to run the locally yarn run build:e2e Locally testing group tests You can tag any test with a group name, for example, #group10 and easily run the test locally. make sure you have nx installed globally group tests are run like any other test, just specify the correct group number method 1 This script will give you an options menu, just select the test you want yarn run select_test method 2 yarn run group_test --test=debugger --group=10 --env=chromeDesktop - specify chromeDesktop to see the browser action, use 'chrome' to run it headless Run the same (flaky) test across all instances in CircleCI In CircleCI all tests are divided across instances to run in parallel. \nYou can also run 1 or more tests simultaneously across all instances.\nThis way the pipeline can easily be restarted to check if a test is flaky. For example: 'Static Analysis run with remixd #group3 #flaky': function (browser) { Now, the group3 of this test will be executed in firefox and chrome 80 times.\nIf you mark more groups in other tests they will also be executed. CONFIGURATION It's important to set a parameter in the .circleci/config.yml, set it to false then the normal tests will run.\nSet it to true to run only tests marked with flaky. parameters:\n  run_flaky_tests:\n    type: boolean\n    default: true Important Links Official website: https://remix-project.org Official documentation: https://remix-ide.readthedocs.io/en/latest/ Curated list of Remix resources: https://github.com/ethereum/awesome-remix Medium: https://medium.com/remix-ide Twitter: https://twitter.com/ethereumremix Join Discord: https://discord.gg/mh9hFCKkEq"}, {"name": "remix-tests", "desc": null, "readme": "MOVED to https://github.com/ethereum/remix/tree/master/remix-tests"}, {"name": "remix-theia", "desc": null, "readme": null}, {"name": "remix-vscode", "desc": "Remix VS Code extension", "readme": "DEPRECATED This extension has been removed from the VSCODE marketplace and will be replaced by a dedicated stand-alone dektop application. Ethereum Remix Project extension for Visual Studio Code This project brings Remix plugins to Visual Studio Code. Remix plugins can perform a variety of tasks such as verifying contracts, linting, generating documentation, running tutorials, compiling, debugging and much more. The Remix Plugin API allows plugins that run in Remix to run in Visual Studio Code too. It allows developers to access and interact with the file system, components, extensions and other Remix plugins without actually having to create a different code base. For more info on what Remix is and what plugins do please visit our Remix IDE and Remix Project website Ethereum Remix Project extension for Visual Studio Code A beta release. Installation from the Visual Studio Code Marketplace Requirements The plugins Select, activate, deactivate a plugin Load a development plugin Compiling Solidity & Yul Deploying contracts & Wallet Connect Contributing and development A beta release. As we are continuing development of Remix and the Plugin API more functionalities will open up. So at first it might feel limited. In this beta release we show you a glimpse of what the possibilities are, inviting everybody to contribute & comment. Installation from the Visual Studio Code Marketplace Install from Visual Studio Code Marketplace Requirements Before being able to use the extension, you need to have at least a folder opened or a workspace. The plugins The extension loads with a default set of plugins. As time goes on we will add more plugins. You can also suggest and create plugins using our plugin system and API. Feel free to contact us on our gitter channels. Remix & Remix Dev and read up on the basics\non Read the docs Select, activate, deactivate a plugin Before you can use a plugin, it needs to be activated. Activation means you open it and it will run. Load a development plugin As you develop your own plugin or you want to try out a plugin by using a custom URL you can easily add it to the list. Click on 'add plugin' from the Remix Plugins More actions menu on top right The plugin system requires a valid JSON string that contains the information needed.\n  Add your JSON plugin info into the input box. An example is given below. The URL can contain any URL or a local file. Make sure to give your plugin a unique name. You can't have two plugins with the same name. json\n{\n  \"name\": \"dev-plugin\",\n  \"displayName\": \"My first plugin\",\n  \"methods\": [],\n  \"version\": \"0.0.1-dev\",\n  \"url\": \"http://localhost:3000\",\n  \"description\": \"A great plugin for the Remix project\",\n  \"icon\": \"https://raw.githubusercontent.com/protofire/solhint/master/solhint-icon.png\",\n  \"location\": \"sidePanel\"\n} Compiling Solidity & Yul Our extension provides some basic functionality to get started with Solidity and Yul development. Quite a few remix plugins use the results of compilation to generate content for you. So this is extremely useful. At this time you can compile your files using two methods:\n* the internal Remix compiler\n* the compiler provided by the Solidity Extension (https://marketplace.visualstudio.com/items?itemName=JuanBlanco.solidity) Compiling with the Solidity extension provides some extra features that are included in the Solidity extension. Warning: when you have the Solidity extension installed you usually hit F5 to compile. This will not work (yet) in conjunction with Remix. You\nshould compile with the 'Compile with Solidity extension'. This way you get the benefits of both extensions. You should have a sol file actively selected when compiling. If you have the plugin in focus it won't be able to tell which file you want to compile. To compile use the command palette ( Shift+cmd+p ) and type in REMIX. You will see both options there. You can also change the compiler version of both compilers from the command palette. You can change to Yul development the same way using the language selector in the command palette. Deploying contracts & Wallet Connect Contributing and development You can checkout our code on github * Make sure the extension from the marketplace is not installed, running both versions will not work.\n* Open up the repo in Visual Studio Code.\n* run Yarn\n* hit F5\n* A new Visual Studio Code window will open where the extension is running."}, {"name": "remix-website", "desc": null, "readme": null}, {"name": "remix-workshops", "desc": null, "readme": "This is a repo of tutorials for the Remix's LearnEth Plugin To use these tutorials: 1. Open Remix https://remix.ethereum.org 2. In the plugin manager activate LEARNETH 3. Go to the Learneth plugin and these tutorials will load by default 4. You may need to sign into Github especially during an in-person workshop Github will block too many requests from the same location, unless you are signed into Github and have input your token.  Generally, this is only an issue during in person workshops, when there can be many requests from the same location. To input your Github token: - In one browser window - go to https://remix.ethereum.org and go to the settings tab\n- In another browser window go to:\n\nhttps://github.com/settings/tokens\n\nand create a new token and save it in Remix in the you just opened on the settings tab. Write your own tutorials for LEARNETH: See this site for instructions: https://remix-learneth-plugin.readthedocs.io/en/latest/index.html#creating-tutorials"}, {"name": "remixd", "desc": "remix server", "readme": "The project code base has been moved to remix-project/remixd . remixd is a tool that intend to be used with Remix IDE (aka. Browser-Solidity). It allows a websocket connection between Remix IDE (web application) and the local computer. Practically Remix IDE make available a folder shared by remixd . More details are explained in this tutorial . Alternatively remixd can be used to setup a development environment that can be used with other popular frameworks like Embark, Truffle, Ganache, etc.. remixd needs npm and node INSTALLATION npm install -g remixd HELP SECTION ```\n  Usage: remixd -s --remix-ide https://remix.ethereum.org Provide a two-way connection between the local computer and Remix IDE. Options: --remix-ide URL of remix instance allowed to connect to this \n                                        web sockect connection\n  -s, --shared-folder Folder to share with Remix IDE\n  --read-only                           Treat shared folder as read-only (experimental)\n  -h, --help                            output usage information ``` SHARE A FOLDER remixd -s <absolute-path> --remix-ide https://remix.ethereum.org The current user should have read/write access to the folder (at least read access). It is important to notice that changes made to the current file in Remix IDE are automatically saved to the local computer every 5000 ms. There is no Save action. But the Ctrl-Z (undo) can be used. Furthermore :\n - No copy of the shared folder are kept in the browser storage.\n - It is not possible to create a file from Remix IDE (that might change).\n - If a folder does not contain any file, the folder will not be displayed in the explorer (that might change).\n - Symbolic links are not forwarded to Remix IDE."}, {"name": "remote-signing-api", "desc": "This repository outlines standard remote signing application programming interface (APIs) for communication between remote signers and Ethereum validator clients.  Remote signing service allows validator clients to offload signing of validation duties (e.g Attestations, BeaconBlocks) by managing security, slashing protection, and key management.", "readme": "Ethereum remote signing APIs Warning: Super fresh repo. Expect rapid iteration and breaking changes API browser: https://ethereum.github.io/remote-signing-api/ Outline This repository outlines standard remote signing application programming interface (APIs) for communication between remote signers and Ethereum\nvalidator clients. Remote signing service allows validator clients to offload signing of validation duties (e.g  Attestations, BeaconBlocks) by managing security, slashing protection,\nand key management. The API is a REST interface, accessed via HTTP/HTTPS. This API should not be exposed directly to the public Internet and appropriate firewall rules should be\nin place to restrict access only from validator clients. At the moment, only JSON is supported as return type. The goal of this specification is to promote interoperability between various validator client implementations and remote signing services. Client support | Validator Clients | Status           |\n| ----------------- | ---------------- |\n| Prysm             | Supported v1.0.0 |\n| Teku              | Supported v1.0.0 |\n| Lighthouse        |                  |\n| Nimbus            |                  |\n| Lodestar          | Supported v1.0.0 | | Remote Signing Service | Status           |\n| ---------------------- | ---------------- |\n| Web3Signer             | Supported v1.0.0 | Running API Browser Locally To render the spec in a browser you will need an HTTP server to serve the index.html file.\nRendering occurs client-side in JavaScript, so no changes are required to the HTML file between\nedits. Python python2 -m SimpleHTTPServer 8080 The API spec will render on http://localhost:8080 . NodeJs ```\nnpm install simplehttpserver -g OR yarn global add simplehttpserver simplehttpserver\n``` The API spec will render on http://localhost:8000 . Contributing The API spec is linted for issues before PRs are merged. To run the linter locally, install spectral : ```\nnpm install -g @stoplight/spectral OR yarn global add @stoplight/spectral\n``` and run with spectral lint remote-signing-oapi.yaml Releasing Create and push a tag Make sure info.version in remote-signing-oapi.yaml file is updated before tagging. CD will create github release and upload bundled spec file Add release entrypoint in index.html In SwaggerUIBundle configuration (inside index.html file), add another entry in \"urls\" field (SwaggerUI will load first item as default).\nEntries should be in the following format (replace <tag> with the real tag name from step 1): javascript\n  {url: \"https://github.com/ethereum/remote-signing-api/releases/download/<tag>/remote-signing-oapi.yaml\", name: \"<tag>\"},"}, {"name": "requests-for-proposals", "desc": null, "readme": "Requests for Proposals This is a public repository of Requests for Proposals (RfP) for work and projects in the Ethereum ecosystem. Open RFPs Staking Operator Documentation -- Proposals due July 8, 2022 Data Availability Sampling Networking -- Proposals due July 1, 2022"}, {"name": "research", "desc": null, "readme": "Research This repository is used mainly for code related to specific research questions, mostly written by @vbuterin. It is not meant as a general research repository for academic papers. An exception to this is the papers folder, which contains the LaTeX files for various academic papers. ## Contribute While contributions are welcome, maintaining this repository is not an active priority. The code in this repository is offered as is, without active support. If you find spelling errors or have suggestions or comments, please feel free to open an issue. ## License MIT \u00a9 2015-2023 Vitalik Buterin et al"}, {"name": "retesteth", "desc": "testeth via RPC. Test run, generation by t8ntool protocol", "readme": "retesteth A test generaion tool for the test fillers https://github.com/ethereum/tests/tree/develop/src Using state transition tool t8n More t8n spec docs: https://github.com/ethereum/go-ethereum/tree/master/cmd/evm Execution stats: http://retesteth.ethdevops.io/ Web interface: http://retesteth.ethdevops.io/web/ Supported clients / evm's geth besu nimbus evmone ethereumjs coregeth (etc | etctranslate configs) Docker Instructions Download docker scripts: Dockerfile dretesteth.sh To use the pyspec tf generator instead of retesteth in the docker, rename the dretesteth.sh to dtf.sh . Note: It is best to put these files in their own directory.\n   The reason is that any files in the same directory, including subdirectories, will be added to the docker container, slowing things down. To setup the clients required, edit the args in Dockerfile script.\n   Setup github repo and branch/commit hash to build from. Leaving an empty \"\" field will disable the client build in the Docker ```\n   ARG BESU_SRC=\"https://github.com/hyperledger/besu.git\"\n   ARG PYSPECS_SRC=\"https://github.com/ethereum/execution-spec-tests\"\n   ARG ETEREUMJS_SRC=\"https://github.com/ethereumjs/ethereumjs-monorepo.git\"\n   ARG RETESTETH_SRC=\"https://github.com/ethereum/retesteth.git\"\n   ARG GETH_SRC=\"https://github.com/ethereum/go-ethereum.git\"\n   ARG NIMBUS_SRC=\"https://github.com/status-im/nimbus-eth1.git\"\n   ARG EVMONE_SRC=\"https://github.com/ethereum/evmone.git\" # Leave empty to disable the build, can point to commit hash as well\n   ARG BESU=\"main\"\n   ARG GETH=\"master\"\n   ARG NIMBUS=\"master\"\n   ARG ETHEREUMJS=\"master\"\n   ARG RETESTETH=\"develop\"\n   ARG PYSPECS=\"main\"\n   ARG EVMONE=\"master\"\n   ``` Build docker locally (if building all clients, ~10 gb space required): chmod +x ./dretesteth.sh\n   ./dretesteth.sh build\n   ./dretesteth.sh install Edit dretesteth.sh and setup local path to the test repo so not to type --testpath . Navigate to the testpath folder test. And use retesteth normally ( dr will be linked to dretesteth.sh after dretesteth.sh install command): dr test.json\n   dr testFiller.json --filltests --clients besu|evmone|ethereumjs|nimbus|t8ntool(default)\n   dr testfolder\n   dr -t GeneralStateTest\n   dr -t BlockchainTests\n   dretesteth.sh --help The command will run retesteth and clients from the docker container but using local tests.\n   Useful options (see --help ): --statediff\n   --poststate\n   --vmtraceraw | --vmtrace\n   --singlenet See the usage tutorial Building locally Basic deps g++-11 / g++-9 required Make sure cmake version is higher than VERSION 3.9.3, otherwise install cmake from a different source sh\nsudo apt-cache policy cmake\nsudo apt-get update\nsudo apt-get install git g++ build-essential cmake Retesteth sh\ngit clone https://github.com/ethereum/retesteth.git\ncd retesteth && git checkout develop\nmkdir build && cd build\ncmake ..\nmake -j4 You should see the successful build files generation result after ( cmake .. command): Configuring done\n-- Generating done\n-- Build files have been written Test clients Setup at least one client (default is geth ).\nCompile required clients locally.\nUse Dockerfile as a hint to setup the clients or visit official page for instructions. Retesteth is looking for client's t8n aliases in the PATH, copy or link them in the system: cp /geth/build/bin/evm /bin/evm\ncp /nimbus/tools/t8n/t8n /bin/evm_nimbus\nln -s /besu/ethereum/evmtool/build/install/evmtool/bin/evm /usr/bin/besuevm\nln -s /evmone/build/bin/evmone-t8n /usr/bin/evmone Setup evn vars: ETHEREUMJS_PATH env var is required for ethereumjs client\nPYSPECS_PATH env var to generate .py test fillers (https://github.com/ethereum/execution-spec-tests)\nETHEREUM_TEST_PATH env to setup default path to the test repo (so not to type --testpath) LLLC to compile LLL basic code in the test fillers lllc compiles Lisp Like Language , an old Ethereum smart contract language that is still in use in tests. apt-get install --yes libboost-filesystem-dev libboost-system-dev libboost-program-options-dev libboost-test-dev\ngit clone --depth 1 -b master https://github.com/winsvega/solidity.git /solidity\nmkdir /build && cd /build\ncmake /solidity -DCMAKE_BUILD_TYPE=Release -DLLL=1 && make lllc\ncp /build/lllc/lllc /bin/lllc Optionally clean the cache: rm -rf /build /solidity /var/cache/* /root/.hunter/* Solidity to compile solidity and yul code in the test fillers wget https://github.com/ethereum/solidity/releases/download/v0.8.17/solc-static-linux\ncp solc-static-linux /usr/bin/solc\nchmod +x /usr/bin/solc Installing on MacOS See https://github.com/ethereum/retesteth/blob/develop/circle.yml file as a hint. use cmake .. -DLOCALDEPS=BOOST to disable hunter boost autoinstall to use locally installed version of BOOST (if there are issues with boost) Contact if any question: Telegram: @wdimitry"}, {"name": "rig", "desc": "Robust Incentives Group", "readme": "The Robust Incentives Group is a research team of the Ethereum Foundation. We specialise in incentive analysis for protocols, using methods from game theory, mechanism design, empirical analysis and simulations. Since our foundation, we actively participated in research on EIP-1559 and Proof-of-Stake Ethereum. Find our releases, posts, and papers on this homepage! RIG Open Questions (ROPs) We propose a set of Open Questions we're looking to collaborate on. Find more details on the ROPs homepage ! Projects Proof-of-Stake Research on Ethereum Proof-of-Stake consensus Timing games in Proof-of-Stake Beacon Runner: Proof-of-Stake digital twin Ongoing effort to produce an incentives-focused testing environment for the consensus layer. Beacon Runner homepage Beacon Runner repo Data analysis Consensus layer and validator analytics. Beacon chain data analysis library (in R) Beacon chain April 2021 incident + Script (in R) Exploring the first 1000 epochs Visualising the 7-block reorg on the Ethereum beacon chain Fee markets abm1559: Agent-based modelling of the fee market Simulations and analysis of transaction fee markets, specifically EIP-1559. abm1559 website abm1559 repo Data analysis A dashboard for EIP-1559 ( Dune ) Gas weather report, July 21st-July 27th + source Exploring blocks, gas and transactions + source Financial products for blockspace Structuring Blockspace Derivatives Next-Block Base Fee Options: Towards a Practical Implementation Other publications Congestion control and EIP-1559 Understanding fees in EIP-1559 Better bidding with EIP-1559 Rollups The road to Ethereum: Visualising a rollup-centric future Understanding rollup economics from first principles + Dashboard Proposer-Builder Separation (PBS) Unbundling PBS: Towards protocol-enforced proposer commitments (PEPC) Publications Schwarz-Schilling, C., Neu, J., Monnot, B., Asgaonkar, A., Tas, E. N., & Tse, D. (2021). Three Attacks on Proof-of-Stake Ethereum. arXiv preprint arXiv:2110.10086 . arXiv link Reijsbergen, D., Sridhar, S., Monnot, B., Leonardos, S., Skoulakis, S., & Piliouras, G. (2021). Transaction Fees on a Honeymoon: Ethereum's EIP-1559 One Month Later. arXiv preprint arXiv:2110.04753 . arXiv link Leonardos, S., Monnot, B., Reijsbergen, D., Skoulakis, S., & Piliouras, G. (2021). Dynamical Analysis of the EIP-1559 Ethereum Fee Market. arXiv preprint arXiv:2102.10567 . arXiv link Talks Meet the RIG and check our previous talks! | Talk | Speaker | Location | Date | Link |\n|---|---|---|---|---|\n| Time in Ethereum | Caspar | Devcon 6 | 12 October 2022 | Video + Slides |\n| ELI5 Cryptoeconomics | Julian | Devcon 6 | 11 October 2022 | Video + Slides |\n| Updates on Proposer-Builder Separation | Barnab\u00e9 | Devcon 6 | 11 October 2022 | Video + Slides |\n| Making sense of rollup economics | Barnab\u00e9 | EthCC[5] | 20 July 2022 | Video + Slides |\n| Modelling blockchain protocols: Consensus and fee markets | Barnab\u00e9 | SMGT Erice | 14 May 2022 | Slides |\n| Let me in! Let me IIINNNN! A longitudinal study of the transaction supply chain from CryptoKitties to MEV-Boost to PBS | Barnab\u00e9 | mev.day @ Devconnect | 22 April 2022 | Video + Slides |\n| Notes on Ethereum\u2019s circulating supply equilibrium and the prospect of perpetual deflation via minimum viable issuance under proof of stake | Anders | ETHconomics @ Devconnect | 21 April 2022 | Video + Slides (TBA) |\n| ETHconomics | RIG team | ETHconomics @ Devconnect | 21 April 2022 | Videos + Schedule |\n| Three Attacks on PoS Ethereum | Caspar | Financial Cryptography 2022 | 19 April 2022 | Video + Slides |\n| Proposer-Builder Separation (PBS) | Barnab\u00e9 | Protocol R&D Workshop @ Devconnect | 19 April 2022 | Slides |\n| Robust incentives testing at the Robust Incentives Group | Barnab\u00e9 | Workshop on Incentive Mechanism Validation (WIMV) @ Devconnect | 18 April 2022 | Video + Slides |\n| The road to Ethereum (2022 version) | Barnab\u00e9 | SUTD Guest Lecture | 11 April 2022 | Slides |\n| Protocol Cryptoeconomics | Barnab\u00e9 | NTU Blockchain workshop | 20 December 2021 | Slides |\n| Economics of EIP-1559 | Barnab\u00e9 | Berlin Ethereum Meetup | 4 November 2021 | Slides |\n| The Game of Reorgs in PoS Ethereum | Caspar | LisCon 2021 | 20 October 2021 | Video + Slides |\n| Employing a reinforcement learning-based framework to analyze incentive mechanism attacks on Ethereum blockchain | Shyam | EDCON 2021 | 28 August 2021 | Video |\n| Post-London EIP-1559 Assessment | Barnab\u00e9 | EIP-1559 breakout call #12 | 13 August 2021 | Video |\n| Protocol cryptoeconomics with the RIG | Barnab\u00e9 | EthCC[4] | 20 July 2021 | Video + Slides |\n| Ethereum : Un protocole en mutation | Barnab\u00e9 | EthCC[4] | 20 July 2021 | |\n| PEEPanEIP #37: EIP-1559: Fee market change with Tim Beiko, Barnab\u00e9 Monnot, Micah Zoltu | Barnab\u00e9 | Ethereum Cat Herders | 21 June 2021 | Video + Slides |\n| The road to Ethereum | Barnab\u00e9 | Online (SUTD) | 9 April 2021 | Blog post |\n| En route pour eip1559 | Barnab\u00e9 | Online (Ethereum France, in French) | 10 November 2020 | Video + Slides |\n| Strategic issues in EIP 1559 | Barnab\u00e9 | Online (ETHTaipei) | 15 October 2020 | Video + Slides |\n| Ethereum's new transaction fee market design, EIP 1559 | Barnab\u00e9 | Online (SUTD) | 25 September 2020 | Notes/slides |\n| cadCAD community call #2 | Barnab\u00e9 | Online | 28 August 2020 | Video + Slides |\n| Eth Magicians EIP 1559 panel | Barnab\u00e9 | Online | 29 July 2020 | Video |\n| RIG Bouillabaisse | Barnab\u00e9 | EthCC[3] | 3 March 2020 | Slides |\n| OpenSUTD Blockchain development IAP | Barnab\u00e9 | SUTD | 16 January 2020 | Slides |"}, {"name": "RIPs", "desc": "The Ethereum Rollup Improvement Proposal repository ", "readme": "Rollup Improvement Proposals (RIPs) ATTENTION : The RIPs repository is in the startup phase, and so is undergoing many changes. Both the process and how RIPs will be written and governed is still being worked on. Feedback encouraged on Ethereum Magicians . The goal of the RIP project is to standardize and provide high-quality documentation for Rollups in Ethereum ecosystem. This repository tracks past and ongoing improvements to Ethereum's Rollup ecosystem in the form of Rollup Improvement Proposals (RIPs). All RIPs are optional. RIPs are and will always remain optional standards for Rollups and participants in the larger EVM ecosystem. RIPs and RollCall are not a governance process."}, {"name": "ropsten", "desc": "Ropsten public testnet PoW chain", "readme": "Morden (2015) | Ropsten (2016) | Rinkeby (2017) | Goerli (2019) | Sepolia (2021) Ropsten Testnet Archive of the --ropsten proof-of-work testnet configuration. :warning: Ropsten has been declared EOL as of December 2022 . Please use Goerli or Sepolia moving forward. To learn more about post-merge testnets check out the Ethereum website or this Devcon 6 talk ."}, {"name": "rpc-tests", "desc": null, "readme": "Ethereum RPC tests Untested: eth_sendTransaction eth_compileSolidity eth_getFilterChanges eth_getWork eth_submitWork shh_post shh_newGroup shh_addToGroup shh_getFilterChanges shh_getMessages A note on tests: everything in the pending state or which requires newly created logs or transcations can't be tested, as the fixed blockchain is not mining. Usage clone $ git clone https://github.com/ethereum/rpc-tests $ cd rpc-tests $ git submodule update --init $ npm install start a local CPP node at http://localhost:8080 and local GO node at http://localhost:8545 The nodes need the following state to work: https://github.com/ethereum/tests/blob/develop/BlockchainTests/bcRPC_API_Test.json NOTE If you run the tests make sure you update the lib/tests submodule as well as the tests repository, which you use to load the blockchain state so that both are in the same state. Running the tests To run the tests start the node(s) at the ports described in lib/config.js (See Start a node with a certain state ) and run: $ make test NOTE you need to restart and reload the blocktests in the nodes, so that all pending and mined transactions get cleared from the test chain. Running test only for specific protocols You can also run only tests for eth_ , shh_ or net_ RPC methods as follows: $ make test.eth\n$ make test.shh\n$ make test.net If you don't want to run the tests against all nodes, or run against remote nodes, just change the hosts in the lib/config.js . Running over an IPC connection To test using the IPC connection, your node needs to run on the default IPC path. Then start with the following: $ make test.ipc\n$ make test.eth.ipc\n$ make test.shh.ipc\n$ make test.net.ipc Running single tests To run a single test you need to install mocha globally: ```bash\n$ npm install -g mocha\n$ cd rpc-tests\n$ mocha test/1_testConnection.js test/eth_myMethod.js add --ipc when you want to use the IPC connection $ mocha test/1_testConnection.js test/eth_myMethod.js --ipc\n``` By changing the last file name to whatever method you want to test, you can run test only for that specifc method. Start a node with a certain state To load a fixed state, clone the ethereum test repo as follows: $ git clone https://github.com/ethereum/tests Go Run the following go cli command to load the RPC_API_Test test: $ gethrpctest --json <pathToTheTestRepo>/lib/tests/BlockchainTests/bcRPC_API_Test.json --test RPC_API_Test C++ Run the following c++ cli command to load the RPC_API_Test test: $ ethrpctest --json <pathToTheTestRepo>/lib/tests/BlockchainTests/bcRPC_API_Test.json --test RPC_API_Test Python Run the following python cli command to load the RPC_API_Test test: $ pyethapp -l :info,eth.chainservice:debug,jsonrpc:debug -c jsonrpc.listen_port=8081 -c p2p.max_peers=0 -c p2p.min_peers=0 blocktest <pathToTheTestRepo>/lib/tests/BlockchainTests/bcRPC_API_Test.json RPC_API_Test For also testing/using ipc, use the the following command: $ pyethapp -l :info,eth.chainservice:debug,jsonrpc:debug -c jsonrpc.listen_port=8081 -c p2p.max_peers=0 -c p2p.min_peers=0 -c ipc.ipcpath=$HOME/.ethereum/geth.ipc blocktest <pathToTheTestRepo>/lib/tests/BlockchainTests/bcRPC_API_Test.json RPC_API_Test License The MIT License Copyright (c) 2015 Fabian Vogelsteller Permission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n'Software'), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions: The above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."}, {"name": "scavenger_hunt", "desc": "Scavenger Hunts!", "readme": "scavenger_hunt Scavenger Hunts!"}, {"name": "secure-drop", "desc": "A service to encrypt messages and documents in browser for secure transmission", "readme": "Secure Drop Secure-drop provides a way for users to securely, using browser-side PGP encryption on the client, submit files and/or messages to specified recipients in the Ethereum Foundation via a web form . User flow User writes a message and may select files for a selected recipient. The user's browser encrypts the content using OpenPGP.js with a public key of the recipient, before submitting the encrypted content to the server. The server uses its email delivery service to send the email to the intended recipient. The recipient receives the encrypted message/file, and can then decrypt it using their private PGP key. Dependencies Docker Compose. Third Party Services Sendgrid Google reCAPTCHA New setup Make a fork of the repository. Set environment variables in .env file, using the provided example. Customise the templates and code. Update public keys in static/js/public-keys.js . Deploy to your web server or K8s cluster. Security If the server running the service were to be compromised, this could lead to severe issues such as public keys and email addresses being changed/added so that an attacker can also read the encrypted messages. A server operator should follow best practises for security when setting up and operating the server running the service. Run docker compose up The server will be listening on 4200 port."}, {"name": "serpent", "desc": null, "readme": "Introduction Serpent is an assembly language that compiles to EVM code that is extended with various high-level features. It can be useful for writing code that requires low-level opcode manipulation as well as access to high-level primitives like the ABI. Being a low-level language, Serpent is NOT RECOMMENDED for building applications unless you really really know what you're doing. The creator recommends Solidity as a default choice, LLL if you want close-to-the-metal optimizations, or Viper if you like its features though it is still experimental. Installation: make && sudo make install Testing Testing is done using pytest and tox . bash\n$ pip install tox -r requirements-dev.txt To run the test suite in your current python version: bash\n$ py.test To run the full test suite across all supported python versions: bash\n$ tox"}, {"name": "serpent-go", "desc": "Serpent Go", "readme": "serpent go bindings. Build instructions go get -d github.com/ethereum/serpent-go\ncd $GOPATH/src/github.com/ethereum/serpent-go\ngit submodule init\ngit submodule update You're now ready to go :-)"}, {"name": "sharding", "desc": "Sharding manager contract, and related software and tests", "readme": "Sharding Sharding Implementation Refer Py-EVM for the latest implementation progress. Specification and Documentation See the \"docs\" directory for documentation and EIPs. Ethereum Research Forum Please visit ethresear.ch ."}, {"name": "simplecasper", "desc": "Casper PoC4 implementation", "readme": "Simple Casper Layer-2 Casper daemon for POC4. Setup Requirements Python2.7 automake libffi tmux Getting started Make sure you have installed the requirements, and have created a virtual enviornment.\nNow install the project dependencies: $ pip install -r requirements.txt\n$ python setup.py install Next run the Casper simulator! $ ./tmux.sh You're done!"}, {"name": "snake-charmers-blog", "desc": null, "readme": "How to blog! Adding yourself as an author Add an entry to _data/authors.yaml Include author: your_name in the front-matter for any blog post you author. Posting Author a new file under _posts/ with the naming scheme: <year>-<month>-<day>-<title-as-dash-separated-string>.markdown Use the following header as front-matter ``` layout: post\ntitle:  \"Welcome from Snaky McSnakeFace!\"\ndate:   2018-11-19 09:53:09 -0700\ncategories: update\nauthor: ``` Categories ??? what should our standard categories be Tags ??? what should our standard tags be"}, {"name": "snake-charmers-tactical-manual", "desc": "Development *stuff* for the Snake Charmers EF team", "readme": "Development Tactical Manual This document lays out guidelines and expectations for the Ethereum Foundation\nPython development team. Code Style Guide Testing Git and Github Documentation Operational Security Ideology and Subjectivity Gitcoin Bug Bounty Guide Cutting a Release"}, {"name": "solc-bin", "desc": "This repository contains current and historical builds of the Solidity Compiler.", "readme": "solc-bin This repository contains current and historical builds of the Solidity Compiler . Please refer to the section on Static Binaries in the official documentation for information about the structure of this repository, its content and recommended usage. Deprecation notice for the ethereum.github.io domain The content of this repository is mirrored at https://binaries.soliditylang.org. This is the recommended way to fetch compiler binaries over HTTPS. The binaries are also available at https://ethereum.github.io/solc-bin/ but this page\nstopped being updated just after the release of version 0.7.2, will not receive any new releases\nor nightly builds for any platform and does not serve the new directory structure, including\nnon-emscripten builds. If you are using it, please switch to https://binaries.soliditylang.org, which is a drop-in\nreplacement. This allows us to make changes to the underlying hosting in a transparent way and\nminimize disruption. Unlike the ethereum.github.io domain, which we do not have any control\nover, binaries.soliditylang.org is guaranteed to work and maintain the same URL structure\nin the long-term."}, {"name": "solc-js", "desc": "Javascript bindings for the Solidity compiler", "readme": "solc-js JavaScript bindings for the Solidity compiler . Uses the Emscripten compiled Solidity found in the solc-bin repository . Node.js Usage To use the latest stable version of the Solidity compiler via Node.js you can install it via npm: bash\nnpm install solc Usage on the Command-Line If this package is installed globally ( npm install -g solc ), a command-line tool called solcjs will be available. To see all the supported features, execute: bash\nsolcjs --help To compile a contract that imports other contracts via relative paths: bash\nsolcjs --bin --include-path node_modules/ --base-path . MainContract.sol Use the --base-path and --include-path options to describe the layout of your project. --base-path represents the root of your own source tree while --include-path allows you to\nspecify extra locations containing external code (e.g. libraries installed with a package manager). Note: ensure that all the files you specify on the command line are located inside the base path or\none of the include paths.\nThe compiler refers to files from outside of these directories using absolute paths.\nHaving absolute paths in contract metadata will result in your bytecode being reproducible only\nwhen it's placed in these exact absolute locations. Note: this commandline interface is not compatible with solc provided by the Solidity compiler package and thus cannot be\nused in combination with an Ethereum client via the eth.compile.solidity() RPC method. Please refer to the Solidity compiler documentation for instructions to install solc .\nFurthermore, the commandline interface to solc-js provides fewer features than the binary release. Usage in Projects There are two ways to use solc : Through a high-level API giving a uniform interface to all compiler versions Through a low-level API giving access to all the compiler interfaces, which depend on the version of the compiler High-level API The high-level API consists of a single method, compile , which expects the Compiler Standard Input and Output JSON . It also accepts an optional set of callback functions, which include the import and the smtSolver callbacks.\nStarting 0.6.0 it only accepts an object in place of the callback to supply the callbacks. The import callback function is used to resolve unmet dependencies.\nThis callback receives a path and must synchronously return either an error or the content of the dependency\nas a string.  It cannot be used together with callback-based, asynchronous,\nfilesystem access. A workaround is to collect the names of dependencies, return\nan error, and keep re-running the compiler until all of them are resolved. Example usage without the import callback Example: ```javascript\nvar solc = require('solc'); var input = {\n  language: 'Solidity',\n  sources: {\n    'test.sol': {\n      content: 'contract C { function f() public { } }'\n    }\n  },\n  settings: {\n    outputSelection: {\n      ' ': {\n        ' ': ['*']\n      }\n    }\n  }\n}; var output = JSON.parse(solc.compile(JSON.stringify(input))); // output here contains the JSON output as specified in the documentation\nfor (var contractName in output.contracts['test.sol']) {\n  console.log(\n    contractName +\n      ': ' +\n      output.contracts['test.sol'][contractName].evm.bytecode.object\n  );\n}\n``` Example usage with import callback ```javascript\nvar solc = require('solc'); var input = {\n  language: 'Solidity',\n  sources: {\n    'test.sol': {\n      content: 'import \"lib.sol\"; contract C { function f() public { L.f(); } }'\n    }\n  },\n  settings: {\n    outputSelection: {\n      ' ': {\n        ' ': ['*']\n      }\n    }\n  }\n}; function findImports(path) {\n  if (path === 'lib.sol')\n    return {\n      contents:\n        'library L { function f() internal returns (uint) { return 7; } }'\n    };\n  else return { error: 'File not found' };\n} // New syntax (supported from 0.5.12, mandatory from 0.6.0)\nvar output = JSON.parse(\n  solc.compile(JSON.stringify(input), { import: findImports })\n); // output here contains the JSON output as specified in the documentation\nfor (var contractName in output.contracts['test.sol']) {\n  console.log(\n    contractName +\n      ': ' +\n      output.contracts['test.sol'][contractName].evm.bytecode.object\n  );\n}\n``` Since version 0.5.1, the smtSolver callback function is used to solve SMT queries generated by\nSolidity's SMTChecker.  If you have an SMT solver installed locally, it can\nbe used to solve the given queries, where the callback must synchronously\nreturn either an error or the result from the solver.  A default smtSolver callback is included in this package via the module smtchecker.js which exports the smtCallback function that takes 1) a\nfunction that takes queries and returns the solving result, and 2) a solver\nconfiguration object. The module smtsolver.js has a few predefined solver\nconfigurations, and relies on Z3, Eldarica or CVC4 being installed locally.  It\nexports the list of locally found solvers and a function that invokes a given\nsolver. The API of the SMT callback is experimental and can change at any time.\nThe last change was in version 0.8.11. Example usage with smtSolver callback ```javascript\nvar solc = require('solc');\nconst smtchecker = require('solc/smtchecker');\nconst smtsolver = require('solc/smtsolver');\n// Note that this example only works via node and not in the browser. var input = {\n  language: 'Solidity',\n  sources: {\n    'test.sol': {\n      content: 'contract C { function f(uint x) public { assert(x > 0); } }'\n    }\n  },\n  settings: {\n    modelChecker: {\n      engine: \"chc\",\n      solvers: [ \"smtlib2\" ]\n    }\n  }\n}; var output = JSON.parse(\n  solc.compile(\n    JSON.stringify(input),\n    { smtSolver: smtchecker.smtCallback(smtsolver.smtSolver, smtsolver.availableSolvers[0]) }\n  )\n); `\nThe assertion is clearly false, and an assertion failure`` warning\nshould be returned, together with a counterexample. Low-level API The low-level API is as follows: solc.lowlevel.compileSingle : the original entry point, supports only a single file solc.lowlevel.compileMulti : this supports multiple files, introduced in 0.1.6 solc.lowlevel.compileCallback : this supports callbacks, introduced in 0.2.1 solc.lowlevel.compileStandard : this works just like compile above, but is only present in compilers after (and including) 0.4.11 For examples how to use them, please refer to the README of the above mentioned solc-js releases. Note : These low-level functions remain available for compatibility reasons.\nHowever, they were superseded by the compile() function and are no longer required.\nStarting from version 0.5.0+commit.1d4f565a , the functions compileSingle , compileMulti , and compileCallback are always null when using newer solc binary versions.\nIt is recommended to use the latest release of solc-js, but it should also handle all the older solc binaries down to 0.1.x . Using with Electron Note: If you are using Electron, nodeIntegration is on for BrowserWindow by default. If it is on, Electron will provide a require method which will not behave as expected and this may cause calls, such as require('solc') , to fail. To turn off nodeIntegration , use the following: javascript\nnew BrowserWindow({\n  webPreferences: {\n    nodeIntegration: false\n  }\n}); Using a Legacy Version In order to compile contracts using a specific version of Solidity, the solc.loadRemoteVersion(version, callback) method is available. This returns a new solc object that uses a version of the compiler specified. You can also load the \"binary\" manually and use setupMethods to create the familiar wrapper functions described above: var solc = solc.setupMethods(require(\"/my/local/soljson.js\")) . Using the Latest Development Snapshot By default, the npm version is only created for releases. This prevents people from deploying contracts with non-release versions because they are less stable and harder to verify. If you would like to use the latest development snapshot (at your own risk!), you may use the following example code. ```javascript\nvar solc = require('solc'); // getting the development snapshot\nsolc.loadRemoteVersion('latest', function(err, solcSnapshot) {\n  if (err) {\n    // An error was encountered, display and quit\n  } else {\n    // NOTE: Use solcSnapshot here with the same interface solc has\n    // For example:\n    const output = solcSnapshot.compile(/ ... /)\n  }\n});\n``` The version must be in the long format.\nThus, if you would like to use version v0.8.17 you need to include the commit hash of the release.\nYou can extract the long version string for each version from the publicly available release list . javascript\nsolc.loadRemoteVersion('v0.8.17+commit.8df45f5f', function(err, solcSnapshot) { /* ... */ }); Linking Bytecode When using libraries, the resulting bytecode will contain placeholders for the real addresses of the referenced libraries. These have to be updated, via a process called linking, before deploying the contract. The linker module ( require('solc/linker') ) offers helpers to accomplish this. The linkBytecode method provides a simple helper for linking: ```javascript\nvar linker = require('solc/linker'); bytecode = linker.linkBytecode(bytecode, { MyLibrary: '0x123456...' });\n``` As of Solidity 0.4.11 the compiler supports standard JSON input and output which outputs a link references map. This gives a map of library names to offsets in the bytecode to replace the addresses at. It also doesn't have the limitation on library file and contract name lengths. There is a method available in the linker module called findLinkReferences which can find such link references in bytecode produced by an older compiler: ```javascript\nvar linker = require('solc/linker'); var linkReferences = linker.findLinkReferences(bytecode);\n``` Updating the ABI The ABI generated by Solidity versions can differ slightly, due to new features introduced. There is a tool included which aims to translate the ABI generated by an older Solidity version to conform to the latest standard. It can be used as: ```javascript\nvar abi = require('solc/abi'); var inputABI = [\n  {\n    constant: false,\n    inputs: [],\n    name: 'hello',\n    outputs: [{ name: '', type: 'string' }],\n    payable: false,\n    type: 'function'\n  }\n];\nvar outputABI = abi.update('0.3.6', inputABI);\n// Output contains: [{\"constant\":false,\"inputs\":[],\"name\":\"hello\",\"outputs\":[{\"name\":\"\",\"type\":\"string\"}],\"payable\":true,\"type\":\"function\"},{\"type\":\"fallback\",\"payable\":true}]\n``` Formatting old JSON assembly output There is a helper available to format old JSON assembly output into a text familiar to earlier users of Remix IDE. ```\nvar translate = require('solc/translate') // assemblyJSON refers to the JSON of the given assembly and sourceCode is the source of which the assembly was generated from\nvar output = translate.prettyPrintLegacyAssemblyJSON(assemblyJSON, sourceCode)\n``` Browser Usage Compilation is generally a long-running and resource intensive task that cannot reasonably be performed in the main thread of the browser.\nSome browsers even dissallow synchronous compilation on the main thread if the module is larger than 4KB.\nThus, the only supported way to use solc in a web browser is through a web worker . Loading solc with web workers Web Workers allow you to run javascript in the background in the browser, letting the browser's main thread free to do whatever it needs to do.\nPlease, see the minimal example of how to use solc with web workers below or check out this repository for a full demo. index.html\n```html ``` worker.js:\n```javascript\nimportScripts('https://binaries.soliditylang.org/bin/soljson-v0.8.19+commit.7dd6d404.js')\nimport wrapper from 'solc/wrapper'; self.addEventListener('message', () => {\n    const compiler = wrapper(self.Module)\n    self.postMessage({\n        version: compiler.version()\n    })\n}, false)\n```"}, {"name": "solidity", "desc": "Solidity, the Smart Contract Programming Language", "readme": "The Solidity Contract-Oriented Programming Language You can talk to us on Gitter and Matrix, tweet at us on X (previously Twitter) or create a new topic in the Solidity forum. Questions, feedback, and suggestions are welcome! Solidity is a statically typed, contract-oriented, high-level language for implementing smart contracts on the Ethereum platform. For a good overview and starting point, please check out the official Solidity Language Portal . Table of Contents Background Build and Install Example Documentation Development Maintainers License Security Background Solidity is a statically-typed curly-braces programming language designed for developing smart contracts\nthat run on the Ethereum Virtual Machine. Smart contracts are programs that are executed inside a peer-to-peer\nnetwork where nobody has special authority over the execution, and thus they allow anyone to implement tokens of value,\nownership, voting, and other kinds of logic. When deploying contracts, you should use the latest released version of\nSolidity. This is because breaking changes, as well as new features and bug fixes, are\nintroduced regularly. We currently use a 0.x version\nnumber to indicate this fast pace of change . Build and Install Instructions about how to build and install the Solidity compiler can be\nfound in the Solidity documentation . Example A \"Hello World\" program in Solidity is of even less use than in other languages, but still: ```solidity\n// SPDX-License-Identifier: MIT\npragma solidity >=0.6.0 <0.9.0; contract HelloWorld {\n    function helloWorld() external pure returns (string memory) {\n        return \"Hello, World!\";\n    }\n}\n``` To get started with Solidity, you can use Remix , which is a\nbrowser-based IDE. Here are some example contracts: Voting Blind Auction Safe remote purchase Micropayment Channel Documentation The Solidity documentation is hosted using Read the Docs . Development Solidity is still under development. Contributions are always welcome!\nPlease follow the Developers Guide if you want to help. You can find our current feature and bug priorities for forthcoming\nreleases in the projects section . Maintainers The Solidity programming language and compiler are open-source community projects governed by a core team.\nThe core team is sponsored by the Ethereum Foundation . License Solidity is licensed under GNU General Public License v3.0 . Some third-party code has its own licensing terms . Security The security policy may be found here ."}, {"name": "solidity-blog", "desc": "Collection of articles about the Solidity language and compiler", "readme": "\ud83d\udea8 This repository has been archived. Please visit the new home for the Solidity website and blog codebase at ethereum/solidity-website Solidity Blog The blog can reached at blog.soliditylang.org . These are the sources for the Solidity blog. Read this for editing instructions ."}, {"name": "solidity-buildpack-deps", "desc": "Source files for docker images used to build the Solidity compiler.", "readme": null}, {"name": "solidity-examples", "desc": "Loose collection of Solidity example code", "readme": "Standard library (draft) Temporary storage for a standard library of Solidity contracts. The code in this library will only run in metropolis compliant networks, and it will only compile using Solidity version 0.5.0 and later. TOC Purpose Packages bits bytes math patricia_tree strings token unsafe Quality Assurance Commandline tool Q&A Purpose The standard library should provide Solidity libraries / functions for performing common tasks, such as working with strings, bits, and other common types, and for working with Ethereum and Ethereum related technologies, like for example Patricia Tries. Packages These are the different packages. bits The bits package is used to work with bitfields (uints). contracts Bits bytes The bytes package is used to work with bytes in memory, and to convert between bytes and other types. contracts Bytes math The math package is used to do math with signed and unsigned integers. contracts ExactMath patricia_tree The patricia_tree package is used to work with the standard Solidity Patricia tree implementation by @chriseth. contracts PatriciaTree Data strings The strings package is used to work Solidity string s. It only supports UTF-8 validation. contracts Strings tokens The tokens package is used to work with Token contracts. contracts ERC20TokenFace unsafe The unsafe package is used to do unsafe operations, like working with memory directly. contracts Memory Quality Assurance The standard library has well-documented routines for making sure that code meets the required standards when it comes to: Security Performance Style Documentation Additionally, the tools used to guarantee this should be simple and easy to replace when new and better alternatives are made available. Testing npm test - runs the contract test-suite, as well as the tests for the typescript code. npm run ts-test - runs the typescript tests. npm run contracts-test - runs the contract test-suite. The contract tests requires solc and evm ( go ethereum ) to be installed and added to the $PATH. Test code is written in Solidity, and is executed directly in the evm. For more information about the tests, such as the test file format, read the full test documentation . For running tests with the command-line tool, check the CLI documentation . Performance npm run contracts-perf will run the entire perf suite. For more information about perf read the full perf documentation . For running perf with the command-line tool, check the CLI documentation . Style npm run ts-lint - will run TS-lint on the entire library. npm run contracts-lint - will run solhint on all contracts. The standard library should serve as an (or perhaps the ) example of strict, idiomatic Solidity. This means all code should follow the style guide and the practices and patterns laid out at https://solidity.readthedocs.org. Documentation Briefly: the documentation should specify - in a very clear and concise a way - what the contract of the library/function is, the interfaces / function signatures should reflect that, and the functions should (obviously) behave as described. Manual review Code should be reviewed by at least one person other then the writer. There should also be review of tests, perf, docs, and code examples as well. This should be done using the PR system in github. Issues and feedback Github issues and gitter solidity channel. Ranking / categorization of contracts The QA only really applies to code that is meant to be used in production, but the library will also include code that has not reached that level. Node.js has a system of categorizing libraries, experimental, stable, deprecated, and so forth. This library should have something similar. Commandline tool The library has a commandline tool which can be used to run tests, view documentation, and other things. The full docs can be found in the commandline tool documentation ."}, {"name": "solidity-fuzzing-corpus", "desc": null, "readme": null}, {"name": "solidity-portal", "desc": "The Solidity Language Portal is a high-level information page for Solidity, aiming to present consolidated news and making visitors aware of and leading them to relevant other websites.", "readme": "\ud83d\udea8 This repository has been archived. Please visit the new home for the Solidity website codebase at ethereum/solidity-website Solidity Language Portal The Solidity Language Portal is based on the Hydra template for Jekyll. Develop Hydra was built with Jekyll version 3.3.1, but should support newer versions as well. Install the dependencies with Bundler : ~~~bash\n$ bundle install\n~~~ Run jekyll commands through Bundler to ensure you're using the right versions: ~~~bash\n$ bundle exec jekyll serve\n~~~"}, {"name": "solidity-summit", "desc": "Website of the Solidity Summit conference series", "readme": "Solidity Summit 2022 Website Credits for Template: Photon by HTML5 UP\nhtml5up.net | @ajlkn\nFree for personal and commercial use under the CCA 3.0 license (html5up.net/license)"}, {"name": "solidity-test-bytecode", "desc": "Test repository for cross-platform comparison of the Solidity compiler", "readme": null}, {"name": "solidity-underhanded-contest", "desc": "Website for the Underhanded Solidity Contest", "readme": "solidity-underhanded-contest Website and resources for the Underhanded Solidity Contest."}, {"name": "solidity-website", "desc": null, "readme": "Solidity Lang Website Welcome to the codebase for the Solidity Lang website! Homepage: https://soliditylang.org Note: This is the codebase for the Solidity website only. For the Solidity Lang codebase please see ethereum/solidity . Soliditylang.org website stack Node.js Yarn package manager React - A JavaScript library for building component-based user interfaces Typescript - TypeScript is a strongly typed programming language that builds on JavaScript Chakra UI - A UI library GitHub Actions - Manages CI/CD, and issue tracking Local environment setup Ensure you're using the correct version of Node.js: bash\nnvm use Or see .nvmrc for correct version. Install dependencies: bash\nyarn Run the development server: bash\nyarn dev Open http://localhost:3000 in your browser to view the site. API keys (optional) This site uses a read-only API key to fetch the latest version of the Solidity compiler, and the GitHub star count for the ethereum/solidity repo from the GitHub API. To enable this functionality locally, first create your .env file: bash\ncp .env.example .env Go to GitHub Personal Access Tokens and generate a \"fine-grained\" personal access token, with \"Public Repositories (read-only)\" selected and nothing else. Copy the token and paste it into your .env file for GITHUB_TOKEN_READ_ONLY . Code structure | Folder                   | Primary use                                                                                     |\n| ------------------------ | ----------------------------------------------------------------------------------------------- |\n| /src | Main source folder for development                                                              |\n| /src/components | React components that do not function as standalone pages                                       |\n| /src/events | Markdown files for events |\n| /src/hooks | Custom React hooks                                                                              |\n| /src/pages | React components that function as standalone pages and will create URL paths                    |\n| /src/posts | Markdown files for blog posts |\n| /src/styles | Custom style declarations                                                                       |\n| /src/theme | Declares site color themes, breakpoints and other constants (try to utilize these colors first) |\n| /src/theme/foundations | Theme foundations imported by theme config at /src/theme |\n| /src/utils | Custom utility scripts                                                                          |\n| /src/constants.ts | Declares all constants that are used throughout the site.                                       |\n| /src/interfaces.ts | Declared interfaces and types for to be used throughout the site                                |\n| /public | Storage for assets that will be available at URL path after build                               |\n| /public/assets | General image assets                                                                            |\n| /public/img | Image assets used in blog posts                                                                 | Events Front matter from markdown files contained within /src/events is used to populate event cards, using the following interface: ```ts\ninterface EventFrontmatter {\n  title: string\n  location: string\n  startDate: string\n  endDate: string\n  imageSrc?: string\n  previewLinks?: Link[]\n  ctaLinks?: Link[]\n  youtube?: string\n  coordsOverride?: [Lat, Long]\n  mapLabel?: string\n} // where...\ninterface Link {\n  label: string\n  href: string\n}\ntype Lat = number\ntype Long = number\n``` (See src/interfaces.ts for canonical EventFrontmatter interface.) The date properties startDate and endDate are used to display recent events and next upcoming events on the homepage. Optional front matter properties for events imageSrc is the relative path to the image asset to be used as the hero banner. previewLinks are used to display button links on the event preview cards shown on the homepage. It accepts a list of Link objects, each with a label and href . ctaLinks are call-to-action button links displayed in the hero and bottom of an event page . The first one listed will be styled as a primary solid button; any additional will be styled as a secondary outline button. It accepts a list of Link objects, each with a label and href . youtube accepts a YouTube video link or video ID, and embeds it below the hero of the event page. It accepts any of the following formats: Standard format: https://youtube.com/watch?v=1234567890 Embed format: https://www.youtube.com/embed/1234567890 Shortened format: https://youtu.be/1234567890 Just the video ID: 1234567890 coordsOverride can be used to provide a latitude and longitude to override the map location being rendered. See below for more info. mapLabel can be provided to customize the <h2> label shown before an embedded map. Location and embedded map The location property is used to display a map on the event page, fetched from OpenStreetMap . If the resulting location is inaccurate or not precise enough, coordsOverride can optionally be provided to override this result. If no results are found, the map will not be displayed. For virtual/remote events, use location: Remote , and the map will not be displayed. Note: Package leaflet-geosearch is being used for geocoding. Using older version 3.6.1 intentionally to avoid the addition of an unnecessary Google dependency added in later versions. Event example ```md title: Solidity Summit 2023\nlocation: Istanbul, Turkey\nstartDate: 2023-11-16\nendDate: 2023-11-16\nimageSrc: /assets/solidity_summit_2023.png\nctaLinks:\n  - label: Speak\n    href: https://link.to.speaker.application\n  - label: Attend\n    href: https://link.to.attendee.application\npreviewLinks:\n  - label: Join us\n    href: /event/solidity-summit-2023/ Intro text First header as h2 ...\n``` Event example using coordsOverride ```md title: Solidity Summit 2023\nlocation: Istanbul, Turkey\nstartDate: 2023-11-16\nendDate: 2023-11-16\nimageSrc: /assets/solidity_summit_2023.png\nctaLinks:\n  - label: Speak\n    href: https://link.to.speaker.application\n  - label: Attend\n    href: https://link.to.attendee.application\npreviewLinks:\n  - label: Join us\n    href: /event/solidity-summit-2023/\ncoordsOverride:\n  - 41.0082\n  - 28.9784 Intro text First header as h2 ...\n``` Note that coordsOverride is a tuple of two numbers, representing latitude and longitude, respectively. Positive numbers represent north and east, while negative represent south and west. Blog entries Blog posts should be markdown files, stored in the /src/posts folder Filename must take the pattern of YYYY-MM-DD-chosen-post-title.md Front matter should take the shape of the following interface: ts\n  interface BlogPostFrontmatter {\n    layout?: string\n    title: string\n    date: string\n    author: string\n    category: Category\n  } (See src/interfaces.ts for canonical BlogPostFrontmatter interface.) Category must take one of the following values: Releases Security Alerts Announcements Explainers (See src/constants.ts and src/interfaces.ts for canonical Category enum.) title property will be displayed automatically as an <h1> ( # in markdown), and should not be included in the markdown body\u2014start document header levels from <h2> ( ## ) date property should be in YYYY-MM-DD format MDX/JSX is not currently supported Images can be placed in a corresponding folder within /public/img and references using ![alt text](/img/chosen-folder/image-name.png) Blog post example ```md title: 'Solidity 0.8.20 Release Announcement'\ndate: '2023-05-10'\nauthor: Solidity Team\ncategory: Releases Intro text First header as h2 ...\n``` Adding internal links When linking to content internal to this repo, relative paths should be used instead of absolute paths. This ensures proper routing with Next.js, and avoids unintentional page refreshes. This includes links to blog posts, which now live under https://soliditylang.org/blog/ and should be referenced using /blog/YYYY/MM-DD/post-name/ , without https://soliditylang.org . This does NOT include links to the docs, which are located at a different subdomain of https://docs.soliditylang.org. These should be referenced using their full URL, including https://docs.soliditylang.org . Learn more about the stack Next.js Documentation - learn about Next.js features and API. Learn Next.js - an interactive Next.js tutorial. Chakra UI Documentation - learn about Chakra UI features and API."}, {"name": "solidity.js", "desc": null, "readme": null}, {"name": "sourcify", "desc": "Decentralized Solidity contract source code verification service", "readme": "Sourcify ( sourcify.dev ) is a Solidity source code verification service for Ethereum smart contracts. Different than other verification services, Sourcify leverages the Solidity metadata file to \"fully verify\" the contracts. Sourcify mainly consists of: sourcify-server - an HTTP server to do verifications and store the verified contracts for supported chains through an API sourcify-ui - a web UI to interact with the server, lookup, and verify contracts sourcify-monitor - a standalone service that listens to various EVM chains for new contract creations and automatically submits them to a Sourcify API for verification. Packages: @ethereum-sourcify/lib-sourcify : The core library for Sourcify. It contains the logic to verify contracts. @ethereum-sourcify/bytecode-utils : A library to extract and parse the CBOR encoded metadata from the bytecode. @ethereum-sourcify/contract-call-decoder : A library to decode the contract calls from the transaction data and show human-readable information using NatSpec comments (currently stale). The project aims to serve as a public good infrastructure with fully open-source development and an open and accessible contract repository of verified contracts. Anyone can easily run their own Sourcify server and monitor to verify contracts on their own. We also aim to provide tooling to verify contracts easier on different platforms e.g. browers. \u2139\ufe0f This monorepo the main modules. The sourcifyeth Github organization contains all other auxiliary services and components. Documentation For more details refer to docs.sourcify.dev Questions? \ud83d\udd0d Check out docs F.A.Q. and use search in docs. \ud83d\udcac Chat with us on Matrix chat or Discord \ud83d\udc26 Follow us and help us spread the word on Twitter . Adding a new chain If you'd like to add a new chain support to Sourcify please follow the chain support instructions in docs."}, {"name": "ssv", "desc": "The repository has moved to https://github.com/bloxapp/ssv", "readme": "Migration notice The repository has migrated to https://github.com/bloxapp/ssv SSV - Secret Shared Validator SSV is a protocol for distributing an eth2 validator key between multiple operators governed by a consensus protocol ( Istanbul BFT ). Getting started An SSV operator's getting started documentation Common commands ```bash Build binary $ CGO_ENABLED=1 go build -o ./bin/ssvnode ./cmd/ssvnode/ Run local 4 node network (requires docker and a .env file as shown below) $ make docker-debug Lint $ make lint-prepare $ make lint Full test $ make full-test ``` Splitting a key We split an eth2 BLS validator key into shares via Shamir-Secret-Sharing(SSS) to be used between the SSV nodes. \n```bash Extract Private keys from mnemonic (optional, skip if you have the public/private keys ) $ ./bin/ssvnode export-keys --mnemonic={mnemonic} --index={keyIndex} Generate threshold keys $ ./bin/ssvnode create-threshold --count {# of ssv nodes} --private-key {privateKey}\n``` Example .env file NETWORK=pyrmont\n   DISCOVERY_TYPE=<mdns for local network, empty for discov5 remote>\n   STORAGE_PATH=<example ./data/db/node_1/2/3/4>\n   BOOT_NODE_EXTERNAL_IP=\n   BOOT_NODE_PRIVATE_KEY=\n   BEACON_NODE_ADDR= <can use eth2-4000-prysm-ext.stage.bloxinfra.com:80>\n   NODE_ID=\n   VALIDATOR_PUBLIC_KEY=\n   SSV_PRIVATE_KEY=\n   PUBKEY_NODE_1=\n   PUBKEY_NODE_2=\n   PUBKEY_NODE_3=\n   PUBKEY_NODE_4= For a 4 node SSV network, 4 .env.node.<1/2/3/4> files need to be created. Progress [X] Free standing, reference iBFT Go implementation\\\n[X] SSV specific iBFT implementor\\\n[X] Port POC code to Glang\\\n[ ] Single standing instance running with Prysm's validator client\\\n[X] Networking and discovery\\\n[X] db, persistance and recovery\\\n[ ] Between instance persistence (pevent starting a new instance if previous not decided)\\\n[ ] Multi network support (being part of multiple SSV groups)\\\n[ ] Aggregation and Proposal support\\\n[X] Key sharing\\\n[X] Deployment\\\n[\\] Documentation\\\n[X] Phase 1 testing\\\n[ ] Audit ** X=done, \\=WIP Research (Deprecated) Secret Shared Validators on Eth2 Litepaper iBTF Paper EIP650 Liveness issues - should have been addressed in the paper Consensys short description POC SSV Python node iBFT Python Prysm adapted validator client Other implementations Consensys Quorum Besu Hyperledger code DKG Blox's eth2 pools research ETH DKG"}, {"name": "stake-voice", "desc": "Give Ethereum Stakers a voice", "readme": "Stake Voice Give Ethereum Stakers a voice Open this app on Mist : ethereum.github.io/stake-voice/"}, {"name": "staking-deposit-cli", "desc": "Secure key generation for deposits", "readme": "staking-deposit-cli Introduction Tutorial for users Build requirements For Linux or MacOS users File Permissions Option 1. Download binary executable file Step 1. Installation Step 2. Create keys and deposit_data-*.json language Argument --non_interactive flag Commands new-mnemonic Arguments existing-mnemonic Arguments Successful message generate-bls-to-execution-change Arguments Option 2. Build deposit-cli with native Python Step 0. Python version checking Step 1. Installation Step 2. Create keys and deposit_data-*.json Language Argument Commands Arguments Successful message Option 3. Build deposit-cli with virtualenv Step 0. Python version checking Step 1. Installation Step 2. Create keys and deposit_data-*.json Language Argument Commands Arguments Option 4. Use Docker image Step 1. Build the docker image Step 2. Create keys and deposit_data-*.json Arguments Successful message For Windows users Option 1. Download binary executable file Step 1. Installation Step 2. Create keys and deposit_data-*.json Language Argument Commands Arguments Option 2. Build deposit-cli with native Python Step 0. Python version checking Step 1. Installation Step 2. Create keys and deposit_data-*.json Language Argument Commands Arguments Option 3. Build deposit-cli with virtualenv Step 0. Python version checking Step 1. Installation Step 2. Create keys and deposit_data-*.json Language Argument Commands Arguments Development Install basic requirements Install testing requirements Run tests Building Binaries Mac M1 Binaries Introduction deposit-cli is a tool for creating EIP-2335 format BLS12-381 keystores and a corresponding deposit_data*.json file for Ethereum Staking Launchpad . Warning: Please generate your keystores on your own safe, completely offline device. Warning: Please backup your mnemonic, keystores, and password securely. Please read Launchpad Validator FAQs before generating the keys. You can find the audit report by Trail of Bits here . Tutorial for users Build requirements Python 3.8+ pip3 For Linux or MacOS users File Permissions On Unix-based systems, keystores and the deposit_data*.json have 440 / -r--r----- file permissions (user & group read only). This improves security by limiting which users and processes that have access to these files. If you are getting permission denied errors when handling your keystores, consider changing which user/group owns the file (with chown ) or, if need be, change the file permissions with chmod . Option 1. Download binary executable file Step 1. Installation See releases page to download and decompress the corresponding binary files. Step 2. Create keys and deposit_data-*.json Run the following command to enter the interactive CLI and generate keys from a new mnemonic: sh\n./deposit new-mnemonic or run the following command to enter the interactive CLI and generate keys from an existing: sh\n./deposit existing-mnemonic language Argument The Launchpad offers many language/internationalization options. If you wish to select one as a CLI argument, it must be passed in before one of the commands is chosen. | Argument | Type | Description |\n| -------- | -------- | -------- |\n| --language | String. Options: \u0627\u0644\u0639\u0631\u0628\u064a\u0629 , \u03b5\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac , English , Fran\u00e7ais , Bahasa melayu , Italiano , \u65e5\u672c\u8a9e , \ud55c\uad6d\uc5b4 , Portugu\u00eas do Brasil , rom\u00e2n , \u7b80\u4f53\u4e2d\u6587 . Default to English | The language you wish to use the CLI in. | --non_interactive flag Warning: with this flag, there will be no confirmation step(s) to verify the input value(s). Please use it carefully. | Argument | Type | Description |\n| -------- | -------- | -------- |\n| --non_interactive | Flag | Run CLI in non-interactive mode. | Commands The CLI offers different commands depending on what you want to do with the tool. | Command | Description |\n| ------- | ----------- |\n| new-mnemonic | (Recommended) This command is used to generate keystores with a new mnemonic. |\n| existing-mnemonic | This command is used to re-generate or derive new keys from your existing mnemonic. Use this command, if (i) you have already generated keys with this CLI before, (ii) you want to reuse your mnemonic that you know is secure that you generated elsewhere (reusing your eth1 mnemonic .etc), or (iii) you lost your keystores and need to recover your keys. | new-mnemonic Arguments You can use new-mnemonic --help to see all arguments. Note that if there are missing arguments that the CLI needs, it will ask you for them. | Argument | Type | Description |\n| -------- | -------- | -------- |\n| --num_validators | Non-negative integer | The number of signing keys you want to generate. Note that the child key(s) are generated via the same master key. |\n| --mnemonic_language | String. Options: \u7b80\u4f53\u4e2d\u6587 , \u7e41\u9ad4\u4e2d\u6587 , \u010desk\u00fd jazyk , English , Italiano , \ud55c\uad6d\uc5b4 , Portugu\u00eas , Espa\u00f1ol . Default to English | The language of the mnemonic word list |\n| --folder | String. Pointing to ./validator_keys by default | The folder path for the keystore(s) and deposit(s) |\n| --chain | String. mainnet by default | The chain setting for the signing domain. |\n| --execution_address (or --eth1_withdrawal_address ) | String. Eth1 address in hexadecimal encoded form | If this field is set and valid, the given Eth1 address will be used to create the withdrawal credentials. Otherwise, it will generate withdrawal credentials with the mnemonic-derived withdrawal public key in ERC-2334 format . | existing-mnemonic Arguments You can use existing-mnemonic --help to see all arguments. Note that if there are missing arguments that the CLI needs, it will ask you for them. | Argument | Type | Description |\n| -------- | -------- | -------- |\n| --validator_start_index | Non-negative integer | The index of the first validator's keys you wish to generate. If this is your first time generating keys with this mnemonic, use 0. If you have generated keys using this mnemonic before, use the next index from which you want to start generating keys from (eg, if you've generated 4 keys before (keys #0, #1, #2, #3), then enter 4 here.|\n| --num_validators | Non-negative integer | The number of new signing keys you want to generate. Note that the child key(s) are generated via the same master key. |\n| --folder | String. Pointing to ./validator_keys by default | The folder path for the keystore(s) and deposit(s) |\n| --chain | String. mainnet by default | The chain setting for the signing domain. |\n| --execution_address (or --eth1_withdrawal_address ) | String. Eth1 address in hexadecimal encoded form | If this field is set and valid, the given Eth1 address will be used to create the withdrawal credentials. Otherwise, it will generate withdrawal credentials with the mnemonic-derived withdrawal public key in ERC-2334 format . | Successful message You will see the following messages after successfully generated the keystore(s) and the deposit(s): ```text\nCreating your keys:               [####################################] / Creating your keystores:          [####################################] / Creating your depositdata:        [####################################] / Verifying your keystores:         [####################################] / Verifying your deposits:          [####################################] / Success!\nYour keys can be found at: ``` generate-bls-to-execution-change Arguments You can use bls-to-execution-change --help to see all arguments. Note that if there are missing arguments that the CLI needs, it will ask you for them. | Argument | Type | Description |\n| -------- | -------- | -------- |\n| --bls_to_execution_changes_folder | String. Pointing to ./bls_to_execution_changes by default | The folder path for the bls_to_execution_change-* JSON file(s) |\n| --chain | String. mainnet by default | The chain setting for the signing domain. |\n| --mnemonic | String. mnemonic split by space.  | The mnemonic you used to create withdrawal credentials. |\n| --mnemonic_password | Optional string. Empty by default. | The mnemonic password you used in your key generation. Note: It's not the keystore password. |\n| --validator_start_index | Non-negative integer | The index position for the keys to start generating withdrawal credentials in ERC-2334 format . |\n| --validator_indices | String of integer(s) | A list of the chosen validator index number(s) as identified on the beacon chain. Split multiple items with whitespaces or commas. |\n| --bls_withdrawal_credentials_list | String of hexstring(s). | A list of the old BLS withdrawal credentials of the given validator(s). It is for confirming you are using the correct keys. Split multiple items with whitespaces or commas. |\n| --execution_address (or --eth1_withdrawal_address ) | String. Eth1 address in hexadecimal encoded form | If this field is set and valid, the given Eth1 address will be used to create the withdrawal credentials. Otherwise, it will generate withdrawal credentials with the mnemonic-derived withdrawal public key in ERC-2334 format . |\n| --devnet_chain_setting | String. JSON string '{\"network_name\": \"<NETWORK_NAME>\", \"genesis_fork_version\": \"<GENESIS_FORK_VERSION>\", \"genesis_validator_root\": \"<GENESIS_VALIDATOR_ROOT>\"}' | The custom chain setting of a devnet or testnet. Note that it will override your --chain choice. | Option 2. Build deposit-cli with native Python Step 0. Python version checking Ensure you are using Python version >= Python3.8: sh\npython3 -V Step 1. Installation Install the dependencies: sh\npip3 install -r requirements.txt\npython3 setup.py install Or use the helper script: sh\n./deposit.sh install Step 2. Create keys and deposit_data-*.json Run one of the following command to enter the interactive CLI: sh\n./deposit.sh new-mnemonic or sh\n./deposit.sh existing-mnemonic You can also run the tool with optional arguments: sh\n./deposit.sh new-mnemonic --num_validators=<NUM_VALIDATORS> --mnemonic_language=english --chain=<CHAIN_NAME> --folder=<YOUR_FOLDER_PATH> sh\n./deposit.sh existing-mnemonic --num_validators=<NUM_VALIDATORS> --validator_start_index=<START_INDEX> --chain=<CHAIN_NAME> --folder=<YOUR_FOLDER_PATH> Language Argument See here for --language arguments. Commands See here Arguments See here for new-mnemonic arguments\nSee here for existing-mnemonic arguments\nSee here for generate-bls-to-execution-change arguments Successful message See here Option 3. Build deposit-cli with virtualenv Step 0. Python version checking Ensure you are using Python version >= Python3.8: sh\npython3 -V Step 1. Installation For the virtualenv users, you can create a new venv: sh\npip3 install virtualenv\nvirtualenv venv\nsource venv/bin/activate and install the dependencies: sh\npython3 setup.py install\npip3 install -r requirements.txt Step 2. Create keys and deposit_data-*.json Run one of the following command to enter the interactive CLI: sh\npython3 ./staking_deposit/deposit.py new-mnemonic or sh\npython3 ./staking_deposit/deposit.py existing-mnemonic You can also run the tool with optional arguments: sh\npython3 ./staking_deposit/deposit.py new-mnemonic --num_validators=<NUM_VALIDATORS> --mnemonic_language=english --chain=<CHAIN_NAME> --folder=<YOUR_FOLDER_PATH> sh\npython3 ./staking_deposit/deposit.py existing-mnemonic --num_validators=<NUM_VALIDATORS> --validator_start_index=<START_INDEX> --chain=<CHAIN_NAME> --folder=<YOUR_FOLDER_PATH> Language Argument See here for --language arguments. Commands See here Arguments See here for new-mnemonic arguments\nSee here for existing-mnemonic arguments\nSee here for generate-bls-to-execution-change arguments Option 4. Use Docker image Step 1. Build the docker image Run the following command to locally build the docker image: sh\nmake build_docker Step 2. Create keys and deposit_data-*.json Run the following command to enter the interactive CLI: sh\ndocker run -it --rm -v $(pwd)/validator_keys:/app/validator_keys ethereum/staking-deposit-cli You can also run the tool with optional arguments: sh\ndocker run -it --rm -v $(pwd)/validator_keys:/app/validator_keys ethereum/staking-deposit-cli new-mnemonic --num_validators=<NUM_VALIDATORS> --mnemonic_language=english --folder=<YOUR_FOLDER_PATH> Example for 1 validator on the Prater testnet using english: sh\ndocker run -it --rm -v $(pwd)/validator_keys:/app/validator_keys ethereum/staking-deposit-cli new-mnemonic --num_validators=1 --mnemonic_language=english --chain=prater Arguments See here Successful message See here For Windows users Option 1. Download binary executable file Step 1. Installation See releases page to download and decompress the corresponding binary files. Step 2. Create keys and deposit_data-*.json Run one of the following command to enter the interactive CLI: sh\ndeposit.exe new-mnemonic or sh\ndeposit.exe existing-mnemonic You can also run the tool with optional arguments: sh\ndeposit.exe new-mnemonic --num_validators=<NUM_VALIDATORS> --mnemonic_language=english --chain=<CHAIN_NAME> --folder=<YOUR_FOLDER_PATH> sh\ndeposit.exe existing-mnemonic --num_validators=<NUM_VALIDATORS> --validator_start_index=<START_INDEX> --chain=<CHAIN_NAME> --folder=<YOUR_FOLDER_PATH> Language Argument See here for --language arguments. Commands See here Arguments See here for new-mnemonic arguments\nSee here for existing-mnemonic arguments\nSee here for generate-bls-to-execution-change arguments Option 2. Build deposit-cli with native Python Step 0. Python version checking Ensure you are using Python version >= Python3.8 (Assume that you've installed Python 3 as the main Python): sh\npython -V Step 1. Installation Install the dependencies: sh\npip3 install -r requirements.txt\npython setup.py install Or use the helper script: sh\nsh deposit.sh install Step 2. Create keys and deposit_data-*.json Run one of the following command to enter the interactive CLI: sh\n./deposit.sh new-mnemonic or sh\n./deposit.sh existing-mnemonic You can also run the tool with optional arguments: sh\n./deposit.sh new-mnemonic --num_validators=<NUM_VALIDATORS> --mnemonic_language=english --chain=<CHAIN_NAME> --folder=<YOUR_FOLDER_PATH> sh\n./deposit.sh existing-mnemonic --num_validators=<NUM_VALIDATORS> --validator_start_index=<START_INDEX> --chain=<CHAIN_NAME> --folder=<YOUR_FOLDER_PATH> Language Argument See here for --language arguments. Commands See here Arguments See here for new-mnemonic arguments\nSee here for existing-mnemonic arguments\nSee here for generate-bls-to-execution-change arguments Option 3. Build deposit-cli with virtualenv Step 0. Python version checking Ensure you are using Python version >= Python3.8 (Assume that you've installed Python 3 as the main Python): cmd\npython -V Step 1. Installation For the virtualenv users, you can create a new venv: cmd\npip3 install virtualenv\nvirtualenv venv\n.\\venv\\Scripts\\activate and install the dependencies: cmd\npython setup.py install\npip3 install -r requirements.txt Step 2. Create keys and deposit_data-*.json Run one of the following command to enter the interactive CLI: cmd\npython .\\staking_deposit\\deposit.py new-mnemonic or cmd\npython .\\staking_deposit\\deposit.py existing-mnemonic You can also run the tool with optional arguments: cmd\npython .\\staking_deposit\\deposit.py new-mnemonic --num_validators=<NUM_VALIDATORS> --mnemonic_language=english --chain=<CHAIN_NAME> --folder=<YOUR_FOLDER_PATH> cmd\npython .\\staking_deposit\\deposit.pyexisting-mnemonic --num_validators=<NUM_VALIDATORS> --validator_start_index=<START_INDEX> --chain=<CHAIN_NAME> --folder=<YOUR_FOLDER_PATH> Language Argument See here for --language arguments. Commands See here Arguments See here for new-mnemonic arguments\nSee here for existing-mnemonic arguments\nSee here for generate-bls-to-execution-change arguments Development Install basic requirements sh\npython3 -m pip install -r requirements.txt\npython3 setup.py install Install testing requirements sh\npython3 -m pip install -r requirements_test.txt Run tests sh\npython3 -m pytest . Building Binaries Developers Only Mac M1 Binaries \ud83d\udc4bThis is not the section you are looking for.\ud83d\udc4b\nIf you are trying to build the binary on macos with an M1 Mac and you are using pyenv to manage your python version. You'll probably need to reinstall a given python version using: env PYTHON_CONFIGURE_OPTS=\"--enable-framework\" pyenv install 3.10.3"}, {"name": "staking-launchpad", "desc": "The deposit launchpad for staking on Ethereum \ud83e\udd8f", "readme": "Ethereum Staking Launchpad The Launchpad is the Ethereum Foundation's official way to deposit your ETH for staking on Ethereum Dependencies Technology stack : React via CRA Redux TypeScript Web3-React Grommet Yarn Configuration To have full functionality of the Launchpad, you must create an .env file in your root directory and add an environment variable. The Infura Project ID will enable the network status progress bar showing the balance of the Deposit Contract REACT_APP_INFURA_PROJECT_ID=your-infura-project-id-here Note: The Portis wallet option is not available when running locally Installation Available Scripts yarn start Runs the app in the development mode. Open http://localhost:3000 to view it in the browser. The page will reload if you make edits. You will also see any lint errors in the console. Install Dependencies and Start the Application yarn\nyarn start Development workflow By default, dev acts as the primary base branch which all PRs should merge into. Make sure any pull requests target this branch. Launchpad deployment The master branch represents the live testnet version of the Launchpad. Open a PR to merge dev into master to deploy a testnet Launchpad (e.g. #517 for https://goerli.launchpad.ethereum.org/ ) The mainnet branch represents the live Mainnet version of the Launchpad. Open a PR to merge master into mainnet to deploy the Mainnet Launchpad (e.g. #518 for https://launchpad.ethereum.org/) Launchpad translation As part of the ethereum.org Translation Program , our community of translators is also working on translating the Ethereum Staking Launchpad. If you are interested in getting involved and helping with the translations, please visit the project in Crowdin . After joining the project, you can start translating by opening your desired language from the language list. If your language isn't available, please reach out to Ethereum.org Team on Crowdin or open an issue to request adding a new language for translation. Detailed information on using Crowdin is available in the Crowdin Online Editor documentation . Open source licensing info Creative Commons Zero v1.0 Universal - For more information read the LICENSE file."}, {"name": "statesweep", "desc": null, "readme": "State Cleaning The primary bloat to the state have been generated from the following contracts. Sequentially increasing 0x6a0a0fc761c612c340a0e98d33b37a75e5268472 Non sequential (identical contracts) 0x7c20218efc2e07c8fe2532ff860d4a5d8287cb31 0x8a2e29e7d66569952ecffae4ba8acb49c1035b6f 0x6a0a0fc761c612c340a0e98d33b37a75e5268472 This one generated suicides into sequentially increasing addresses, from 0x0000000000000000000000000000000000000001 -> 0x0000000000000000000000000000000000346b60 So the cleanup from that is pretty trivial. 0x7c20218efc2e07c8fe2532ff860d4a5d8287cb31 These are a bit more tricky, using two sources for seeding and generating destination addresses from these. See reverse_engineering.md for details. In order to generate the same addresses, we need to two pieces of data from each original transcation: CALLDATA The hash of the previous block (which is not available on-chain any longer, since we've passed 256 blocks) Also the exploit-contract worked like this: 0x7c20218efc2e07c8fe2532ff860d4a5d8287cb31 created contract x . It CALL :ed x 40 times with an address of a sucide beneficiary. Before each call, generate a new address. During each call, x performed suicide to the supplied address. If we have more than 1800 gas, repeat step 2. One more piece of data that we need is the number of suicides performed, in order to know when to stop our sweep. Files in this repo Contracts This repository contains a solidity implementation of a Sweeper contract, with the following signature: function asm_clean(uint s, uint i);\n\nfunction sol_clean(uint256 s, uint i); These should be equivalent, but with asm_clean requiring less gas. The first parameter s is the initial seed, and the i is the number of touches to perform. Data files The files in /data are: state_bloat_transactions_original.json - A file containing some basic data about all transactions into the two attack-contracts listed above. blh the block hash of the preceding block txhash the transaction hash state_bloat_transactions.json - Generated from state_bloat_transactions_original.json by using a web3 API to fetch some more data for each transaction: input - the input to the transactoin gasUsed - the gas used by the transaction mappings_gas_suicidecount.json - Generated from state_bloat_transactions_original.json , by using a web3 API to perform traces of transcations, and mapping gasUsed to number of suicides performed. final_data.json - Generated from state_bloat_transactions_original.json and mappings_gas_suicidecount.json . This calculates the seed and iter values to send into the solidity contract. The json file has the following data points: seed - Seed value num - Number of addresses to touch The file state_bloat_transactions_original.json was generated from the Etherchain API, which has been hugely helpful in gathering data. The scripts to create this file is not included in this repository. This file is the only file required to generate the rest of the files. Python The preprocess_data.py generates all data based on the state_bloat_transactions_original.json . During execution, it saves results to files, and can be aborted/resumed. In this repo, the files are already generated and the script does not need to actually do much work. If you want to regenerate the data based on state_bloat_transactions_original.json from scratch, you need to delete the other json-files and ensure that you have a http-api with debug available: geth --rpc --rpcapi \"debug,eth\" Live contracts The Sweeper.sol contract was deployed on the main net in 0xad4ceddc9e345ac9f3076bf657ee1e22e382b98de6d351d35c7f8e28e8398021 , and lives on 0xa43ebd8939d8328f5858119a3fb65f65c864c6dd ```javascript var sweeperAbi = [{\"constant\":false,\"inputs\":[{\"name\":\"s\",\"type\":\"uint256\"},{\"name\":\"i\",\"type\":\"uint256\"}],\"name\":\"sol_clean\",\"outputs\":[],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"s\",\"type\":\"uint256\"},{\"name\":\"i\",\"type\":\"uint256\"}],\"name\":\"asm_clean\",\"outputs\":[],\"payable\":false,\"type\":\"function\"}];\nvar sweeperContract = web3.eth.contract(sweeperAbi).at(\"0xa43ebd8939d8328f5858119a3fb65f65c864c6dd\");\n```"}, {"name": "swarm-dapps", "desc": "Swarm \u0110app Examples", "readme": "Swarm \u0110app Examples In this repository, you find the source code for distributed applications (so-called \u0111apps),\nthe primary purpose of which is to demonstrate the use of Swarm's API and the most useful\npatterns of developing such applications. examples/album A photo album dapp with a set of public-domain photographs that lets users upload their own photos. The code is based on fgallery version 1.7. All chenges in the gallery are accompanied by a change in the root hash of the album. Sharing or registering the root hash corresponds to sharing and/or publishing a particular state of the photo album. This is an example of non-interactive content dissemination, with no feedback from the audience. examples/filemanager This is a GUI explorer for file collections hosted on swarm. An example of a tool for working on file collections other than itself. The root hash of the explorer remains the same (or changes with upgrades); the root hash of the explored collection is appended as a fragment to the URI. Of course, it can be used to explore itself. examples/ens-updater This is a GUI tool for updating ENS domain with SWARM hash. examples/bzzhandler.html This html installs http protocol handlers for bzz, bzzi and bzzr protocols. You can either upload each example into Swarm and run it from there or run a \nproxy server (see below) Running via proxy server shell\nnpm install live-server Now run ./start-proxy <folder> . For example, to run the filemanager: shell\n./start-proxy ./examples/filemanager"}, {"name": "system-testing", "desc": "Ethereum system-testing", "readme": "system-testing Testing ethereum clients in dedicated networks. More info in the wiki . Tests are deployed via docker-machine on Amazon EC2 instances. Installing necessary software Using Docker Add your AWS credentials in your local ~/.boto , it will get mounted as a single-file volume inside the container. [Credentials]\naws_access_key_id = <ACCESS_KEY_ID>\naws_secret_access_key = <SECRET_ACCESS_KEY> Running with docker : docker run -v ~/.boto:/root/.boto -it ethereum/system-testing Running with docker-compose ( brew install docker-compose or official install docs ): docker-compose run testing Directly apt-get install graphviz-dev libfreetype6-dev pkg-config python python-dev\ngit clone https://github.com/ethereum/system-testing.git\ncd system-testing\nvirtualenv venv  # optional\nsource venv/bin/activate  # optional\npip install -e . You will also need docker-machine , docker-compose and docker . Usage Launch testing to run tests. ```\nusage: testing [-h] [-v] [-c CPP_NODES] [--cpp-image CPP_IMAGE]\n               [--cpp-boot CPP_BOOT] [-g GO_NODES] [--go-image GO_IMAGE]\n               [--go-boot GO_BOOT] [-p PYTHON_NODES]\n               [--python-image PYTHON_IMAGE] [--python-boot PYTHON_BOOT]\n               [-e ELASTICSEARCH] [-i VPC] [-r REGION] [-z ZONE] [-d DEBUG]\n               [-s [{p2p_connect,tx_propagation,chain_consensus,mine_consensus} [{p2p_connect,tx_propagation,chain_consensus,mine_consensus} ...]]]\n               [{ls,stop,rm,cleanup}] [parameters [parameters ...]] positional arguments:\n  {ls,stop,rm,cleanup}  Optional commands for maintenance\n  parameters            Optional parameters optional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n  -c CPP_NODES, --cpp CPP_NODES\n                        Number of C++ nodes to launch (default: 1)\n  --cpp-image CPP_IMAGE\n                        Base C++ image to use (default: ethereum/client-cpp)\n  --cpp-boot CPP_BOOT   Number of C++ bootnodes to launch (default: 0)\n  -g GO_NODES, --go GO_NODES\n                        Number of Go nodes to launch (default: 1)\n  --go-image GO_IMAGE   Base Go image to use (default: ethereum/client-go)\n  --go-boot GO_BOOT     Number of Go bootnodes to launch (default: 1)\n  -p PYTHON_NODES, --python PYTHON_NODES\n                        Number of Python nodes to launch (default: 1)\n  --python-image PYTHON_IMAGE\n                        Base PyEthApp image to use (default: ethereum/client-\n                        python)\n  --python-boot PYTHON_BOOT\n                        Number of Python bootnodes to launch (default: 0)\n  -e ELASTICSEARCH, --es ELASTICSEARCH\n                        IP of the ElasticSearch node (default: None)\n  -i VPC, --vpc-id VPC  AWS VPC ID (default: vpc-3fe30e5a)\n  -r REGION, --region REGION\n                        AWS Region (default: us-east-1)\n  -z ZONE, --zone ZONE  AWS Zone (default: b)\n  -d DEBUG, --debug DEBUG\n                        Debug (default: False)\n  -s [{p2p_connect,tx_propagation,chain_consensus,mine_consensus} [{p2p_connect,tx_propagation,chain_consensus,mine_consensus} ...]], --scenarios [{p2p_connect,tx_propagation,chain_consensus,mine_consensus} [{p2p_connect,tx_propagation,chain_consensus,mine_consensus} ...]]\n                        Scenarios to test (default: all)\n``` Cleanup Stopping clients testing stop [nodename] Removing client instances testing rm [nodename] Removing all instances testing cleanup See related wiki article"}, {"name": "test-tools", "desc": "Benchmark and test tools for Ethereum", "readme": "Ethereum Test Tools Benchmark and test tools for Ethereum implementations Requirements Python 3 and 2 is supported, but Python 3 is preferred. Dependencies:\n- click - library for command line interface,\n- PyYAML - YAML implementations for Python,\n- tabulate - Pretty-print tabular data. All dependencies can be installed by pip3 install --user -r requirements.txt Supported VMs evm from go-ethereum , ethvm from cpp-ethereum . Example Register evm without JIT. python3 testeth.py tool register evm-jit /usr/bin/evm -- --nojit Register evm with JIT. python3 testeth.py tool register evm-jit /usr/bin/evm -- --forcejit Execute example performace tests. python3 testeth.py test tests/performance.yml Execute VM tests . python3 testeth.py test <path-to-tests-repo>/VMTests"}, {"name": "testeth", "desc": "One consensus test generator", "readme": "testeth - Ethereum consensus test generator. This repository contains testeth, an Ethereum consensus test generator. This repository is out of date and should be closed. Anyone wanting to use testeth should instead build and run it from the ethereum/aleth repository. Contact Difference from cpp-ethereum Currently the repository is almost identical to cpp-ethereum\n* testeth will drop MacOS and Windows supports\n* testeth will drop commands except eth and testeth * testeth will drop key management features except needed for generating tests However, eth command in testeth will keep the ability to sync the main network.  It's important to generate tests using the code compliant with the main network. Building from source Get the source code Git and GitHub is used to maintain the source code. Clone the repository by: shell\ngit clone --recursive https://github.com/ethereum/testeth.git\ncd testeth The --recursive option is important. It orders git to clone additional \nsubmodules which are required to build the project.\nIf you missed it you can correct your mistake with command git submodule update --init . Install CMake CMake is used to control the build configuration of the project. Quite recent \nversion of CMake is required \n(at the time of writing 3.4.3 is the minimum ).\nWe recommend installing CMake by downloading and unpacking the binary \ndistribution  of the latest version available on the CMake download page . The CMake package available in your operating system can also be installed\nand used if it meets the minimum version requirement. Alternative method The repository contains the scripts/install_cmake.sh script that downloads \na fixed version of CMake and unpacks it to the given directory prefix. \nExample usage: scripts/install_cmake.sh --prefix /usr/local . Install dependencies (Linux, macOS) The following libraries are required to be installed in the system in their\ndevelopment variant: leveldb They usually can be installed using system-specific package manager.\nExamples for some systems: Operating system | Installation command\n---------------- | --------------------\nDebian-based     | sudo apt-get install libleveldb-dev RedHat-based     | dnf install leveldb-devel macOS            | brew install leveldb We also support a \"one-button\" shell script scripts/install_deps.sh which attempts to aggregate dependencies installation instructions for Unix-like\noperating systems. It identifies your distro and installs the external packages.\nSupporting the script is non-trivial task so please inform us if it does not work for your use-case. Build Configure the project build with the following command. It will create the build directory with the configuration. shell\nmkdir build; cd build  # Create a build directory.\ncmake ..               # Configure the project.\ncmake --build .        # Build all default targets. Testing To run the tests, make sure you clone https://github.com/ethereum/tests and point the environment variable ETHEREUM_TEST_PATH to that path. After building, ctest -j4 will run the tests with some parallelism. You can also add testeth options (that come after the separator -- ) like ctest -j4 -DTESTETH_ARGS=\"--verbosity 5\" To see the list of options, test/testeth --help Documentation Internal documentation for developers . License All contributions are made under the GNU General Public License v3 . See LICENSE ."}, {"name": "testng", "desc": null, "readme": null}, {"name": "tests", "desc": "Common tests for all Ethereum implementations", "readme": "Ethereum Execution Tests (EVM) Common tests for all clients to test against. Test execution tool: https://github.com/ethereum/retesteth Test Formats Maintained tests: /BasicTests\n/BlockchainTests\n/GeneralStateTests\n/TransactionTests\n/EIPTests\n/EOFTests\n/RLPTest\n/src See descriptions of the different test formats in the official documentation at  http://ethereum-tests.readthedocs.io/. Note : The format of BlockchainTests recently changed with the introduction of a new field sealEngine (values: NoProof | Ethash ), see related JSON Schema change or BlockchainTest format docs for reference. This means that you can skip PoW validation for NoProof tests but also has the consequence that it is not possible to rely on/check PoW related block parameters for these tests any more. Clients using the library The following clients make use of the tests from this library. You can use these implementations for inspiration on how to integrate. If your client is missing, please submit a PR (requirement: at least some minimal test documentation)! Mana (Elixir): Docs , Test location: ethereum_common_tests go-ethereum (Go): Docs , Test location: tests/testdata Parity Ethereum (Rust): Docs , Test location: ethcore/res/ethereum/tests ethereumjs-vm (JavaScript): Docs , Test location: ethereumjs-testing dependency Trinity (Python): Docs , Test location: fixtures Hyperledger Besu (Java): Docs , Test Location: ethereum/referencetests/src/test/resources Nethermind (C#) Docs , Test Location: src/tests Nimbus-eth1 (Nim) Docs , Test location: tests/fixtures Mantis (Scala) Docs , Test Location: https://github.com/input-output-hk/mantis/tree/develop/ets Using the Tests We do versioned tag releases for tests and you should aim to run your client libraries against the latest repository snapshot tagged. Generally the develop branch in ethereum/tests is always meant to be stable and you should be able to run your test against. Contribute to the Test Suite See the dedicated section in the docs on how to write new tests. Or read a shorter description here . If you want to follow up with current tasks and what is currently in the works, have a look at the issues Currently the geth evm t8ntool client is the reference client for generating tests. Besu client also has support for generating the tests using rpc test protocol. See at https://github.com/ethereum/retesteth/wiki Testing stats Testing results are available at http://retesteth.ethdevops.io/ There is a web tool for vmtracing the tests using supported clients and retesteth: http://retesteth.ethdevops.io/web/ All blockchain tests are being run by hive tool: https://hivetests.ethdevops.io/ Contents of this repository Do not change test files in folders: \n* StateTests\n* BlockchainTests\n* TransactionTests \n* VMTests It is being created by the testFillers which could be found at src folder. The filler specification and wiki are in development so please ask on gitter channel for more details. If you want to modify a test filler or add a new test please contact @wdimitry at telegram\nUse the following guide: https://github.com/ethereum/retesteth/wiki/Creating-a-State-Test-with-retesteth"}, {"name": "tlsnotary-old-website", "desc": "A copy of the https://tlsnotary.org/", "readme": "tlsnotary.org copy Since new website will be deployed to tlsnotary.org, this repository will now host a clone of the old website that now will be available at https://old.tlsnotary.org for history purposes."}, {"name": "trin", "desc": "An Ethereum portal client: a json-rpc server with nearly instant sync, and low CPU & storage usage", "readme": "Trin Trin is a Rust implementation of a Portal Network client. The Portal Network is still in the research phase, and this client is experimental. Do not rely on Trin in a production setting. NOTE: Unix-only Trin currently only runs on Unix-based platforms (Linux, macOS). We plan to eventually implement support for Windows, but until then do not expect any support for issues on Windows. How to use Trin Check out the Trin book to quickly get up and running with Trin. Experimental Status Trin is a prototype Portal Network client. This implementation and the Portal Network specifications will continue to co-evolve. In this stage of development, Trin lacks comprehensive data validation. Want to help? Want to file a bug, contribute some code, or improve documentation? Excellent! Read up on our\nguidelines for contributing in the Trin book ,\nthen check out issues that are labeled Good First Issue . Join our Discord to participate in the conversation!"}, {"name": "trinity", "desc": "The Trinity client for the Ethereum network", "readme": "\ud83d\udd25 NO LONGER MAINTAINED OR DEVELOPED \ud83d\udd25 The Trinity Ethereum client is no longer being developed or maintained.  This repository will remain here in archive mode."}, {"name": "trinity-eth2", "desc": "The Trinity client for the Eth2 network", "readme": "The Trinity Ethereum 2.0 Client trinity-eth2 a client for the Ethereum 2.0 / Serenity spec. For the offical website, visit https://trinity.ethereum.org/"}, {"name": "trinity-web", "desc": "The trinity.ethereum.org web site", "readme": null}, {"name": "trio-run-in-process", "desc": "Trio-based API for running code in other processes", "readme": "Trio run_in_process Trio based API for running code in a separate process Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install trio-run-in-process Developer Setup If you would like to hack on trio-run-in-process, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/trio-run-in-process.git\ncd trio-run-in-process\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 trio_run_in_process/ tests/ -c \"clear; flake8 trio_run_in_process tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on trio-run-in-process failed'\" ../tests ../trio_run_in_process Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). To include changes made with each\nrelease, update \"docs/releases.rst\" with the changes, and apply commit directly to master \nbefore release. If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "tryethereum", "desc": "Try Ethereum with an online interface", "readme": "tryethereum Try Ethereum with an online interface. Recommended https://github.com/ethereum/cpp-ethereum/releases It is the most up-to-date and feature-complete including a HTML/JS front-end API and a JavaScript console. Currently, tryethereum is on pause (https://github.com/ethereum/tryethereum/issues/8) Prior instructions for running Install nodejs, npm, mongo-db Run \"npm install\" and mongod node server.js Clone and build https://github.com/ethereum/pyethereum.  Make pyethtool globally accessible (eg create symlink /usr/local/bin/pyethtool) Clone and build https://github.com/ethereum/serpent In browser go to http://localhost:3000 For example: Enter cow for seed Click \"Gimme more money\" Get the namecoin contract written in serpent from http://blog.ethereum.org/2014/04/10/pyethereum-and-serpent-programming-guide-2 and submit it. Note the address of the contract, let's call it NAMECOIN_ADDRESS. In \"State Explorer\" enter NAMECOIN_ADDRESS to see your namecoin contract Submit Transaction to NAMECOIN_ADDRESS with value 0 and data \"harry 60\" (no quotes) In \"State Explorer\" you should see your data will now be in storage \"1734439545 60\" Try out other stuff and if you want to reset (genesis block), delete it from mongo eg. db.block.remove({})"}, {"name": "twig", "desc": null, "readme": "twig A tool for Ethereum smart contract development. Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install twig Developer Setup If you would like to hack on twig, please check out the Ethereum Development Tactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/twig.git\ncd twig\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 twig/ tests/ -c \"clear; flake8 twig tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on twig failed'\" ../tests ../twig Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). To include changes made with each\nrelease, update \"docs/releases.rst\" with the changes, and apply commit directly to master \nbefore release. If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "UniversalLoginSDK", "desc": "Archive of deprecated Universal Login SDK", "readme": "Archival Notice This repository is archived. Ethereum Universal Login Universal Login is a design pattern for storing funds and connecting to Ethereum applications, aiming to simplify new users on-boarding. This repository is a monorepo including sdk, relayer, smart contracts and example. Each public sub-package is independently published to NPM. Learn documentation . Documentation Documentation is available at universalloginsdk.readthedocs.io Disclaimer This is a work in progress. Expect breaking changes. The code has not been audited and therefore can not be considered secure. Technical concepts Technically Universal Login utilizes four major concepts:\n- Personal multi-sig wallet - a smart contract used to store personal funds. A user gets his wallet created in a bearly noticeable manner. The user then gets engaged incrementally to add authorization factors and recovery options.\n- Meta-transactions - that give user ability to interact with his wallet from multiple devices easily, without a need to store ether on each of those devices. Meta-transactions, also allow paying for execution with tokens.\n- ENS names - naming your wallet with easy-to-remember human-readable name\n- Universal login - ability to use the wallet as authorization layer to numerous web applications dapps Structure Packages maintained with this monorepo are listed below. Contracts - all contracts used in this project Relayer - node.js server application that allows interacting with blockchain without a wallet SDK - a JS library, that helps to communicate with relayer Example - example application written in React OPS - scripts for development and deployment Contributing Contributions are always welcome, no matter how large or small. Before contributing, please read the code of conduct and contribution policy . Before you issue pull request:\n* Make sure all tests and linters pass.\n* Make sure you have test coverage for any new features. Running linting/tests You can run lint via: sh\nyarn lint You can run tests: sh\nyarn test You can ran full clean: sh\nyarn clean And you can emulate full CI process by: sh\nyarn clean\nyarn\nyarn ci License Universal Login SDK is released under the MIT License ."}, {"name": "upnp-port-forward", "desc": "UPnP port forwarding for humans", "readme": "UPnP Port Forward UPnP port forwarding for humans Read more in the documentation on ReadTheDocs . View the change log . Quickstart sh\npip install upnp-port-forward Developer Setup If you would like to hack on upnp-port-forward, please check out the Snake Charmers\nTactical Manual for information on how we do: Testing Pull Requests Code Style Documentation Development Environment Setup You can set up your dev environment with: sh\ngit clone git@github.com:ethereum/upnp-port-forward.git\ncd upnp-port-forward\nvirtualenv -p python3 venv\n. venv/bin/activate\npip install -e .[dev] Testing Setup During development, you might like to have tests run on every file save. Show flake8 errors on file change: ```sh Test flake8 when-changed -v -s -r -1 upnp_port_forward/ tests/ -c \"clear; flake8 upnp_port_forward tests && echo 'flake8 success' || echo 'error'\"\n``` Run multi-process tests in one command, but without color: ```sh in the project root: pytest --numprocesses=4 --looponfail --maxfail=1 the same thing, succinctly: pytest -n 4 -f --maxfail=1\n``` Run in one thread, with color and desktop notifications: sh\ncd venv\nptw --onfail \"notify-send -t 5000 'Test failure \u26a0\u26a0\u26a0\u26a0\u26a0' 'python 3 test on upnp-port-forward failed'\" ../tests ../upnp_port_forward Release setup For Debian-like systems: apt install pandoc To release a new version: sh\nmake release bump=$$VERSION_PART_TO_BUMP$$ How to bumpversion The version format for this repo is {major}.{minor}.{patch} for stable, and {major}.{minor}.{patch}-{stage}.{devnum} for unstable ( stage can be alpha or beta). To issue the next version in line, specify which part to bump,\nlike make release bump=minor or make release bump=devnum . This is typically done from the\nmaster branch, except when releasing a beta (in which case the beta is released from master,\nand the previous stable branch is released from said branch). If you are in a beta version, make release bump=stage will switch to a stable. To issue an unstable version when the current version is stable, specify the\nnew version explicitly, like make release bump=\"--new-version 4.0.0-alpha.1 devnum\""}, {"name": "utp", "desc": "uTorrent transport protocol", "readme": "utp A Rust library for the uTorrent transport protocol (uTP) . \ud83d\udea7 WARNING: UNDER CONSTRUCTION \ud83d\udea7 This library is currently unstable, with known issues. Use at your own discretion. Usage ```rust\nuse std::net::SocketAddr; use utp_rs::conn::ConnectionConfig;\nuse utp_rs::socket::UtpSocket;\nuse utp_rs::udp::AsyncUdpSocket; [tokio::main] fn main() {\n    // bind a standard UDP socket. (transport is over a tokio::net::UdpSocket .)\n    let socket_addr = SocketAddr::from(([127, 0, 0, 1], 3400));\n    let udp_based_socket = UtpSocket::bind(socket_addr).await.unwrap(); // bind a custom UDP socket. here we assume `CustomSocket` implements `AsyncUdpSocket`.\nlet async_udp_socket = CustomSocket::new(..);\nlet custom_socket = UtpSocket::with_socket(async_udp_socket).await.unwrap();\n\n// connect to a remote peer over uTP.\nlet remote = SocketAddr::from(..);\nlet config = ConnectionConfig::default();\nlet mut stream = udp_socket::connect(remote, config).await.unwrap();\n\n// write data to the remote peer over the stream.\nlet data = vec![0xef; 2048];\nlet n = stream.write(data.as_slice()).await.unwrap();\n\n// accept a connection from a remote peer.\nlet config = ConnectionConfig::default();\nlet stream = udp_socket.accept(config).await;\n\n// read data from the remote peer until the peer indicates there is no data left to write.\nlet mut data = vec![];\nlet n = stream.read_to_eof(&mut data).await.unwrap(); }\n```"}, {"name": "verkle-dev-website", "desc": "Github Pages: https://verkle.dev", "readme": "Verkle Dev Contributor Website This website is built using Docusaurus 2 , a modern static website generator. Installation *npm can also be used in place of yarn $ yarn Local Development $ yarn start This command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server. Build $ yarn build This command generates static content into the build directory and can be served using any static contents hosting service."}, {"name": "vim-solidity", "desc": "Vim syntax file for solidity", "readme": null}, {"name": "web3.py", "desc": "A python interface for interacting with the Ethereum blockchain and ecosystem.", "readme": "web3.py A Python library for interacting with Ethereum. Python 3.7.2+ support Quickstart Get started in 5 minutes or take a tour of the library. Documentation For additional guides, examples, and APIs, see the documentation . Want to help? Want to file a bug, contribute some code, or improve documentation? Excellent! Read up on our\nguidelines for contributing ,\nthen check out issues that are labeled Good First Issue . Questions on implementation or usage? Join the conversation on discord ."}, {"name": "webthree", "desc": "Submodule of the Ethereum C++ implementation, please see webthree-umbrella.", "readme": "Former home of webthree (part of cpp-ethereum) cpp-ethereum is the Ethereum C++ client. This repository was a sub-module used within the webthree-umbrella repo between October 2015 and August 2016. The code formerly developed in this repo has been merged back into cpp-ethereum as of August 2016. Please do not create pull-requests against this repository.  It is no longer in-use."}, {"name": "webthree-helpers", "desc": "Former home of webthree-helpers (part of cpp-ethereum)", "readme": "Former home of webthree-helpers (part of cpp-ethereum) cpp-ethereum is the Ethereum C++ client. This repository was a sub-module used within the webthree-umbrella repo between October 2015 and August 2016. The code formerly developed in this repo has been merged back into cpp-ethereum as of August 2016. Please do not create pull-requests against this repository.  It is no longer in-use."}, {"name": "webthree-umbrella", "desc": "Former home of cpp-ethereum (Oct 2015 to Aug 2016)", "readme": "Former home of webthree-umbrella (cpp-ethereum) cpp-ethereum is the Ethereum C++ client. This repository was an \"umbrella\" repository which was the home for the various C++\nprojects betwen October 2015 and August 2016.   Prior to that point all the work had happened\nunder a single repository ( cpp-ethereum ), and that is where all C++ runtime development\nwork has now returned, with solidity now being a standalone repository. AlethZero, AlethOne and AlethFive have been retired Mix has been retired Solidity is now standalone, and development continues in that repo The restored cpp-ethereum repository is the mainline for the C++ runtime client That is a merger of the libethereum, libweb3core, webthree and webthree-helpers repositories Please do not create pull-requests against this repository.  It is no longer in-use."}, {"name": "whisper", "desc": null, "readme": "whisper This repository is extracted from the go-ethereum whisper implementation and is used as an archive. The rationale for archiving this project is that it is obvious that in its current implementation, Whisper will never scale beyond a couple hundred nodes. Further development has now been taken on by status . It also contains various whisper-related tools. Building Type go build ./cmd/wnode to build the Whisper node utility."}, {"name": "wiki", "desc": "The Ethereum Wiki", "readme": "Wiki :no_entry_sign: no longer actively maintained :no_entry_sign: This wiki is a now a largely outdated collection of resources explaining the state-of-the-art in Ethereum circa 2014-2018. Most of the material in this repository has been updated and migrated to ethereum.org. This repository is due to be archived shortly. Please visit ethereum.org instead for current Ethereum information! Looking to contribute to Ethereum documentation? Check out the ethereum.org repo: https://github.com/ethereum/ethereum-org-website"}, {"name": "www", "desc": "[ARCHIVED] Ethereum website from 2015", "readme": "www / gulp-presale Server setup Linux/Debian/Ubuntu Ensure you have an updated version of nodejs and npm installed. Ubuntu repos often contain an old version, so it's recommend to use a more up-to-date repo . If you already had nodejs installed and need it updated, make sure to sudo apt-get update && sudo apt-get upgrade . Otherwise a sudo apt-get install nodejs npm should be sufficient. Mac brew install node Windows Install node from http://nodejs.org/download/ and open the node command prompt. Assuming nodejs/npm is correctly installed, the next step is to install gulp with sudo npm -g install gulp . Project setup npm install && gulp build This will install all dependencies and compile the site to ./build/ (or whatever is defined as basePaths.dest in gulpfile.js). To instruct gulp to compile for production, pass --prod and possibly gulp bundle to compress it into a zip. For example: gulp build --prod && gulp bundle Or use the default dev task, which launches a local live-reload server for preview: gulp"}, {"name": "yellowpaper", "desc": "The \"Yellow Paper\": Ethereum's formal specification", "readme": "Ethereum Yellow Paper The Yellow Paper is a formal definition of the Ethereum protocol, originally by Gavin Wood, currently maintained by Nick Savers and with contributions from many people around the world. It is a free culture work, licensed under Creative Commons Attribution Share-Alike (CC-BY-SA) Version 4.0. Repository Currently Outdated The Yellow Paper is out of date. It reflects the Ethereum specification up to the Paris network upgrade (\"the merge\"), activated on the Ethereum mainnet at block 15_537_394 (September 2022). It does not contain changes introduced in any post-merge upgrade. An alternative Python Execution Layer specification is actively maintained and up to date. Usage If you just want to read the paper, the latest version is generally available as a PDF at https://ethereum.github.io/yellowpaper/paper.pdf. If you find that the borders for links block too much text when viewing the PDF in the browser, you can instead download it and open and view it with a PDF viewer application such as Adobe Acrobat or Evince, where the borders are less likely to display over text. However, if you want to edit the paper, then read on. The paper comes as a single latex file Paper.tex . It is recommended to use an IDE such as Visual Studio Code with the LaTeX Workshop extension, to edit the tex file, and show the PDF. Another option is to separately edit the tex file and build as follows (you'll still need to clone the repo then open the yellowpaper folder): git clone https://github.com/ethereum/yellowpaper.git\ncd yellowpaper\n./build.sh This will create a PDF version of the Yellow Paper. Following building, you can also use standard pdflatex tools for compiling/preview, like http://latex.informatik.uni-halle.de/latex-online/latex.php. Tips on editing You can use TeX Stack Exchange ; https://en.wikibooks.org/wiki/LaTeX/ (e.g. Bibliography Management and Hyperlinks ); and BibTeX editor . Versions The previous protocol versions are listed in BRANCHES.md . Other language versions Chinese translated by YuanGe and GaoTianlu. French translated by Asseth (checkout to branch 'french' )."}, {"name": "yul-isabelle", "desc": null, "readme": "Yul-Isabelle: Executable Formal Semantics of Yul This repository contains an implementation of a semantics for the Yul laguage using\nthe Isabelle/HOL proof assistant.\nIt is compatible with Isabelle2021. Design goals are to create a maintainable formal semantics of Yul -\nincluding a reference interpreter - suitable for use in verifying\nSolidity compiler transformations. The Yul language is designed to be integrated with a machine language,\nsuch that Yul captures control-flow and variable-assignment, and\nthe machine language's primitives capture the remaining functionality.\nSuch a combination is called a Yul Dialect . In this repository we\nfocus on the Yul/EVM Dialect . The repository is organized as follows: Yul : Implementation of Yul syntax and control-flow semantics YulSyntax : Yul semantics AST data structure YulSemanticsSingleStep : executable reference interpreter for Yul YulDialect : Useful primitives for defining dialects of Yul YulSemantics : inductive semantics for Yul; currently incomplete Word_Lib : A copy of the \"Word_Lib\" entry from the Isabelle Archive of Formal Proofs\n  (as of Isabelle2021, several useful operations on Isabelle machine words have been\n  moved out of the standard library and into this entry) EVM : an implementation of a substantial subset of the EVM virtual machine for use in defining the Yul/EVM dialect.\n  Based on LLL tests from Solidity. MiniEvm : An implementation of a large subset of EVM operations. Currently does not model gas accounting or cross-contract calls. Used in the EVM dialect. LowLevelEvm : An implementation of a datatype for EVM bytecodes, currently incomplete GlobalEvm : An attempt at modeling global Ethereum state and cross-contract behaviors, currently incomplete EvmTests : Tests for the EVM implementation contained in EVM Keccak : Isabelle implementation of Keccak256, drawn from eth-isabelle Dialects : Instantiations of Yul to different dialects; most importantly, EVM EvmDialect : the Yul/EVM dialect YulTests : Tests for the Yul interpreter, including the EVM dialect"}, {"name": "Yul-K", "desc": "Formal semantics of the yul language", "readme": "yul-semantics K formalization of the Yul language Requires the same dependencies as evm-semantics Build with: sh\nmake The main goal of this repository is to verify optimizations done by the Solidity compiler via translation validation . In other words, given a yul program, A and the optimized version, A' , we prove the an equivalence of programs A <=> A' through bisimulation. Try the example tests/proofs/sstoreloop-spec.k by running: sh\n./kyul prove tests/proofs/sstoreloop-spec.k If you want to explore the proof, run: sh\n./kyul klab-prove tests/proofs/sstoreloop-spec.k followed by: sh\n./kyul klab-view tests/proofs/sstoreloop-spec.k"}]