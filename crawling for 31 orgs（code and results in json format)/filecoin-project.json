[{"name": "assets", "description": "Filecoin design assets, such as logos and other illustrations", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# assets\n\nThis repo holds the Filecoin project's key design assets and logos.\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/assets/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/assets/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "athena", "description": null, "language": null, "license": null, "readme": "# Project Athena\n\nIn Greek mythology, Athena was supposedly born, fully formed, from the head of Zeus. In many ways that's what we're trying to do here except with IPFS infrastructure.\n\nSpecifically, **Project Athena** is a cross Filecoin project to make setting up of the various components that make up the IPFS/Filecoin network.\n\nTypes of setup that we would need declarative setup for include:\n- Lotus\n- Gateways\n- File servers (e.g. NFS?)\n- ...\n- ...\n\n## Near Term Goals\n\nFrom a user experience perspective, IDEALLY we would have the following setup experience. \n\nAssuming a current Kubernetes cluster is available.\n```\nNUMBER_OF_LOTUS_NODES=10 helm install -f local_values.yaml lotus\n```\n\nInside `local_values.yaml` would be all environment specific configurations. \n\n**NOTE:** The above is highly implementation specific (e.g. using helm and Kubernetes). We are not suggesting these are *necessarily* the right technology choices, but this clean experience, with single line declarative setup and well separated environment variables will dramatically improve setup and adoption.\n\n## Lotus as First Effort\n\nThe Lotus Miner is a good first effort for exploration. One thing that we have discovered is that there are a variety of \"profiles\" that need Lotus. These include:\n- lotus newbies\n- storage providers\n- application developers\n- API providers\n\nIt may be interesting to build a sample profile for each, and describe what the criteria are for setting up according to that profile. \n\nThis requirements should include:\n\n- cpu\n- memory\n- stoarge\n- networking\n- secrets\n\nAt the end, we could see what commonalities and where the variables are, and use that as a mechanism to understand what to parameterize.\n\n## End goal\nFor each setup construct, we should plan on having a minimum of two profiles for each service:\n- A highly instrumented, full log export reference architecture. This will likely not be particularly efficient, but will allow for simplified debugging of new deployments.\n- A fairly efficient deployment.\n\nIn both cases, these are reference architectures, fully open sourced and forkable. Ideally, new participants in the Filecoin ecosystem could use these architectures as starting points and re-use components that make sense to them (e.g. containers).\n\nAdditionally, we should plan on integrating all components here into native build, CI/CD and test systems. So, every time a new release is tagged, new containers are built, the system goes through high level smoke tests and bugs are visible in test coverage (or filed with the appropriate teams).\n\n## Prior Art\n\nThere are many examples of existing sample work here:\n- Setting up a lotus node (gist) - https://gist.github.com/ribasushi/5b06148b19d1fcd350421b70cbade7af\n- A bunch of helm charts we already have - https://github.com/filecoin-project/helm-charts\n- Instructions for installing everything -  https://lotus.filecoin.io/docs/set-up/install/\n\nDiscussions:\n- https://github.com/filecoin-project/lotus/discussions\n- https://github.com/filecoin-project/community/discussions\n- https://lotus.filecoin.io/\n- https://github.com/filecoin-project/lotus/discussions/5989#discussion-3310965\n", "release_dates": []}, {"name": "awesome-filecoin", "description": "Curated list of useful resources for Filecoin", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<img src=\"https://filecoin.io/images/filecoin-logo.svg\" width=\"100\">\n\nA curated list of useful resources for Filecoin\n\n## Contents\n- [Documentation](#-documentation)\n- [Nodes](#-nodes)\n- [Libraries and tools](#-libraries-and-tools)\n- [Filecoin explorers](#-filecoin-explorers)\n- [Apps](#-apps)\n- [Wallets](#-wallets)\n- [Filecoin Virtual Machine](#-filecoin-virtual-machine)\n  * [Tutorials](#-fvm-tutorials)\n  * [Libraries and tools](#-fvm-libraries-and-tools)\n  * [Documentation](#-fvm-documentation)\n  * [Other resources](#-fvm-other-resources)\n- [Resources](#resources)\n  * [Articles](#-articles)\n  * [Videos](#-videos)\n  * [Other resources](#-other-resources)\n\n\n### \ud83d\udcc4 Documentation\n- [Filecoin website](https://filecoin.io/) - Official Filecoin website\n- [What is Filecoin](https://docs.filecoin.io/intro/intro-to-filecoin/what-is-filecoin/) - Official Filecoin intro\n- [Filecoin Spec](https://spec.filecoin.io/) - Filecoin specification\n- [FIPs](https://github.com/filecoin-project/FIPs) - Filecoin Improvement Proposals\n- [Networks](https://docs.filecoin.io/networks/overview/) - Available Filecoin networks\n- [Network Upgrades](https://github.com/filecoin-project/core-devs/tree/master/Network%20Upgrades) - Network upgrades (FIPs included, bugfixes, improvements)\n\n### \ud83c\udf10 Nodes\n\n- [\ud83e\udeb7 Lotus](https://github.com/filecoin-project/lotus) - Reference implementation of the Filecoin protocol, written in Go\n  - [Lotus docs](https://lotus.filecoin.io/) - Lotus node website, tutorials, knowledge base\n\n- [\ud83c\udf32Forest](https://github.com/ChainSafe/forest) - Implementation of the Filecoin protocol, written in Rust\n- [\ud83e\ude90 Venus](https://github.com/filecoin-project/venus) - Implementation of the Filecoin protocol, written in Go\n\n### \ud83e\uddf0 Libraries and Tools\n- [Filecoin status](https://status.filecoin.io/) - Filecoin (mainnet, calibnet, butterfly-snapnet) status page\n- [built-in actors](https://github.com/filecoin-project/builtin-actors) - On-chain built-in actors code\n- [FilSnap](https://github.com/ChainSafe/filsnap) - MetaMask snap for interacting with Filecoin dapps\n- [Lily](https://github.com/filecoin-project/lily/) - A wrapped Lotus node designed specifically for indexing the Filecoin blockchain.\n- [Lotus Docker images](https://github.com/glifio/filecoin-docker)\n\n### \ud83e\udded Filecoin explorers\n- [Filfox](https://filfox.info/)\n- [Beryx Explorer](https://beryx.zondax.ch/)\n- [Starboard FVM explorer](https://fvm.starboard.ventures/)\n- [Filscan](https://filscan.io/)\n- [dev.storage explorer](https://dev.storage/)\n- [Glif Explorer](https://explorer.glif.io/)\n\n### Apps \ud83d\udcf1\n- [Station](https://www.filstation.app/)\n\n### \ud83d\udc5b Wallets\n- [Brave Wallet](https://brave.com/wallet/)\n- [GLIF Wallet](https://wallet.glif.io/)\n\n## FVM(Filecoin Virtual Machine)\n\n\ud83d\udce2 **[FVM cheatsheet](./fvm.md)** - for builders/devs to get started building on FVM.\n\n### \ud83d\udcc4 Introduction\n\n- [FVM Docs](https://docs.filecoin.io/fvm)\n- [What is FEVM](https://docs.filecoin.io/smart-contracts/fundamentals/filecoin-evm-runtime/) - Ethereum-compatible FVM.\n- [Quickstart with Remix](https://docs.filecoin.io/developers/smart-contracts/quickstart/) - Tutorial on deploying your first FEVM actor.\n\n### \ud83c\udfeb FVM starter kits\n\n- [FEVM Hardhat Kit](https://github.com/filecoin-project/FEVM-Hardhat-Kit) - A starter hardhat project for developing, deploying, and testing Solidity smart contracts on the FEVM.\n- [FEVM Foundry Kit](https://github.com/filecoin-project/fevm-foundry-kit) - A starter foundry project for developing, deploying, and testing Solidity smart contracts on the FEVM.\n- [FVM Deal Making starter kit](https://github.com/filecoin-project/fvm-starter-kit-deal-making) - use the client contract here to make a deal proposal directly with the Storage Provider for data >4GB.\n- [DataDao starter kit](https://github.com/filecoin-project/fevm-data-dao-kit) - quickly spin up a DataDAO using client contract & OpenZepplin's  Dao contracts.\n\n### \ud83e\uddf0 FVM Libraries and Tools\n\n- [Filecoin.solidity](https://docs.zondax.ch/fevm/filecoin-solidity/) - Solidity library for FEVM development to call methods on system/built-in actors on Filecoin.\n- [ref-fvm](https://github.com/filecoin-project/ref-fvm) - Reference Filecoin VM implementation\n- [fvm-rs-sdk](https://github.com/polyphene/fvm-rs-sdk) - FVM Rust SDK for building actors\n- [FVM AssemblyScript SDK](https://github.com/Zondax/fvm-as-sdk)\n- [FVM Go SDK](https://github.com/ipfs-force-community/go-fvm-sdk)\n\n### \ud83e\udd9d FVM Other resources\n\n- [FVM Conceptual Overview](https://hackernoon.com/the-filecoin-virtual-machine-everything-you-need-to-know)\n- [FVM resources list from Protocol Labs](https://www.notion.so/Filecoin-Virtual-Machine-FVM-Developer-Resources-94cabfd650184f4b9664bd4974e4d329)\n- [EVM to FVM Address Management (F4 Addressing)](https://drive.google.com/file/d/17ngqxflu9B-gBqVl--5KqVhXsTLhkWtJ/view)\n- [FEVM Technical Overview presentation](https://www.youtube.com/watch?v=ybR9sYlKkOs)\n\n## Resources\n\n### \ud83d\udcf0 Articles\n- [How storage and retrieval deals work on Filecoin](https://filecoin.io/blog/posts/how-storage-and-retrieval-deals-work-on-filecoin/)\n\n### \ud83d\udcf9 Videos\n- [Filecoin Foundation YouTube channel](https://www.youtube.com/@filecoinfoundation) - Talks from Filecoin conferences/events\n- [Filecoin Project YouTube channel](https://www.youtube.com/@filecoinfoundation) - Talks/recordings from the Filecoin ecosystem\n- [How Filecoin Actors Work](https://www.youtube.com/watch?v=9JbwbTPonv0) - Deep dive into the actors by [zenground0](https://github.com/ZenGround0)\n- [The EVM-compatibility of FVM aka FEVM](https://www.youtube.com/watch?v=lgUMVhM3FIM)\n\n### \ud83e\udd9d Other resources\n- [Launchpad Curriculum](https://curriculum.pl-launchpad.io/) - PL Launchpad bootcamp resources\n\n", "release_dates": []}, {"name": "bellperson", "description": "zk-SNARK library", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# bellperson [![Crates.io](https://img.shields.io/crates/v/bellperson.svg)](https://crates.io/crates/bellperson)\n\n> This is a fork of the great [bellman](https://github.com/zkcrypto/bellman) library.\n\n`bellman` is a crate for building zk-SNARK circuits. It provides circuit traits\nand primitive structures, as well as basic gadget implementations such as\nbooleans and number abstractions.\n\n## Backend\n\nThere is currently one backend available for the implementation of Bls12 381:\n- [`blstrs`](https://github.com/filecoin-project/blstrs) - optimized with hand tuned assembly, using [blst](https://github.com/supranational/blst)\n\n## GPU\n\nThis fork contains GPU parallel acceleration to the FFT and Multiexponentation algorithms in the groth16 prover codebase under the compilation features `cuda` and `opencl`.\n\n### Requirements\n- NVIDIA (Turing or newer) or \n- AMD GPU Graphics Driver (OpenCL)\n\n( For AMD devices we recommend [ROCm](https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html) )\n\n### Environment variables\n\nThe gpu extension contains some env vars that may be set externally to this library.\n\n- `BELLMAN_NO_GPU`\n\n    Will disable the GPU feature from the library and force usage of the CPU.\n\n    ```rust\n    // Example\n    env::set_var(\"BELLMAN_NO_GPU\", \"1\");\n    ```\n\n- `BELLMAN_VERIFIER`\n\n    Chooses the device in which the batched verifier is going to run. Can be `cpu`, `gpu` or `auto`.\n\n    ```rust\n    Example\n    env::set_var(\"BELLMAN_VERIFIER\", \"gpu\");\n    ```\n\n- `RUST_GPU_TOOLS_CUSTOM_GPU`\n\n    Will allow for adding a GPU not in the tested list. This requires researching the name of the GPU device and the number of cores in the format `[\"name:cores\"]`.\n\n    ```rust\n    // Example\n    env::set_var(\"RUST_GPU_TOOLS_CUSTOM_GPU\", \"GeForce RTX 2080 Ti:4352, GeForce GTX 1060:1280\");\n    ```\n\n- `BELLMAN_CPU_UTILIZATION`\n\n    Can be set in the interval [0,1] to designate a proportion of the multiexponenation calculation to be moved to cpu in parallel to the GPU to keep all hardware occupied.\n\n    ```rust\n    // Example\n    env::set_var(\"BELLMAN_CPU_UTILIZATION\", \"0.5\");\n    ```\n\n- `RAYON_NUM_THREADS`\n\n    Restricts the number of threads used in the library to roughly that number (best effort). In the past this was done using `BELLMAN_NUM_CPUS` which is now deprecated. The default is set to the number of logical cores reported on the machine.\n\n    ```rust\n    // Example\n    env::set_var(\"RAYON_NUM_THREADS\", \"6\");\n    ```\n\n - `EC_GPU_NUM_THREADS`\n\n    Restricts the number of threads used by the FFT and multiexponentiation calculations. In the past this setting was shared with `RAYON_NUM_THREADS`, now they are separate settings that can be controlled independently. The default is set to the number of logical cores reported on the machine.\n\n    ```rust\n    // Example\n    env::set_var(\"EC_GPU_NUM_THREADS\", \"6\");\n    ```\n\n - `BELLMAN_GPU_FRAMEWORK`\n\n     Bellman can be compiled with both, OpenCL and CUDA support. When both are available, `BELLMAN_GPU_FRAMEWORK` can be used to set it to a specific one, either `cuda` or `opencl`.\n\n    ```rust\n    // Example\n    env::set_var(\"BELLMAN_GPU_FRAMEWORK\", \"opencl\");\n    ```\n\n - `BELLMAN_CUDA_NVCC_ARGS`\n\n     By default the CUDA kernel is compiled for several architectures, which may take a long time. `BELLMAN_CUDA_NVCC_ARGS` can be used to override those arguments. The input and output file will still be automatically set.\n\n    ```rust\n    // Example for compiling the kernel for only the Turing architecture\n    env::set_var(\"BELLMAN_CUDA_NVCC_ARGS\", \"--fatbin --gpu-architecture=sm_75 --generate-code=arch=compute_75,code=sm_75\");\n    ```\n\n - `BELLPERSON_GPUS_PER_LOCK`\n\n    Restricts the number of devices used by the FFT and multiexponentiation calculations.\n    - If it's not set, a single lock will be created, and each calculation uses all devices\n    - If BELLPERSON_GPUS_PER_LOCK = 0, no lock will be created, each calculation uses all devices, and each device can run multiple calculations. **WARNING**: this option can break things easily. Each kernel expects that it's run without anything else running on the GPU at the same time. If two kernels run at the same time, they might interfere with each other and lead to crashes or wrong results.\n    - If BELLPERSON_GPUS_PER_LOCK > 0, create a lock for each device, each calculation uses BELLPERSON_GPUS_PER_LOCK (up to device number) devices\n\n    ```rust\n    // Example\n    env::set_var(\"BELLPERSON_GPUS_PER_LOCK\", \"0\");\n    env::set_var(\"BELLPERSON_GPUS_PER_LOCK\", \"1\");\n    ```\n\n#### Supported / Tested Cards\n\nDepending on the size of the proof being passed to the gpu for work, certain cards will not be able to allocate enough memory to either the FFT or Multiexp kernel. Below are a list of devices that work for small sets. In the future we will add the cuttoff point at which a given card will not be able to allocate enough memory to utilize the GPU.\n\n| Device Name            | Cores | Comments       |\n|------------------------|-------|----------------|\n| Quadro RTX 6000        | 4608  |                |\n| TITAN RTX              | 4608  |                |\n| Tesla V100             | 5120  |                |\n| Tesla P100             | 3584  |                |\n| Tesla T4               | 2560  |                |\n| Quadro M5000           | 2048  |                |\n| GeForce RTX 3090       |10496  |                |\n| GeForce RTX 3080       | 8704  |                |\n| GeForce RTX 3070       | 5888  |                |\n| GeForce RTX 2080 Ti    | 4352  |                |\n| GeForce RTX 2080 SUPER | 3072  |                |\n| GeForce RTX 2080       | 2944  |                |\n| GeForce RTX 2070 SUPER | 2560  |                |\n| GeForce GTX 1080 Ti    | 3584  |                |\n| GeForce GTX 1080       | 2560  |                |\n| GeForce GTX 2060       | 1920  |                |\n| GeForce GTX 1660 Ti    | 1536  |                |\n| GeForce GTX 1060       | 1280  |                |\n| GeForce GTX 1650 SUPER | 1280  |                |\n| GeForce GTX 1650       |  896  |                |\n|                        |       |                |\n| gfx1010                | 2560  | AMD RX 5700 XT |\n| gfx906                 | 7400  | AMD RADEON VII |\n|------------------------|-------|----------------|\n\n### Running Tests\n\n```bash\nRUSTFLAGS=\"-C target-cpu=native\" cargo test --release --all\n```\n\nTo run using CUDA and OpenCL, you can use:\n\n```bash\nRUSTFLAGS=\"-C target-cpu=native\" cargo test --release --all --features cuda,opencl\n```\n\nTo run the multiexp_consistency test you can use:\n\n```bash\nRUST_LOG=info cargo test --features cuda,opencl -- --exact multiexp::gpu_multiexp_consistency --nocapture\n```\n\n### Considerations\n\nBellperson uses `rust-gpu-tools` as its CUDA/OpenCL backend, therefore you may see a\ndirectory named `~/.rust-gpu-tools` in your home folder, which contains the\ncompiled binaries of OpenCL kernels used in this repository.\n\n### Experimental\n\nThe instance aggregation provided by `groth16::aggregate::prove::aggregate_proofs_and_instances()` has not yet been\naudited so should be used with caution. It is not recommended to use instance aggregation in production until it has\nbeen audited.\n\n## License\n\nLicensed under either of\n\n- Apache License, Version 2.0, |[LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "bellperson-gadgets", "description": "Additional gadgets for bellperson", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Gadgets for `bellperson`\n\n> The code is based on [alex-ozdemir/bellman-bignat](https://github.com/alex-ozdemir/bellman-bignat) and has been updated to work with bellperson and newer Rust. It also includes gadgets from [matter-labs/sapling-crypto](https://github.com/matter-labs-archive/sapling-crypto).\n\nThis is a library providing different gadgets for use with `bellperson`, including multiprecision arithmetic and RSA accumulators.\n\n## Available Gadgets\n\n<TODO>\n\n## Development\n\nTest can be run using `cargo`.\n\n## Examples\n\n<TODO>\n\n## License\n\nLicensed under either of\n\n- Apache License, Version 2.0, |[LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "benchmarks", "description": "A place for community-submitted Filecoin benchmarks", "language": "JavaScript", "license": null, "readme": "# Hardware benchmarks on the Filecoin testnet\n\nThis repo is a place to collect benchmarks collected from the Filecoin community. Submissions are reviewed manually, but we try to be quick. You can review the current benchmarks [here](https://filecoin-benchmarks.on.fleek.co/).\n\n## Running a benchmark\n\n**IT IS IMPORTANT TO BUILD LOTUS FROM SOURCE TO TAKE ADVANTAGE OF ALL AVAILABLE OPTIMIZATIONS**\n\nThe information below assumes you are already able to build lotus from source. The instructions below detail how to natively compile the filecoin-ffi when building lotus and its tools.\n\nIf you have not previosuly built lotus from source, please see the [lotus docs](https://docs.lotu.sh/en+install-lotus-ubuntu).\n\nTo build the filecoin-ffi from source you will need to have `rustup` installed. You can install it by following the instructions at [https://rustup.rs/](https://rustup.rs/).\n\nYou will need **600GB** of free disk space available, replace the value of `/storage` with an appropriate path in the last command.\n\n**Build and Run**\n\n```\n$ git clone --branch master https://github.com/filecoin-project/lotus.git\n$ cd lotus\n$ env RUSTFLAGS=\"-C target-cpu=native -g\" FFI_BUILD_FROM_SOURCE=1 make clean deps bench\n$ env FIL_PROOFS_MAXIMIZE_CACHING=1 RUST_LOG=info TMPDIR=/storage ./bench sealing --storage-dir /storage/bench --sector-size 32GiB 2>&1 | tee bench.log\n```\n\n## Adding a benchmark to the list\n\n- Fork the repo\n- Create a new file in the `benchmarks/{YOUR_VERSION}` folder. Copy the format of `benchmarks/template.yaml`.\n- Submit a pull request\n\n## Dev server\n\nIf you want to test your addition locally or otherwise play around, `yarn dev` and you're off to the races.\n\n## Build\n\nRunning `yarn parse-data` turns the YAML files into the JSON files used during the build process. Adding a new `.yaml` file does _not_ trigger a JSON rebuild automatically.\n\n## Deploy\n\nAny new push to `master` triggers a rebuild and deploy.\n", "release_dates": []}, {"name": "biscuit-dao", "description": "An example DataDAO, built with Filecoin primitives.", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# BiscuitDAO\n\nThis is a fun example repo of a DataDAO called BiscuitDAO (Biscuit is name of the Filecoin Corgi Mascot)! This repo is meant to give a simple example of how a simple DataDAO might be structured. To learn more about where this project idea came from and what a DataDAO is, checkout [this video](https://www.youtube.com/watch?v=o58CMUURDEo).\n\n\nIf you're completely new to DAO's you may want to start out with [fevm-data-dao-kit](https://github.com/filecoin-project/fevm-data-dao-kit). \n\n## Using This Repo\n\nStart out in the \"hardhat\" directory and follow the readme there to begin deploying and interacting with contracts.\n\nFrontend directory on the way!\n\n![Biscuit the Corgi](https://pin.ski/3ZndRUt)", "release_dates": []}, {"name": "bitsets", "description": "Benchmark different bitset algorithms for their size savings.", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Bitsets\n\n> Benchmark different bitset algorithms for their size savings.\n\n\n## Running\n\n```sh\n> cargo run\n```\n", "release_dates": []}, {"name": "bls-signatures", "description": "BLS Signatures in Rust", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# BLS Signatures\n\n[![CircleCI][circleci-shield]][circleci] [![License][license-shield]][license]\n\n> Implementation of BLS signatures in pure Rust.\n\n\n## Development\n\n### BLST Portability\n\nTo enable the portable feature when building blst dependencies, use the 'blst-portable' feature: `--features blst-portable`.\n\n### Tests\n\n```\n> cargo test\n```\n\n### Benchmarks\n\n```\n> cargo bench\n```\n\n### Examples\n\n```\n# Verify 10,000 aggregated signatures\n> cargo run --example verify --release\n```\n\n## LICENSE\n\nMIT or Apache 2.0\n\n## Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in bls-signatures by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n\n[circleci-shield]: https://img.shields.io/circleci/project/github/filecoin-project/bls-signatures.svg?style=flat-square\n[circleci]: https://circleci.com/gh/filecoin-project/bls-signatures\n[license-shield]: https://img.shields.io/badge/License-MIT%2FApache2.0-green.svg?style=flat-square\n[license]: https://github.com//filecoin-project/bls-signatures/blob/master/README.md#LICENSE\n[crate-shield]: https://img.shields.io/crates/v/accumulators.svg?style=flat-square\n[crate]: https://crates.io/crates/accumulators\n", "release_dates": ["2021-09-30T10:30:22Z", "2020-06-26T13:28:40Z", "2020-06-26T13:18:28Z", "2020-06-08T11:15:26Z", "2020-04-30T15:03:38Z", "2020-04-30T15:04:48Z", "2020-03-29T21:23:55Z", "2020-02-27T01:05:50Z", "2020-02-25T22:55:50Z", "2020-02-24T18:52:17Z", "2020-02-10T22:20:53Z", "2020-02-10T22:22:26Z", "2019-11-27T13:37:14Z", "2019-11-27T13:39:05Z", "2019-11-26T20:49:00Z", "2019-11-26T21:02:52Z", "2019-11-26T21:03:49Z", "2019-11-26T20:36:56Z", "2019-11-03T18:24:42Z", "2019-10-09T20:50:28Z", "2019-09-19T19:33:17Z", "2019-08-13T22:44:31Z", "2019-05-02T16:42:23Z", "2019-04-17T21:08:44Z", "2019-03-22T17:22:18Z"]}, {"name": "blst", "description": "BLS12-381 signature library", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "[![Build Status](https://travis-ci.org/supranational/blst.svg?branch=master)](https://travis-ci.org/supranational/blst) [![ubuntu-latest](https://github.com/supranational/blst/workflows/ubuntu-latest/badge.svg)](https://github.com/supranational/blst/actions)\n<div align=\"left\">\n  <img src=blst_logo_small.png>\n</div>\n\n# blst\nblst (pronounced 'blast') is a BLS12-381 signature library focused on performance and security. It is written in C and assembly.\n\n## Table of Contents\n\n  * [Status](#status)\n  * [General notes on implementation](#general-notes-on-implementation)\n  * [Platform and Language Compatibility](#platform-and-language-compatibility)\n  * [API](#api)\n  * [Introductory Tutorial](#introductory-tutorial)\n    + [Public Keys and Signatures](#public-keys-and-signatures)\n    + [Signature Verification](#signature-verification)\n    + [Signature Aggregation](#signature-aggregation)\n  * [Build](#build)\n    + [C static library](#c-static-library)\n  * [Language-specific notes](#language-specific-notes)\n    + [Go](#go)\n    + [Rust](#rust)\n  * [Repository Structure](#repository-structure)\n  * [Performance](#performance)\n  * [License](#license)\n\n## Status\n**This library has not yet been audited. Use at your own risk.**\n\nFormal verification of this library is planned and will utilize [Cryptol](https://www.cryptol.net) and [Coq](https://coq.inria.fr/) to verify field, curve, and bulk signature operations.\n\nThis library is compliant with the following IETF draft specifications:\n- [IETF BLS Signature V2](https://tools.ietf.org/html/draft-irtf-cfrg-bls-signature)\n- [IETF Hash-to-Curve V9](https://tools.ietf.org/html/draft-irtf-cfrg-hash-to-curve)\n\nThe serialization formatting is implemented according to [Appendix A. BLS12-381](https://tools.ietf.org/html/draft-irtf-cfrg-bls-signature-02#appendix-A) of the IETF spec that calls for using the [ZCash definition](https://github.com/zkcrypto/pairing/blob/master/src/bls12_381/README.md#serialization).\n\n## General notes on implementation\nThe goal of the blst library is to provide a foundational component for applications and other libraries that require high performance and formally verified BLS12-381 operations. With that in mind some decisions are made to maximize the public good beyond BLS12-381. For example, the field operations are optimized for general 384-bit usage, as opposed to tuned specifically for the 381-bit BLS12-381 curve parameters. With the formal verification of these foundational components, we believe they can provide a reliable building block for other curves that would like high performance and an extra element of security.\n\nThe library deliberately abstains from dealing with memory management and multi-threading, with the rationale that these ultimately belong in language-specific bindings. Another responsibility that is left to application is random number generation. All this in the name of run-time neutrality, which makes integration into more stringent environments like Intel SGX or ARM TrustZone trivial.\n\n## Platform and Language Compatibility\n\nThis library supports x86_64 and ARM64 hardware platforms, and Linux, Mac, and Windows operating systems.\n\nThis repository includes explicit bindings for:\n- [Go](bindings/go)\n- [Rust](bindings/rust)\n\nUnless deemed appropriate to implement, bindings for other languages will be provided using [SWIG](http://swig.org). Proof-of-concept scripts are available for:\n- [Python](bindings/python)\n- [Java](bindings/java)\n\n## API\n\nThe blst API is defined in the C header [bindings/blst.h](bindings/blst.h). The API can be categorized as follows, with some example operations:\n- Field Operations (add, sub, mul, neg, inv, to/from Montgomery)\n- Curve Operations (add, double, mul, to/from affine, group check)\n- Intermediate (hash to curve, pairing, serdes)\n- BLS12-381 signature (sign, verify, aggregate)\n\nNote: there is also an auxiliary header file, [bindings/blst_aux.h](bindings/blst_aux.h), that is used as a staging area for experimental interfaces that may or may not get promoted to blst.h.\n\n## Introductory Tutorial\n\nProgramming is understanding, and understanding implies mastering the lingo. So we have a pair of additive groups being mapped to multiplicative one... What does it mean? Well, this tutorial is not about explaining that, but rather about making the connection between what you're supposed to know about [pairing-based cryptography](https://en.wikipedia.org/wiki/Pairing-based_cryptography) and the interface provided by the library.\n\n### Public Keys and Signatures\n\nWe have two elliptic curves, E1 and E2, points on which are contained in `blst_p1` and `blst_p2`, or `blst_p1_affine` and `blst_p2_affine` structures. Elements in the multiplicative group are held in a `blst_fp12` structure. One of the curves, or more specifically, a subset of points that form a cyclic group, is chosen for public keys, and another, for signatures. The choice is denoted by the subroutines' suffixes, `_pk_in_g1` or `_pk_in_g2`. The most common choice appears to be the former, that is, `blst_p1` for public keys, and `blst_p2` for signatures. But it all starts with a secret key...\n\nThe secret key is held in a 256-bit `blst_scalar` structure which can be instantiated with either [`blst_keygen`](https://tools.ietf.org/html/draft-irtf-cfrg-bls-signature#section-2.3), or deserialized with `blst_scalar_from_bendian` or `blst_scalar_from_lendian` from a previously serialized byte sequence. It shouldn't come as surprise that there are two uses for a secret key:\n\n- generating the associated public key, either with `blst_sk_to_pk_in_g1` or `blst_sk_to_pk_in_g2`;\n- performing a sign operation, either with `blst_sign_pk_in_g1` or `blst_sign_pk_in_g2`;\n\nAs for signing, unlike what your intuition might suggest, `blst_sign_*` doesn't sign a message, but rather a point on the corresponding elliptic curve. You can obtain this point from a message by calling `blst_hash_to_g2` or `blst_encode_to_g2` (see the [IETF hash-to-curve](https://tools.ietf.org/html/draft-irtf-cfrg-hash-to-curve#section-3) draft for distinction). Another counter-intuitive aspect is the apparent g1 vs. g2 naming mismatch, in the sense that `blst_sign_pk_in_g1` accepts output from `blst_hash_to_g2`, and `blst_sign_pk_in_g2` accepts output from `blst_hash_to_g1`. This is because, as you should recall, public keys and signatures come from complementary groups.\n\nNow that you have a public key and signature, as points on corresponding elliptic curves, you can serialize them with `blst_p1_serialize`/`blst_p1_compress` and `blst_p2_serialize`/`blst_p2_compress` and send the resulting byte sequences over the network for deserialization/uncompression and verification.\n\n### Signature Verification\n\nEven though there are \"single-shot\" `blst_core_verify_pk_in_g1` and `blst_core_verify_pk_in_g2`, you should really familiarize yourself with the more generalized pairing interface. `blst_pairing` is an opaque structure, and the only thing you know about it is `blst_pairing_sizeof`, which is how much memory you're supposed to allocate for it. In order to verify an aggregated signature for a set of public keys and messages, or just one[!], you would:\n```\nblst_pairing_init(ctx, hash_or_encode, domain_separation_tag);\nblst_pairing_aggregate_pk_in_g1(ctx, PK[0], aggregated_signature, message[0]);\nblst_pairing_aggregate_pk_in_g1(ctx, PK[1], NULL, message[1]);\n...\nblst_pairing_commit(ctx);\nresult = blst_pairing_finalverify(ctx, NULL);\n```\n**The essential point to note** is that it's the caller's responsibility to ensure that public keys are group-checked with `blst_p1_affine_in_g1`. This is because it's a relatively expensive operation and it's naturally assumed that the application would cache the check's outcome. Signatures are group-checked internally. Not shown in the pseudo-code snippet above, but `aggregate` and `commit` calls return `BLST_ERROR` denoting success or failure in performing the operation. Call to `finalverify`, on the other hand, returns boolean.\n\nAnother, potentially more useful usage pattern is:\n```\nblst_p2_affine_in_g2(signature);\nblst_aggregated_in_g2(gtsig, signature);\nblst_pairing_init(ctx, hash_or_encode, domain_separation_tag);\nblst_pairing_aggregate_pk_in_g1(ctx, PK[0], NULL, message[0]);\nblst_pairing_aggregate_pk_in_g1(ctx, PK[1], NULL, message[1]);\n...\nblst_pairing_commit(ctx);\nresult = blst_pairing_finalverify(ctx, gtsig);\n```\nWhat is useful about it is that `aggregated_signature` can be handled in a separate thread. And while we are at it, aggregate calls can also be executed in different threads. This naturally implies that each thread will operate on its own `blst_pairing` context, which will have to be combined with `blst_pairing_merge` as threads join.\n\n### Signature Aggregation\n\nAggregation is a trivial operation of performing point additions, with `blst_p2_add_or_double_affine` or `blst_p1_add_or_double_affine`. Note that the accumulator is a non-affine point.\n\n---\n\nThat's about what you need to know to get started with nitty-gritty of actual function declarations.\n\n## Build\nThe build process is very simple and only requires a C complier. It's integrated into the Go and Rust ecosystems, so that respective users would go about as they would with any other external module. Otherwise, a binary library would have to be compiled.\n\n### C static library\nA static library called libblst.a can be built in the current working directory of the user's choice:\n\nLinux, Mac, and Windows (in MinGW or Cygwin environments)\n```\n/some/where/build.sh\n```\n\nWindows (Visual C)\n```\n\\some\\where\\build.bat\n```\n\nIf final application crashes with an \"illegal instruction\" exception [after copying to another system], pass `\u2011D__BLST_PORTABLE__` on `build.sh` command line. If you don't use build.sh, complement the `CFLAGS` environment variable with the said command line option. If you compile a Go application, you will need to modify the `CGO_CFLAGS` variable instead. Alternatively, if you compile a Rust application on an older Intel system, but will execute it on a newer one, consider instead adding `\u2011D__ADX__` to `CFLAGS` for better performance.\n\n## Language-specific notes\n\n### [Go](bindings/go)\nThere are two primary modes of operation that can be chosen based on type definitions in the application.\n\nFor minimal-pubkey-size operations:\n```\ntype PublicKey = blst.P1Affine\ntype Signature = blst.P2Affine\ntype AggregateSignature = blst.P2Aggregate\ntype AggregatePublicKey = blst.P1Aggregate\n```\n\nFor minimal-signature-size operations:\n```\ntype PublicKey = blst.P2Affine\ntype Signature = blst.P1Affine\ntype AggregateSignature = blst.P1Aggregate\ntype AggregatePublicKey = blst.P2Aggregate\n```\n\nFor more details see the Go binding [readme](bindings/go/README.md).\n\n### [Rust](bindings/rust)\n[`blst`](https://crates.io/crates/blst) is the Rust binding crate.\n\nTo use min-pk version:\n```\nuse blst::min_pk::*;\n```\n\nTo use min-sig version:\n```\nuse blst::min_sig::*;\n```\n\nFor more details see the Rust binding [readme](bindings/rust/README.md).\n\n## Repository Structure\n\n**Root** - Contains various configuration files, documentation, licensing, and a build script\n* **Bindings** - Contains the files that define the blst interface\n    * blst.h - provides C API to blst library\n    * blst_aux.h - contains experimental functions not yet committed for long-term maintenance\n    * blst.hpp - provides foundational class-oriented C++ interface to blst library\n    * blst.swg - provides SWIG definitions for creating blst bindings for other languages, such as Java and Python\n    * **Go** - folder containing Go bindings for blst, including tests and benchmarks\n        * **Hash_to_curve**: folder containing test for hash_to_curve from IETF specification\n    * **Java** - folder containing an example of how to use SWIG Java bindings for blst\n    * **Python** - folder containing an example of how to use SWIG Python bindings for blst\n    * **Rust** - folder containing Rust bindings for blst, including tests and benchmarks\n* **Src** - folder containing C code for lower level blst functions such as field operations, extension field operations, hash-to-field, and more\n    * **Asm** - folder containing Perl scripts that are used to generate assembly code for different hardware platforms including x86 with ADX instructions, x86 without ADX instructions, and ARMv8, and [ABI](https://en.wikipedia.org/wiki/Application_binary_interface)[1]\n* **Build** - this folder containing a set of pre-generated assembly files for a variety of operating systems and maintenance scripts.\n    * **Coff** - assembly code for use on Window systems with GNU toolchain\n    * **Elf** - assembly code for use on Unix systems\n    * **Mach-o** - assembly code for use on Apple operating systems\n    * **Win64** - assembly code for use on Windows systems with Microsoft toolchain\n\n[1]: See [refresh.sh](build/refresh.sh) for usage. This method allows for simple reuse of optimized assembly across various platforms with minimal effort.\n\n## Performance\nCurrently both the [Go](bindings/go) and [Rust](bindings/rust) bindings provide benchmarks for a variety of signature related operations.\n\n## License\nThe blst library is licensed under the [Apache License Version 2.0](LICENSE) software license.\n", "release_dates": []}, {"name": "blstrs", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# `blstrs`\n\n> Implementation of BLS12-381 pairing-friendly elliptic curve construction, using the [blst](https://github.com/supranational/blst) library as backend.\n\n## Pronounciation\n\nMost important section, the name is pronounced `blasters`.\n\n## Supported Platforms\n\nDue to the assembly based nature of the implementation in `blst`, currently only the following architectures are supported\n\n- `x86_64`,\n- `aarch64`.\n\n## BLST Portability\n\nTo enable portable features when building the blst dependency, use the 'portable' feature: `--features portable`.\n\n\n## Benchmarking\n\n```\n$ cargo bench --features __private_bench\n```\n\n\n## BLS12 Parameterization\n\nBLS12 curves are parameterized by a value *x* such that the base field modulus *q* and subgroup *r* can be computed by:\n\n* q = (x - 1)<sup>2</sup> ((x<sup>4</sup> - x<sup>2</sup> + 1) / 3) + x\n* r = (x<sup>4</sup> - x<sup>2</sup> + 1)\n\nGiven primes *q* and *r* parameterized as above, we can easily construct an elliptic curve over the prime field F<sub>*q*</sub> which contains a subgroup of order *r* such that *r* | (*q*<sup>12</sup> - 1), giving it an embedding degree of 12. Instantiating its sextic twist over an extension field F<sub>q<sup>2</sup></sub> gives rise to an efficient bilinear pairing function between elements of the order *r* subgroups of either curves, into an order *r* multiplicative subgroup of F<sub>q<sup>12</sup></sub>.\n\nIn zk-SNARK schemes, we require F<sub>r</sub> with large 2<sup>n</sup> roots of unity for performing efficient fast-fourier transforms. As such, guaranteeing that large 2<sup>n</sup> | (r - 1), or equivalently that *x* has a large 2<sup>n</sup> factor, gives rise to BLS12 curves suitable for zk-SNARKs.\n\nDue to recent research, it is estimated by many that *q* should be approximately 384 bits to target 128-bit security. Conveniently, *r* is approximately 256 bits when *q* is approximately 384 bits, making BLS12 curves ideal for 128-bit security. It also makes them ideal for many zk-SNARK applications, as the scalar field can be used for keying material such as embedded curve constructions.\n\nMany curves match our descriptions, but we require some extra properties for efficiency purposes:\n\n* *q* should be smaller than 2<sup>383</sup>, and *r* should be smaller than 2<sup>255</sup>, so that the most significant bit is unset when using 64-bit or 32-bit limbs. This allows for cheap reductions.\n* F<sub>q<sup>12</sup></sub> is typically constructed using towers of extension fields. As a byproduct of [research](https://eprint.iacr.org/2011/465.pdf) for BLS curves of embedding degree 24, we can identify subfamilies of BLS12 curves (for our purposes, where x mod 72 = {16, 64}) that produce efficient extension field towers and twisting isomorphisms.\n* We desire *x* of small Hamming weight, to increase the performance of the pairing function.\n\n## BLS12-381 Instantiation\n\nThe BLS12-381 construction is instantiated by `x = -0xd201000000010000`, which produces the largest `q` and smallest Hamming weight of `x` that meets the above requirements. This produces:\n\n* q = `0x1a0111ea397fe69a4b1ba7b6434bacd764774b84f38512bf6730d2a0f6b0f6241eabfffeb153ffffb9feffffffffaaab` (381 bits)\n* r = `0x73eda753299d7d483339d80809a1d80553bda402fffe5bfeffffffff00000001` (255 bits)\n\nOur extension field tower is constructed as follows:\n\n1. F<sub>q<sup>2</sup></sub> is constructed as F<sub>q</sub>(u) / (u<sup>2</sup> - \u03b2) where \u03b2 = -1.\n2. F<sub>q<sup>6</sup></sub> is constructed as F<sub>q<sup>2</sup></sub>(v) / (v<sup>3</sup> - \u03be) where \u03be = u + 1\n3. F<sub>q<sup>12</sup></sub> is constructed as F<sub>q<sup>6</sup></sub>(w) / (w<sup>2</sup> - \u03b3) where \u03b3 = v\n\nNow, we instantiate the elliptic curve E(F<sub>q</sub>) : y<sup>2</sup> = x<sup>3</sup> + 4, and the elliptic curve E'(F<sub>q<sup>2</sup></sub>) : y<sup>2</sup> = x<sup>3</sup> + 4(u + 1).\n\nThe group G<sub>1</sub> is the *r* order subgroup of E, which has cofactor (x - 1)<sup>2</sup> / 3. The group G<sub>2</sub> is the *r* order subgroup of E', which has cofactor (x<sup>8</sup> - 4x<sup>7</sup> + 5x<sup>6</sup> - 4x<sup>4</sup> + 6x<sup>3</sup> - 4x<sup>2</sup> - 4x + 13) / 9.\n\n### Generators\n\nThe generators of G<sub>1</sub> and G<sub>2</sub> are computed by finding the lexicographically smallest valid `x`-coordinate, and its lexicographically smallest `y`-coordinate and scaling it by the cofactor such that the result is not the point at infinity.\n\n#### G1\n\n```\nx = 3685416753713387016781088315183077757961620795782546409894578378688607592378376318836054947676345821548104185464507\ny = 1339506544944476473020471379941921221584933875938349620426543736416511423956333506472724655353366534992391756441569\n```\n\n#### G2\n\n```\nx = 3059144344244213709971259814753781636986470325476647558659373206291635324768958432433509563104347017837885763365758*u + 352701069587466618187139116011060144890029952792775240219908644239793785735715026873347600343865175952761926303160\ny = 927553665492332455747201965776037880757740193453592970025027978793976877002675564980949289727957565575433344219582*u + 1985150602287291935568054521177171638300868978215655730859378665066344726373823718423869104263333984641494340347905\n```\n\n## License\n\n<sup>\nLicensed under either of <a href=\"LICENSE-APACHE\">Apache License, Version\n2.0</a> or <a href=\"LICENSE-MIT\">MIT license</a> at your option.\n</sup>\n\n<br/>\n\n<sub>\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in this crate by you, as defined in the Apache-2.0 license, shall\nbe dual licensed as above, without any additional terms or conditions.\n</sub>\n", "release_dates": ["2020-10-08T20:20:54Z"]}, {"name": "boost", "description": "Boost is a tool for Filecoin storage providers to manage data storage and retrievals on Filecoin.", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Boost\n\nBoost is a tool for Filecoin storage providers to manage data storage and retrievals on Filecoin.\n\nSee the docs at [https://boost.filecoin.io](https://boost.filecoin.io/getting-started) to get started.\n\n## Table of Contents\n\n- [Building and Installing Boost](#building-and-installing-boost)\n- [Running Boost devnet in Docker](#running-boost-devnet-in-docker-for-development)\n- [External Contribution Guidelines](#external-contribution-guidelines)\n- [License](#license)\n\n## Building and Installing Boost\n\nCompile and install using the instructions at the `Building and installing` section in [the docs](https://boost.filecoin.io/getting-started#building-and-installing).\n\n## Running Boost devnet in Docker for development\n\n### Prerequisites\n* Install Docker - https://docs.docker.com/get-docker/\n\n### Building Docker images\n\n1. Build images from the root of the Boost repository\n\n```\nmake clean docker/all\n```\n\nIf you need to build containers using a specific version of lotus then provide the version as a parameter, e.g. `make clean docker/all lotus_version=v1.23.3`. The version must be a tag or a remote branch name of [Lotus git repo](https://github.com/filecoin-project/lotus).\nIf the branch or tag you requested does not exist in our [Github image repository](https://github.com/filecoin-shipyard/lotus-containers/pkgs/container/lotus-containers) then you can build the lotus image manually with  `make clean docker/all lotus_version=test/branch1 build_lotus=1`. We are shipping images all releases from Lotus in our [Github image repo](https://github.com/filecoin-shipyard/lotus-containers/pkgs/container/lotus-containers).\n\n### Start devnet Docker stack\n\n1. Run\n\n```\nmake devnet/up\n```\n\nIt will spin up `lotus`, `lotus-miner`, `boost`, `booster-http` and `demo-http-server` containers. All temporary data will be saved in `./docker/devnet/data` folder.\n\nThe initial setup could take up to 20 min or more as it needs to download Filecoin proof parameters. During the initial setup, it is normal to see error messages in the log. Containers are waiting for the lotus to be ready. It may timeout several times. Restart is expected to be managed by `docker`.\n\n2. Try opening the Boost GUI http://localhost:8080 . Devnet is ready to operate when the URL opens and indicates no errors on the startup page.\n\nYou can inspect the status using `cd docker/devnet && docker compose logs -f`.\n\n### Start monitoring docker stack\n\n```\ndocker plugin install grafana/loki-docker-driver:latest --alias loki --grant-all-permissions\n\ncd docker/monitoring\ndocker compose up -d\n```\n\n### Connect monitoring stack to devnet stack\n\n```\ndocker network connect devnet tempo\ndocker network connect devnet prometheus\n```\n\n### Explore Grafana / Tempo and search for traces\n\nhttp://localhost:3333 (username: `admin` ; password: `admin`)\n\n### Making a deal\n\nThe `boost` container is packed with `boost` and `lotus` clients. You can connect to the container with the command `docker compose exec boost /bin/bash` and follow instructions for [storing files with Boost guide](https://boost.filecoin.io/tutorials/how-to-store-files-with-boost-on-filecoin). But the recommended startup is to follow the semi-interactive demo first:\n\n```\n# Attach to a running boost container\nmake devnet/exec service=boost\n\n# Execute the demo script /app/sample/make-a-deal.sh\nroot@83260455bbd2:/app# ./sample/make-a-deal.sh\n```\n\nYou can also generate, dense, random cars and automatically make deals by leveraging the script at `./docker/devnet/boost/sample/random-deal.sh`. See the scripts comments for usage details.\n\n### Accessing Lotus from localhost\n\nBy default the [docker-compose.yaml](./docker-compose.yaml) does not expose any port of the `lotus` container. To access the `lotus` from a local machine:\n1. You can either expose `1234` in [docker-compose.yaml](./docker-compose.yaml) or find the IP of the `lotus` container using `docker inspect lotus | grep IPAddress` command.\n2. Get the `FULLNODE_API_INFO`\n```\ndocker exec -it lotus lotus auth api-info --perm=admin\nFULLNODE_API_INFO=eyJ...ms4:/dns/lotus/tcp/1234/http\n\ndocker exec -it lotus-miner lotus-miner auth api-info --perm=admin\nMINER_API_INFO=eyJ...UlI:/dns/lotus-miner/tcp/2345/http\n```\n3. Change the `dns/lotus/tcp/1234/http` to `ip4/<127.0.0.1 or container's IP>/tcp/1234/http` for the use in `FULLNODE_API_INFO`.\n\n### Cleaning up\n\nTo stop containers and drop everything:\n```\nmake devnet/down\n\nrm -rf ~/.cache/filecoin-proof-parameters\n```\n\n## External Contribution Guidelines\nIf you want to contribute to the Boost project, please refer to [these guidelines](./CONTRIBUTING.md). \n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/boost/blob/main/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/boost/blob/main/LICENSE-APACHE)\n", "release_dates": ["2024-01-22T15:05:44Z", "2023-11-30T15:16:04Z", "2023-11-24T15:32:52Z", "2023-11-01T17:38:52Z", "2023-10-18T20:58:33Z", "2023-08-30T17:47:07Z", "2023-08-08T09:56:30Z", "2023-07-31T16:56:10Z", "2023-07-11T09:17:05Z", "2023-07-10T08:24:04Z", "2023-06-12T09:07:18Z", "2023-06-01T16:05:03Z", "2023-05-23T15:10:55Z", "2023-05-10T08:39:57Z", "2023-04-27T14:18:05Z", "2023-04-27T14:06:02Z", "2023-04-26T13:55:17Z", "2023-04-20T12:42:19Z", "2023-04-20T08:40:19Z", "2023-04-06T19:10:16Z", "2023-03-30T08:48:38Z", "2023-03-27T14:39:42Z", "2023-03-22T14:42:46Z", "2023-03-17T16:25:10Z", "2023-03-08T17:28:58Z", "2023-03-03T15:49:08Z", "2023-03-01T20:17:53Z", "2023-02-24T13:01:47Z", "2023-02-24T12:36:51Z", "2023-02-16T12:42:01Z"]}, {"name": "boost-docs", "description": "Documentation for Boost", "language": null, "license": null, "readme": "# What is Boost?\n\nBoost is a tool for Storage Providers to manage data onboarding and retrieval on the Filecoin network. It replaces the `go-fil-markets` package in lotus with a standalone binary that runs alongside a Lotus daemon and Lotus miner.\n\nBoost exposes libp2p interfaces for making storage and retrieval deals, a web interface for managing storage deals, and a GraphQL interface for accessing and updating real-time deal information.\n\n![Web UI - Storage Deals screen](<.gitbook/assets/Boost - storage deals.png>)\n\n![Web UI - Storage Space screen](<.gitbook/assets/Boost - storage space.png>)\n\n![Web UI - Sealing Pipeline screen](<.gitbook/assets/Boost - sealing pipeline.png>)\n", "release_dates": []}, {"name": "boost-gfm", "description": "Shared Implementation of Storage and Retrieval Markets for Filecoin Node Implementations", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-fil-markets\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-fil-markets.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-fil-markets)\n[![codecov](https://codecov.io/gh/filecoin-project/go-fil-markets/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-fil-markets)\n[![GoDoc](https://godoc.org/github.com/filecoin-project/go-fil-markets?status.svg)](https://godoc.org/github.com/filecoin-project/go-fil-markets)\n\nThis repository contains modular implementations of the [storage and retrieval market subsystems][1] of Filecoin. \nThey are guided by the [v1.0 and 1.1 Filecoin specification updates](https://filecoin-project.github.io/specs/#intro__changelog). \n\nSeparating implementations into a blockchain component and one or more mining and market components presents an opportunity to encourage implementation diversity while reusing non-security-critical components.\n\n## Disclaimer: Reporting issues\n\nThis repo shared the issue tracker with lotus. Please report your issues at the [lotus issue tracker](https://github.com/filecoin-project/lotus/issues)\n\n## Components\n\n* **[storagemarket](./storagemarket)**: for finding, negotiating, and consummating deals to\n store data between clients and providers (storage miners).\n* **[retrievalmarket](./retrievalmarket)**: for finding, negotiating, and consummating deals to\n retrieve data between clients and providers (retrieval miners).\n* **[filestore](./filestore)**: a wrapper around os.File for use by pieceio, storagemarket, and retrievalmarket.\n* **[pieceio](./pieceio)**: utilities that take IPLD graphs and turn them into pieces. Used by storagemarket.\n* **[piecestore](./piecestore)**:  a database for storing deal-related PieceInfo and CIDInfo. \nUsed by storagemarket and retrievalmarket.\n\nRelated components in other repos:\n* **[go-data-transfer](https://github.com/filecoin-project/go-data-transfer)**: for exchanging piece data between clients and miners, used by storage & retrieval market modules.\n\n### Background reading\n\n* The [Markets in Filecoin][1]\nsection of the Filecoin Specification contains the canonical spec.\n\n### Technical Documentation\n* [GoDoc for Storage Market](https://godoc.org/github.com/filecoin-project/go-fil-markets/storagemarket) contains an architectural overview and robust API documentation\n* [GoDoc for Retrieval Market](https://godoc.org/github.com/filecoin-project/go-fil-markets/retrievalmarket) contains an architectural overview and robust API documentation\n\n## Installation\n```bash\ngo get \"github.com/filecoin-project/go-fil-markets/<MODULENAME>\"`\n```\n\n## Usage\nDocumentation is in the README for each module, listed in [Components](#Components).\n\n## Contributing\nIssues and PRs are welcome! Please first read the [background reading](#background-reading) and [CONTRIBUTING](.go-fil-markets/CONTRIBUTING.md) guide, and look over the current code. PRs against master require approval of at least two maintainers. \n\nDay-to-day discussion takes place in the #fil-components channel of the [Filecoin project chat](https://github.com/filecoin-project/community#chat). Usage or design questions are welcome.\n\n## Project-level documentation\nThe filecoin-project has a [community repo](https://github.com/filecoin-project/community) with more detail about our resources and policies, such as the [Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md).\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019. Protocol Labs, Inc.\n\n[1]:https://spec.filecoin.io/#section-systems.filecoin_markets\n", "release_dates": ["2023-06-26T09:35:45Z", "2023-06-20T08:51:48Z", "2023-03-27T15:47:08Z"]}, {"name": "boost-graphsync", "description": "Initial Implementation Of GraphSync Wire Protocol", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-graphsync\n\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![](https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square)](http://ipfs.io/)\n[![Coverage Status](https://codecov.io/gh/ipfs/go-graphsync/branch/master/graph/badge.svg)](https://codecov.io/gh/ipfs/go-graphsync/branch/master)\n[![Build Status](https://circleci.com/gh/ipfs/go-bitswap.svg?style=svg)](https://circleci.com/gh/ipfs/go-graphsync)\n\n> An implementation of the [graphsync protocol](https://github.com/ipld/specs/blob/master/block-layer/graphsync/graphsync.md) in go!\n\n## Table of Contents\n\n- [Background](#background)\n- [Install](#install)\n- [Usage](#usage)\n- [Architecture](#architecture)\n- [Contribute](#contribute)\n- [License](#license)\n\n## Background\n\n[GraphSync](https://github.com/ipld/specs/blob/master/block-layer/graphsync/graphsync.md) is a protocol for synchronizing IPLD graphs among peers. It allows a host to make a single request to a remote peer for all of the results of traversing an [IPLD selector](https://ipld.io/specs/selectors/) on the remote peer's local IPLD graph. \n\n`go-graphsync` provides an implementation of the Graphsync protocol in go.\n\n### Go-IPLD-Prime\n\n`go-graphsync` relies on `go-ipld-prime` to traverse IPLD Selectors in an IPLD graph. `go-ipld-prime` implements the [IPLD specification](https://github.com/ipld/specs) in go and is an alternative to older implementations such as `go-ipld-format` and `go-ipld-cbor`. In order to use `go-graphsync`, some understanding and use of `go-ipld-prime` concepts is necessary. \n\nIf your existing library (i.e. `go-ipfs` or `go-filecoin`) uses these other older libraries, you can largely use go-graphsync without switching to `go-ipld-prime` across your codebase, but it will require some translations\n\n## Install\n\n`go-graphsync` requires Go >= 1.13 and can be installed using Go modules\n\n## Usage\n\n### Initializing a GraphSync Exchange\n\n```golang\nimport (\n  graphsync \"github.com/ipfs/go-graphsync/impl\"\n  gsnet \"github.com/ipfs/go-graphsync/network\"\n  ipld \"github.com/ipld/go-ipld-prime\"\n)\n\nvar ctx context.Context\nvar host libp2p.Host\nvar lsys ipld.LinkSystem\n\nnetwork := gsnet.NewFromLibp2pHost(host)\nexchange := graphsync.New(ctx, network, lsys)\n```\n\nParameter Notes:\n\n1. `context` is just the parent context for all of GraphSync\n2. `network` is a network abstraction provided to Graphsync on top\nof libp2p. This allows graphsync to be tested without the actual network\n3. `lsys` is an go-ipld-prime LinkSystem, which provides mechanisms loading and constructing go-ipld-prime nodes from a link, and saving ipld prime nodes to serialized data\n\n### Using GraphSync With An IPFS BlockStore\n\nGraphSync provides a convenience function in the `storeutil` package for\nintegrating with BlockStore's from IPFS.\n\n```golang\nimport (\n  graphsync \"github.com/ipfs/go-graphsync/impl\"\n  gsnet \"github.com/ipfs/go-graphsync/network\"\n  storeutil \"github.com/ipfs/go-graphsync/storeutil\"\n  ipld \"github.com/ipld/go-ipld-prime\"\n  blockstore \"github.com/ipfs/go-ipfs-blockstore\"\n)\n\nvar ctx context.Context\nvar host libp2p.Host\nvar bs blockstore.Blockstore\n\nnetwork := gsnet.NewFromLibp2pHost(host)\nlsys := storeutil.LinkSystemForBlockstore(bs)\n\nexchange := graphsync.New(ctx, network, lsys)\n```\n\n### Calling Graphsync\n\n```golang\nvar exchange graphsync.GraphSync\nvar ctx context.Context\nvar p peer.ID\nvar selector ipld.Node\nvar rootLink ipld.Link\n\nvar responseProgress <-chan graphsync.ResponseProgress\nvar errors <-chan error\n\nresponseProgress, errors = exchange.Request(ctx context.Context, p peer.ID, root ipld.Link, selector ipld.Node)\n```\n\nParamater Notes:\n1. `ctx` is the context for this request. To cancel an in progress request, cancel the context.\n2. `p` is the peer you will send this request to\n3. `link` is an IPLD Link, i.e. a CID (cidLink.Link{Cid})\n4. `selector` is an IPLD selector node. Recommend using selector builders from go-ipld-prime to construct these\n\n### Response Type\n\n```golang\n\ntype ResponseProgress struct {\n  Node      ipld.Node // a node which matched the graphsync query\n  Path      ipld.Path // the path of that node relative to the traversal start\n\tLastBlock struct {  // LastBlock stores the Path and Link of the last block edge we had to load. \n\t\tipld.Path\n\t\tipld.Link\n\t}\n}\n\n```\n\nThe above provides both immediate and relevant metadata for matching nodes in a traversal, and is very similar to the information provided by a local IPLD selector traversal in `go-ipld-prime`\n\n## Contribute\n\nPRs are welcome!\n\nBefore doing anything heavy, checkout the [Graphsync Architecture](docs/architecture.md)\n\nSee our [Contributing Guidelines](https://github.com/ipfs/go-graphsync/blob/master/CONTRIBUTING.md) for more info.\n\n## License\n\nThis library is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019. Protocol Labs, Inc.\n", "release_dates": ["2023-09-21T07:33:51Z", "2023-09-20T00:17:22Z", "2023-08-25T07:48:02Z", "2023-03-27T12:01:19Z"]}, {"name": "builtin-actors", "description": "The Filecoin built-in actors", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Built-in Filecoin actors\n\nThis repo contains the code for the on-chain built-in actors that power the\nFilecoin network starting from network version 16, epoch 1960320 on 2022-07-06.\n\nThese actors are written in Rust and are designed to operate inside the\n[Filecoin Virtual Machine](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0030.md).\nA reference implementation of the latter exists at\n[filecoin-project/ref-fvm](https://github.com/filecoin-project/ref-fvm).\n\nThe build process of this repo compiles every actor into Wasm bytecode and\ngenerates an aggregate bundle to be imported by all clients. The structure of\nthis bundle is standardized. Read below for details.\n\nThis codebase was canonicalized in [FIP-0031](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0031.md).\nAs a result, this actor implementation is the only one recognized by the network\nfrom network version 16 onwards.\n\n## Pre-FVM actors\n\nActors for the following network versions prior to nv16 are implemented here as\nwell:\n\n- nv14 actors to facilitate testing.\n- nv15 actors to enable the nv15=>nv16 upgrade.\n\n## Importable bundle\n\nThe main output of this repo is a [CARv1 archive](https://ipld.io/specs/transport/car/carv1/)\nbundling all Wasm bytecode for all actors into a single file, with the following\ncharacteristics:\n\n- The CARv1 header points to a single root CID.\n- The root CID resolves to a [DAG-CBOR](https://ipld.io/specs/codecs/dag-cbor/spec/)\n  encoded block defining a `Manifest` type (defined below) containing a version\n  number for the bundle format (currently always `1`) and a CID for a\n  `ManifestPayload`.\n- The `ManifestPayload` (defined below) is contained within a DAG-CBOR encoded\n  block and defines a type that associates actor type names with their\n  corresponding CIDs.\n- The CIDs for all actors are contained within the same CARv1 archive as\n  compiled Wasm bytecode contained within RAW blocks.\n\n### Manifest [schema](https://ipld.io/docs/schemas/)\n\n```ipldsch\n# Manifest is encoded as: [version, CID]\ntype Manifest struct {\n  version Int\n  payload &ManifestPayload\n} representation tuple\n\n# ManifestPayload is encoded as: [ [\"actorkey\", CID], [\"actorkey\", CID], ... ]\n#\n# It alternatively may be interpreted as:\n#   type ManifestPayload {String : &ActorBytecode} representation listpairs\n# Or simply as a list of tuples.\ntype ManifestPayload struct {\n  system &ActorBytecode\n  init &ActorBytecode\n  cron &ActorBytecode\n  account &ActorBytecode\n  storagepower &ActorBytecode\n  storageminer &ActorBytecode\n  storagemarket &ActorBytecode\n  paymentchannel &ActorBytecode\n  multisig &ActorBytecode\n  reward &ActorBytecode\n  verifiedregistry &ActorBytecode\n  datacap &ActorBytecode\n  placeholder &ActorBytecode\n  evm &ActorBytecode\n  eam &ActorBytecode\n  ethaccount &ActorBytecode\n} representation listpairs\n\n# RAW block\ntype ActorBytecode bytes\n```\n\nPrecompiled actor bundles are provided as [release binaries][releases] in this repo. The\n[`fil_builtin_actors_bundle`](https://crates.io/crates/fil_builtin_actors_bundle) crate on\n[crates.io](https://crates.io) will not be updated.\n\n## Releasing\n\nWe release all actors, the runtime, and the state abstraction at the same time by:\n\n1. Changing the `workspace.package.version` in the top-level `Cargo.toml` file.\n2. Creating a [release][releases] in GitHub.\n\nThis will trigger an automatic bundle-build by GitHub CI, and the generated bundles will be attached to the GitHub release.\n\n## Instructions for client implementations\n\n### Obtaining an actors bundle\n\nThere are two options:\n\n1. Building from source.\n2. Downloading the precompiled release bundle from GitHub.\n\nInstructions to build from source (option 1):\n\n1. Clone the repo.\n2. Check out the relevant branch or tag (see Versioning section below).\n3. `make bundle` from the workspace root.\n\nThe bundle be written to `output/builtin-actors.car`.\n\nBoth options are compatible with automation via scripts or CI pipelines.\n\n### Integrating an actors bundle\n\nThis part is implementation-specific. Options include:\n\n1. Embedding the bundle's CARv1 bytes into the distribution's binary.\n2. Downloading CARv1 files on start (with some form of checksumming for added security).\n\n### Loading and using the actors bundle with ref-fvm\n\nOnce the implementation has validated the authenticity of the bundle, it is\nexpected to do the following:\n\n1. Import the CARv1 into the blockstore.\n2. Retain the root CID in memory, indexed by network version.\n3. Feed the root CID to ref-fvm's Machine constructor, to tell ref-fvm which\n   CodeCID maps to which built-in actor.\n\n### Multiple network version support\n\nBecause every network version may be backed by different actor code,\nimplementations should be ready to load multiple actor bundles and index them\nby network version.\n\nWhen instantiating the ref-fvm Machine, both the network version and the\ncorresponding Manifest root CID must be passed.\n\n## Versioning\n\nA fair question is how crate versioning relates to the protocol concept of\n`ActorVersion`. We adopt a policy similar to specs-actors:\n\n- Major number in crate version correlates with `ActorVersion`.\n- We generally don't use minor versions; these are always set to `0`.\n- We strive for round major crate versions to denote the definitive release for\n  a given network upgrade. However, due to the inability to predict certain\n  aspects of software engineering, this is not a hard rule and further releases\n  may be made by bumping the patch number.\n\nDevelopment versions will use qualifiers such as -rc (release candidate).\n\nAs an example of application of this policy to a v10 actor version lineage:\n\n- Unstable development versions are referenced by commit hash.\n- Stable development versions are tagged as release candidates: 10.0.0-rc1, 10.0.0-rc2, etc.\n- Definitive release: 10.0.0.\n- Patched definitive release: 10.0.1.\n- Patched definitive release: 10.0.2.\n- Network upgrade goes live with 10.0.2.\n\n## About this codebase\n\n### Relation to specs-actors\n\nThis repo supersedes [specs-actors](https://github.com/filecoin-project/specs-actors),\nand fulfils two roles:\n- executable specification of built-in actors.\n- canonical, portable implementation of built-in actors.\n\n### Credits\n\nThis codebase was originally forked from the actors v6 implementation of the\n[Forest client](https://github.com/ChainSafe/forest/), and was adapted to the\nFVM environment.\n\n## Community\n\nBecause this codebase is a common good across all Filecoin client\nimplementations, it serves as a convergence area for all Core Devs regardless\nof the implementation or project they identify with.\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the\n[Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n\nExcept the EVM precompile [test data](actors/evm/precompile-testdata), which is licensed under the\nLGPL v3 and not included in crates or build artifacts.\n\n[releases]: https://github.com/filecoin-project/builtin-actors/releases\n", "release_dates": ["2024-02-08T23:26:52Z", "2024-02-01T21:15:28Z", "2024-02-01T15:00:29Z", "2024-02-07T20:28:35Z", "2023-11-21T18:12:32Z", "2023-11-14T17:30:15Z", "2023-10-24T19:49:41Z", "2023-10-11T15:17:41Z", "2023-09-29T13:53:15Z", "2023-09-22T20:48:40Z", "2023-09-18T14:59:42Z", "2023-08-23T22:12:45Z", "2023-04-21T15:40:06Z", "2023-04-17T19:26:21Z", "2023-04-17T23:08:31Z", "2023-04-10T14:38:06Z", "2023-04-06T20:02:17Z", "2023-02-28T18:20:53Z", "2023-02-24T14:36:29Z", "2023-02-20T17:57:24Z", "2023-02-14T01:20:47Z", "2023-02-13T23:30:55Z", "2023-02-13T14:05:15Z", "2023-02-10T22:28:50Z", "2023-02-10T19:39:24Z", "2023-02-07T20:40:16Z", "2023-02-06T17:58:01Z", "2023-02-03T14:22:57Z", "2023-01-31T17:48:11Z", "2023-01-18T03:35:43Z"]}, {"name": "builtin-actors-bundler", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Built-in Filecoin Actors Bundler\n\nThis repo contains the bundler used for bundling the [built-in\nactors](https://github.com/filecoin-project/builtin-actors) into a CAR file.\n\n## Community\n\nBecause this codebase is a common good across all Filecoin client implementations, it serves as a\nconvergence area for all Core Devs regardless of the implementation or project they identify with.\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the\n[Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n", "release_dates": []}, {"name": "cache-action", "description": "Cache dependencies and build outputs in GitHub Actions", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# cache\n\nThis action allows caching dependencies and build outputs to improve workflow execution time.\n\n[![Tests](https://github.com/actions/cache/actions/workflows/workflow.yml/badge.svg)](https://github.com/actions/cache/actions/workflows/workflow.yml)\n\n## Documentation\n\nSee [\"Caching dependencies to speed up workflows\"](https://help.github.com/github/automating-your-workflow-with-github-actions/caching-dependencies-to-speed-up-workflows).\n\n## What's New\n### v3\n* Added support for caching from GHES 3.5.\n* Fixed download issue for files > 2GB during restore.\n* Updated the minimum runner version support from node 12 -> node 16.\n* Fixed avoiding empty cache save when no files are available for caching.\n* Fixed tar creation error while trying to create tar with path as `~/` home folder on `ubuntu-latest`.\n\nRefer [here](https://github.com/actions/cache/blob/v2/README.md) for previous versions\n\n## Usage\n\n### Pre-requisites\nCreate a workflow `.yml` file in your repositories `.github/workflows` directory. An [example workflow](#example-workflow) is available below. For more information, reference the GitHub Help Documentation for [Creating a workflow file](https://help.github.com/en/articles/configuring-a-workflow#creating-a-workflow-file).\n\nIf you are using this inside a container, a POSIX-compliant `tar` needs to be included and accessible in the execution path.\n\n### Inputs\n\n* `path` - A list of files, directories, and wildcard patterns to cache and restore. See [`@actions/glob`](https://github.com/actions/toolkit/tree/main/packages/glob) for supported patterns.\n* `key` - An explicit key for restoring and saving the cache\n* `restore-keys` - An ordered list of keys to use for restoring stale cache if no cache hit occurred for key. Note\n`cache-hit` returns false in this case.\n\n### Environment Variables\n* `CACHE_SKIP_SAVE` - [optional] When set to `true`, any modifications made to the restored cache will not be persisted back at the end of the step.  This environment variable can be set at any time using `echo \"CACHE_SKIP_SAVE=true\" >> $GITHUB_ENV`\n\n### Outputs\n\n* `cache-hit` - A boolean value to indicate an exact match was found for the key\n\n> See [Skipping steps based on cache-hit](#Skipping-steps-based-on-cache-hit) for info on using this output\n\n### Cache scopes\nThe cache is scoped to the key and branch. The default branch cache is available to other branches.\n\nSee [Matching a cache key](https://help.github.com/en/actions/configuring-and-managing-workflows/caching-dependencies-to-speed-up-workflows#matching-a-cache-key) for more info.\n\n### Example workflow\n\n```yaml\nname: Caching Primes\n\non: push\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Cache Primes\n      env:\n        CACHE_SKIP_SAVE: true\n      id: cache-primes\n      uses: actions/cache@v3\n      with:\n        path: prime-numbers\n        key: ${{ runner.os }}-primes\n\n    - name: Generate Prime Numbers\n      if: steps.cache-primes.outputs.cache-hit != 'true'\n      run: /generate-primes.sh -d prime-numbers\n\n    - name: Use Prime Numbers\n      run: /primes.sh -d prime-numbers\n```\n\n> Note: You must use the `cache` action in your workflow before you need to use the files that might be restored from the cache. If the provided `key` doesn't match an existing cache, a new cache is automatically created if the job completes successfully.\n\n## Implementation Examples\n\nEvery programming language and framework has its own way of caching.\n\nSee [Examples](examples.md) for a list of `actions/cache` implementations for use with:\n\n- [C# - NuGet](./examples.md#c---nuget)\n- [D - DUB](./examples.md#d---dub)\n- [Deno](./examples.md#deno)\n- [Elixir - Mix](./examples.md#elixir---mix)\n- [Go - Modules](./examples.md#go---modules)\n- [Haskell - Cabal](./examples.md#haskell---cabal)\n- [Haskell - Stack](./examples.md#haskell---stack)\n- [Java - Gradle](./examples.md#java---gradle)\n- [Java - Maven](./examples.md#java---maven)\n- [Node - npm](./examples.md#node---npm)\n- [Node - Lerna](./examples.md#node---lerna)\n- [Node - Yarn](./examples.md#node---yarn)\n- [OCaml/Reason - esy](./examples.md#ocamlreason---esy)\n- [PHP - Composer](./examples.md#php---composer)\n- [Python - pip](./examples.md#python---pip)\n- [Python - pipenv](./examples.md#python---pipenv)\n- [R - renv](./examples.md#r---renv)\n- [Ruby - Bundler](./examples.md#ruby---bundler)\n- [Rust - Cargo](./examples.md#rust---cargo)\n- [Scala - SBT](./examples.md#scala---sbt)\n- [Swift, Objective-C - Carthage](./examples.md#swift-objective-c---carthage)\n- [Swift, Objective-C - CocoaPods](./examples.md#swift-objective-c---cocoapods)\n- [Swift - Swift Package Manager](./examples.md#swift---swift-package-manager)\n\n## Creating a cache key\n\nA cache key can include any of the contexts, functions, literals, and operators supported by GitHub Actions.\n\nFor example, using the [`hashFiles`](https://help.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions#hashfiles) function allows you to create a new cache when dependencies change.\n\n```yaml\n  - uses: actions/cache@v3\n    with:\n      path: |\n        path/to/dependencies\n        some/other/dependencies\n      key: ${{ runner.os }}-${{ hashFiles('**/lockfiles') }}\n```\n\nAdditionally, you can use arbitrary command output in a cache key, such as a date or software version:\n\n```yaml\n  # http://man7.org/linux/man-pages/man1/date.1.html\n  - name: Get Date\n    id: get-date\n    run: |\n      echo \"::set-output name=date::$(/bin/date -u \"+%Y%m%d\")\"\n    shell: bash\n\n  - uses: actions/cache@v3\n    with:\n      path: path/to/dependencies\n      key: ${{ runner.os }}-${{ steps.get-date.outputs.date }}-${{ hashFiles('**/lockfiles') }}\n```\n\nSee [Using contexts to create cache keys](https://help.github.com/en/actions/configuring-and-managing-workflows/caching-dependencies-to-speed-up-workflows#using-contexts-to-create-cache-keys)\n\n## Cache Limits\n\nA repository can have up to 10GB of caches. Once the 10GB limit is reached, older caches will be evicted based on when the cache was last accessed.  Caches that are not accessed within the last week will also be evicted.\n\n## Skipping steps based on cache-hit\n\nUsing the `cache-hit` output, subsequent steps (such as install or build) can be skipped when a cache hit occurs on the key.\n\nExample:\n```yaml\nsteps:\n  - uses: actions/checkout@v3\n\n  - uses: actions/cache@v3\n    id: cache\n    with:\n      path: path/to/dependencies\n      key: ${{ runner.os }}-${{ hashFiles('**/lockfiles') }}\n\n  - name: Install Dependencies\n    if: steps.cache.outputs.cache-hit != 'true'\n    run: /install.sh\n```\n\n> Note: The `id` defined in `actions/cache` must match the `id` in the `if` statement (i.e. `steps.[ID].outputs.cache-hit`)\n\n\n## Cache Version\nCache version is unique for a combination of compression tool used for compression of cache (Gzip, Zstd, etc based on runner OS) and the path of directories being cached. If two caches have different versions, they are identified as unique cache entries. This also means that a cache created on `windows-latest` runner can't be restored on `ubuntu-latest` as cache `Version`s are different. \n\nExample: Below example will create 3 unique caches with same keys. Ubuntu and windows runners will use different compression technique and hence create two different caches. And `build-linux` will create two different caches as the `paths` are different.\n\n```yaml\njobs:\n  build-linux:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Cache Primes\n        id: cache-primes\n        uses: actions/cache@v3\n        with:\n          path: prime-numbers\n          key: primes\n\n      - name: Generate Prime Numbers\n        if: steps.cache-primes.outputs.cache-hit != 'true'\n        run: ./generate-primes.sh -d prime-numbers\n\n      - name: Cache Numbers\n        id: cache-numbers\n        uses: actions/cache@v3\n        with:\n          path: numbers\n          key: primes\n\n      - name: Generate Numbers\n        if: steps.cache-numbers.outputs.cache-hit != 'true'\n        run: ./generate-primes.sh -d numbers\n\n  build-windows:\n    runs-on: windows-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Cache Primes\n        id: cache-primes\n        uses: actions/cache@v3\n        with:\n          path: prime-numbers\n          key: primes\n\n      - name: Generate Prime Numbers\n        if: steps.cache-primes.outputs.cache-hit != 'true'\n        run: ./generate-primes -d prime-numbers\n```\n\n## Contributing\nWe would love for you to contribute to `actions/cache`, pull requests are welcome! Please see the [CONTRIBUTING.md](CONTRIBUTING.md) for more information.\n\n## License\nThe scripts and documentation in this project are released under the [MIT License](LICENSE)\n", "release_dates": []}, {"name": "cgo-blockstore", "description": null, "language": "Go", "license": null, "readme": "# CGO Blockstore\n\nThis package bridges a go-based blockstore with any CGO-based module. To use it:\n\n1. In your cgo library, import the shim implementation (e.g., `./rust`).\n2. In your go application, register a blockstore to get back a handle.\n3. Pass the handle into your cgo library.\n4. Use that handle to operate on the go-based blockstore.\n\nTake a look at the [./example](./example) directory for how all this fits together.\n", "release_dates": []}, {"name": "chain-love-website", "description": null, "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# chain-love-website", "release_dates": []}, {"name": "chain-validation", "description": "(DEPRECATED) See https://github.com/filecoin-project/test-vectors instead. (was: chain validation tools)", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# This repo is deprecated \ud83d\udd1a\n\nSee https://github.com/filecoin-project/test-vectors/ instead.\n\n---\n\n# Chain-Validation\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/chain-validation.svg?style=svg)](https://circleci.com/gh/filecoin-project/chain-validation)\n\nThis library provides tools for validating the correctness of a Filecoin implementation according to the [specification](https://github.com/filecoin-project/specs). \n\nTo maintain consensus, all Filecoin implementations must produce identical state transformations for any (state, message) pair. Further, they must implement the same block reward and chain selection logic. Validating correctness in this respect requires extensive coverage over (state, message) pairs, message sequences, and blockchain structures, and is important in maintaining the security and integrity of the network.\n\nThis library designed to allow any implementation of Filecoin to import it, implement a simple \u201cdriver\u201d interface, and then run the tests provided by the testing library, passing the driver in as the parameter. \n\nFor a comprehensive project description refer to the [Filecoin Chain-Validation Tools Design Doc](https://docs.google.com/document/d/1o0ODvpKdWsYMK_KmK-j-uPxYei6CZAZ4n_3ilQJPn4A/edit#).\n\n## Goals\n- A validation library that is implementation-independent enabling validation suites to be written once and used by different Filecoin implementations.\n- High-level script-like methods for constructing long and complex message sequences, and making semantic assertions about the expected state resulting from their application.\n- High-level script-like methods for constructing complex blockchain structures containing those messages, and making assertions about the expected state from their evaluation.\n- Validation suites with significant coverage over actor state and code paths.\n- Integration with both Go-filecoin and Lotus, enabling importing and use of the validation suites.\n- Incremental utility to both these implementations while they are in development (rather than requiring an implementation to be complete before validation is useful)\n\n## Non-Goals\n- Immediate integration with Filecoin implementations not written in Go (though there should be a path towards this). Other implementations will be expected to write code for their implementation to work with this tool.\n- High-performance execution, if this comes at a cost of timeliness or comprehensiveness\n\n## Usage\n// TODO\n", "release_dates": ["2019-12-11T22:44:59Z", "2019-12-10T18:10:16Z", "2019-12-04T23:03:21Z", "2019-12-03T23:28:30Z", "2019-12-02T22:06:26Z"]}, {"name": "circleci-exporter", "description": "CircleCI Insights Prometheus Exporter", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# CircleCI Exporter\n\nPrometheus exporter exposing [CircleCI](https://circleci.com) metrics.\n\n\nThis exporter collects the insights metrics from CircleCI - [CircleCI's insights API](https://circleci.com/docs/api/v2/#tag/Insights)\n\n## Getting Started\n\n\nWhen configuring for an organization Access tokens must have the `repo` or `admin:org` scope.\nWhen configuring for an user Access tokens must have the `user` scope.\n\n\n### Prerequisites\n\nTo run this project, you will need a [working Go environment](https://golang.org/doc/install).\n\n### Installing\n\n```shell\n$ go get -u github.com/cpanato/circleci-exporter\n```\n\n## Building\n\nBuild the sources with\n\n```shell\n$ make build\n```\n\n## Run the binary\n\n```shell\n$ ./circleci-exporter --gh.circleci-token=\"CIRCLECI_TOKEN\" --gh.circleci-org=\"Honk-org\" --gh.circleci-projects=\"My_Project_1\" --gh.circleci-projects=\"My_Project_2\"\n```\n\n## Docker\n\nYou can deploy this exporter using the [ghcr.io/cpanato/github_actions_exporter-linux-amd64](https://github.com/users/cpanato/packages/container/package/github_actions_exporter-linux-amd64) Docker image.\n\nFor example:\n\n```shell\n$ docker pull ghcr.io/cpanato/circleci-exporter:v0.1.0\n\n$ docker run -d -p 9101:9101 ghcr.io/cpanato/circleci_exporter:v0.1.0  --gh.circleci-token=\"CIRCLECI_TOKEN\" --gh.circleci-org=\"Honk-org\" --gh.circleci-projects=\"My_Project_1\" --gh.circleci-projects=\"My_Project_2\"\n```\n\n## Testing\n\n### Running unit tests\n\n```shell\n$ make test\n```\n\n## Contributing\n\nRefer to [CONTRIBUTING.md](https://github.com/cpanato/circleci-exporter/blob/master/CONTRIBUTING.md).\n\n## License\n\nApache License 2.0, see [LICENSE](https://github.com/cpanato/circleci-exporter/blob/master/LICENSE).\n", "release_dates": []}, {"name": "client-growth", "description": "Tools and processes to facilitate client growth and large data ingestion.", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Filecoin Client Growth\n\n## Introduction\nThis repo is aimed at consolidating efforts toward enabling client growth on the Filecoin network. The goal of this working group is to accelerate client acquisition by enabling smooth processes and building the necessary tools.\n\nIt serves as a place where the community can collect issues and requests on:\n - Data Ingestion - the infrastructure necessary to help clients onboard data as seamlessly as possible.\n - User Research - efforts to get feedback on client data onboarding (problems with tooling).\n - Data Analytics - analytics tooling for monitoring the progress around client growth.\n - Product Operations - managing OKRs and goals that support the efforts above.\n\n## Discussion\nDo you have questions on how to prepare your data? Can't figure out what tools to use? Use the Discussions feature to ask questions or share best practices with each other.\n", "release_dates": []}, {"name": "cod-starter-kit", "description": null, "language": "Solidity", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# FEVM Compute Over Data Kit\n\n## Cloning the Repo\n\nOpen up your terminal (or command prompt) and navigate to a directory you would like to store this code on. Once there type in the following command:\n\n\n```\ngit clone https://github.com/filecoin-project/fevm-hardhat-kit.git\ncd fevm-hardhat-kit\nyarn install\n```\n\n\nThis will clone the hardhat kit onto your computer, switch directories into the newly installed kit, and install the dependencies the kit needs to work.\n\n\n## Get a Private Key\n\nYou can get a private key from a wallet provider [such as Metamask](https://metamask.zendesk.com/hc/en-us/articles/360015289632-How-to-export-an-account-s-private-key).\n\n\n## Add your Private Key as an Environment Variable\n\nAdd your private key as an environment variable by running this command:\n\n ```\nexport PRIVATE_KEY='abcdef'\n```\n\nIf you use a .env file, don't commit and push any changes to .env files that may contain sensitive information, such as a private key! If this information reaches a public GitHub repository, someone can use it to check if you have any Mainnet funds in that wallet address, and steal them!\n\n\n## Get the Deployer Address\n\nRun this command:\n```\nyarn hardhat get-address\n```\n\nThis will show you the ethereum-style address associated with that private key and the filecoin-style f4 address (also known as t4 address on testnets)! The Ethereum address can now be exclusively used for almost all FEVM tools, including the faucet.\n\n\n## Fund the Deployer Address\n\nGo to the [Hyperspace testnet faucet](https://hyperspace.yoga/#faucet), and paste in the Ethereum address from the previous step. This will send some hyperspace testnet FIL to the account.\n\n\n## Deploy the Contracts\n\n\nType in the following command in the terminal to deploy the contracts:\n\n ```\nyarn hardhat deploy\n```\n\nThis will compile all the contracts in the contracts folder and deploy them to the Hyperspace test network automatically!\n\nKeep note of the deployed contract addresses for the next step.\n\n## Interact with the StableDiffusionCallerV2 Contract\n\nYou can interact with contracts via hardhat tasks, found in the 'tasks' folder. For example, to interact with the SimpleCoin contract:\n\nType in the following command in the terminal:\n\n ```\nyarn hardhat stable-diffusion --contract 'THE DEPLOYED CONTRACT ADDRESS HERE' --prompts 'Awesome Decentralized Storage'\n```", "release_dates": []}, {"name": "community", "description": "Filecoin community and ecosystem channels, discussion forums, and more", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Community\n\n- [Community](#community)\n  - [About](#about)\n  - [Join the Community](#join-the-community)\n    - [Forums](#forums)\n      - [Filecoin Community Forum](#filecoin-community-forum)\n      - [lotus Discussion Forum](#lotus-discussion-forum)\n      - [Filecoin Proving Subsystem Discussion](#filecoin-proving-subsystem-discussion)\n    - [Implementation Related Repo](#implementation-related-repo)\n    - [Chat](#chat)\n    - [GitHub issues](#github-issues)\n    - [Security issues and disclosures](#security-issues-and-disclosures)\n  - [Useful links](#useful-links)\n  - [Ecosystem Projects](#ecosystem-projects)\n    - [Showcase Your Project!](#showcase-your-project)\n    - [Updates and Newsletter](#updates-and-newsletter)\n    - [Filecoin Shipyard](#filecoin-shipyard)\n  - [Events](#events)\n    - [Community calls](#community-calls)\n    - [Filecoin Meetups](#filecoin-meetups)\n  - [Contributing](#contributing)\n    - [Contributing Guidelines](#contributing-guidelines)\n  - [Maintainers](#maintainers)\n  - [License](#license)\n\n## About\n\nWelcome to the Filecoin community repository! You can treat this repo as your go-to for all meta, non-code discussions in the [*Discussions Forum*](https://github.com/filecoin-project/community/discussions), documents used by multiple repositories (such as the Code of Conduct), and how to interact with the Filecoin project and other community members.\n\nTo get the latest network notifications, subscribe to [status.filecoin.io](https://status.filecoin.io).\n\nIf you are interested in discussing code or protocol design, feel free to come talk to us on our [forums](#forums), [chat channels](#chat), or in issues on our other [Filecoin project repos](https://github.com/filecoin-project).\n\n## Join the Community\n\n**> Note: Before posting to different communications channels, make sure to read the [Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md).**\n\nThe vast majority of the Filecoin Project conversations, including implementation, community support, ecosystem news, etc. take place on:\n\n- [Forums](#forums) (mainly on Github Discussions)\n- GitHub Issues (see [Implementation related repo](#impelmentation-related-repo) section below)\n- Chat (mainly on Slack) (see [Chat](#chat) section below)\n\nThe Filecoin Project is an open sourced project with a very supportive and welcoming community, where many community members are responsive in various forums and slack channels. We also have [Filecoin community ambassadors](https://github.com/filecoin-project/community/discussions/116#discussioncomment-617066) here to support you, tag their GitHub handlers in GitHub discussions or @fil-community-ambassadors in all slack channels if you have any questions!\n\nImplementation dev teams tend to check their corresponding GitHub repo issues and discussions regularly and try to respond within 5 business days.\n\nWe also push updates to the community via:\n\n- Forum - [`Network and implementations updates`](https://github.com/filecoin-project/community/discussions/categories/network-and-implementations-updates) updates and [`news and events`](https://github.com/filecoin-project/community/discussions/categories/news-and-events)\n- Filecoin blog: [https://blog.filecoin.io](https://blog.filecoin.io)\n- CryptoComputeLab blog(proof updates): [https://research.protocol.ai/groups/cryptocomputelab/](https://research.protocol.ai/groups/cryptocomputelab/)\n- Youtube: [Filecoin](https://www.youtube.com/channel/UCPyYmtJYQwxM-EUyRUTp5DA)\n- Twitter: [@Filecoin](https://twitter.com/Filecoin)\n- WeChat ID: Filecoin-Official\n\n![filecoin qr code](/images/qrcode_for_gh_da36751a6108_1280.jpg)\n\n\n### Forums\n\n#### Filecoin Community Forum\n\nWhen in doubt or curiosity, please post in [Filecoin community forum](https://github.com/filecoin-project/community/discussions)!\n\nWe love to hear what the community has to say, whether it is to:\n\n- Ask a question\n- Gather community feedback on a new feature proposal before opening an FIP \n- Share a new project you're working on\n- Find collaborators for your own community project\n- And whatever else! Honestly!\n\nThe discussion forum uses the same Code of Conduct as our other community channels. Please make sure to read this before posting.\n\n> Note: A Chinese-language community forum is also available at https://github.com/filecoin-project/community-china/discussions. It is managed by [CoinSummer](https://github.com/CoinSummer).\n\n#### lotus Discussion Forum\n\n[lotus discussion](https://github.com/filecoin-project/lotus/discussions) is an all-in-one place where you can track [lotus releases and announcements](https://github.com/filecoin-project/lotus/discussions/categories/announcement), find [tutorials](https://github.com/filecoin-project/lotus/discussions/categories/tutorials) ask questions about running[ a lotus node](https://github.com/filecoin-project/lotus/discussions/categories/syncing), [lotus miner ](https://github.com/filecoin-project/lotus/discussions/categories/miner-q-a)or lotus client, get help with troubleshooting, [share your lotus setup or thoughts](https://github.com/filecoin-project/lotus/discussions/categories/show-and-tell), chat with your fellow developers with [how to build ](https://github.com/filecoin-project/lotus/discussions/categories/developer-q-a)applications using lotus JsonRPC API and so on.\n\n\n#### Filecoin Proving Subsystem Discussion\n\nThe Filecoin Proving Subsystem (or FPS) provides the storage proofs required by the Filecoin protocol. If you have any questions regarding the current proof, feedbacks for proof performance on different machines, ideas to improve proof or implementing new proof, join the [forum here](https://github.com/filecoin-project/rust-fil-proofs/discussions)!\n\n### Implementation Related Repo\n\n### Chat\n\nVast majority of community live chat is happening in [Filecoin Project Slack](https://filecoin.io/slack). Tag @fil-community-ambassadors if you have any questions!\n\nFun channels to join once you are in the workspace:\n\n- `#fil-announcements`: This channel is for official Filecoin announcements only (including network, implementations, and ecosystem announcements). Join to get most up-to-date news. Please do not post questions or other messages here; they will be deleted! \n- `_fil-lobby`: for general Filecoin-related sharing\n- `fil-help`: ask questions here if you can't find another specific channel for your question\n- `fil-lotus`: for lotus related discussion\n- `fil-fips`: for [Filecoin Improvement Proposals](https://github.com/filecoin-project/FIPs) related discussion \n- `fil-plus`: for Filecoin Plus([notary-governance](https://github.com/filecoin-project/notary-governance)) related discussion\n- `fil-net-calibration-discuss`/`fil-net-nerpa-discuss`: for testnet disucssions\n- `fil-ecosystem-dev`: for updates and discussion about building in the Filecoin ecosystem\n- `fil-deal-market`: promote your miner as a storage provider or find your provider as a client here\n- `hackathons-help`: join this channel if you are participating any Filecoin hackathons and have questions\n\nPrimary Slack channels are bridged (automatically mirrored and read-only) to [Matrix](https://app.element.io/#/group/+filecoin:matrix.org).\n\n\n### GitHub issues\n\nIf you find something puzzling or encounter a straight-up bug in any of our repositories, please file a well-scoped issue. The issue lists for our most active repositories are below:\n\n- [`lotus`](https://github.com/filecoin-project/lotus/issues) ([contribution guide](https://github.com/filecoin-project/lotus#contribute))\n- [`venus`](https://github.com/filecoin-project/venus/issues)\n- [`specs-actors`](https://github.com/filecoin-project/specs-actors/issues)\n- [`rust-ffi-proofs`](https://github.com/filecoin-project/rust-fil-proofs)\n- [`specs`](https://github.com/filecoin-project/specs/issues)\n\nIf a repo has a Contributing Guide, please read it before filing an issue!\n\n### Security issues and disclosures\n\nAlmost anything you find that is a bug in the codebase should be filed as an issue. The exception is if you find a security vulnerability. The Filecoin protocol is still under heavy development. This means that there may be problems in our protocol design or implementations. Though Filecoin is not yet production-ready, many people are already running nodes on their machines. So we take security vulnerabilities very seriously! If you discover a security issue, please bring it to our attention right away!\n\nPlease refer to [SECURITY.md](./SECURITY.md) document found in this repo on how to best report findings and participate on the bug bounty program.\n\n## Useful links\n\nIf you are new to the Filecoin Project, below are some helpful links for you to learn more about it:\n- Official website: [https://filecoin.io](https://filecoin.io)  \n- [Filecoin Specification](https://spec.filecoin.io): contains documents, code, models, and diagrams that constitute the specification of the Filecoin Protocol.\n- [Filecoin Docs](https://docs.filecoin.io): offers all the necessary resources to learn about Filecoin, the software and the tools to contribute to the network, either as a user looking for storage, or as a miner providing it  \n\n## Ecosystem Projects\n\nIf your project uses Filecoin, you're in the Filecoin ecosystem! We'd love to see all awesome projects that are built on top of the Filecoin ecosystem to be known and get used by the Filecoin community! \n\n### Showcase Your Project!\n\nFollowing the steps below to submit your projects to be featured in this [repo](https://github.com/filecoin-project/community/tree/master/projects):\n- Create a project profile using the [project submission template](https://github.com/filecoin-project/community/blob/master/templates/project-submission-template.md). Name the file name after your project and fill in as much information as you can.  Use your project name as the file name so the community can find your project easily!\n- Create a new discussion thread in this repository's [Discussions > Project Showcase](https://github.com/filecoin-project/community/discussions/categories/project-showcase), titled `[Category] Project Name`(i.e: `[Application] Slate`). Add this link to the \"How the community can engage\" section. Use this thread to share your updates, and chat with users and potential users!\n- Once the project profile is ready, create a [PR](https://github.com/filecoin-project/community/pulls), prefix `[Project Submission]` in the title, and request a review from one of the [maintainers](#maintainers).\n- Let the maintainer know if you want your [updates](#updates-and-newsletter) to be featured in [Filecoin newsletter](https://mailchi.mp/filecoin.io/subscribe) or not in the PR description!\n- If everything looks good, the maintainer will merge the PR and voila, your project is now featured here!\n\n### Updates and Newsletter\n\nWe'd encourage all projects featured in this repo to share all of your thrilling updates with the community! Start a new comment with header `Project Name Update/Newsletter - Date` (i.e `## Slate Update - Feb, 2021`) in your project discussion to share the exciting news with the community!\n\n## Events\n\nAdd our [Google Calendar](https://calendar.google.com/calendar/b/6?cid=ZmlsZWNvaW4ub3JnX2o3bW1ldjI0ZzgwcmVsbzU2cHFtMWVsMWUwQGdyb3VwLmNhbGVuZGFyLmdvb2dsZS5jb20) or follow issues in this repo to keep track of events (meetups, hackathons, etc.) hosted by the Filecoin Project and/or Protocol Labs.\n\n### Community calls\n\nOur community calls are venues for all Filecoin Project community members to meet each other, share demos of recent work, discuss open problems, and more. We expect these calls to be extremely respectful venues where all community members follow our [Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md) and treat each other (i) as they would like to be treated and (ii) as they would treat each other in real life.\n\nAll community calls are **open for anyone to join**. However, we recommend that you take a look at each call's agenda (which can be found on GitHub issues under the label [`agenda`](https://github.com/filecoin-project/community/labels/agenda)) to make sure the call will be a good use of your time. We do our best to group similar demos and other agenda items together in the same call so it is easier to choose calls that you would like to attend.\n\nFurthermore, we hold different calls for different communities. If you are a third-party app developer or OSS contributor, you might be interested in attending our **monthly development community calls** that are geared towards topics that developers will find useful. We also hold occasional **mining community calls** that are geared towards the needs of Filecoin miners.\n\nFeel free to attend whichever calls are interesting to you. All calls are recorded, and the recording will be posted online at this repo.\n\nLearn more about:\n\n- [Development Community Calls](https://github.com/filecoin-project/community/blob/master/community-calls/dev-calls/dev-calls.md)\n- [Mining Community Calls](https://github.com/filecoin-project/community/blob/master/community-calls/mining-calls/mining-calls.md)\n\nWe will announce each upcoming community call by making announcements in our [chat channels](#chat) and [website](https://filecoin.io/build/#events).\n\n### Filecoin Meetups\n\nFilecoin meetups are a great way to meet and connect with other developers and miners in your community that are using and learning about Filecoin.\n\nClick [Attend a Filecoin virtual meetup](https://www.meetup.com/Filecoin-San-Francisco/events/276433326/) for joining the next event!\n\n\n## Contributing\n\n### Contributing Guidelines\n\nWe use a common [Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md) across all of our repos.\n\nEach repo should have its own contributing guide, called `CONTRIBUTING.md`. Here is an example [Contributing Guide for `venus`](https://github.com/filecoin-project/venus/blob/master/CONTRIBUTING.md).\n\n## Maintainers\n\nMaintainers are responsible for maintaining the content of this repo, create an issue and tag one of the maintainers if you have any questions.\n\nCurrent maintainers are:\n@jennijuju ([jennijuju@protocol.ai](jennijuju@protocol.ai))\n\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/community/blob/master/LICENSE-APACHE) or [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0))\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/community/blob/master/LICENSE-MIT) or [http://opensource.org/licenses/MIT](http://opensource.org/licenses/MIT))\n", "release_dates": []}, {"name": "community-china", "description": "Resources and forum for the Chinese community, maintained and moderated by CoinSummer & PL.", "language": "C", "license": null, "readme": "# Awesome Filecoin\n\n**\u8bf7\u6ce8\u610f\uff1a\u672c\u6587\u4e2d\u7684\u94fe\u63a5\u5e76\u975e\u5168\u90e8\u662f\u5b98\u65b9\u94fe\u63a5\uff0c\u90e8\u5206\u94fe\u63a5\u662f\u7b2c\u4e09\u65b9\u94fe\u63a5\uff0c\u6709\u4e9b\u751a\u81f3\u662f\u6536\u8d39\u94fe\u63a5\uff0c\u8bf7\u5927\u5bb6\u6ce8\u610f\u533a\u5206\u3002**\n\n## 1. Website\n\n#### 1.1 \u6d4f\u89c8\u5668\n- [FilFox](https://filfox.info/en) - 6Block \u56e2\u961f\u5f00\u53d1\u7684 Filecoin \u6d4f\u89c8\u5668\n- [Filscan](https://filscan.io) - IPFS\u539f\u529b\u56e2\u961f\u5f00\u53d1\u7684 Filecoin \u6d4f\u89c8\u5668\n- [Filscout](https://filscout.io) - \u661f\u9645\u8054\u76df\u56e2\u961f\u5f00\u53d1\u7684 Filecoin \u6d4f\u89c8\u5668\n- [1475ipfs](https://1475ipfs.com/#/blockBrowser) - ~~1475 \u56e2\u961f\u5f00\u53d1 Filecoin \u6d4f\u89c8\u5668~~\u3010\u5df2\u5173\u95ed\u3011\n- [Stats](https://stats.testnet.filecoin.io/) - \u5b98\u65b9 Filecoin \u6d4f\u89c8\u5668\uff08\u6309 `ESC` \u53ef\u67e5\u770b\u4e0d\u540c\u7684\u7f51\u7edc\uff09\n- [Spacegap](https://spacegap.github.io/#/) - \u5b98\u65b9 Filecoin \u6d4f\u89c8\u5668\uff08\u603b\u89c8\u89c6\u56fe\uff09\n- [Atpool](https://explorer.atpool.com/) - \u96c5\u5178\u5a1c\u6d4f\u89c8\u5668-Filecoin\u4e13\u4e1a\u77ff\u5de5\u6570\u636e\u670d\u52a1\n\n#### 1.2 \u4ee3\u7801\u4ed3\u5e93\n- [lotus](https://github.com/filecoin-project/lotus) - Filecoin lotus\u9879\u76ee\u6e90\u4ee3\u7801\u5730\u5740\n- [filecoin-ffi](https://github.com/filecoin-project/filecoin-ffi)\n- [rust-fil-proofs](https://github.com/filecoin-project/rust-fil-proofs)\n- [bellperson](https://github.com/filecoin-project/bellperson)\n- [neptune](https://github.com/filecoin-project/neptune)\n\n#### 1.3 Filecoin\u5176\u4ed6\u5b9e\u73b0\n- [Venus](https://github.com/filecoin-project/venus) - Filecoin Go\u8bed\u8a00\u7684\u5b9e\u73b0\uff0c\u57fa\u4e8e\u4ee5\u524d\u7684go-filecoin\n- [Fuhon](https://github.com/filecoin-project/cpp-filecoin) - Filecoin C++\u8bed\u8a00\u7684\u5b9e\u73b0\n- [Forest](https://github.com/ChainSafe/forest) - Rust\u8bed\u8a00\u7684\u5b9e\u73b0\n\n#### 1.4 \u8d44\u6e90\u4e0b\u8f7d\n- [\u8bc1\u660e\u53c2\u6570\u56fd\u5185\u955c\u50cf](https://proof-parameters.s3.cn-south-1.jdcloud-oss.com/ipfs/) - \u4eac\u4e1c\u4e91\u955c\u50cf\n- [\u793e\u533a\u8bc1\u660e\u53c2\u6570\u955c\u50cf](https://gateway.yeaosound.com/ipns/filecoin-proofs.ipns.network/) - \u793e\u533a@Ego Lee \u5206\u4eab\u7684\u8bc1\u660e\u53c2\u6570\u56fd\u5185\u955c\u50cf\n\n## 2. Network\n- [\u7f51\u7edc\u6982\u89c8](https://network.filecoin.io/) - \u5305\u62ec\u4e3b\u7f51\u548c\u6d4b\u8bd5\u7f51\u7b49\u5404\u4e2a\u7f51\u7edc\u7684\u8be6\u7ec6\u4fe1\u606f\n- [MainNet](https://github.com/filecoin-project/lotus/tree/master) - Filecoin\u4e3b\u7f51\n- [Calibration](https://github.com/filecoin-project/community/discussions/74#discussioncomment-1922550) - Calibration \u6821\u51c6\u7f51\n- [Spacegap](https://spacegap.github.io/#/) - \u5b9e\u65f6\u7b97\u529b\u6982\u89c8\n## 3. Documentation\n### Filecoin\u6587\u6863\n  - [FIPs \u6587\u6863\u5165\u53e3](https://github.com/filecoin-project/FIPs) - FIPs\n  - [\u5b98\u65b9\u6587\u6863](https://lotus.filecoin.io/docs/set-up/about/) - Filecoin Documentation\n  - [\u4f9d\u8d56\u5b89\u88c5\u548c\u4ee3\u7801\u7f16\u8bd1](https://lotus.filecoin.io/lotus/install/prerequisites/) - Filecoin\u5b98\u65b9\u4f9d\u8d56\u5b89\u88c5\u548c\u4ee3\u7801\u7f16\u8bd1\u6559\u7a0b\n  - [\u6316\u77ff\u6559\u7a0b](https://docs.filecoin.io/mine/lotus/) - Filecoin\u5b98\u65b9\u7684\u6316\u77ff\u6559\u7a0b\uff0c\u7cfb\u7edf\u6027\u5f3a\u3001\u8be6\u7ec6\u5b8c\u6574\uff0c\u5efa\u8bae\u65b0\u624b\u901a\u8bfb\n  - [Venus\u6587\u6863](https://venus.filecoin.io/) - Venus Documentation\n\n### Filecoin\u7ecf\u6d4e\u6a21\u578b\n  - [Filecoin\u7ecf\u6d4e\u6a21\u578b\u767d\u76ae\u4e66\u4e2d\u6587\u7248](https://filecoin.io/zh-cn/2020-engineering-filecoins-economy-zh-cn.pdf)\n  - [Filecoin\u7ecf\u6d4e\u6a21\u578b\u767d\u76ae\u4e66\u82f1\u6587\u7248](https://filecoin.io/2020-engineering-filecoins-economy-en.pdf)\n  - [Filecoin\u7684\u6d41\u901a\u4f9b\u5e94\u673a\u5236](https://filecoin.io/zh-cn/blog/posts/%E4%BA%86%E8%A7%A3filecoin%E6%B5%81%E9%80%9A%E4%BE%9B%E5%BA%94%E6%9C%BA%E5%88%B6/)\n\n### \u786c\u4ef6\u914d\u7f6e\n  - [\u77f3\u69b4\u77ff\u6c60Filecoin\u6316\u77ff\u65b9\u6848](https://6block.com/files/zh/Filecoin%20mining%20solution%20v8.0.pdf) - \u77f3\u69b4\u77ff\u6c60Filecoin\u6316\u77ff\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u542bAMD 3960CPU\u548cEPYC 7542\u4e24\u79cd\u65b9\u6848\n  - [\u793e\u533a\u63a8\u8350Filecoin\u786c\u4ef6\u65b9\u6848](https://github.com/filecoin-project/community-china/discussions/18) - \u793e\u533a\u63a8\u8350\u7684\u57fa\u4e8eAMD EPYC 7542\u7684Filecoin\u6316\u77ff\u786c\u4ef6\u65b9\u6848\n\n### \u6316\u77ff\u96c6\u7fa4\u642d\u5efa\n  - [Filecoin\u6316\u77ff\u96c6\u7fa4\u642d\u5efa](https://github.com/filecoin-project/community-china/discussions/4) - \u5982\u4f55\u4ece\u96f6\u5f00\u59cb\u642d\u5efa\u4e00\u4e2a\u6316\u77ff\u96c6\u7fa4\n  - [\u5206\u5e03\u5f0fMiner\u96c6\u7fa4\u642d\u5efa](https://github.com/minerdao/posts/blob/master/posts/filecoin/distributed-miner-configuration.md) - \u793e\u533a\u5206\u5e03\u5f0fMiner\u67b6\u6784\u8be6\u89e3\n\n### Daemon\u64cd\u4f5c\n  - [\u8282\u70b9\u542f\u52a8](https://github.com/filecoin-project/community-china/discussions/2) - Lotus\u4ee3\u7801\u7f16\u8bd1\u3001\u8282\u70b9\u642d\u5efa\u3001\u914d\u7f6e\u3001\u542f\u52a8\n  - [\u8282\u70b9\u64cd\u4f5c](https://github.com/filecoin-project/community-china/discussions/8) - Lotus\u8282\u70b9\u5e38\u7528\u64cd\u4f5c\uff0c\u5feb\u7167\u5bfc\u51fa\u3001\u5bfc\u5165\uff0c\u5feb\u7167\u88c1\u526a\uff0c\u516c\u7f51IP\u914d\u7f6e\n  - [Lotus\u94b1\u5305\u5e38\u7528\u64cd\u4f5c\u53ca\u4f7f\u7528\u573a\u666f](https://github.com/filecoin-project/community-china/discussions/15) - Lotus\u94b1\u5305\u521b\u5efa\u3001\u5bfc\u5165\u5bfc\u51fa\uff0c\u591a\u94b1\u5305\u914d\u7f6e\n\n### Miner\u64cd\u4f5c\n  - [\u6247\u533a\u64cd\u4f5c](https://github.com/filecoin-project/community-china/discussions/14) - \u6247\u533a\u751f\u547d\u5468\u671f\u89e3\u6790\u3001\u6247\u533a\u72b6\u6001\u66f4\u65b0\u3001\u6247\u533a\u5220\u9664\n  - [\u5b58\u50a8\u8def\u5f84\u64cd\u4f5c](https://github.com/minerdao/posts/blob/master/posts/filecoin/storage-manage.md) - \u5b58\u50a8\u8def\u5f84\u64cd\u4f5c\u3001\u5b58\u50a8i/o\u6027\u80fd\u5206\u6790\u3001\u7f51\u7edc\u5206\u6790\n  - [Owner\u3001Worker\u3001Control\u94b1\u5305\u8bf4\u660e](https://github.com/filecoin-project/community-china/discussions/15) - \u5982\u4f55\u914d\u7f6e\u65f6\u7a7a\u8bc1\u660e\u3001PreCommit\u3001ProveCommit\u591a\u94b1\u5305\u5730\u5740\n  - [Miner\u91cd\u542f\u65f6\u673a\u9009\u62e9](https://docs.filecoin.io/mine/lotus/miner-lifecycle/#ensuring-proofs-for-the-current-deadline-have-been-sent) - \u91cd\u542fMiner\u524d\u9700\u8981\u68c0\u67e5\u4ec0\u4e48\n  - [\u65b0\u77ff\u5de5\u8282\u70b9\u4e0a\u7ebfCheckList](https://github.com/minerdao/posts/blob/master/posts/filecoin/new-miner-checklist.md) - \u65b0\u77ff\u5de5\u8282\u70b9\u4e0a\u7ebf\u64cd\u4f5c\u7cfb\u7edf\u3001\u57fa\u7840\u73af\u5883\u3001Daemon\u3001Miner\u3001Worker\u68c0\u67e5\u5217\u8868\n  - [\u5982\u4f55\u8fc1\u79fb\u77ff\u5de5\u8282\u70b9](./documents/tutorial/How_to_migrate_miner_nodes/How_to_migrate_miner_nodes.md) - \u5982\u4f55\u8fc1\u79fb\u77ff\u5de5\u8282\u70b9\u81f3\u65b0\u7684\u673a\u5668\u4e0a\uff0c\u9700\u8981\u505a\u54ea\u4e9b\u914d\u7f6e\u548c\u64cd\u4f5c\n  - [\u5982\u4f55\u6b63\u786e\u5220\u9664\u6247\u533a](./documents/tutorial/How_to_delete_sector_correctly/How_to_delete_sector_correctly.md) - \u6559\u4f60\u5220\u9664\u6247\u533a\u7684\u6b63\u786e\u59ff\u52bf\uff0c\u4ee5\u53ca\u6b8b\u7559\u6247\u533a\u5982\u4f55\u5904\u7406\n\n### Deal \u64cd\u4f5c\n  - [Filecoin \u8ba2\u5355\u914d\u7f6e\u53ca\u8ba2\u5355\u64cd\u4f5c](https://github.com/filecoin-project/community-china/discussions/5) - \u5b58\u50a8\u77ff\u5de5\u5982\u4f55\u63a5\u8ba2\u5355\uff0c\u8ba2\u5355\u5e38\u89c1\u64cd\u4f5c\n\n### \u90e8\u7f72\u8fd0\u7ef4\n  - [Lotus-ops\u90e8\u7f72\u8fd0\u7ef4\u5de5\u5177](https://github.com/minerdao/lotus-ops) - [MinerDAO](https://github.com/minerdao)\u5f00\u6e90\u7684Lotus\u90e8\u7f72\u8fd0\u7ef4\u5de5\u5177\u548c\u8fd0\u7ef4\u64cd\u4f5c\u624b\u518c\n  - [Ansible\u90e8\u7f72\u5de5\u5177\u4f7f\u7528](https://github.com/minerdao/posts/blob/master/posts/filecoin/ansible-deploy-tool-usage.md) - \u5982\u4f55\u4f7f\u7528Ansible\u6279\u91cf\u81ea\u52a8\u5316\u90e8\u7f72Daemon\u3001Miner\u3001Worker\n  - [Prometheus + Grafana\u76d1\u63a7\u7cfb\u7edf\u642d\u5efa](https://github.com/minerdao/posts/blob/master/posts/filecoin/monitoring-deployment.md) - \u57fa\u4e8ePrometheus\u548cGrafana\u642d\u5efaFilecoin\u76d1\u63a7\u62a5\u8b66\u7cfb\u7edf\n  - [Lotus\u65e5\u5e38\u8fd0\u7ef4\u5de1\u68c0\u505a\u4ec0\u4e48](https://github.com/filecoin-project/community-china/discussions/10) - \u65e5\u5e38\u786c\u4ef6\u68c0\u67e5\u3001\u9519\u8bef\u6247\u533a\u5904\u7406\u3001\u94b1\u5305\u68c0\u67e5\u3001\u6d88\u606f\u6c60\u758f\u901a\u7b49\n  - [Lotus-alert\u7b80\u5355\u6613\u7528\u7684Lotus\u544a\u8b66\u7cfb\u7edf](https://github.com/jyma/lotus-alert) - \u672c\u9879\u76ee\u7531\u6280\u672f\u7fa4\u7fa4\u53cb @mje \u63d0\u4f9b\uff0c\u53ef\u76f4\u63a5\u53d1\u9001\u544a\u8b66\u4fe1\u606f\u5230\u5fae\u4fe1\n  - [\u4e2d\u56fd\u5927\u9646\u5730\u533aFileCoin\u8bc1\u660e\u53c2\u6570\u7684\u4e0b\u8f7d](https://ipns.tech/2.FileCoin/%E4%B8%AD%E5%9B%BD%E5%A4%A7%E9%99%86%E5%9C%B0%E5%8C%BAFileCoin%E8%AF%81%E6%98%8E%E5%8F%82%E6%95%B0%E7%9A%84%E4%B8%8B%E8%BD%BD%E4%BC%98%E5%8C%96) - \u793e\u533a@Ego Lee\u5206\u4eab\u7684\u4e2d\u56fd\u5927\u9646\u5730\u533aFileCoin\u8bc1\u660e\u53c2\u6570\u7684\u4e0b\u8f7d\u4f18\u5316\n\n### \u5e38\u7528\u73af\u5883\u53d8\u91cf\n  - [Lotus Daemon\u73af\u5883\u53d8\u91cf](https://github.com/filecoin-project/community-china/discussions/6) - Lotus Daemon\u5e38\u7528\u73af\u5883\u53d8\u91cf\u8bf4\u660e\n  - [Lotus Miner\u73af\u5883\u53d8\u91cf](https://github.com/filecoin-project/community-china/discussions/6) - Lotus Miner\u5e38\u7528\u73af\u5883\u53d8\u91cf\u8bf4\u660e\n  - [Lotus Worker\u73af\u5883\u53d8\u91cf](https://github.com/filecoin-project/community-china/discussions/6) - Lotus Worker\u5982\u4f55\u5f00\u542fPreCommit1 SDR\u52a0\u901f\uff0c\u5982\u4f55\u6307\u5b9a\u663e\u5361\u578b\u53f7\u7b49\n\n### \u5e38\u89c1\u8f6f\u4ef6\u95ee\u9898\n  - [Golang\u7f16\u8bd1\u73af\u5883\u5b89\u88c5\u914d\u7f6e](./documents/build/build_env_config.md) - Golang\u7f16\u8bd1\u73af\u5883\u5b89\u88c5\u3001\u4ee3\u7406\u8bbe\u7f6e\n  - [Rust\u7f16\u8bd1\u73af\u5883\u5b89\u88c5\u914d\u7f6e](./documents/build/build_env_config.md) - Rust\u7f16\u8bd1\u73af\u5883\u5b89\u88c5\u914d\u7f6e\uff0c`crate.io` \u6e90\u56fd\u5185\u955c\u50cf\u914d\u7f6e\n  - [\u4ee3\u7801\u7f16\u8bd1\u5e38\u89c1\u9519\u8bef\u89e3\u51b3](./documents/build/build_env_config.md) - \u56fd\u5185\u4ee3\u7406\u914d\u7f6e\u3001Intel\u673a\u5668\u7f16\u8bd1\u73af\u5883\u53d8\u91cf\u914d\u7f6e\n\n### \u5e38\u89c1\u786c\u4ef6\u95ee\u9898\n  - [CPU\u5f00\u542f\u6027\u80fd\u6a21\u5f0f](./documents/hardware/cpu_performance.md)\n\n### Benchmarks\n  - [AMD EPYC 7542 + RTX 2080Ti](https://github.com/filecoin-project/community-china/blob/master/documents/benchmark/bench.md#amd-epyc%E7%B3%BB%E5%88%97cpu)\n  - [AMD EPYC 7542 + RTX 3080](https://github.com/filecoin-project/community-china/blob/master/documents/benchmark/bench.md#amd-epyc%E7%B3%BB%E5%88%97cpu)\n  - [AMD EPYC 7302 + RTX 2080Ti](https://github.com/filecoin-project/community-china/blob/master/documents/benchmark/bench.md#amd-epyc%E7%B3%BB%E5%88%97cpu)\n  - [AMD 3970X + RTX 2080Ti](https://github.com/filecoin-project/community-china/blob/master/documents/benchmark/bench.md#amd-3970x%E7%B3%BB%E5%88%97cpu)\n\n### \u8d44\u6e90\u6d88\u8017\u7edf\u8ba1\n  - [\u78c1\u76d8\u6d88\u8017\u7edf\u8ba1](./documents/resource/resource_usage/resource_usage.md)\n  - [\u5185\u5b58\u6d88\u8017\u7edf\u8ba1](./documents/resource/resource_usage/resource_usage.md)\n  - [\u67e5\u770b\u7cfb\u7edf\u8d44\u6e90\u5de5\u5177\u4ecb\u7ecd](./documents/resource/resource_usage/resource_usage.md)\n    - htop \uff08CPU \u6027\u80fd\u67e5\u770b\u5de5\u5177\uff09\n    - nvtop \uff08GPU \u6027\u80fd\u67e5\u770b\u5de5\u5177\uff09\n\n### \u6280\u672f\u6587\u7ae0\u5206\u4eab\n  - [\u661f\u60f3\u6cd5\u516c\u4f17\u53f7Filecoin\u7cfb\u5217\u6587\u7ae0](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU5MzMxNTk2Nw==&action=getalbum&album_id=1458647927098130433)\n  - [MerkleTree\u7684\u7b97\u6cd5\u6d41\u7a0b](https://github.com/kikakkz/rust-fil-proofs-test/blob/master/apps/data/MerkleTree%E7%9A%84%E7%AE%97%E6%B3%95.txt) - [@kikakkz](https://github.com/kikakkz)\u5206\u4eab\u7684MerkleTree\u7b97\u6cd5\u8c03\u7528\u6d41\u7a0b\n  - Seal\u5bc6\u5c01\u6d41\u7a0b\u5206\u6790\n    - [P1\u8ba1\u7b97\u8fc7\u7a0b\u7b80\u4ecb](./documents/tutorial/lotus_seal_process/seal_process.md)\n    - [P2\u8ba1\u7b97\u8fc7\u7a0b\u7b80\u4ecb](./documents/tutorial/lotus_seal_process/seal_process.md)\n### \u57fa\u7840\u6559\u7a0b\n  - [\u672c\u5730\u642d\u5efa 2K \u6d4b\u8bd5\u7f51\u5165\u95e8\u6559\u7a0b](./documents/tutorial/local_2k_dev_tutorial/local_2k_dev_tutorial.md) - \u5f3a\u70c8\u63a8\u8350\u7684\u65b0\u624b\u5165\u95e8\u6559\u7a0b\n  - [Calibration \u6d4b\u8bd5\u7f51\u4f7f\u7528\u6559\u7a0b](./documents/tutorial/use_cali-net_tutorial/use_cali-net_tutorial.md) - \u5f3a\u70c8\u63a8\u8350\u7684\u65b0\u624b\u5165\u95e8\u6559\u7a0b\n  - [\u94fe\u6570\u636e\u5bfc\u5165\u5bfc\u51fa\u4f7f\u7528\u6559\u7a0b](./document/../documents/tutorial/lotus_chain_op/lotus_chain_op.md) - \u6587\u6863\u5185\u5305\u542b\u5b98\u65b9\u5feb\u7167\u7f51\u5740\n  - [GDB\u8c03\u8bd5Lotus\u6e90\u7801](./documents/tutorial/gdb_debug_lotus/gdb_debug.md) - \u4f7f\u7528\u672c\u5730\u7f16\u8bd1\u7684 Rust \u5e93\n  - [Filecoin \u6700\u65b0\u6316\u77ff\u96c6\u7fa4\u786c\u4ef6\u914d\u7f6e](https://github.com/filecoin-project/community-china/discussions/18)\n  - [Filecoin \u6316\u77ff\u6559\u7a0b\u96c6\u5408](https://www.r9it.com/categories.html#Filecoin-ref) - \u7fa4\u53cb @Rock-Yang \u63d0\u4f9b\u7684\u4f18\u8d28\u6587\u7ae0\u6559\u7a0b\n  - [Calibration \u6d4b\u8bd5\u7f51\u548c Nerpnet \u6d4b\u8bd5\u7f51\u5feb\u7167\u4e0b\u8f7d\u5730\u5740\u548c\u4f7f\u7528\u6559\u7a0b](./documents/tutorial/testnet_snapshot/testnet_snapshot.md) - \u6709\u6548\u65f6\u95f4\u4ece2021/07/15\u5f00\u59cb\u5230\u4e0b\u6b21\u6d4b\u8bd5\u7f51\u91cd\u7f6e\n  - [\u5982\u4f55\u6b63\u786e\u5220\u9664\u6247\u533a](./documents/tutorial/How_to_delete_sector_correctly/How_to_delete_sector_correctly.md) \n  - [\u5982\u4f55\u8fc1\u79fb\u77ff\u5de5\u8282\u70b9](./documents/tutorial/How_to_migrate_miner_nodes/How_to_migrate_miner_nodes.md) \n  - [\u5feb\u901f\u5207\u6362 Daemon \u8282\u70b9](./documents/tutorial/change_lotus_daemon/change_lotus_daemon.md) - \u5982\u4f55\u5207\u6362\u77ff\u5de5\u7684 `Daemon` \u8282\u70b9\uff0c\u540c\u65f6\u63d0\u4f9b\u5927\u91cf\u5173\u4e8e\u672c\u5730\u6d4b\u8bd5\u7f51\u7684\u76f8\u5173\u811a\u672c\n  - [\u5206\u79bb\u5b58\u50a8\u5e02\u573a\u5230\u4e0d\u540c\u7684\u8282\u70b9](./documents/tutorial/split_markets_node/split_markets_node.md)\u3000- \u89e3\u91ca\u5206\u79bb\u5b58\u50a8\u5e02\u573a\u5230\u4e0d\u540c\u8282\u70b9\u7684\u5fc5\u8981\u6027\u548c\u6b65\u9aa4\n  - [\u8fc7\u4f4e\u7684\u5e78\u8fd0\u503c\u7684\u6392\u67e5\u65b9\u6cd5](./documents/tutorial/low_lucky_value/low_lucky_value.md) - \u5f53\u4f60\u7684\u5e78\u8fd0\u503c\u4e00\u76f4\u5f88\u4f4e\uff0c\u8be5\u5982\u4f55\u6392\u67e5\u539f\u56e0\n  - [\u4ece\u5bc6\u5c01\u6587\u4ef6\u751f\u6210\u6247\u533a\u7f13\u5b58\u6587\u4ef6](./documents/tutorial/Generate_cache_files_from_sealed/Generate_cache_files_from_sealed.md) -\u4ece\u5bc6\u5c01\u6587\u4ef6\u751f\u6210\u6247\u533a\u7f13\u5b58\u6587\u4ef6\u7684\u4e2d\u6587\u7ffb\u8bd1\u7248\u672c\n  - [\u624b\u52a8\u5c06\u6247\u533a\u6587\u4ef6\u8f6c\u79fb\u81f3\u6c38\u4e45\u5b58\u50a8](./documents/tutorial/finalize_sector_manually/finalize_sector_manually.md) - \u5f53\u6247\u533a\u843d\u76d8\u5931\u8d25\u65f6\u624b\u52a8\u8f6c\u79fb\u6247\u533a\u81f3\u6c38\u4e45\u5b58\u50a8\n\n### \u771f\u5b9e\u6570\u636e\u6587\u6863\n   \n  - [\u5173\u4e8e\u516c\u8bc1\u4eba](./documents/real_data/fil_plus/about_notary.md) - \u7ffb\u8bd1\u81ea\u5b98\u65b9\u6587\u6863\uff0c\u89e3\u91ca\u516c\u8bc1\u4eba\u7684\u4f5c\u7528\u53ca\u8fd0\u884c\u673a\u5236 \n  - [Filecoin plus](./documents/real_data/fil_plus/file_coin_plus.md) - \u7ffb\u8bd1\u81ea\u5b98\u65b9\u6587\u6863\uff0c\u5173\u4e8efilecoin plus\u7684\u6982\u5ff5\u53ca\u53c2\u4e88\u65b9\u5f0f \n  - [\u5982\u4f55\u83b7\u53d6\u771f\u5b9e\u4ea4\u6613\u8ba2\u5355](./documents/real_data/where_do_find_verified_deal/where_do_find_verified_deal.md) \u5f53\u4e0b\u83b7\u53d6\u771f\u5b9e\u6570\u636e\u7684\u4e3b\u8981\u65b9\u5f0f\n  - [textile\u5b58\u50a8\u62cd\u5356\u7cfb\u7edf](./documents/real_data/where_do_find_verified_deal/textileio_bidbot.md) textile\u5b58\u50a8\u62cd\u5356\u7cfb\u7edf,\u79bb\u7ebf\u4ea4\u6613\u5e73\u53f0\uff0c\u66f4\u9002\u5408\u56fd\u5185\u77ff\u5de5\u63a5\u5355\n  - [~~textile\u5956\u52b1\u8ba1\u5212~~](./documents/real_data/where_do_find_verified_deal/grabs_with_Filecoin_Auctions.md) ~~textile\u5956\u52b1\u8ba1\u5212\uff0c\u771f\u5b9e\u6570\u636e+\u5956\u52b1\uff0c2021\u5e7411\u67088\u65e5\u5f00\u59cb~~\n  - [\u771f\u5b9e\u6570\u636e\u4e13\u9898\u8ba8\u8bba](https://github.com/filecoin-project/community-china/discussions/166) \u8fd9\u91cc\u8ba8\u8bba\u5173\u4e8e\u771f\u5b9e\u6570\u636e\u95ee\u9898\n  \n### \u9ad8\u7ea7\u6559\u7a0b\n  - [Poseidon \u54c8\u5e0c\u7b97\u6cd5 C \u8bed\u8a00\u5b9e\u73b0](./ref_src/poseidon/PoseidonHashOriginal/Readme.md) - \u57fa\u7840\u7248\uff08\u6240\u4f7f\u7528\u7684\u53c2\u6570\u548c lotus \u6709\u6240\u4e0d\u540c\uff09\n  - [Poseidon \u54c8\u5e0c\u7b97\u6cd5 C \u8bed\u8a00\u5b9e\u73b0](./ref_src/poseidon/PoseidonHashNeptune/Readme.md) - \u9ad8\u7ea7\u7248\uff08\u6240\u4f7f\u7528\u7684\u53c2\u6570\u548c lotus \u5b8c\u5168\u76f8\u540c\uff09\n\n## 4. Optimized Lotus\n- [C2\u4f18\u5316\u7248](https://github.com/jackoelv/bellperson) - [@jacklelv](https://github.com/jackoelv)\u5f00\u6e90\u7684C2\u4f18\u5316\u7248\n- [\u8c03\u5ea6\u4f18\u5316\u7248 & \u5206\u5e03\u5f0f Miner \u5907\u4efd: \u3010lotus-1.10.0-1.10.0.zip\u3011](./ref_src/anonymouse_lotus/lotus-1.10.0-1.10.0.zip) - \u67d0\u533f\u540d\u5927\u4f6c\u5f00\u6e90\u7684\u5206\u5e03\u5f0f Miner\n- [lotus-bee\u4f18\u5316\u7248](https://github.com/beelant/lotus-bee) \u7531\u8702\u706f\u79d1\u6280\u63d0\u4f9b\u7684\u5168\u65b9\u4f4d\u4f18\u5316\u7684lotus\u8f6f\u4ef6\u514d\u8d39\u4f7f\u7528\n\n## 5. Ecosystem Tools\n- [Singularity](https://github.com/tech-greedy/singularity) - \u7528\u4e8e\u5c06PB\u7ea7\u6570\u636e\u8f7d\u5165Filecoin\u7f51\u7edc\u7684\u5ba2\u6237\u7aef\u5de5\u5177\n- [Go-generate-car](https://github.com/tech-greedy/go-generate-car) - \u6253\u5305\u751f\u6210.car\u6587\u4ef6\u7684\u5de5\u5177\n- [File.app](https://file.app) - \u5b9e\u65f6\u8ba2\u5355\uff0c\u5b58\u50a8\u8d39\u7528\uff0c\u5b58\u50a8\u77ff\u5de5\u7b49\u67e5\u8be2\n- [Fgas](https://fgas.io/index) - \u6316\u77ff\u6210\u672c\u67e5\u8be2\uff0c\u53ef\u5b9e\u65f6\u67e5\u770b\u62b5\u62bc\u5e01\u548cGas\u6d88\u8017\n- [FileStats](https://filstats.com) - Filecoin\u6316\u77ff\u6210\u672c\u67e5\u8be2\n- [Spacegap](https://spacegap.github.io/#/) - \u4e3b\u7f51\u6570\u636e\u7edf\u8ba1\u6982\u89c8\uff0c\u663e\u793a\u524d50\u540d\u77ff\u5de5\u7684\u7b97\u529b\u3001\u8d26\u6237\u4f59\u989d\u7edf\u8ba1\n- [Filkeep](https://console.filkeep.com) - Filecoin\u6316\u77ff\u76d1\u63a7\u62a5\u8b66\u7cfb\u7edf\n- [\u6536\u76ca\u8ba1\u7b97\u5668](https://calculator.atpool.com) - \u96c5\u5178\u5a1c\u77ff\u6c60\u6536\u76ca\u8ba1\u7b97\u5668\n- [\u8ba2\u5355\u7edf\u8ba1](https://storage.fileco) - Filecoin\u7f51\u7edc\u8ba2\u5355\u7edf\u8ba1\n- [\u8ba2\u5355\u67e5\u8be2\u5de5\u5177](https://filecoin.tools/) - Filecoin\u8ba2\u5355\u5e02\u573a\u67e5\u8be2\n- [\u53d1\u5355\u3001\u63a5\u5355\u5de5\u5177](https://github.com/nebulaai/swan) - \u6280\u672f\u7fa4\u6210\u5458[@\u7af9\u98ce](https://github.com/flyworker)\u5f00\u6e90\u7684\u77ff\u5de5\u63a5\u5355\u3001\u5ba2\u6237\u53d1\u5355\u5de5\u5177\n- [\u77ff\u673a\u6295\u8d44\u6536\u76ca\u8ba1\u7b97\u5668](http://fil8.top/invest/) - \u602a\u76d7FIL\u6536\u76ca\u8ba1\u7b97\u5668\n- [\u77ff\u6c60\u7edf\u8ba1\u5de5\u5177](http://fil8.top/pools) - Filecoin\u77ff\u6c60\u7edf\u8ba1\u5668\n- [Slingshot \u6570\u636e\u7edf\u8ba1](https://slingshot.filecoin.io/) - Filecoin \u6709\u6548\u6570\u636e\u5b58\u50a8\u6392\u540d\n- [FIL \u4e3b\u7f51\u6570\u636e\u7edf\u8ba1\u56fe\u8868](http://fil8.top/) - \u7fa4\u53cb @\u602a\u76d7Kid \u63d0\u4f9b\u7684 FIL \u4e3b\u7f51\u6570\u636e\u7edf\u8ba1\u56fe\u8868\n- [Filecoin\u6247\u533a\u4fee\u590d\u5de5\u5177](https://github.com/froghub-io/filecoin-sealer-recover) - \u7fa4\u53cb@Chen\u5f00\u6e90\u7684Filecoin\u6247\u533a\u4fee\u590d\u5de5\u5177\n- [Filecoin-Storage-Tool](https://github.com/VshareCloud-Project/Filecoin-Storage-Tool) - VshareCloud\u56e2\u961f\u5f00\u6e90\u7684FileCoin\u4ea4\u6613\u53d1\u8d77/\u6570\u636e\u5907\u4efd\u7ec4\u4ef6\n- [Lotus-wallet-security](https://github.com/cdcdx/lotus/tree/wallet-security) - \u7fa4\u53cb@Pangtou\u5f00\u6e90\u7684Lotus\u94b1\u5305\u52a0\u5bc6\u65b9\u6848\n\n## 6. Community\n- [\u5fae\u4fe1\u4ea4\u6d41\u7fa4](./README.md)\uff1a**Filecoin \u6280\u672f\u4ea4\u6d41\u7fa4** \u662f\u76ee\u524d\u56fd\u5185\u6700\u53cb\u597d\uff0c\u4e5f\u662f\u5168\u7403\u6700\u5927\u3001\u6700\u6d3b\u8dc3\u7684 Filecoin \u6280\u672f\u4ea4\u6d41\u793e\u533a\uff0c\u6b22\u8fce\u5e7f\u5927 Filecoin \u77ff\u5de5\u3001\u5f00\u53d1\u8005\u548c\u7231\u597d\u8005\u52a0\u5165\u6211\u4eec\u7684\u6280\u672f\u4ea4\u6d41\u7fa4\u3002\n  - Filecoin \u6280\u672f\u4ea4\u6d41-1\u7fa4\uff08\u76ee\u524d\u5df2\u6ee1\uff09\n  - Filecoin \u6280\u672f\u4ea4\u6d41-2\u7fa4\uff08\u76ee\u524d\u5df2\u6ee1\uff09\n  - Filecoin \u6280\u672f\u4ea4\u6d41-3\u7fa4\uff08\u76ee\u524d\u5df2\u6ee1\uff09\n  - Filecoin \u6280\u672f\u4ea4\u6d41-4\u7fa4\uff08\u76ee\u524d\u5df2\u6ee1\uff09\n  - Filecoin \u6280\u672f\u4ea4\u6d41-5\u7fa4\uff08\u76ee\u524d\u5df2\u6ee1\uff09\n  - Filecoin \u6280\u672f\u4ea4\u6d41-6\u7fa4\uff08\u76ee\u524d\u5df2\u6ee1\uff09\n  - Filecoin \u6280\u672f\u4ea4\u6d41-7\u7fa4\uff08\u76ee\u524d\u8fd8\u6709\u7a7a\u4f4d\uff09\n  - **Filecoin \u6280\u672f\u4ea4\u6d41\u7fa4**\uff08\u552f\u4e00\u4e0e\u5fae\u4fe1\u7fa4\u540c\u6b65\u7684 Telegram \u7fa4\uff09 \n  - \u5165\u7fa4\u8bf7\u8054\u7cfb\u7fa4\u4e3b\u3010**TEARS**\u3011\uff0c\u5e76\u505a\u597d\u5907\u6ce8\uff0c\u5426\u5219\u53ef\u80fd\u4f1a\u88ab\u62d2\u7edd\u3002\n  - ![TEARS](./images/tears_wchart.png)\n\n\n- [Telegram\u4ea4\u6d41\u7fa4](https://t.me/+TOGYnsZ2itA0NGZl)   \n- [Discord\u4ea4\u6d41\u7fa4](https://discord.gg/zA7smFQd)\n\n## 7. \u6742\u9879\n\n### 7.1 \u65e7\u7248\u8d44\u6e90\u5927\u5168\n\n\u76ee\u524d\uff0c\u8be5\u6587\u6863\u662f\u4ece\u65e9\u671f\u7248\u672c\u4e2d\u6539\u9020\u8fc7\u6765\u7684\uff0c\u65e9\u671f\u7ef4\u62a4\u7684\u4e00\u4e2a\u8d44\u6e90\u5927\u5168\uff0c\u4fe1\u606f\u4f9d\u7136\u975e\u5e38\u4e30\u5bcc\uff0c\u6709\u4e9b\u8d44\u6599\u5728\u8fd9\u4e2a\u6587\u6863\u4e2d\u6ca1\u6709\u7684\uff0c\u53ef\u4ee5\u53bb\u65e7\u7248\u4e2d\u627e\u627e\uff0c\u6216\u8bb8\u5c31\u80fd\u627e\u5230\u5f88\u591a\u6709\u7528\u7684\u4fe1\u606f\uff0c\u7279\u522b\u662f\u4e00\u4e9b\u57fa\u672c\u64cd\u4f5c\uff0c\u73af\u5883\u53d8\u91cf\u7b49\u7b49\u3002\n\n[\u3010\u65e7\u7248\u8d44\u6e90\u5165\u53e3\u5730\u5740\u3011](./documents/legacy_resource/README.md) -- \u5df2\u8fc1\u79fb\u5230\u672c\u9879\u76ee\u5f53\u4e2d\n\n", "release_dates": []}, {"name": "consensus", "description": "Filecoin consensus work", "language": "Python", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin Consensus\n---\n\nOne of Filecoin's main goals is to create a useful Proof-of-Work based on storage, building upon past work in both Proof-of-Work and Proof-of-Stake protocols.\n\n**Disclaimer:** While we work hard to document our work as it progresses, research progress may not be fully reflected here for some time, or may be worked out out-of-band.\n\nThis repository houses a lot of our work on this area of research: Filecoin consensus. While it is by no means exhaustive, it should provide a good place from which to start engaging on Filecoin consensus research. You may also want to read up on [Filecoin](https://github.com/filecoin-project/specs) and [Filecoin Research](https://github.com/filecoin-project/research).\n\nBroadly, our goals are to:\n- Finalize design aspects of consensus starting with EC to make it secure and workable for wanted Filecoin design,\n- Formalize parameters and other implementation requirements in a clear Filecoin Ccnsensus spec implementable by a dev team,\n- Define and prove Filecoin consensus security properties.\n\n**Note 1**: Content here may be out-of-sync.\n\n**Note 2**: We may sometimes link to inaccessible content here, alas some of these research endeavours require some gestation or privacy on part of our endeavors.\n\n**Note 3**: Throughout this repo, *miners* will most often refer to Filecoin Storage miners (unless otherwise specified). While we refer to both storage and retrieval miners as miners, strictu sensu, only participation in EC (from storage miners) is mining.\n\n## Table of Contents\n\n- [What is consensus in Filecoin?](#what-is-consensus-in-filecoin?)\n- [Consensus Research](#consensus-research)\n- [FAQ](#faq)\n- [Communication](#communication)\n- [License](#license)\n\n## What is consensus in Filecoin?\n\nThe state of the Filecoin network is maintained in a blockchain. It is updated as new blocks are mined by a chosen network participant at regular intervals. This \"leader\" earns FIL for this and is chosen from the set of participants in the Filecoin network with a probability proportional to how much storage this participant is verifiably providing the network. In proceeding thus, block creation\n- Provably updates the state of the Filecoin network to reflect network activity (i.e. token transfer and storage proofs);\n- Mints new FIL tokens that can be used to buy or sell storage;\n- Incentivizes actors to put storage on the network. \n\nFrom the perspective of consensus research this can be decomposed into three distinct protocols:\n\n1. **The Filecoin protocol** -- this allows miners to make storage deals with clients, submit and process messages to the state machine and create cryptographically verifiable proofs of storage over data.\n1. **Storage Power Consensus (SPC)** -- this generates a power table provably reflecting how much storage participants are providing to the network.\n1. **Expected Consensus (EC)** -- invokes leader election to select a miner from a weighted set of participants and ensures chain growth and convergence.\n\nThese protocols are meant to be modular and have [interfaces](./research-notes/interfaces.md) which enable us to swap them out or improve them without affecting the rest of the Filecoin stack, for instance updating proofs without changing how SPC functions, or leader election without changing the Filecoin protocol.\n\n## Consensus Research\n\n#### Current state of Filecoin consensus work\n\nTo gain familiarity with this subject matter, we refer the reader to:\n- [Filecoin Spec](https://github.com/filecoin-project/specs/) -- The spec is the output of these research efforts and reflects our must up-to-date working version of the protocols. The reader may specifically want to look at:\n    - [Expected Consensus](https://github.com/filecoin-project/specs/blob/master/expected-consensus.md)\n    - [Mining](https://github.com/filecoin-project/specs/blob/master/mining.md) -- the routine that invokes expected consensus.\n- [Filecoin Whitepaper](https://filecoin.io/filecoin.pdf) -- We urge readers to pay special attention to Section 6: `Useful Work Consensus`.\n- [Power Fault Tolerance Technical Report](https://filecoin.io/power-fault-tolerance.pdf) (PFT) -- Outlining some of the motivations and implications of this work, reframing Byzantine Fault Tolerance as a function of power committed to the network (in our case storage) rather than number of nodes.\n- Expected Consensus Overview -- This is a quick talk going over the basics of EC from ConsensusDay held in February 2019 at Stanford. [Talk](https://www.youtube.com/watch?v=pUIVMG4ZS2E&list=PLhuBigpl7lqtG6LgQ0FiiR4Pbrph9nocn&index=4&t=1s)/[Slides](https://drive.google.com/open?id=1eXLTSPmXTdtNoPk58VVgcwxdlrn8dUVr).\n\n#### Current avenues of research\n\nMost of our work on consensus to date focuses on these major endeavours. You can read more about general open problems on the [Filecoin Research repo](https://github.com/filecoin-project/research).\n\nBy design, these are meant to be extremely large, open-ended endeavours each of which breaks out into multiple open or completed problems. The endeavours themselves are evergreen sources of enquiry for and beyond Filecoin.\n\n| **Project** | **Description** | **Status** | **Notes** |\n| ---- | ---- | ---- | ---- |\n| **Formal Treatment of Expected Consensus** | Formal analysis of Expected Consensus' security guarantees | Working On/Collaboration | -[issue](https://github.com/filecoin-project/consensus/issues/19) |\n| **EC incentive compatibility** | This broadly refers to EC incentive compatibility and initial parameter setting for the Filecoin blockchain ensuring EC incentive compatibility using simulations or probabilistic proofs. | Working On/Collaboratoin | - Chain convergence <br>- [Weighting](https://github.com/filecoin-project/consensus/issues/27)<br/>- [LBP](https://github.com/filecoin-project/consensus/issues/11)<br>- [Slashing](https://github.com/filecoin-project/consensus/issues/32)<br>- [VDF use](https://github.com/filecoin-project/consensus/issues/25)<br>- [Block time ](https://github.com/filecoin-project/consensus/issues/28)<br>- [Finality](https://github.com/filecoin-project/consensus/issues/29) |\n| **Simulate EC Attacks** | Bottoms-up analysis of EC security simulating likely attacks under various proportions of honest/rational/adversarial miners to iterate on protocol design | Working On | -[issue](https://github.com/filecoin-project/consensus/issues/26) |\n| **Secret Single Leader Election** | Working out a full construction for SSLE. In spirit similar to cryptographic sortition but guaranteeing a single leader at every round | Collaboration/RFP | - [issue](https://github.com/filecoin-project/research-private/issues/8) <br>- [SSLE RFP](https://github.com/protocol/research-RFPs/blob/master/RFPs/rfp-6-SSLE.md) <br>- [SSLE Overview](https://www.youtube.com/watch?v=_ha6abiM0Uw&list=PLhuBigpl7lqtG6LgQ0FiiR4Pbrph9nocn&index=5&t=0s) from ConsensusDay 2019 |\n| **Formalizing Power Fault Tolerance (PFT)** | BFT is abstracted in terms of influence over the protocol rather than machines | Working On/Collaboration | - [issue](https://github.com/filecoin-project/consensus/issues/38) |\n| **Random beacons and the Filecoin blockchain** | Looking at and beyond the chain for trusted randomness in Filecoin | In Progress (70%) | -[issue](https://github.com/filecoin-project/consensus/issues/24)|\n\n## FAQ\n\n**Why build EC?**\n\n**Q**: Alright, so Filecoin wants a semi-permissionless (or optimally fully-permissionless), robustly reconfigurable consensus protocol that SPC can invoke to do leader election. There are a number of existing proof-of-stake protocol that may be adapted for this purpose. Why roll out our own?\n\n**A**: The answer comes down to a [number of factors](https://github.com/filecoin-project/consensus/issues/13) that boil down to what we have found often happens when trying to adapt theoretical work to real-world security models, including:\n\n- Wanting a secret leader election process (otherwise known as unpredictibility i.e. accounting for DOSing and adaptive attackers)\n- Wanting certain liveness guarantees that make MPCs unattractive (use of VDFs)\n- Ensuring chain safety under eventual synchrony\n- The complexity or partial omissions that we found in other candidate proposals\n- Accounting for \"rational\" miner behaviors rather than simply \"honest\" or \"byzantine\" (e.g. [rushing the protocol](research-notes/waiting.md))\n\nWith all of that said, it remains important to specify that our work builds upon existing work, notably Snow White and Algorand, and we believe our security analysis will be based on that of Shi and Pass.\n\n**Common misconceptions**\n\n**Q**: Why does EC use tickets for randomness?\n\n**A**: We use tickets for two reasons in the spec as currently laid out:\n\n- Preventing PoST precomputation - we use winning tickets from the previous block as our challenge for a per-slot delay function.\n  - Wanted property: \"verifiable recency\"\n- Leader Election - we use the tickets from a past block as a means of secretly and provably checking whether someone has been elected to post the block\n  - Wanted property: \u201cverifiable\u201d input on the chain common to all miners\n\nUltimately, in leader election, we are using tickets in order to approximate a [random beacon](./research-notes/randomness.md), but a promising area of research is to swap this source of randomness out for another on or off-chain source of verifiable randomness.\n\n**Q**: Is block generation (reward and transaction fees) the only way miners will earn FIL?\n\n**A**: No. Miners will also earn FIL through the orders they manage on the network (dealing with clients).\nIt is interesting to note that a miner must commit storage to the network (and thus appear in the power table) in order to participate in leader election and earn a block reward. This is in fact key to Filecoin's design of a `useful Proof of Work`.\nFurther, it is worth noting that only storage miners participate in Filecoin consensus. Retrieval miners only earn FIL through deals.\n\n**Q**: Where does collateral come into this?\n\n**A**: This is a direct follow-up to the above question. Because miners earn FIL in two ways (through participation in leader election and in deals), collateral is used in Filecoin to ensure good behavior in both cases. Specifically:\n\n- The Filecoin protocol slashes miners who break a contract (i.e. do not prove they are storing client data during the agreed upon period).\n\n- Expected Consensus slashes miners that sign two distinct blocks in the same slot as a means of speeding up convergence/disincentivizing forks.\n- Expected Consensus slashes miners that provably ignore smaller tickets from the tipset, as a means of grinding the chain (and unfairly winning leader election).\n\nThe collateral needs for both actions are distinct (in fact EC may not strictly require collateral).\n\n**EC vs SSLE**\n\n**Q**: What is the distinction between EC and SSLE?\n\n**A**: SSLE is an aspirational protocol for finding a single block proposer in leader election. EC is a consensus protocol that includes a block proposer and a way to achieve agreement (PoS Nakamoto consensus) on a particular block.\nEC's block proposer function is secret but it is not single.  0 or many blocks could be proposed in a given time slot.\nThe expected value of proposed leaders per time slot on any chain is 1.\nSSLE is an open-problem on which we are actively working as it should greatly simplify the Filecoin consensus construction and lead to faster convergence on the blockchain.\n\n## Communication\n\n- Slack channel: #filecoin-research\n- Issues in this repo\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/research/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/research/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT/)\n", "release_dates": []}, {"name": "core-devs", "description": "Technical Project Management: Meeting notes and agenda items", "language": null, "license": null, "readme": "# Core Devs Meetings\n\n## Purpose\nThe core devs meeting is a technical meeting intended to bring together various Filecoin teams who play major roles in determining the direction of the protocol. Filecoin implementation and research teams provide updates to their projects, discuss the implementation of various [FIPs](https://github.com/filecoin-project/FIPs), set priorities for network upgrades, and are convened for decisionmaking in the instance of a network -critical security breach or bug. \n\nCore Devs provide a central pillar of technical expertise to the broader Filecoin community as we work to build a decentralized, efficient, and robust foundation for humanity\u2019s most important information.\n\n## Recent Meetings\n\n \u2116  | Date                             | Agenda         |Notes          | Recording            |\n--- | -------------------------------- | -------------- |-------------- | -------------------- |\n49 | Thursday, September 1, 2022      | [agenda](https://github.com/filecoin-project/core-devs/issues/110) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200049.md) | [meeting](https://www.youtube.com/watch?v=Zm1eNpGK6Zw) |\n50 | Thursday, October 6, 2022      | [agenda](https://github.com/filecoin-project/core-devs/issues/111) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200050.md)| [meeting](https://www.youtube.com/watch?v=pvrGxhelIkU) |\n51 | Friday, November 11, 2022      | [agenda](https://github.com/filecoin-project/core-devs/issues/120) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200051.md)| [meeting](https://www.youtube.com/watch?v=NaaJ-pqzMxE) |\n52 | Thursday, December 1, 2022      | [agenda](https://github.com/filecoin-project/core-devs/issues/124) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200052.md)| [meeting](https://youtu.be/v_ljI98Xrl8) |\n53 | Thursday, January 5, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/124) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200053.md)| [meeting](https://youtu.be/MRV6f7jwVE0) |\n54 | Thursday, February 2, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/125) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting0054.md)| [meeting](https://youtu.be/5OxUyx_nrJA) |\n55 | Friday, March 3, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/131) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting0055.md)| [meeting](https://youtu.be/6Bz8-jK3K18) |\n56 | Thursday, April 6, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/134) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200056.md)| [meeting](https://youtu.be/upUHn21ZIlQ) |\n57 | Friday, May 5, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/136) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200057.md)| [meeting](https://youtu.be/Fdm-eq8Ie6w) |\n58 | Thursday, June 1, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/141) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200058.md)| [meeting](https://youtu.be/5-MVAhzC2nw) |\n59 | Thursday, July 6, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/142) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200059.md)| [meeting](https://youtu.be/qhd0u7z9Fnw) |\n60 | Thursday, August 3, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/144) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200060.md)| [meeting](https://youtu.be/77TnY_vmm94) |\n61 | Friday, September 1, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/146) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200061.md)| [meeting](https://youtu.be/s5msHsLjlB4) |\n62 | Thursday, October 5, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/152) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200062.md)| [meeting](https://youtu.be/YhsXe3hRcww) |\n63 | Friday, November 3, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/156) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200063.md)| [meeting](https://youtu.be/K9fa2WI00Mw) |\n64 | Thursday, December 7, 2023      | [agenda](https://github.com/filecoin-project/core-devs/issues/159) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200064.md)| [meeting](https://youtu.be/xY7MaLc5Y-U) |\n65 | Friday, January 19, 2024      | [agenda](https://github.com/filecoin-project/core-devs/issues/160) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200065.md)| [meeting](https://youtu.be/xnxFm5vAFfs) |\n66 | Thursday, February 1, 2024      | [agenda](https://github.com/filecoin-project/core-devs/issues/161) | [notes](https://github.com/filecoin-project/core-devs/blob/master/Core%20Dev%20Meetings/Meeting%200066.md)| [meeting](https://youtu.be/LzlRbDnsZtw) |\n\nA full record of all meeting notes can be found [HERE](https://github.com/filecoin-project/core-devs/tree/master/Core%20Dev%20Meetings). \n\n## Who Can Attend\nAs an open source project, anyone is able to contribute their work, skills, or other expertise to Filecoin.  Individuals do not need to be 'Core Devs' to develop the Filecoin tech stack, or make meaningful contributions to the Filecoin community. \n\nTypically, core devs are individuals who have 1) been involved in the project for a long time, are 2) deeply knowledge about the Filecoin protocol and related subsystems, and 3) are interested in committing their time and expertise to reviewing work and contributing technical guidance outside of their immediate work domain. Furthermore, individuals who serve as Core Devs are publicly known, expected to participate in monthly Core Devs meetings, and are included in closed communication channels in order to discuss technical issues related to the security and development of the Filecoin protocol. \n\n### Becoming a Core Dev\n* Anyone who wishes to become a Core Dev can send their request to the repo admin, Kaitlin Beegle (kaitlin@fil.org, or @kaitlin_FF on Slack) \n* Your request will be flagged for existing Core Devs, who are asked to consider your inclusion according to open source principles of [thoughtful meritocracy](https://postmeritocracy.org/). \n* If no one opposes your inclusion, you will be added to the meeting invite and all private groups.  You will be listed publicly as a Core Dev. \n* If anyone raises meaningful opposition to your inclusion, a simple majority vote to accept or reject your request will be levied at the next Core Devs meeting.\n\n### Core Dev Observers\nOccasionally, Filecoin community members may want or need to join a Core Devs meeting.  Common reasons for this include: \n   * They are authoring a FIP and have been asked to present their proposal. \n   * They have expertise in a topic of discussion, and have been asked to contribute their knowledge. \n   * Their work is relevant to a series of Core Dev discussions (e.g., network upgrades) but they do not want to contribute as full Core Devs. \n\nAs a reminder, being a Core Dev means opting into a position of community leadership, lending your time to help move forward work and technical discussions for the entire Filecoin community.  Individuals can be signficant contributors to Filecoin and not serve as Core Devs. Please keep these expectations in mind when you request to observe or become a part of the group. \n\nIf you'd like to be an observer, please send your request to Kaitlin via email (kaitlin@fil.org) and explain exactly how many meetings you expect to be able to attend. \n\n### Addendum: Removing a Core Dev\nOccassionally, the repo admins will review Core Dev attendance records and follow up with Core Devs who have been less engaged in the group.  These individuals will be reminded of group expectations and/or given the opportunity to step down as Core Devs. \n\nPlease note that Filecoin is a decentralized, global community.  As such, there are not currently any requirements for attendance or participation for Core Devs.  However, it is important that Core Devs be reachable, reliable, and engaged.  Anyone who wishes to maintain their status as a Core Dev is expected to be so. \n\nThough unlikely, anyone can propose the removal of someone as a Core Dev.  If a significant reason is raised for removal, a simple majority vote among current Core Devs will be taken at the next Core Devs meeting. \n\n## Meeting Scheduling \nThe schedule for Core Dev meetings periodically changes, depending on needs. \n\nCurrently, meetings occur monthly for one hour.  Exact timing alternates every other month: \n* 16:00 UTC on the first Thursday of the month (even-numbered months) \n* 00:00 UTC on the first Friday of the month (odd-numbered months) \n\n## Agenda Items\nAgendas are posted to https://github.com/filecoin-project/core-devs/issues. Anyone is welcome to add an item to the agenda.  Items should generally be technical in nature, and relate to FIPs, FRCs or other network standards, network upgrades, technical network operations, or security issues. \n\nPlease note that agenda items are accepted at the sole discretion of repo admins. \n\n## Who Manages the Meetings\nAs of August 2021, [@kaitlin-beegle](https://github.com/kaitlin-beegle) is the primary repo admin.  \n\nThe meetings are independent of any organization. However, the Filecoin Foundation pays for the videoconference software used in the meetings. \n\n", "release_dates": []}, {"name": "cpp-filecoin", "description": "C++17 implementation of Filecoin", "language": "C++", "license": {"key": "gpl-3.0", "name": "GNU General Public License v3.0", "spdx_id": "GPL-3.0", "url": "https://api.github.com/licenses/gpl-3.0", "node_id": "MDc6TGljZW5zZTk="}, "readme": "# Filecoin (cpp-filecoin)\n\n> C++17 implementation of blockchain based digital storage\n\nFilecoin is a decentralized protocol described in [spec](https://filecoin-project.github.io/specs/)\n\n## Minimal hardware requirements\n### Node minimal parameters:\n**Hard disk space**: at least 200 GB  \n**RAM**: 8 GB  \n**OS**: Linux(Ubuntu), macOS. Other operating systems builds are not supported yet, so running on them may be unstable.  \n### Miner minimal parameters:\n**CPU**: 8+ cores  \n**Hard Disk space**: 256 GiB of very fast NVMe SSD memory space + 1 TiB of slow HDD memory space  \n**RAM**: 16 GB  \n**GPU**: GPU is highly recommended, it will speed up computations, but Mixing AMD CPUs and Nvidia GPUs should be avoided.\n\nYou can also read about lotus minimal requirements in [filecoin-docs](https://docs.filecoin.io/mine/hardware-requirements/#specific-operation-requirements \"Minimal requirements filecoin-specific-configuration\")\n## Dependencies\n\nAll C++ dependencies are managed using [Hunter](https://github.com/cpp-pm/hunter).\nIt uses cmake to download required libraries and do not require downloading and installing packages manually.\n\nTarget C++ compilers are:\n* GCC 9.3.0\n* Clang 9.0.1\n* AppleClang 12.0.0\n\n### Lotus CLI\n`fuhon-node` supports subset of `lotus` CLI commands.  \nYou may download [pre-built binaries](https://github.com/filecoin-project/lotus/releases) or build [lotus](https://github.com/filecoin-project/lotus) from source.  \nLotus CLI [introduction](https://docs.filecoin.io/get-started/lotus/installation/#interact-with-the-daemon).\n\n### Rust\n[filecoin-ffi](https://github.com/filecoin-project/filecoin-ffi) provides pre-built binaries for some platforms.  \nIf they are unavailable, you need Rust compiler to build them.  \nRust [installation instruction](https://www.rust-lang.org/tools/install).\n\n## Build\n```sh\n# clone project\ngit clone --recursive https://github.com/filecoin-project/cpp-filecoin\n# configure cmake\ncmake cpp-filecoin -B cpp-filecoin/build\n# build and install fuhon-node and fuhon-miner\ncmake --build cpp-filecoin/build --target install\n# check that fuhon-node and fuhon-miner are now available\nfuhon-node --help\nfuhon-miner --help\n```\n\n## Usage\n\n### Interopnet node\n\nCreate the following `fuhon-interopnet/config.cfg` file\n```properties\n# use interopnet profile, corresponds to \"make interopnet\" lotus target\nprofile=interopnet\n\n# enable debug logs to see sync progress\nlog=d\n\n# bootstrap peers from https://github.com/filecoin-project/lotus/blob/master/build/bootstrap/interopnet.pi\nbootstrap=/dns4/bootstrap-0.interop.fildev.network/tcp/1347/p2p/12D3KooWLGPq9JL1xwL6gHok7HSNxtK1Q5kyfg4Hk69ifRPghn4i\nbootstrap=/dns4/bootstrap-1.interop.fildev.network/tcp/1347/p2p/12D3KooWFYS1f31zafv8mqqYu8U3hEqYvaZ6avWzYU3BmZdpyH3h\n```\n\nStart node\n```sh\nfuhon-node --repo fuhon-interopnet --genesis docker/interopnet/genesis.car\n# you can omit --genesis flag after first run\nfuhon-node --repo fuhon-interopnet\n```\n\nTo use lotus CLI add `--repo` flag\n```sh\nlotus --repo fuhon-interopnet net peers\n```\n\n### Mainnet node (from snapshot)\n\nDownload mainnet snapshot ([docs](https://docs.filecoin.io/get-started/lotus/chain)).\n```sh\nLATEST_SNAPSHOT=$(curl -sI https://fil-chain-snapshots-fallback.s3.amazonaws.com/mainnet/minimal_finality_stateroots_latest.car | perl -ne '/x-amz-website-redirect-location:\\s(.+\\.car)/ && print $1')\ncurl -o mainnet-snapshot.car $LATEST_SNAPSHOT\n```\n\nCreate following `fuhon-mainnet/config.cfg` file\n```properties\n# use downloaded snapshot file (do not delete that file)\nuse-snapshot=mainnet-snapshot.car\n\n# bootstrap peers from https://github.com/filecoin-project/lotus/blob/master/build/bootstrap/mainnet.pi\nbootstrap=/dns4/node.glif.io/tcp/1235/p2p/12D3KooWBF8cpp65hp2u9LK5mh19x67ftAam84z9LsfaquTDSBpt\n```\n\nStart node (first run may take some time)\n```sh\nfuhon-node --repo fuhon-mainnet --genesis cpp-filecoin/core/docker/mainnet/genesis.car\n```\n\n### Docker-compose example\n\n```sh\ndocker-compose up\n```\n\n## CodeStyle\n\nWe follow [CppCoreGuidelines](https://github.com/isocpp/CppCoreGuidelines).\n\nPlease use clang-format 11.0.0 with provided [.clang-format](.clang-format) file to autoformat the code.\n\n## Maintenance\n\nMaintainers: @zuiris, @turuslan, @Elestrias, @ortyomka, @wer1st, @Alexey-N-Chernyshov\n\nTickets: Can be opened in GitHub Issues.\n\n## Hunter cache upload\n\nIf you have access and want to upload to [hunter-binary-cache](https://github.com/soramitsu/hunter-binary-cache), you need to add your GitHub token with `read:packages` and `write:packages` permissions.  \nTo generate GitHub token follow the [instructions](https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line).\n```sh\nexport GITHUB_HUNTER_USERNAME=<github account name>\nexport GITHUB_HUNTER_TOKEN=<github token>\n```\n", "release_dates": ["2021-12-06T12:30:21Z", "2021-11-22T18:34:27Z"]}, {"name": "cryptolab", "description": "Filecoin research-development Cryptolab.", "language": "HTML", "license": null, "readme": null, "release_dates": []}, {"name": "dagstore", "description": "a sharded store to hold large IPLD graphs efficiently, packaged as location-transparent attachable CAR files, with mechanical sympathy", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "## DAG store\n\nThis README will be populated soon. In the meantime, please refer to the\n[design document](https://github.com/filecoin-project/dagstore/blob/master/docs/design.md).\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the\n[Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n", "release_dates": ["2023-03-07T14:32:58Z", "2023-02-09T15:42:58Z", "2023-01-27T12:43:14Z", "2022-10-03T12:18:51Z", "2022-09-30T10:16:50Z", "2022-09-20T11:36:38Z", "2022-08-10T11:12:36Z", "2022-02-23T13:19:23Z", "2022-01-12T09:06:22Z", "2022-01-12T07:32:39Z", "2021-11-12T15:49:28Z", "2021-08-18T10:11:54Z", "2021-08-06T15:13:30Z", "2021-08-05T13:24:16Z", "2021-07-30T14:27:02Z", "2021-07-29T20:09:36Z", "2021-07-27T17:20:44Z", "2021-07-26T13:52:18Z", "2021-07-21T03:16:06Z", "2021-07-20T10:50:09Z", "2021-07-13T15:54:26Z"]}, {"name": "data-prep-tools", "description": null, "language": "Python", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Data preparation for Filecoin\n\nThis repository contains information about everything related to data preparation that is\nrequired before onboarding data to [Filecoin](https://filecoin.io). This includes tooling,\ndocumentation, and performance benchmarks.\n\nThe repository is split into 4 main sections:\n\n1. [Docs](./docs): this section includes documentation explaining how data onboarding to\nfilecoin works, best practices and common pitfalls. It also contains links to available\ntools in the ecosystem.\n2. [Modules](./modules): the different data onboarding steps are encoded as modules\n(written in python and bash) which could be easily imported and used in any data\nonboarding pipeline.\n3. [Orchestrators](./orchestrators): these are example scripts demonstrating how to import\nand use the modules from the [modules section](./modules) to orchestrate data onboarding.\n4. [Performance benchmarks](./performance): these include performance benchmarks for\ndifferent available tools.\n\n\n## Other tools in the ecosystem\n\n- [banyancomputer/dataprep](https://github.com/banyancomputer/dataprep) -- this tool handles encryption, compression, deduping and chunking. The output of this tool could then be carred etc and used for deal making.\n\n\n## Lead Maintainer\n\n[Anjor](https://github.com/anjor)\n", "release_dates": []}, {"name": "data-transfer-benchmark", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Data Transfer Benchmark\n\n### What This Does\n\nThis test plan measures a series of transfers between two nodes with graphsync and go-data-transfer, optionally comparing them to HTTP and HTTP over libp2p. It offers a wide variety of configurable parameters, which are documented here.\n\n### Comparing performance\n\nThe included Testground composition demonstrates a comparison of GraphSync, HTTP, and libp2p over HTTP in transferring a 500MB CAR file under various network conditions. It uses unlimited bandwidth and three latencies, with interesting results. The big takeaway is we see the biggest performance drop comes from the switch traditional network to libp2p, at least with our go libraries. Here is a summary of the results:\n\n- **No Latency**: GraphSync is slowest, cause under unlimited bandwidth and no latency, the performance penalty of writing a CAR file block by block comes into play. HTTP is best and HTTP over Libp2p is slightly behind. Everything overall is fast.\n- **40ms roundtrip latency** (it says 20ms in pics but it\u2019s on both sides -- half of real world cross country US): we see Graphsync do extremely well \u2014 basically on par with HTTP. Both drop significantly from zero latency. HTTP over libp2p takes a big drop and runs the slowest by 3x\n- **80ms roundtrip latency** (close to real world latency conditions): this is where we see a 5x difference emerge with pure HTTP. Graphsync takes 44 seconds to transfer the file, HTTP takes 7. HTTP over libp2p tanks further, taking 2 minutes 38 seconds.\n\nConclusions:\nHTTP seems to excel under real world conditions. What\u2019s happening? I don\u2019t know. But it actually drops from around 20s to 7s between 40ms & 80ms! Perhaps go\u2019s http library (written by Google and used for downloads.google.com, so presumably written with an eye to performance) opens several connections at high latency? (essentially reverse multi-plexing).\n\n![run 1](./run1.png) ![run 2](./run2.png)\n\n### File Parameters\n\nThese parameters configure the nature of the file that is transfered:\n\n- `size` - size of file to transfer, in human-friendly form \n   - **Default**: 1MiB\n- `chunk_size` - unixfs chunk size (power of 2), controls the size of the leaves in file\n   - **Default**: 20 *(or 1MB chunks)*\n- `links_per_level` - unixfs links per level, controlles UnixFS DAG shape (wide vs deep) \n   - **Default**: 1024\n- `raw_leaves` - should unixfs leaves be raw bytes (true), or wrapped as protonodes (false)\n   - **Default**: true\n- `concurrency` - number of files to construct and attempt to transfer *simultaneously*\n   - **Default**: 1\n\nWhy you might want to change these:\n- obviously large file sizes more closely mirror use cases in a typical filecoin data transfer work load\n- the links per level, chunk size, and raw leaves allow you to expriment with different dag structures and see how graphsync performs in different conditions\n- concurrency allows you to test how graphsync performs under heavy loads of attempting transfer many files simultaneously\n- using car stores emulates the Lotus transfer flow, which is MUCH faster than using a single data store\n\n### Networking Parameters\n\nThese parameters control the parameters for the network layer\n- `secure_channel` - type secure encoding for the libp2p channel\n   - **Default**: \"noise\"\n- `transport` - setup libp2p to listen on either tcp or udp+quic\n   - **Default**: \"tcp\"\n- `latencies` - list of non-zero latencies to run the test under. \n   - **Default**: 100ms, 200ms, 300ms\n- `no_latency_case` - also run a test case with no latency \n   - **Default**: true\n- `bandwidths` - list limited bandwidths (egress bytes/s) to run the test under (written as humanized sizes). \n   - **Default**: 10M, 1M, 512kb\n- `unlimited_bandwidth_case` - also run a test case with unlimited latency\n   - **Default**: true\n\nWhy you might want to change these:\n- we may pay a penalty for the cost of transfering over secure io\n- bandwidth and latency parameters allow you to test graphsync under different network conditions. Importantly, these parameters generate a new test case for each instance, in a combinatorial form. So, if you you do two latencies and two bandwidths, you will get 4 rounds. And if concurrency is >1, each round with have more than one transfer\n\n### Graphsync Options\n\nThe parameters control values passed constructing graphsync that may affect overall performance. Their default values are the same default values is no value is passed to the graphsync constructor\n\n- `max_memory_per_peer` - the maximum amount of data a responder can buffer in memory for a single peer while it waits for it to be sent out over the wire\n   - **Default**: 16MB\n- `max_memory_total` - the maximum amount of data a responder can buffer in memory for *all peers* while it waits for it to be sent out over the wire\n   - **Default**: 256MB\n- `max_in_progress_requests` - The maximum number of requests Graphsync will respond to at once. When graphsync receives more than this number of simultaneous in bound requests, those after the first six (with a priotization that distributes evenly among peers) will wait for other requests to finish before they beginnin responding.\n   - **Default**: 6\n\nThese performance configuration parameters in GraphSync may cause bottlenecks with their default values. For example if the `concurrency` parameter is greater than 6, the remaining files will block until graphsync finishes some of the first 6. The buffering parameters may artificially lower performance on a fast connection. In a production context, they can be adjusted upwards based on the resources and goals of the graphsync node operator\n\n### HTTP Comparison Parameters\n\nThe parameters allow you to compare graphsync performance against transfer of the same data under similar conditions over HTTP\n\n- `compare_http` - run an HTTP comparison test\n   - **Default**: true\n- `compare_libp2p_http` - run an HTTP comparison test, but use HTTP running on top of a libp2p connection\n   - **Default**: true\n\n### Diagnostic Parameters\n\nThese parameters control what kind of additional diagnostic data the test will generate\n\n- `memory_snapshots` - specifies whether we should take memory snapshots as we run. Has three potention values: *none* (no snapshots), *simple* (take snapshots at the end of each request) and *detailed* (take snap shots every 10 blocks when requests are executing). Note: snapshoting will take a snapshot, then run GC, then take a snapshot again. *detailed* should not be used in any scenario where you are measuring timings\n   - **Default**: none\n- `block_diagnostics` - should we output detailed timings for block operations - blocks queued on the responder, blocks sent out on the network from the responder, responses received on the requestor, and blocks processed on the requestor\n   - **Default**: false\n\n\n### Jaeger Parameters\n\nThese parameters will collect traces to a running Jaeger instance. Note that\nthis is easiest to setup with the `local:exec` runner and fairly difficult with `local:docker` or `cluster:k8s`\n\n- `jaeger_collector_endpoint` - jaeger HTTP collector endpoint\n- `jaeger_username` - if using HTTP collector, username to authenticate with\n- `jaeger_password` - if using HTTP collector, password to authenticate with\n- `jaeger_agent_host` - jaeger Thrift UDP agent host\n- `jaeger_agent_port` - jaeger Thrift UDP agent port\n", "release_dates": []}, {"name": "dealbot", "description": "\ud83e\udd16\ud83e\udd1d A bot for making deals", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Dealbot\n\nA tool to test and analyze storage and retrieval deal capability on the Filecoin network.\n\n## Getting Started\n\nClone the repo and build:\n\n\tgit clone git@github.com:filecoin-project/dealbot.git\n\tcd dealbot\n\tgo build\n\nDealbot requires a local synced instance of [Lotus](https://github.com/filecoin-project/lotus/) to communicate with miners and the chain. This can be a Devnet instance for testing or a node connected to a larger network. The node needs to have wallet address with funds for making deals and a data cap for making verified deals (if verified deals are necessary).\n\n### Usage\n\nDealbot runs on multiple machines with a centralized controller. The controller can be started with:\n\n\t./dealbot controller --configpath config.toml\n\nSee dealbot-example.toml for configuration parameters. Individual Dealbot nodes run with the daemon command:\n\n\t./dealbot --api [LOTUS_API_URL] daemon --configpath config.toml\n\nThe `--api` parameter points to the Lotus API and can be specified as a URL token pair. Alternatively you can specify `--lotus-path` either as a parameter or environment variable:\n\n\t--api [lotus_api_url]:[lotus_api_token]\n\texport FULLNODE_API_INFO=[lotus_api_url]:[lotus_api_token]\n\t--lotus-path ~/.lotus\n\texport LOTUS_PATH=~/.lotus\n\nDealbot can also run individual storage or retrieval task when invoked from the command-line with:\n\n\t./dealbot --api [api] storage-deal --data-dir [shared-dir] --miner [miner-address] --size 2GB\n\nor\n\n\t./dealbot --api [api] retrieval-deal --data-dir [shared-dir] --miner [miner-address] --cid [payload-cid]\n\nTo start Lotus locally, or tunnel to a remote Lotus, see [devnet/README.md](devnet/README.md).\n\n### Flags\n\nDealbot Controller\n\n| Flag | Env Var | Function |\n| :--- | :--- | --- |\n| listen | `DEALBOT_LISTEN` | exposed `host:port` for daemons to contact and for tasking the system |\n| graphql | `DEALBOT_GRAPHQL_LISTEN` | exposed `host:port` for external public graphql queries |\n| metrics | `DEALBOT_METRICS` | either `prometheus` to expose a `/metrics` api, or `log` to write metrics to stdout |\n| identity | `DEALBOT_IDENTITY_KEYPAIR` | filepath of a libp2p identity to sign public records of dealbot activity |\n| driver | `DEALBOT_PERSISTENCE_DRIVER` | `postgres` |\n| dbloc | `DEALBOT_PERSISTENCE_CONN` |  db conn string from postgres |\n| gqlAccessToken | `DEALBOT_GRAPHQL_ACCESS_TOKEN` | a static key for querying non-public data from the graphql server |\n| devAssetDir| - | serve controller assets from disk rather the compiled binary for development |\n| basicauth | `DEALBOT_BASICAUTH` | basic authentication credentials if the controller is being served behind them to make xhrs work in that environment |\n| datapointlog | `DEALBOT_DATAPOINT_LOG` | file / stream to write out a json line for each completed task |\n| gateway-api | `DEALBOT_LOTUS_GATEWAY` | address of lotus gateway to query for wallet balances for controller UX |\n\nDealbot Daemon\n\n| Flag | Env Var | Function |\n| :--- | :--- | --- |\n|  id | `DEALBOT_ID` | The worker name to report to the controller |\n| listen | `DEALBOT_LISTEN` | a `host:port` to bind to when metrics are exposed |\n| stage-timeout | `STAGE_TIMEOUT` | a list of stagenames and timeouts (example: DealAccepted=15m) |\n| tags | `DEALBOT_TAGS` | tags to use when accepting tasks |\n| workers | `DEALBOT_WORKERS` | how many tasks to accept at a time |\n| minfil | `DEALBOT_MIN_FIL` | minimum balance lotus must report before the bot will accept tasks |\n| mincap | `DEALBOT_MIN_CAP` | minimum dealcap lotus must report before the bot will accept tasks |\n| posthook | `DEALBOT_POST_HOOK` | a bash script that will be run as `bash $posthook $uuid` when a task finishes |\n| endpoint | `DEALBOT_CONTROLLER_ENDPOINT` | the `host:port` of the controller to ask for tasks |\n| data-dir | `DEALBOT_DATA_DIRECTORY` | the directory for the bot to make cars in or verify they have shown up in |\n| node-data-dir | `DEALBOT_NODE_DATA_DIRECTORY` | the directory for lotus to import the cars from or write them to |\n| wallet | `DEALBOT_WALLET_ADDRESS` | an explicit wallet to use with lotus if not the default one |\n \n## Versioning and Releases\n\nTagged releases indicate versions run on our local deployment.\nSemver is used to indicate when data would be lost on downgrading (miner version bumps) and when data becomes incompatible (major version bumps)\n\n## Code of Conduct\n\nDealbot follows the [Filecoin Project Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md). Before contributing, please acquaint yourself with our social courtesies and expectations.\n\n\n## Contributing\n\nWe welcome [new issues](https://github.com/filecoin-project/dealbot/issues/new) and [pull requests](https://github.com/filecoin-project/dealbot/pulls).\n\n\n## License\n\nThe Filecoin Project and Dealbot is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/dealbot/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/dealbot/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": ["2022-05-06T13:57:01Z", "2022-05-06T13:42:20Z", "2022-05-04T10:31:19Z", "2022-03-08T13:15:49Z", "2022-03-07T11:37:27Z", "2022-03-04T14:38:33Z", "2022-03-02T15:13:31Z", "2022-03-01T12:06:02Z", "2022-02-25T13:26:18Z", "2022-02-23T10:29:27Z", "2022-02-23T09:47:09Z", "2022-02-17T13:29:43Z", "2022-02-15T17:25:25Z", "2022-02-11T17:21:05Z", "2021-12-09T15:38:44Z", "2021-12-08T00:12:13Z", "2021-12-06T23:18:50Z", "2021-12-01T20:00:36Z", "2021-12-01T18:05:09Z", "2021-09-14T18:53:53Z", "2021-07-26T21:54:24Z", "2021-07-23T23:12:57Z", "2021-07-23T16:24:54Z", "2021-07-20T10:37:07Z", "2021-07-20T00:19:23Z", "2021-07-19T20:07:47Z", "2021-07-16T20:19:36Z", "2021-07-14T14:12:58Z", "2021-07-14T01:53:25Z", "2021-07-09T22:52:25Z"]}, {"name": "designdocs", "description": "Docs that capture the design intent for important components", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Design Docs\nThis README is an index of documents for important components and changes, as well as notes, thoughts, and discussions that don't fit anywhere else yet.\n\nSee [Design Docs: What are they and how we use them](designdocs.md).\n\n## Design Docs\n_Newest to oldest_\n\n* [Filecoin Chain-Validation Tools](https://docs.google.com/document/d/1o0ODvpKdWsYMK_KmK-j-uPxYei6CZAZ4n_3ilQJPn4A/edit?usp=sharing) - November 2019\n* [Filecoin component architecture](https://docs.google.com/document/d/1ukPD8j6plLEbbzUjxfo7eCauIrOeC_tqxqYK_ls9xbc/edit#) - October 2019\n* [Go-filecoin code layout](https://docs.google.com/document/d/15P3laXxXSUR_FKcqkhzyrvcJNOQFV_JBJ4go4zPo714/edit#) - September 2019\n* [JSON REST API Rationale and Plan](https://docs.google.com/document/d/1ANnTHOU-8612ayvvS7Ru4B1L4voojLE0R0TQ8zF1x5s/edit#) - Aug 2019\n* [Protocol Upgrade Table](https://docs.google.com/document/d/17VsfFQk1mZKJj9gkXgSzIPWZAcVeL7VyNjP-is576e4/edit#) - July 2019\n* [Hello Protocol and Protocol Versions](https://docs.google.com/document/d/1w8ki-7EGaqk41Vbjn4tHLeEVQIjhIzHOCcPXiT8mLRM/edit#) - July 2019\n* [Separating Messages from Block](https://docs.google.com/document/d/1xOHUeM-svZoE3qQtOPCx1U96EQ6CuKsfB2GJYOHOk18/edit?usp=sharing) July 2019\n* [Faults & Slashing implementation](https://docs.google.com/document/d/1U3b9GVNVOLoS_-q9kXU3a9dqHGvcrHprwDFzNYgLI0M/edit#) - June 2019\n* [SectorSet and Bitfield Implementation Plan](https://docs.google.com/document/d/1aE5a-QZojprMkig6IyYkwV1SrMDDLOnNBqNdnwpu9tk/edit?usp=sharing) - June 2019\n* [Model for change: Filesystem repo migrations](https://docs.google.com/document/d/1THzh1mrNCKYbdk1zP72xV8pfr1yQBe2n3ptrSAYyVI8/edit?usp=sharing) - April 2019\n* [Slashing Mechanism](https://docs.google.com/document/d/1bGjNI4wItBWgH5SOxpLNFF3ij85CRKG_uRVSbI7yLS4/edit#heading=h.2xtbr35i3dx3) - March 2019\n* [Outbound Message Queue](https://docs.google.com/document/d/1Ns5_ushX9exsKr0xbc2Kt0ZHzAA0WnVvl42hyGRR5l0/edit) - March 2019\n* [Message Tracking](https://docs.google.com/document/u/2/d/1Ofoid90l9JwyW8zUy00kaHdvpLoV4gr2mcN3s4irkPY/edit?usp=drive_web&ouid=117191042581679083795) - Feb 2019\n* [Porcelain/Plumbing Refactor Plan](https://docs.google.com/document/u/2/d/1L5hbcDGhfH3AlMti4RQ3Zke6nc4-eGOmk9lD0nNoiEs/edit?usp=drive_web&ouid=117191042581679083795) - Feb 2019\n* [meta] [Design Docs: What are they and how we use them](https://github.com/filecoin-project/designdocs/blob/master/designdocs.md) - Aug 2018\n\n### Video Recordings\n_Explainer talks or demos._\n\n### Other Writeups & Notes\n_Other writeups or less-edited notes from discussions & meetings_\n* [Are We Speced Yet?](https://docs.google.com/spreadsheets/d/1zh7Ys6Tr0y4nLsR9d9e28Q0pYNBvclmcgHU3yuwMhSI/edit?usp=sharing)\n\n## How to Create New Design Docs\nWe follow a process to ensure that new design docs are accessible and communicated widely.\n* Create a GitHub issue for the design doc in the appropriate repository (e.g. [go-filecoin](https://github.com/filecoin-project/go-filecoin), [consensus](https://github.com/filecoin-project/consensus)).\n* Create a new Google doc in the `Filecoin Community` team drive, `Design Docs` folder.\n  * Check that you're using the GApps identity of your choice.\n  * Use `DRAFT`, `IN REVIEW`, `IMPLEMENTING` near the top of the content to note status.\n* When you're ready, enable public comments. As of April 2019, this takes 5 clicks:\n  * Click \"Share\" button.\n  * Click \"Who has access\" to open the advanced settings panel.\n  * Toggle on \"Link sharing\".\n  * Choose who: \"Anyone with the link\".\n  * In the dropdown after \"Access\", select \"Can comment\".\n* Add an entry with shareable link in this README's list of design docs, thus making the document public (you can commit directly).\n* Email a link to the `dev@filecoin.org` email list, which will reach all committers. \nAlso announce in `#fil-dev` or other appropriate channel the filecoin-project Slack.\n  * This email thread will function as a low-noise channel for high-level discussion of the proposal.\n* Solicit feedback from individuals and/or channels, evolving the design as needed.\n  * Advertise major changes with a post to the email/slack threads where the design was announced.\n  * Seek approval from at least one maintainer before considering the proposal accepted.\n* Once ready, translate into GitHub/ZenHub epics or issues according to the appropriate repo's contributing guide.\n\nNote: people outside committers and some other full-time project contributors cannot directly place docs in the team drive.\nIf a document originates outside this set but is accepted, a committer should copy the content into the team drive.\n\nAs an alternative to Google Drive, a design doc may be drafted in a PR to a markdown file in the `docs` directory of this repository.\n\n\n## Contributing to this repo\nWe play fast and loose in this here `designdocs` repo, but not recklessly.\n- If you are adding new content, committers can commit directly.\n- If you are editing or refactoring existing content, get 1 reviewer (preferably the original author, but others if they're not available). \nIf they don't reply in 3 days with reasonable reminding efforts, committers can commit directly.\n", "release_dates": []}, {"name": "dev-wg", "description": "A documentation repo for the Developers Working Group. ", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# dev-wg\nA documentation repo for the Developers Working Group. \n", "release_dates": []}, {"name": "DeveloperWG", "description": null, "language": null, "license": null, "readme": "# Developer WG (DevWG)\n\n### Mission and Purpose\nThe Developer WG is a space to connect with developers, community members, researchers, and others interested in the development of new tools, technologies, and use cases that leverage the Filecoin protocol. \nThe purpose of the Developer WG is to organize participants around key areas of interest to the Filecoin developer community.  By participating, community members can: \n- Share knowledge and perspective in areas that incorporate their technical or industry expertise;\n- Raise challenges and questions for collective deliberation; \n- Advocate the importance of developing in specific areas of the Filecoin Network;\n- Provide updates on projects and future plans within the Filecoin ecosystem, and;\n- Discuss open FIPs and develop a coordinated presence in the Filecoin governance process. \n\nWhile Filecoin Foundation provides administration support to community working groups, the Developer WG is a community body that is independent of any single organization. Discussions, coordination activities, and other initiatives are carried out at the sole discretion of active working group members. The Developer WG is intended to be self-governed and self-maintained in accordance with open source best practices\n\n### Who Should Join?\n\nEcosystem contributors and learners who intend to build, research or otherwise support development activities on top of the Filecoin protocol are encouraged to join! Though conversations are often technical in nature, all interested parties are welcome to participate regardless of skill set or background. \n\nIn order to ensure alignment with the mission and purpose of the group, it is expected that all participants share a mutual interest in developing Filecoin use cases in support of Filecoin\u2019s mission. Please also note that the DevWG is entirely distinct from [Core Devs](https://github.com/filecoin-project/core-devs), a separate community group responsible for overseeing the technical development of the core Filecoin protocol. \n\nWorking group participation is both optional and voluntary. All participants are required to adhere to the Filecoin Community Code of Conduct.  Participants found by the group to be in violation of these guidelines are subject to censorship and/or removal by the group. \n\n### Joining the Working Group\n\nParticipants can engage in the Developer WG through the following connection points:\n- Attend Quarterly calls. \n- DM @Erin O\u2019Connor on Filecoin Project Slack or email erin@fil.org to be added to the meeting.\n- Join the #dev-wg Slack channel.\n- Create an Issue in this Github repo to add a new agenda item.\n\nThe Developer WG is a means for those active or highly interested in the Filecoin ecosystem to  engage in meaningful discussion over the future of Filecoin.  \n\n### Recent Meetings\n\n| Number | Date       | Agenda  | Notes|\n| :---   | :------                 | :---                                                       | :---                       | \n| 1.     |                         |                                                            |                            | \n| 2.     |                         |                                                            |                            | \n| 3.     |                         |                                                            |                            | \n| 4.     |                         |                                                            |                            | \n\n\nWhile the meetings are independent of any organization, the Filecoin Foundation pays for the videoconference software used in the meetings. @erinOCon is the primary repo admin.\n", "release_dates": []}, {"name": "devgrants", "description": "\ud83d\udc5f Apply for a Filecoin devgrant. Help build the Filecoin ecosystem!", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "\n\n# Filecoin Grants\n\n\nWelcome to the Filecoin Grant Platform! The Filecoin Grant Platform connects grant makers with builders and researchers in the Filecoin community. Whether you represent a foundation that wants to move the space forward, a company looking to accelerate development on the features your application needs, or a dev team itching to hack on Filecoin tools, you've come to the right place. Take a look at the supported grant types and available opportunities below.\n\n## Grant Types\n\n---\n\n### Open Grant\nDo you have an idea for pushing the Filecoin ecosystem forward? Grants up to $50,000 are available to support novel ideas that advance the Filecoin ecosystem, bring significant new usage, or directly advance the Filecoin mission statement.\n\n\n[**LEARN MORE ABOUT OPEN GRANTS**](https://github.com/filecoin-project/devgrants/blob/master/Program%20Resources/Open%20Grants%20README.md) **AND** [**APPLY FOR AN OPEN GRANT**](https://github.com/filecoin-project/devgrants/issues/new/choose)\n\n---\n\n### Requests for Proposals (RFPs)\nRFPs are grants for specific development work. As the name suggests, we are requesting proposals from teams that want to complete the work specified in each RFP. In these grants, we generally have clearly scoped deliverables, milestones, and funding limits. Some RFPs will ask you to propose your own milestones and funding needs. While there is some flexibility in RFP deliverables, we expect teams will deliver what is in scope in the RFP. Any deviations from the specified scope must be approved between your team and ours before we can approve funding. RFPs may be funded by Protocol Labs, other community members, or a consortium of interested parties.\n\nOPEN RFPs: Keep an eye out for future RFPs!\n\nCLOSED RFPs:\n\n* [Zcash x Filecoin](https://github.com/filecoin-project/devgrants/blob/master/Archive/rfps/zcash-and-filecoin.md)\n* [FVM Tooling & Infrastructure](https://github.com/filecoin-project/devgrants/blob/master/Archive/rfps/fvm-open-tools-infra.md)\n* [Green Grants](https://github.com/filecoin-project/devgrants/blob/master/Archive/rfps/green-grants.md)\n* [Filecoin-solidity Phase II: Optimization, improvements and maintenance](https://github.com/filecoin-project/devgrants/blob/master/Archive/rfps/Filecoin-solidity-Optimization.md) \n\n---\n\n### Next Step Microgrants\n\nGrants of $5,000 in FIL are available to support those taking the _next step_ after creating an initial prototype with Filecoin, IPFS, or related technologies.\n\nSince January 27, 2023, microgrants are exclusively awarded for projects within rotating [Microgrant focus areas](https://github.com/filecoin-project/devgrants/blob/master/Program%20Resources/Microgrants%20README.md#focusareas). Applications for the most recent focus area, [Filecoin Virtual Machine](https://fvm.filecoin.io/), are currently being processed. \n\nIf you have (1) a working prototype that matches the current focus area and (2) concrete _next steps_ for your project, consider applying for a microgrant!\n\nThis program is intended for early stage projects. If your project has already received more than $30,000 USD from any source, please apply for an open grant (details below) rather than a microgrant.\n\n[**LEARN MORE ABOUT MICROGRANTS**](https://github.com/filecoin-project/devgrants/blob/master/Program%20Resources/Microgrants%20README.md) **AND** [**APPLY FOR A MICROGRANT GRANT**](https://github.com/filecoin-project/devgrants/issues/new/choose)\n\n---\n\n### Don't see your grant type?\nIs your organization interested in offering a grant that doesn't fit into any of the above categories? [Email us directly](mailto:grants@fil.org) with your idea.\n\n", "release_dates": []}, {"name": "docker-hub-exporter", "description": "Prometheus exporter for the Docker Hub", "language": "Go", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Prometheus Docker Hub Exporter\n\nExposes metrics of container pulls and stars from the Docker Hub API, to a Prometheus compatible endpoint. The exporter is capable of pulling down stats for individual images, or for orgs or users from DockerHub. This is based on the un-documented V2 Docker Hub API.\n\n## Configuration\n\nThe image is setup to take parameters from environment variables or flags:\n\nThe available environment variables are:\n\n* `BIND_PORT` The port you wish to run the container on, defaults to 9170\n* `ORGS` The docker hub organizations you wish to monitor, expected in the format \"org1, org2\" (Also works for users)\n* `IMAGES` The images you wish to monitor, expected in the format \"user/image1, user/image2\". Can be across different dockerhub users.\n\n\nBelow is a list of the available flags. You can also find this list by using the `--help` flag.\n\n* `images` Images you wish to monitor: expected format 'user/image1,user/image2'\n* `listen-address` Address on which to expose metrics and web interface. (default \":9170\")\n* `organisations` Organisations/Users you wish to monitor: expected format 'org1,org2'\n* `telemetry-path` Path under which to expose metrics. (default \"/metrics\") \n\n## Install and deploy\n\nRun manually from Docker Hub:\n```\ndocker run -d --restart=always -p 9170:9170 filecoin/docker-hub-exporter -listen-address=:9170\n```\n\nBuild a docker image:\n```\ndocker build -t <image-name> .\ndocker run -d --restart=always -p 9170:9170 <image-name> -listen-address=:9170 -images=\"filecoin/lotus,filecoin/docker-hub-exporter\" -organisations=\"filecoin\"\n```\n\n## Known Issues\n\nCurrently there is a known issue with this build where if you provide a image or list of images belonging to an organisation\nthat has also been passed into the application then Prometheus will error during metrics gathering reporting that the metric was already collected with the same name and labels.\n\n## Metrics\n\nMetrics will be made available on port 8080 by default\nAn example of these metrics can be found in the `METRICS.md` markdown file in the root of this repository\n", "release_dates": []}, {"name": "drg-attacks", "description": null, "language": "Rust", "license": null, "readme": "[![CircleCI](https://circleci.com/gh/filecoin-project/drg-attacks.svg?style=svg)](https://circleci.com/gh/filecoin-project/drg-attacks)\n\n# Attacks on DRG Graph \n\nThis repository is a library for generating *Depth Robust Graphs* as well\ncontains code for *attacking* those graphs. This repository holds as well the\ncode to generate results based on the attacks and is the baseline for the\nchallenge.\n\n## Depth Robust Graphs\n\nA depth robust graph is a directed graph where the label of a node depends on\nits parent and with the following property:\n> After removing any subset of up to e nodes (and adjacent edges) there remains\n> a directed path of length d.\n\nOne usage of these graphs is to enforce a long sequential computation even\nagainst adversarial behavior thanks to this directed path.\n\nYou can find the code to generate multiple kind of such graphs in `src/graph.rs`\nfile.\n\n## Attacks\n\nThe theoretical bounds for the DRG properties are unfortunately very low, and\ncan't be used to derive practical applications of DRGs. There are\nempirical attacks that thrive to find the smallest set of nodes to remove to\nreach a given depth (or find the smallest depth for a given size of nodes to\nremove): these attacks are called *depth-reducing set* attacks.\n\nYou can find multiple implementations of different such attacks in\n`src/attacks.rs`. In particular there are two general \"kinds\" of attacks\nimplemented:\n- **Valiant based attacks**: these attacks rely on the Valiant Lemma to iteratively\n  construct the set of nodes to remove which results in an graph which has\n  half of the size at each steps. \n- **Greedy attacks**: these attacks are trying to find the best set of nodes\n  possible according to some heuristics.\n\n## Resource\n\nThe most comprehensive resource is from Blocki et al. from 2019: [paper](https://eprint.iacr.org/2018/944.pdf)\nAlwen et al. first showed the DRSample algorithm and the valiant based depth\nreducing attacks in this [CCS paper](https://eprint.iacr.org/2018/944.pdf)\n", "release_dates": []}, {"name": "ec-gpu", "description": "OpenCL code generator for finite-field arithmetic over arbitrary prime fields", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# `ec-gpu` & `ec-gpu-gen`\n\n[![crates.io][crate-image-ec-gpu]][crate-link-ec-gpu]\n[![Documentation][doc-image-ec-gpu]][doc-link-ec-gpu]\n[![Build Status][build-image-ec-gpu]][build-link-ec-gpu]\n![minimum rustc 1.51][msrv-image-ec-gpu]\n[![dependency status][deps-image-ec-gpu]][deps-link-ec-gpu]\n\n[![crates.io][crate-image-ec-gpu-gen]][crate-link-ec-gpu-gen]\n[![Documentation][doc-image-ec-gpu-gen]][doc-link-ec-gpu-gen]\n[![Build Status][build-image-ec-gpu-gen]][build-link-ec-gpu-gen]\n![minimum rustc 1.51][msrv-image-ec-gpu-gen]\n[![dependency status][deps-image-ec-gpu-gen]][deps-link-ec-gpu-gen]\n\nCUDA/OpenCL code generator for finite-field arithmetic over prime fields and elliptic curve arithmetic constructed with Rust.\n\nNotes:\n - Limbs are 32/64-bit long, by your choice (on CUDA only 32-bit limbs are supported).\n - The library assumes that the most significant bit of your prime-field is unset. This allows for cheap reductions.\n\n## Usage\n\n### Quickstart\n\nGenerating CUDA/OpenCL codes for `blstrs` Scalar elements:\n\n```rust\nuse blstrs::Scalar;\nuse ec_gpu_gen::SourceBuilder;\n\nlet source = SourceBuilder::new()\n    .add_field::<Scalar>()\n    .build_64_bit_limbs();\n```\n\n### Integration into your library\n\nThis crate usually creates GPU kernels at compile-time. CUDA generates a [fatbin], which OpenCL only generates the source code, which is then compiled at run-time.\n\nIn order to make things easier to use, there are helper functions available. You would put some code into `build.rs`, that generates the kernels, and some code into your library which then consumes those generated kernels. The kernels will be directly embedded into your program/library. If something goes wrong, you will get an error at compile-time.\n\nIn this example we will make use of the FFT functionality. Add to your `build.rs`:\n\n```rust\nuse blstrs::Scalar;\nuse ec_gpu_gen::SourceBuilder;\n\nfn main() {\n    let source_builder = SourceBuilder::new().add_fft::<Scalar>()\n    ec_gpu_gen::generate(&source_builder);\n}\n```\n\nThe `ec_gpu_gen::generate()` takes care of the actual code generation/compilation. It will automatically create a CUDA and/or OpenCL kernel. It will define two environment variables, which are meant for internal use. `_EC_GPU_CUDA_KERNEL_FATBIN` that points to the compiled CUDA kernel, and `_EC_GPU_OPENCL_KERNEL_SOURCE` that points to the generated OpenCL source.\n\nThose variables are then picked up by the `ec_gpu_gen::program!()` macro, which generates a program, for a given GPU device. Using FFT within your library would then look like this:\n\n```rust\nuse ec_gpu_gen::{\n    rust_gpu_tools::Device,\n};\n\nlet devices = Device::all();\nlet programs = devices\n    .iter()\n    .map(|device| ec_gpu_gen::program!(device))\n    .collect::<Result<_, _>>()\n    .expect(\"Cannot create programs!\");\n\nlet mut kern = FftKernel::<Fr>::create(programs).expect(\"Cannot initialize kernel!\");\nkern.radix_fft_many(&mut [&mut coeffs], &[omega], &[log_d]).expect(\"GPU FFT failed!\");\n```\n\n## Feature flags\n\nThis crate supports CUDA and OpenCL, which can be enabled with the `cuda` and `opencl` feature flags.\n\n### Environment variables\n\n - `EC_GPU_CUDA_NVCC_ARGS`\n\n     By default the CUDA kernel is compiled for several architectures, which may take a long time. `EC_GPU_CUDA_NVCC_ARGS` can be used to override those arguments. The input and output file will still be automatically set.\n\n    ```console\n    // Example for compiling the kernel for only the Turing architecture.\n    EC_GPU_CUDA_NVCC_ARGS=\"--fatbin --gpu-architecture=sm_75 --generate-code=arch=compute_75,code=sm_75\"\n    ```\n\n - `EC_GPU_FRAMEWORK`\n\n    When the library is built with both CUDA and OpenCL support, you can choose which one to use at run time. The default is `cuda`, when you set nothing or any other (invalid) value. The other possible value is `opencl`.\n\n    ```console\n    // Example for setting it to OpenCL.\n    EC_GPU_FRAMEWORK=opencl\n    ```\n\n - `EC_GPU_NUM_THREADS`\n\n   Restricts the number of threads used in the library. The default is set to the number of logical cores reported on the machine.\n\n    ```console\n    // Example for setting the maximum number of threads to 6.\n    EC_GPU_NUM_THREADS=6\n    ```\n\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n\n\n[crate-image-ec-gpu]: https://img.shields.io/crates/v/ec-gpu.svg\n[crate-link-ec-gpu]: https://crates.io/crates/ec-gpu\n[doc-image-ec-gpu]: https://docs.rs/ec-gpu/badge.svg\n[doc-link-ec-gpu]: https://docs.rs/ec-gpu\n[build-image-ec-gpu]: https://circleci.com/gh/filecoin-project/ec-gpu.svg?style=shield\n[build-link-ec-gpu]: https://circleci.com/gh/filecoin-project/ec-gpu\n[msrv-image-ec-gpu]: https://img.shields.io/badge/rustc-1.54+-blue.svg\n[deps-image-ec-gpu]: https://deps.rs/repo/github/filecoin-projectt/ec-gpu/status.svg\n[deps-link-ec-gpu]: https://deps.rs/repo/github/filecoin-project/ec-gpu\n\n\n[crate-image-ec-gpu-gen]: https://img.shields.io/crates/v/ec-gpu-gen.svg\n[crate-link-ec-gpu-gen]: https://crates.io/crates/ec-gpu-gen\n[doc-image-ec-gpu-gen]: https://docs.rs/ec-gpu-gen/badge.svg\n[doc-link-ec-gpu-gen]: https://docs.rs/ec-gpu-gen\n[build-image-ec-gpu-gen]: https://circleci.com/gh/filecoin-project/ec-gpu.svg?style=shield\n[build-link-ec-gpu-gen]: https://circleci.com/gh/filecoin-project/ec-gpu\n[msrv-image-ec-gpu-gen]: https://img.shields.io/badge/rustc-1.54+-blue.svg\n[deps-image-ec-gpu-gen]: https://deps.rs/repo/github/filecoin-projectt/ec-gpu/status.svg\n[deps-link-ec-gpu-gen]: https://deps.rs/repo/github/filecoin-project/ec-gpu\n\n[Fast Fourier transform]: https://en.wikipedia.org/wiki/Fast_Fourier_transform\n[fatbin]: https://en.wikipedia.org/wiki/Fat_binary#Heterogeneous_computing\n", "release_dates": []}, {"name": "ecodash", "description": "A community-managed Filecoin ecosystem directory and showcase", "language": "Vue", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Filecoin Ecosystem Directory\n[![Twitter Follow](https://img.shields.io/twitter/follow/filecoin?style=social)](https://twitter.com/Filecoin) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) ![Validation](https://github.com/filecoin-project/ecodash/actions/workflows/validation.yml/badge.svg?branch=develop)\n\nAn interactive ecosystem directory and showcase, visible on [ecosystem.filecoin.io](https://ecosystem.filecoin.io)\n\n![Data Programs graph image](static/images/open-graph.png)\n\n***\n\n## Adding or editing a project\n\nThis is a public repository, and you can add a new project or amend an existing project by submitting a pull request (PR). Your PR should contain a `json` file in `content/projects/` with your changes. This file must conform to a specific schema, otherwise one of the checks will fail.\n\nLet's go through the steps to adding a new project. Editing a project is a simpler version of the same process, where you do not have to create a new file. \n\nYou can follow these steps by editing directly in Github, or by cloning the repo and editing locally.\n\n1. Create a new `json` file in `content/projects/my-project.json`, where `my-project` is the lowercase alphanumeric kebab-case name of your project (for example, a project called \"Hello World Labs\" would become `hello-world-labs.json`)\n\n2. Copy the contents of the template, found in [`content/project-template.json`](content/project-template.json) (do not change this file, only copy), and add it to your file\n\n3. Replace the content in the file with your project's data (see next section for detailed constraints and limitations)\n\n4. Upload a sqare icon to `static/images/projects` and reference that file name in the `icon` key of your json (only the file name is needed, not the full path)\n\n5. Create commit your changes and create a pull request against the `main` branch using the pull request template\n\n6. If all checks pass, your PR will be reviewed by a community administrator\n\n\n## Project schema\n\nEach modified `json` file in `content/projects` runs through several CI checks: \n\n1. The first checks to ensure that the `json` is syntactically valid\n2. The second performs more advanced checks:\n  - `json` keys and values must match certain criteria (e.g., they exist, meet minimums, maximums, etc.)\n  - Categories and subcategories must follow the defined taxonomy (defined in `taxonomy.json`)\n  - Images are sized correctly (< 500px for raster images and 1:1 aspect ratio)\n\nIn order to pass these checks, you should be aware of the schema, and its contraints. Let's take a look at a sample data structure, pre-filled with some content.\n\n```json\n{\n    \"display\": true,\n    \"since\": 2023,\n    \"icon\": \"icon-myproject.png\",\n    \"name\": \"My Project\",\n    \"org\": \"Optional Parent Company Name\",\n    \"description\": \"One to several sentences describing your project\",\n    \"website\": \"//myproject.xyz\",\n    \"social\": [\n        { \"github\": \"//github.com/myproject\" },\n        { \"twitter\": \"//twitter.com/myproject\" }\n      ],\n    \"taxonomy\": [\n      {\n        \"category\": \"finance\",\n        \"subcategories\": [ \"leasing-and-staking\", \"exchanges-and-swaps\", \"infrastructure-and-other\", \"bridges-and-oracles\" ]\n      },\n      {\n        \"category\": \"media-and-entertainment\",\n        \"subcategories\":  [ \"arts-and-collectibles\", \"photo-and-video\", \"music\", \"gaming\", \"communication-and-social\", \"publishing-and-news\" ]\n      },\n      {\n        \"category\": \"tooling-and-productivity\",\n        \"subcategories\": [ \"wallets-identity-and-authentication\", \"network-explorers-and-reputation\", \"developer-tools-and-other\", \"privacy-and-security\", \"ai-productivity-and-utilities\" ]\n      },\n      {\n        \"category\": \"storage-and-cloud-services\",\n        \"subcategories\": [ \"data-storage-and-management\", \"data-retrieval\", \"compute-services\", \"data-curation-and-monetization\", \"enterprise-solutions\" ]\n      },\n      {\n        \"category\": \"education-science-and-public-goods\",\n        \"subcategories\": [ \"governance-daos-and-public-goods\", \"education-and-science\" ]\n      }\n    ],\n    \"tags\": [ \"optionally\", \"include\", \"some\", \"tags\", \"like\", \"fvm\" ]\n  }\n  \n```\n\n## Project validation rules\n\n#### Global rules\n\nThere are two rules that apply globally to all the fields:\n\n1. Written content should be in English, therefore all content fields accept only `Latin-1` characters\n2. If an optional top-level field is not in use, it should still appear in the data structure, but with an empty value, such as `[]` or `\"\"`\n\n\n#### Field-specific rules\n\nNext, let's take a look at what each key means and what values they must contain\n> _* denotes a required field_\n\n- `\"display\"` *\n  - This is a boolean\n  - Should generally be left as `true`\n\n- `\"since\"` *\n  - The year the project became part of the ecosystem (i.e., started using Filecoin)\n  - This should be a number with no quotes, for example `2019`\n\n- `\"icon\"` *\n  - A small square icon, typically containing the logo of the project\n  - Must match an image file uploaded to this repo in `static/images/projects/`\n  - Must be one of the following file types: `.png` `.gif` `.jpg` `.jpeg` `.svg` `.webp`\n  - Must be a square image, i.e., an aspect ratio of `1:1`\n  - In the case of raster images, must not exceed `500px` in dimension (not applicable to SVGs)\n\n- `\"name\"` *\n  - The plain text name of the project\n  - Should not be excessively verbose\n\n- `\"org\"`\n  - The parent organization or company, if one exists\n  - This field is optional\n    - If no org is needed, just leave the string empty like `\"org\": \"\",`\n\n- `\"description\"` *\n  - A short couple of sentences describing the project\n\n- `\"website\"` *\n  - A URL to link to the project's website\n  - Must begin with a web accessible protocol: `http://`, `https://`, or just `//`\n\n- `\"social\"`\n  - This is an array of objects where a project's social links can be added\n  - This field is optional\n    - To leave it empty, just use an empty array like `social: [],`\n  - Include social links by populating the array with key-value pair objects\n    - Each object can be a different social link like `{ \"github\": \"//github.com/myproject\" }`\n\n- `\"taxonomy\"` *\n  - Select a subcategory for your project to fit into\n  - Delete all the other subcategories that do not apply to your project\n  - The category-subcategory pair determines where your project is grouped in the ecosystem explorer\n  - Do not create any new subcategories, and do not modify top-level category names\n    - The taxonomy is checked against a source of truth [`taxonomy.js`](content/data/taxonomy.js)\n\n- `\"tags\"`\n  - An optional array of tags\n  - Tags must be short strings\n  - Using the `fvm` tag adds a badge to your project\n\nIf in doubt, check out some project files here in [`content/projects`](content/projects)\n\n\n## Local development quickstart\n\nTo get started developing locally\n\n1. Clone the repo `git clone git@github.com:filecoin-project/ecosystem-directory.git`\n\n2. Install dependencies `npm ci`\n\n3. Run the app in development mode `npm run dev`\n\nFor more advanced developer documentation, see the [administrator docs](/docs/admin.md)\n\n## Questions\n\nIf you have any additional questions, [open an issue](https://github.com/filecoin-project/ecodash/issues/new/choose)!\n", "release_dates": []}, {"name": "ent", "description": "Herd state trees for migrations and validations", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "![ent logo](assets/old-trees.jpeg)\n## ent\n\nThis is a tool for testing out state tree migrations on lotus chain data\n\n## Usage\n\nTo get started you need data in a lotus directory at `~/.lotus`\n\n- `ent migrate one <state-cid> <state-epoch>` does a migration and outputs the new state tree cid\n- `ent migrate chain <start-block-cid>` does a migration on all states between start header and genesis\n- `ent validate v2 <state-cid> <state-epoch>` runs long paranoid validation on the new state\n\n`ent migrate one` and `ent migrate chain` take a `--validate` command for running a validation after a migratino\nFor a migration directly comparable to a filecoin protocol migration over the input `<state-cid>` provide a `<state-epoch>` equal to the epoch the state was created in. In other words use the height of the parent tipset of a header containing `<state-cid>`.\nent validation directly on a state tree only works with a v2 state.  The name `ent validate v2` tries to help make this clear.  The call will fail with \"unexpected actor code CID...\" when run on v0 state roots.\n\nMigrations are from specs actors v1 state to specs actors v2 state\n", "release_dates": []}, {"name": "eudico", "description": "lotus, but also other things", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "\n<h1 align=\"center\">[Archived] Project Eudico</h1>\n\n------\n> This repo is where the first of MVP for the IPC (InterPlanetary Consensus) framework and other consensus-related experiments by ConsensusLab were implemented and tested. This fork of Lotus is no longer maintained and a lot of the features and protocol tested here are being productionized in a new and [improved version of Eudico](https://github.com/consensus-shipyard/lotus/). \n>\n> We keep this repo archived for historical relevance and future reference (it still includes a lot of valuable code that haven't been merged and implemented in production). If you are looking to test Eudico in a testnet refer to [Spacenet](https://github.com/consensus-shipyard/spacenet). You can also learn more about all of our ongoing projects and research at https://consensuslab.world.\n------\n\nEudico is a modularised implementation of [Lotus](https://github.com/filecoin-project/lotus), itself an implementation of the Filecoin Distributed Storage Network. For more details about Filecoin, check out the [Filecoin Spec](https://spec.filecoin.io). This is a work-in-progress, intended to enable easier experimentation with future protocol features, and is not meant to be used in the production network.\n\n## Building & Documentation\n\n> Note: The default `eudico` branch is the dev branch, please use with caution. \n \nFor complete instructions on how to build, install and setup eudico, please visit the Lotus documentation at [https://docs.filecoin.io/get-started/lotus](https://docs.filecoin.io/get-started/lotus/). Basic build instructions can be found further down in this readme.\n\n## Reporting a Vulnerability\n\nPlease send an email to security@filecoin.org. See our [security policy](SECURITY.md) for more details.\n\n## Related packages\n\nThese repos are independent and reusable modules, but are tightly integrated into Lotus/Eudico to make up a fully featured Filecoin implementation:\n\n- [go-fil-markets](https://github.com/filecoin-project/go-fil-markets) which has its own [kanban work tracker available here](https://app.zenhub.com/workspaces/markets-shared-components-5daa144a7046a60001c6e253/board)\n- [specs-actors](https://github.com/filecoin-project/specs-actors) which has its own [kanban work tracker available here](https://app.zenhub.com/workspaces/actors-5ee6f3aa87591f0016c05685/board)\n\n## Contribute\n\nEudico is an open project and welcomes contributions of all kinds: code, docs, and more. However, before making a contribution, we ask you to heed these recommendations.\n\nWhen implementing a change:\n\n1. Adhere to the standard Go formatting guidelines, e.g. [Effective Go](https://golang.org/doc/effective_go.html). Run `go fmt`.\n2. Stick to the idioms and patterns used in the codebase. Familiar-looking code has a higher chance of being accepted than eerie code. Pay attention to commonly used variable and parameter names, avoidance of naked returns, error handling patterns, etc.\n3. Comments: follow the advice on the [Commentary](https://golang.org/doc/effective_go.html#commentary) section of Effective Go.\n4. Minimize code churn. Modify only what is strictly necessary. Well-encapsulated changesets will get a quicker response from maintainers.\n5. Lint your code with [`golangci-lint`](https://golangci-lint.run) (CI will reject your PR if unlinted).\n6. Add tests.\n7. Title the PR in a meaningful way and describe the rationale and the thought process in the PR description.\n8. Write clean, thoughtful, and detailed [commit messages](https://chris.beams.io/posts/git-commit/). This is even more important than the PR description, because commit messages are stored _inside_ the Git history. One good rule is: if you are happy posting the commit message as the PR description, then it's a good commit message.\n\n## Basic Build Instructions\n**System-specific Software Dependencies**:\n\nBuilding Eudico requires some system dependencies, usually provided by your distribution.\n\nUbuntu/Debian:\n```\nsudo apt install mesa-opencl-icd ocl-icd-opencl-dev gcc git bzr jq pkg-config curl clang build-essential hwloc libhwloc-dev wget -y && sudo apt upgrade -y\n```\n\nFedora:\n```\nsudo dnf -y install gcc make git bzr jq pkgconfig mesa-libOpenCL mesa-libOpenCL-devel opencl-headers ocl-icd ocl-icd-devel clang llvm wget hwloc libhwloc-dev\n```\n\nFor other distributions you can find the required dependencies [here.](https://docs.filecoin.io/get-started/lotus/installation/#system-specific) For instructions specific to macOS, you can find them [here.](https://docs.filecoin.io/get-started/lotus/installation/#macos)\n\n#### Go\n\nTo build Eudico, you need a working installation of [Go 1.17.9 or higher](https://golang.org/dl/):\n\n```bash\nwget -c https://golang.org/dl/go1.17.9.linux-amd64.tar.gz -O - | sudo tar -xz -C /usr/local\n```\n\n**TIP:**\nYou'll need to add `/usr/local/go/bin` to your path. For most Linux distributions you can run something like:\n\n```shell\necho \"export PATH=$PATH:/usr/local/go/bin\" >> ~/.bashrc && source ~/.bashrc\n```\n\nSee the [official Golang installation instructions](https://golang.org/doc/install) if you get stuck.\n\n### Build and install Eudico\n\nOnce all the dependencies are installed, you can build and install Eudico.\n\n1. Clone the repository:\n\n   ```sh\n   git clone https://github.com/filecoin-project/eudico.git\n   cd eudico/\n   ```\n   \nNote: The default branch `eudico` is the dev branch where the latest new features, bug fixes and improvement are in. \n\n2. Build Eudico:\n\n   ```sh\n   make eudico\n   ```\n   This will create the `eudico` executable in the current directory.\n\n### Run a local test network.\n\n**Note**: `eudico` uses the `$HOME/.eudico` folder by default for storage (configuration, chain data, wallets, etc). See [advanced options](https://docs.filecoin.io/get-started/lotus/configuration-and-advanced-usage/) for information on how to customize the folder.\nIf you want to run more than one Eudico node the same host, you need to tell the nodes to use different folders (see [FAQ](FAQ.md#q-how-can-i-run-two-eudico-peers-on-the-same-host))\nMake sure that this directory does not exist when you are starting a new network.\n\nFirst, a key needs to be generated. \nIn order to do that, compile the Lotus key generator:\n\n   ```bash\n   make lotus-keygen\n   ```\n\nThen, generate a key:\n\n   ```bash\n   ./lotus-keygen -t secp256k1\n   ```\nThis creates a key file, with the name `f1[...].key` (e.g. `f16dv4rlp3b33d5deasf3lxkrbfwhi4q4a5uw5scy.key`) in the local directory.\nThe file name, without the `.key` extension, is the corresponding Filecoin address.\nIf this is the only key you generated so far, you can obtain the address, for example, by running\n\n   ```bash\n   ADDR=$(echo f1* | tr '.' ' ' | awk '{print $1}')\n   ```\n\nUse this address to create a genesis block for the system and start the Eudico daemon.\nThe following command uses the `delegated` consensus.\n\n   ```bash\n   ./eudico delegated genesis $ADDR gen.gen\n   ./eudico delegated daemon --genesis=gen.gen\n   ```\n\nThe daemon will continue running until you stop it.\nTo start a miner, first import a wallet, using the generated key\n(replacing `f1*.key` by the generated key file if more than one key is present in the directory).\n\n   ```bash\n   ./eudico wallet import --format=json-lotus f1*.key\n   ```\n\nThen, start the miner.\n\n   ```bash\n   ./eudico delegated miner\n   ```\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/lotus/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/lotus/blob/master/LICENSE-APACHE)\n", "release_dates": ["2022-08-27T12:12:59Z"]}, {"name": "fevm-contract-tests", "description": "Integration tests for the Ethereum JSON-RPC API in Lotus", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Lotus Eth JSON-RPC integration tests\n\nThis project holds a suite of integration tests for the Ethereum JSON-RPC API\nbuilt in Lotus with the Filecoin EVM runtime.\n\nThis repo is the test runner for all the project repo in the `extern/` folder.\n\n## Running tests\n\n### Build the local lotus\n\n1. Go through the [Lotus installation](https://lotus.filecoin.io/lotus/install/prerequisites/) guide to install the dependencies\n2. Install node dependencies by running `npm install`\n3. cd `./node` and run `make node`\n4. Run the node in `./bin/node`\n\n### Prepare the .env file\n\n1. echo -n DEPLOYER_PRIVATE_KEY=0x > .env\n2. openssl rand -hex 32 >> .env\n3. echo -n USER_1_PRIVATE_KEY=0x >> .env\n4. openssl rand -hex 32 >> .env\n5. Copy the .env file into ./extern/fevm-hardhat-kit/, ./extern/openzeppelin-contracts/, ./extern/fevm-uniswap-v3-core/\n\n### Run each test project\n\n1. ethers.js and web3.js (root folder)\n   1. npm install\n   2. npx hardhat --network itest test\n2. ./extern/fevm-hardhat-kit\n   1. change the `DEPLOYER_PRIVATE_KEY` in .env to `PRIVATE_KEY`\n   2. yarn\n   3. npx hardhat --network itest deploy\n3. ./extern/openzeppelin-contracts \n   1. npm install\n   2. npx hardhat --network itest test\n4. ./extern/fevm-uniswap-v3-core\n   1. yarn\n   2. npx hardhat --network itest test\n\n### Known issues\n1. Wrong kind of exception received: FVM's backtrace message format is different from Ethereum's, so this repo bypasses checking the revert reason by removing the following code from `node_modules/@openzeppelin/test-helpers/src/expectRevert.js`:\n\n   ```expect(actualError).to.equal(expectedError, 'Wrong kind of exception received');```\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the\n[Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n", "release_dates": []}, {"name": "fevm-data-dao-kit", "description": "A kit to demonstrate the basics of getting a DataDAO up and running on the Filecoin Virtual Machine (FVM).", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# FEVM-Data-DAO-Kit\n\nThis is a beta kit to demo how to build a basic Decentralized Autonomous Organization (DAO) on Filecoin.\n\n## About This Repo\n\nStart out in the \"hardhat\" directory and follow the readme there to begin deploying and interacting with contracts.\n\nThen go to the \"frontend\" directory to run an example frontend!\n\n\n", "release_dates": []}, {"name": "fevm-foundry-kit", "description": "A starter foundry project for developing, deploying, and testing Solidity smart contracts on the FEVM (Ethereum Virtual Machine on Filecoin)", "language": "Solidity", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# FEVM Foundry Kit\n\nThis is a template for foundry that provides the basic scaffolding for quickly getting started with new projects. \n\n## Download Foundry\n\nYou can find the instructions to download Foundry in the [official Foundry repo](https://github.com/foundry-rs/foundry#installation). \n\n## Cloning the Repo\n\nOpen up your terminal (or command prompt) and navigate to a directory you would like to store this code on. Once there type in the following command:\n\n\n```\ngit clone https://github.com/filecoin-project/fevm-foundry-kit\ncd fevm-foundry-kit\nyarn install\n```\n\nThis will clone the hardhat kit onto your computer, switch directories into the newly installed kit, and install the dependencies the kit needs to work.\n\n## Get a Private Key\n\nYou can get a private key from a wallet provider [such as Metamask](https://metamask.zendesk.com/hc/en-us/articles/360015289632-How-to-export-an-account-s-private-key).\n\n\n## Add your Private Key as an Environment Variable\n\nAdd your private key as an environment variable by running this command:\n\n```\nexport PRIVATE_KEY='abcdef'\n```\n\nAlternatively, to avoid having to do that every time, create a .env file in the root directory of the project (you can use .env.example to do so easily) and add the following line:\n\n```\nPRIVATE_KEY=abcdef\nCALIBRATIONNET_RPC_URL=https://api.calibration.node.glif.io/rpc/v1\n```\n\nand then, open a new terminal and run the following command:\n\n```\nsource .env\n```\n\nIf you use a .env file, don't commit and push any changes to .env files that may contain sensitive information, such as a private key! If this information reaches a public GitHub repository, someone can use it to check if you have any Mainnet funds in that wallet address, and steal them!\n\n\n## Fund the Deployer Address\n\nGo to the [Calibrationnet testnet faucet](https://faucet.calibration.fildev.network), and paste in the Ethereum address from the previous step. This will send some calibrationnet testnet FIL to the account.\n\n## Deploy the Contracts\n\nCurrently there are 3 main types of contracts:\n\n* Basic Solidity Examples: Simple contracts to show off basic solidity\n\n* Filecoin API Examples: Contracts that demo how to use the Filecoin APIs in Solidity to access storage deals and other Filecoin specific functions.\n\n* Basic Deal Client: A contract that demos how to create Filecoin storage deals within Solidity smart contracts. See below to learn more.\n\n\nType in the following command in the terminal to deploy a contract. Keep in mind that you can swap out the contract path and name for whichever one of your choosing:\n\n```\nforge build\nforge create --rpc-url https://api.calibration.node.glif.io/rpc/v1 --private-key $PRIVATE_KEY --contracts /src/SimpleCoin.sol SimpleCoin\n```\n\nThis will deploy the SimpleCoin contract to the Calibrationnet testnet. You can find the contract address in the terminal output:\n\n```\nDeployer: 0x42C930A33280a7218bc924732d67dd84D6247Af4\nDeployed to: 0x859723aA05F8B0C10215C31E50d9647AD7c82C82\nTransaction hash: 0x74071603994339f01b745e304c10f1bd97cfba4003d7a447977de1c89b478c7d\n```\n\nNow try doing the same with the Deal Client:\n\n```\nforge create --rpc-url https://api.calibration.node.glif.io/rpc/v1 --private-key $PRIVATE_KEY --contracts src/client-contract/DealClient.sol DealClient\n```\n\nA common issue that you may see is a failure due to gas:\n\n```\n(code: 1, message: verify msg failed: message will not be included in a block: 'GasLimit' field cannot be less than the cost of storing a message on chain 152605 < 288863, data: None)\n```\n\nSimply pass in a higher gas limit to fix this (either via. a higher gas estimate multiplier or a fixed gas limit):\n\n```\nforge create --rpc-url https://api.calibration.node.glif.io/rpc/v1 --private-key $PRIVATE_KEY --contracts src/client-contract/DealClient.sol DealClient -g 1000\n```\n\n## Interact with the Contracts\n\nYou can interact with contracts via forge scripts scripts, found in the 'scripts' folder. For example, to interact with the SimpleCoin contract:\n\nType in the following command in the terminal:\n\n```\nforge script script/SimpleCoin.s.sol:MyScript --rpc-url https://api.calibration.node.glif.io/rpc/v1 --broadcast --skip-simulation\n```\n\nYou can also interact with contracts via the terminal/command line using the [Foundry cast tool](https://book.getfoundry.sh/cast/#overview-of-cast).\n\n## Empty Transaction Reciepts\nSome users are facing the issue of an empty receipt for your txn on testnet but the txn shows that it has gone through successfully on explorers.\n```\nError: \nReceived an empty receipt for 0xe661e7a4e5ec511c93c2b966ae382da9267c5ad217d9b5ec75de3ce3ab848608\n```\n\nOR facing an error message that txn has dropped from mempool, but again, txn shows up on explorer.\n\n```\nError: \nTransaction dropped from the mempool: 0x9b293d053a0c148677b46425f143fd46dd58d13b47251208d68c458653f30038\n```\n\nTry these fixes:\n- Increase the amount of times for retrying the tx, perhaps through the `\u2014resume` flag. Ideally setting it to ~10, which you can specify with `--retries`. \n- Alternatively, try using ethers-rs to handle contract transactions. there is a [send_tx](https://github.com/filecoin-saturn/rs-fevm-utils/blob/5c850005bbe50d7547d2585173ab2bd39c47c011/src/lib.rs#LL215C4-L215C4) function in there that allows you to override the default no of retries.\n\n## Filecoin APIs\n\nThe primary advantage of the FEVM over other EVM based chains is the ability to access and program around Filecoin storage deals. This can be done in the FEVM via the [Filecoin.sol library maintained by Zondax](https://github.com/Zondax/filecoin-solidity). **Note this library is currently in BETA**. It is unaudited, and the APIs will likely be changing with time. This repo will be updated as soon as possible when a breaking change occurs.\n\nThe library is included in this kit as an NPM package and will automatically be downloaded when you perform the `yarn` command (don't confuse these with the included mocks)!\n\nCurrently you will find a getter contract that calls the getter methods on the MarketAPI to get storage deal data and store that data. To do this you will need *dealIDs* which you can [find here on FilFox](https://calibration.filfox.info/en/deal).\n\n### Preparing Data for Storage\n\nBefore storing a file with a storage provider, it needs to be prepared by turning it into a .car file and the metadata must be recorded. To do this locally, you can use [this tool](https://github.com/filecoin-project/fevm-hardhat-kit/tree/main/tools), written in the language Go, which can do this for you. You can also use the [FVM Data Depot website](https://data.lighthouse.storage/) will automatically convert files to the .car format, output all the necessary metadata, and act as an HTTP retrieval point for the storage providers.\n\n### Client Contract - Making Storage Deals in Solidity\n\nUnder contracts, within the `basic-deal-client` sub-directory, you will find a file called `DealClient.sol`. This is an example contract that uses the Filecoin.sol API's to create storage deals via Solidity smart contracts on Filecoin. This works by emitting a Solidity event that [Boost storage providers](https://boost.filecoin.io/) can listen to. To learn more about this contract feel free to [checkout the app kit repo](https://github.com/filecoin-project/fvm-starter-kit-deal-making) which includes a detailed readme and a frontend.\n\n### Bounty Contract\n\nUnder contracts, within the `filecoin-api-examples` sub-directory, you will find a file called `deal-rewarder.sol`. This is a basic example contract that uses the Filecoin.sol API's to create bounties for specific data to be stored on the Filecoin blockchain. This is intended to be an example to illustrate how you can use the Filecoin APIs to do some cool functionality. To learn more about this contract feel free to [checkout the original Foundry project](https://github.com/lotus-web3/deal-bounty-contract) which includes a detailed readme.\n\n", "release_dates": []}, {"name": "fevm-hardhat-kit", "description": "A starter hardhat project for developing, deploying, and testing Solidity smart contracts on the FEVM (Ethereum Virtual Machine on Filecoin)", "language": "Solidity", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# FEVM Hardhat Kit\n\n## Cloning the Repo\n\nOpen up your terminal (or command prompt) and navigate to a directory you would like to store this code on. Once there type in the following command:\n\n\n```\ngit clone --recurse-submodules https://github.com/filecoin-project/fevm-hardhat-kit.git\ncd fevm-hardhat-kit\nyarn install\n```\n\n\nThis will clone the hardhat kit onto your computer, switch directories into the newly installed kit, and install the dependencies the kit needs to work.\n\n\n## Get a Private Key\n\nYou can get a private key from a wallet provider [such as Metamask](https://metamask.zendesk.com/hc/en-us/articles/360015289632-How-to-export-an-account-s-private-key).\n\n\n## Add your Private Key as an Environment Variable\n\nAdd your private key as an environment variable by running this command:\n\n ```\nexport PRIVATE_KEY='abcdef'\n```\n\nIf you use a .env file, don't commit and push any changes to .env files that may contain sensitive information, such as a private key! If this information reaches a public GitHub repository, someone can use it to check if you have any Mainnet funds in that wallet address, and steal them!\n\n\n## Get the Deployer Address\n\nRun this command:\n```\nyarn hardhat get-address\n```\n\nThis will show you the ethereum-style address associated with that private key and the filecoin-style f4 address (also known as t4 address on testnets)! The Ethereum address can now be exclusively used for almost all FEVM tools, including the faucet.\n\n\n## Fund the Deployer Address\n\nGo to the [Calibrationnet testnet faucet](https://faucet.calibration.fildev.network/), and paste in the Ethereum address from the previous step. This will send some calibration testnet FIL to the account.\n\n\n## Deploy the Contracts\n\nCurrently there are 3 main types of contracts:\n\n* Basic Solidity Examples: Simple contracts to show off basic solidity\n\n* Filecoin API Examples: Contracts that demo how to use the Filecoin APIs in Solidity to access storage deals and other Filecoin specific functions.\n\n* Basic Deal Client: A contract that demos how to create Filecoin storage deals within Solidity smart contracts. See below to learn more.\n\n\nType in the following command in the terminal to deploy all contracts:\n\n ```\nyarn hardhat deploy\n```\n\nThis will compile all the contracts in the contracts folder and deploy them to the Calibrationnet test network automatically!\n\nKeep note of the deployed contract addresses for the next step.\n\n## Interact with the Contracts\n\nYou can interact with contracts via hardhat tasks, found in the 'tasks' folder. For example, to interact with the SimpleCoin contract:\n\nType in the following command in the terminal:\n\n ```\nyarn hardhat get-balance --contract 'THE DEPLOYED CONTRACT ADDRESS HERE' --account 'YOUR ETHEREUM ADDRESS HERE'\n```\n\nThe console should read that your account has 12000 SimpleCoin!\n\n## Filecoin APIs\n\nThe primary advantage of the FEVM over other EVM based chains is the ability to access and program around Filecoin storage deals. This can be done in the FEVM via the [Filecoin.sol library maintained by Zondax](https://github.com/Zondax/filecoin-solidity). **Note this library is currently in BETA**. It is unaudited, and the APIs will likely be changing with time. This repo will be updated as soon as possible when a breaking change occurs.\n\nThe library is included in this kit as an NPM package and will automatically be downloaded when you perform the `yarn` command (don't confuse these with the included mocks)!\n\nCurrently you will find a getter contract that calls the getter methods on the MarketAPI to get storage deal data and store that data. To do this you will need *dealIDs* which you can [find here on FilFox](https://calibration.filfox.info/en/deal).\n\nAs an example to store most of the data available for a deal run the store-all command with a specified dealID. Below is an example of using this command below with a deal on Calibrationnet testnet with a dealID of 707.\n\n```\nyarn hardhat store-all --contract \"DEPLOYED FILECOIN_MARKET_CONSUMER CONTRACT ADDRESS HERE\" --dealid \"707\"\n```\n\n### Preparing Data for Storage\n\nBefore storing a file with a storage provider, it needs to be prepared by turning it into a .car file and the metadata must be recorded. To do this, the hardhat kit has a [tool submodule](https://github.com/filecoin-project/fevm-hardhat-kit/tree/main/tools), written in the language Go, which can do this for you. You can also use the [FVM Data Depot website](https://data.lighthouse.storage/) will automatically convert files to the .car format, output all the necessary metadata, and act as an HTTP retrieval point for the storage providers.\n\n### Client Contract - Making Storage Deals in Solidity\n\nUnder contracts, within the `basic-deal-client` sub-directory, you will find a file called `DealClient.sol`. This is an example contract that uses the Filecoin.sol API's to create storage deals via Solidity smart contracts on Filecoin. This works by emitting a Solidity event that [Boost storage providers](https://boost.filecoin.io/) can listen to. To learn more about this contract feel free to [checkout the app kit repo](https://github.com/filecoin-project/fvm-starter-kit-deal-making) which includes a detailed readme and a frontend.\n\n### Bounty Contract\n\nUnder contracts, within the `filecoin-api-examples` sub-directory, you will find a file called `deal-rewarder.sol`. This is a basic example contract that uses the Filecoin.sol API's to create bounties for specific data to be stored on the Filecoin blockchain. This is intended to be an example to illustrate how you can use the Filecoin APIs to do some cool functionality. To learn more about this contract feel free to [checkout the original Foundry project](https://github.com/lotus-web3/deal-bounty-contract) which includes a detailed readme.\n", "release_dates": []}, {"name": "fff", "description": "Traits and utilities for working with finite fields", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# fff\n\n> Fork of the great [ff](https://github.com/zkcrypto/ff) library.\n\n`fff` is a finite field library written in Rust.\n\n## Disclaimers\n\n* This library does not provide constant-time guarantees.\n\n\nThe `fff` crate contains `Field`, `PrimeField`, `PrimeFieldRepr` and `SqrtField` traits.\nSee the **[documentation](https://docs.rs/fff/)** for more.\n\n### #![derive(PrimeField)]\n\nIf you need an implementation of a prime field, this library also provides a procedural\nmacro that will expand into an efficient implementation of a prime field when supplied\nwith the modulus. `PrimeFieldGenerator` must be an element of Fp of p-1 order, that is\nalso quadratic nonresidue.\n\nFirst, enable the `derive` crate feature:\n\n```toml\n[dependencies]\nfff = { version = \"0.2\", features = [\"derive\"] }\n```\n\nAnd then use the macro like so:\n\n```rust\nextern crate rand;\n#[macro_use]\nextern crate fff;\n\n#[derive(PrimeField)]\n#[PrimeFieldModulus = \"52435875175126190479447740508185965837690552500527637822603658699938581184513\"]\n#[PrimeFieldGenerator = \"7\"]\nstruct Fp(FpRepr);\n```\n\nAnd that's it! `Fp` now implements `Field` and `PrimeField`. `Fp` will also implement\n`SqrtField` if supported. The library implements `FpRepr` itself and derives\n`PrimeFieldRepr` for it.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "ffi-stub", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin FFI stub\n\n_For testing and non-production purposes only._\n\nThis is an FFI stub that can be used with a go.mod `replace` directive\nin tests that do not require real proofs.\n\n## Usage\n\nIn your go.mod:\n\n```\nreplace github.com/filecoin-project/filecoin-ffi => github.com/filecoin-project/ffi-stub ${version}\n```\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the\n[Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n", "release_dates": ["2023-02-01T11:12:47Z", "2022-03-03T11:27:00Z", "2021-08-12T12:25:06Z", "2021-08-12T12:25:22Z"]}, {"name": "fil-blst", "description": null, "language": "Assembly", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# fil-blst (Filecoin blast)\n\nA library to accelerate SNARK verification for the Filecoin network using the blst BLS12-381 performance library.\n\n# Building\n\n./build.sh\n\n# Test\n./a.out\n", "release_dates": []}, {"name": "fil-calculations", "description": "Filecoin Parameter Calculations", "language": "Jupyter Notebook", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin Parameter Calculations\n\n## NOTE\n\nAll code and notebooks contained here are very rough. The eventual goal is to unify existing calculators into a \nversion-controlled and well-documented library. However, the primary immediate use is to analyze and project \nperformance, synthesizing theoretical calculations with actual performance data. This is a dirty problem, and the \nwork product reflects the nature of trying to draw a bead on a moving target. The first and foremost goal is to find \na firing solution that will allow us to meet both security and scaling requirements for Proof of Replication. This is\n like searching for a needle in a haystack, but the end is in sight.\n \nUntil that happens, this work should be seens as an artifact of that effort. Over time, the goal is to tame the complexity \n(then well-understood and stabilized) and refactor the resulting model for clarity and auditable explanatory power.\n\n## Environment\n\nCreate the conda environment:\n\n```console\n> conda env create -f environment.yml\n```\n\nActivate it:\n```console\n> conda activate fil-calculations\n```\n\n## Notebook Config\n\nNotebooks should be saved in both `.md` and `.ipynb`.\n- To use `.md` (required), append to `jupyter_notebook_config.py`:\n```\nc.NotebookApp.contents_manager_class = \"jupytext.TextFileContentsManager\"\nc.ContentsManager.default_jupytext_formats = \"ipynb,md\"\n```\n\n## Local Notebooks\n\nFrom project root:\n```console\n> cd fil-calculations\n> jupyter notebook\n````\n\n## Version Control\n\nAlways load and save any notebooks which may have changed so that the `.ipynb` files have accurate values. In \nparticular, this makes the non-interactive view available on GitHub useful.\n\nTODO: Script this. Eventually verify on CI.\n\n## Entry Points\n\n - [Proof Scalling](fil-calculations/proof_scaling.ipynb)\n - [ZigZag Performance](fil-calculations/zigzag_performance.ipynb)\n - [Apex Optimization](fil-calculations/apex.ipynb)\n\n\n# License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](../LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](../LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "fil-docs-bot", "description": null, "language": null, "license": null, "readme": "# FilDocsBot\n\n> FilDocsBot is a hacky experiment, not a production-ready application :D\n\nFilDocsBot is a chatbot application that answers users questions about Filecoin using the [official documentation](https://docs.filecoin.io/). \nThe bot uses the [Superpowered AI Python SDK](https://github.com/SuperpoweredAI/superpowered-python-sdk) to provide ChatGPT with a \"knowledge base\" (the official Filecoin docs),\nso that ChatGPT will not make up wacky answers using unknown or outdated sources. In other words, Superpowered AI provides guardrails, so that ChatGPT only draws from sources provided and does not hallucinate. \n\nThe bot then uses this knowledge to answer questions about Filecoin that the user asks via the command line. The bot also cites the document used to answer the question.\n\n## How to use the bot\n\nAs described above, FilDocsBot is currently an experiemental app. As such, setting it up and using it is a little hacky.\n\n### Prerequisites\n\n1. Python 3.10.9 or higher\n\n1. The Superpowered AI Python SDK\n\n    ```shell\n    pip install superpowered-sdk\n    ```\n    \n1. The OpenAI Python SDK\n\n    ```shell\n    pip install openai\n    ```\n    \n1. An OpenAI account \n\n1. An OpenAI API key\n\n1. A Superpowered AI key and key secret\n\n1. A text editor \n\n1. A terminal application\n\n### Setup\n\nOnce you've met the prerequisites, you must complete some intital set up to use the bot.\n\n1. Clone this repository:\n\n   ```shell\n   git clone https://github.com/ElPaisano/fil-docs-bot.git\n   ```\n   \n1. Navigate to the `fil-docs-bot` repository:\n\n   ```shell\n   cd fil-docs-bot\n   ```\n   \n1. In your favorite text editor, open `create_kb.py`.\n\n1. Enter your Superpowered API key and secret on the correct lines, which should now look something like:\n\n   ```shell\n   os.environ[\"SUPERPOWERED_API_KEY_ID\"] = \"fake-key-12ey31811kjhgjk03\"\n   os.environ[\"SUPERPOWERED_API_KEY_SECRET\"] = \"fake-secret-86483264289342893\"\n   ```\n   \n1. Close and save the file.\n\n1. In a terminal, run `create_kb.py` to create the knowledge base that the bot will use to answer questions.\n\n   ```shell\n   python create_kb.py\n   ```\n   \n   The script outputs a knowledge base ID in the terminal. **You will need this in next steps, so don't forget it.**\n   \n   ```shell\n   Created knowledge base with id: da8abde5-6b55-4e51-b396-863fd7bfb35b\n   ```\n\n1. In your favorite text editor, open `chat.py`.\n\n1. On the correct lines, enter the following info:\n\n   - Your Superpowered AI key and secret\n   - Your OpenAI API key\n   - The ID of the knowledge base you created\n\n   Your `chat.py` should look something like:\n   \n   ```shell\n   os.environ[\"OPENAI_API_KEY\"] = \"fake-z6HVRmnFAKENXzdptT3BlbkFJhp4\"\n   os.environ[\"SUPERPOWERED_API_KEY_ID\"] = \"fake1123256789\"\n   os.environ[\"SUPERPOWERED_API_KEY_SECRET\"] = \"alsofake-cewyb56789YYhbjdg\"\n\n   knowledge_base_id = \"532fake259-109f-478a-aa63-fe3c0ab3d3ab\"\n   ```\n\n1. Close and save the file.\n\nYay! You've completed the setup! Now, you can use the bot.\n\n### Use the bot\n\nNow that the set up is complete, fire up the bot and start asking questions. \n\n> A note on latency: Responses to questions may experience a latency of at least a few seconds and the terminal may hang briefly.\n\n1. Run the bot.\n\n   ```shell\n   python chat.py\n   ```\n   \n   You should see something like:\n   \n   ```shell\n   GREETINGS HUMAN, I WILL ANSWER YOUR QUESTIONS ABOUT FILECOIN. BOOP.\n   ...\n   ENTER YOUR QUESTION BELOW.\n\n\n   USER: \n   ```\n1. In the `USER` field, type your question and press the **ENTER** key. Here's an example question and response:\n\n   ```shell\n   USER: What is Filecoin?\n\n   CHATBOT: Filecoin is a decentralized storage network that allows users to store files on a peer-to-peer network with built-in economic incentives and cryptography to ensure files are stored reliably over time. \n   Users pay to store their files on storage providers, who are responsible for storing files and proving they have stored them correctly over time. \n   Filecoin facilitates open markets for storing and retrieving files that anyone can participate in. \n   It is built on top of the same software powering IPFS protocol and has an incentive layer on top to incentivize contents to be reliably stored and accessed. \n   You can learn more at https://docs.filecoin.io/basics/what-is-filecoin/overview/.\n   ```\n\n> To exit the application, type `exit` in the `USER` field and press the **ENTER** key.\n", "release_dates": []}, {"name": "fil-ocl", "description": "OpenCL for Rust", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "ocl\n===\n\n#### [Documentation](https://docs.rs/ocl) | [Change Log](https://github.com/cogciprocate/ocl/blob/master/RELEASES.md)\n\n[![](http://meritbadge.herokuapp.com/ocl)](https://crates.io/crates/ocl) [![](https://docs.rs/ocl/badge.svg)](https://docs.rs/ocl)\n[![Supported platforms](https://img.shields.io/badge/platform-windows%20%7C%20macos%20%7C%20linux%20%7C%20bsd-orange.svg)](https://en.wikipedia.org/wiki/Cross-platform)\n[![Linux Build Status](https://travis-ci.org/cogciprocate/ocl.svg?branch=master)](https://travis-ci.org/cogciprocate/ocl)\n\nPure OpenCL&trade; bindings and interfaces for\n[Rust](https://www.rust-lang.org/).\n\n## Goals\n\nTo provide:\n- A simple and intuitive interface to OpenCL devices\n- The full functionality and power of the OpenCL API\n- An absolute minimum of boilerplate\n- Zero or virtually zero performance overhead\n- Thread-safe and automatic management of API pointers and resources\n\n## Usage\n\nEnsure that an OpenCL library is installed for your platform and that `clinfo`\nor some other diagnostic command will run. Add the following to your project's\n`Cargo.toml`:\n\n```toml\n[dependencies]\nocl = \"0.19\"\n```\n\nAnd add the following to your crate root (lib.rs or main.rs):\n```rust\nextern crate ocl;\n```\n\n## Example\n\nFrom [`examples/trivial.rs`]:\n```rust\nextern crate ocl;\nuse ocl::ProQue;\n\nfn trivial() -> ocl::Result<()> {\n    let src = r#\"\n        __kernel void add(__global float* buffer, float scalar) {\n            buffer[get_global_id(0)] += scalar;\n        }\n    \"#;\n\n    let pro_que = ProQue::builder()\n        .src(src)\n        .dims(1 << 20)\n        .build()?;\n\n    let buffer = pro_que.create_buffer::<f32>()?;\n\n    let kernel = pro_que.kernel_builder(\"add\")\n        .arg(&buffer)\n        .arg(10.0f32)\n        .build()?;\n\n    unsafe { kernel.enq()?; }\n\n    let mut vec = vec![0.0f32; buffer.len()];\n    buffer.read(&mut vec).enq()?;\n\n    println!(\"The value at index [{}] is now '{}'!\", 200007, vec[200007]);\n    Ok(())\n}\n```\n\nSee the the remainder of [`examples/trivial.rs`] for more information about\nhow this library leverages Rust's zero-cost abstractions to provide the full\npower and performance of the C API in a simple package.\n\n## Recent Changes\n\n* 0.18.0: Creating a\n  [`Kernel`](https://docs.rs/ocl/0.18.0/ocl/struct.Kernel.html) now requires\n  the use of the new\n  [`KernelBuilder`](https://docs.rs/ocl/0.18.0/ocl/struct.KernelBuilder.html).\n  See the [change\n  log](https://github.com/cogciprocate/ocl/blob/master/RELEASES.md) for more\n  information.\n\n##### Introduction to OpenCL\n\nFor a quick but thorough primer on the basics of OpenCL, please see [Matthew\nScarpino's excellent article, 'A Gentle Introduction to OpenCL' at\ndrdobbs.com](http://www.drdobbs.com/parallel/a-gentle-introduction-to-opencl/231002854)\n(his\n[book](https://www.amazon.com/OpenCL-Action-Accelerate-Graphics-Computations/dp/1617290173/ref=sr_1_2?ie=UTF8&qid=1500745843&sr=8-2&keywords=opencl)\nis great too).\n\n##### Diving Deeper\n\nAlready familiar with the standard OpenCL core API? See the [`ocl-core`] crate\nfor access to the complete feature set in the conventional API style with\nRust's safety and convenience.\n\n##### Version Support\n\nOpenCL versions 1.1 and above are supported. OpenCL version 1.0 is **not**\nsupported due to its inherent thread unsafety.\n\n##### Vulkan&trade; and the Future\n\nThe OpenCL API already posesses all of the new attributes of the Vulkan API\nsuch as low-overhead, high performance, and unfettered hardware access. For all\npractical purposes, Vulkan is simply a graphics-focused superset of OpenCL's\nfeatures (sorta kinda). OpenCL 2.1+ and Vulkan kernels/shaders now both\ncompile into SPIR-V making the device side of things the same. I wouldn't be\nsuprised if most driver vendors implement the two host APIs identically.\n\nIn the future it's possible the two may completely merge (or that Vulkan will\nabsorb OpenCL). Whatever happens, nothing will change as far as the front end\nof this library is concerned. This library will maintain its focus on the\ncompute side of things. For the graphics side, see the [voodoo] library.\n\n##### License\n\nLicensed under either of:\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n##### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any\nadditional terms or conditions.\n\n<br/>*\u201cOpenCL and the OpenCL logo are trademarks of Apple Inc. used by\npermission by Khronos.\u201d* <br/>*\u201cVulkan and the Vulkan logo are trademarks of\nthe Khronos Group Inc.\u201d*\n\n[OpenCL libraries for your CPU]: https://software.intel.com/en-us/intel-opencl/download\n[AMD]: https://software.intel.com/en-us/intel-opencl/download\n[`ocl-core`]: https://github.com/cogciprocate/ocl/tree/master/ocl-core\n[issue]: https://github.com/cogciprocate/ocl_rust/issues\n[provide feedback]: https://github.com/cogciprocate/ocl_rust/issues\n[`examples`]: https://github.com/cogciprocate/ocl/tree/master/ocl/examples\n[`examples/trivial.rs`]: https://github.com/cogciprocate/ocl/blob/master/ocl/examples/trivial.rs\n[voodoo]: https://github.com/cogciprocate/voodoo\n[intel-win64]: https://software.intel.com/en-us/articles/opencl-drivers#win64\n[intel-linux64-redhat-suse]: https://software.intel.com/en-us/articles/opencl-drivers#lin64\n[intel-linux64-ubuntu]: https://software.intel.com/en-us/articles/opencl-drivers#ubuntu64\n[amd-app-sdk]: http://developer.amd.com/tools-and-sdks/opencl-zone/amd-accelerated-parallel-processing-app-sdk/\n", "release_dates": []}, {"name": "fil-rustacuda", "description": "Temporary fork of RustaCUDA.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# fil-rustacuda\r\n\r\n[![crates.io][crate-image-fil-rustacuda]][crate-link-fil-rustacuda]\r\n[![Documentation][doc-image-fil-rustacuda]][doc-link-fil-rustacuda]\r\n\r\n**NOTE**: This is a temporary fork of [RustaCUDA](https://github.com/bheisler/RustaCUDA), the plan is to get all changes merged upstream.\r\n\r\nHigh-level Interface to [NVIDIA\u00ae CUDA\u2122 Driver API](https://developer.nvidia.com/cuda-zone) in Rust.\r\n\r\nRustaCUDA helps you bring GPU-acceleration to your projects by providing a flexible, easy-to-use\r\ninterface to the CUDA GPU computing toolkit. RustaCUDA makes it easy to manage GPU memory,\r\ntransfer data to and from the GPU, and load and launch compute kernels written in any language.\r\n\r\n## Table of Contents\r\n- [Table of Contents](#table-of-contents)\r\n  - [Goals](#goals)\r\n  - [Roadmap](#roadmap)\r\n  - [Quickstart](#quickstart)\r\n  - [Contributing](#contributing)\r\n  - [Maintenance](#maintenance)\r\n  - [License](#license)\r\n  - [Requirements](#requirements)\r\n  - [Related Projects](#related-projects)\r\n\r\n### Goals\r\n\r\n The primary design goals are:\r\n\r\n - __High-Level__: Using RustaCUDA should feel familiar and intuitive for Rust programmers.\r\n - __Easy-to-Use__: RustaCUDA should be well-documented and well-designed enough to help novice GPU programmers get started, while not limiting more experienced folks too much.\r\n - __Safe__: Many aspects of GPU-accelerated computing are difficult to reconcile with Rust's safety guarantees, but RustaCUDA should provide the safest interface that is reasonably practical.\r\n - __Fast__: RustaCUDA should aim to be as fast as possible, where it doesn't conflict with the other goals.\r\n\r\nRustaCUDA is intended to provide a programmer-friendly library for working with the host-side CUDA\r\nDriver API. It is not intended to assist in compiling Rust code to CUDA kernels (though see\r\n[rust-ptx-builder](https://github.com/denzp/rust-ptx-builder) for that) or to provide device-side\r\nutilities to be used within the kernels themselves.\r\n\r\nRustaCUDA is deliberately agnostic about how the kernels work or how they were compiled. This makes\r\nit possible to (for example) use C kernels compiled with `nvcc`.\r\n\r\n### Roadmap\r\n\r\nRustaCUDA currently supports a minimum viable subset of the CUDA API (essentially, the minimum\r\nnecessary to manage memory and launch basic kernels). This does not include:\r\n\r\n- Any asynchronous operation aside from kernel launches\r\n- Access to CUDA 1/2/3D arrays and texture memory\r\n- Multi-GPU support\r\n- Runtime linking\r\n- CUDA Graphs\r\n- And more!\r\n\r\nThese additional features will be developed later, as time permits and as necessary. If you need a\r\nfeature that is not yet supported, consider submitting a pull request!\r\n\r\n### Quickstart\r\n\r\nBefore using RustaCUDA, you must install the CUDA development libraries for your system. Version\r\n8.0 or newer is required. You must also have a CUDA-capable GPU installed with the appropriate\r\ndrivers.\r\n\r\nFirst, set the `CUDA_LIBRARY_PATH` environment variable to the location of your CUDA headers:\r\n\r\n```text\r\nexport CUDA_LIBRARY_PATH=\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.1\\lib\\x64\"\r\n```\r\n\r\nSome Ubuntu users have encountered linker errors when using CUDA_LIBRARY_PATH. If you see an error\r\nlike this:\r\n\r\n```text\r\n  = note: /usr/bin/ld: cannot find -lcudart                                                              \r\n          /usr/bin/ld: cannot find -lcublas                                                              \r\n          collect2: error: ld returned 1 exit status \r\n```\r\n\r\nUsing `LIBRARY_PATH` instead of `CUDA_LIBRARY_PATH` seems to help.\r\n\r\nNow, to start building a basic CUDA crate. Add the following to your `Cargo.toml`:\r\n\r\n```yaml\r\n[dependencies]\r\nrustacuda = \"0.1\"\r\nrustacuda_core = \"0.1\"\r\nrustacuda_derive = \"0.1\"\r\n```\r\n\r\nAnd this to your crate root:\r\n\r\n```rust\r\n#[macro_use]\r\nextern crate rustacuda;\r\n\r\n#[macro_use]\r\nextern crate rustacuda_derive;\r\nextern crate rustacuda_core;\r\n```\r\n\r\nNext, download the `resources/add.ptx` file from the RustaCUDA repository and place it in\r\nthe resources directory for your application.\r\n\r\nThe *examples/* directory contains sample code that helps getting started. \r\nTo execute the most simple example, (adding two numbers on GPU),\r\nplace this code to your `main.rs` file.\r\n\r\n```rust\r\n#[macro_use]\r\nextern crate rustacuda;\r\n\r\nuse rustacuda::prelude::*;\r\nuse rustacuda::memory::DeviceBox;\r\nuse std::error::Error;\r\nuse std::ffi::CString;\r\n\r\nfn main() -> Result<(), Box<dyn Error>> {\r\n    // Initialize the CUDA API\r\n    rustacuda::init(CudaFlags::empty())?;\r\n    \r\n    // Get the first device\r\n    let device = Device::get_device(0)?;\r\n\r\n    // Create a context associated to this device\r\n    let context = Context::create_and_push(\r\n        ContextFlags::MAP_HOST | ContextFlags::SCHED_AUTO, device)?;\r\n\r\n    // Load the module containing the function we want to call\r\n    let module_data = CString::new(include_str!(\"../resources/add.ptx\"))?;\r\n    let module = Module::load_from_string(&module_data)?;\r\n\r\n    // Create a stream to submit work to\r\n    let stream = Stream::new(StreamFlags::NON_BLOCKING, None)?;\r\n\r\n    // Allocate space on the device and copy numbers to it.\r\n    let mut x = DeviceBox::new(&10.0f32)?;\r\n    let mut y = DeviceBox::new(&20.0f32)?;\r\n    let mut result = DeviceBox::new(&0.0f32)?;\r\n\r\n    // Launching kernels is unsafe since Rust can't enforce safety - think of kernel launches\r\n    // as a foreign-function call. In this case, it is - this kernel is written in CUDA C.\r\n    unsafe {\r\n        // Launch the `sum` function with one block containing one thread on the given stream.\r\n        launch!(module.sum<<<1, 1, 0, stream>>>(\r\n            x.as_device_ptr(),\r\n            y.as_device_ptr(),\r\n            result.as_device_ptr(),\r\n            1 // Length\r\n        ))?;\r\n    }\r\n\r\n    // The kernel launch is asynchronous, so we wait for the kernel to finish executing\r\n    stream.synchronize()?;\r\n\r\n    // Copy the result back to the host\r\n    let mut result_host = 0.0f32;\r\n    result.copy_to(&mut result_host)?;\r\n    \r\n    println!(\"Sum is {}\", result_host);\r\n\r\n    Ok(())\r\n}\r\n```\r\n\r\nIf everything is working, you should be able to run `cargo run` and see the output:\r\n\r\n```text\r\nSum is 30.0\r\n```\r\n\r\n### Contributing\r\n\r\nThanks for your interest! Contributions are welcome.\r\n\r\nIssues, feature requests, questions and bug reports should be reported via the issue tracker above.\r\nIn particular, because RustaCUDA aims to be well-documented, please report anything you find\r\nconfusing or incorrect in the documentation.\r\n\r\nCode or documentation improvements in the form of pull requests are also welcome. Please file or\r\ncomment on an issue to allow for discussion before doing a lot of work, though.\r\n\r\nFor more details, see the [CONTRIBUTING.md file](https://github.com/bheisler/rustaCUDA/blob/master/CONTRIBUTING.md).\r\n\r\n### Maintenance\r\n\r\nRustaCUDA is currently maintained by Brook Heisler (@bheisler).\r\n\r\n### License\r\n\r\nRustaCUDA is dual-licensed under the Apache 2.0 license and the MIT license.\r\n\r\n### Requirements\r\n\r\nRustaCUDA requires at least CUDA version 8 to be installed.\r\n\r\n### Related Projects\r\n\r\n- [accel](https://github.com/rust-accel/accel) is a full CUDA computing framework. Thanks to accel for creating and maintaining the `cuda-sys` FFI wrapper library.\r\n- [rust-ptx-builder](https://github.com/denzp/rust-ptx-builder) is a `build.rs` helper library which makes it easy to compile Rust crates into CUDA kernels.\r\n\r\n[crate-image-fil-rustacuda]: https://img.shields.io/crates/v/fil-rustacuda.svg\r\n[crate-link-fil-rustacuda]: https://crates.io/crates/fil-rustacuda\r\n[doc-image-fil-rustacuda]: https://docs.rs/fil-rustacuda/badge.svg\r\n[doc-link-fil-rustacuda]: https://docs.rs/fil-rustacuda\r\n", "release_dates": []}, {"name": "fil-sppark", "description": "A Rust binding to [sppark] specifically for Filecoin proofs' needs", "language": "Rust", "license": null, "readme": null, "release_dates": []}, {"name": "filcryo", "description": "\ud83e\uddca Filecoin Archival-grade snapshots", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# :ice_cube: Filcryo\n\n```sh\ndocker pull filecoin/filcryo\n```\n\nFilcryo is used to freeze chunks of the Filecoin chain with all nutritional\nproperties (archival grade quality). They can then be cooked with\n[Filet](https://github.com/filecoin-project/filet).\n\nThis project first and foremost aim is to create archival-grade snapshots as\nused by the Sentinel/Data Engineering Team at Protocol Labs for further\nprocessing. It is meant to \"just work\" for this and be as simple and easy to\nfollow as possible. Generalization or re-usability are secondary concerns as\nof now.\n\nUsage, build and deployment information is found in [DOCS.md](DOCS.md).\n", "release_dates": []}, {"name": "filecoin", "description": "GitHub home for the Filecoin Project", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin\n\nWelcome to the home page for the [Filecoin Project](https://filecoin.io) on GitHub.\n\n## Table of Contents\n\n- [Key Filecoin Project resources](#key-filecoin-project-resources)\n- [Reporting security vulnerabilities](#reporting-security-vulnerabilities)\n- [License](#license)\n\n## Key Filecoin Project resources\n\nThe [Filecoin Project on GitHub](https://github.com/filecoin-project) is where you can find our active work. Sometimes we use Google Drive for work products (usually design docs and priorities lists). In these instances, we will either translate these docs to Markdown and post on GitHub or make them public and link to them from the relevant GitHub repos. So, you can generally keep track of the Filecoin Project's work by following us on GitHub.\n\nHere are the main Filecoin Project repos:\n- [`specs`](https://github.com/filecoin-project/specs): This is the home of the WIP Filecoin protocol specification\n- [`go-filecoin`](https://github.com/filecoin-project/go-filecoin): An implementation of the Filecoin protocol, written in Go\n- [`rust-proofs`](https://github.com/filecoin-project/rust-proofs): Implementations of Filecoin cryptographic proofs, written in Rust\n- [`research`](https://github.com/filecoin-project/research): Where open problems in Filecoin research are discussed\n- [`designdocs`](https://github.com/filecoin-project/designdocs): Contains links to our key design docs\n- [`community`](https://github.com/filecoin-project/community): Resources for community calls and pointers to main communication channels\n\n## Reporting security vulnerabilities\n\nAlmost anything you find that is a bug in the codebase should be filed as an issue. The exception is if you find a security vulnerability. The Filecoin protocol is still under heavy development. This means that there may be problems in our protocol design or implementations. Though Filecoin is not yet production-ready, many people are already running nodes on their machines. So we take security vulnerabilities very seriously! If you discover a security issue, please bring it to our attention right away!\n\nIf you find a security vulnerability, please send your report privately to security@filecoin.org. Please DO NOT file a public issue.\n\nIf the issue is a protocol weakness that cannot be immediately exploited or has not yet been deployed, just discuss it openly.\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/filecoin/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/filecoin/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "filecoin-actor-utils", "description": "Collection of libraries to implement common patterns and standards on the Filecoin Virtual Machine", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin\n\n[Filecoin](https://filecoin.io) is a decentralized storage network designed to\nstore humanity's most important information.\n\nThis repo contains utilities and libraries to work with the\n[Filecoin Virtual Machine](https://fvm.filecoin.io/)\n\n[![Coverage Status](https://coveralls.io/repos/github/helix-onchain/filecoin/badge.svg?branch=main)](https://coveralls.io/github/helix-onchain/filecoin?branch=main)\n\n## Packages\n\n### fvm_actor_utils\n\nA set of utilities to help write testable native actors for the Filecoin Virtual\nMachine. Provides abstractions on top of FVM-SDK functionality that can be\nshimmed or mocked in unit tests. This includes helpers for:\n\n- Universal receiver hooks (as defined in\n  [FRC-0046](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0046.md))\n- IPLD-compatible blockstore\n- Messaging and address resolution\n\n### frc42_dispatch\n\nReference library containing macros for standard method dispatch. A set of CLI\nutilities to generate method numbers is also available:\n[fvm_dispatch_tools](./fvm_dispatch_tools/)\n\n| Specification                                                                     | Reference Implementation                     | Examples                                         |\n| --------------------------------------------------------------------------------- | -------------------------------------------- | ------------------------------------------------ |\n| [FRC-0042](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0042.md) | [frc42_dispatch](./frc42_dispatch/README.md) | [greeter](./dispatch_examples/greeter/README.md) |\n\n### frc46_token\n\nReference library for implementing a standard fungible token in native actors\n\n| Specification                                                                     | Reference Implementation               | Examples                                                                                                                                                                   |\n| --------------------------------------------------------------------------------- | -------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [FRC-0046](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0046.md) | [frc46_token](./frc46_token/README.md) | [basic_token](./testing/fil_token_integration/actors/basic_token_actor/README.md) [basic_receiver](./testing/fil_token_integration/actors/basic_receiving_actor/README.md) |\n\n### frc53_nft\n\nReference library for implementing a standard non-fungible token in native\nactors\n\n| Specification                                                                     | Reference Implementation           | Examples                                                                                                                                                               |\n| --------------------------------------------------------------------------------- | ---------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [FRC-0053](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0053.md) | [frc53_nft](./frc53_nft/README.md) | [basic_nft](./testing/fil_token_integration/actors/basic_nft_actor/README.md) [basic_receiver](./testing/fil_token_integration/actors/basic_receiving_actor/README.md) |\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT),\n[Apache Software License v2](./LICENSE-APACHE).\n\n<sub>Copyright Protocol Labs, Inc, 2022</sub>\n", "release_dates": []}, {"name": "filecoin-chain-archiver", "description": "Filecoin snapshot / chain export software", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin Chain Archiver\n\nFilecoin chain archiver is a software tool for creating chain exports / snapshots using the lotus filecoin node.\n\n## Background\n\nFilecoin network snapshots are a segment of the Filecoin chain exported to a Content Addressable aRchives (CAR) file.\nThey contain a chain segment large enough to allow the Filecoin network consensus protocol to apply messages\nsuccessfully.\n\n## Building & Dependencies\n\n- Go 1.19 or higher\n\n```\nmake all\n```\n\n## Usage\n\nA running lotus node is required with automatic restarts and a jwt token with `admin` privileges.\n\nSetup Daemon\n```\n$ while true; do lotus daemon; done\n```\n\nCreate Token\n```\nlotus auth create-token --perm admin | tr -d '\\n' > token\n```\n\n```\ncat > config.toml <<EOF\n[[Nodes]]\n  Address = \"/ip4/127.0.0.1/tcp/1234\"\n  TokenPath = ./token\"\nEOF\n```\n\n```\n./filecoin-chain-archiver nodelocker run\n```\n\n```\n./filecoin-chain-archiver create --height <height> --discard\n```\n\n## Contributing\n\nPRs accepted.\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/filecoin-chain-archiver/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/filecoin-chain-archiver/blob/master/LICENSE-APACHE)\n", "release_dates": ["2023-12-12T17:22:09Z", "2023-05-10T18:13:06Z", "2023-03-10T12:31:15Z"]}, {"name": "filecoin-client-tutorial", "description": "Store data on the Filecoin Network in under 5 minutes.", "language": "JavaScript", "license": null, "readme": "# Filecoin Client Tutorial\n\nA simple tutorial for starting an express server and storing data on the Filecoin Network in under 5 minutes.\n\n\n## Satisfy dependency requirements\n\n- Make sure you have [homebrew](https://brew.sh/).\n- Make sure you run `xcode-select -p`, if the command does not return a response, run `xcode-select --install`\n- Make sure you run `brew install node`\n- Make sure you run `brew install go`\n\n\n## Setup Docker\n\n- `brew install docker`.\n- Install [Docker for Desktop](https://www.docker.com/products/docker-desktop) if you are running MacOS.\n\n\n\n## Terminal\nYou will need to run three simultaneous terminal windows:\n\n\n\n## Setup Lotus DevNet\n**In Terminal window 1:**\n- Clone the [Lotus DevNet](https://github.com/textileio/lotus-devnet) repository: `git@github.com:textileio/lotus-devnet.git`\n- Run `docker run --name texdevnet -e TEXLOTUSDEVNESPEED=1500 -p 1234:7777 textile/lotus-devnet`\n\n\n## Setup Powergate\n**In Terminal window 2:**\n- Clone the [Powergate](https://github.com/textileio/powergate/) repository: `git@github.com:textileio/powergate.git`\n- `cd powergate`\n- Build and install the CLI: `make build-pow`\n- Build the Powergate server: `make build-powd`\n- `cd docker`\n- `make devnet`\n\n\n## Install and run\n**In Terminal window 3:**\n\nRun these commands to start the client locally.\n\n```sh\ngit clone git@github.com:filecoin-project/filecoin-client-tutorial.git\ncd filecoin-client-tutorial\nnpm install\n```\n\n## Create a server.js file\n\nThe main API you will interact with is the Filecoin File System (FFS).\n\n```sh\n//import express server\nimport express from \"express\";\n\nimport fs from \"fs\"\nimport { ffs, createPow } from \"@textile/powergate-client\"\n\nconst pow = createPow({ host:\"http://0.0.0.0:6002\" })\nconst server = express();\n\nserver.listen(8080, async () => {\n\n  //create a new FFS instance.\n  const { token } = await pow.ffs.create()\n  console.log({token});\n\n  //set the auth token that the Powergate client to use.\n  pow.setToken(token)\n\n  // cache data in IPFS in preparation to store it using FFS\n  const { cid } = await pow.ffs.addToHot(buffer)\n  console.log({cid});\n  const buffer = fs.readFileSync(`dog.jpg`)\n\n  // store the data in FFS using the default storage configuration\n  const { jobId } = await pow.ffs.pushConfig(cid)\n  console.log({jobId});\n\n  // watch the FFS job status to see the storage process progressing\n  const cancel = pow.ffs.watchJobs((job) => {\n    console.log({job})\n    if (job.status === ffs.JobStatus.CANCELED) {\n      console.log(\"job canceled\")\n    } else if (job.status === ffs.JobStatus.FAILED) {\n      console.log(\"job failed\")\n    } else if (job.status === ffs.JobStatus.SUCCESS) {\n      console.log(\"job success!\")\n    }\n  }, jobId);\n});\n```\n\n- Run `node .`\n\nGo to the [Filecoin Client](https://github.com/filecoin-project/filecoin-client/) to see the full end to end application.\n\n## References\n- https://blog.textile.io/integrating-powergate/\n- https://github.com/textileio/js-powergate-client\n", "release_dates": []}, {"name": "filecoin-contributors", "description": "\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66 Script to generate a list of the contributors to Filecoin since a given date", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# filecoin-contributors\n\n> Script to generate a list of the contributors to Filecoin since a given date\n\n![Screenshot](https://raw.githubusercontent.com/filecoin-project/filecoin-contributors/master/screenshot.png)\n\n## Install\n\nInstall dependences:\n\n* [Node.js](https://nodejs.org/en/)\n\nThen:\n\n```sh\nnpm install -g filecoin-contributors\n```\n\nOr, install from source:\n\n```sh\n# Clone the repo\ngit clone https://github.com/filecoin-project/filecoin-contributors.git\ncd filecoin-contributors\n\n# Install project dependencies\nnpm install\n```\n\n## Usage\n\nSimply run the tool by typing the following at the command line:\n\n```sh\nfilecoin-contributors\n```\n\nOr, if you've installed from source:\n\n```sh\nnpm start\n```\nThen follow the prompts. You will need a [Github personal access token](https://github.com/settings/tokens/) with the following scopes:\n* read_org\n* user_email\n\nNote: It may take a long time! Please be patient!\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/go-filecoin/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/go-filecoin/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "filecoin-discover-dealer", "description": null, "language": "Shell", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "filecoin-discover-dealer\n==================\n\n## Onboarding instructions\n\nThe direct-from-disk Filecoin Discover onboarding program has closed.\n\nHowever, the data originally shipped is still valuable and there is **continuing interest** in onboarding and renewal of the **~1.4 Million `.car`** files originally distributed.\n\nThe datasets are in the process of being folded into the SlingshotLegacy \u2660\ufe0f tenant, projected to become active some time during Jan 2023.\n\nCome join us in [#spade over at the Fil Slack](https://filecoinproject.slack.com/archives/C0377FJCG1L) and stay tuned \ud83d\ude80\n", "release_dates": []}, {"name": "filecoin-discover-validator", "description": null, "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "This repository used to contain a Discover Drive content inference tool.\n\nIt's most notable part now lives standalone as https://pkg.go.dev/github.com/filecoin-project/go-fil-commp-hashhash#Calc", "release_dates": []}, {"name": "filecoin-docs", "description": "Filecoin Docs", "language": "Shell", "license": null, "readme": "<div align=center>\n    \n[![MIT License](https://img.shields.io/badge/license-MIT-blueviolet?style=for-the-badge)](https://protocol.ai/blog/announcing-the-permissive-license-stack/)\n[![Website status](https://img.shields.io/website.svg?style=for-the-badge&url=https%3A%2F%2Fdocs.filecoin.io)](https://docs.filecoin.io/)\n[![Backlog](https://img.shields.io/badge/backlog-Updated-blue?style=for-the-badge)](https://github.com/orgs/filecoin-project/projects/103/views/1)\n![Link Checker](https://img.shields.io/github/actions/workflow/status/filecoin-project/filecoin-docs/check-external-links.yml?style=for-the-badge&label=External%20link%20checker)\n\n<picture align=center>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://bafybeiaqdbd5zbl55x5vjmkwpjhqapt3ks3q4ykaclqkajhsdwyzlbz3g4.ipfs.w3s.link/Filecoin-logo-blue-white.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://bafybeihuk3hsy6d43dn36tqnvf6tvzleiijd5idbf2q7maw3nshnfm6wiu.ipfs.w3s.link/filecoin-logo-black-type.svg\">\n    <img alt=\"The Filecoin project logo.\" src=\"https://bafybeihuk3hsy6d43dn36tqnvf6tvzleiijd5idbf2q7maw3nshnfm6wiu.ipfs.w3s.link/filecoin-logo-black-type.svg\">\n</picture>\n\n</div>\n\n## Table of contents\n\n- [About this repo](#about-this-repo)\n- [Contributing](#contributing)\n- [Issues](#issues)\n    - [Backlog](#backlog)\n    - [Priority](#priority)\n- [License](#license)\n\n## About this repo\n\nThis repository manages the documentation for the [Filecoin network](https://filecoin.io). The content is built and hosted by [GitBook](https://github.com). View the docs site at [docs.filecoin.io](https://docs.filecoin.io).\n\n## Contributing\n\nWant to help out? Pull requests (PRs) are always welcome! If you want to help out but aren't sure where to start, check out the [issues board](https://github.com/filecoin-project/filecoin-docs/issues).\n\n## Issues \n\nFound a problem with the Filecoin docs site? [Please raise an issue](https://github.com/filecoin-project/filecoin-docs/issues/new). Be as specific and descriptive as possible; screenshots help!\n\n### Backlog\n\nYou can view the backlog of issues, as well as what we're working on next, [over on the project board](https://github.com/orgs/filecoin-project/projects/103/views/1)\n\n### Priority\n\nWe use `p` tags to define the priority of an issue. The priority is defined by the docs team using the following definitions:\n\n| Label | Impact | Due date | Example |\n| ----- | ------ | -------- | ------- |\n| P0 | Severely business-impacting | Same day. Drop everything and fix it immediately. | The website is down. |\n| P1 | Business-impacting. | Within three days. | The API endpoint for a project is about to change. |\n| P2 | Planned project request. | Within two weeks. | A new method will soon be added to a project API. |\n| P3 | Suggestion or conceptual update. | No due date. | A blog post discussing the benefits of decentralization for web developers. |\n| P4 | Deprioritized suggestions. These will not be addressed unless significant activity or community requests are received. | No due date. | Translate the docs into Klingon. |\n\n## License\n\nDual-licensed: MIT, Apache Software License v2, by way of the [Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n", "release_dates": []}, {"name": "filecoin-docs-CAT", "description": "Filecoin Docs", "language": "SCSS", "license": null, "readme": "[![Contributors][contributors-shield]][contributors-url]\r\n[![Forks][forks-shield]][forks-url]\r\n[![Issues][issues-shield]][issues-url]\r\n[![MIT License][license-shield]][license-url]\r\n[![Website status][website-status]][website-status-url]\r\n\r\n<br>\r\n\r\n<picture align=center>\r\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://bafybeiaqdbd5zbl55x5vjmkwpjhqapt3ks3q4ykaclqkajhsdwyzlbz3g4.ipfs.w3s.link/Filecoin-logo-blue-white.svg\">\r\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://bafybeihuk3hsy6d43dn36tqnvf6tvzleiijd5idbf2q7maw3nshnfm6wiu.ipfs.w3s.link/filecoin-logo-black-type.svg\">\r\n    <img alt=\"The Filecoin project logo.\" src=\"https://bafybeihuk3hsy6d43dn36tqnvf6tvzleiijd5idbf2q7maw3nshnfm6wiu.ipfs.w3s.link/filecoin-logo-black-type.svg\">\r\n</picture>\r\n\r\n<br>\r\n<br>\r\n\r\n<h4 align=\"center\"> This repository manages the documentation for the <a href=\"https://filecoin.io\">Filecoin network</a>. This repo also contains the build scripts and tools to create the Filecoin docs website. <a href=\"https://docs.filecoin.io/\">Explore the docs \u2192</a></h4>\r\n\r\n<!-- /HEADER -->\r\n\r\n\r\n\r\n<!-- TABLE OF CONTENTS -->\r\n## Table of contents\r\n\r\n- [Getting started](#getting-started)\r\n    - [Prerequisites](#prerequisites)\r\n    - [Installation](#installation)\r\n- [About the project](#about-the-project)\r\n    - [Files and folders](#files-and-folders)\r\n- [Contributing](#contributing)\r\n    - [Video guides for site management](#video-guides-for-site-management)\r\n    - [Front-matter variables](#front-matter-variables)\r\n        - [Title](#title)\r\n        - [Description](#description)\r\n        - [Lead](#lead)\r\n        - [Weight](#weight)\r\n        - [Menu](#menu)\r\n            - [Sidebar menu](#sidebar-menu)\r\n            - [Sub-menu](#sub-menu)\r\n        - [Aliases](#aliases)\r\n        - [Draft](#draft)\r\n    - [Features](#features)\r\n        - [Archived content](#archived-content)\r\n        - [Code tabs](#code-tabs)\r\n        - [Tooltips](#tooltips)\r\n- [Issues](#issues)\r\n- [License](#license)\r\n- [Acknowledgments](#acknowledgments)\r\n<!-- /TABLE OF CONTENTS -->\r\n\r\n\r\n\r\n<!-- GETTING STARTED-->\r\n## Getting Started\r\n\r\nFollow these simple example steps to get a local version of the site up and running.\r\n<!-- /GETTING STARTED-->\r\n\r\n\r\n\r\n<!-- PREREQUISITES -->\r\n### Prerequisites\r\n\r\nTo run these commands, you must have [NPM installed](https://www.npmjs.com/). If you already have NPM installed, make sure you are running the latest version:\r\n\r\n```shell\r\nnpm install npm@latest -g\r\n```\r\n<!-- /PREREQUISITES -->\r\n\r\n\r\n\r\n<!-- INSTALLATION -->\r\n### Installation\r\n\r\nFollow these steps to run a copy of this site on your local computer. \r\n\r\n1. Clone this repo:\r\n\r\n    ```shell\r\n    git clone https://github.com/filecoin-project/filecoin-docs\r\n    ```\r\n\r\n1. Move into the new folder and download the dependencies:\r\n\r\n    ```shell\r\n    cd filecoin-docs\r\n    npm install\r\n    ```\r\n\r\n1. Build and serve the project locally: \r\n\r\n    ```shell\r\n    npm run start\r\n    ```\r\n    \r\n1. Visit [localhost:1313](http://localhost:1313) to view the site.\r\n1. Press `CTRL` + `c` in the terminal to stop the local server.\r\n\r\nIf you want to just build the site but _not_ serve it locally, run:\r\n\r\n```shell\r\nnpm run build\r\n```\r\n\r\nA static site will be built and stored in the `/public` directory.\r\n<!-- /INSTALLATION -->\r\n\r\n\r\n\r\n<!-- ABOUT THE PROJECT -->\r\n## About the project\r\n\r\n<picture align=center>\r\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://bafybeick5a6esj6qqtw35jdgrouyn3nrg5ckrmjptuvx3jjjnih7vkdzre.ipfs.w3s.link/filecoin-homepage-dark.png\">\r\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://bafybeib2c67ernhjnqzrdcmtzn5cvi45qrftz6qlo37wr5cnnhvrs6ocg4.ipfs.w3s.link/filecoin-homepage-light.png\">\r\n    <img alt=\"The Filecoin project logo.\" src=\"https://bafybeib2c67ernhjnqzrdcmtzn5cvi45qrftz6qlo37wr5cnnhvrs6ocg4.ipfs.w3s.link/filecoin-homepage-light.png\">\r\n</picture>\r\n\r\nThis repository manages the documentation for the Filecoin project. This repo also contains the build scripts and tools to create the Filecoin docs website and the API documentation. If you want to learn about Filecoin, how it works, or how to build on it, then you're in the right place.\r\n\r\n### Files and folders\r\n\r\nThis section lists the various files and folders and defines the purpose for each of them.\r\n\r\n| Name | Purpose |\r\n| --- | --- |\r\n| `.git`, `.github` | Manage the git configurations and contain information for GitHub constant integrations. |\r\n| `README.md` | This file. Acts as an introduction to this repo and how to spin up a local copy of the `docs.filecoin.io` site. |\r\n| `archetypes/` | Used by Hugo to programmatically create new pages. |\r\n| `assets/` | Assets like JavaScript and fonts used by Hugo to create the static site. These assets are not explorable in a built site. You must reference them in code before building the site. |\r\n| `babel.config.js` | A configuration file used for the Babel JS compiler. |\r\n| `config/` | Contains the configuration files for Hugo. You can manage things like the top-bar menu and site title within this directory. |\r\n| `content/` | This is where all the `.md` files live that control the content of this site. Most contributions happen in this directory. |\r\n| `data/` | You can supply extra variables for Hugo to use when building pages in this directory. These variables act just like front-matter variables. See [Data Templates](https://gohugo.io/templates/data-templates/) in the Hugo docs for more info. |\r\n| `functions/` | Functions callable from any template, partial, or shortcode within Hugo. |\r\n| `i18n/` | Contains files specific to managing different languages. |\r\n| `layouts/` | This is where web developers will likely spend most of their time. This folder contains the shortcodes and partials that Hugo uses to scaffold and build the site. |\r\n| `node_modules/` | Where NPM throws its packages. If you see this in GitHub, something's gone wrong. It should only exist on your computer after you run `npm install`. |\r\n| `package-lock.json` | One of the NPM configuration files. Specify which version of packages to download. |\r\n| `package.json` | Another one of the NPM configuration files. Specifies which packages to download but doesn't specify which _version_ of the package to grab.\r\n| `resources/` | A cache where Hugo throws generated files like CSS and JSON after `npm run build` has been called. Unless `npm run clean` is called, Hugo will re-use these files when calling `npm run build`. |\r\n| `static/` | Images, CSS, fonts, and other misc files available at `docs.filecoin.io/` when the site is built. For example, `docs.filecoin.io/site.webmanifest`.\r\n| `theme.toml` | A Hugo configuration file that specifies which theme to use. This file should not change that often. |\r\n<!-- /ABOUT THE PROJECT -->\r\n\r\n\r\n\r\n<!-- CONTRIBUTING -->\r\n## Contributing\r\n\r\nWant to help out? Pull requests (PRs) are always welcome! If you want to help out but aren't sure where to start, check out the [issues board](https://github.com/filecoin-project/filecoin-docs/issues).\r\n\r\n### Video guides for site management\r\n\r\n\r\nHere's a collection of guides you can use to help manage and contribute to this site:\r\n\r\n- [Managing the top-bar navigation](https://bafybeidn4wxz44rssgdlu3p2dzh4tbyevuqd27xv7avioyf2m65jzlhnj4.ipfs.w3s.link/DaaS%20-%20Managing%20the%20topbar%20navigation%20-%20HD%201080p.mov)\r\n- [Move a page and add a redirect](https://bafybeibuwipv4rk2tzcqvouu2xlnebh4d7ol47mvmegtispbvlcruuwmhi.ipfs.w3s.link/Move%20and%20page%20and%20add%20a%20redirect.mp4)\r\n\r\n### Creating sidebar labels and content pages\r\n\r\nTo create sidebar labels, use the `npm create` command:\r\n\r\n```shell\r\nnpm run create -- --kind sidebar storage-provider/hardware \r\n```\r\n\r\nThe above command will create the folder structure and a `_index.md` file containing the front-matter for the label.\r\n\r\n### Creating content pages\r\n\r\nTo create content pages, use the `npm create` command:\r\n\r\n```shell\r\nnpm run create -- --kind page storage-provider/hardware/architectures\r\n```\r\n\r\nThe above command will create a folder and an `index.md` file containing the front-matter for that page, that can then be edited.\r\n\r\nIf you make a mistake and need to remove a page, or section, just delete the folder.\r\n\r\nTo move content from one place to another, create the new pages using `npm create`, copy the text across to the newly created pages and delete the originals.\r\n\r\n\r\n\r\n### Front-matter variables \r\n\r\nThe front-matter is that small section of metadata you can find at the top of each `.md` file within the [`/content` folder](https://github.com/filecoin-project/filecoin-docs/tree/main/content/en). Each variable has a specific purpose, and while not all are necessary, it's useful to know what they do and why they exist. \r\n\r\n```YAML\r\n---\r\ntitle: \"Get started\"\r\ndescription: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to maintaining the Filecoin blockchain, obtaining storage services, and receiving rewards in the process. This section walks you through how to get started, build a node, and create a simple application.\"\r\nlead: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to maintaining the Filecoin blockchain, obtaining storage services, and receiving rewards in the process. This section walks your through how to get started, build a node, and create a simple application.\"\r\nmenu:\r\n    getstarted:\r\n        parent: \"getstarted-overview\"\r\naliases:\r\n    - /get-started\r\n    - /how-to/install-filecoin\r\n---\r\n```\r\n\r\nIt's also good to note that we use the YAML as our front-matter format. We could use [JSON or TOML](https://gohugo.io/content-management/front-matter#front-matter-formats) if we really wanted, but we found YAML the easiest to read. Plus, _yammal_ is fun to say.\r\n\r\nThis list has been created in order of commonality; variables you will come across most often are closer to the top of this list.\r\n\r\n#### Title\r\n\r\nThe `title` variable defines what the `<h1>` tag on this page will say, along with the contents of `<title>` in this page's `<head>`. This variable also defines what is shown as the sidebar item; however, this can be overwritten in the `menus` config file.\r\n\r\n```YAML\r\n---\r\ntitle: \"Get started\"\r\n---\r\n```\r\n\r\n![](./static/images/front-matter-variables-title.png)\r\n\r\n#### Description\r\n\r\nThe `description` variable defines what is in the [meta `<description>`](https://moz.com/learn/seo/meta-description) tag within the `<head>` tag of this page's HTML.  This description often shows up in search engine results, and social network embeds. This description is meant to give the reader an idea of the content on this page and how it relates to their search query.\r\n\r\n```YAML\r\n---\r\ndescription: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to [...]\"\r\n---\r\n```\r\n\r\n![](./static/images/front-matter-variables-description.png)\r\n\r\n#### Lead\r\n\r\nThe `lead` variable defines the content of the first paragraph on a page. This is usually an introduction, informing the reader what this page is referring to, what they're about to learn, and any prerequisites for understanding the content on this page. Often, the content of this variable is the same as the `description` variable.\r\n\r\n```YAML\r\n---\r\nlead: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to [...]\"\r\n---\r\n```\r\n\r\n![](./static/images/front-matter-variables-lead.png)\r\n\r\n#### Weight\r\n\r\nThe `weight` variable defines where this page or menu item should be in a menu. The lower the number, the closer to the start of the menu this page will be. If set, `weight` should be non-zero, as `0` is interpreted as an unset weight. There is no upper limit for a weight value.\r\n\r\nIn the top-bar menu, a lower number will cause the menu item to be further to the left in a regular view or further to the top in a mobile view.\r\n\r\nThis example is from the `/config/_default/menus/menus.en.toml` file:\r\n\r\n```\r\n[[main]]\r\n  name = \"About Filecoin\"\r\n  url = \"/about-filecoin/what-is-filecoin\"\r\n  weight = 10\r\n  \r\n[[main]]\r\n  name = \"Networks\"\r\n  url = \"/networks/overview\"\r\n  weight = 20\r\n\r\n[[main]]\r\n  name = \"Get started\"\r\n  url = \"/get-started/overview\"\r\n  weight = 30\r\n```\r\n\r\n![](./static/images/front-matter-variables-weight-1.png)\r\n\r\nIn the sidebar menu, a lower number will cause the menu item or page to be higher up.\r\n\r\n![](./static/images/front-matter-variables-weight-2.png)\r\n\r\nThe weight of a page also defines the _next_ and _previous_ buttons at the bottom of the page. The _previous_ page will be the page with the closest weight _below_ the current page's weight. The _next_ page will be the page with the closest weight _above_ the current page's weight.\r\n\r\n![](./static/images/front-matter-variables-weight-3.png)\r\n\r\n#### Menu\r\n\r\nThe `menu` variable defines which sidebar menu this page is assigned to, along with which sub-menu this page falls under. This variable is made of three parts:\r\n\r\n1. The `menu` delimiter. This tells Hugo that were are about to define the menu object for this page.\r\n1. The section/top-bar menu that this page falls under.\r\n1. The sub-menu within the sidebar that this page falls under.\r\n\r\n```YAML\r\n---\r\nmenu:\r\n    store:\r\n        parent: \"store-filecoin-plus\"\r\n---\r\n```\r\n\r\n##### Sidebar menu\r\n\r\nEach section has its own sidebar menu. The name of each sidebar menu is usually a lowercase version of the name of the section. For sections that contain a space, the sidebar menu name is a lowercase version of the section without the space:\r\n\r\n| Section | Sidebar menu name |\r\n| --- | --- |\r\n| About Filecoin | `about` |\r\n| Build | `build` |\r\n| Get started | `getstarted` |\r\n| Networks | `networks` |\r\n| Reference | `reference` |\r\n| Storage provider | `storageprovider` |\r\n| Store | `store` |\r\n\r\n\r\n```YAML\r\n---\r\nmenu:\r\n    storageprovider:\r\n---\r\n```\r\n\r\n##### Sub-menu\r\n\r\nYou can think of a sub-menu as the dropdown item in the sidebar menu. Sub-menus are defined in `/config/\\_default/menus/menus.en.toml`. \r\nEach sub-menu is a _child_ of a sidebar menu. A sidebar menu can contain multiple sub-menus, but a sub-menu can only belong to one sidebar menu.\r\n\r\nSub-menus are made up of:\r\n\r\n- `name`: The visible text shown to the user.\r\n- `weight`: How high or low this sub-menu is shown within the sidebar.\r\n- `identifier`: A unique string used in the front-matter to specify this particular sub-menu.\r\n- `url`: The default page a user will go to if they click on this sub-menu link.\r\n\r\n```YAML\r\n[[about]]\r\n  name = \"Basics\"\r\n  weight = 10\r\n  identifier = \"about-filecoin-basics\"\r\n  url = \"/about-filecoin/what-is-filecoin\"\r\n\r\n...\r\n\r\n[[networks]]\r\n  name = \"Overview\"\r\n  weight = 10\r\n  identifier = \"networks-overview\"\r\n  url = \"/networks/\"\r\n\r\n...\r\n\r\n[[getstarted]]\r\n  name = \"Overview\"\r\n  weight = 1 \r\n  identifier = \"getstarted-overview\"\r\n  url = \"/get-started/overview/\"\r\n```\r\n\r\nTo assign a page to a sub-menu, you must supply both the menu object name and the `identifier` value into the front-matter:\r\n\r\n```YAML\r\nmenu:\r\n    getstarted:\r\n        parent: \"getstarted-overview\"\r\n```\r\n\r\nThe identifier of each sub-menu is usually the menu object name and the title of the sub-menu, all in lowercase with dashes `-`:\r\n\r\n![](/.static/images/front-matter-variables-sub-menus.png)\r\n\r\n#### Aliases\r\n\r\nThe `aliases` variable defines URLs will redirect to this page. Each page can have multiple `aliases`, but each alias can only appear once throughout all the `.md` files within the `/content` folder.\r\n\r\nFor example, the `/get-started/overview` page can list `/get-started` as one of its aliases. However, no other page can list `/get-started` as an alias. If you attempt to assign another page the `/get-started` alias, Hugo will throw an error when you or Fleek try to build the website.\r\n\r\nAliases only work for internal links. You cannot assign a redirect to an external website using an alias.\r\n\r\n```YAML\r\n---\r\naliases:\r\n    - /get-started\r\n    - /how-to/install-filecoin\r\n---\r\n```\r\n\r\n#### Draft\r\n\r\nThe `draft` variable, when set to `true`, will hide the page from all site navigation. The page will still be accessible by visiting its URL. If this variable is not set, Hugo will assume that it is set to `false`.\r\n\r\n```YAML\r\ndraft: true\r\n```\r\n\r\nThis feature is generally used when we need to share content that isn't fully complete, but some users could benefit from its information at this exact moment.\r\n\r\n### Features\r\n\r\nThis project contains some handy features you can include within your project.\r\n\r\n#### Archived content\r\n\r\nOld pages can be archived and hidden from the sidebar view. However, the can still be accessed for historical purposes. \r\n\r\n![](/.static/images/archived-page.png)\r\n\r\nTo archive a page:\r\n\r\n1. Move the page and any associated images into the `/content/en/archive` directory.\r\n1. Add an alias redirect using the original location of this file:\r\n\r\n    ```markdown\r\n    ---\r\n    ...\r\n    aliases:\r\n        - \"/build/tools/filecoin-pinning-services/\"\r\n    ---\r\n    ```\r\n\r\n1. Add the following shortcode to the top of the page, just below the front-matter\r\n\r\n    ```markdown\r\n    ---\r\n\r\n    {{< archived-content >}}\r\n\r\n    ...\r\n    ```\r\n\r\nTake a look at the `/content/en/archive` directory for examples.\r\n\r\n<!-- #### Code tabs -->\r\n\r\n\r\n\r\n#### Tooltips\r\n\r\nTo make understanding terms in the docs a bit easier, users can hover over certain terms to get a short definition. These descriptions are located within a `dict` variable at the top of the `layouts/shortcodes/tooltip.html` shortcode:\r\n\r\n```go\r\n<!-- Create array/map of all possible tooltips. -->\r\n{{ $tooltips := dict\r\n    \"dApps\" \"Decentralized applications that don't rely on centralized infrastructure.\"\r\n    \"IPFS\" \"The InterPlanetary File System (IPFS) is a peer-to-peer protocol for sharing and storing files on the internet, designed to be decentralized and distributed.\"\r\n    \"Lotus\" \"The reference node implementation for the filecoin network.\"\r\n    \"Lily\" \"Software designed to simplify the recording of blockchain data.\"\r\n    \"web3\" \"A new iteration of the World Wide Web which incorporates concepts such as decentralization, blockchain technologies, and token-based economics.\"\r\n}}\r\n\r\n...\r\n```\r\n\r\nWithin your markdown you can use one of these tooltips with the following syntax:\r\n\r\n```markdown\r\n[...] storage on {{< tooltip \"IPFS\" >}} with blockchain-powered [...]\r\n```\r\n\r\nThe tooltip should show up once the site has built:\r\n\r\n![](static/images/tooltip-example.png)\r\n\r\n<!-- /CONTRIBUTING -->\r\n\r\n\r\n\r\n<!-- ISSUES -->\r\n## Issues \r\n\r\nFound a problem with the Filecoin docs site? [Please raise an issue](https://github.com/filecoin-project/filecoin-docs/issues/new). Be as specific and descriptive as possible; screenshots help!\r\n<!-- /ISSUES -->\r\n\r\n\r\n\r\n<!-- LICENSE -->\r\n## License\r\n\r\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the [Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\r\n<!-- /LICENSE -->\r\n\r\n\r\n<!-- TODO\r\n## Contact\r\n\r\nProject Link: [https://github.com/filecoin-project/filecoin-docs](https://github.com/filecoin-project/filecoin-docs)\r\n-->\r\n\r\n\r\n\r\n<!-- ACKNOWLEDGMENTS -->\r\n## Acknowledgments\r\n\r\n- [Fleek](https://fleek.co) web hosting\r\n- [Hugo](https://gohugo.io) static site generator \r\n- [Doks](https://getdoks.org) starter theme \r\n<!-- /ACKNOWLEDGMENTS -->\r\n\r\n\r\n\r\n<!-- MARKDOWN LINKS & IMAGES -->\r\n[contributors-shield]: https://img.shields.io/github/contributors/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[contributors-url]: https://github.com/filecoin-project/filecoin-docs/graphs/contributors\r\n[forks-shield]: https://img.shields.io/github/forks/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[forks-url]: https://github.com/filecoin-project/filecoin-docs/network/members\r\n[stars-shield]: https://img.shields.io/github/stars/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[stars-url]: https://github.com/filecoin-project/filecoin-docs/stargazers\r\n[issues-shield]: https://img.shields.io/github/issues/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[issues-url]: https://github.com/filecoin-project/filecoin-docs/issues\r\n[license-shield]: https://img.shields.io/badge/license-MIT-blueviolet?style=for-the-badge\r\n[license-url]: https://github.com/filecoin-project/filecoin-docs/blob/master/LICENSE.txt\r\n[product-screenshot]: ./static/images/filecoin-docs-homepage.png\r\n[website-status]: https://img.shields.io/website.svg?down_color=red&style=for-the-badge&url=https%3A%2F%2Flotus.filecoin.io\r\n[website-status-url]: https://docs.filecoin.io/\r\n<!-- /MARKDOWN LINKS & IMAGES -->\r\n\r\n<!-- markdownlint-disable-file -->\r\n", "release_dates": []}, {"name": "filecoin-docs-stefnotes", "description": "Filecoin Docs", "language": "SCSS", "license": null, "readme": "[![Contributors][contributors-shield]][contributors-url]\r\n[![Forks][forks-shield]][forks-url]\r\n[![Issues][issues-shield]][issues-url]\r\n[![MIT License][license-shield]][license-url]\r\n[![Website status][website-status]][website-status-url]\r\n\r\n<br>\r\n\r\n<picture align=center>\r\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://bafybeiaqdbd5zbl55x5vjmkwpjhqapt3ks3q4ykaclqkajhsdwyzlbz3g4.ipfs.w3s.link/Filecoin-logo-blue-white.svg\">\r\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://bafybeihuk3hsy6d43dn36tqnvf6tvzleiijd5idbf2q7maw3nshnfm6wiu.ipfs.w3s.link/filecoin-logo-black-type.svg\">\r\n    <img alt=\"The Filecoin project logo.\" src=\"https://bafybeihuk3hsy6d43dn36tqnvf6tvzleiijd5idbf2q7maw3nshnfm6wiu.ipfs.w3s.link/filecoin-logo-black-type.svg\">\r\n</picture>\r\n\r\n<br>\r\n<br>\r\n\r\n<h4 align=\"center\"> This repository manages the documentation for the <a href=\"https://filecoin.io\">Filecoin network</a>. This repo also contains the build scripts and tools to create the Filecoin docs website. <a href=\"https://docs.filecoin.io/\">Explore the docs \u2192</a></h4>\r\n\r\n<!-- /HEADER -->\r\n\r\n\r\n\r\n<!-- TABLE OF CONTENTS -->\r\n## Table of contents\r\n\r\n- [Getting started](#getting-started)\r\n    - [Prerequisites](#prerequisites)\r\n    - [Installation](#installation)\r\n- [About the project](#about-the-project)\r\n    - [Files and folders](#files-and-folders)\r\n- [Contributing](#contributing)\r\n    - [Video guides for site management](#video-guides-for-site-management)\r\n    - [Front-matter variables](#front-matter-variables)\r\n        - [Title](#title)\r\n        - [Description](#description)\r\n        - [Lead](#lead)\r\n        - [Weight](#weight)\r\n        - [Menu](#menu)\r\n            - [Sidebar menu](#sidebar-menu)\r\n            - [Sub-menu](#sub-menu)\r\n        - [Aliases](#aliases)\r\n        - [Draft](#draft)\r\n    - [Features](#features)\r\n        - [Archived content](#archived-content)\r\n        - [Code tabs](#code-tabs)\r\n        - [Tooltips](#tooltips)\r\n- [Issues](#issues)\r\n- [License](#license)\r\n- [Acknowledgments](#acknowledgments)\r\n<!-- /TABLE OF CONTENTS -->\r\n\r\n\r\n\r\n<!-- GETTING STARTED-->\r\n## Getting Started\r\n\r\nFollow these simple example steps to get a local version of the site up and running.\r\n<!-- /GETTING STARTED-->\r\n\r\n\r\n\r\n<!-- PREREQUISITES -->\r\n### Prerequisites\r\n\r\nTo run these commands, you must have [NPM installed](https://www.npmjs.com/). If you already have NPM installed, make sure you are running the latest version:\r\n\r\n```shell\r\nnpm install npm@latest -g\r\n```\r\n<!-- /PREREQUISITES -->\r\n\r\n\r\n\r\n<!-- INSTALLATION -->\r\n### Installation\r\n\r\nFollow these steps to run a copy of this site on your local computer. \r\n\r\n1. Clone this repo:\r\n\r\n    ```shell\r\n    git clone https://github.com/filecoin-project/filecoin-docs\r\n    ```\r\n\r\n1. Move into the new folder and download the dependencies:\r\n\r\n    ```shell\r\n    cd filecoin-docs\r\n    npm install\r\n    ```\r\n\r\n1. Build and serve the project locally: \r\n\r\n    ```shell\r\n    npm run start\r\n    ```\r\n    \r\n1. Visit [localhost:1313](http://localhost:1313) to view the site.\r\n1. Press `CTRL` + `c` in the terminal to stop the local server.\r\n\r\nIf you want to just build the site but _not_ serve it locally, run:\r\n\r\n```shell\r\nnpm run build\r\n```\r\n\r\nA static site will be built and stored in the `/public` directory.\r\n<!-- /INSTALLATION -->\r\n\r\n\r\n\r\n<!-- ABOUT THE PROJECT -->\r\n## About the project\r\n\r\n<picture align=center>\r\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://bafybeick5a6esj6qqtw35jdgrouyn3nrg5ckrmjptuvx3jjjnih7vkdzre.ipfs.w3s.link/filecoin-homepage-dark.png\">\r\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://bafybeib2c67ernhjnqzrdcmtzn5cvi45qrftz6qlo37wr5cnnhvrs6ocg4.ipfs.w3s.link/filecoin-homepage-light.png\">\r\n    <img alt=\"The Filecoin project logo.\" src=\"https://bafybeib2c67ernhjnqzrdcmtzn5cvi45qrftz6qlo37wr5cnnhvrs6ocg4.ipfs.w3s.link/filecoin-homepage-light.png\">\r\n</picture>\r\n\r\nThis repository manages the documentation for the Filecoin project. This repo also contains the build scripts and tools to create the Filecoin docs website and the API documentation. If you want to learn about Filecoin, how it works, or how to build on it, then you're in the right place.\r\n\r\n### Files and folders\r\n\r\nThis section lists the various files and folders and defines the purpose for each of them.\r\n\r\n| Name | Purpose |\r\n| --- | --- |\r\n| `.git`, `.github` | Manage the git configurations and contain information for GitHub constant integrations. |\r\n| `README.md` | This file. Acts as an introduction to this repo and how to spin up a local copy of the `docs.filecoin.io` site. |\r\n| `archetypes/` | Used by Hugo to programmatically create new pages. |\r\n| `assets/` | Assets like JavaScript and fonts used by Hugo to create the static site. These assets are not explorable in a built site. You must reference them in code before building the site. |\r\n| `babel.config.js` | A configuration file used for the Babel JS compiler. |\r\n| `config/` | Contains the configuration files for Hugo. You can manage things like the top-bar menu and site title within this directory. |\r\n| `content/` | This is where all the `.md` files live that control the content of this site. Most contributions happen in this directory. |\r\n| `data/` | You can supply extra variables for Hugo to use when building pages in this directory. These variables act just like front-matter variables. See [Data Templates](https://gohugo.io/templates/data-templates/) in the Hugo docs for more info. |\r\n| `functions/` | Functions callable from any template, partial, or shortcode within Hugo. |\r\n| `i18n/` | Contains files specific to managing different languages. |\r\n| `layouts/` | This is where web developers will likely spend most of their time. This folder contains the shortcodes and partials that Hugo uses to scaffold and build the site. |\r\n| `node_modules/` | Where NPM throws its packages. If you see this in GitHub, something's gone wrong. It should only exist on your computer after you run `npm install`. |\r\n| `package-lock.json` | One of the NPM configuration files. Specify which version of packages to download. |\r\n| `package.json` | Another one of the NPM configuration files. Specifies which packages to download but doesn't specify which _version_ of the package to grab.\r\n| `resources/` | A cache where Hugo throws generated files like CSS and JSON after `npm run build` has been called. Unless `npm run clean` is called, Hugo will re-use these files when calling `npm run build`. |\r\n| `static/` | Images, CSS, fonts, and other misc files available at `docs.filecoin.io/` when the site is built. For example, `docs.filecoin.io/site.webmanifest`.\r\n| `theme.toml` | A Hugo configuration file that specifies which theme to use. This file should not change that often. |\r\n<!-- /ABOUT THE PROJECT -->\r\n\r\n\r\n\r\n<!-- CONTRIBUTING -->\r\n## Contributing\r\n\r\nWant to help out? Pull requests (PRs) are always welcome! If you want to help out but aren't sure where to start, check out the [issues board](https://github.com/filecoin-project/filecoin-docs/issues).\r\n\r\n### Video guides for site management\r\n\r\n\r\nHere's a collection of guides you can use to help manage and contribute to this site:\r\n\r\n- [Managing the top-bar navigation](https://bafybeidn4wxz44rssgdlu3p2dzh4tbyevuqd27xv7avioyf2m65jzlhnj4.ipfs.w3s.link/DaaS%20-%20Managing%20the%20topbar%20navigation%20-%20HD%201080p.mov)\r\n- [Move a page and add a redirect](https://bafybeibuwipv4rk2tzcqvouu2xlnebh4d7ol47mvmegtispbvlcruuwmhi.ipfs.w3s.link/Move%20and%20page%20and%20add%20a%20redirect.mp4)\r\n\r\n### Creating sidebar labels and content pages\r\n\r\nTo create sidebar labels, use the `npm create` command:\r\n\r\n```shell\r\nnpm run create -- --kind sidebar storage-provider/hardware \r\n```\r\n\r\nThe above command will create the folder structure and a `_index.md` file containing the front-matter for the label.\r\n\r\n### Creating content pages\r\n\r\nTo create content pages, use the `npm create` command:\r\n\r\n```shell\r\nnpm run create -- --kind page storage-provider/hardware/architectures\r\n```\r\n\r\nThe above command will create a folder and an `index.md` file containing the front-matter for that page, that can then be edited.\r\n\r\nIf you make a mistake and need to remove a page, or section, just delete the folder.\r\n\r\nTo move content from one place to another, create the new pages using `npm create`, copy the text across to the newly created pages and delete the originals.\r\n\r\n\r\n\r\n### Front-matter variables \r\n\r\nThe front-matter is that small section of metadata you can find at the top of each `.md` file within the [`/content` folder](https://github.com/filecoin-project/filecoin-docs/tree/main/content/en). Each variable has a specific purpose, and while not all are necessary, it's useful to know what they do and why they exist. \r\n\r\n```YAML\r\n---\r\ntitle: \"Get started\"\r\ndescription: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to maintaining the Filecoin blockchain, obtaining storage services, and receiving rewards in the process. This section walks you through how to get started, build a node, and create a simple application.\"\r\nlead: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to maintaining the Filecoin blockchain, obtaining storage services, and receiving rewards in the process. This section walks your through how to get started, build a node, and create a simple application.\"\r\nmenu:\r\n    getstarted:\r\n        parent: \"getstarted-overview\"\r\naliases:\r\n    - /get-started\r\n    - /how-to/install-filecoin\r\n---\r\n```\r\n\r\nIt's also good to note that we use the YAML as our front-matter format. We could use [JSON or TOML](https://gohugo.io/content-management/front-matter#front-matter-formats) if we really wanted, but we found YAML the easiest to read. Plus, _yammal_ is fun to say.\r\n\r\nThis list has been created in order of commonality; variables you will come across most often are closer to the top of this list.\r\n\r\n#### Title\r\n\r\nThe `title` variable defines what the `<h1>` tag on this page will say, along with the contents of `<title>` in this page's `<head>`. This variable also defines what is shown as the sidebar item; however, this can be overwritten in the `menus` config file.\r\n\r\n```YAML\r\n---\r\ntitle: \"Get started\"\r\n---\r\n```\r\n\r\n![](./static/images/front-matter-variables-title.png)\r\n\r\n#### Description\r\n\r\nThe `description` variable defines what is in the [meta `<description>`](https://moz.com/learn/seo/meta-description) tag within the `<head>` tag of this page's HTML.  This description often shows up in search engine results, and social network embeds. This description is meant to give the reader an idea of the content on this page and how it relates to their search query.\r\n\r\n```YAML\r\n---\r\ndescription: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to [...]\"\r\n---\r\n```\r\n\r\n![](./static/images/front-matter-variables-description.png)\r\n\r\n#### Lead\r\n\r\nThe `lead` variable defines the content of the first paragraph on a page. This is usually an introduction, informing the reader what this page is referring to, what they're about to learn, and any prerequisites for understanding the content on this page. Often, the content of this variable is the same as the `description` variable.\r\n\r\n```YAML\r\n---\r\nlead: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to [...]\"\r\n---\r\n```\r\n\r\n![](./static/images/front-matter-variables-lead.png)\r\n\r\n#### Weight\r\n\r\nThe `weight` variable defines where this page or menu item should be in a menu. The lower the number, the closer to the start of the menu this page will be. If set, `weight` should be non-zero, as `0` is interpreted as an unset weight. There is no upper limit for a weight value.\r\n\r\nIn the top-bar menu, a lower number will cause the menu item to be further to the left in a regular view or further to the top in a mobile view.\r\n\r\nThis example is from the `/config/_default/menus/menus.en.toml` file:\r\n\r\n```\r\n[[main]]\r\n  name = \"About Filecoin\"\r\n  url = \"/about-filecoin/what-is-filecoin\"\r\n  weight = 10\r\n  \r\n[[main]]\r\n  name = \"Networks\"\r\n  url = \"/networks/overview\"\r\n  weight = 20\r\n\r\n[[main]]\r\n  name = \"Get started\"\r\n  url = \"/get-started/overview\"\r\n  weight = 30\r\n```\r\n\r\n![](./static/images/front-matter-variables-weight-1.png)\r\n\r\nIn the sidebar menu, a lower number will cause the menu item or page to be higher up.\r\n\r\n![](./static/images/front-matter-variables-weight-2.png)\r\n\r\nThe weight of a page also defines the _next_ and _previous_ buttons at the bottom of the page. The _previous_ page will be the page with the closest weight _below_ the current page's weight. The _next_ page will be the page with the closest weight _above_ the current page's weight.\r\n\r\n![](./static/images/front-matter-variables-weight-3.png)\r\n\r\n#### Menu\r\n\r\nThe `menu` variable defines which sidebar menu this page is assigned to, along with which sub-menu this page falls under. This variable is made of three parts:\r\n\r\n1. The `menu` delimiter. This tells Hugo that were are about to define the menu object for this page.\r\n1. The section/top-bar menu that this page falls under.\r\n1. The sub-menu within the sidebar that this page falls under.\r\n\r\n```YAML\r\n---\r\nmenu:\r\n    store:\r\n        parent: \"store-filecoin-plus\"\r\n---\r\n```\r\n\r\n##### Sidebar menu\r\n\r\nEach section has its own sidebar menu. The name of each sidebar menu is usually a lowercase version of the name of the section. For sections that contain a space, the sidebar menu name is a lowercase version of the section without the space:\r\n\r\n| Section | Sidebar menu name |\r\n| --- | --- |\r\n| About Filecoin | `about` |\r\n| Build | `build` |\r\n| Get started | `getstarted` |\r\n| Networks | `networks` |\r\n| Reference | `reference` |\r\n| Storage provider | `storageprovider` |\r\n| Store | `store` |\r\n\r\n\r\n```YAML\r\n---\r\nmenu:\r\n    storageprovider:\r\n---\r\n```\r\n\r\n##### Sub-menu\r\n\r\nYou can think of a sub-menu as the dropdown item in the sidebar menu. Sub-menus are defined in `/config/\\_default/menus/menus.en.toml`. \r\nEach sub-menu is a _child_ of a sidebar menu. A sidebar menu can contain multiple sub-menus, but a sub-menu can only belong to one sidebar menu.\r\n\r\nSub-menus are made up of:\r\n\r\n- `name`: The visible text shown to the user.\r\n- `weight`: How high or low this sub-menu is shown within the sidebar.\r\n- `identifier`: A unique string used in the front-matter to specify this particular sub-menu.\r\n- `url`: The default page a user will go to if they click on this sub-menu link.\r\n\r\n```YAML\r\n[[about]]\r\n  name = \"Basics\"\r\n  weight = 10\r\n  identifier = \"about-filecoin-basics\"\r\n  url = \"/about-filecoin/what-is-filecoin\"\r\n\r\n...\r\n\r\n[[networks]]\r\n  name = \"Overview\"\r\n  weight = 10\r\n  identifier = \"networks-overview\"\r\n  url = \"/networks/\"\r\n\r\n...\r\n\r\n[[getstarted]]\r\n  name = \"Overview\"\r\n  weight = 1 \r\n  identifier = \"getstarted-overview\"\r\n  url = \"/get-started/overview/\"\r\n```\r\n\r\nTo assign a page to a sub-menu, you must supply both the menu object name and the `identifier` value into the front-matter:\r\n\r\n```YAML\r\nmenu:\r\n    getstarted:\r\n        parent: \"getstarted-overview\"\r\n```\r\n\r\nThe identifier of each sub-menu is usually the menu object name and the title of the sub-menu, all in lowercase with dashes `-`:\r\n\r\n![](/.static/images/front-matter-variables-sub-menus.png)\r\n\r\n#### Aliases\r\n\r\nThe `aliases` variable defines URLs will redirect to this page. Each page can have multiple `aliases`, but each alias can only appear once throughout all the `.md` files within the `/content` folder.\r\n\r\nFor example, the `/get-started/overview` page can list `/get-started` as one of its aliases. However, no other page can list `/get-started` as an alias. If you attempt to assign another page the `/get-started` alias, Hugo will throw an error when you or Fleek try to build the website.\r\n\r\nAliases only work for internal links. You cannot assign a redirect to an external website using an alias.\r\n\r\n```YAML\r\n---\r\naliases:\r\n    - /get-started\r\n    - /how-to/install-filecoin\r\n---\r\n```\r\n\r\n#### Draft\r\n\r\nThe `draft` variable, when set to `true`, will hide the page from all site navigation. The page will still be accessible by visiting its URL. If this variable is not set, Hugo will assume that it is set to `false`.\r\n\r\n```YAML\r\ndraft: true\r\n```\r\n\r\nThis feature is generally used when we need to share content that isn't fully complete, but some users could benefit from its information at this exact moment.\r\n\r\n### Features\r\n\r\nThis project contains some handy features you can include within your project.\r\n\r\n#### Archived content\r\n\r\nOld pages can be archived and hidden from the sidebar view. However, the can still be accessed for historical purposes. \r\n\r\n![](/.static/images/archived-page.png)\r\n\r\nTo archive a page:\r\n\r\n1. Move the page and any associated images into the `/content/en/archive` directory.\r\n1. Add an alias redirect using the original location of this file:\r\n\r\n    ```markdown\r\n    ---\r\n    ...\r\n    aliases:\r\n        - \"/build/tools/filecoin-pinning-services/\"\r\n    ---\r\n    ```\r\n\r\n1. Add the following shortcode to the top of the page, just below the front-matter\r\n\r\n    ```markdown\r\n    ---\r\n\r\n    {{< archived-content >}}\r\n\r\n    ...\r\n    ```\r\n\r\nTake a look at the `/content/en/archive` directory for examples.\r\n\r\n<!-- #### Code tabs -->\r\n\r\n\r\n\r\n#### Tooltips\r\n\r\nTo make understanding terms in the docs a bit easier, users can hover over certain terms to get a short definition. These descriptions are located within a `dict` variable at the top of the `layouts/shortcodes/tooltip.html` shortcode:\r\n\r\n```go\r\n<!-- Create array/map of all possible tooltips. -->\r\n{{ $tooltips := dict\r\n    \"dApps\" \"Decentralized applications that don't rely on centralized infrastructure.\"\r\n    \"IPFS\" \"The InterPlanetary File System (IPFS) is a peer-to-peer protocol for sharing and storing files on the internet, designed to be decentralized and distributed.\"\r\n    \"Lotus\" \"The reference node implementation for the filecoin network.\"\r\n    \"Lily\" \"Software designed to simplify the recording of blockchain data.\"\r\n    \"web3\" \"A new iteration of the World Wide Web which incorporates concepts such as decentralization, blockchain technologies, and token-based economics.\"\r\n}}\r\n\r\n...\r\n```\r\n\r\nWithin your markdown you can use one of these tooltips with the following syntax:\r\n\r\n```markdown\r\n[...] storage on {{< tooltip \"IPFS\" >}} with blockchain-powered [...]\r\n```\r\n\r\nThe tooltip should show up once the site has built:\r\n\r\n![](static/images/tooltip-example.png)\r\n\r\n<!-- /CONTRIBUTING -->\r\n\r\n\r\n\r\n<!-- ISSUES -->\r\n## Issues \r\n\r\nFound a problem with the Filecoin docs site? [Please raise an issue](https://github.com/filecoin-project/filecoin-docs/issues/new). Be as specific and descriptive as possible; screenshots help!\r\n<!-- /ISSUES -->\r\n\r\n\r\n\r\n<!-- LICENSE -->\r\n## License\r\n\r\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the [Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\r\n<!-- /LICENSE -->\r\n\r\n\r\n<!-- TODO\r\n## Contact\r\n\r\nProject Link: [https://github.com/filecoin-project/filecoin-docs](https://github.com/filecoin-project/filecoin-docs)\r\n-->\r\n\r\n\r\n\r\n<!-- ACKNOWLEDGMENTS -->\r\n## Acknowledgments\r\n\r\n- [Fleek](https://fleek.co) web hosting\r\n- [Hugo](https://gohugo.io) static site generator \r\n- [Doks](https://getdoks.org) starter theme \r\n<!-- /ACKNOWLEDGMENTS -->\r\n\r\n\r\n\r\n<!-- MARKDOWN LINKS & IMAGES -->\r\n[contributors-shield]: https://img.shields.io/github/contributors/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[contributors-url]: https://github.com/filecoin-project/filecoin-docs/graphs/contributors\r\n[forks-shield]: https://img.shields.io/github/forks/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[forks-url]: https://github.com/filecoin-project/filecoin-docs/network/members\r\n[stars-shield]: https://img.shields.io/github/stars/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[stars-url]: https://github.com/filecoin-project/filecoin-docs/stargazers\r\n[issues-shield]: https://img.shields.io/github/issues/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[issues-url]: https://github.com/filecoin-project/filecoin-docs/issues\r\n[license-shield]: https://img.shields.io/badge/license-MIT-blueviolet?style=for-the-badge\r\n[license-url]: https://github.com/filecoin-project/filecoin-docs/blob/master/LICENSE.txt\r\n[product-screenshot]: ./static/images/filecoin-docs-homepage.png\r\n[website-status]: https://img.shields.io/website.svg?down_color=red&style=for-the-badge&url=https%3A%2F%2Flotus.filecoin.io\r\n[website-status-url]: https://docs.filecoin.io/\r\n<!-- /MARKDOWN LINKS & IMAGES -->\r\n\r\n<!-- markdownlint-disable-file -->\r\n", "release_dates": []}, {"name": "filecoin-explorer", "description": "Filecoin block explorer", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin Explorer (filecoin-explorer)\n\n[![CircleCI](https://circleci.com/gh/filecoin-project/filecoin-explorer.svg?style=svg&circle-token=3b2c3a7a34d3e6927d9f49d518e9228478c72911)](https://circleci.com/gh/filecoin-project/filecoin-explorer)\n\n> Filecoin block explorer\n\nAn open source Filecoin block explorer written in JavaScript.\n\n## Table of Contents\n\n- [Development](#development)\n  - [Install Node](#install-node)\n  - [Clone](#clone)\n  - [Install Dependencies](#install-dependencies)\n  - [Launch the Development Server](#launch-the-development-server)\n  - [Linting](#linting)\n- [Usage](#usage)\n  - [Start a Filecoin Node](#start-a-filecoin-node)\n  - [Launch the JavaScript Client](#launch-the-javascript-client)\n- [Contribute](#contribute)\n- [License](#license)\n\n## Development\n\nCheck the docs for [`create-react-app`](https://github.com/facebook/create-react-app/blob/master/packages/react-scripts/template/README.md)\n\n### Install Node\n\nThe build process for filecoin-explorer requires at least Node version 8.0.0, which you can download [here][1].\n\n### Clone\n\n```sh\n> git clone git@github.com:filecoin-project/filecoin-explorer.git\n```\n\n### Install Dependencies\n\nfilecoin-explorer's dependencies are managed by Yarn, which you can download [here][2]. To install filecoin-explorer's\nbuild and development dependencies, run:\n\n```sh\n> cd filecoin-explorer\n> yarn install\n```\n\n### Launch the Development Server\n\nDuring development, the filecoin-explorer is served from a locally running [webpack-dev-server][6]. The development\nserver is configured to automatically reload source files as they are changed. To launch the server, run:\n\n```sh\n> yarn start\n```\n\n#### Important: Access-Control-Allow-Origin Headers\n\nBy default, HTTP responses from the go-filecoin node will have their [`Access-Control-Allow-Origin`][5] header set to\n`http://localhost:8080`. If want to serve the filecoin-explorer from a different host or port, you'll need to\nreconfigure the go-filecoin daemon accordingly.\n\n### Linting\n\nThis project uses [StandardJS][7] for linting and code-formatting. To use StandardJS, run:\n\n```sh\n> yarn lint\n```\n\nIf you want starndard to fix your issues for you, run:\n\n```sh\n> yarn lint-fix\n```\n\n## Usage\n\n### Start a Filecoin Node\n\nThe Filecoin Explorer JavaScript application communicates via HTTP requests with a locally-running Filecoin node. For\ninstructions on building a Filecoin node, review the [go-filecoin README][4]. Then, run:\n\n```sh\n> ./go-filecoin daemon\n```\n\n### Launch the JavaScript Client\n\nWith the development server running (see _Launch the Development Server_, above), open your web browser and navigate to\n[http://localhost:8080](http://localhost:8080). From here, you can explore the Filecoin blockchain.\n\n## Contribute\n\nSee [the contribute file](CONTRIBUTING.md).\n\nIf editing the readme, please conform to the [standard-readme][3] specification.\n\n[1]: https://nodejs.org/en/download/releases/\n[2]: https://yarnpkg.com/en/docs/install\n[3]: https://github.com/RichardLitt/standard-readme\n[4]: https://github.com/filecoin-project/go-filecoin\n[5]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Origin\n[6]: https://github.com/webpack/webpack-dev-server\n[7]: https://github.com/standard/standard\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/filecoin-explorer/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/filecoin-explorer/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "filecoin-ffi", "description": "C and CGO bindings for Filecoin's Rust libraries", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "[![Build Status][circleci-image]][circleci-link]\n\n# Filecoin FFI\n\n> C and CGO bindings for Filecoin's Rust libraries, i.e: [proofs](https://github.com/filecoin-project/rust-fil-proofs) and [ref-fvm](https://github.com/filecoin-project/ref-fvm). This repository is built to enable the reference implementation of Filecoin, [Lotus](https://github.com/filecoin-project/lotus), to consume the Rust libraries that are needed.\n\n## Building\n\nTo build and install libfilcrypto, its header file and pkg-config manifest, run:\n\n```shell\nmake\n```\n\nTo optionally authenticate with GitHub for assets download (to increase API limits)\nset `GITHUB_TOKEN` to personal access token.\n\nIf no precompiled static library is available for your operating system, the\nbuild tooling will attempt to compile a static library from local Rust sources.\n\n### Installation notes\n\nBy default, building this will download a pre-built binary of the ffi.  The advantages for downloading it are faster build times, and not requiring a rust toolchain and build environment.\n\nThe disadvantage to downloading the pre-built binary is that it will not be optimized for your specific hardware.  This means that if raw performance is of utmost importance to you, it's highly recommended that you build from source.\n\n### Building from Source\n\nTo opt out of downloading precompiled assets, set `FFI_BUILD_FROM_SOURCE=1`:\n\nTo allow portable building of the `blst` dependency, set `FFI_USE_BLST_PORTABLE=1`:\n\n```shell\nrm .install-filcrypto \\\n    ; make clean \\\n    ; FFI_BUILD_FROM_SOURCE=1 FFI_USE_BLST_PORTABLE=1 make\n```\n\nBy default, a 'gpu' option is used in the proofs library.  This feature is also used in FFI unless explicitly disabled.  To disable building with the 'gpu' dependency, set `FFI_USE_GPU=0`:\n\n```shell\nrm .install-filcrypto \\\n    ; make clean \\\n    ; FFI_BUILD_FROM_SOURCE=1 FFI_USE_GPU=0 make\n```\n\n#### GPU support\n\nCUDA for GPU support is now enabled by default in the proofs library.  This feature can optionally be replaced by OpenCL by using `FFI_USE_OPENCL=1` set in the environment when building from source.  Alternatively, if the CUDA toolkit (such as `nvcc`) cannot be located in the environment, OpenCL support is used instead.  To disable GPU support entirely, set `FFI_USE_GPU=0` in the environment when building from source.\n\nThere is experimental support for faster C2 named \"SupraSeal\". To enable it, set `FFI_USE_CUDA_SUPRASEAL=1`. It's specific to CUDA and won't work with OpenCL.\n\n```shell\nrm .install-filcrypto \\\n    ; make clean \\\n    ; FFI_BUILD_FROM_SOURCE=1 make\n```\n\nBy default, a 'multicore-sdr' option is used in the proofs library.  This feature is also used in FFI unless explicitly disabled.  To disable building with the 'multicore-sdr' dependency, set `FFI_USE_MULTICORE_SDR=0`:\n\n```shell\nrm .install-filcrypto \\\n    ; make clean \\\n    ; FFI_BUILD_FROM_SOURCE=1 FFI_USE_MULTICORE_SDR=0 make\n```\n\n## Updating rust-fil-proofs (via rust-filecoin-proofs-api)\n\nIf rust-fil-proofs has changed from commit X to Y and you wish to get Y into\nthe filecoin-ffi project, you need to do a few things:\n\n1. Update the rust-filecoin-proofs-api [Cargo.toml][1] file to point to Y\n2. Run `cd rust && cargo update -p \"filecoin-proofs-api\"` from the root of the filecoin-ffi project\n3. After the previous step alters your Cargo.lock file, commit and push\n\n## go get\n\n`go get` needs some additional steps in order to work as expected.\n\nGet the source, add this repo as a submodule to your repo, build it and point to it:\n\n```shell\n$ go get github.com/filecoin-project/filecoin-ffi\n$ git submodule add https://github.com/filecoin-project/filecoin-ffi.git extern/filecoin-ffi\n$ make -C extern/filecoin-ffi\n$ go mod edit -replace=github.com/filecoin-project/filecoin-ffi=./extern/filecoin-ffi\n```\n\n## Updating the Changelog\n\nThe `mkreleaselog` script (in the project root) can be used to generate a good\nportion of the filecoin-ffi changelog. For historical reasons, the script must\nbe run from the root of a filecoin-ffi checkout which is in your `$GOPATH`.\n\nRun it like so:\n\n```shell\n./mkreleaselog v0.25.0 v0.26.0 > /tmp/v0.26.0.notes.txt\n```\n\n## Contribution \n\n### Maintainers\n\nThe core maintainers of this repository are:\n- @nemo & @vmx, from the fil-crypto team\n- @lotus-maintainers\n- @stebalien, from the FVM team \n\nMaintainers are not only the contributors of this repository, but also exercise a range of editorial responsibilities to keep the repository organized for the OSS contributors, that includes triage the issues, review and merge/close PRs, publish releases and so on.\n\n### Development Guidelines (WIP)\n\n#### CI Builds\n\nTo start a CI job to build binaries off of a commit push a tag starting with the character `v`, i.e. `v1.22.0-rc2`.\n\n#### Branches\n\n`master` is considered as the development branch of this repository. Changes being introduced to master must be tested (programmable and/or manual). The head of the master will be tagged and released upon the merge of each PR automatically.\n\nWe will cooperates with the [lotus' releases and it's testing flows](https://github.com/filecoin-project/lotus/blob/0c91b0dc1012c3e54b305a76bb25fb68390adf9d/LOTUS_RELEASE_FLOW.md?plain=1#L50) to confirm whether a tagged release is production ready:\n\n*Non-consensus breaking changes*\n- All PRs introduce non-consensus breaking changes can be merged to master as long they have maintainers' approvals.\n- Roughly on a monthly basis, lotus will integrate ffi's head in `master` branch, for it's new feature release, and carry it through the testing flows.\n  - `release/lotus-vX` will be created to determine the commit that lotus integrates in the corresponding release.\n- If any bug is found during the testing, the fix should land in master then get backported to `release/lotus-vX`. The updated commit should be integrated into lotus and getting tested. Repeat the steps until it can be considered as stable.\n\n#Consensus breaking changes*\n- Consensus breaking changes should be developed in it's own branch, (branch name is suggested to be: feature branches `feat/` or bug fix branches `bug/`). \n- Consensus breaking changes that are scoped into the next immediate network upgrade shall land in `next` branch first. The maintainers are responsible to coordinate on when to land `next` to `master` according to lotus mandatory(network upgrade) release schedules.\n- A new dev branch should be created and contributors are responsible to rebase the branch onto `master`/`next` as needed.\n\n\n\n## License\n\nMIT or Apache 2.0\n\n[1]: https://github.com/filecoin-project/rust-filecoin-proofs-api/commit/61fde0e581cc38abc4e13dbe96145c9ad2f1f0f5\n\n[circleci-image]: https://circleci.com/gh/filecoin-project/filecoin-ffi.svg?branch=master&style=shield\n[circleci-link]: https://app.circleci.com/pipelines/github/filecoin-project/filecoin-ffi?branch=master\n", "release_dates": ["2024-01-31T18:55:28Z", "2024-01-31T19:09:09Z", "2024-01-30T16:02:29Z", "2024-01-30T16:16:24Z", "2024-01-09T12:29:04Z", "2023-11-20T16:54:53Z", "2023-10-04T19:39:53Z", "2023-10-16T14:57:50Z", "2023-10-03T16:06:53Z", "2023-10-03T16:19:37Z", "2023-09-23T16:33:13Z", "2023-09-23T15:53:49Z", "2023-09-19T09:03:27Z", "2023-09-19T09:15:07Z", "2023-08-28T17:45:45Z", "2023-08-28T18:00:54Z", "2023-08-23T15:38:25Z", "2023-08-22T17:52:22Z", "2023-08-21T19:55:36Z", "2023-08-03T08:32:15Z", "2023-08-03T08:44:46Z", "2023-07-31T10:07:18Z", "2023-07-13T07:37:02Z", "2023-07-13T13:23:09Z", "2023-07-13T13:35:39Z", "2023-07-13T07:33:55Z", "2023-06-30T18:23:54Z", "2023-07-13T07:48:46Z", "2023-05-01T14:12:20Z", "2023-04-23T14:01:43Z"]}, {"name": "filecoin-fvm-localnet", "description": "A complete filecoin lotus and boost docker image to spin up a localnet for smart contract development", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "![FVM Localnet build status](https://github.com/filecoin-project/filecoin-fvm-localnet/actions/workflows/filecoin-fvm-localnet-combined.yml/badge.svg)\n\n# Filecoin FVM localnet\n\nFilecoin FVM Localnet is a complete Filecoin [Lotus](https://lotus.filecoin.io/) and [Boost](https://boost.filecoin.io/) Docker image that allows you to spin up a localnet for FVM smart contract development. You can also run two miners for testing things like replication between SPs.\n\n\n## System requirements\n\nARM64 (e.g. Macbook M1/M2s) or AMD64 (e.g. x86 Linux / Windows / MacOS).\n\n## Prerequisites\n\nEnsure you have [Docker installed](https://docs.docker.com/get-docker/). \n\n## Installation\n\n**Please note**, that running the commands below will result in docker downloading a 3GB image on first run (or 7GB if you choose to run an 8M network). So if you are going to be running this at somewhere with poor or metered internet connectivity, please be aware.\n\n1. Clone this repository:\n\n    ```sh\n    git clone https://github.com/filecoin-project/filecoin-fvm-localnet.git\n    ```\n\n1. Navigate to the repository:\n\n    ```sh\n    cd filecoin-fvm-localnet\n    ```\n    \n1. OPTIONAL: Edit the file `.env` if you wish to optionally run an 8M sector network, otherwise the default 2k sectors will be used\n\n1. To run a single miner instance (default): run Docker `compose up`:\n    ```sh\n    cp .env.example .env\n    ```\n\n    ```sh\n    docker compose up\n    ```\n\n1. To run two miners and two Boost instances (replication): run:\n\n    ```sh\n    docker compose --profile replication up\n    ```\n\n1. To stop the network type `ctrl-c`.\n\nOnce the localnet is started, you can navigate the Boost UI at: `http://localhost:8080`. If you run in replication mode there is a second Boost instance at: `http://localhost:8081`.\n\n## Metamask and Funding a Wallet\n\n### Setting up Metamask\n\nYou can configure metamask to connect to this local network by adding a new custom network, with the following steps:\n\n1. Click the network at the top of Metamask\n1. Click `Add a network manually` at the bottom\n1. Enter the network information below\n\n    ```\n    Network name: Filecoin localnet\n    New RPC URL: http://127.0.0.1:1234/rpc/v1\n    Chain ID: 31415926\n    Currency symbol: tFIL\n    ```\n\n### Funding a wallet\n\nIn order to transact with the network, you will need some funds (tFIL) in your wallet, you can fund a wallet using the `lotus` command:\n\n1. First find out the `t4` address of your wallet from its `0x` address shown in Metamask:\n\n    ```\n    docker compose exec lotus lotus evm stat 0x403D6E3Aff483A3c727Df731c6720A49E36De3eb\n    ```\n    ```\n    Filecoin address:  t410fia6w4ox7ja5dy4t564y4m4qkjhrw3y7ldcn3u3q\n    Eth address:  0x403d6e3aff483a3c727df731c6720a49e36de3eb\n    Actor lookup failed for faddr t410fia6w4ox7ja5dy4t564y4m4qkjhrw3y7ldcn3u3q with error: resolution lookup failed (t410fia6w4ox7ja5dy4t564y4m4qkjhrw3y7ldcn3u3q): resolve address t410fia6w4ox7ja5dy4t564y4m4qkjhrw3y7ldcn3u3q: actor not found\n    ```\n\n1. Then send some funds to that wallet using the t4 address above:\n    ```\n    docker compose exec lotus lotus send t410fia6w4ox7ja5dy4t564y4m4qkjhrw3y7ldcn3u3q 1000\n    ```\n    ```\n    bafy2bzacecdtzoq6llosskugezsmtlefxjbjww3pddj42iqgqa3vcalgjm6rs\n    ```\n   The funds will show up in your metamask wallet in around 45 seconds.\n\n### Fill with Metamask Mnemonic\nensure the MNEMONIC .env variable contains your seed phrase\n```sh\ndocker cp ./scripts lotus:/app/\ndocker exec -it lotus bash './scripts/fillAccounts.sh'\n``` \n\n## Usage notes\n\n- This network has a sector size of 2KiB. This means that the largest storage deals you can make with the miner will be 2KiB. If you want an 8MiB network and storage deals of up to 8MiB, then uncomment the appropriate section in the `.env` file, delete the `data/` directory and restart docker compose.\n\n- The localnet will take a while to start up -- around 5 - 10 minutes depending on how quickly it can download the docker image and initial proof data.\n\n- If you have not started the network for a while, then it may take a while to re-sync with itself. If you wish to avoid the wait and wish to reset the network (losing any local state) then you can delete the `data` directory.\n\n- This network has a block time of 15 seconds (half the time of Filecoin mainnet).\n\n- Running in 'replication' mode will start up a second Lotus miner instance and a second boost instance connected to it. This allows you to test replication between miners, and smart contracts that need two miners to work.\n\n", "release_dates": ["2023-08-27T08:37:03Z"]}, {"name": "filecoin-http-api", "description": "Specification for the Filecoin node HTTP API", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# filecoin-http-api (WIP)\nOpenAPI specification for the Filecoin HTTP REST API. \n\nThe HTML version of the documentation can be [viewed here](https://filecoin-project.github.io/filecoin-http-api/).\n\nThis is the specification for the HTTP REST API (to be) implemented by Filecoin nodes. Some details of its design and rationale can be found in this [Design Document](https://docs.google.com/document/d/1ANnTHOU-8612ayvvS7Ru4B1L4voojLE0R0TQ8zF1x5s/edit#heading=h.8v8p3fl8e3gj). \n\n## Setup \nTo facilitate development and review we're using [speccy](https://github.com/wework/speccy) as a linter and [redoc](https://github.com/Redocly/redoc) to generate HTML documentation. You can install them using NPM or Yarn.\n\n```sh\n$ npm install\n# or\n$ yarn install\n```\n\n## Usage\nTo view the specification in HTML form you can invoke redoc via:\n```sh\n$ npm run serve\n```\nAnd view the resulting documentation at http://localhost:5000.\n\n## License\nDual MIT and Apache 2\n", "release_dates": []}, {"name": "filecoin-network-sim", "description": "Filecoin Network Visualization Backend", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# filecoin-network-sim\n\nServer for https://github.com/filecoin-project/filecoin-network-viz\n\n## Setup\n\n### go-filecoin\n\ngo-filecoin is required\n\n```sh\ncd $GOPATH/src/github.com/filecoin-project/\ngit clone git@github.com:filecoin-project/go-filecoin.git\ncd $GOPATH/src/github.com/filecoin-project/go-filecoin\ngit checkout feat/extractTestDaemon\ngo run ./build/*.go deps\ngo run ./build/*.go build\n```\n\n### filecoin-network-sim\n\n```\ncd $GOPATH/src/github.com/filecoin-project/\ngit clone git@github.com:filecoin-project/filecoin-network-sim.git\n\ncd $GOPATH/src/github.com/filecoin-project/filecoin-network-sim\nmake deps\nmake\nmake runDebug\n```\n\n## Run\n\n```\nmake run\n```\nThis will start the server, the network simulation, and open a browser window pointing at the visualization.\n\n## Warnings\n\n- This will spawn a lot of go-filecoin processes, for running daemons and for running cli commands. Many of the commands will hang forever (fail to terminate) -- this is clearly a bug that needs to be fixed (time them out). Currently, your machine may run out of process descriptors if you leave it running indefinitely (don't do that...). (TODO: fix the bug...)\n- Update wrt to the above comment, we think this is mosly fixed now, we recomend not going over 50 nodes in the simulator.\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/filecoin-network-sim/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/filecoin-network-sim/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "filecoin-network-viz", "description": "Filecoin Network Visualization Frontend", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# filecoin-network-viz\nViz tool for Filecoin.\n\nA demo of this tool can be seen in [this talk](https://www.youtube.com/watch?v=w944sFTjLq8). Feel free to use and modify the library. Note that it is not actively maintained. [filecoin-network-sim](https://github.com/filecoin-project/filecoin-network-sim) is the required backend for this visualization tool.\n\nNetwork visualizer (this repo: filecoin-network-viz):\n![Network Visualizer](/img/network-viz.png)\n\n![Network Visualizer CLI](/img/network-viz-cli.png)\n\n# License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/filecoin-network-viz/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/filecoin-network-viz/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "filecoin-phase2", "description": "Phase2 for Filecoin circuits", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Filecoin Phase2\n\nLibrary and binary to run phase2 of the Groth16 trusted-setups for Filecoin's circuits.\n\n## Build Library\n\n```\n$ cargo build\n```\n\n## Build `phase2` Binary\n\n```\n$ cargo build --release --bins && cp target/release/filecoin-phase2 phase2\n$ ./phase2 help\n```\n\n## Run Tests\n\n```\n$ cargo test\n```\n\n## License\n\nMIT or Apache 2.0\n", "release_dates": []}, {"name": "filecoin-plus-application-json-restructure", "description": "Sample repo tracking how the Fil+ DataCap application structure will change if we move away from Issues to describing applications in JSON and leveraging PRs.", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": []}, {"name": "filecoin-plus-client-onboarding", "description": null, "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<p align=\"left\">\n  <img src=\"docs/_media/Filecoin-plus-logo-color-dark.png\" alt=\"Filecoin Plus Logo\" width=\"320\" />\n</p>\n\n## Introduction\nFilecoin Plus aims to maximize the amount of useful storage on Filecoin by adding a layer of social trust to the Network. [Clients](#client) can apply to [Notaries](#notary) to receive [DataCap](#datacap), which can be used to incentivize Storage Providers (SPs) to take storage deals. SPs who take deals that are compensated with DataCap receive a 10x to their quality adjusted power - increasing their probability of winning block rewards. Filecoin Plus puts power in the hands of Clients and incentivizes SPs to support real use case on the Network.\n\n## Using DataCap\n### How to Get DataCap\nClients can get DataCap by making a request to a Notary - you can find a list of active Notaries on the [Filecoin Plus Registry](https://plus.fil.org/verifiers). Notaries may specialize in the types of requests they\u2019ll choose to support - some may hand out small amounts of DataCap freely, while others may support larger requests (but may also require more due diligence). _**If you're looking to store large data (over 500TiB) - check out the [Large Dataset Notary program](https://github.com/filecoin-project/filecoin-plus-large-datasets), which can grant between 500TiB-5PiB of DataCap.**_\n\nAt a minimum, every Notary will require an [on-chain Filecoin address](https://docs.filecoin.io/get-started/lotus/send-and-receive-fil/) to which they can send the requested DataCap. A Client can initialize their address on-chain by sending a minimal amount of Filecoin to it, e.g. as a result of purchasing some FIL from an exchange. As a Client makes deals using DataCap, the balance of DataCap on that address will be depleted. If you run out or need more DataCap allocation, please make a new request using your same address (now that [FIP-0012 is live](https://fips.fission.app/fips/fip-0012/)). \n\n### How to Spend DataCap\nOnce you have an address with DataCap, you can make deals using DataCap as a part of the payment. Because SPs receive a deal quality multiplier for taking Fil+ deals, many SPs offer special pricing and services to attract Clients who use DataCap to make deals.\n\nBy default, when you make a deal with an address that has DataCap allocated, you will spend DataCap when making the deal. \n\nIf making deals through the [API](https://github.com/filecoin-project/lotus/blob/master/documentation/en/api-methods.md#ClientStartDeal), make sure when calling `ClientStartDeal` that the `VerifiedDeal` parameter is set to `true`. \n\nIf making deals from the command line, make sure to pass the flag `--verified-deal=true` as a parameter.\n\n```\n lotus client deal --verified-deal=true\n```\n\n### Checking Remaining DataCap \nOnce you have received DataCap to an address, you can check the remaining balance either by visiting a site that enables this (e.g. [verify.glif.io](https://verify.glif.io/)) or by querying your address on a node. \n\n#### With lotus v1.10.0 ^\n\n```\nlotus filplus check-client-datacap f00000\n```\n\n#### With lotus v1.9.0 and below\n_Note: [Lotus-shed](https://github.com/filecoin-project/lotus/tree/master/cmd/lotus-shed) is a separate package you will need to build and install (`make lotus-shed` in the [Lotus](https://github.com/filecoin-project/lotus) source), although these features are slated to be merged into Lotus._\n\n```\nlotus-shed verifreg check-client f00000\n```\n\n### Finding Storage Providers to Take Fil+ Deals\nThe general recommendation for clients on the network is to build several replicas of their data on the network, ideally with different SPs / SP entities to spread risk. From a DataCap distribution perspective, guidance is that clients should engage at least 4 SPs and no single SP ID should receive >30% of a client's allocated DataCap. This aligns SP growth incentives with client needs for reliably storing data on the network longer term.\n\nThere are a few difference ways in which a client can find a SP to take a Fil+ storage deal:\n- This [issue](https://github.com/filecoin-project/notary-governance/issues/8) has a list of SPs involved in the discussion below that advertise details about their services\n- Join the [#fil-plus](https://filecoinproject.slack.com/archives/C01DLAPKDGX) channel on Filecoin Slack to discuss storage options\n- Hop into the network with your node and query SPs (using `query-ask`) to check their verified deal prices\n\n### Best Practices\nAs a client who has received DataCap for making storage deals on Filecoin, this [issue](https://github.com/filecoin-project/notary-governance/issues/9) is a great starting point. A few of the key thoughts shared in the issue include: \n\n- Store multiple copies of data across different data centers, and perhaps even regions, to ensure your data is reliably stored\n- Distribute your storage deals across different miners so your data is more likely to be accessible long term\n- Ask for features (like `fast retrieval`) that would make your experience better\n- Stay in compliance with Miners\u2019 stated Terms of Service and Content Policy\n\n## Terminology\n### DataCap\nDataCap, when allocated to a Client, can be spent by the Client in storage deals with miners. These deals carry a higher deal quality multiplier, which increases the \u201cquality adjusted power\u201d of the storage miner on the network (yielding better block rewards for the miner over time). In short, miners are heavily incentivized to take deals from Clients who use DataCap to pay for their deals. \n\nDataCap is granted in batches to Notaries, who in turn, allocate it to responsible clients that spend the DataCap to fund storage deals. DataCap is consumed as it is used to make deals. \n\n### Notary\nNotaries are selected to serve as fiduciaries for the Filecoin Network, and are responsible for allocating DataCap to clients with legitimate storage use cases. The base responsibilities of notaries include: \n- Allocate DataCap to clients in order to subsidize reliable and useful storage on the network.\n- Verify that Clients receive a DataCap commensurate with the level of trust that is warranted based on information provided.\n- Ensure that in the allocation of the DataCap no party is given excessive trust in any form that might jeopardize the network.\n- Follow operational guidelines, keep record of decision flow, and respond to any requests for audits of their allocation decisions.\n\nYou can find a list of the active Notaries [here](https://plus.fil.org) who can allocate DataCap. \n\nNotaries are selected through an application process described [here](https://github.com/filecoin-project/notary-governance/tree/main/notaries#application--selection-process). If approved, [Root Key Holders](https://github.com/filecoin-project/notary-governance/tree/main/root-key-holders#overview) (executors of the decisions made by the community on-chain) grant Notary status and associated DataCap amounts. Those interested in becoming Notaries should apply to this role by filing an Issue in the [Notary Governance Repo](https://github.com/filecoin-project/notary-governance/).\n\nNotaries are given autonomy in their decision making process and encouraged to allocate DataCap based on their best judgement. However, Notaries should expect to answer any potential questions about previous allocation decisions before receiving future DataCap to distribute. \n\nAdditionally, to prevent conflicts of interest, Notaries should not allocate DataCap to clients over which they control the private keys. In the event this is an issue, the Notary should contact another Notary (in the same geography or aligned to the same use case) to handle the allocation for that specific client.\n\n_See additional information [here](https://github.com/filecoin-project/notary-governance/tree/main/notaries#overview)._\n\n### Storage Client\nClients are active participants of the network with DataCap allocation for their use cases. Clients can use their DataCap to incentivize miners to provide additional features and levels of services that meet their specific requirements. In doing so, storage related goods and services on Filecoin are made more valuable and competitive over time. Clients are vetted by Notaries to ensure the client receives DataCap commensurate with their reputation and needs, and that the Client responsibly allocates that DataCap. Obtain verification and DataCap allocation from a Notary. Deploy DataCap responsibly in accordance with the Principles. Follow operational guidelines, keep record of decision flow, and respond to any requests for audits of their allocation decisions.\n\nSpecific details on the suggested framework for responsible DataCap allocation are described in the [repository](https://github.com/filecoin-project/notary-governance). It is expected that clients who intend to receive greater amounts of DataCap may be asked to provide evidence for responsible spending of their previous allocation before receiving more.\n\n### FVM Smart Contracts\nSmart contracts can acquire DataCap just like any regular client. To do so, simply enter the f410 address of the smart contract that requires DataCap as the client address when making a request.\n\nThe process outlined above is for larger amounts of Datacap > 32 GiBs. For a smart contract's first DataCap allocation, we recommend using auto-verifier [Verify.glif.io](Verify.glif.io) to get 32 GiB of DataCap, as specified [here](https://docs.filecoin.io/store/filecoin-plus/overview/).\n\nIt's important to note that DataCap allocations are a one-time credit for a Filecoin address and cannot be transferred between smart contracts. If you need to redeploy the smart contract, you must request additional DataCap. To improve this experience, we are developing an FRC to allow DataCap to be held between redeployments. \n\n## Resources\nFIP introducing Filecoin Plus:\nhttps://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0003.md\n\nNotary Governance Repo (includes links to bi-weekly Governance Calls):\nhttps://github.com/filecoin-project/notary-governance\n", "release_dates": []}, {"name": "filecoin-plus-falcon", "description": null, "language": null, "license": null, "readme": "# filplus-tooling-backend\n\nThis is a test repo to replicate production repo that handles LDN Applications.\n\nMust of the work here is done throug github actions where we listen to different events(like ISSUE_OPEN) and execute actions.\n\nManaging LDN Applications involves allowing intializatin an application through an issue or a pull request. In the first scenario\nwe parse the new issue opened and create a pull request for it, after that all the management of that application will occur under the pull request.\nyou can open an application through a pr through the filplus-backend API or the a template we will implement in Github. Otherwise, you can follow the filecoin LDN application standards to open an application on your own.\n\n", "release_dates": []}, {"name": "filecoin-plus-large-datasets", "description": "Hub for client applications for DataCap at a large scale", "language": null, "license": null, "readme": "# Filecoin Plus for large datasets\n\nFilecoin Plus is a community program that aims to increase Filecoin's network by becoming the decentralized storage network for humanity's most important information. As the network continues to grow, we as a community need to make sure to maintain a civil online engagement. To learn more about acceptable community behavior please check the [Filecoin Community Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md).\n\nThis repo serves as the hub for client applications for DataCap at a large scale - currently defined as > 100 TiB of DataCap. If you wish to generally learn more about Filecoin Plus or apply for less than 500 TiB of DataCap, check out the following resources: \n\n- Filecoin Plus documentation: https://docs.filecoin.io/store/filecoin-plus/\n- Fil+ community governance repo: https://github.com/filecoin-project/notary-governance/\n- Fil+ client on-boarding and DataCap applications: https://github.com/filecoin-project/filecoin-plus-client-onboarding\n- To apply for DataCap: https://filplus.storage/apply\n\nThe process outlined below for clients looking to apply for a large amount of DataCap was initially proposed in [Issue #94 - Onboarding projects with large DataCap requirements](https://github.com/filecoin-project/notary-governance/issues/94). Through an initial pilot phase and learnings/feedback collected over time, we are currently on the third iteration of the Large Dataset Notary (LDN) process. See #217, #328, #509 for additional details.\n\nThe main difference between this process and applying for DataCap directly from a notary (via filplus.storage) is that this process is (1) significantly more public, (2) DataCap is allocated from a large multisig Notary address, and (3) DataCap is allocated in tranches. \n\n## Current Scope\n\nBased on conversations in various issues and governance calls, here is the current scope of the Large Dataset Notary (LDN) program. You can find relevant issues, as well as links to governance call recordings in the [Notary Governance repo](https://github.com/filecoin-project/notary-governance). Please note that this is still an evolving conversation, so the scope is subject to change. If you would like to participate in this conversation or have feedback, please let us know! You can start a discussion topic in the [Notary Governance repo](https://github.com/filecoin-project/notary-governance/discussions), in the [fil-plus](https://filecoinproject.slack.com/archives/C01DLAPKDGX) public Slack channel, or in an upcoming [Governance call](https://calendar.google.com/calendar/embed?src=c_k1gkfoom17g0j8c6bam6uf43j0%40group.calendar.google.com&ctz=America%2FLos_Angeles).\n\nClients can currently apply for a **Large Dataset Notary** which can grant them between 100 TiB and 5 PiB of total DataCap per application. \n\nIn order for a client and their dataset to be eligible: \n\n- The dataset should be public, open, and mission aligned with Filecoin and Filecoin Plus. This also means that the data should be accessible to anyone in the network, without requiring any special permissions or access requirement. If this is not the case - consider instead going via the E-Fil+ pathway to getting DataCap. You can read more about that [here](https://efilplus.super.site/)\n\n- If a client wants to onboard more than 5+PiBs, the recommendation would be to start with a few applications and earn trust from the community. Having a positive reputation and proving to the community first by onboarding a smaller amount of data will help anyone who wants to onboard massive amounts of data much faster and smoother. \n\n- Stored data should be readily retrievable on the network and this can be regularly verified (though the use of manual or automated verification that includes retrieving data from various miners over the course of the DataCap allocation timeframe). Each project should specify what portion of the data is retrievable and provide justification. From there notaries can decide during the due diligence phases if the client\u2019s application is justifiable and can agree to sign it or not.\n\n- There should be no open disputes in the Fil+ ecosystem against the client during the time that the application is open for review\n\n- With the current tooling and workflow, the recommendation would be to use a different address for every application. However, if you cannot, know that the workaround requires manual attention. We strongly do not recommend this due to delays created and mixed math for subsequent allocation issues. In the short term, we can support this. Please notify Simon Kim and add this to your LDN application if you absolutely have to go down this path and share why.\n\n- Best practice for storing large datasets includes ideally, storing it in 3 or more regions, with 4 or more storage provider operators or owners, and having at least 5 replicas of the dataset. No more than one replica should be stored with one SP ID, and if the data cannot leave a particular geographic boundary, then it is expected that replication will still happen across different locations (cities, datacenters, etc.). Each storage provider should not exceed 30% of the total datacap that the client was allocated and the storage provider should have published its public IP address. If you cannot follow these practices due to policy or any other issues, you may explain your case in the application and provide to the community what method you can do instead. These are recommendations and not strict rules that every client must follow.  \n\n- Regarding cases of abusing the program\u2019s incentive structure, notaries should not be signing their own applications. For the program to work, each stakeholder will need to play their parts in a truthful manner. \n\n- Datasets that have been stored previously, may be allowed to be copied over time on chain. This can provide value to the network if it is a new team, a new datacenter, and a new geopolitical region. However, storage providers should not be storing more than 20% of the duplicated data. While same datasets may help the network, this should not be a reason for client\u2019s to onboard the same exact dataset repeatedly, client\u2019s should  explicitly justify their reasoning on why the repeated dataset should be onboarded.\n\n- To help notaries more efficiently complete their due diligence process, clients should justify their reasoning of the amount of DataCap that you are applying for will help notaries with their due diligence process. Clients should explain how their dataset is useful for the network, and visible proof of the size of the data that is being onboarded.\n\nIf you are a client who is interested in applying for a large DataCap allocation via an LDN, please see the steps outlined below.\n\n## Applying for a large DataCap allocation\n\nApplication flow: \n\n- Client submits an application by applying on https://filplus.storage/apply or creating a GitHub issue in this repo\n- Automation and the Fil+ governance team ensures that the application has been fully filled out, and a request is sent to the RKH to set up a Notary (LDN) for this client\n- Notaries and community members carry out due diligence via comments on the issue and in conversation during a Notary Governance call\n- In parallel, RKH are informed of the client application request and approve the multisig LDN to allocate DataCap to this client in tranches\n- If the community is in agreement that the dataset is in line with the values of the Filecoin Plus program and should be approved for a DataCap allocation, 2 notaries approve the request to allocate the first tranche of DataCap\n\nWhen clients use up > 75% of the prior DataCap allocation, a request for additional DataCap in the form of the next tranche is automatically kicked off (via the'subsequent allocation bot'). Notaries have access to on-chain data required to verify that the client is operating in good faith, in accordance with the principles of the program, and in line with their allocation strategy outlined in the original application. 2 notaries need to approve the next tranche of DataCap to be allocated to the client. The same notary cannot sign off on immediately subsequent allocations of DataCap, i.e., you need at minimum 4 unique notaries to support your application on an ongoing basis to receive multiple tranches of DataCap. \n\n## Application flow labels\n\nThe following labels indicate the statues of LDN applications. The most recent version of these labels were released on April 15, 2023. More comprehensive release notes can be found in [this blog](https://medium.com/filecoin-plus/ldn-label-update-part-1-label-consolidation-ae2691c78702).\n\n- **Validated**: \n  - The validated label is added to an issue when the parent comment of an LDN application is fully completed and all questions have been answered. \n  - When the validated label is added, a member of the governance team will review the application and post the trigger message. \n  - This trigger message signifies to the SSA bot (subsequent allocation bot) to initiate the tranche allocation process, which will then post the request message.\n\n- **Ready to Sign**: \n    - If the SSA bot detects the trigger message posted by the governance team or identifies that the client is low on previously granted DataCap (<25% of DataCap balance last granted), it will post a request message. \n    - Once there is a request message, the ready to sign label should be added to the LDN application. \n    - SSA bot detects the ready to sign label and notaries should be able to view the LDN application on the Fil+ registry (filplus.fil.org) for next steps.\n\n- **Start Sign Datacap**: \n    - When the first notary, of the two notaries required, has completed their due diligence and has signed in support of the LDN application DataCap allocation tranche, the proposal message is posted. \n    - The start sign datacap label is added to the issue when this proposal message is posted and the SSA bot detects it. \n    - On the Fil+ registry, the status is updated to indicate that one notary has already supported the LDN application. The applicant now needs a second notary to sign the tranche to release DataCap.\n\n- **Granted**: \n    - When a second notary has completed due diligence and signed in support of the LDN application\u2019s DataCap tranche request, the approval message is posted.\n    - The granted label is added to the issue when this approval message is posted and the SSA bot detects it. \n    - If successful, DataCap is issued for the granted allocation. The LDN application is removed from the list notaries see on the Filecoin Plus registry, until the next tranche is requested and the process repeats.\n\n- **Total DataCap Reached**: \n    - The total datacap reached label is added when the client has reached the total amount of DataCap requested in the application.\n\n- **Error**: \n    - Consolidation of what used to be a set of many error labels that indicate tooling errors. \n    - An error message with more information about the error is posted in the issue. \n    - The following is an example of an error message where the \u201cAddress\u201d field is not specified in the \u201cApproved Comment.\u201d\n\n- **Governance Review Needed**: \n    - Information provided by the applicant has changed, requiring a manual check from members focused on the client UX on the governance team.\n\n- **EFil+**: \n    - Applications that are part of the E-Fil+ pipeline (read more at: https://efilplus.super.site/) will have this label.\n    \n## DataCap tranche size calculations\n\n- First allocation: lesser of 5% of total DataCap requested or 50% of weekly allocation rate\n- Second allocation: lesser of 10% of total DataCap requested or 100% of weekly allocation rate\n- Third allocation: lesser of 20% of total DataCap request or 200% of weekly allocation rate\n- Fourth allocation: lesser of 40% of total DataCap requested or 400% of weekly allocation rate\n- Fifth allocation onwards: lesser of 80% of total DataCap request or 800% of weekly allocation rate\n\n\n### Granting DataCap to the client\nThe bot will post a comment with the following structure to kick off a request for DataCap allocation:\n\n```\n## DataCap Allocation requested\n\n#### Multisig Notary address\n> <addr1>\n\n#### Client address\n> <addr2>\n\n#### DataCap allocation requested\n> XTiB\n\n#### Id\n> Id\n```\n\nThis initiates a proposal to the multisig Notary to grant the associated amount of DataCap to the <addr2> client address. Other notaries will now see this in the Filecoin Plus Registry app where they can approve or decline the request. \n  \n  In order to approve the request in the [Fil+ Registry App](https://plus.fil.org/), Notaries need to sign in with their Ledger. During this initial authorization, the app will check if the Ledger address is an approved signer on the large dataset multisig notary addresses (previously, the Organization). Notaries can then action and sign multiple large requests in a row, without needing to re-auth for each multisig.\n  \nAll notaries signing onto the LDN multisig are encouraged to track the client's use of previous DataCap allocations using on-chain information, data available on chain browsers, or on Fil+ specific dashboards like https://filplus.d.interplanetary.one/ or https://filplus.info/.\n  \n## FVM Smart Contracts\nSmart contracts can acquire DataCap just like any regular client. To do so, simply enter the f410 address of the smart contract that requires DataCap as the client address when making a request.\n\nThe process outlined above is for larger amounts of Datacap > 500 TiBs. For a smart contract's first DataCap allocation, we recommend using auto-verifier [Verify.glif.io](Verify.glif.io) to get 32 GiB of DataCap, as specified [here](https://docs.filecoin.io/store/filecoin-plus/overview/).\n\nIt's important to note that DataCap allocations are a one-time credit for a Filecoin address and cannot be transferred between smart contracts. If you need to redeploy the smart contract, you must request additional DataCap. To improve this experience, we are developing an FRC to allow DataCap to be held between redeployments. \n  \n## Current status\n\nNew applications are being accepted at this time, though please expect that the process will likely have some issues as we continue to test and improve the functionality of the process.\n\n## Retrieval Guidelines for Data Clients\n\n1. Fil+ data clients are advised to meticulously choose SPs that align with their specific data retrieval requirements.\n2. Fil+ open dataset clients commit to ensuring the retrievability of open datasets by storing with SPs that serve HTTP retrievals with either [booster-http](https://boost.filecoin.io/http-retrieval/serving-files-with-booster-http) or their custom tooling.\n3. Fil+ clients can enhance their reputation by holding their SPs accountable for retrievability. This may streamline acquisition of additional DataCap in the future.\n4. Fil+ Notaries will consider the client\u2019s track record on retrievability as part of their due diligence.\n5. Data clients and SPs should be aware of the risk of network attacks, and mitigate these risks via rate limiting tools (e.g. set a max requests per second limit).\n6. Data clients and SPs should consider implementing a throttling limit that determines the maximum bandwidth a single retrieving client can consume at any given time.\n7. Private data clients (E Fil+) should store with SPs that provide a level of retrievability consistent with the data clients\u2019 retrieval needs indicated on the DataCap application.\n8. In the event of a large retrieval size, SPs should leverage tooling for load balancing to protect themselves.\n9. Multiple SPs can share a single unsealed copy of data with the same CID. This practice is deemed acceptable as it optimizes time and resource utilization.\n10. If the data client has very good (95-100%) retrievability track record via another retrieval method (GraphSync or BitSwap), then the data client may work with Notaries to get future DataCap approval on a case-by-case basis.\n", "release_dates": []}, {"name": "filecoin-plus-leaderboard", "description": "Fil+ Leaderboard website", "language": "TypeScript", "license": null, "readme": "# Fil+ Leaderboard\n\n## Getting Started\n\nFirst, run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nYou can start editing the page by modifying `pages/index.js`. The page auto-updates as you edit the file.\n\n[API routes](https://nextjs.org/docs/api-routes/introduction) can be accessed on [http://localhost:3000/api/hello](http://localhost:3000/api/hello). This endpoint can be edited in `pages/api/hello.js`.\n\nThe `pages/api` directory is mapped to `/api/*`. Files in this directory are treated as [API routes](https://nextjs.org/docs/api-routes/introduction) instead of React pages.\n\n## Learn More\n\nTo learn more about Next.js, take a look at the following resources:\n\n- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\n- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\n", "release_dates": []}, {"name": "filecoin-plus-leaderboard-data", "description": "Data for the Filecoin Plus leaderboard", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Filecoin Plus data\n\nThis repository contains general data for the Filecoin Plus ecosystem.\n\n> *This is work-in-progress and the documentation will soon be improved to cover more details about the project.*\n\n## How it works\n\nWe're using GitHub workflows to handle data pipelines by leveraging GitHub's [Flat Data](https://githubnext.com/projects/flat-data/) toolkit. This way, we keep datasets public, versioned, and reusable.\n\nProcessing tasks and their outputs are separate from data fetched from the source, making the dataset lifecycle easier to understand while maintaining explainability, so stakeholders can safely and efficiently use the data and audit when necessary.\n\n## Repository structure\n\nThe repository has the following structure:\n\nDirectory path | Description\n-------------- | -----------\n[/.github/workflows](/.github/workflows) | Here's where we define how the data pipeline runs and set basic configuration.\n[/data](/data) | Holds directories for each data stage.\n[/data/raw](/data/raw) | Raw datasets as fetched from source.\n[/data/processed](/data/processed) | Datasets that've been processed by scripts in [/postprocessing](/postprocessing).\n[/data/generated](/data/generated) | New datasets generated for data integration by scripts in [/postprocessing](/postprocessing).\n[/postprocessing](/postprocessing) | This is the home for all processing scripts.\n[/typings](/typings) | This is work-in-progress and is expected to hold TypeScript definitions for the data we maintain.\n[/utils](/utils) | Holds utility scripts used by processing scripts.\n\n## Data contents\n\nFile path | Description\n--------- | -----------\n[/data/generated/verifiers.json](/data/generated/verifiers.json) | Data of all Verifiers/Notaries pulled from multiple sources, processed, and combined.\n[/data/generated/address-mapping.json](/data/generated/address-mapping.json) | Address mapping of on-chain addresses (Filecoin Address ID <-> Filecoin Address Key). Addresses are only added to this file if they exist on-chain (both address types are validated through [Glif's APIs](https://api.node.glif.io/)).\n[/data/processed/notary-governance-issues.json](/data/processed/notary-governance-issues.json) | Data extracted from the notary-governance issues and gone through filtering, cleansing, and normalization.\n[/data/raw/interplanetaryone-verifiers.json](/data/raw/interplanetaryone-verifiers.json) | Raw data fetched from the `getVerifiers` endpoint of InterPlanetary One's API.\n[/data/raw/interplanetaryone-verified-clients.json](/data/raw/interplanetaryone-verified-clients.json) | Raw data fetched from the `getVerifiedClients` endpoint of InterPlanetary One's API.\n[/data/raw/notary-governance-issues.json](/data/raw/notary-governance-issues.json) | Raw data fetched from an endpoint running a script to get all issues from the [notary-governance repository](https://github.com/filecoin-project/notary-governance).\n\n## Recommended reading\n\nHere are some recommended readings if you're interested in some of the concepts that have influenced this project.\n- https://githubnext.com/projects/flat-data/\n- https://github.com/viadee/bpmn.ai-patterns#increasing-levels-of-destruction\n", "release_dates": []}, {"name": "filecoin-plus-roadmap", "description": null, "language": null, "license": null, "readme": "# filecoin-plus-roadmap", "release_dates": []}, {"name": "filecoin-retrieval-market-website", "description": null, "language": "TypeScript", "license": null, "readme": "# filecoin-retrieval-market-website\n\n## Project setup\n\n### Requirements\n\n- Node.js >= 14.17.0\n- NPM >= please-use-yarn\n- Yarn >= 1.22.0\n\n## Docs and links\n\n- [Figma design](https://www.figma.com/file/Jyqz4uiIduzTDulNAs0A0U/Retrieval-Market-(Dev)?node-id=2%3A2)\n- [Website staging](https://filecoin-retrieval-market-website-staging.vercel.app/)\n\n### Install dependencies\n\n```sh\nyarn\n```\n\n## Running the application\n\nTo start the project locally run:\n\n```sh\nyarn start\n```\n\n## Running storybook\n\nTo start the project locally run:\n\n```sh\nyarn start:storybook\n```\n\n## Bundle the application\n\nTo bundle the project run:\n\n```sh\nyarn bundle\n```\n\n## Running tests\n\nTo run the project tests (eslint, stylelint, typescript and jest):\n\n```sh\nyarn lint\n```\n\n## Releases\n\nBe sure to have configured `GITHUB_TOKEN` in your globals.\n\n```bash\ngit checkout development\nnpm version [<new version> | major | minor | patch] -m \"Release %s\"\ngit checkout master\ngit rebase development\ngit push origin development && git push origin master && git push --tags\n```\n", "release_dates": ["2022-05-25T09:14:59Z", "2022-04-13T11:23:01Z", "2022-03-28T12:50:58Z", "2022-03-25T15:17:43Z", "2022-03-24T11:12:05Z", "2022-03-22T17:15:55Z", "2022-03-17T15:53:30Z"]}, {"name": "filecoin-solidity", "description": "Filecoin Solidity API Library", "language": "Solidity", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin Solidity\n\n---\n\n[Protocol Labs](https://protocol.ai/) are now the owners of this library, and will mantain it moving forward.\n\nOriginally authored by [Zondax](https://www.zondax.ch).\n\n---\n\n## Notice\n\nThis software is dual-licensed under the [MIT License](./LICENSE-MIT) and the [Apache Software License v2](./LICENSE-APACHE) by way of the [Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/). Use of this library implies your acceptance of these terms and conditions.\n\nThings to keep in mind, while using this library:\n\n- There are implicit invariants these contracts expect to hold.\n- You should exhaustively read each contract you plan to use, top to bottom.\n- **You can easily \u201cshoot yourself in the foot\u201d if you\u2019re not careful with how you use the library.**\n\n---\n\n## Disclaimer :warning:\n\nThe libraries have been developed under the following set of assumptions.\n\nTake a look at them [here](https://docs.zondax.ch/fevm/filecoin-solidity/introduction/assumptions).\n\n---\n\n## Introduction\n\n### Filecoin Virtual Machine (FVM)\n\nFilecoin today lacks general programmability. As a result, it is not possible to deploy user-defined behaviour, or \"smart contracts\", to the blockchain. The goal of the FVM project is to add general programmability to the Filecoin blockchain.\nThey predict this will unleash a proliferation of new services and tools that can be built and deployed to the Filecoin network, without requiring network upgrades, involvement from core implementation maintainers, changes in the embedded actors, or spec alterations.\n\n## Filecoin Solidity\n\nIt is a set of Solidity libraries that allow Solidity smart contracts to seamlessly call methods of Filecoin built-in actors. They do cross-platform calls to the real Filecoin built-in actors. A set of mock libraries are located too. They respond to specific scenarios based on the received parameters instead of doing real calls.\n\n### Features\n\n#### Libraries to interact with built-in actors\n\nQuerying an operating on the storage market, miner actors, verified registry for FIL+ automation, and more.\n\n#### OpenZeppelin-like utilities specific to Filecoin\n\nFor developer convenience.\n\n#### Filecoin data types\n\nSectors, deals, partitions, deadlines, and more.\n\n#### Access to system features\n\nvia Filecoin precompiles\n\n### How to use it\n\nIn order to use these APIs in your project, you will need to import them on your own contract.\nAs they are embeddable libraries, they don't need to be present on the chain first. You can just import the library you desire and call its methods.\n\n#### Local files\n\nYou will need to copy these files to a folder inside your project. Let's name it `libs`. In your smart contract, copy and paste these lines.\n\n```solidity\nimport { MarketAPI } from \"./libs/MarketAPI.sol\";\nimport { CommonTypes } from \"./libs/types/CommonTypes.sol\";\nimport { MarketTypes } from \"./libs/types/MarketTypes.sol\";\n```\n\n#### NPM Package\n\nBetter approach to import these libs is using the [NPM package](https://www.npmjs.com/package/filecoin-solidity-api) created for this .\n\n```\n$ npm install filecoin-solidity-api\n```\n\n#### Foundry (git)\n\n> [!WARNING]\n> When installing via git, it is a common error to use the `master` branch. This is a development branch that should be avoided in favor of tagged releases. The release process involves security measures that the `master` branch does not guarantee.\n\n> [!WARNING]\n> Foundry installs the latest version initially, but subsequent `forge update` commands will use the `master` branch.\n\n```\n$ forge install filecoin-project/filecoin-solidity\n```\n\nAdd `filecoin-solidity-api=lib/filecoin-project/filecoin-solidity/` in `remappings.txt.`\n\n\n#### Usage\n\nIn your smart contract, copy and paste these lines.\n\n```solidity\nimport { MarketAPI } from \"filecoin-solidity-api/contracts/v0.8/MarketAPI.sol\";\nimport { CommonTypes } from \"filecoin-solidity-api/contracts/v0.8/types/CommonTypes.sol\";\nimport { MarketTypes } from \"filecoin-solidity-api/contracts/v0.8/types/MarketTypes.sol\";\nimport { BigIntCBOR } from \"filecoin-solidity-api/contracts/v0.8/cbor/BigIntCbor.sol\";\n```\n\n## Complementary lectures\n\n### Introduction to Filecoin [:link:](https://docs.filecoin.io/intro/intro-to-filecoin/what-is-filecoin/)\n\nImportant explainers & concepts on Filecoin storage and retrieval markets, FVM as part of Filecoin and Lotus nodes that power the Filecoin network.\n\n### Filecoin 101: conceptual read [:link:](https://hackernoon.com/the-filecoin-virtual-machine-everything-you-need-to-know)\n\nIf you\u2019re starting totally new, we got you! Here\u2019s a 101 conceptual read on understanding FVM from scratch.\n\n### Past Hackathons\n\n#### FVM Space Warp ETHGlobal Cheat Sheet [:link:](https://github.com/filecoin-project/community/discussions/585)\n\n### Community Discussions [:link:](https://github.com/filecoin-project/community/discussions)\n\nFind nice articles with rich and valuable content about different topics related to Filecoin network.\n\n## Looking for the complete documentation? :books::books:\n\nFilecoin solidity documentation: [Let's go to docs web](https://docs.filecoin.io/smart-contracts/developing-contracts/solidity-libraries/) :arrow_upper_right:\n\n---\n\n_**Information for `filecoin-solidity` lib developers is contained in [./lib-dev](./lib-dev)**_\n", "release_dates": ["2023-12-08T11:04:40Z", "2023-12-08T10:43:39Z", "2023-12-08T10:28:54Z"]}, {"name": "filet", "description": "\ud83e\uddd1\u200d\ud83c\udf73 Filecoin Extract & Transformation jobs", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# :cook: Filet\n\nFilet (**Fil**ecoin **E**xtract **T**ransform) makes it simple to get CSV data from Filecoin Archival Snapshots using [Lily](https://github.com/filecoin-project/lily) and [`lily-archiver`](https://github.com/filecoin-project/lily-archiver/).\n\n## :rocket: Usage\n\nThe `filet` image available on Google Container Artifact Hub. Alternatively, you can build it locally with `make build`.\n\nThe following command will generate CSVs from an Filecoin Archival Snapshot:\n\n```bash\ndocker run -it \\\n    -v $PWD:/tmp/data \\\n    europe-west1-docker.pkg.dev/protocol-labs-data/pl-data/filet:latest -- \\\n    /lily/export.sh archival_snapshot.car.zst .\n```\n\n## :alarm_clock: Scheduling Jobs\n\nYou can use the [`send_export_jobs.sh`](scripts/send_export_jobs.sh) script to schedule jobs on Google Cloud Batch. The script takes a file with a list of snapshots as input.\n\n```bash\n./scripts/send_export_jobs.sh SNAPSHOT_LIST_FILE [--dry-run]\n```\n\nFor more details on the scheduled jobs configuration, you can check the [`gce_batch_job.json`](./gce_batch_job.json) file.\n\nThe `SNAPSHOT_LIST_FILE` file should contain a list of snapshots, one per line. The snapshots should be available in the `fil-mainnet-archival-snapshots` Google Cloud Storage bucket.\n\n```\ngsutil ls gs://fil-mainnet-archival-snapshots/historical-exports/ | sort --version-sort > all_snapshots.txt\n```\n\nTo get the batches you can use the following command to filter by snapshot height:\n\n```bash\ngrep -E '^[2226480-2232002]$'\n```\n\n## :wrench: Managing Jobs\n\nIn case you need to retry a bunch of failed jobs, you can use the following commands:\n\n```bash\n# Get the list of failed jobs\ngcloud alpha batch jobs list --format=json --filter=\"Status.state:FAILED\" > failed_jobs.json\n\n# Get the snapshot name from failed jobs\ncat failed_jobs.json | jq \".[].taskGroups[0].taskSpec.runnables[0].container.commands[0]\" -r | cut -d '/' -f 2 | sort > failed_jobs.list\n\n# Retry the failed jobs\n./scripts/send_export_jobs.sh failed_jobs.list\n```\n", "release_dates": []}, {"name": "filplus-backend", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Fil+ Backend\n\n### About\n\nThe Fil+ Backend is a web service aiming to provide several HTTP\nendpoints to manage LDN applications, perform actions on filecoin\ngithub and read blockchain data related to applications.\n\n### Architecture\n\nThe backend has two different external services:\n\n* Github:\n    used to manage applications.\n* Blockchain data(using demob): used to validate data related to the\n  different lifecycles of the application.\n\nThese services are the backbone for the core code that will be\nmodifying the applications, this code is located under \"core\" folder\nand it is basically defining the structure of the json file, and a way\nof changing the file.\n\nAnother important section is the `parsers.rs` this file include the\nparsers that validate the structure and format of the json file.\n\n###### Application Version\nTBD\n\n\n### Related Projects\n- [Fil+ Registry](https://github.com/filecoin-project/filplus-registry)\n- [Fil+ SSA Bot](https://github.com/filecoin-project/filplus-ssa-bot)\n- [Fil+ Application Repository (Falcon)](https://github.com/filecoin-project/filecoin-plus-falcon)\n\n### Swagger Documentation\n\nhttps://app.swaggerhub.com/apis/jesraa/FilecoinBackend/1.0.0#/\n\n### How should I use this?\nThere are two different kinds of endpoints:\n* `/application`: these endpoints are util to manage the application.\n  you can start by making a POST method to `/application` with the\n  application id(see swagger documentation for detailed api\n  documentation). Currently the application id is the github issue.\n  after creating application via the endpoint, a new pull request will\n  be created with a json file with initial data. Next step for the\n  application is to be reviewed by governance team. once they are\n  happy with it they can hit `/application/{id}/trigger ` to move the\n  application to proposal state.\n  Next, a notary should review the application and sign it with their\n  ledger. In order for the notary to document the signature, they call\n  `/application/{id}/propose` with data related to the blockchain tx\n  made. Next step is the same as the one before, but you would call\n  `/application/{id}/approve`. In that stage, the application is\n  granted and completed. in order to merge the pull request you can\n  call `/application/{id}/merge`.\n\n* `/blockchain`: these endpoints retrive blockchain data related to\n  ldn applications. it is using demob as a data source.\n\n### Run Localy\n\n- Install Rust\n- Add env variables (an example present in the repo)\n- `cargo run` \n\n### Contributions\nAs an open-source project, we welcome and encourage the community to contribute to the Fil+ Backend. Your insights and improvements are valuable to us. Here's how you can contribute:\n\n- **Fork the Repository**: Start by forking the repository to your GitHub account.\n- **Clone the Forked Repository**: Clone it to your local machine for development purposes.\n- **Create a New Branch**: Always create a new branch for your changes.\n- **Make Your Changes**: Implement your features, bug fixes, or improvements.\n- **Commit Your Changes**: Make sure to write clear, concise commit messages.\n- **Push to Your Fork**: Push your changes to your forked repository.\n- **Create a Pull Request**: Submit a pull request from your forked repository to our main repository.\n\nPlease read through our [CONTRIBUTING.md](CONTRIBUTING.md) file for detailed instructions on how to contribute.\n\n### License\nThis project is dual-licensed under the `Permissive License Stack`, which means you can choose to use the project under either:\n\n- The Apache License 2.0, which is a free and open-source license, focusing on patent rights and copyright notices. For more details, see the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\n- The MIT License, a permissive and open-source license, known for its broad permissions and limited restrictions. For more details, see the [MIT License](https://opensource.org/licenses/MIT).\n\nYou may not use the contents of this repository except in compliance with one of these licenses. For an extended clarification of the intent behind the choice of licensing, please refer to the `LICENSE` file in this repository or visit [Permissive License Stack Explanation](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n\nFor the full license text, please see the [LICENSE](LICENSE) file in this repository.\n\n### CHANGELOG\n1.0.4\n- The database workspace is temporarily removed from the project and as a dependency.", "release_dates": ["2023-11-06T13:36:04Z", "2023-11-06T13:17:26Z", "2023-10-26T08:50:46Z", "2023-10-26T08:47:23Z", "2023-09-01T13:59:35Z", "2023-09-01T13:47:47Z"]}, {"name": "filplus-registry", "description": null, "language": "TypeScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Fil+ Registry Frontend\n\nWelcome to the Fil+ Registry Frontend repository. This web application is a crucial component of the Fil+ program, providing an interactive interface for notaries and Root Key Holders to manage datacap allocations efficiently.\n\n## Overview\n\nThe Fil+ Registry is accessible at [https://filplus-registry.netlify.app/](https://filplus-registry.netlify.app/) and serves as a centralized platform for notaries and Root Key Holders involved in the Fil+ program. It facilitates the process of triggering, proposing, and approving datacap allocations to clients, streamlining the overall workflow and enhancing transparency.\n\n## Features\n\n- **Datacap Allocation**: Enables notaries and Root Key Holders to propose and approve datacap allocations.\n- **User-Friendly Interface**: Simplifies the process of managing datacap requests and approvals.\n- **Real-Time Updates**: Keeps all stakeholders informed with the latest status of datacap allocations.\n- **Secure and Reliable**: Ensures the integrity and confidentiality of the datacap allocation process.\n\n# Related Projects\n\n- [Fil+ Backend](https://github.com/filecoin-project/filplus-backend)\n- [Fil+ SSA Bot](https://github.com/filecoin-project/filplus-ssa-bot)\n- [Fil+ Application Repository (Falcon)](https://github.com/filecoin-project/filecoin-plus-falcon)\n\n## Contribution\n\nAs an open-source project, we welcome and encourage the community to contribute to the Filplus SSA Bot. Your insights and improvements are valuable to us. Here's how you can contribute:\n\n- **Fork the Repository**: Start by forking the repository to your GitHub account.\n- **Clone the Forked Repository**: Clone it to your local machine for development purposes.\n- **Create a New Branch**: Always create a new branch for your changes.\n- **Make Your Changes**: Implement your features, bug fixes, or improvements.\n- **Commit Your Changes**: Make sure to write clear, concise commit messages.\n- **Push to Your Fork**: Push your changes to your forked repository.\n- **Create a Pull Request**: Submit a pull request from your forked repository to our main repository.\n\nPlease read through our [CONTRIBUTING.md](CONTRIBUTING.md) file for detailed instructions on how to contribute.\n\n## Getting Started\n\nTo get started with the Fil+ Registry Frontend, you can visit the live application at [https://filplus-registry.netlify.app/](https://filplus-registry.netlify.app/). For developers interested in contributing or setting up a local version, follow the instructions below:\n\n### Prerequisites\n\n- Ensure you have a modern web browser installed (e.g., Chrome, Firefox, Safari).\n- For local development, you will need Node.js and npm installed on your machine.\n\n### Installation for Local Development\n\n1. **Clone the Repository**\n\n   ```bash\n   git clone https://github.com/filecoin-project/filplus-registry.git\n   cd filplus-registry\n   ```\n\n2. **Install dependencies**\n   ```bash\n   npm install\n   ```\n3. **Create .env file**\n   ```bash\n   # Please, request access to Environment Variables\n   NEXT_PUBLIC_API_URL\n   NEXT_PUBLIC_DMOB_API_KEY\n   NEXT_PUBLIC_NODE_ADDRESS\n   NEXT_PUBLIC_NODE_TOKEN\n   GITHUB_ID\n   GITHUB_SECRET\n   NEXT_PUBLIC_MODE=development\n   ```\n\n## Support and Community\n\nIf you have any questions, suggestions, or need assistance, please reach out to our community channels. We strive to build a welcoming and supportive environment for all our contributors and users.\n\n## License\n\nThis project is dual-licensed under the `Permissive License Stack`, which means you can choose to use the project under either:\n\n- The Apache License 2.0, which is a free and open-source license, focusing on patent rights and copyright notices. For more details, see the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\n- The MIT License, a permissive and open-source license, known for its broad permissions and limited restrictions. For more details, see the [MIT License](https://opensource.org/licenses/MIT).\n\nYou may not use the contents of this repository except in compliance with one of these licenses. For an extended clarification of the intent behind the choice of licensing, please refer to the `LICENSE` file in this repository or visit [Permissive License Stack Explanation](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n\nFor the full license text, please see the [LICENSE](LICENSE) file in this repository.\n\n[![Netlify Status](https://api.netlify.com/api/v1/badges/af2318b1-1bde-4385-b78e-d1d0a6bb0b82/deploy-status)](https://app.netlify.com/sites/filplus-registry/deploys)\n", "release_dates": []}, {"name": "filplus-ssa-bot", "description": null, "language": "TypeScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filplus SSA Bot\nWelcome to the \"Filplus SSA Bot\" (Subsequent Allocation Bot) repository. This bot is an integral part of the Filplus program, specifically designed to enhance the efficiency and effectiveness of the Large Dataset Notaries (LDN) program.\n\n## Overview\nThe Filplus SSA Bot, written in <code>TypeScript</code>, plays a crucial role in managing the allocation of datacap within the LDN program. It is programmed to automatically launch every 12 hours, performing a thorough scan of all active datacap requests. For those requests where more than 75% of the allocated datacap in the last tranche has been consumed, the bot initiates the process of assigning a new tranche.\n\n## Key Features\n- **Automated Scanning**: Every 12 hours, the bot scans all active datacap requests within the LDN program.\n- **Tranche Allocation**: When a request has consumed over 75% of its last allocated datacap, the bot triggers the allocation of a new tranche.\n- **Notary Approval**: Each new tranche allocation must be proposed and approved by two different notaries to ensure fairness and transparency.\n\n# Related Projects\n- [Fil+ Backend](https://github.com/filecoin-project/filplus-backend)\n- [Fil+ Registry](https://github.com/filecoin-project/filplus-registry)\n- [Fil+ Application Repository (Falcon)](https://github.com/filecoin-project/filecoin-plus-falcon)\n\n## Contribution\nAs an open-source project, we welcome and encourage the community to contribute to the Filplus SSA Bot. Your insights and improvements are valuable to us. Here's how you can contribute:\n\n- **Fork the Repository**: Start by forking the repository to your GitHub account.\n- **Clone the Forked Repository**: Clone it to your local machine for development purposes.\n- **Create a New Branch**: Always create a new branch for your changes.\n- **Make Your Changes**: Implement your features, bug fixes, or improvements.\n- **Commit Your Changes**: Make sure to write clear, concise commit messages.\n- **Push to Your Fork**: Push your changes to your forked repository.\n- **Create a Pull Request**: Submit a pull request from your forked repository to our main repository.\n\nPlease read through our [CONTRIBUTING.md](CONTRIBUTING.md) file for detailed instructions on how to contribute.\n\n## Usage\nThis bot is specifically designed as a part of the Filplus program and is not intended for general installation or standalone use. Its primary function is to automate certain processes within the LDN program, contributing to the overall efficiency and effectiveness of datacap allocation.\n\n## Support and Community\nIf you have any questions, suggestions, or need assistance, please reach out to our community channels. We strive to build a welcoming and supportive environment for all our contributors and users.\n\n## License\nThis project is dual-licensed under the `Permissive License Stack`, which means you can choose to use the project under either:\n\n- The Apache License 2.0, which is a free and open-source license, focusing on patent rights and copyright notices. For more details, see the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\n- The MIT License, a permissive and open-source license, known for its broad permissions and limited restrictions. For more details, see the [MIT License](https://opensource.org/licenses/MIT).\n\nYou may not use the contents of this repository except in compliance with one of these licenses. For an extended clarification of the intent behind the choice of licensing, please refer to the `LICENSE` file in this repository or visit [Permissive License Stack Explanation](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n\nFor the full license text, please see the [LICENSE](LICENSE) file in this repository.", "release_dates": []}, {"name": "filplus-tooling-backend-test", "description": "Replication of LDN Production Repo", "language": "Shell", "license": null, "readme": "# filplus-tooling-backend-test\n\nThis is a test repo to replicate production repo that handles LDN Applications.\n\nMust of the work here is done throug github actions where we listen to different events(like ISSUE_OPEN) and execute actions.\n\nManaging LDN Applications involves allowing intializatin an application through an issue or a pull request. In the first scenario\nwe parse the new issue opened and create a pull request for it, after that all the management of that application will occur under the pull request.\nyou can open an application through a pr through the filplus-backend API or the a template we will implement in Github. Otherwise, you can follow the filecoin LDN application standards to open an application on your own.\n\n", "release_dates": []}, {"name": "filplus-utils", "description": null, "language": "TypeScript", "license": null, "readme": "HELLO\n", "release_dates": []}, {"name": "filsnap", "description": "MetaMask snap for interacting with Filecoin dapps.", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# \u2a0e FilSnap Monorepo\n\nFilecoin Metamask Snap and related packages to enable developers to add Filecoin integration to their dapps.\n\nThis Snap enables storage of native Filecoin private keys in Metamask's local vault, to support native Filecoin addresses (e.g. f1 addresses or t1 testnet addresses).\n\nFor FEVM (Filecoin EVM) address support using Ethereum-style 0x addresses, you can also use regular Metamask directly **without** installing this Snap. \n\n- If you're using FEVM, the Snap can also show your 0x address info and its equivalent Filecoin f410 address. (More info about 0x / f410 addresses can be found in the [Filecoin Docs - Ethereum Address Manager](https://docs.filecoin.io/smart-contracts/filecoin-evm-runtime/address-types#ethereum-address-manager).)\n\n## Resources\n\n- [Filecoin MetaMask Snap Wallet Demo](https://filsnap.fission.app/)\n- [Filecoin Metamask Snap Docs](https://filecoin-project.github.io/filsnap/)\n\n## Packages\n\n- [filsnap](https://github.com/filecoin-project/filsnap/tree/master/packages/snap) - Filecoin snap for Metamask\n- [filsnap-adapter](https://github.com/filecoin-project/filsnap/tree/master/packages/adapter) - Adapter to interact with Filsnap from a dapp\n- [filsnap-adapter-react](https://github.com/filecoin-project/filsnap/tree/master/packages/adapter-react) - React hooks to interact with Filsnap from a dapp\n\n## Examples\n\n- [`demo`](https://github.com/filecoin-project/filsnap/tree/master/examples/demo) - Preact demo dapp using [filsnap-adapter](<[./packages/adapter](https://github.com/filecoin-project/filsnap/tree/master/packages/adapter)>) to interact with [filsnap](<[./packages/snap](https://github.com/filecoin-project/filsnap/tree/master/packages/snap)>)\n- [`fil-forwarder-viem`](https://github.com/filecoin-project/filsnap/tree/master/examples/fil-forwarder-viem) - [Viem](https://viem.sh/) example to send FIL using FilForwarder contract.\n- [Fund Ring](https://github.com/FundRing/fundring/tree/main/src/routes/filfund) - Svelte dapp [dapp](https://fundring.fission.app/) that using filsnap to fund projects with Filecoin.\n\n### Checkout examples\n\nYou can use [Codesandbox](https://githubbox.com/filecoin-project/filsnap/tree/master/examples/demo) and start hacking right away.\n\nTo clone it locally:\n\n```bash\nnpx tiged filecoin-project/filsnap/examples/demo filsnap-demo\ncd filsnap-demo\npnpm install\npnpm dev\n```\n\nYou can try any of the examples by replacing `demo` with the name of the example you want to try.\n\n## Contributing\n\nRead contributing guidelines [here](.github/CONTRIBUTING.md).\n\n[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/filecoin-project/filsnap)\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the\n[Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n\n## Security Audits\n\n**Filsnap v1.0.1** - The FilSnap v0.5.0 was audited by [ConsenSys Diligence](https://consensys.io/diligence/) in August 2023 with a follow-up assessment of fixes conducted in October 2023, leading to the release of [filsnap-v1.0.1](https://github.com/filecoin-project/filsnap/releases/tag/filsnap-v1.0.1). The complete audit report is [available here](./audits/filsnap-audit-2023-08.pdf) in the `audits/` directory as well as on the [ConsenSys Diligence website](https://consensys.io/diligence/audits/2023/08/metamask/partner-snaps-filsnap/).\n", "release_dates": ["2023-10-10T19:49:28Z", "2023-09-12T15:53:44Z", "2023-09-12T16:04:13Z", "2023-09-12T16:16:53Z", "2023-08-09T18:03:03Z", "2023-08-09T18:09:25Z", "2023-07-30T19:59:09Z", "2023-07-30T16:51:42Z", "2023-07-29T17:35:53Z", "2023-07-29T14:46:14Z", "2023-07-29T14:56:19Z", "2023-07-29T15:08:31Z", "2023-07-24T18:07:48Z", "2023-07-24T17:52:46Z", "2023-07-24T18:17:02Z", "2023-07-22T00:32:53Z", "2023-07-22T00:38:47Z", "2023-07-21T15:11:18Z", "2023-07-14T00:02:56Z", "2023-07-13T23:17:28Z", "2023-07-13T16:37:43Z", "2023-07-13T12:38:20Z", "2023-07-13T17:02:41Z"]}, {"name": "fil_pasta_curves", "description": "Rust implementation for zcash/pasta", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# `pasta_curves`\n\nThis crate provides an implementation of the Pasta elliptic curve constructions,\nPallas and Vesta. More details about the Pasta curves can be found\n[in this blog post](https://electriccoin.co/blog/the-pasta-curves-for-halo-2-and-beyond/).\n\n## [Documentation](https://docs.rs/pasta_curves)\n\n## Minimum Supported Rust Version\n\nRequires Rust **1.56** or higher.\n\nMinimum supported Rust version can be changed in the future, but it will be done with a\nminor version bump.\n\n## Curve Descriptions\n\n- Pallas: y<sup>2</sup> = x<sup>3</sup> + 5 over\n  `GF(0x40000000000000000000000000000000224698fc094cf91b992d30ed00000001)`.\n\n- Vesta:  y<sup>2</sup> = x<sup>3</sup> + 5 over\n  `GF(0x40000000000000000000000000000000224698fc0994a8dd8c46eb2100000001)`.\n\nThe Pasta curves form a cycle with one another: the order of each curve is exactly the\nbase field of the other. This property is critical to the efficiency of recursive proof\nsystems. They are designed to be highly 2-adic, meaning that a large power-of-two\nmultiplicative subgroup exists in each field. This is important for the performance of\npolynomial arithmetic over their scalar fields and is essential for protocols similar\nto PLONK.\n\nThese curves can be reproducibly obtained\n[using a curve search utility we\u2019ve published](https://github.com/zcash/pasta).\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "FIPs", "description": "The Filecoin Improvement Proposal repository", "language": "Jupyter Notebook", "license": null, "readme": "## Filecoin Improvement Protocol\n\nThe Filecoin Improvement Protocol contains the set of fundamental governing principles for the Filecoin Network. It outlines the vision for Filecoin and the principles, processes, and parties involved in making decisions that affect the future of the network. It also describes how improvements to these rules can be proposed and ratified.\n\n\n## The Filecoin Vision\n\nFilecoin is a peer-to-peer network that stores files, with built-in economic incentives to ensure that files are stored reliably over time. Its mission is to create a decentralized, efficient and robust foundation for humanity\u2019s information. To advance that mission, Filecoin has created a decentralized storage network that lets anyone in the world store or retrieve files.\n\nIn Filecoin, users pay to store their files on storage miners. Storage miners are computers responsible for storing files and proving they have stored the files correctly over time. Anyone who wants to store their files or get paid for storing other users\u2019 files can join Filecoin. Available storage and pricing are not controlled by any single entity. Instead, Filecoin facilitates open markets for storing and retrieving files that anyone can participate in, thereby providing storage to billions of people who are currently locked out of the web.\n\n## Filecoin Design Principles\n\nThe design of Filecoin is intended to follow a set of principles. The community will help define these principles in the coming months.\n\n\n## Filecoin Improvement Principles\n\nWhen making decisions about how to improve Filecoin, we will follow a set of principles. The community will help define these principles in the coming months.\n\n## Making changes to the Filecoin network\n\n[Filecoin Improvement Proposals (FIPs)](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0001.md) are the primary mechanism by which the Filecoin community can submit, discuss, and approve changes relevant to the Filecoin network. These discussions and decisions should be guided by the governance and design principles above.\n\nFIPs are classified into three categories:\n\n**Technical FIPs, or Filecoin Technical Proposals (FTPs)** are designed to gather community feedback on technical Filecoin issues. These include changes to the Filecoin protocol, a change in block or transaction validity rules, and proposed application standards or conventions. They are then reviewed by the Filecoin community and the technical steering committee. They are normally followed by a PR to the [Filecoin Specification repository](https://github.com/filecoin-project/specs) to update the protocol's spec.\n\n**Organizational FIPs, or Filecoin Organization Proposals (FOPs)** allow the Filecoin community to propose, discuss, and achieve consensus on Filecoin governance. This includes procedures, guidelines, decision-making processes, and changes to FIP processes.\n\n**Recovery FIPs, or Filecoin Recovery Proposals (FRPs)** are intended to provide the Filecoin community with a forum to raise, discuss, and achieve consensus on fault recovery and chain rewrites, under a very limited, clearly-defined set of criteria (ex, in the case of protocol bugs destroying network value). The community will help define this process as needed in the coming months.\n\n## A decentralized, global network\n\nFilecoin is still in its infancy, but it has the potential to play a central role in the storage and distribution of humanity\u2019s information. To help the network grow and evolve, it is critical for the community to collectively be engaged in proposing, discussing, and implementing changes that improve the network and its operations.\n\nThis improvement protocol helps achieve that objective for all members of the Filecoin community (developers, miners, clients, token holders, ecosystem partners, and more).\n\n## FIPs\n\n|FIP #   | Title  | Type  | Author  | Status  |\n|---|---|---|---|---|\n|[0001](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0001.md)  | FIP Purpose and Guidelines  | FIP  | @Whyrusleeping  | Active  |\n|[0002](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0002.md)  | Free Faults on Newly Faulted Sectors of a Missed WindowPoSt  | FIP | @anorth, @davidad, @miyazono, @irenegia, @lucaniz, @nicola, @zixuanzh |Final   |\n|[0003](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0003.md)  | Filecoin Plus Principles  | FIP  | @feerst, @jbenet, @jnthnvctr, @tim-murmuration, @mzargham, @zixuanzh |Active   |\n|[0004](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0004.md)  | Liquidity Improvement for Storage Miners   | FIP  | @davidad, @jbenet, @zenground0, @zixuanzh, @danlessa | Final  |\n|[0005](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0005.md)  | Remove ineffective reward vesting    | FIP  | @anorth, @Zenground   |Final   |\n|[0006](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0006.md)  | No repay debt requirement for DeclareFaultsRecovered  | FIP  |  @nicola, @irenegia  | Deferred  |\n|[0007](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0007.md)  | h/amt-v3  | FIP  | @rvagg, @Stebalien, @anorth, @Zenground0 |Final   |\n|[0008](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0008.md)  | Add miner batched sector pre-commit method  | FIP  |@anorth, @ZenGround0, @nicola |Final   |\n|[0009](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0009.md)  | Exempt Window PoSts from BaseFee burn  | FIP  |@Stebalien, @momack2, @magik6k, @zixuanzh |Final   |\n|[0010](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0010.md)  | Off-Chain Window PoSt Verification  | FIP  |@Stebalien, @anorth  |Final  |\n|[0011](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0011.md)  | Remove reward auction from reporting consensus faults  | FIP  |@Kubuxu |Final   |\n|[0012](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0012.md)  | DataCap Top up for FIL+ Client Addresses  | FIP  |@dshoy, @jnthnvctr, @zx |Final  |\n|[0013](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0013.md)  | Add ProveCommitSectorAggregated method to reduce on-chain congestion  | FIP  | @ninitrava @nicola |Final   |\n|[0014](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0014.md)  | Allow V1 proof sectors to be extended up to a maximum of 540 days | FIP  | @deltazxm, @neogeweb3 |Final   |\n|[0015](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0015.md)  | Revert FIP-0009(Exempt Window PoSts from BaseFee burn) | FIP  | @jennijuju, @arajasek |Final   |\n|[0016](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0016.md)  | Pack arbitrary data in CC sectors | FIP  | donghengzhao (@1475) |Deferred  |\n|[0017](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0017.md)  | Three-messages lightweight sector updates | FIP  |@nicole, @lucaniz, @irenegia |Deferred  |\n|[0018](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0018.md)  | New miner terminology proposal | FIP  |@Stefaan-V |Final  |\n|[0019](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0019.md)  | Snap Deals | FIP  |@Kubuxu, @lucaniz, @nicola, @rosariogennaro, @irenegia |Final  |\n|[0020](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0020.md)  | Add return value to WithdrawBalance | FIP  |@Stefaan-V |Final  |\n|[0021](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0021.md)  | Correct quality calculation on expiration | FIP  |@Steven004, @Zenground0 |Final  |\n|[0022](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0022.md)  | Bad deals don't fail PublishStorageDeals | FIP  |@Zenground0 |Final  |\n|[0023](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0023.md)  | Break ties between tipsets of equal weights | FIP  |@sa8, @arajasek |Final  |\n|[0024](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0024.md)  | BatchBalancer & BatchDiscount Post -Hyperdrive adjustment | FIP  |@zx, @jbenet, @zenground0, @momack2 |Final  |\n|[0025](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0025.md)  | Handle expired deals in ProveCommit | FIP  |@ZenGround0 |Deferred  |\n|[0026](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0026.md)  | Extend sector fault cutoff period from 2 weeks to 6 weeks | FIP  |@IPFSUnion |Final  |\n|[0027](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0027.md)  | Change type of DealProposal Label field from a (Golang) String to a Union | FIP  |@laudiacay, @Stebalien, @arajasek |Final  |\n|[0028](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0028.md)  | Remove DataCap and verified client status from client address | FIP  |@jennijuju, @dkkapur |Final  |\n|[0029](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0029.md)  | Beneficiary address for storage providers | FIP  |@steven004 |Final  |\n|[0030](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0030.md)  | Introducing the Filecoin Virtual Machine (FVM) | FIP  |@raulk, @stebalien |Final  |\n|[0031](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0031.md)  | Atomic switch to non-programmable FVM | FIP  |@raulk, @stebalien |Final  |\n|[0032](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0032.md)  | Gas model adjustment for non-programmable FVM | FIP  |@raulk, @stebalien |Final  |\n|[0033](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0033.md)  | Explicit premium for FIL+ verified deals | FIP  |@anorth |Deferred  |\n|[0034](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0034.md)  | Fix pre-commit deposit independent of sector content | FIP  |@anorth, @Kubuxu |Final |\n|[0035](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0035.md)  | Support actors as built-in storage market clients | FIP  |@anorth |Withdrawn  |\n|[0036](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0036.md)  | Introducing a Sector Duration Multiple for Longer Term Sector Commitment | FIP  |@AxCortesCubero, @jbenet, @misilva73, @momack2, @tmellan, @vkalghatgi, @zixuanzh |Rejected  |\n|[0037](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0037.md)  | Gas model adjustment for user programmability | FIP  |@raulk, @stebalien |Draft  |\n|[0038](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0038.md)  | Indexer Protocol for Filecoin Content Discovery | FRC  |@willscott, @gammazero, @honghaoq |Draft  |\n|[0039](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0039.md)  | Filecoin Message Replay Protection | FIP  |@q9f |Draft  |\n|[0040](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0040.md)  | Boost - Filecoin Storage Deals Market Protocol | FRC  |@dirkmc, @nonsense, @jacobheun, @brendalee |Draft  |\n|[0041](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0041.md)  | Forward Compatibility for PreCommit and ReplicaUpdate | FIP  |@Kubuxu |Final  |\n|[0042](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0042.md)  | Calling Convention for Hashed Method Name | FRC  |@Kubuxu, @anorth |Draft  |\n|[0044](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0044.md)  | Standard Authentication Method for Actors | FIP  |@arajasek, @anorth |Final  |\n|[0045](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0045.md)  | De-couple verified registry from markets | FIP  |@anorth, @zenground0 |Final  |\n|[0046](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0046.md)  | Fungible token standard | FRC  |@anorth, @jsuresh, @alexytsu |Draft  |\n|[0047](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0047.md)  | Proof Expiration & PoRep Security Policy | FIP  |@Kubuxu, @irenegia, @anorth | Superseded  |\n|[0048](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0048.md)  | f4 Address Class | FIP  |@stebalien, @mriise, @raulk | Final  |\n|[0049](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0049.md)  | Actor Events | FIP  |@stebalien, @raulk | Final  |\n|[0050](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0050.md)  | API Between User-Programmed Actors and Built-In Actors | FIP  |@anorth, @arajasek | Final  |\n|[0051](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0051.md)  | Synchronous Consistent Block Broadcast for EC Security | FRC  |Guy Goren <guy.goren@protocol.ai>, Alfonso de la Rocha <alfonso@protocol.ai> | Draft  |\n|[0052](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0052.md)  | Increase max sector commitment to 3.5 years | FIP  |@anorth | Final  |\n|[0053](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0053.md)  | Non-Fungible Token Standard | FRC  |@alexytsu, @abright, @anorth | Draft  |\n|[0054](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0054.md)  | Filecoin EVM Runtime (FEVM)  | FIP  |@raulk, @stebalien | Final  |\n|[0055](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0055.md)  | Supporting Ethereum Accounts, Addresses, and Transactions  | FIP  |@raulk, @stebalien | Final |\n|[0056](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0056.md)  | Sector Duration Multiplier  | FIP  | @AxCortesCubero, @jbenet, @misilva73, @momack2, @tmellan, @vkalghatgi, @zixuanzh | Rejected  |\n|[0057](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0057.md)  | Update Gas Charging Schedule and System Limits for FEVM  | FIP  |@raulk, @stebalien, @aakoshh, @kubuxu| Final  |\n|[0058](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0058.md)  | Verifiable Data Aggregation  | FRC  |Jakub Sztandera (@Kubuxu), Nicola Greco (@nicola), Peter Rabbitson (@ribasushi)| Draft  |\n|[0059](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0059.md)  | Synthetic PoRep  | FIP  |@Kubuxu @Luca @Rosario Gennaro @Nicola @Irene| Final  |\n|[0060](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0060.md)  | Set market deal maintenance interval to 30 days  | FIP  |Jakub Sztandera (@Kubuxu), @Zenground0, Alex North (@anorth)| Final  |\n|[0061](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0061.md)  | WindowPoSt Grindability Fix  | FIP  |@cryptonemo @Kubuxu  @DrPeterVanNostrand @Nicola @porcuquine @vmx @arajasek| Final  |\n|[0062](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0062.md)  | Fallback Method Handler for the Multisig Actor  | FIP  |JDimitris Vyzovitis (@vyzo), Ra\u00fal Kripalani (@raulk)| Final  |\n|[0063](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0063.md)  | Switching to new Drand mainnet network  | FIP  | @yiannisbot, @CluEleSsUK, @AnomalRoil, @nikkolasg, @willscott | Accepted    |\n|[0065](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0065.md)  | Ignore built-in market locked balance in circulating supply calculation  | FIP  | @anorth  | Accepted  |\n|[0066](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0066.md)  | Piece Retrieval Gateway | FRC  | @willscott, @dirkmc  | Draft  |\n|[0067](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0067.md)  | PoRep Security Policy & Replacement Sealing Enforcement  | FIP  | @Kubuxu, @anorth, @irenegia, @lucaniz | Accepted  |\n|[0068](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0068.md)  | Deal-Making Between SPs and FVM Smart Contracts | FRC  | @aashidham, @raulk, @skottie86, @jennijuju, @nonsense, @shrenujbansal | Draft  |\n|[0069](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0069.md)  | Piece Multihash and v2 Piece CID | FRC  | @aschmahmann, @ribasushi | Draft  |\n|[0070](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0070.md)  | Allow SPs to move partitions between deadlines  | FIP  |Steven Li (@steven004), Alan Xu (@zhiqiangxu), Mike Li (@hunjixin), Alex North (@anorth), Nicola (@nicola)| Rejected  |\n|[0071](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0071.md)  | Deterministic State Access (IPLD Reachability)  | FIP  |@stebalien| Final  |\n|[0072](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0072.md)  | Improved event syscall API  | FIP  | @fridrik01, @Stebalien | Final  |\n|[0073](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0073.md)  | Remove beneficiary from the self_destruct syscall | FIP  | @Stebalien | Final  |\n|[0074](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0074.md)  | Remove cron-based automatic deal settlement  | FIP  | @anorth, @alexytsu| Accepted  |\n|[0075](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0075.md)  | Improvements to the FVM randomness syscalls  | FIP  | @arajasek, @Stebalien  | Final  |\n|[0076](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0076.md)  | Direct data onboarding | FIP  | @anorth, @zenground0 | Accepted  |\n|[0077](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0077.md)  | Add Cost Opportunity For New Miner Creation  | FIP  |Zac (@remakeZK), Mike Li (@hunjixin)| Draft  |\n|[0078](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0078.md)  | Remove Restrictions on the Minting of Datacap  | FIP  |Fatman13 (@Fatman13), flyworker (@flyworker), stuberman (@stuberman), Eliovp (@Eliovp), dcasem (@dcasem), and The-Wayvy (@The-Wayvy)| Draft  |\n|[0079](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0079.md)  | Add BLS Aggregate Signatures to FVM  | FIP  | Jake (@drpetervannostrand) | Accepted  |\n|[0080](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0080.md)  | Phasing Out Fil+ and Restoring Deal Quality Multiplier to 1x | FIP | @Fatman13, @ArthurWang1255, @stuberman, @Eliovp, @dcasem, @The-Wayvy | Draft |\n|[0081](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0081.md)  | Introduce lower bound for sector initial pledge | FIP | @anorth, @vkalghatgi | Draft |\n|[0082](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0082.md)  | Add support for aggregated replica update proofs | FIP | nemo (@cryptonemo), Jake (@drpetervannostrand), @anorth | Accepted |\n|[0083](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0083.md) | Add built-in Actor events in the Verified Registry, Miner and Market Actors | FIP | Aarsh (@aarshkshah1992)| Accepted |\n|[0084](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0084.md) | Remove Storage Miner Actor Method `ProveCommitSectors`   | FIP | Jennifer Wang (@jennijuju)| Accepted |\n|[0085](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0085.md) | Convert f090 Mining Reserve actor to a keyless account actor   | FIP | Jennifer Wang (@jennijuju), Jon Victor (@jnthnvctr)| Last Call |\n|[0086](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0086.md) | Fast Finality in Filecoin (F3) | FIP | @stebalien, @mb1896, @hmoniz, @anorth, @matejpavlovic, @arajasek, @ranchalp, @jsoares, @Kubuxu, @vukolic | Draft |\n|[0087](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0087.md) | FVM-Enabled Deal Aggregation | FRC | @aashidham, @honghao, @raulk, @nonsense | Draft |\n|[0089](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0089.md) | A Finality Calculator for Filecoin | FRC | @guy-goren, @jsoares | Draft |\n", "release_dates": []}, {"name": "FIPs-1", "description": "The Filecoin Improvement Proposal repository", "language": null, "license": null, "readme": "## Filecoin Improvement Protocol\n\nThe Filecoin Improvement Protocol contains the set of fundamental governing principles for the Filecoin Network. It outlines the vision for Filecoin and the principles, processes, and parties involved in making decisions that affect the future of the network. It also describes how improvements to these rules can be proposed and ratified.\n\n\n## The Filecoin Vision\n\nFilecoin is a peer-to-peer network that stores files, with built-in economic incentives to ensure that files are stored reliably over time. Its mission is to create a decentralized, efficient and robust foundation for humanity\u2019s information. To advance that mission, Filecoin has created a decentralized storage network that lets anyone in the world store or retrieve files. \n\nIn Filecoin, users pay to store their files on storage miners. Storage miners are computers responsible for storing files and proving they have stored the files correctly over time. Anyone who wants to store their files or get paid for storing other users\u2019 files can join Filecoin. Available storage and pricing are not controlled by any single entity. Instead, Filecoin facilitates open markets for storing and retrieving files that anyone can participate in, thereby providing storage to billions of people who are currently locked out of the web. \n\n## Filecoin Design Principles\n\nThe design of Filecoin is intended to follow a set of principles. The community will help define these principles in the coming months.\n\n\n## Filecoin Improvement Principles\n\nWhen making decisions about how to improve Filecoin, we will follow a set of principles. The community will help define these principles in the coming months.\n\n## Making changes to the Filecoin network\n\n[Filecoin Improvement Proposals (FIPs)](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0001.md) are the primary mechanism by which the Filecoin community can submit, discuss, and approve changes relevant to the Filecoin network. These discussions and decisions should be guided by the governance and design principles above.\n\nFIPs are classified into three categories:\n\n**Technical FIPs, or Filecoin Technical Proposals (FTPs)** are designed to gather community feedback on technical Filecoin issues. These include changes to the Filecoin protocol, a change in block or transaction validity rules, and proposed application standards or conventions. They are then reviewed by the Filecoin community and the technical steering committee. They are normally followed by a PR to the [Filecoin Specification repository](https://github.com/filecoin-project/specs) to update the protocol's spec.\n\n**Organizational FIPs, or Filecoin Organization Proposals (FOPs)** allow the Filecoin community to propose, discuss, and achieve consensus on Filecoin governance. This includes procedures, guidelines, decision-making processes, and changes to FIP processes.\n\n**Recovery FIPs, or Filecoin Recovery Proposals (FRPs)** are intended to provide the Filecoin community with a forum to raise, discuss, and achieve consensus on fault recovery and chain rewrites, under a very limited, clearly-defined set of criteria (ex, in the case of protocol bugs destroying network value). The community will help define this process as needed in the coming months.\n\n## A decentralized, global network\n\nFilecoin is still in its infancy, but it has the potential to play a central role in the storage and distribution of humanity\u2019s information. To help the network grow and evolve, it is critical for the community to collectively be engaged in proposing, discussing, and implementing changes that improve the network and its operations. \n\nThis improvement protocol helps achieve that objective for all members of the Filecoin community (developers, miners, clients, token holders, ecosystem partners, and more). \n\n## FIPs\n\n|FIP #   | Title  | Type  | Author  | Status  |\n|---|---|---|---|---|\n|[0001](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0001.md)   | FIP Purpose and Guidelines  | FIP  | @Whyrusleeping  | Active  |\n|[0002](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0002.md)   | Free Faults on Newly Faulted Sectors of a Missed WindowPoSt  | FIP | @anorth, @davidad, @miyazono, @irenegia, @lucaniz, @nicola, @zixuanzh   |Final   |\n|[0003](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0003.md)   | Filecoin Plus Principles  | FIP  | @feerst, @jbenet, @jnthnvctr, @tim-murmuration, @mzargham, @zixuanzh  |Active   |\n|[0004](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0004.md)   | Liquidity Improvement for Storage Miners   | FIP  | @davidad, @jbenet, @zenground0, @zixuanzh, @danlessa   | Final  |\n|[0005](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0005.md)   | Remove ineffective reward vesting    | FIP  | @anorth, @Zenground   |Final   |\n|[0006](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0006.md)   | No repay debt requirement for DeclareFaultsRecovered  | FIP  |  @nicola, @irenegia  | Deferred  |\n|[0007](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0007.md)   | h/amt-v3  | FIP  | @rvagg, @Stebalien, @anorth, @Zenground0   |Final   |\n|[0008](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0008.md)   | Add miner batched sector pre-commit method  | FIP  |@anorth, @ZenGround0, @nicola  |Final   |\n|[0009](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0009.md)   | Exempt Window PoSts from BaseFee burn  | FIP  |@Stebalien, @momack2, @magik6k, @zixuanzh  |Final   |\n|[0010](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0010.md)   | Off-Chain Window PoSt Verification  | FIP  |@Stebalien, @anorth  |Final  |\n|[0011](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0011.md)   | Remove reward auction from reporting consensus faults  | FIP  |@Kubuxu |Final   |\n|[0012](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0012.md)   | DataCap Top up for FIL+ Client Addresses  | FIP  |@dshoy, @jnthnvctr, @zx |Final  |\n|[0013](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0013.md)   | Add ProveCommitSectorAggregated method to reduce on-chain congestion  | FIP  | @ninitrava @nicola |Final   |\n|[0014](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0014.md)   | Allow V1 proof sectors to be extended up to a maximum of 540 days | FIP  | @deltazxm, @neogeweb3 |Final   |\n|[0015](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0015.md)   | Revert FIP-0009(Exempt Window PoSts from BaseFee burn) | FIP  | @jennijuju, @arajasek |Final   |\n|[0016](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0016.md)   | Pack arbitrary data in CC sectors | FIP  | donghengzhao (@1475) |Deferred  |\n|[0017](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0017.md)   | Three-messages lightweight sector updates | FIP  |@nicole, @lucaniz, @irenegia |Deferred  |\n|[0018](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0018.md)   | New miner terminology proposal | FIP  |@Stefaan-V |Final  |\n|[0019](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0019.md)   | Snap Deals | FIP  |@Kubuxu, @lucaniz, @nicola, @rosariogennaro, @irenegia |Final  |\n|[0020](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0020.md)   | Add return value to WithdrawBalance | FIP  |@Stefaan-V |Final  |\n|[0021](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0021.md)   | Correct quality calculation on expiration | FIP  |@Steven004, @Zenground0 |Final  |\n|[0022](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0022.md)   | Bad deals don't fail PublishStorageDeals | FIP  |@Zenground0 |Final  |\n|[0023](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0023.md)   | Break ties between tipsets of equal weights | FIP  |@sa8, @arajasek |Final  |\n|[0024](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0024.md)   | BatchBalancer & BatchDiscount Post -Hyperdrive adjustment | FIP  |@zx, @jbenet, @zenground0, @momack2 |Final  |\n|[0025](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0025.md)   | Handle expired deals in ProveCommit | FIP  |@ZenGround0 |Deferred  |\n|[0026](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0026.md)   | Extend sector fault cutoff period from 2 weeks to 6 weeks | FIP  |@IPFSUnion |Final  |\n|[0027](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0027.md)   | Change type of DealProposal Label field from a (Golang) String to a Union | FIP  |@laudiacay, @Stebalien, @arajasek |Final  |\n|[0028](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0028.md)   | Remove DataCap and verified client status from client address | FIP  |@jennijuju, @dkkapur |Final  |\n|[0029](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0029.md)   | Beneficiary address for storage providers | FIP  |@steven004 |Final  |\n|[0030](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0030.md)   | Introducing the Filecoin Virtual Machine (FVM) | FIP  |@raulk, @stebalien |Final  |\n|[0031](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0031.md)   | Atomic switch to non-programmable FVM | FIP  |@raulk, @stebalien |Final  |\n|[0032](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0032.md)   | Gas model adjustment for non-programmable FVM | FIP  |@raulk, @stebalien |Final  |\n|[0033](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0033.md)   | Explicit premium for FIL+ verified deals | FIP  |@anorth |Deferred  |\n|[0034](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0034.md)   | Fix pre-commit deposit independent of sector content | FIP  |@anorth, @Kubuxu |Final |\n|[0035](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0035.md)   | Support actors as built-in storage market clients | FIP  |@anorth |Withdrawn  |\n|[0036](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0036.md)   | Introducing a Sector Duration Multiple for Longer Term Sector Commitment | FIP  |@AxCortesCubero, @jbenet, @misilva73, @momack2, @tmellan, @vkalghatgi, @zixuanzh |Rejected  |\n|[0037](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0037.md)   | Gas model adjustment for user programmability | FIP  |@raulk, @stebalien |Draft  |\n|[0038](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0038.md)   | Indexer Protocol for Filecoin Content Discovery | FRC  |@willscott, @gammazero, @honghaoq |Draft  |\n|[0039](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0039.md)   | Filecoin Message Replay Protection | FIP  |@q9f |Draft  |\n|[0040](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0040.md)   | Boost - Filecoin Storage Deals Market Protocol | FRC  |@dirkmc, @nonsense, @jacobheun, @brendalee |Draft  |\n|[0041](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0041.md)   | Forward Compatibility for PreCommit and ReplicaUpdate | FIP  |@Kubuxu |Final  |\n|[0042](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0042.md)   | Calling Convention for Hashed Method Name | FRC  |@Kubuxu, @anorth |Draft  |\n|[0044](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0044.md)   | Standard Authentication Method for Actors | FIP  |@arajasek, @anorth |Final  |\n|[0045](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0045.md)   | De-couple verified registry from markets | FIP  |@anorth, @zenground0 |Final  |\n|[0046](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0046.md)   | Fungible token standard | FRC  |@anorth, @jsuresh, @alexytsu |Draft  |\n|[0047](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0047.md)   | Proof Expiration & PoRep Security Policy | FIP  |@Kubuxu, @irenegia, @anorth |Accepted  |\n|[0048](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0048.md)   | f4 Address Class | FIP  |@stebalien, @mriise, @raulk | Final  |\n|[0049](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0049.md)   | Actor Events | FIP  |@stebalien, @raulk | Final  |\n|[0050](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0050.md)   | API Between User-Programmed Actors and Built-In Actors | FIP  |@anorth, @arajasek | Final  |\n|[0051](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0051.md)   | Synchronous Consistent Block Broadcast for EC Security | FRC  |Guy Goren <guy.goren@protocol.ai>, Alfonso de la Rocha <alfonso@protocol.ai> | Draft  |\n|[0052](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0052.md)   | Increase max sector commitment to 3.5 years | FIP  |@anorth | Accepted  |\n|[0053](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0053.md)   | Non-Fungible Token Standard | FRC  |@alexytsu, @abright, @anorth | Draft  |\n|[0054](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0054.md)   | Filecoin EVM Runtime (FEVM)  | FIP  |@raulk, @stebalien | Final  |\n|[0055](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0055.md)   | Supporting Ethereum Accounts, Addresses, and Transactions  | FIP  |@raulk, @stebalien | Final |\n|[0056](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0056.md)   | Sector Duration Multiplier  | FIP  | @AxCortesCubero, @jbenet, @misilva73, @momack2, @tmellan, @vkalghatgi, @zixuanzh | Rejected  |\n|[0057](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0057.md)   | Update Gas Charging Schedule and System Limits for FEVM  | FIP  |@raulk, @stebalien, @aakoshh, @kubuxu| Final  |\n|[0058](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0058.md)   | Verifiable Data Aggregation  | FRC  |Jakub Sztandera (@Kubuxu), Nicola Greco (@nicola), Peter Rabbitson (@ribasushi)| Draft  |\n|[0059](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0059.md)   | Synthetic PoRep  | FIP  |@Kubuxu @Luca @Rosario Gennaro @Nicola @Irene| Draft  |\n|[0060](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0060.md)   | Set market deal maintenance interval to 30 days  | FIP  |Jakub Sztandera (@Kubuxu), @Zenground0, Alex North (@anorth)| Accepted  |\n|[0061](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0061.md)   | WindowPoSt Grindability Fix  | FIP  |@cryptonemo @Kubuxu  @DrPeterVanNostrand @Nicola @porcuquine @vmx @arajasek| Accepted  |\n|[0062](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0062.md)   | Fallback Method Handler for the Multisig Actor  | FIP  |JDimitris Vyzovitis (@vyzo), Ra\u00fal Kripalani (@raulk)| Accepted  |\n", "release_dates": []}, {"name": "fungi", "description": "A distributed task runner", "language": "Go", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# fungi\n\nA very simple distributed task runner.\n\n\n# Architecture\n\nFungi is comprised of two main components, the coordinator, and the worker. A fungi coordinator is started up with a set of jobs to complete, and starts up a job server to serve those jobs to workers.\nFungi workers can run on any machine and connect to the coordinator over http. Once they start up they will issue a quick hello to handshake with the coordinator, and then will start requesting tasks, executing them, and returning the results.\n\n# Building\nJust run `make`.\n\n# Running\n\n## 1. Job Configuration\nFirst, you need to generate job files. Ideally this is an automated process, but you can also manually create the job files yourself. The job files should all be placed in the same directory, and follow the naming scheme of `sim-SIMNAME-job-JOBID.json`.\n\nThe files (as of writing) should look something like:\n```json\n{\n \"Cmd\": \"python\",\n \"Args\": [\"-c\", \"import time; time.sleep(20); print(\\\"1\\\")\"]\n}\n```\n\n## 2. Run Coordinator\nOnce you have your job files written, you can start up the coordinator.\n```\ncoord run --jobs-dir=/path/to/jobs/ --results-dir=/path/for/outputs/\n```\n\nThis will spin up the coordinator process and start the jobs server on port :5292\n\n## 3. Run Workers\nNow, you can run as many workers as you'd like, pointing them at your coordinator.\nThe worker binary is called 'spore'.\n```\nspore run http://localhost:5292\n```\n\n\n\n## License\nMIT\n\n", "release_dates": []}, {"name": "fuzzing-lotus", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Fuzzing tests for Lotus\n\nReceived from previous audit for version [v0.3.2](https://github.com/filecoin-project/lotus/releases/tag/v0.3.2), uploaded as is. It hasn't been reviewed in depth.\n\n* FIXME: Provide a simple description of the directory layout and how to use the fuzzer.\n", "release_dates": []}, {"name": "fvm-bench", "description": "Tools for testing and benchmarking FVM", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# fvm-bench\nTools for testing and benchmarking FVM\n\n## Status\n\nCurrently this is a program called `fvm-bench`, which allows you to execute and gas-benchmark\nfevm contracts.\n\nThis is a barebones MVP, it requires you to have checked out ref-fvm in a sibling directory\nin order to build.\n\nUsage:\n```\nRun a contract invocation for benchmarking purposes\n\nUsage: fvm-bench [OPTIONS] --bundle <BUNDLE> <CONTRACT> <METHOD> <PARAMS>\n\nArguments:\n  <CONTRACT>  Contract file\n  <METHOD>    Invocation method; solidity entry point for fevm, actor method for wasm\n  <PARAMS>    Invocation parameters, in hex\n\nOptions:\n  -m, --mode <MODE>      Execution mode: wasm or fevm [default: fevm]\n  -b, --bundle <BUNDLE>  Builtin actors bundle to use\n  -h, --help             Print help information\n```\n\nExample invocation:\n```\n$ ./target/debug/fvm-bench -b bundles/builtin-actors-next-3c902469.car ../builtin-actors/actors/evm/tests/contracts/SimpleCoin.bin f8b2cb4f 000000000000000000000000ff00000000000000000000000000000000000064\nContract invocation successfull\nResult: 0000000000000000000000000000000000000000000000000000000000002710\nGas Used: 2290168\n\n$ ./target/debug/fvm-bench -b bundles/builtin-actors-next-5a4b15b9.car ../builtin-actors/actors/evm/tests/contracts/SimpleCoin.bin f8b2cb4f 000000000000000000000000ff00000000000000000000000000000000000064\nContract invocation successfull\nResult: 0000000000000000000000000000000000000000000000000000000000002710\nGas Used: 2252508\n```\n", "release_dates": []}, {"name": "fvm-docs", "description": "Documentation and website build scripts for the Filecoin Virtual Machine (FVM) project.", "language": "HTML", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# THIS REPO IS ARCHIVED. SEE [DOCS.FILECOIN.IO](https://docs.filecoin.io) FOR FVM DOCS.\n\n<!-- HEADER -->\n[![Contributors][contributors-shield]][contributors-url]\n[![Forks][forks-shield]][forks-url]\n[![Issues][issues-shield]][issues-url]\n[![MIT License][license-shield]][license-url]\n\n<br>\n\n<picture align=center>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://user-images.githubusercontent.com/9611008/185500541-565c4d4d-660b-43e8-bc4e-00e9e8fb48b2.png\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://user-images.githubusercontent.com/9611008/185500539-e0a0e852-c3b6-452b-bc7c-fe2fd165fc15.png\">\n    <img alt=\"Shows a black logo in light color mode and a white one in dark color mode.\" src=\"https://user-images.githubusercontent.com/25423296/163456779-a8556205-d0a5-45e2-ac17-42d089e3c3f8.png\">\n</picture>\n\n<br>\n<br>\n\n<p align=\"center\"> This repository manages the documentation for the <a href=\"https://github.com/filecoin-project/fvm\">Filecoin Virtual Machine (FVM) project</a>. This repo also contains the build scripts and tools to create the FVM docs website and the API documentation. <a href=\"https://fvm.filecoin.io/docs\">Explore the docs \u2192</a></p>\n\n<!-- /HEADER -->\n\n\n\n<!-- TABLE OF CONTENTS -->\n## Table of contents\n\n- [Getting started](#getting-started)\n    - [Prerequisites](#prerequisites)\n    - [Installation](#installation)\n- [About the project](#about-the-project)\n    - [Files and folders](#files-and-folders)\n- [Contributing](#contributing)\n- [Issues](#issues)\n- [License](#license)\n- [Acknowledgments](#acknowledgments)\n<!-- /TABLE OF CONTENTS -->\n\n\n\n<!-- GETTING STARTED-->\n## Getting Started\n\nTo get a local version of the site up and running, follow these simple example steps.\n<!-- /GETTING STARTED-->\n\n\n\n<!-- PREREQUISITIES -->\n### Prerequisites\n\nTo run these commands, you must have [NPM installed](https://www.npmjs.com/). If you already have NPM installed, make sure you are running the latest version:\n\n```shell\nnpm install npm@latest -g\n```\n<!-- /PREREQUISITIES -->\n\n\n\n<!-- INSTALLATION -->\n### Installation\n\nFollow these steps to run a copy of this site on your local computer. \n\n1. Clone this repo:\n\n    ```shell\n    git clone https://github.com/filecoin-project/fvm-docs\n    ```\n\n1. Move into the new folder and download the dependencies:\n\n    ```shell\n    cd fvm-docs\n    npm install\n    ```\n\n1. Build the project and serve it locally using Hugo's built-in server:\n\n    ```shell\n    npm run build\n    ```\n\n1. Visit [localhost:1313](http://localhost:1313) to view the site.\n1. Press `CTRL` + `c` in the terminal to stop the local server.\n<!-- /INSTALLATION -->\n\n\n\n<!-- ABOUT THE PROJECT -->\n## About the project\n\n[![FVM Homepage][product-screenshot]](https://fvm.filecoin.io/)\n\nThis repository manages the documentation for the Filecoin Virtual Machine (FVM) project. This repo also contains the build scripts and tools to create the FVM docs website and the API documentation. If you want to learn about the FVM, how it works, or how to build on it, then you're in the right place.\n\n### Files and folders\n\nThis section lists the various files and folders and defines the purpose for each of them.\n\n| Name | Purpose |\n| --- | --- |\n| `.git`, `.github` | Manage the git configurations and contain information for GitHub constant integrations. |\n| `CONTRIBUTIONS.md` | A collection of guides on how to contribute to this repository. |\n| `README.md` | This file. Acts as an introduction to this repo, along with how to spin up a local copy of the `fvm.filecoin.io/docs` site. |\n| `archetypes/` | Used by Hugo to programmatically create new pages. |\n| `assets/` | Assets like JavaScript and fonts used by Hugo to create the static site. These assets are not explorable in a built site and must be referenced before the site is built. |\n| `babel.config.js` | A configuration file used for the Babel JS compiler. |\n| `config/` | Contains the configuration files for Hugo. Things like the topbar menu and site title can be managed within this directory. |\n| `content/` | This is where all the `.md` files live that control the content of this site. This is where most contributions happen. |\n| `data/` | Extra variables for Hugo to use when building pages can be supplied here. These variables act just like front-matter variables. See [Data Templates](https://gohugo.io/templates/data-templates/) in the Hugo docs for more info. |\n| `functions/` | Functions that can be called from any template, partial, or shortcode within Hugo. |\n| `i18n/` | Contains files specific to managing different languages. |\n| `images/` | Images that aren't displayed on the website but are present in the repo for things like the `README.md` or `CONTRIBUTIONS.md` guides. |\n| `layouts/` | This is where web developers will spend most of their time. This folder contains the shortcodes and partials that Hugo uses to scaffold and build the site. |\n| `/node_modules/` | Where NPM throws it's packages. If you see this in GitHub, something's gone wrong. It should only show up on your computer after you run `npm install`. |\n| `package-lock.json` | One of the NPM configuration files. Specifies which version of packages to download. |\n| `package.json` | Another one of the NPM configuration files. Specifies which packages to download but doesn't specify which _version_ of the package to grab.\n| `resources/` | A cache where Hugo throws generated files like CSS and JSON after `npm run build` has been called. Unless `npm run clean` is called, Hugo will re-use these files when calling `npm run build`. |\n| `static/` | Images, css, fonts, and other misc files available at `fvm.filecoin.io/` when the site is built. For example, `fvm.filecoin.io/site.webmanifest`.\n| `theme.toml` | A Hugo configuration file that specifies which theme to use. This file should not change that often. |\n<!-- /ABOUT THE PROJECT -->\n\n\n\n<!-- CONTRIBUTING -->\n## Contributing\n\nWant to help out? Pull requests (PRs) are always welcome! Check out `CONTRIBUTIONS.md` for more details on how you can help out. If you want to help out but aren't sure where to start, check out the [issues board](https://github.com/filecoin-project/fvm-docs/issues).\n<!-- /CONTRIBUTING -->\n\n\n\n<!-- ISSUES -->\n## Issues \n\nFound a problem with the FVM docs site? [Please raise an issue](https://github.com/filecoin-project/fvm-docs/issues/new). Be as specific and descriptive as possible; screenshots help.\n<!-- /ISSUES -->\n\n\n\n<!-- LICENSE -->\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the [Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n<!-- /LICENSE -->\n\n\n<!-- TODO\n## Contact\n\nProject Link: [https://github.com/filecoin-project/fvm-docs](https://github.com/filecoin-project/fvm-docs)\n-->\n\n\n\n<!-- ACKNOWLEDGMENTS -->\n## Acknowledgments\n\n- [Fleek](https://fleek.co) web hosting\n- [Hugo](https://gohugo.io) static site generator \n- [Doks](https://getdoks.org) starter theme \n<!-- /ACKNOWLEDGMENTS -->\n\n\n\n<!-- MARKDOWN LINKS & IMAGES -->\n[contributors-shield]: https://img.shields.io/github/contributors/filecoin-project/fvm-docs.svg?style=for-the-badge\n[contributors-url]: https://github.com/filecoin-project/fvm-docs/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/filecoin-project/fvm-docs.svg?style=for-the-badge\n[forks-url]: https://github.com/filecoin-project/fvm-docs/network/members\n[stars-shield]: https://img.shields.io/github/stars/filecoin-project/fvm-docs.svg?style=for-the-badge\n[stars-url]: https://github.com/filecoin-project/fvm-docs/stargazers\n[issues-shield]: https://img.shields.io/github/issues/filecoin-project/fvm-docs.svg?style=for-the-badge\n[issues-url]: https://github.com/filecoin-project/fvm-docs/issues\n[license-shield]: https://img.shields.io/badge/license-MIT-blueviolet?style=for-the-badge\n[license-url]: https://github.com/filecoin-project/fvm-docs/blob/master/LICENSE.txt\n[product-screenshot]: ./images/fvm-docs-homepage.png\n<!-- /MARKDOWN LINKS & IMAGES -->\n\n<!-- markdownlint-disable-file -->\n", "release_dates": []}, {"name": "fvm-evm", "description": "EVM runtime for the Filecoin Virtual Machine", "language": "Rust", "license": null, "readme": "# [ARCHIVED] Filecoin Virtual Machine EVM Actor prototype\n\n---\n>\n> ### This is a deprecated repo with historical relevance\n>\n> This repo is where the EVM actor for the Filecoin Virtual Machine was incubated.\n>\n> This actor was merged into builtin-actors in the following PR: https://github.com/filecoin-project/builtin-actors/pull/517\n>\n---\n\nThis is a very early stage of the project and this readme will evolve over time to include build and deployment instrustions.\n\n## Build to WASM\n\nIn the root of the project execute the following command:\n\n```sh\n$ make\n```\n\nIt should produce a wasm binary in `./wasm/fil_actor_evm.compact.wasm` that containst the EVM runtime actor in optimized release mode.\n\n## Running tests\n\nIn the root of the project execute the following command: \n\n```sh\n$ make test\n```\n\nit will compile all actors to wasm and then run them inside a simulated FVM environment and excercise all test cases.\n\n## Design Overview\n\n### Opcodes\n\nThe EVM runtime in this actor implement opcodes and their semantics as of the London hard fork.\n\n### Memory\n\nHandling of EVM `MSTORE`, `MLOAD` and `MSIZE` opcodes is implemented by the `Memory` module. This module is responsible for the volatile memory that is available only during contract execution and reclaimed afterwards by the system. \n\nThe basic unit of allocation is a _Page_ which is 64KB, to map 1:1 to WASM memory model of allocating memory in pages of 64KB. \n\nEvery contract execution context begins with one memory page allocated and it grows to more pages if the contract requests more memory than the current reserved amount.\n\nCurrently there is no limit on the EVM side on how much memory a contract may reserve. This is limited by the wasmtime configuration in FVM.\n\n### Persistance\n\nHandling of EVM `SSTORE` and `SLOAD` opcodes is implemented in terms of reads and writes to _IPLD Hamt_. EVM defines the concept of cold and warm memory access, where first access to a given address is considered cold that is more expensive and subsequent reads or writes to that memory address are considered warm and incur lower gas cost. This comes from [EIP-2930](https://eips.ethereum.org/EIPS/eip-2930). Filecoin does not have a notion of warm and cold storage access so this is kind of meaningless to us in general and is only kept there for now to keep EVM gas accounting accurate. This will likely go in future iterations and all state access will be treated equally.\n\nAll contract runtime state is persisted in a `Hamt::<_, U256, U256>` mapping and its root `Cid` is stored in the `state` field of the contract state. This Cid is conceptially equivalent to Ethereum's state root field of a contract account. This data structure may mutate throught contract's lifetime and the root Cid of the mapping gets updated after every successfull transaction that performed writes.\n\nBytecode is an immutable part of the state that is created in EVM runtime's constructor as a result of executing the init EVM bytecode in the creation transaction.\n\nAny change to the contract state will invoke `sself::set_root` and update the state tree roof of the contract actor. This syscall is called only once at the end of a successful non-reverted transaction.\n\nThe entire contract state is represented using the following structure:\n\n```rust\npub struct ContractState {\n  pub bridge: FilecoinAddress,\n  pub bytecode: Cid,\n  pub state: Cid,\n  pub self_address: H160,\n}\n```\n\nA reference to the bridge actor is stored in every EVM contract for resolving FIL addresses of other actors in cross-contract calls.\n\n\n### Platform Interface\n\n\n\n### Transactions\n\n### Addressing and Registry\n\nCurrently there is a component called _Registry_ that is responsible for translating EVM addresses to FVM addresses. EVM transactions and inter-contract calls must use EVM addresses which are the first 20 bytes of keccak hash of their secp256k1 public key. This is incompatible with Filecoin addresses that are first 20 bytes of Blake2B hash of the account public key.\n\nThe registry contains a _Hamt_ IPLD structure keyed by `H160` values (Eth address). Each key maps to the following structure:\n\n```rust\npub struct EthereumAccount {\n  pub nonce: u64,\n  pub balance: U256,\n  pub kind: AccountKind,\n}\n\npub enum AccountKind {\n  ExternallyOwned {\n    fil_account: Option<FileCoinAddress>,\n  },\n  Contract {\n    fil_account: FileCoinAddress\n  },\n}\n```\n\nExternally owned addresses don't always have a known mapping to their Filecoin equivalent. This mapping is discovered only once a transaction is issued from that account. This mapping discovery process relies on `ecrecover` to recover the public key used for sigining a transaction and then hasing it using _Blake2B_ to get a FIL address that is controlled by the same private key as the EVM account.\n\nContract accounts _always_ maps to a known FIL address because contract creation occurs on the registry and the robust address is returned by the EVM Runtime actor constructor.\n\nIn later iterations we are planning on removing the registry commonent and replace it with univeral addresses, but this is still under design and discussion.\n\n## Common Scenatios\n\n### Contract Deployment\n\n### Contract Invocation\n\n### Delegate Call\n\n### Cross Contract Calls\n", "release_dates": []}, {"name": "fvm-example-actors", "description": "A collection of actors, created and maintained by the FVM community.", "language": "Solidity", "license": null, "readme": null, "release_dates": []}, {"name": "fvm-runtime-experiment", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# FVM\n\nThe only interesting thing here right now is the SDK.\n", "release_dates": []}, {"name": "fvm-specs", "description": "home of the FVM (Filecoin Virtual Machine) project \u2699\ufe0f ", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# [ARCHIVED] Filecoin Virtual Machine spec notebook\n\n---\n>\n> ### This is a deprecated repo with historical relevance\n>\n> This repo is where the original design of the Filecoin Virtual Machine was originally incubated.\n>\n> The FVM shipped to Filecoin's mainnet in [Network Version 16 (Skyr upgrade)](https://filecoin.io/blog/posts/filecoin-v16-network-upgrade-skyr/).\n>\n> The final design of the FVM was formalized in [FIP-0030](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0030.md), its activation was proposed in [FIP-0031](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0031.md), and the new gas model was introduced in [FIP-0032](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0032.md).\n>\n> Today, most discussions and spec work take place in these venues:\n>\n> - **Early specification work, ideas, and design questions** are discussed in the [ref-fvm issue tracker](https://github.com/filecoin-project/ref-fvm/issues/). Technical design discussions and ideas can be found under these labels:\n>    - [`Kind: Discussion`](https://github.com/filecoin-project/ref-fvm/issues?q=is%3Aissue+label%3A%22Kind%3A+Discussion%22)\n>    - [`Kind: Idea`](https://github.com/filecoin-project/ref-fvm/issues?q=is%3Aissue+label%3A%22Kind%3A+Idea%22)\n> - **Formal protocol discussions** involving the community at large take place in the [Filecoin Improvement Proposals discussion forum](https://github.com/filecoin-project/FIPs/discussions).\n> - **Formal technical proposals** are submitted as [Filecoin Improvement Proposals](https://github.com/filecoin-project/FIPs), and are subject to the governance process on their path to being scheduled for \u2014and eventually released on\u2014 a network upgrade.\n\n---\n\nThis is the home of the FVM project in Filecoin.\n\n**Contents**\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n\n\n- [Context and goals](#context-and-goals)\n- [About this effort](#about-this-effort)\n- [About this repo](#about-this-repo)\n- [Document index](#document-index)\n- [Experiments](#experiments)\n- [License](#license)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n## Context and goals\n\n_See discussion in FIPs repo: https://github.com/filecoin-project/FIPs/issues/113_\n\nFilecoin today lacks general programmability. As a result, it is not possible to deploy user-defined behaviour, or \"smart contracts\", to the blockchain.\n\nThe closest thing that Filecoin has is a **discrete** set of **embedded** smart contracts, denominated [system \"actors\"](https://spec.filecoin.io/#section-systems.filecoin_vm.sysactors). They provide the logic for elements like storage power accounting, deal-making, payment channels, scheduled execution, and more. But their functionality is hardcoded as per the specs.\n\nThe goal of this project is to add general programmability to the Filecoin blockchain. We predict this will unleash a profileration of new services and tools that can be built and deployed to the Filecoin network, without requiring network upgrades, involvement from core implementation maintainers, changes in the embedded actors, or spec alterations.\n\nSmart contracts on Filecoin can bring huge benefits to both clients and providers \u2014 from unlocking \"repair providers\" that automate the process of repeat storage deals for programmatic \u201cfire and forget\u201d storage, to on-chain storage onboarding contracts (a la programmatic Slingshot), to collective DataDAOs that fund/monetize data on Filecoin.\n\nFurthermore, we aim for full EVM compatibility, allowing Filecoin to leverage the vast pool of assets, talent and tools that already exist in that ecosystem.\n\n**FVM (Filecoin Virtual Machine)** is the name of this project, as well as the name of the execution environment for smart contracts on the Filecoin blockchain.\n\n## About this effort\n\n<details><summary>Click to expand</summary>\nFVM unlocks major new network capabilities without requiring network upgrades, core dev implementation work, or any cross-team coordination - helping increase the network\u2019s iteration speed. However it will also *add* complexity to the protocol and needs a lot of design work to get it right.\n\nWe acknowledge that significant exploration/prototyping is necessary before ready to land. While this work is initiated by Protocol Labs, we rely on the vibrant Filecoin community to engage continuously, collaborate around ideas and designs, implement prototypes, test preview releases, build on it, come up with tooling, and ultimately, collectively own it and extend it.\n\nNote: landing FVM will likely also have significant network scalability impacts as well that will need to be mitigated.\n</details>\n\n## About this repo\n\n<details><summary>Click to expand</summary>\nThis repo acts as an entrypoint, hosting notes, design proposals, product ideas, and other documents related to this proejct.\n\nCode and prototypes will usually be hosted in separate repos, linked from here for discovery.\n\nThis repo will incubate the [FIP (Filecoin Improvement Proposal)](https://github.com/filecoin-project/FIPs) that shall formally introduce this capability into the network.\n</details>\n\n## Document index\n\n> \u26a0\ufe0f  These documents are being drafted.\n\n- [`00-introduction.md`](./00-introduction.md): summarizes vision, goals, assumptions, and requirements of this project.\n- [`01-architecture.md`](./01-architecture.md): details the proposed architecture.\n- [`02-state-of-the-art.md`](./02-state-of-the-art.md): analyses the state of the art concerning WASM+Blockchain, and concrete case studies of programmability in other blockchains.\n- [`03-impl-notes.md`](./03-impl-notes.md): notes on potential implementation.\n- [`04-evm-mapping.md`](./04-evm-mapping.md): EVM compatibility proposals and notes.\n- [`05-use-cases.md`](./05-use-cases.md): catalogue of brainstormed use cases the FVM should enable at some stage.\n- [`06-scalability-considerations.md`](./06-scalability-considerations.md): discusses the scalability considerations concerning state size, state churn, message/transaction throughput, etc.\n\n## Experiments\n\n- [FVM Runtime Experiment](https://github.com/filecoin-project/fvm-runtime-experiment)\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the\n[Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n", "release_dates": []}, {"name": "fvm-starter-kit-deal-making", "description": "Full dapp starter kit for automating Filecoin deal making", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Introduction\nWelcome to the fevm deal making kit! This kit has several tools to help enable you make storage deals on the Filecoin network via Solidity smart contracts. This kit assumes some knowledge at interacting with the Filecoin Virtual Machine (FVM). If you are new to the FVM, you may want to start with these starter kits instead:\n\n* [FEVM Hardhat Starter Kit](https://github.com/filecoin-project/fevm-hardhat-kit)\n* [FEVM Foundry Starter Kit](https://github.com/filecoin-project/fevm-foundry-kit)\n\nAlso have a look at this accompanying [Quickstart](https://pl-strflt.notion.site/Data-FVM-Getting-Started-with-the-Client-Contract-745e307f48a147148293aebace746c7f) that dives a bit deeper with the resources described in this repo.\n\nThe whole flow for deal making (from file upload to making a deal on FVM) is described here: \n\n![shapes (6) copy](https://user-images.githubusercontent.com/782153/224225887-1a546129-62b5-41e8-b98d-eb52fe35fac8.png)\n\n## Table of Contents\n+ [Using this Repo](#using-this-repo)\n+ [Data Prep](#1-data-prep)\n    - [Option A: Use FVM Tooling](#option-a-use-fvm-tooling)\n    - [Option B: Use the generate-car tool locally](#option-b-use-the-generate-car-tool-locally)\n+ [Creating a Deal Proposal Payload](#2-creating-a-deal-proposal-payload)\n+ [Calling the makeDealProposal method](#3-calling-the-makedealproposal-method)\n    - [Option A: Use the dapp frontend](#option-a-use-the-dapp-frontend)\n    - [Option B: Use the hardhat task](#option-b-use-the-hardhat-task)\n+ [Boost Provider Picks up Deal](#4-boost-provider-picks-up-deal)\n\n## Using this Repo\n\nGet started by typing in the following commands into your terminal/command prompt. This will clone the repo and all submodules, switch into the hardhat kit, and install packages: \n\n```bash\ngit clone https://github.com/filecoin-project/fvm-starter-kit-deal-making.git\ncd fvm-starter-kit-deal-making\nyarn install\n```\n\nAdd your private key as an environment variable by running this command, replacing the text *abcdef* with your private key:\n\n```bash\nexport PRIVATE_KEY='abcdef'\n```\n\nNow type in the following command to deploy the contracts in the kit:\n\n```bash\nyarn hardhat deploy\n```\nMake sure to record the address of where the `DealClient.sol` is deployed for later use.\n\nNow, edit the contract address for your frontend in [Input.js here](https://github.com/filecoin-project/fvm-starter-kit-deal-making/blob/main/frontend/src/components/Inputs.js#L11).\n\n## (1) Data Prep\n\nFiles need to be converted and prepped for storage on Filecoin. \n\nFor any file you want to upload you need to convert it to a .car file and obtain four pieces of information about this file. These are: \n\n* An https URL to the .car file so storage providers can download it. This is the `carLink`.\n\n* The size of the piece in bytes. This is the `piecesize`. \n\n* The DataCID of the original raw file. This is essentially a hash that represents the original file. This is known as the `commD` or sometimes the `label`.\n\n* The size of the CAR file that represents the file in bytes. This is known as the `carSize`.\n\n* The PieceCID of the file. This is essentially a hash that represents the .car file. This is also known as the `commP`.\n\n\n### Option A: Use FVM Tooling\n\nOne option is to go to the [FVM Data Depot](https://data.lighthouse.storage/), upload the file you want to store on Filecoin, and the tool will generate all the information we discussed. \n\n**Note**: The data depot is only meant as an intermediate step to get your data to the storage providers. It will hold your files for 30 days before the link to your car file expires. After this, storage providers will not be able to retrieve your file to store it more permanentaly.\n\n### Option B: Use the generate-car tool locally\n\nAnother option is to use the [`generate-car`](https://github.com/tech-greedy/generate-car) tool, written in the language Go, and included as a submodule within this repo.\n\nIf you are currently in this repo's directory, run these commands to switch into the proper directory and build the tool:\n\n```bash\ncd generate-car\nmake build\n```\n\nNow you can create a directory for the tools output and use the utility as follows:\n\n```bash\n$ mkdir out\n$ ./generate-car --single -i /path/to/file/A.txt -o out -p /path/to/file/\n```\n\nYou should get a json file that looks like this:\n```json\n{\"Ipld\":{\"Name\":\"\",\"Hash\":\"bafybeieawlmgtnb455ynra7kxyzipvhfxrms5yeuylr4w7dbpx7w4e6tqe\",\"Size\":0,\"Link\":[{\"Name\":\"shapes.png\",\"Hash\":\"bafybeigeisbcozxm7xyuf6vviijjg5fm2ptha2ciuyvjfdaedunhdfwsee\",\"Size\":1687130,\"Link\":null}]},\"DataCid\":\"bafybeieawlmgtnb455ynra7kxyzipvhfxrms5yeuylr4w7dbpx7w4e6tqe\",\"PieceCid\":\"baga6ea4seaqesm5ghdwocotmdavlrrzssfl33xho6xtrr5grwyi5gj3vtairaoq\",\"PieceSize\":2097152,\"CidMap\":{\"\":{\"IsDir\":true,\"Cid\":\"bafybeieawlmgtnb455ynra7kxyzipvhfxrms5yeuylr4w7dbpx7w4e6tqe\"},\"shapes.png\":{\"IsDir\":false,\"Cid\":\"bafybeigeisbcozxm7xyuf6vviijjg5fm2ptha2ciuyvjfdaedunhdfwsee\"}}}\n```\n\nNote that this results in a `PieceSize`, `PieceCID`, `DataCID` and `Size` is the `CarSize`. \n\nAs a result of the above, you should also get a `.car` file. You can upload this file to any http endpoint of your choice. Any example is using [Web3.storage](https://web3.storage/). Sign in, upload the `.car` file, click on the CID column, and once you get to the IPFS portal right click on the `Copy Link Location`. You should get a link that looks something like this: https://bafybeif74tokne4wvxsrcsxh6dhrzv6ys7mtifhwzaen7jfjuvltean32a.ipfs.w3s.link/ipfs/bafybeif74tokne4wvxsrcsxh6dhrzv6ys7mtifhwzaen7jfjuvltean32a/baga6ea4seaqesm5ghdwocotmdavlrrzssfl33xho6xtrr5grwyi5gj3vtairaoq.car\n\nThis link is `carLink` for your file.\n\n\n## (2) Creating a Deal Proposal Payload\n\nBecause of the way the client contract is set up, you need to prepare a deal proposal payload and call `makeDealProposal` with this payload. The payload consists of these solidity structs (which can be found [here in the Client Contract](https://github.com/filecoin-project/fevm-hardhat-kit/blob/main/contracts/basic-deal-client/DealClient.sol#L38)):\n\n\nHere is an example with these fields initialized:\n\n```javascript\n  const DealRequestStruct = [\n    \"baga6ea4seaqesm5ghdwocotmdavlrrzssfl33xho6xtrr5grwyi5gj3vtairaoq\", // pieceCID (Generated in previous step)\n    262144, // pieceSize (Generated in previous step)\n    false, // verifiedDeal (whether the deal has datacap or not)\n    \"baga6ea4seaqesm5ghdwocotmdavlrrzssfl33xho6xtrr5grwyi5gj3vtairaoq\", // DataCID (generated in previous step)\n    520000, // startEpoch (when you want the storage to start)\n    1555200, // endEpoch (when you want the storage to end)\n    0, // storagePricePerEpoch (how much attoFIL per GiB per 30s you are offering for this deal, set to 0 for a free deal)\n    0, // providerCollateral (how much collateral the provider must put up for the deal)\n    0, // clientCollateral (how much collateral you, the client, must put up for the deal)\n    1, // extraParamsVersion (set to 1)\n    extraParamsV1, // see below\n  ];\n\n    const extraParamsV1 = [\n    \"https://bafybeif74tokne4wvxsrcsxh6dhrzv6ys7mtifhwzaen7jfjuvltean32a.ipfs.w3s.link/ipfs/bafybeif74tokne4wvxsrcsxh6dhrzv6ys7mtifhwzaen7jfjuvltean32a/baga6ea4seaqesm5ghdwocotmdavlrrzssfl33xho6xtrr5grwyi5gj3vtairaoq.car\", // carLink (Generated in previous step)\n    236445, // carSize (Generated in previous step).\n    false, // skipIpniAnnounce (whether or not the deal should be announced to IPNI indexers, set to false)\n    false, // removeUnsealedCopy (whether or not the storage provider should remove an unsealed copy. Set to false)\n  ];\n```\n\n## (3) Calling the makeDealProposal method\n\n\n\n### Option A: Use the dapp frontend\n\nTake the four outputs of part (I) and put each into the four fields of the [frontend in this repo](https://github.com/filecoin-project/fvm-starter-kit-deal-making/tree/main/frontend). \n\nOnce the deal handshake is completed (described more in part III), you should be able to see the deal ID for this transaction in Filfox on the frontend. Here is a previous example of a DealID submitted through the frontend: https://calibration.filfox.info/en/deal/1016\n\n### Option B: Use the hardhat task\n\nYou can also call the method by running the make-deal-proposal task. Below is an example of how to run the task. Make sure to replace any values with your own.\n\n```bash\nyarn hardhat make-deal-proposal --contract 0xD4aac4D8fBc7575bDf5C19f900634d6c61a00a79 --piece-cid baga6ea4seaqayn6kwvhnajfgec2qakj7vb5aeqisbbnojunowdyapkdfcyhzcpy --piece-size 262144 --verified-deal false --label \"baga6ea4seaqayn6kwvhnajfgec2qakj7vb5aeqisbbnojunowdyapkdfcyhzcpy\" --start-epoch 520000 --end-epoch 1555200 --storage-price-per-epoch 0 --provider-collateral 0 --client-collateral 0 --extra-params-version 1 --location-ref \"https://data-depot.lighthouse.storage/api/download/download_car?fileId=005b377e-89a6-44c6-aa04-871509019bec.car\" --car-size 194875 --skip-ipni-announce false --remove-unsealed-copy false\n```\n\n## (4) Boost Provider Picks up Deal\n\nThe Client Contract (CC) is built to interact with Boost SPs and generate deals on behalf of a client, entirely on-chain.\n\nThe CC primarily interacts with the Boost SPs through an event known as `DealProposalCreate`, which looks like this:\n\n```solidity\nevent DealProposalCreate(\n    bytes32 indexed id,\n    uint64 size,\n    bool indexed verified,\n    uint256 price\n);\n```\n\nThe payload we generated earlier is then picked up by the storage provider.\n\nThe overall flow is a push-pull mechanism. The CC \"pushes\" a `DealProposalCreate` event onto the FVM event log, which is watched by Boost SPs. SPs look for `DealProposalCreate` events that interest them (they can filter by price, verified state and size). They then ask the CC to provide them the `DealProposal` payload. Data transfer can begin. SPs can also publish the deal by submitting a PublishStorageDeal message on-chain with the fields in the DealProposal payload.\n\nSee the diagram of this information here:\n\n![shapes (6) copy](https://user-images.githubusercontent.com/782153/224235188-f1b2ecfc-c88b-4efb-9896-b90ec5c3152f.png)\n\nIn summary, the \"front-end\" of the CC interacts with the contract, and takes in a deal proposal payload. The \"back-end\" of the CC interacts with the Boost SP in order to generate the deal, as well as in order to authenticate the deal. \n\nNote that we have a few active threads and FRCs where the client contract is being discussed: \n - [Our latest FRC draft, WIP](https://www.notion.so/WIP-Deal-Client-Contract-FRC-458e625f13b14c70bfdfe7ed64007b6c)\n - [FIP discussion 604](https://github.com/filecoin-project/FIPs/discussions/604)\n - [Boost discussion 1160](https://github.com/filecoin-project/boost/discussions/1160)\n", "release_dates": []}, {"name": "fvm-test-vectors", "description": "Test vectors for WASM-based FVM implementations", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Test vectors for FVM implementations\n\nThe Filecoin Virtual Machine is WASM-based polyglot virtual machine that\nintroduces the ability to deploy user-specified smart contracts to the\nFilecoin network. For more information, refer to [filecoin-project/fvm-project](https://github.com/filecoin-project/fvm-project/).\n\nThis repository follows the steps of the original [filecoin-project/test-vectors](https://github.com/filecoin-project/test-vectors/),\nbut containing test vectors that specifically target the FVM. We expect\nthe corpus in `filecoin-project/test-vectors` to become deprecated in favour of\nthe corpus herein when the non-programmable VM is replaced with the FVM on mainnet.\n\nThe FVM hosts builtin actors (e.g. power actor, miner actors, market actor)\nas WASM modules. **Only v6+ actors and network versions 14+ are supported.**\n\nBecause of that, the corpus in this repo is bootstrapped with actors v6 vectors.\n\n## Structure and schema\n\nThe structure of this repo and the test vector schema are identical to those in\n[filecoin-project/test-vectors](https://github.com/filecoin-project/test-vectors/).\n\n## License\n\nDual-licensed under\n[MIT](https://github.com/filecoin-project/fvm-test-vectors/blob/master/LICENSE-MIT) +\n[Apache 2.0](https://github.com/filecoin-project/fvm-test-vectors/blob/master/LICENSE-APACHE).", "release_dates": []}, {"name": "fvm-wasm-instrument", "description": "Instrument and transform wasm modules.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# fvm-wasm-instrument\n\nThis started as a [wasm-instrumet](https://github.com/paritytech/wasm-instrument) with some FVM specific changes, but has since been significantly refactored to move away from parity-wasm which reached EOL.\n\nfvm-wasm-instrument is a Rust library containing a collection of WASM module instrumentations and\ntransformations mainly useful for wasm based block chains and smart contracts.\n\n## Provided functionality\n\nThis library provides two features:\n\n- Gas metering.\n- Stack height limiting.\n\n### Gas Metering\n\nAdd gas metering to your platform by injecting the necessary code directly into the wasm module. This allows having a uniform gas metering implementation across different execution engines (interpreters, JIT compilers).\n\n### Stack Height Limiter\n\nNeither the wasm standard nor any sufficiently complex execution engine specifies how many items on the wasm stack are supported before the execution aborts or malfunctions. Even the same execution engine on different operating systems or host architectures could support a different number of stack items and be well within its rights.\n\nThis is the kind of indeterminism that can lead to consensus failures when used in a blockchain context.\n\nTo address this issue we can inject some code that meters the stack height at runtime and aborts the execution when it reaches a predefined limit. Choosing this limit suffciently small so that it is smaller than what any reasonably parameterized execution engine would support solves the issue: All execution engines would reach the injected limit before hitting any implementation specific limitation.\n\n## License\n\n`fvm-wasm-instrument` is distributed under the terms of both the MIT license and the\nApache License (Version 2.0), at your choice.\n\nSee LICENSE-APACHE, and LICENSE-MIT for details.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in `fvm-wasm-instrument` by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n", "release_dates": []}, {"name": "fvm-workbench", "description": "Tooling for developing actors on the FVM", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# FVM Workbench\nThis repo provides a stand-alone Filecoin Virtual Machine, i.e. one that runs without needing\na full Filecoin node like Lotus.\nThis supports running native (i.e. WASM) actors in a controlled environment,\nand includes tools for analysis of execution traces.\nA conventional log message format supports the notion of trace spans, \nallowing fine-grained analysis of gas consumption.\n\nThe repo also provides an abstraction over the VM implementation that can be implemented by\na proxy or light-weight fake VM.\nThis allows test scripts to be written that do not depend on the FVM directly,\nindependent even of compiling the actors to WASM.\nSuch tests can be executed quickly and with first-class debugging support with a fake VM that\nuses the high level language's native debugging tools (e.g. Rust).\nThen exactly the same test can be executed on a real VM for gas analysis.\n\n## Crates\nThe repo is divided into several crates in order to limit dependencies.\n\n### `api`\nThe `api` crate provides an API for setting up a VM and executing messages.\nThe crate does not depend on an FVM implementation, \nonly the shared libraries commonly used by actors.\nThis crate can thus be imported directly into actor repositories, \nand integration tests written there without introducing a dependency on the full FVM.\n\n### `vm`\nThe `vm` crate implements the API in terms of a real FVM,\nimported from the reference implementation.\nIt provides methods to initialise the VM and install actors that make \nas few assumptions as possible about how you want to use it.\nThis crate does not depend on the built-in actors implementation, \nbut users will need to install built-in actors for the VM to function.\n\n*For Apple-silicon Macs* you will need the following in `.cargo/config.toml` in order to compile\nthe proof crates.\n\n```\n[build]\ntarget = \"x86_64-apple-darwin\"\n```\n\n### `builtin`\nThe `builtin` crate depends on the built-in actors implementation \nand provides methods for establishing initial state in a VM, which depends on the actors in use.\nThe `builtin/tests/hookup.rs` \"test\" demonstrates initialisation and use with the `vm` crate.\n\nThis crate is intended to also directly execute the integration tests\nimported from the built-in actors repo, once those tests are adapted to the API provided above.\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2022-2023. Protocol Labs, Inc.", "release_dates": []}, {"name": "gb-filecoin-docs", "description": null, "language": null, "license": null, "readme": "---\ndescription: >-\n  This section aims to provide a comprehensive overview of Filecoin to\n  developers and serves as a reference that developers can check back on.\n---\n\n# What is Filecoin\n\nFilecoin is a peer-to-peer network that stores files, with built-in economic incentives and cryptography to ensure files are stored reliably over time. In Filecoin, users pay to store their files on storage providers. Storage providers are computers responsible for storing files and proving they have stored them correctly over time. Anyone who wants to store their files or get paid for storing other users\u2019 files can join Filecoin. Available storage, and the price of that storage, are not controlled by any single company. Instead, Filecoin facilitates open markets for storing and retrieving files that anyone can participate in.\n\nFilecoin is built on top of the same software powering [IPFS protocol](https://docs.ipfs.tech/), which is a peer-to-peer distributed storage network that leverages [content addressing](https://docs.ipfs.tech/concepts/content-addressing/) to allow permanent references to the data, and avoids relying on specific devices or cloud servers for addressing the content. Filecoin is different from IPFS because it has an incentive layer on top to incentivize contents to be reliably stored and accessed.\n\nFilecoin enables several use cases, from Web3 native NFT and metaverse/game assets storage, incentivized permanent storage, to archiving Web2 datasets as a cheaper alternative to cloud storage. For example, [NFT.Storage](https://nft.storage/) utilizes Filecoin to provide a simple decentralized storage solution for NFT contents and metadata, while [Shoah Foundation](https://sfi.usc.edu/) and [Internet Archive](https://archive.org/) leverages Filecoin to backup their contents. Filecoin also supports a wide range of formats of data, including audio and video files, allowing Web3 platforms such as [Audius](https://audius.co/) and [Huddle01](https://huddle01.com/) to leverage Filecoin as the decentralized storage backend for music streaming and video conferencing.\n", "release_dates": []}, {"name": "github-exporter", "description": ":octocat: Prometheus exporter for github metrics", "language": "Go", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Prometheus GitHub Exporter\n\nExposes basic metrics for your repositories from the GitHub API, to a Prometheus compatible endpoint.\n\n## Configuration\n\nThis exporter is setup to take input from environment variables. All variables are optional:\n\n* `ORGS` If supplied, the exporter will enumerate all repositories for that organization. Expected in the format \"org1, org2\".\n* `REPOS` If supplied, The repos you wish to monitor, expected in the format \"user/repo1, user/repo2\". Can be across different Github users/orgs.\n* `USERS` If supplied, the exporter will enumerate all repositories for that users. Expected in\nthe format \"user1, user2\".\n* `GITHUB_TOKEN` If supplied, enables the user to supply a github authentication token that allows the API to be queried more often. Optional, but recommended.\n* `GITHUB_TOKEN_FILE` If supplied _instead of_ `GITHUB_TOKEN`, enables the user to supply a path to a file containing a github authentication token that allows the API to be queried more often. Optional, but recommended.\n* `API_URL` Github API URL, shouldn't need to change this. Defaults to `https://api.github.com`\n* `LISTEN_PORT` The port you wish to run the container on, the Dockerfile defaults this to `9171`\n* `METRICS_PATH` the metrics URL path you wish to use, defaults to `/metrics`\n* `LOG_LEVEL` The level of logging the exporter will run with, defaults to `debug`\n\n\n## Install and deploy\n\nRun manually from Docker Hub:\n```\ndocker run -d --restart=always -p 9171:9171 -e REPOS=\"filecoin-project/github-exporter, filecoin-project/lotus\" filecoin-project/github-exporter\n```\n\nBuild a docker image:\n```\ndocker build -t <image-name> .\ndocker run -d --restart=always -p 9171:9171 -e REPOS=\"filecoin-project/github-exporter, filecoin-project/lotus\" <image-name>\n```\n\n## Docker compose\n\n```\ngithub-exporter:\n    tty: true\n    stdin_open: true\n    expose:\n      - 9171\n    ports:\n      - 9171:9171\n    image: filecoin-project/github-exporter:latest\n    environment:\n      - REPOS=<REPOS you want to monitor>\n      - GITHUB_TOKEN=<your github api token>\n\n```\n\n## Metrics\n\nMetrics will be made available on port 9171 by default\nAn example of these metrics can be found in the `METRICS.md` markdown file in the root of this repository\n\n## Tests\n\nThere is a set of blackbox behavioural tests which validate metrics endpoint in the `test` directory. \nRun as follows\n\n```bash\nmake test\n```\n\n## Version Release Procedure\nOnce a new pull request has been merged into `master` the following script should be executed locally. The script will trigger a new image build in docker hub with the new image having the tag `release-<version>`. The version is taken from the `VERSION` file and must follow semantic versioning. For more information see [semver.org](https://semver.org/).\n\nPrior to running the following command ensure the number has been increased to desired version in `VERSION`: \n\n```bash\n./release-version.sh\n```\n", "release_dates": []}, {"name": "gitops-profile-catalog", "description": null, "language": "Smarty", "license": null, "readme": "# gitops-profile-catalog\n\nProfiles Catalog contains a curated list of profiles for various use cases. A profile is an individual package of Kubernetes components. \n\nNeed more information about profiles? Please visit [Profiles Documentation](https://docs.gitops.weave.works/docs/cluster-management/profiles).\n", "release_dates": ["2023-09-20T17:17:24Z", "2023-05-17T17:52:53Z", "2023-05-17T17:29:11Z", "2023-04-25T12:01:32Z", "2023-03-16T14:46:00Z", "2023-03-13T19:07:45Z", "2023-03-09T21:58:00Z", "2023-03-09T21:45:01Z", "2023-03-09T21:32:12Z", "2023-03-09T21:26:01Z", "2023-03-09T21:57:59Z", "2023-03-09T21:44:59Z", "2023-03-09T21:32:10Z", "2023-03-09T21:22:05Z", "2023-02-16T18:43:16Z", "2023-02-16T18:43:14Z", "2023-02-16T18:43:13Z", "2023-01-11T23:30:37Z", "2023-01-11T23:30:36Z", "2023-01-11T23:30:35Z", "2023-01-11T23:30:33Z", "2023-01-06T20:48:34Z", "2023-01-06T20:04:52Z", "2023-01-06T19:27:58Z", "2023-01-06T19:27:57Z", "2022-12-14T21:39:40Z", "2022-12-14T21:39:38Z", "2022-12-09T23:33:57Z", "2022-12-09T22:44:49Z", "2022-12-09T22:26:49Z"]}, {"name": "go-address", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-address\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-address.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-address)\n[![codecov](https://codecov.io/gh/filecoin-project/go-address/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-address)\n\nThe filecoin address type, used for identifying actors on the filecoin network, in various formats.\n\n## Install\n\nInstall this library with `go mod`\n\n## Usage\n\nAddresses support various types of encoding formats and have constructors\nfor each format\n\n```golang\n// address from ID\nidAddress := NewIDAddress(id)\n// address from a secp pub key\nsecp256k1Address := NewSecp256k1Address(pubkey)\n// address from data for actor protocol\nactorAddress := NewActorAddress(data) \n// address from the BLS pubkey\nblsAddress := NewBLSAddress(pubkey)\n```\n\nSerialization\n\n```golang\nvar outBuf io.writer\nerr := address.MarshalCBOR(outbuf)\nvar inBuf io.reader\nerr := address.UnmarshalCBOR(inbuf)\n```\n\n## Project-level documentation\nThe filecoin-project has a [community repo](https://github.com/filecoin-project/community) that documents in more detail our policies and guidelines, such as discussion forums and chat rooms and  [Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md).\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019. Protocol Labs, Inc.\n", "release_dates": ["2022-06-08T16:28:38Z", "2020-09-25T19:00:38Z", "2020-02-07T12:27:19Z"]}, {"name": "go-amt-ipld", "description": "Implementation of an array mapped trie using go and ipld", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-amt-ipld\n\n> Array Mapped Trie (Persistent Vector) implementation using go-ipld\n\n**This package is a reference implementation of the IPLD AMT used in the\nFilecoin blockchain.**\n\nAMT is an array mapped trie, suitable for storing large arrays, including\nsparse arrays.\n\n**See https://godoc.org/github.com/filecoin-project/go-amt-ipld for more\n information and API details\n\n## License\n\nDual MIT and Apache 2\n", "release_dates": ["2022-10-14T06:22:11Z", "2021-06-22T18:34:53Z", "2021-05-24T22:27:50Z"]}, {"name": "go-bitfield", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-bitfield\n\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-bitfield.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-bitfield)\n[![standard-readme compliant](https://img.shields.io/badge/standard--readme-OK-green.svg?style=flat-square)](https://github.com/RichardLitt/standard-readme)\n\n> Advanced RLE+ implementation\n\nFeatures iterator based primitives that scale with number of runs instead of number of bits.\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/go-bitfield/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/go-bitfield/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": ["2020-11-06T19:14:53Z"]}, {"name": "go-bls-sigs", "description": null, "language": "Go", "license": null, "readme": "# Go Binding for BLS Signatures\n", "release_dates": []}, {"name": "go-bs-lmdb", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "!!! WARNING: This package is not stable and may cause random crashes or data corruption in your application if used.\n\n# go-bs-lmdb\n\nAn LMDB-backed [IPFS Blockstore](https://github.com/ipfs/go-ipfs-blockstore/).\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the\n[Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n", "release_dates": ["2021-07-06T23:30:17Z", "2021-06-04T10:49:03Z", "2021-02-11T17:30:43Z", "2021-01-26T19:28:36Z", "2021-01-25T17:15:27Z", "2021-01-20T18:45:32Z", "2020-12-01T16:38:10Z"]}, {"name": "go-bs-postgres-chainnotated", "description": " IPFS Blockstore backed by a PostgreSQL RDBMS coupled with a write-through RAM cache", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-bs-postgres-chainnotated\n\nThis module implements an [IPFS Blockstore](https://github.com/ipfs/go-ipfs-blockstore/) backed by a combination of a PostgreSQL RDBMS coupled with a write-through RAM cache. A number of augmentations make this suitable as a massive-scale blockstore ( e.g. for something like the Filecoin blockchain ).\n\n### Notable differences/improvements overa standard blockstore are:\n  - Everything is keyed by complete CIDs instead of multihash\n  - Block-data is transparently stored zstd-compressed where sensible\n  - There is ability to efficiently record and query DAG-forming block relationships directly in the database\n  - If configured with an instance namespace, keeps a log of recently-accessed blocks, which is then used to bulk-load blocks into the LRU cache on cold-starts\n  - Has a mode tracking every Read/Write with millisecond precision\n  - Ability to track filecoin-chain specific changes in real time\n", "release_dates": []}, {"name": "go-cbor-util", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-cbor-util\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-cbor-util.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-cbor-util)\n[![codecov](https://codecov.io/gh/filecoin-project/go-cbor-util/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-cbor-util)\n\nCBOR utilities for reading and writing objects to CBOR representation, optimizing for fast path serialization/deserialization generated by cbor-gen\n\n## Install\n\nInstall this library with `go mod`\n\n## Usage\n\nWrite an object to a stream in cbor\n\n```golang\nimport (\n  cborutil \"github.com/filecoin-project/go-cbor-util\"\n  cbg \"github.com/whyrusleeping/cbor-gen\"\n)\n\nvar w io.Writer\n// some object type with cbg fastpath marshalling\nvar out cbg.CBORMarshaler\nerr := cborutil.WriteCborRPC(w, obj)\n\nvar slow interface{}\n// will work but will be slower if slow does not support fast path marshalling\nerr := cborutil.WriteCborRPC(w, slow)\n```\n\nRead an object form a stream in cbor\n\n```golang\nimport (\n  cborutil \"github.com/filecoin-project/go-cbor-util\"\n  cbg \"github.com/whyrusleeping/cbor-gen\"\n)\n\nvar r io.Reader\n// some object type with cbg fastpath marshalling\nvar out cbg.CBORUnmarshaler\nerr := cborutil.ReadCborRPC(r, obj)\n\nvar slow interface{}\n// will work but will be slower if slow does not support fast path unmarshalling\nerr := cborutil.ReadCborRPC(r, slow)\n```\n\n## Project-level documentation\nThe filecoin-project has a [community repo](https://github.com/filecoin-project/community) that documents in more detail our policies and guidelines, such as discussion forums and chat rooms and  [Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md).\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019. Protocol Labs, Inc.\n", "release_dates": ["2021-08-18T17:39:00Z"]}, {"name": "go-cid-tools", "description": "Tools for working with CIDs", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# go-cid-tools\nTools for working with CIDs\n", "release_dates": []}, {"name": "go-commp-utils", "description": "Utilities for working with CommP", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-commp-utils\n\nUtilities for generating and working with CommP for Filecoin pieces\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/go-padreader/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/go-padreader/blob/master/LICENSE-APACHE)\n", "release_dates": ["2022-11-07T20:21:05Z", "2021-10-15T02:37:50Z", "2021-08-18T17:09:13Z", "2021-03-27T09:10:43Z"]}, {"name": "go-crypto", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-crypto\n\nCrypto utility functions used in filecoin\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019. Protocol Labs, Inc.\n", "release_dates": ["2021-08-18T17:45:15Z"]}, {"name": "go-dagaggregator-unixfs", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "go-dagaggregator-unixfs\n=======================\n\n> A stateless aggregator for organizing arbitrary IPLD dags within a UnixFS hierarchy\n\n[![GoDoc](https://godoc.org/github.com/filecoin-project/go-dagaggregator-unixfs?status.svg)](https://pkg.go.dev/github.com/filecoin-project/go-dagaggregator-unixfs)\n[![GoReport](https://goreportcard.com/badge/github.com/filecoin-project/go-dagaggregator-unixfs)](https://goreportcard.com/report/github.com/filecoin-project/go-dagaggregator-unixfs)\n\nThis library provides functions and convention for aggregating multiple\narbitrary DAGs into a single superstructure, while preserving sufficient\nmetadata for basic navigation with pathing [IPLD selectors][1].\n\n# Typical use case\n\nUsers who want to store relatively small ( below about 8GiB ) DAGs on Filecoin\noften find it difficult to have their deal accepted, even in the presence of\nFil+. A solution to this is grouping the root CIDs of multiple non-related DAGs\ninto an \"aggregate structure\" which is then used to make a deal with a specific\nminer. Naturally the resulting structure will have a new root CID, which\ncomplicates both discovery and retrieval. Additionally certain limits need to be\nrespected otherwise such a structure can become unwieldy in other IPLD contexts\nlike IPFS.\n\nThis library provides basic solutions to the above problems.\n\n# Spec\n\nThe test-fixture demonstrating everything below can be found at https://dweb.link/ipfs/bafybeib62b4ukyzjcj7d2h4mbzjgg7l6qiz3ma4vb4b2bawmcauf5afvua\n\n## Grouping UnixFS structure\n\nA \"dag aggregation\" UnixFS directory has the following structure:\n- The first entry is a manifest file in [ND-JSON](http://ndjson.org/) format (detailed in next section)\n- Every CID is represented as base32 CIDv1. Any `Qm...` CIDv0, is upgraded to CIDv1 as this operation is lossless.\n- For browseability/recognizeability purposes, and to stay within bitswap limits, the **leading** 3 characters of a CIDv1 are combined with the 2 and 4 trailing characters for each directory sublevel, based on the calculations in the `Limits` section below.\n\nThis means a directory looking roughly like:\n```\n- bafyAggregateRootCid\n  - @AggregateManifest.ndjson\n  - baf...aa\n    - baf...aaaa\n    - baf...abaa\n    \u2026\n    - baf...77aa\n  - baf...ab\n    - baf...aaab\n    \u2026\n    - baf...77ab\n  \u2026\n  - baf...77\n    - baf...7777\n        - bafymbzacid777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777\n```\n\n## Manifest format\n\nThe Aggregate Manifest is an [ND-JSON](http://ndjson.org/) file comprised of 3 types of records.\n\n### Preamble\n\nThis is always the first record of the manifest, it signals how to parse the\nrest of the manifest.\n```\n{\n  \"RecordType\": \"DagAggregatePreamble\",\n  \"Version\": 1\n}\n```\n\n### Summary\n\nThis is the second record within the manifest. Has entry count and various other\nmetadata.\n```\n{\n  \"RecordType\": \"DagAggregateSummary\",\n  \"EntryCount\": 4,\n  \"EntriesSortedBy\": \"DagCidV1\",\n  \"Description\": \"Aggregate of non-related DAGs, produced by github.com/filecoin-project/go-dagaggregator-unixfs\"\n}\n```\n\n### Individual DAG Entries\n\nThe rest of the manifest records contain information about the included DAGs, one\nper record.\n\n```\n{\n  \"RecordType\": \"DagAggregateEntry\",\n  \"DagCidV1\": \"bafybeibhbx3y6tnn7q4gpsous6apnobft5jybvroiepdsmvps2lmycjjxu\",\n  \"DagCidV0\": \"QmQy6xmJhrcC5QLboAcGFcAE1tC8CrwDVkrHdEYJkLscrQ\",\n  \"DagSize\": 42,\n  \"NodeCount\": 1,\n  \"PathPrefixes\": [ \"baf...xu\", \"baf...jjxu\" ],\n  \"PathIndexes\": [ 2, 0, 0 ]\n}\n```\n\n`PathPrefixes` contains the parent directories for this particular DAG, based on the chosen parts of the target CID. They currently can be derived from `DagCIDV1`, but are included for ease of navigation.\n\n`PathIndexes` contains the 0-based position of each entry within its\ncorresponding parent directory. It is provided to make partial retrievals possible\nwith simple pathing selectors [as described in this lotus changeset](https://github.com/filecoin-project/lotus/pull/6393#issue-661783290)\n\n## Limits in consideration\n- A car file accepted by the Filecoin network currently can have a maximum payload size of about 65,024MiB ( 64<<30 / 128 * 127 ). For the sake of argument let's assume a future with 128GiB sectors, which gives an exact maximum payload size of 136,365,211,648 bytes. Assuming ~60 bytes for a car header, **shortest safe CID** representation of a CIDv0 sha2-256 at 34 bytes, and payload of 1024 bytes per block ( ridiculously small NFTs ), gives us an upper bound of (136365211648 - 60) / ( 2 + 34 + 1024) ~~ 128,646,426 ~~ an upper bound of 2^27 individual CIDs that could be in a deal and all be individually addressable.\n\n- The **longest textual representation** of a \"tenuously common\" CID would be a `b`-multibase base32 representation of a [blake2b-512](https://cid.ipfs.io/#bafymbzacid777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777), which clocks at 113 bytes. This in turn means that a typical UnixFS directory can contain:\n1048576 = ( 4b dir hdr ) + N * ( 2b pbframe hdr + 2b CID prefix + 70b CID + 2b name prefix + 113b text-CID + ~5 bytes for prefixed size ) ~~ 5405 such names without sharding, before going over the 1MiB libp2p limit. In order to be super-conservative assume a target of 2^12 entries per \"aggregate shard\". If we go with the more reasonable 256-bit hashes, we arrive at ~9363 names which translates to 2^13 entries per shard.\n\n- The common textual representation of CIDs is base32, each character of which represents exactly 5 bits. This means that sharding on 2 base32 characters gives a rough distribution of 2^10 per shard, fitting comfortably within the above considerations.\n\nThe limits described above, combined with the perfect distribution of hashes\nwithin CIDs, means that one can safely store a \"super-sector\" full of\naddressable CIDs by having 2 layers of directories, the first layer \"sharded\" by\n2 base32 characters, the second layer by 4 base32 characters, and the final\ncontainer having the full CIDs pointing to the content: 2^(10+10+10) > 2^(27).\nThis does not even take into account the vast overestimation of sector and CID\nsizes.\n\n## Lead Maintainer\n\n[Peter Rabbitson](https://github.com/ribasushi)\n\n## License\n\n[SPDX-License-Identifier: Apache-2.0 OR MIT](LICENSE.md)\n\n[1]: https://pkg.go.dev/github.com/ipld/go-ipld-prime/traversal/selector\n", "release_dates": ["2021-08-29T13:07:04Z", "2021-07-07T21:17:58Z"]}, {"name": "go-data-segment", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-data-segment\n\ngo-data-segment implements the [FRC-0058](https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0058.md) verifiable aggregation scheme.\n\nIt provides both the [Aggregator](https://pkg.go.dev/github.com/filecoin-project/go-data-segment/datasegment#Aggregate) and [Verifier](https://pkg.go.dev/github.com/filecoin-project/go-data-segment/datasegment#DataAggregationProof) APIs.\n\n\n### Maintainer\nJakub Sztandera (@Kubuxu)\n\n## License\n\nDual MIT and Apache 2\n", "release_dates": ["2023-07-04T13:18:38Z", "2023-06-05T09:57:06Z"]}, {"name": "go-data-transfer", "description": "Data Transfer Shared Component for go-filecoin & go-lotus", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-data-transfer\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-data-transfer.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-data-transfer)\n[![codecov](https://codecov.io/gh/filecoin-project/go-data-transfer/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-data-transfer)\n\nA go module to perform data transfers over [ipfs/go-graphsync](https://github.com/ipfs/go-graphsync)\n\n## Description\nThis module encapsulates protocols for exchanging piece data between storage clients and miners, both when consummating a storage deal and when retrieving the piece later. \n\n## Table of Contents\n* [Background](https://github.com/filecoin-project/go-data-transfer/tree/master#background)\n* [Usage](https://github.com/filecoin-project/go-data-transfer/tree/master#usage)\n    * [Initialize a data transfer module](https://github.com/filecoin-project/go-data-transfer/tree/master#initialize-a-data-transfer-module)\n    * [Register a validator](https://github.com/filecoin-project/go-data-transfer/tree/master#register-a-validator)\n    * [Open a Push or Pull Request](https://github.com/filecoin-project/go-data-transfer/tree/master#open-a-push-or-pull-request)\n    * [Subscribe to Events](https://github.com/filecoin-project/go-data-transfer/tree/master#subscribe-to-events)\n* [Contribute](https://github.com/filecoin-project/go-data-transfer/tree/master#contribute)\n\n## Usage\n\n**Requires go 1.13**\n\nInstall the module in your package or app with `go get \"github.com/filecoin-project/go-data-transfer/v2\"`\n\n\n### Initialize a data transfer module\n1. Set up imports. You need, minimally, the following imports:\n    ```go\n    package mypackage\n\n    import (\n        gsimpl \"github.com/ipfs/go-graphsync/impl\"\n        datatransfer \"github.com/filecoin-project/go-data-transfer/v2/impl\"\n        gstransport \"github.com/filecoin-project/go-data-transfer/v2/transport/graphsync\"\n        \"github.com/libp2p/go-libp2p/core/host\"\n    )\n            \n    ```\n1. Provide or create a [libp2p host.Host](https://github.com/libp2p/go-libp2p-examples/tree/master/libp2p-host)\n1. You will need a transport protocol. The current default transport is graphsync. [go-graphsync GraphExchange](https://github.com/ipfs/go-graphsync#initializing-a-graphsync-exchange)\n1. Create a data transfer by building a transport interface and then initializing a new data transfer instance\n    ```go\n    func NewGraphsyncDataTransfer(h host.Host, gs graphsync.GraphExchange) {\n        tp := gstransport.NewTransport(h.ID(), gs)\n        dt := impl.NewDataTransfer(h, tp)\n    }\n    ```\n\n1. If needed, build out your voucher struct and its validator. \n    \n    A push or pull request must include a voucher. The voucher's type must have been registered with \n    the node receiving the request before it's sent, otherwise the request will be rejected.  \n\n    [datatransfer.Voucher](https://github.com/filecoin-project/go-data-transfer/blob/21dd66ba370176224114b13030ee68cb785fadb2/datatransfer/types.go#L17)\n    and [datatransfer.Validator](https://github.com/filecoin-project/go-data-transfer/blob/21dd66ba370176224114b13030ee68cb785fadb2/datatransfer/types.go#L153)\n    are the interfaces used for validation of graphsync datatransfer messages.  Voucher types plus a Validator for them must be registered\n    with the peer to whom requests will be sent.  \n\n#### Example Toy Voucher and Validator\n```go\ntype myVoucher struct {\n\tdata string\n}\n\nfunc (v *myVoucher) ToBytes() ([]byte, error) {\n\treturn []byte(v.data), nil\n}\n\nfunc (v *myVoucher) FromBytes(data []byte) error {\n\tv.data = string(data)\n\treturn nil\n}\n\nfunc (v *myVoucher) Type() string {\n\treturn \"FakeDTType\"\n}\n\ntype myValidator struct {\n\tctx                 context.Context\n\tValidationsReceived chan receivedValidation\n}\n\nfunc (vl *myValidator) ValidatePush(\n\tsender peer.ID,\n\tvoucher datatransfer.Voucher,\n\tbaseCid cid.Cid,\n\tselector datamodel.Node) error {\n    \n    v := voucher.(*myVoucher)\n    if v.data == \"\" || v.data != \"validpush\" {\n        return errors.New(\"invalid\")\n    }   \n\n\treturn nil\n}\n\nfunc (vl *myValidator) ValidatePull(\n\treceiver peer.ID,\n\tvoucher datatransfer.Voucher,\n\tbaseCid cid.Cid,\n\tselector datamodel.Node) error {\n\n    v := voucher.(*myVoucher)\n    if v.data == \"\" || v.data != \"validpull\" {\n        return errors.New(\"invalid\")\n    }   \n\n\treturn nil\n}\n\n```\n\n\nPlease see \n[go-data-transfer/blob/master/types.go](https://github.com/filecoin-project/go-data-transfer/blob/master/types.go) \nfor more detail.\n\n\n### Register a validator\nBefore sending push or pull requests, you must register a `datatransfer.Voucher` \nby its `reflect.Type` and `dataTransfer.RequestValidator` for vouchers that\nmust be sent with the request.  Using the trivial examples above:\n```go\n    func NewGraphsyncDatatransfer(h host.Host, gs graphsync.GraphExchange) {\n        tp := gstransport.NewTransport(h.ID(), gs)\n        dt := impl.NewDataTransfer(h, tp)\n\n        vouch := &myVoucher{}\n        mv := &myValidator{} \n        dt.RegisterVoucherType(reflect.TypeOf(vouch), mv)\n    }\n```\n    \nFor more detail, please see the [unit tests](https://github.com/filecoin-project/go-data-transfer/blob/master/impl/impl_test.go).\n\n### Open a Push or Pull Request\nFor a push or pull request, provide a context, a `datatransfer.Voucher`, a host recipient `peer.ID`, a baseCID `cid.CID` and a selector `datamodel.Node`.  These\ncalls return a `datatransfer.ChannelID` and any error:\n```go\n    channelID, err := dtm.OpenPullDataChannel(ctx, recipient, voucher, baseCid, selector)\n    // OR\n    channelID, err := dtm.OpenPushDataChannel(ctx, recipient, voucher, baseCid, selector)\n\n```\n\n### Subscribe to Events\n\nThe module allows the consumer to be notified when a graphsync Request is sent or a datatransfer push or pull request response is received:\n\n```go\n    func ToySubscriberFunc (event Event, channelState ChannelState) {\n        if event.Code == datatransfer.Error {\n            // log error, flail about helplessly\n            return\n        }\n        // \n        if channelState.Recipient() == our.PeerID && channelState.Received() > 0 {\n            // log some stuff, update some state somewhere, send data to a channel, etc.\n        }\n    }\n\n    dtm := SetupDataTransferManager(ctx, h, gs, baseCid, snode)\n    unsubFunc := dtm.SubscribeToEvents(ToySubscriberFunc)\n\n    // . . . later, when you don't need to know about events any more:\n    unsubFunc()\n```\n\n## Contributing\nPRs are welcome!  Please first read the design docs and look over the current code.  PRs against \nmaster require approval of at least two maintainers.  For the rest, please see our \n[CONTRIBUTING](https://github.com/filecoin-project/go-data-transfer/CONTRIBUTING.md) guide.\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019. Protocol Labs, Inc.\n", "release_dates": ["2023-03-27T14:50:52Z", "2021-11-17T07:18:24Z", "2021-08-27T19:46:12Z", "2021-08-23T05:46:12Z", "2021-08-18T11:21:51Z", "2021-08-06T15:20:21Z", "2021-07-29T09:50:47Z"]}, {"name": "go-data-transfer-bus", "description": "Expermental bus for coordinating data transfer alyers", "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "go-ds-versioning", "description": "Utilities for working with go-datastores across versions", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-ds-versioning\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-ds-versioning.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-ds-versioning)\n[![codecov](https://codecov.io/gh/filecoin-project/go-ds-versioning/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-ds-versioning)\n\nTools for building migratable datastore\n\n## Description\n\nThis module provides building blocks for migrating key-value datastores that match the interfaces defined in [go-datastore](https://github.com/ipfs/go-datastore)\n\n## Table of Contents\n* [Background](#background)\n* [Installation](#installation)\n* [Usage](#usage)\n    * [Defining migrations](#defining-migrations)\n    * [Executing migrations on Datastores, StateStores, and Finite State Machine groups](#executing-migrations)\n* [Architecture](#architecture)\n* [Contribute](#contribute)\n\n## Background\n\nIn the Filecoin ecosystem, we maintain a number of key-value datastores that\ntrack the off-chain states of various components of Filecoin. As the protocol evolves, we will need to migrate these datastores. The Filecoin protocol requires nodes on the network maintain near constant uptime in order to meet proving requirements. We'd like to be able to migrate off-chain states while taking down only the components of the node that use these states.\n\nThis library provides two core components:\n\n1. Tools for defining migrations. `go-datastore` is a freeform key-value database, so a migration could potentially mean any kind of transformation on\nthe database. However, most commonly, we want to migrate one record type to another. This library provides tools for doing that easily, and for composing these migrations together with versions to build a system for a versioned datastore that can be migrated easily with minimal potential for data-loss\n\n2. Tools for migrating datastores, statestores, and finite state machines transparently, without changing the interfaces for those stores. We define versions of these stores that simply error until they are migrated. This means we can run migrations seperately and when they finish (if they finish successfully), the store comes online.\n\n## Installation\n\n**Requires go 1.14**\n\nInstall the module in your package or app with `go get \"github.com/filecoin-project/go-ds-versioning\"`\n\n## Usage\n\nFor our example, let's imagine a key value store of records with the following structures:\n\n```golang\ntype FruitType string\n\ntype FruitBasketOld struct {\n    Type FruitType\n    Count uint64\n    Price big.Int\n}\n```\n\nWe want to support multiple fruits in the basked so our new structure is as follows:\n\n```golang\ntype FruitBasket struct {\n    Types []FruitType\n    Count uint64\n    Price big.Int\n}\n```\n\nWe've generated cbor-gen code for both of these. Now we have a function to migrate one to the other:\n\n```golang\nfunc MigrateFruitBasket(old * FruitBasketOld) (*FruitBasket, error) {\n    return &FruitBasket{\n        Types: []FruitType{old.Type},\n        Count: old.Count,\n        Price: old.Price,\n    }, nil\n}\n```\n\n### Defining Migrations\n\nNow we want to migrate our store. Let's say we've never migrated our store before, so this is the first time we're going to migrate it.\n\nLet's defined a initial set of migration using go-ds-versioning's builders:\n\n```golang\nimport (\n\tversioning \"github.com/filecoin-project/go-ds-versioning/pkg\"\n\t\"github.com/filecoin-project/go-ds-versioning/pkg/versioned\"\n)\n\nbuilder := versioned.NewVersionedBuilder(MigrateFruitBasket, versioning.VersionKey(\"1\"))\n\nmigrationBuilders := versioned.BuilderList{builder}\n\nmigrations, err := migrationBuilders.Build()\n```\n\nThere's a lot happening there so let's take a look at this. We build a migration here:\n\n```golang\nbuilder := versioned.NewVersionedBuilder(MigrateFruitBasket, versioning.VersionKey(\"1\")),\n```\n\nWe're defining a migration that will use MigrateFruitBasket as its transformation function and will migration to version `1`. While not shown here, there are other things we can also do with this builder:\n\n```golang\n// if we want to provide a mechanism to reverse this migration\nbuilder := builder.Reversable(UnMigrateFruitBasket)\n\n// after our initial version, we always want to make sure we define the old version we're migrating from\nversion2Builder := version2Builder.OldVersion(\"1\")\n\n// we may need to for whatever reason, leave certain keys out of a migration\n// (i.e. delete them, or we may need to exclude some keys that are at the same\n// namespace hierarchy in our initial migration)\nbuilder := builder.FilterKeys(\"rotten-fruit-basket\")\n```\n\nWe're assuming we'll probably define all our migrations in one place, so we make a `BuilderList` -- a list of migration definitions assembled using our builder interface. Typically you can just put your builders inline in the BuilderList.\n\nFinally, to turn these into actual migrations, we call `.Build()` on the `BuilderList` -- this will ensure that our migrations are valid. In particular, every migration function must have the form:\n\n```golang\nfunc <T extends cbg.CBORUnmarshaller, U extends cbg.CBORMarshaller>(old T) (new U, error)\n```\n\n### Executing Migrations\n\nLet's say we are using a [go-statestore](https://github.com/filecoin-project/go-statestore) for our fruit baskets:\n\n```golang\nimport (\n    \"github.com/ipfs/go-datastore\"\n    \"github.com/filecoin-project/go-statestore\"\n)\n\nvar ds datastore // this was setup elsewhere\nfruitBaskets := statestore.New(ds)\n```\n\nTo make it migratable, we replace it with a versioned statestore, with our migrations:\n\n```golang\nimport (\n    \"github.com/ipfs/go-datastore\"\n    versioning \"github.com/filecoin-project/go-ds-versioning/pkg\"\n    \"github.com/filecoin-project/go-ds-versioning/pkg/statestore\"\n)\n\nvar ds datastore // this was setup elsewhere\nvar migrations versioning.VersionedMigrationList // the migrations we setup previously\n\nfruitBaskets, migrateFruitBaskets := statestore.NewVersionedStateStore(ds, migrations, versioning.VersionKey(\"1\"))\n```\n\nHere we're setting up a migrated statestore using the datastore, a list of migrations, and a target version. (target cause in certain cases we want to migrate to a particular version, either UP or DOWN).\n\nWe get back our statestore, and a function to run migrations so we're at our target version.\n\nWhile the returned statestore has all the functions of our statestore, till we migrate, they won't work. After we migrate, we can use them:\n\n```golang\n\nhas, err := fruitBaskets.Has(\"monday basket\")\n// has = false, err = versioning.ErrMigrationsNotRun\n\nvar ctx context.Context\nmigrationErr := migrateFruitBaskets(ctx)\n\nif migrationErr != nil {\n    has, err := fruitBaskets.Has(\"monday basket\")\n    // has = false, err = migrationErr\n} else {\n    has, err := fruitBaskets.Has(\"monday basket\")\n    // returns whatever the underlying state store would return\n}\n```\n\nThe assumption here is we'll want to setup our store in a constructor of a module, but in the context of Lotus, not want to run migrations until we get to some lifecycle hook. We can block in the lifecyle hook to insure migraitons are successful, but we may want to run them in a go-routine so Lotus can get up and running, and deal with the repercusions of failing migrations later.\n\n`go-ds-versioning` also provides these abstractions for raw datastores, and for finite state machines defined with the DSL in `go-statemachine`\n\n## Architecture\n\nUnder the hood, `go-ds-versioning` is creating new records within a versioned name space. Let's say our datastore has the following keys:\n\n```\n\"/apples\"\n\"/oranges\"\n```\n\nAnd we're migrating with single initial migration to version \"1\". After migrating, the data base will look as follows:\n\n```\n\"/versions/current\" // value == \"1\"\n\"/1/apples\"\n\"/1/oranges\"\n```\n\nNot that the initial step of the migration is non-destructive -- we will copy rather than move when we transform. The old keys are only deleted after we know the ENTIRE migration is successful. If we have multiple migrations, we only delete keys after each step succeeds entirely.\n\nNow if we migrate again later, we'll use \"/versions/current\" to figure out what we're migrating from. We might also use it if we wanted the ability to downgrade to an older version in order to run an older version of the code.\n\nThe basic rules are:\n- assume anything could go wrong, including migration errors \n- assume we could get terminated in the middle (we include context as a parameter for this reason)\n- try to avoid worst possible outcomes, in particular data loss.\n\n## Contributing\n\nPRs are welcome!  Please first read the design docs and look over the current code.  PRs against \nmaster require approval of at least two maintainers.  For the rest, please see our \n[CONTRIBUTING](https://github.com/filecoin-project/go-ds-versioning/CONTRIBUTING.md) guide.\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019. Protocol Labs, Inc.\n", "release_dates": ["2021-12-14T22:58:48Z"]}, {"name": "go-f3", "description": "Simulator for Granite consensus and Fast Finality in Filecoin (F3)", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Go implementation of Fast Finality for Filecoin\n\nThis repository contains a Go implementation of the [Filecoin finality module,\nF3](https://github.com/filecoin-project/FIPs/blob/f3564189d11817328168c9e75a80ff5f7292ba13/FIPS/fip-xxxx.md)\n(WIP). \n\nThis executes an iterative GossiPBFT consensus protocol to declare tipsets as\nfinal when voted for by >2/3 of the consensus power.\n\n## Status\n\nWork in progress.\n\nThis implementation began as a simulation during the protocol design phase. It\nis currently being transformed into production code, while maintaining and\nexpanding the simulator.\n\n## Usage\n\nRun the unit tests to exercise the GossipPBFT protocol.\n\n```\n$ go test ./...\n```\n\nThere is also a main entry point to run GossiPBFT instance with honest nodes in\nsimulation.\n\n```\n$ go run f3sim.go -help\nUsage of /path/to/f3sim:\n  -granite-delta float\n    \tgranite delta parameter (default 6)\n  -granite-delta-rate float\n    \tchange in delta for each round (default 2)\n  -iterations int\n    \tnumber of simulation iterations (default 1)\n  -latency-mean float\n    \tmean network latency (default 0.5)\n  -latency-seed int\n    \trandom seed for network latency (default current time)\n  -max-rounds int\n    \tmax rounds to allow before failing (default 10)\n  -participants int\n    \tnumber of participants (default 3)\n  -trace int\n    \ttrace verbosity level\n```\n\n## Integration\n\nThe code does not yet express an API for integration into a Filecoin node.\nComing soon!\n\n## Structure\nModules:\n- `f3`: the protocol implementation\n- `sim`: the simulation harness\n- `adversary`: specific adversarial behaviors for use in tests\n- `test`: unit tests which execute the protocol in simulation\n\n## License\n\nDual-licensed under MIT + Apache 2.0", "release_dates": []}, {"name": "go-fil-commcid", "description": "Conversion Between CID and Piece/Data/Replica Commitments", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-fil-commcid\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-fil-commcid.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-fil-commcid)\n[![codecov](https://codecov.io/gh/filecoin-project/go-fil-commcid/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-fil-commcid)\n\nConversion Utilities Between CID and Piece/Data/Replica Commitments\n\n## Description\n\nThis provides utility functions to convert from\ncommitment hashes used by Filecoin and Content IDs that meet [the CIDv1 standard](https://github.com/multiformats/cid)\n\n## Table of Contents\n* [Background](https://github.com/filecoin-project/go-fil-commcid/tree/master#background)\n* [Usage](https://github.com/filecoin-project/go-fil-commcid/tree/master#usage)\n* [Contribute](https://github.com/filecoin-project/go-fil-commcid/tree/master#contribute)\n\n## Background\n\nSee the [Filecoin PoRep Spec](https://filecoin-project.github.io/specs/#algorithms__porep) and the [Filecoin Paper](https://filecoin.io/filecoin.pdf) for how these commitment hashes (Piece Commitment, Data Commitment, Replica Commitment) are generated.\n\nThis library adds codes neccesary to convert those commitment hashes to CIDs\n\nWe define two combinations of `codec` and `multihash`:\n- [fil-commitment-unsealed](https://github.com/multiformats/multicodec/blob/bf5c4806e/table.csv#L435) + [sha2-256-trunc254-padded](https://github.com/multiformats/multicodec/blob/bf5c4806e/table.csv#L110) for Piece Commitments and Data Commitments (shared due to identical underlying structure)\n- [fil-commitment-sealed](https://github.com/multiformats/multicodec/blob/bf5c4806e/table.csv#L436) + [poseidon-bls12_381-a2-fc1](https://github.com/multiformats/multicodec/blob/bf5c4806e/table.csv#L433) for Replica Commitments\n\n## Usage\n\n**Requires go 1.13**\n\nInstall the module in your package or app with `go get \"github.com/filecoin-project/go-fil-commcid\"`\n\n### Generating CIDs for CommP, CommD, CommR\n\n```golang\npackage mypackage\n\nimport (\n        commcid \"github.com/filecoin-project/go-fil-commcid\"\n)\n\nvar commP []byte\nvar commD []byte\nvar commR []byte            \n\n// will error if the given commX is not the expected size (currently 32 bytes)\npieceCID, err := commcid.PieceCommitmentV1ToCID(commP)\nunsealedSectorCID, err := commcid.DataCommitmentV1ToCID(commD)\nsealedSectorCID, err := commcid.ReplicaCommitmentV1ToCID(commR)\n\n```\n\n### Getting a raw CommP, CommR, CommD from a CID\n\n```golang\npackage mypackage\n\nimport (\n        commcid \"github.com/filecoin-project/go-fil-commcid\"\n)\n\nvar pieceCID cid.Cid\nvar unsealedSectorCID cid.Cid\nvar sealedSectorCID cid.Cid           \n\n// will error if pieceCID does not have the correct codec & hash type\ncommP, err := commcid.CIDToPieceCommitmentV1(pieceCID)\n\n// will error if unsealedSectorCID does not have the correct codec & hash type\ncommD, err := commcid.CIDToDataCommitmentV1(unsealedSectorCID)\n\n// will error if sealedSectorCID does not have the correct codec & hash type\ncommR, err := commcid.CIDToReplicaCommitmentV1(sealedSectorCID)\n```\n\n### Going from arbitrary commitment to CID and back\n\nAs Filecoin evolves, there will likely be new and better constructions for both sealed and unsealed data. Note `V1` in front of the above method names.\n\nTo support future evolution, we provide more generalized methods for\ngoing back and forth:\n\n\n```golang\npackage mypackage\n\nimport (\n        commcid \"github.com/filecoin-project/go-fil-commcid\"\n)\n\nvar commIn []byte\nvar filCodec commcid.FilMultiCodec\nvar filHashAlg commcid.FilMultiHash\n\ncommCID, err := commcid.CommmitmentToCID(filCodecIn, filHashAlgIn, commIn)\n\nfilCodecOut, filHashOut, commOut, err := commcid.CIDToCommitment(commCID)\n```\n\n## Contributing\nPRs are welcome!  Please first read the design docs and look over the current code.  PRs against \nmaster require approval of at least two maintainers.  For the rest, please see our \n[CONTRIBUTING](https://github.com/filecoin-project/go-fil-commcid/CONTRIBUTING.md) guide.\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019. Protocol Labs, Inc.\n", "release_dates": []}, {"name": "go-fil-commp-hashhash", "description": "A hash.Hash implementation of fil-commitment-unsealed", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "go-fil-commp-hashhash\n=======================\n\n> A hash.Hash implementation of [fil-commitment-unsealed](https://github.com/multiformats/multicodec/blob/eb94500c/table.csv#L508)\n\n[![GoDoc](https://godoc.org/github.com/thamaraiselvam/github-api-cli?status.svg)](https://pkg.go.dev/github.com/filecoin-project/go-fil-commp-hashhash)\n[![GoReport](https://goreportcard.com/badge/github.com/filecoin-project/go-fil-commp-hashhash)](https://goreportcard.com/report/github.com/filecoin-project/go-fil-commp-hashhash)\n\nPackage commp allows calculating a [Filecoin Unsealed Commitment (commP/commD)](https://spec.filecoin.io/#section-systems.filecoin_files.piece.data-representation)\ngiven a bytestream. It is implemented as a standard [hash.Hash() interface](https://pkg.go.dev/hash#Hash),\nwith the entire padding and treebuilding algorithm written in golang.\n\nThe returned digest is a 32-byte raw commitment payload. Use something like [DataCommitmentV1ToCID](https://pkg.go.dev/github.com/filecoin-project/go-fil-commcid#DataCommitmentV1ToCID)\nin order to convert it to a proper [cid.Cid](https://pkg.go.dev/github.com/ipfs/go-cid#Cid).\n\nThe output of this library is 100% identical to [ffi.GeneratePieceCIDFromFile()](https://github.com/filecoin-project/filecoin-ffi/blob/d82899449741ce19/proofs.go#L177-L196)\n\n\n## Lead Maintainer\n[Peter 'ribasushi' Rabbitson](https://github.com/ribasushi)\n\n\n## License\n[SPDX-License-Identifier: Apache-2.0 OR MIT](LICENSE.md)\n", "release_dates": ["2023-03-06T21:28:22Z"]}, {"name": "go-fil-filestore", "description": null, "language": "Go", "license": null, "readme": null, "release_dates": []}, {"name": "go-fil-markets", "description": "Shared Implementation of Storage and Retrieval Markets for Filecoin Node Implementations", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-fil-markets\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-fil-markets.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-fil-markets)\n[![codecov](https://codecov.io/gh/filecoin-project/go-fil-markets/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-fil-markets)\n[![GoDoc](https://godoc.org/github.com/filecoin-project/go-fil-markets?status.svg)](https://godoc.org/github.com/filecoin-project/go-fil-markets)\n\nThis repository contains modular implementations of the [storage and retrieval market subsystems][1] of Filecoin. \nThey are guided by the [v1.0 and 1.1 Filecoin specification updates](https://filecoin-project.github.io/specs/#intro__changelog). \n\nSeparating implementations into a blockchain component and one or more mining and market components presents an opportunity to encourage implementation diversity while reusing non-security-critical components.\n\n## Disclaimer: Reporting issues\n\nThis repo shared the issue tracker with lotus. Please report your issues at the [lotus issue tracker](https://github.com/filecoin-project/lotus/issues)\n\n## Components\n\n* **[storagemarket](./storagemarket)**: for finding, negotiating, and consummating deals to\n store data between clients and providers (storage miners).\n* **[retrievalmarket](./retrievalmarket)**: for finding, negotiating, and consummating deals to\n retrieve data between clients and providers (retrieval miners).\n* **[filestore](./filestore)**: a wrapper around os.File for use by pieceio, storagemarket, and retrievalmarket.\n* **[pieceio](./pieceio)**: utilities that take IPLD graphs and turn them into pieces. Used by storagemarket.\n* **[piecestore](./piecestore)**:  a database for storing deal-related PieceInfo and CIDInfo. \nUsed by storagemarket and retrievalmarket.\n\nRelated components in other repos:\n* **[go-data-transfer](https://github.com/filecoin-project/go-data-transfer)**: for exchanging piece data between clients and miners, used by storage & retrieval market modules.\n\n### Background reading\n\n* The [Markets in Filecoin][1]\nsection of the Filecoin Specification contains the canonical spec.\n\n### Technical Documentation\n* [GoDoc for Storage Market](https://godoc.org/github.com/filecoin-project/go-fil-markets/storagemarket) contains an architectural overview and robust API documentation\n* [GoDoc for Retrieval Market](https://godoc.org/github.com/filecoin-project/go-fil-markets/retrievalmarket) contains an architectural overview and robust API documentation\n\n## Installation\n```bash\ngo get \"github.com/filecoin-project/go-fil-markets/<MODULENAME>\"`\n```\n\n## Usage\nDocumentation is in the README for each module, listed in [Components](#Components).\n\n## Contributing\nIssues and PRs are welcome! Please first read the [background reading](#background-reading) and [CONTRIBUTING](.go-fil-markets/CONTRIBUTING.md) guide, and look over the current code. PRs against master require approval of at least two maintainers. \n\nDay-to-day discussion takes place in the #fil-components channel of the [Filecoin project chat](https://github.com/filecoin-project/community#chat). Usage or design questions are welcome.\n\n## Project-level documentation\nThe filecoin-project has a [community repo](https://github.com/filecoin-project/community) with more detail about our resources and policies, such as the [Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md).\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019. Protocol Labs, Inc.\n\n[1]:https://spec.filecoin.io/#section-systems.filecoin_markets\n", "release_dates": ["2023-05-30T15:57:13Z", "2022-11-14T08:44:00Z", "2022-10-07T15:22:43Z", "2022-09-29T21:30:43Z", "2022-08-03T08:32:10Z", "2021-08-23T09:13:26Z", "2021-08-16T19:52:58Z", "2021-07-29T09:55:15Z"]}, {"name": "go-filecoin-badges", "description": "Badges to be included in go-filecoin documentation", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Badges for go-filecoin\n\nA repository for build related badges belonging to [go-filecoin](https://github.com/filecoin-project/go-filecoin)\n\nUses [shields.io](https://shields.io/) badge service.\n\n## Badges\n\n[![User Devnet Release](https://img.shields.io/endpoint.svg?color=brightgreen&style=flat&logo=GitHub&url=https://raw.githubusercontent.com/filecoin-project/go-filecoin-badges/master/user-devnet.json)](https://github.com/filecoin-project/go-filecoin/releases/latest)\n[![Test Devnet Release](https://img.shields.io/endpoint.svg?color=brightgreen&style=flat&logo=GitHub&url=https://raw.githubusercontent.com/filecoin-project/go-filecoin-badges/master/test-devnet.json)](https://github.com/filecoin-project/go-filecoin/releases)\n[![Nightly Devnet Release](https://img.shields.io/endpoint.svg?color=blue&style=flat&logo=GitHub&url=https://raw.githubusercontent.com/filecoin-project/go-filecoin-badges/master/nightly-devnet.json)](https://github.com/filecoin-project/go-filecoin/releases)\n\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\nApache License, Version 2.0, (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0)\nMIT license (LICENSE-MIT or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "go-hamt-ipld", "description": "An implementation of a HAMT using ipld", "language": "Go", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "go-hamt-ipld\n==================\n\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](https://protocol.ai/)\n[![Travis CI](https://travis-ci.org/filecoin-project/go-hamt-ipld.svg?branch=master)](https://travis-ci.org/filecoin-project/go-hamt-ipld)\n\n**This package is a reference implementation of the IPLD HAMT used in the\nFilecoin blockchain.** It includes some optional flexibility such that it may\nbe used for other purposes outside of Filecoin.\n\nHAMT is a [\"hash array mapped trie\"](https://en.wikipedia.org/wiki/Hash_array_mapped_trie).\nThis implementation extends the standard form by including buckets for the\nkey/value pairs at storage leaves and [CHAMP mutation semantics](https://michael.steindorfer.name/publications/oopsla15.pdf).\nThe CHAMP invariant and mutation rules provide us with the ability to maintain\ncanonical forms given any set of keys and their values, regardless of insertion\norder and intermediate data insertion and deletion. Therefore, for any given\nset of keys and their values, a HAMT using the same parameters and CHAMP\nsemantics, the root node should always produce the same content identifier\n(CID).\n\n**See https://godoc.org/github.com/filecoin-project/go-hamt-ipld for more information and\nAPI details.**\n\n## License\n\nMIT \u00a9 Whyrusleeping\n", "release_dates": ["2023-03-29T20:20:15Z", "2022-10-14T06:22:43Z", "2021-05-24T22:27:27Z"]}, {"name": "go-http-api", "description": "HTTP API for Filecoin nodes in go", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-http-api\n\nA package that provides an HTTP REST API for a Filecoin implementation written in go.\n\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-http-api.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-http-api)\n[![codecov](https://codecov.io/gh/filecoin-project/go-http-api/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-http-api)\n\n## Features\n* Response body is JSON.\n* POST request bodies are expected to be JSON.\n* SSL/TLS supported\n* Bearer auth scheme supported (SOON)\n\n## Install\n```\ngo get github.com/filecoin-project/go-http-api\n```\n\n## Implement\n\n### 1. Set up `vN.Callbacks`\nThe core of the API is the `Callbacks` struct.  It is a typestruct in each API version package containing named callback functions, which should call into your code.  The server is then instantiated with your desired callbacks. Each version of the API has its own `Callbacks` struct: \n```go\npackage v1\nimport(...)\ntype Callbacks struct {\n\tGetActorByID func(string) (*types.Actor, error)\n\tGetActorNonce func(string) (*big.Int, error)\n\tGetActors func() ([]*types.Actor, error)\n    // ... etc\n}\n```\nBecause it is a struct and not an interface, implementers are free to support as much of the API as they like; a default handler will be used for nil `Callbacks` in each, for example:\n```bash\ncurl http://localhost:5000/api/filecoin/v1/actors\n    /api/filecoin/v1/actors is not implemented\n``` \nA 404 response will be sent for endpoints that don't (and can't) exist:\n```bash\ncurl http://localhost:5000/api/filecoin/v1/atcorz\n    curl: (22) The requested URL returned error: 404 Not Found\n```\n This standardizes unimplemented endpoint responses for every node, ensures the API endpoints are compliant with the [API spec](https://github.com/filecoin-project/filecoin-http-api), and more easily allows the API consumer to know what functionality is implemented -- or at least, what is exposed to the API -- by each node. \n\n The design also allows one to implement a proxy server that can communicate via its backend with a Filecoin cluster (if there are separate nodes for storage, retrieval, payments, proofs, mining, etc.) controlled by one operator, thus providing a single, externally accessible endpoint. Potential use cases include exchanges, block explorers, node control, or storage management.\n \nIt is expected for this API to be useful for building a Filecoin implementation's command line interface.\n\nIn order to be implementation-agnostic, this package uses its own Filecoin-based typestructs for callbacks and serialized responses.\n\n### 2. Instantiate and run the server\nPlace the following code somewhere in your node startup sequence:\n\n```go\ncb := &v1.Callbacks {\n    GetActorByID: cbs.MyGetActorByIDFunc,\n    GetActorNonce: cbs.MyGetActorNonceFunc,\n    // ...\n    SendSignedMessage: cbs.MySendSignedMessageFunc,\n    WaitForMessage: cbs.MyWaitForMessageFunc,\n}\n\ncfg := server.Config{\n    Port: 5001,\n    TLSCertPath os.Getenv(\"TLS_CERT_PATH\")\n    TLSKeyPath  os.Getenv(\"TLS_KEY_PATH\")\n}\n\ns := server.NewHTTPAPI(context.Background(), cb, cfg).Run()\n```\n\n### 3. Launch your node and test the endpoints\nFirst launch your filecoin node. Then, to verify only that you have correctly launched the HTTP API server, use the `hello` endpoint:\n\n```bash\ncurl http://localhost:5000/api/filecoin/v1/hello\n    HELLO\n```\n\nThen attempt to retrieve information from your node, by sending a request to an endpoint for one of the callbacks you implemented:\n```bash\ncurl http://localhost:5000/api/filecoin/v1/actors\n```\n\nAssuming you have correctly implemented your callbacks, you should see familiar output.\n\nPlease see test files for more details. \n\n## References\n* For a current map of endpoints to callbacks, see [`server.Route()`](https://github.com/filecoin-project/go-http-api/blob/516f52ea8f6e13c708613c42e087c346c1f39e2b/server.go#L84)\n* [Filecoin HTTP API Specification](https://github.com/filecoin-project/filecoin-http-api)\n* filecoin-project/go-filecoin [example implementation in a branch](https://github.com/filecoin-project/go-filecoin/tree/feat/rest-api-part1)\n\n## Contributing\n\nWe \u2764\ufe0f all our contributors; this project wouldn\u2019t be what it is without you! If you want to help out, please see [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## License\nThe Filecoin Project, including this repository, is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\n## [Copyright](COPYRIGHT)", "release_dates": []}, {"name": "go-ipld-cbor", "description": "A cbor implementation of the go-ipld-format", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "go-ipld-cbor\n==================\n\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![](https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square)](http://libp2p.io/)\n[![](https://img.shields.io/badge/freenode-%23ipfs-blue.svg?style=flat-square)](http://webchat.freenode.net/?channels=%23ipfs)\n[![Coverage Status](https://coveralls.io/repos/github/libp2p/js-libp2p-floodsub/badge.svg?branch=master)](https://coveralls.io/github/libp2p/js-libp2p-floodsub?branch=master)\n[![Travis CI](https://travis-ci.org/libp2p/js-libp2p-floodsub.svg?branch=master)](https://travis-ci.org/libp2p/js-libp2p-floodsub)\n\n> An implementation of a cbor encoded merkledag object.\n\n\n## Table of Contents\n\n- [Install](#install)\n- [Usage](#usage)\n- [API](#api)\n- [Contribute](#contribute)\n- [License](#license)\n\n## Install\n\n```sh\nmake install\n```\n\n## Usage\n\nTODO: Right now this package isn't the easiest to use, it will be getting better rapidly, soon.\n```go\n// Make an object\nobj := map[interface{}]interface{}{\n\t\"foo\": \"bar\",\n\t\"baz\": &Link{\n\t\tTarget: myCid,\n\t},\n}\n\n// Parse it into an ipldcbor node\nnd, err := WrapMap(obj)\n\nfmt.Println(nd.Links())\n\n```\n\n## Contribute\n\nPRs are welcome!\n\nSmall note: If editing the Readme, please conform to the [standard-readme](https://github.com/RichardLitt/standard-readme) specification.\n\n## License\n\nMIT \u00a9 Jeromy Johnson\n", "release_dates": []}, {"name": "go-jsonrpc", "description": "Low Boilerplate JSON-RPC 2.0 library", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "go-jsonrpc\n==================\n\n[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white&style=flat-square)](https://pkg.go.dev/github.com/filecoin-project/go-jsonrpc)\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](https://protocol.ai)\n\n> Low Boilerplate JSON-RPC 2.0 library\n\n## Usage examples\n\n### Server\n\n```go\n// Have a type with some exported methods\ntype SimpleServerHandler struct {\n    n int\n}\n\nfunc (h *SimpleServerHandler) AddGet(in int) int {\n    h.n += in\n    return h.n\n}\n\nfunc main() {\n    // create a new server instance\n    rpcServer := jsonrpc.NewServer()\n    \n    // create a handler instance and register it\n    serverHandler := &SimpleServerHandler{}\n    rpcServer.Register(\"SimpleServerHandler\", serverHandler)\n    \n    // rpcServer is now http.Handler which will serve jsonrpc calls to SimpleServerHandler.AddGet\n    // a method with a single int param, and an int response. The server supports both http and websockets.\n    \n    // serve the api\n    testServ := httptest.NewServer(rpcServer)\n    defer testServ.Close()\n\t\n    fmt.Println(\"URL: \", \"ws://\"+testServ.Listener.Addr().String())\n    \n    [..do other app stuff / wait..]\n}\n```\n\n### Client\n```go\nfunc start() error {\n    // Create a struct where each field is an exported function with signatures matching rpc calls\n    var client struct {\n        AddGet      func(int) int\n    }\n\t\n\t// Make jsonrp populate func fields in the struct with JSONRPC calls\n    closer, err := jsonrpc.NewClient(context.Background(), rpcURL, \"SimpleServerHandler\", &client, nil)\n    if err != nil {\n    \treturn err\n    }\n    defer closer()\n    \n    ...\n    \n    n := client.AddGet(10)\n    // if the server is the one from the example above, n = 10\n\n    n := client.AddGet(2)\n    // if the server is the one from the example above, n = 12\n}\n```\n\n### Supported function signatures\n\n```go\ntype _ interface {\n    // No Params / Return val\n    Func1()\n    \n    // With Params\n    // Note: If param types implement json.[Un]Marshaler, go-jsonrpc will use it\n    Func2(param1 int, param2 string, param3 struct{A int})\n    \n    // Returning errors\n    // * For some connection errors, go-jsonrpc will return jsonrpc.RPCConnectionError{}.\n    // * RPC-returned errors will be constructed with basic errors.New(__\"string message\"__)\n    // * JSON-RPC error codes can be mapped to typed errors with jsonrpc.Errors - https://pkg.go.dev/github.com/filecoin-project/go-jsonrpc#Errors\n    // * For typed errors to work, server needs to be constructed with the `WithServerErrors`\n    //   option, and the client needs to be constructed with the `WithErrors` option\n    Func3() error\n    \n    // Returning a value\n    // Note: The value must be serializable with encoding/json.\n    Func4() int\n    \n    // Returning a value and an error\n    // Note: if the handler returns an error and a non-zero value, the value will not\n    //       be returned to the client - the client will see a zero value.\n    Func4() (int, error)\n    \n    // With context\n    // * Context isn't passed as JSONRPC param, instead it has a number of different uses\n    // * When the context is cancelled on the client side, context cancellation should propagate to the server handler\n    //   * In http mode the http request will be aborted\n    //   * In websocket mode the client will send a `xrpc.cancel` with a single param containing ID of the cancelled request\n    // * If the context contains an opencensus trace span, it will be propagated to the server through a\n    //   `\"Meta\": {\"SpanContext\": base64.StdEncoding.EncodeToString(propagation.Binary(span.SpanContext()))}` field in\n    //   the jsonrpc request\n    //   \n    Func5(ctx context.Context, param1 string) error\n    \n    // With non-json-serializable (e.g. interface) params\n    // * There are client and server options which make it possible to register transformers for types\n    //   to make them json-(de)serializable\n    // * Server side: jsonrpc.WithParamDecoder(new(io.Reader), func(ctx context.Context, b []byte) (reflect.Value, error) { ... }\n    // * Client side: jsonrpc.WithParamEncoder(new(io.Reader), func(value reflect.Value) (reflect.Value, error) { ... }\n    // * For io.Reader specifically there's a simple param encoder/decoder implementation in go-jsonrpc/httpio package\n    //   which will pass reader data through separate http streams on a different hanhler.\n    // * Note: a similar mechanism for return value transformation isn't supported yet\n    Func6(r io.Reader)\n    \n    // Returning a channel\n    // * Only supported in websocket mode\n    // * If no error is returned, the return value will be an int channelId\n    // * When the server handler writes values into the channel, the client will receive `xrpc.ch.val` notifications\n    //   with 2 params: [chanID: int, value: any]\n    // * When the channel is closed the client will receive `xrpc.ch.close` notification with a single param: [chanId: int]\n    // * The client-side channel will be closed when the websocket connection breaks; Server side will discard writes to\n    //   the channel. Handlers should rely on the context to know when to stop writing to the returned channel.\n    // NOTE: There is no good backpressure mechanism implemented for channels, returning values faster that the client can\n    // receive them may cause memory leaks.\n    Func7(ctx context.Context, param1 int, param2 string) (<-chan int, error)\n}\n\n```\n\n## Contribute\n\nPRs are welcome!\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/go-jsonrpc/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/go-jsonrpc/blob/master/LICENSE-APACHE)\n", "release_dates": ["2023-05-09T15:09:49Z", "2023-05-09T15:09:15Z", "2023-03-15T16:17:10Z", "2023-03-06T17:10:51Z", "2023-02-01T13:05:58Z", "2023-01-26T12:57:01Z", "2022-11-07T15:05:52Z", "2022-09-21T16:27:42Z", "2022-08-22T18:13:50Z", "2022-07-19T17:36:38Z", "2021-08-18T17:51:34Z", "2021-08-18T17:47:44Z"]}, {"name": "go-leb128", "description": "LEB128 integer encoding", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# leb128\n\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-leb128/tree/master.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-leb128/tree/master)\n\nLEB128 integer encoding for golang. Only a few cases for now,\nothers can be added as needed.\n", "release_dates": []}, {"name": "go-legs", "description": "Does the legwork for go-data-transfer", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "## legs \ud83e\uddb5\n\nLegs is an interface for [go-data-transfer](https://github.com/filecoin-project/go-data-transfer),\nproviding a 1:1 mechanism for maintaining a synchronized [IPLD dag](https://docs.ipld.io/) of data between\na publisher and a subscriber's current state for that publisher.\n\n## Usage\n\nTypically an application will be either a provider or a subscriber, but may be both.\n\n### Publisher\n\nCreate a legs publisher.  Update its root to cause it to publish.\n\n```golang\npub, err :=  NewPublisher(host, dsstore, lsys, \"/legs/topic\")\nif err != nil {\n\tpanic(err)\n}\n...\n// Publish updated root.\nerr = publisher.UpdateRoot(ctx, lnk.(cidlink.Link).Cid)\nif err != nil {\n\tpanic(err)\n}\n```\n\n### Subscriber\n\nThe `Subscriber` handles subscribing to a topic, reading messages from the topic and tracking the state of each publisher.\n\nCreate a `Subscriber`:\n\n```golang\nsub, err := legs.NewSubscriber(dstHost, dstStore, dstLnkS, \"/legs/topic\", nil)\nif err != nil {\n\tpanic(err)\n}\n\n```\nOptionally, request notification of updates:\n\n```golang\nwatcher, cancelWatcher := sub.OnSyncFinished()\ndefer cancelWatcher()\ngo watch(watcher)\n\nfunc watch(notifications <-chan legs.SyncFinished) {\n    for {\n        syncFinished := <-notifications\n        // newHead is now available in the local dataStore\n    }\n}\n```\n\nTo shutdown a `Subscriber`, call its `Close()` method.\n\nA `Subscriber` can be created with a function that determines if the `Subscriber` accepts or rejects messages from a publisher.  Use the `AllowPeer` option to specify the function.\n```golang\nsub, err := legs.NewSubscriber(dstHost, dstStore, dstLnkS, \"/legs/topic\", nil, legs.AllowPeer(allowPeer))\n```\n\nThe `Subscriber` keeps track of the latest head for each publisher that it has synced. This avoids exchanging the whole DAG from scratch in every update and instead downloads only the part that has not been synced. This value is not persisted as part of the library. If you want to start a `Subscriber` which has already partially synced with a provider you can use the `SetLatestSync` method:\n```golang\nsub, err := legs.NewSubscriber(dstHost, dstStore, dstLnkS, \"/legs/topic\", nil)\nif err != nil {\n    panic(err)\n}\n// Set up partially synced publishers\nif err = sub.SetLatestSync(peerID1, lastSync1) ; err != nil {\n    panic(err)\n}\nif err = sub.SetLatestSync(peerID2, lastSync2) ; err != nil {\n    panic(err)\n}\nif err = sub.SetLatestSync(peerID3, lastSync3) ; err != nil {\n    panic(err)\n}\n```\n\nLicense\n---\n\nLegs is dual-licensed under Apache 2.0 and MIT terms:\n\n    Apache License, Version 2.0, (LICENSE or http://www.apache.org/licenses/LICENSE-2.0)\n    MIT license (LICENSE-MIT or http://opensource.org/licenses/MIT)\n", "release_dates": ["2022-10-06T00:23:21Z", "2022-10-01T05:41:44Z", "2022-09-19T08:08:07Z", "2022-09-16T12:15:48Z", "2022-09-08T18:41:07Z", "2022-08-25T02:22:17Z", "2022-08-12T15:34:42Z", "2022-08-10T23:26:06Z", "2022-08-05T14:00:40Z", "2022-07-20T09:50:47Z", "2022-06-24T10:48:20Z", "2022-06-14T20:36:45Z", "2022-05-27T00:34:51Z", "2022-05-26T15:32:13Z", "2022-05-24T16:02:20Z", "2022-05-23T17:00:38Z", "2022-05-17T09:44:18Z", "2022-04-21T13:43:55Z", "2022-04-14T08:17:34Z", "2022-03-17T19:30:33Z", "2022-03-10T17:51:18Z", "2022-03-04T12:42:45Z", "2022-02-25T21:54:46Z", "2022-02-25T21:47:59Z", "2022-02-23T20:52:58Z", "2022-02-23T10:06:45Z", "2022-02-22T18:55:54Z", "2022-02-21T19:26:57Z", "2022-02-16T13:34:10Z", "2022-02-11T03:56:45Z"]}, {"name": "go-multistore", "description": "Multistore uses go-datastore and namespaces to simulate having multiple storage instances", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-fil-markets\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-multistore.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-multistore)\n[![codecov](https://codecov.io/gh/filecoin-project/go-multistore/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-multistore)\n[![GoDoc](https://godoc.org/github.com/filecoin-project/go-multistore?status.svg)](https://godoc.org/github.com/filecoin-project/go-multistore)\n\nThis repository provides a mechanism for constructing multiple, isolated, IPFS storage instances (blockstore, filestore, DAGService) on top of a single\ngo-datastore instance.\n\n### Background reading\n\nYou may want to familiarize yourself with various IPFS storage layer components:\n\n- [DataStore](https://github.com/ipfs/go-datastore)\n- [BlockStore](https://github.com/ipfs/go-ipfs-blockstore)\n- [FileStore](https://github.com/ipfs/go-filestore)\n- [BlockService](https://github.com/ipfs/go-blockservice)\n- [DAGService](https://github.com/ipfs/go-ipld-format/blob/master/merkledag.go)\n\n## Installation\n```bash\ngo get \"github.com/filecoin-project/go-multistore\"`\n```\n\n## Usage\n\nInitialize multistore:\n\n```golang\nvar ds datastore.Batching\nmultiDs, err := multistore.NewMultiDstore(ds)\n```\n\nCreate new store:\n\n```golang\nnext := multiDs.Next()\nstore, err := multiDs.Get(store)\n\n// store will have a blockstore, filestore, and DAGService\n```\n\nList existing store indexes:\n\n```golang\nindexes := multiDs.List()\n```\n\nDelete a store (will delete all data in isolated store without touching the rest of the datastore):\n\n```golang\nvar index int\nerr := multiDs.Delete(index)\n```\n\nShutdown (make sure everything is closed):\n\n```golang\nmultiDs.Close()\n```\n\n## Contributing\nIssues and PRs are welcome! Please first read the [background reading](#background-reading) and [CONTRIBUTING](./CONTRIBUTING.md) guide, and look over the current code. PRs against master require approval of at least two maintainers. \n\nDay-to-day discussion takes place in the #fil-components channel of the [Filecoin project chat](https://github.com/filecoin-project/community#chat). Usage or design questions are welcome.\n\n## Project-level documentation\nThe filecoin-project has a [community repo](https://github.com/filecoin-project/community) with more detail about our resources and policies, such as the [Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md).\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2020. Protocol Labs, Inc.\n", "release_dates": []}, {"name": "go-padreader", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-padreader\n\nTools for mapping between bit-padded and not-bit-padded byte streams\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/go-padreader/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/go-padreader/blob/master/LICENSE-APACHE)\n", "release_dates": ["2021-08-18T17:55:33Z"]}, {"name": "go-paramfetch", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-paramfetch\n\nA program used to download Groth parameters and verifying keys used by the Filecoin network\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/go-paramfetch/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/go-paramfetch/blob/master/LICENSE-APACHE)\n", "release_dates": ["2022-02-08T16:56:43Z"]}, {"name": "go-retrieval-market-project", "description": null, "language": null, "license": null, "readme": "# go-retrieval-market-project", "release_dates": []}, {"name": "go-retrieval-types", "description": "Types associated with Filecoin markets retrieval protocol v1", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-retrieval-types\n\nThis is an extraction of types from go-fil-markets used in the libp2p\n/fil/retrieval/qry/1.0.0 protocol and the Filecoin Markets V1 retrieval protocol\n\n## License\n\nThis library is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2022. Protocol Labs, Inc.\n", "release_dates": []}, {"name": "go-sectorbuilder", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-sectorbuilder\n\nAn abstraction used to manage a storage miner's sectors\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/go-sectorbuilder/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/go-sectorbuilder/blob/master/LICENSE-APACHE)\n", "release_dates": []}, {"name": "go-shared-types", "description": "DEPRECATED DO NOT USE", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# DEPRECATED\n\nThis repo is no longer supported.\n\n# go-shared-types\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-shared-types.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-shared-types)\n[![codecov](https://codecov.io/gh/filecoin-project/go-shared-types/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-shared-types)\n\nThis repository contains modular implementations of several Filecoin subsystems. These modules are guided by the [v1.0 and 1.1 Filecoin specification updates](https://filecoin-project.github.io/specs/#intro__changelog), which separate core blockchain consensus functionality from the storage mining, storage market, and piece data transfer subsystems. \n\nSeparating an implementation into a blockchain component and one or more mining and market components presents an opportunity to encourage implementation diversity while re-using non-security-critical components, and also greatly ease miner-operator customisations.\n\n## Components\n\n* [pkg/address](https://github.com/filecoin-project/go-shared-types/address), a shared address type\n... \n\n## Contributing\nPRs are welcome!  Please first read the design docs and look over the current code.  PRs against \nmaster require approval of at least two maintainers.  For the rest, please see our \n[CONTRIBUTING](https://github.com/filecoin-project/go-shared-types/CONTRIBUTING.md) guide.\n\n## Project-level documentation\nThe filecoin-project has a [community repo](https://github.com/filecoin-project/community) that documents in more detail our policies and guidelines, such as discussion forums and chat rooms and  [Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md).\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019. Protocol Labs, Inc.\n", "release_dates": []}, {"name": "go-state-types", "description": "Primitive and low level types used in chain state and actor method parameters", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin state types\n[![CircleCI](https://circleci.com/gh/filecoin-project/go-state-types.svg?style=svg)](https://circleci.com/gh/filecoin-project/go-state-types)\n[![codecov](https://codecov.io/gh/filecoin-project/go-state-types/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/go-state-types)\n\nThis repository contains primitive and low level types used in the Filecoin blockchain state representation.\n\nThese are primarily intended for use by [Actors](https://github.com/filecoin-project/specs-actors) and other\nmodules that read chain state directly.\n\n## Versioning\n\nBlockchain state versioning does not naturally align with common semantic versioning conventions.\n\nAny change in behaviour, including repairing any error that may have affected blockchain evaluation,\nmust be released in a major version change. We intend that to be a rare event for the contents of \nthis repository.\n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2020. Protocol Labs, Inc.\n", "release_dates": ["2023-11-21T15:40:52Z", "2023-08-03T14:30:36Z", "2023-04-21T15:58:39Z", "2023-04-20T19:11:06Z", "2023-02-24T21:57:21Z", "2022-12-22T18:02:20Z", "2022-12-16T17:05:00Z", "2022-12-15T00:33:03Z", "2022-12-13T17:29:04Z", "2022-12-12T16:39:27Z", "2022-11-23T20:25:34Z", "2022-11-23T18:46:07Z", "2022-10-31T17:01:27Z", "2022-10-24T11:56:17Z", "2022-10-24T10:59:22Z", "2022-10-21T21:43:38Z", "2022-10-21T13:40:43Z", "2022-10-20T21:17:34Z", "2022-10-19T19:06:35Z", "2022-10-17T16:26:41Z", "2022-10-13T18:42:41Z", "2022-10-11T12:16:11Z", "2022-10-07T04:14:27Z", "2022-09-29T19:47:05Z", "2022-09-20T15:56:35Z", "2022-09-12T16:12:36Z", "2022-06-20T18:14:59Z", "2022-06-10T14:09:55Z", "2022-06-09T22:43:20Z", "2022-05-12T18:48:48Z"]}, {"name": "go-statemachine", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-statemachine\n\nA generic state machine\n\n## Table of Contents\n\n* [Description](./README.md#description)\n* [Usage](./README.md#usage)\n* [Interation With Statestore](./README.md#interaction-with-statestore)\n* [License](./README.md#license)\n\n## Description\n\nThe module provides tools for defining and tracking generic state machines. For a more specific implementation that specifically defines finite state machines, see the FSM module, that provides additional tools on top of the generic machines defined here\n\nState machines:\n- Receive Events\n- Modify State\n- Take further actions based on new state, possibly generating more events\n\n## Usage\n\nA state machine is defined in terms of a Planner.\n\nIt has the following signature:\n\n```golang\ntype Planner func(events []Event, user interface{}) (nextActions interface{}, eventsProcessed uint64, err error)\n```\n\nA planner receives a series of events and a pointer to the current state (represented by user)\n\nThe planner generally:\n- processes one or more events that mutate state\n- constructs a function that will perform additional actions based on the new state\n\nIt returns:\n1. The next actions handler-- should have the signature func(ctx Context, st <T>) error), where <T> is the typeOf(user) param\n2. The number of events processed\n3. An error if occured\n\nAs a general rule, you mutate **inside** the planner function, while you perform side effects **outside** the planner in the return handler, which only receives a value for state and cannot mutate it (but can dispatch more events).\n\n## Interaction with statestore\n\nThe `go-statemachine` is designed to be used with a list of data structures, persisted to a datastore through the `go-statestore` module. When working with statemachines this way, you define a StateHandler with a Plan function that works like a Planner.\n\nYou initialize a new set of statemachines for a given type of state as follows:\n\n```golang\nvar ds datastore.Batching\nvar stateHandler StateHandler\n\nvar stateMachines = statemachine.New(ds, stateHandler, StateType{})\n```\n\nThis creates a machine for the given data store that will process data of type `StateType` with the given stateHandler.\n\nYou can now dispatch events to a state machine with:\n\n```golang\nvar id interface{} // some identifier of a tracked state\nvar evt Event // some event type\nstateMachines.Send(id, evt)\n```\n\nThe state machine group will initialize a new statemachine if it is not already tracking data for the given identifier\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/go-statemachine/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/go-statemachine/blob/master/LICENSE-APACHE)\n", "release_dates": ["2021-07-29T14:31:36Z"]}, {"name": "go-statestore", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-statestore\n\nA general-purpose key-value store for CBOR-encodable data\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/go-statestore/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/go-statestore/blob/master/LICENSE-APACHE)\n", "release_dates": ["2021-03-25T11:31:41Z"]}, {"name": "go-storage-miner", "description": "A Filecoin storage miner", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-storage-mining\n\nA Filecoin storage miner\n", "release_dates": []}, {"name": "go-storedcounter", "description": "Simple stored counter", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# go-storedcounter\n\nA simple thread safe persisted counter\n\n## Table of Contents\n\n* [Description](./README.md#description)\n* [Install](./README.md#install)\n* [Usage](./README.md#usage)\n* [License](./README.md#license)\n\n## Description\n\nThe module provides a simple counter on top of a go-ipfs-datastore interface\n\n## Install\n\n```\ngo get github.com/filecoin-project/go-storedcounter\n```\n\n## Usage\n\nCreate/load a counter for a datastore and key:\n\n```golang\nimport(\n  \"github.com/ipfs/go-datastore\"\n  \"github.com/filecoin-project/go-storedcounter\"\n)\n\nvar ds datastore.Datastore\nvar name datastore.Key\n\nstoredCounter := storedcounter.New(ds, name)\n```\n\nGet the next value (will start at 0):\n\n```golang\nnext := storedcCounter.Next()\n```\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/go-statemachine/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/go-statemachine/blob/master/LICENSE-APACHE)\n", "release_dates": ["2021-12-14T22:51:06Z"]}, {"name": "go-ulimit", "description": null, "language": "Go", "license": null, "readme": null, "release_dates": []}, {"name": "gov_docs", "description": "A knowledge management hub for Filecoin governance documentation and best practices. ", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Filecoin Governance Docs\nA knowledge management hub for Filecoin governance documentation and best practices. \nWelcome to the knowledge base! This is a central repository of information, guidance, and resources related to our organization and its products or services. Our goal is to provide a single source of truth for all the information you need.\nGovernance at Filecoin is underpinned by the notion of community participation, shared vision of the growth of the network and collaboration. \nAs the Filecoin network grows rapidly, community interest and interaction with governance processes peak hence requiring a one-stop-shop containing documentation, principles and materials for better engagement and understanding of governance procedures. \n\nTo get started, you can use the search bar to look for specific topics or use the navigation menu to browse through the different categories. If you can't find what you're looking for, you can also request new content to be added to the knowledge base.\n\nWe encourage you to contribute to the knowledge base as well. If you have information that you think would be helpful to others, you can submit it for review by submitting a pull request.\n\n**Governance at Filecoin**\n\n[Filecoin Foundation](https://fil.org/) is the independent steward for the governance of the Filecoin ecosystem. Governance at Filecoin is off-chain and community driven imbibing the ethos of decentralized technologies.  \n\n**Sections of the Governance Docs**\n\nIn this docs site, you will find foundational documentation guiding the governance of Filecoin including a governance roadmap, FIPs dashboard, FIPs workflow, community standard, FIP001 (''The Constitution'') and other relevant documentation. If there are missing or out of date docuentation please raise that to our helpdesk. \n\n\n**Maintenance of filecoin Governance Docs**\n\n[Filecoin Foundation](https://fil.org/) is the independent steward for the governance of the Filecoin ecosystem. Governance at Filecoin is off-chain and community driven imbibing the ethos of decentralized technologies.\n\nThis repository is maintined by the governance team at Filecoin Foundation. In the coming months, we hope to add more documentation and information and we will rely on your feedback to make this hub a helful tool to members of the Filecoin community.  \n\nThank you for using the knowledge base, and we hope it helps you find the information you need!\n\n\n**License**\n\nDual-licensed by Protocol Labs under Apache 2.0 and MIT terms, as explained in the Permissive License Stack:\n", "release_dates": []}, {"name": "group", "description": "Elliptic curve group traits and utilities.", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# group [![Crates.io](https://img.shields.io/crates/v/group.svg)](https://crates.io/crates/group) #\n\n`group` is a crate for working with groups over elliptic curves.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "halo2", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# halo2 [![Crates.io](https://img.shields.io/crates/v/halo2.svg)](https://crates.io/crates/halo2) #\n\n## [Documentation](https://docs.rs/halo2)\n\n## Minimum Supported Rust Version\n\nRequires Rust **1.56.1** or higher.\n\nMinimum supported Rust version can be changed in the future, but it will be done with a\nminor version bump.\n\n## Controlling parallelism\n\n`halo2` currently uses [rayon](https://github.com/rayon-rs/rayon) for parallel computation.\nThe `RAYON_NUM_THREADS` environment variable can be used to set the number of threads.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "helm-charts", "description": null, "language": "Smarty", "license": null, "readme": "# Filecoin Helm Charts\n[![CircleCI](https://dl.circleci.com/status-badge/img/gh/filecoin-project/helm-charts/tree/master.svg?style=svg)](https://dl.circleci.com/status-badge/redirect/gh/filecoin-project/helm-charts/tree/master)\n\nThis functionality is in beta and is subject to change. The code is provided as-is with no\nwarranties. Beta features are not subject to the support SLA of official GA features.\n\n## Usage\n\n[Helm](https://helm.sh) must be installed to use the charts.\nPlease refer to Helm's [documentation](https://helm.sh/docs/) to get started.\n\nOnce Helm is set up properly, add the repo as follows:\n\n```console\nhelm repo add filecoin https://filecoin-project.github.io/helm-charts/\n```\n\nYou can then run `helm search repo filecoin` to see the charts.\n", "release_dates": ["2023-09-12T16:16:32Z", "2023-09-06T11:46:09Z", "2023-09-05T19:14:12Z", "2023-09-05T11:57:15Z", "2023-09-04T14:52:29Z", "2023-09-04T11:21:58Z", "2023-08-30T14:31:44Z", "2023-08-29T17:00:52Z", "2023-04-14T12:07:01Z", "2023-04-14T21:10:28Z", "2023-03-31T17:32:10Z", "2023-03-31T17:32:08Z", "2023-03-31T17:32:07Z", "2023-03-31T17:32:04Z", "2023-03-31T17:32:03Z", "2023-03-31T17:32:01Z", "2023-03-30T23:01:43Z", "2023-03-30T22:49:43Z", "2023-03-30T11:40:25Z", "2023-03-30T09:42:30Z", "2023-03-27T10:37:39Z", "2023-03-24T09:26:51Z", "2023-03-17T13:31:10Z", "2023-03-17T00:35:32Z", "2023-03-15T19:48:40Z", "2023-03-15T19:35:24Z", "2023-03-15T18:49:01Z", "2023-03-15T17:51:00Z", "2023-03-09T17:15:21Z", "2023-03-02T16:23:07Z"]}, {"name": "homebrew-exporter", "description": "A Prometheus Exporter for parsing public homebrew metrics at https://formulae.brew.sh/analytics/", "language": "Go", "license": null, "readme": "# homebrew-exporter\nA Prometheus Exporter for parsing public homebrew metrics at https://formulae.brew.sh/analytics/\n\n### To configure\n\n| ENV variable | Default value | Description |\n|--------------|---------------|-------------|\n| `METRICS_PATH` | `\"/metrics\"`| The path to publish the metrics to. |\n| `LISTEN_PORT`  | `\"9888\"`    | The port the metrics exporter listens on. |\n| `HOMEBREW_FORMULAE` | REQUIRED | The list of formulae to grab metrics for. If blank, the exporter will exit immediately. |\n", "release_dates": []}, {"name": "homebrew-lotus", "description": null, "language": "Ruby", "license": null, "readme": "# Filecoin-project Lotus\n\n## How do I install these formulae?\n\n`brew install filecoin-project/lotus/lotus`\n\nOr `brew tap filecoin-project/lotus` and then `brew install lotus`.\n\n## Documentation\n\n`brew help`, `man brew` or check [Homebrew's documentation](https://docs.brew.sh).\n\n", "release_dates": []}, {"name": "infra", "description": "Issue and Documentation repo for the Filecoin Infra team", "language": "HCL", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# infra\nIssue and Documentation repo for the Filecoin Infra team\n", "release_dates": []}, {"name": "kubo-api-client", "description": "copy of github.com/ipfs/kubo/client/rpc", "language": "Go", "license": null, "readme": "# `coreiface.CoreAPI` over http `rpc`\n\n> IPFS CoreAPI implementation using HTTP API\n\nThis packages implements [`coreiface.CoreAPI`](https://pkg.go.dev/github.com/ipfs/boxo/coreiface#CoreAPI) over the HTTP API.\n\n## Documentation\n\nhttps://pkg.go.dev/github.com/filecoin-project/kubo-api-client\n\n### Example\n\nPin file on your local IPFS node based on its CID:\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/filecoin-project/kubo-api-client\"\n    path \"github.com/ipfs/boxo/coreiface/path\"\n)\n\nfunc main() {\n    // \"Connect\" to local node\n    node, err := rpc.NewLocalApi()\n    if err != nil {\n        fmt.Printf(err)\n        return\n    }\n    // Pin a given file by its CID\n    ctx := context.Background()\n    cid := \"bafkreidtuosuw37f5xmn65b3ksdiikajy7pwjjslzj2lxxz2vc4wdy3zku\"\n    p := path.New(cid)\n    err = node.Pin().Add(ctx, p)\n    if err != nil {\n    \tfmt.Printf(err)\n        return\n    }\n    return\n}\n```\n", "release_dates": []}, {"name": "lassie", "description": "A minimal universal retrieval client library for IPFS and Filecoin", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Lassie\n\n> Fetches from Filecoin, every time\n\n## Table of Contents\n\n* [Overview](#overview)\n* [Installation](#installation)\n* [Methods of Retrieval](#methods-of-retrieval)\n\t* [Command Line Interface](#command-line-interface)\n\t\t* [Extracting Content from a CAR](#extracting-content-from-a-car)\n\t\t* [Fetch Example](#fetch-example)\n\t* [HTTP API](#http-api)\n\t\t* [Daemon Example](#daemon-example)\n\t* [Golang Library](#golang-library)\n\t* [Roots, pieces and payloads](#roots-pieces-and-payloads)\n* [Contribute](#contribute)\n* [License](#license)\n\n## Overview\n\nLassie is a simple retrieval client for Filecoin. It finds and fetches your data over the best retrieval protocols available. Lassie makes Filecoin retrieval.\n\n## Installation\n\nDownload the [lassie binary form the latest release](https://github.com/filecoin-project/lassie/releases/latest) based on your system architecture, or download and install the [lassie](https://github.com/filecoin-project/lassie) package using the Go package manager:\n\n```bash\n$ go install github.com/filecoin-project/lassie/cmd/lassie@latest\n\ngo: downloading github.com/filecoin-project/lassie v0.3.1\ngo: downloading github.com/libp2p/go-libp2p v0.23.2\ngo: downloading github.com/filecoin-project/go-state-types v0.9.9\n\n...\n```\n\nOptionally, download the [go-car binary from the latest release](https://github.com/ipld/go-car/releases/latest) based on your system architecture, or install the [go-car](https://github.com/ipld/go-car) package using the Go package manager:\n\n```bash\n$ go install github.com/ipld/go-car/cmd/car@latest\n\ngo: downloading github.com/ipld/go-car v0.6.0\ngo: downloading github.com/ipld/go-car/cmd v0.0.0-20230215023242-a2a8d2f9f60f\ngo: downloading github.com/ipld/go-codec-dagpb v1.6.0 \n\n...\n```\n\nThe go-car package makes it easier to work with files in the content-addressed archive (CAR) format, which is what Lassie uses to return the content it fetches. For the lassie use-case, go-car will be used to extract the contents of the CAR into usable files.\n\n## Methods of Retrieval\n\n### Command Line Interface\n\nThe lassie command line interface (CLI) is the simplest way to retrieve content from the Filecoin/IPFS network. The CLI is best used when needing to fetch content from the network on an ad-hoc basis. The CLI is also useful for testing and debugging purposes, such as making sure that a CID is retrievable from the network or from a specific provider.\n\nThe CLI can be used to retrieve content from the network by passing a CID to the `lassie fetch` command:\n\n```bash\n$ lassie fetch [-o <output file>] [-t <timeout>] <CID>[/path/to/content]\n```\n\nThe `lassie fetch` command will return the content of the CID to a file in the current working directory by the name of `<CID>.car`. If the `-o` output flag is used, the content will be written to the specified file. If the `-t` timeout flag is used, the timeout will be set to the specified value. The default timeout is 20 seconds.\n\n`fetch` will also take as input [IPFS Trustless Gateway](https://specs.ipfs.tech/http-gateways/trustless-gateway/) style paths. If the CID is prefixed with `/ipfs/`, the remainder will be interpreted as a URL query, accepting query parameters that the Trustless Gateway spec accepts, including `dag-scope=`, `entity-bytes=`. For example, `lassie fetch '/ipfs/<CID>/path/to/content?dag-scope=all'` will fetch the CID, the blocks required to navigate the path, and all the content at the terminus of the path.\n\nMore information about available flags can be found by running `lassie fetch --help`.\n\n#### Extracting Content from a CAR\n\nThe go-car package can be used to extract the contents of the CAR file into usable files. For example, if the content of the CID is a video, the go-car package can be used to extract the video into a file on the local filesystem.\n\n```bash\n$ car extract -f <CID>.car\n```\n\nThe `-f` flag is used to specify the CAR file to extract the contents from. The contents of the CAR will be extracted into the current working directory.\n\n#### Fetch Example\n\nLet's grab some content from the Filecoin/IPFS network using the `lassie fetch` command:\n\n```bash\n$ lassie fetch -o fetch-example.car -p bafybeic56z3yccnla3cutmvqsn5zy3g24muupcsjtoyp3pu5pm5amurjx4\n```\n\nThis will fetch the `bafybeic56z3yccnla3cutmvqsn5zy3g24muupcsjtoyp3pu5pm5amurjx4` CID from the network and save it to a file named `fetch-example.car` in our current working directory.\n\nThe `-p` progress flag is used to get more detailed information about the state of the retrieval.\n\n_Note: If you received a timeout issue, try using the `-t` flag to increase your timeout time to something longer than 20 seconds. Retrievability of some CIDs is highly variable on local network characteristics._\n\n_Note: For the internet cautious out there, the `bafybeic56z3yccnla3cutmvqsn5zy3g24muupcsjtoyp3pu5pm5amurjx4` CID is a directory that has a video titled `birb.mp4`, which is a video of a bird bouncing to the song \"Around the World\" by Daft Punk. We've been using it internally during the development of Lassie to test with._\n\nTo extract the contents of the `fetch-example.car` file we created in the previous example, we would run:\n\n```bash\n$ car extract -f fetch-example.car\n```\n\nTo fetch and extract at the same time, we can use the `lassie fetch` command and pipe the output to the `car extract` command:\n\n```bash\n$ lassie fetch -o - -p bafybeic56z3yccnla3cutmvqsn5zy3g24muupcsjtoyp3pu5pm5amurjx4 | car extract\n```\n\nThe `-o` output flag is used with the `-` character to specify that the output should be written to `stdout`. The `car extract` command reads input via `stdin` by default, so the output of the `lassie fetch` command is piped to the `car extract` command.\n\nYou should now have a `birb.mp4` file in your current working directory. Feel free to play it with your favorite video player!\n\n### HTTP API\n\nThe lassie HTTP API allows one to run a web server that can be used to retrieve content from the Filecoin/IPFS network via HTTP requests. The HTTP API is best used when needing to retrieve content from the network via HTTP requests, whether that be from a browser or a programmatic tool like `curl`. We will be using `curl` for the following examples but know that any HTTP client can be used including a web browser. Curl specific behavior will be noted when applicable.\n\nThe API server can be started with the `lassie daemon` command:\n\n```bash\n$ lassie daemon\n\nLassie daemon listening on address 127.0.0.1:41443\nHit CTRL-C to stop the daemon\n```\n\nThe port can be changed by using the `-p` port flag. Any available port will be used by default.\n\nMore information about available flags can be found by running `lassie daemon --help`.\n\nTo fetch content using the HTTP API, make a `GET` request to the `/ipfs/<CID>[/path/to/content]` endpoint:\n\n```bash\n$ curl http://127.0.0.1:41443/ipfs/<CID>[/path/to/content]\n```\n\nBy default, this will output the contents of the CID to `stdout`.\n\nTo save the output to a file, use the `filename` query parameter:\n\n```bash\n$ curl http://127.0.0.1:41443/ipfs/<CID>[/path/to/content]?filename=<filename> --output <filename>\n```\n\n_CURL Note: With curl we need to also specify the `--output <filename>` option. However, putting the above URL into a browser will download the file with the given filename parameter value upon a successful fetch._\n\nMore information about HTTP API requests and responses, as well as the numerous request parameters that can be used to control fetch behavior on a per request basis, can be found in the [HTTP Specification](./docs/HTTP_SPEC.md) document.\n\n#### Daemon Example\n\nWe can start the lassie daemon by running:\n\n```bash\n$ lassie daemon\n\nLassie daemon listening on address 127.0.0.1:41443\nHit CTRL-C to stop the daemon\n```\n\nWe can now fetch the same content we did in the [CLI example](#fetch-example) by running:\n\n```bash\n$ curl http://127.0.0.1:41443/ipfs/bafybeic56z3yccnla3cutmvqsn5zy3g24muupcsjtoyp3pu5pm5amurjx4?filename=daemon-example.car --output daemon-example.car\n```\n\n_CURL Note: With curl we need to also specify the `--output <filename>` option. However, putting the above URL into a browser will download the file with the given filename parameter value upon a successful fetch._\n\nTo extract the contents of the `daemon-example.car` file we created in the above example, we would run:\n\n```bash\n$ car extract -f daemon-example.car\n```\n\n### Golang Library\n\nThe lassie library allows one to integrate lassie into their own Go programs. The library is best used when needing to retrieve content from the network programmatically.\n\nThe lassie dependency can be added to a project with the following command:\n\n```bash\n$ go install github.com/filecoin-project/lassie/cmd/lassie@latest\n```\n\nThe lassie library can then be imported into a project with the following import statement:\n\n```go\nimport \"github.com/filecoin-project/lassie/pkg/lassie\"\n```\n\nThe following code shows a small example for how to use the lassie library to fetch a CID:\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/filecoin-project/lassie/pkg/lassie\"\n\t\"github.com/filecoin-project/lassie/pkg/storage\"\n\t\"github.com/filecoin-project/lassie/pkg/types\"\n\t\"github.com/ipfs/go-cid\"\n\ttrustlessutils \"github.com/ipld/go-trustless-utils\"\n)\n\n// main creates a default lassie instance and fetches a CID\nfunc main() {\n\tctx := context.Background()\n\n\t// Create a default lassie instance\n\tlassie, err := lassie.NewLassie(ctx)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Prepare the fetch\n\trootCid := cid.MustParse(\"bafybeic56z3yccnla3cutmvqsn5zy3g24muupcsjtoyp3pu5pm5amurjx4\")       // The CID to fetch\n\tstore := storage.NewDeferredStorageCar(os.TempDir(), rootCid)                                 // The place to put the CAR file\n\trequest, err := types.NewRequestForPath(store, rootCid, \"\", trustlessutils.DagScopeAll, nil)  // The fetch request\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Fetch the CID\n\tstats, err := lassie.Fetch(ctx, request)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Print the stats\n\tfmt.Printf(\"Fetched %d blocks in %d bytes\\n\", stats.Blocks, stats.Size)\n}\n\n```\n\nLet's break down the above code.\n\nFirst, we create a default lassie instance:\n\n```go\nctx := context.Background()\n\n// Create a default lassie instance\nlassie, err := lassie.NewLassie(ctx)\nif err != nil {\n\tpanic(err)\n}\n```\n\nThe `NewLassie` function creates a new lassie instance with default settings, taking a `context.Context`. The context is used to control the lifecycle of the lassie instance. The function returns a `*Lassie` instance and an `error`. The `*Lassie` instance is used to make fetch requests. The `error` is used to indicate if there was an error creating the lassie instance.\n\nAdditionally, the `NewLassie` function takes a variable number of `LassieOption`s. These options can be used to customize the lassie instance. For example, the `WithGlobalTimeout` option can be used to set a global timeout for all fetch requests made with the lassie instance. More information about the available options can be found in the [lassie.go](https://pkg.go.dev/github.com/filecoin-project/lassie/pkg/lassie) file.\n\nNext, we prepare the fetch request:\n\n```go\n// Prepare the fetch\nrootCid := cid.MustParse(\"bafybeic56z3yccnla3cutmvqsn5zy3g24muupcsjtoyp3pu5pm5amurjx4\")       // The CID to fetch\nstore := storage.NewDeferredStorageCar(os.TempDir(), rootCid)                                 // The place to put the CAR file\nrequest, err := types.NewRequestForPath(store, rootCid, \"\", trustlessutils.DagScopeAll, nil)  // The fetch request\nif err != nil {\n\tpanic(err)\n}\n```\n\nThe `rootCid` is the CID we want to fetch. The `store` is where we want to write the car file. In this case we are choosing to store it in the OS's temp directory. The `request` is the resulting fetch request that we'll hand to the `lassie.Fetch` function.\n\nThe `request` is created using the `NewRequestForPath` function. The only new information that this function takes that we haven't discussed is the `path` and the `dagScope`. The `path` is an optional path string to a file in the CID being requested. In this case we don't have a path, so pass an empty string. The `dagScope` has to do with traversal and describes the shape of the DAG fetched at the terminus of the specified path whose blocks are included in the returned CAR file after the blocks required to traverse path segments. More information on `dagScope` can be found in the [dag-scope HTTP Specification](./docs/HTTP_SPEC.md#dag-scope-request-query-parameter) section. In this case we use `trustlessutils.DagScopeAll` to specify we want everything from the root CID onward.\n\nThe function returns a `*types.Request` and an `error`. The `*types.Request` is the resulting fetch request we'll pass to `lassie.Fetch`, and the `error` is used to indicate if there was an error creating the fetch request.\n\nFinally, we fetch the CID:\n\n```go\n// Fetch the CID\nstats, err := lassie.Fetch(ctx, request)\nif err != nil {\n\tpanic(err)\n}\n```\n\nThe `Fetch` function takes a `context.Context`, a `*types.Request`, and a `*types.FetchOptions`. The `context.Context` is used to control the lifecycle of the fetch. The `*types.Request` is the fetch request we made above. The `*types.FetchOptions` is used to control the behavior of the fetch, but it's variadic, so we don't pass anything. The function returns a `*types.FetchStats` and an `error`. The `*types.FetchStats` is the fetch stats. The `error` is used to indicate if there was an error fetching the CID.\n\n### Roots, pieces and payloads\n\nLassie uses the term **Root** to refer to the head block of a potential graph (DAG) of IPLD blocks. This is typically the block you request, using its CID, when you perform a _fetch_ with Lassie. Of course a root could also be a sub-root of a larger graph, but when performing a retrieval with Lassie, you are focusing on the graph underneath the block you are fetching, and considerations of larger DAGs are not relevant.\n\nIn the Filecoin ecosystem, there exists terminology related to \"pieces\" and \"payloads\" and there may be confusion between the way lassie uses the term \"root CID\" and some of the language used in Filecoin. A **Piece** is a Filecoin storage deal unit, typically containing user data organized into a CAR; then padded to size to form a portion of a Filecoin sector. Filecoin pieces have their own CIDs, and it is possible to retrieve a whole, raw piece, from Filecoin. This can lead to terminology such as \"piece root CID\". Lassie currently does not perform whole-piece retrievals, and is not intended to be able to handle piece CIDs. Additionally, in Filecoin the term **Payload** is sometimes used in reference to the IPLD data inside a piece when performing a storage or retrieval deal. This is closer to the way Lassie uses the term **Root** and historical Lassie code contains some references to \"payloads\" that are actually referring to the root CID of a graph.\n\n## Contribute\n\nEarly days PRs are welcome!\n\n## License\n\nThis library is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2022. Protocol Labs, Inc.\n", "release_dates": ["2024-01-27T03:53:57Z", "2023-10-12T05:19:57Z", "2023-10-12T04:42:45Z", "2023-10-02T07:46:14Z", "2023-09-27T04:44:00Z", "2023-09-21T10:00:38Z", "2023-09-19T23:28:01Z", "2023-09-11T10:47:52Z", "2023-08-24T07:23:39Z", "2023-08-24T06:18:26Z", "2023-08-24T05:51:49Z", "2023-08-16T00:20:56Z", "2023-08-02T15:28:52Z", "2023-07-14T05:59:26Z", "2023-07-13T23:55:51Z", "2023-07-13T00:07:56Z", "2023-06-22T06:30:38Z", "2023-06-14T01:45:45Z", "2023-06-07T20:10:25Z", "2023-06-05T19:07:58Z", "2023-05-30T01:10:35Z", "2023-05-25T17:44:42Z", "2023-05-15T16:16:42Z", "2023-05-10T01:07:45Z", "2023-05-09T21:33:58Z", "2023-05-09T10:28:16Z", "2023-05-09T10:21:57Z", "2023-05-03T23:56:36Z", "2023-04-24T06:26:15Z", "2023-04-07T01:56:06Z"]}, {"name": "lassie-event-recorder", "description": "Records events emitted from lassie", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# :movie_camera: Lassie Event Recorder\n\n[![Go Reference](https://pkg.go.dev/badge/github.com/filecoin-project/lassie-event-recorder.svg)](https://pkg.go.dev/github.com/filecoin-project/lassie-event-recorder)\n[![Go Test](https://github.com/filecoin-project/lassie-event-recorder/actions/workflows/go-test.yml/badge.svg)](https://github.com/filecoin-project/lassie-event-recorder/actions/workflows/go-test.yml)\n> Records Retrieval Events published by [`lassie`](https://github.com/filecoin-project/lassie)\n\nThis repo provides a Golang implementation of [`lassie`](https://github.com/filecoin-project/lassie) event recorder.\nIt exposes a REST HTTP API that accepts `lassie` retrieval events and stores them in the configured postgres database. \n\n\n## Install\n\nTo install the event recorder run:\n```shell\ngo install github.com/filecoin-project/lassie-event-recorder/cmd/recorder@latest\n```\n\n## Usage\n\n```text\n$ recorder --help\nUsage of recorder:\n  -dbDSN string\n        The database Data Source Name. Alternatively, it may be specified via LASSIE_EVENT_RECORDER_DB_DSN environment variable. If both are present, the environment variable takes precedence.\n  -httpListenAddr string\n        The HTTP server listen address in address:port format. (default \"0.0.0.0:8080\")\n  -logLevel string\n        The logging level. Only applied if GOLOG_LOG_LEVEL environment variable is unset. (default \"info\")\n```\n\n### Running event recorder locally\n\nTo start the recorder service running locally, execute:\n```shell\ndocker-compose up\n```\n\nThe recorder service is then accessible on `localhost:8080`. \nHere is an example `curl` that posts an event to the server:\n\n```shell\ncurl -v -X POST --location \"http://localhost:8080/v1/retrieval-events\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\n          \\\"events\\\": [\n            {\n              \\\"retrievalId\\\": \\\"d05a522e-9608-401a-a33f-1eb4ac4111a0\\\",\n              \\\"instanceId\\\": \\\"test-instance-id\\\",\n              \\\"cid\\\": \\\"bafybeic4jpi2detp5n3q6rjo7ckulebtr7dsvt2tbrtcqlnnzqmi3bzz2y\\\",\n              \\\"storageProviderId\\\": \\\"12D3KooWHwRmkj4Jxfo2YnKJC4YBzTNEGDW6Et4E68r7RYVXk46h\\\",\n              \\\"phase\\\": \\\"query\\\",\n              \\\"phaseStartTime\\\": \\\"2023-03-02T00:15:50.479910907Z\\\",\n              \\\"eventName\\\": \\\"started\\\",\n              \\\"eventTime\\\": \\\"2023-03-02T00:15:52.361371026Z\\\"\n            }\n          ]\n        }\"\n```\n\nTo stop the containers press `Ctrl + C`.\n\n#### Postgres\n\nThe postgres container can be accessed via port `localhost:5432` for local DBMS setups or psql connections.\n\n#### Lassie\n\nLassie can talk to this local event recorder instance by using the `--endpoint-url` and `--endpoint-instance-id` options on either the `daemon`\n\n## Resources\n - [JS implementation of lassie event recorder](https://github.com/filecoin-project/autoretrieve-deploy/tree/19f55fad23555add12e312ee20e0f54383f8482c/lassie-event-recorder-api)\n - [K8S manifests to deploy event recorder as a service](https://github.com/filecoin-project/autoretrieve-deploy/tree/main/deploy/manifests/base/lassie-event-recorder)\n   - [`dev` manifests deployed using `nginx` ingress with basic auth enabled](https://github.com/filecoin-project/autoretrieve-deploy/tree/main/deploy/manifests/dev/us-east-2/lassie-event-recorder)\n\n## License\n[SPDX-License-Identifier: Apache-2.0 OR MIT](LICENSE.md)\n", "release_dates": ["2023-05-03T21:08:31Z", "2023-03-02T13:58:54Z"]}, {"name": "lightning-planning", "description": "This repo is purely for adding issues for the lightning project that don't fit elsewhere", "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "lily", "description": "capturing on-chain state for the filecoin network", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Lily\n[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white&style=flat-square)](https://pkg.go.dev/github.com/filecoin-project/lily) [![docker build status](https://img.shields.io/docker/cloud/build/filecoin/lily?style=flat-square)](https://hub.docker.com/repository/docker/filecoin/lily) [![CI build](https://img.shields.io/circleci/build/gh/filecoin-project/lily?label=ci%20build&style=flat-square)](https://app.circleci.com/pipelines/github/filecoin-project/lily)\n\nA component of [**Sentinel**](https://github.com/filecoin-project/sentinel), a collection of services which monitor the health and function of the Filecoin network. \n\nLily is a instrumentalized instance of a [**Lotus**](https://github.com/filecoin-project/lotus/) node that collects _permanent_ Filecoin chain metrics and writes them to a [**TimescaleDB**](https://github.com/timescale/timescaledb) time-series and relational datastore or to CSV files.\n\n## User documentation\n\nLily documentation, including with [build](https://lilium.sh/software/lily/setup/), [operation instructions](https://lilium.sh/software/lily/operation/), [data models](https://lilium.sh/data/models/) and [access to data dumps](https://lilium.sh/data/dumps/) is available at https://lilium.sh/.\n\n## Running tests\n\nTo quickly run tests, you can provide the `LILY_TEST_DB` envvar and execute `make test` like so:\n\n`LILY_TEST_DB=\"postgres://postgres:password@localhost:5432/postgres?sslmode=disable\" make test`\n\nFor more, manual test running, you could also prepare your environment in the following way:\n\nCreate a new DB in postgres for testing:\n\n```sql\nCREATE DATABASE lily_test;\n```\n\nMigrate the database to the latest schema:\n\n```sh\nlily migrate --db \"postgres://username@localhost/lily_test?sslmode=disable\" --latest\n```\n\nRun the tests:\n\n```sh\nLILY_TEST_DB=\"postgres://username@localhost/lily_test?sslmode=disable\" go test ./...\n```\n\n\n## Metrics, tracing and debugging\n\nSee https://lilium.sh/software/lily/operation/#metrics--debugging.\n\n## Versioning and Releases\n\nFeature branches and master are designated as **unstable** which are internal-only development builds. \n\nPeriodically a build will be designated as **stable** and will be assigned a version number by tagging the repository\nusing Semantic Versioning in the following format: `vMajor.Minor.Patch`.\n\n## Other Topics\n\n- [Release Management](docs/release_management.md)\n- [Schema/Migration Management](docs/migrations.md)\n\n## Code of Conduct\n\nLily follows the [Filecoin Project Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md). Before contributing, please acquaint yourself with our social courtesies and expectations.\n\n\n## Contributing\n\nWelcoming [new issues](https://github.com/filecoin-project/lily/issues/new) and [pull requests](https://github.com/filecoin-project/lily/pulls).\n\n\n## License\n\nThe Filecoin Project and Lily are dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/lily/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/lily/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": ["2023-12-11T06:55:49Z", "2023-08-31T03:05:23Z", "2023-08-02T17:58:14Z", "2023-05-15T06:15:56Z", "2023-04-25T17:31:15Z", "2023-04-25T06:15:10Z", "2023-03-16T05:16:53Z", "2023-03-08T19:44:58Z", "2022-11-29T01:39:07Z", "2022-09-08T01:02:56Z", "2022-09-07T17:32:11Z", "2022-09-01T21:10:11Z", "2022-08-30T23:52:51Z", "2022-07-05T23:25:57Z", "2022-07-05T22:42:17Z", "2022-07-04T22:40:56Z", "2022-06-29T00:09:41Z", "2022-06-20T19:14:30Z", "2022-05-25T18:21:49Z", "2022-04-26T16:48:00Z", "2022-03-11T21:01:46Z", "2022-03-07T21:42:09Z", "2022-02-25T23:23:41Z", "2021-12-02T20:12:11Z", "2021-10-29T16:10:05Z", "2021-10-26T01:14:32Z", "2021-10-25T16:08:03Z", "2021-08-31T21:42:51Z", "2021-08-24T17:06:36Z", "2021-08-24T16:51:49Z"]}, {"name": "lily-archiver", "description": "Produces regular archives of on-chain state for the Filecoin network.", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Lily Archiver\n[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white&style=flat-square)](https://pkg.go.dev/github.com/filecoin-project/lily-archiver)\n\nProduces regular archives of on-chain state for the Filecoin network.\n\nLily Archiver is a component of [**Sentinel**](https://github.com/filecoin-project/sentinel), a collection of services which monitor the health and function of the Filecoin network. \n\n\n## Overview\n\nLily Archiver works in conjunction with a [Lily](https://github.com/filecoin-project/lily) node to extract data from the Filecoin network and package it into convenient archives for public reuse.\n\nThe data is partitioned into separate **tables** defined by the [Lily schema](https://github.com/filecoin-project/lily/tree/master/schemas).\nArchive files for each table are produced daily, covering a 24 hour period from midnight UTC. \nProduction will be delayed until at least one finality (900 epochs) after the end of the period. \nEach archive file is formatted as CSV compressed using gzip.\n\nArchive files are organised in a directory hierarchy following the pattern `network/format/schema/table/year`\n\n - Top level is the network name (for example: mainnet)\n - Second level is the format of the data (for example: csv)\n - Third level is the major schema version number being used for the extract (for example: 1)\n - Fourth level is the name of table (for example: messages)\n - Fifth level is the four digit year (for example: 2021)\n\nFile names in each directory use following pattern: `table-year-month-day.format.compression`\n\nExample of file in directory hierarchy: `mainnet/csv/1/messages/2021/messages-2021-08-02.csv.gz`\n\n## Outline of Operation\n\nLily Archiver needs to be paired with a Lily node which it will use to extract data by running walk jobs.\nIt produces archive files by executing walks against the Lily node, verifying the files produced do not contain errors and then compressing and shipping to the final archive location.\n\nThe `run` command starts the archiver as a long running daemon that will attempt to maintain a complete archive of the Filecoin chain.\n\nOn startup the archiver scans the files that have been shipped so far to determine whether there are any missing archive files that need to be reprocessed.\nIf it finds one or more missing files for a day it prepares a walk with the appropriate tasks and height range, submits it to Lily and waits for the walk to complete.\nIf all files are present the archiver will wait until it is allowed to process the current day's data. \nThe earliest this may happen is one finality (900 epochs) after midnight (which is about 7:30AM).\n\n## Running\n\nThe `run` command accepts several flags that may be used to configure the behaviour of the archiver.\n\n - `--ship-path` must be set to the root directory where the final archive files will be written. The archiver will create the necessary file hierachy beneath this directory (i.e. `<ship path>/network/format/schema/table/year`)\n - `--storage-name` must be set to the name of a file storage defined in the [Lily config file](https://lilium.sh/lily/setup.html#storage-definitions). If the section in the config file is `[Storage.File.CSV]` then the name will be `CSV`.\n - `--storage-path` must be set to the directory where Lily writes its output files. This is the path assigned to the named file storage in the [Lily config file](https://lilium.sh/lily/setup.html#storage-definitions).\n - `--tasks` may optionally be set to limit the tasks that this instance is responsible for. By default all known tasks will be run. Responsibility for different tasks may be split between multiple instances of the archiver by specifying a different subset of tasks for each one.\n - `--min-height` may be used to instruct the archiver to only consider archives after a certain epoch. This can be used to operate against a Lily node that only contains a partial history of the network, such as one initialised from a car export.\n\nBy default the archiver assumes it is operating against mainnet. The following flags may be used to configure it to operate against an alternate network. Note that these flags are hidden from the help output since they are rarely needed.\nIt is crucial that the Lily node paired with the archiver must have been built specifically for the selected network. Consult the [lily documentation](https://lilium.sh/lily/setup.html#build) for instructions on how to do this. \n\n - `--network` must be set to the name of the network. This is only used to determine the name of the directory in which shipped files should be placed.\n - `--genesis-ts` must be set to the UNIX timestamp of the genesis of the alternate network. This may vary depending on when the network was created. \n\nIf Lily is restarted or becomes unavailable during a walk, the archiver will wait until it is back online and resubmit the walk.\n\nThe archiver may be also restarted while a walk is in progress and it will attempt to find the correct one to wait for when it starts.\n\nExports that contain errors are not shipped, leaving a potential gap in the archive. When the archiver next scans the archive folder these missing files will automatically be scheduled for processing. The archiver will issue a new walk to cover just the failed tables. (Note: although this prevents the archiver from shipping bad exports it can also hold up all exports if the errors encountered are permanent failures since they will appear during any subsequent walk).\n\n## Notes\n\nThe dates for naming archive files are calculated using UTC and start at midnight.\n\nArchive files files do not contain a header row so multiple CSV files for the same table can simply be concatenated.\nA file for each table containing a single header row will be added to each table\u2019s folder.\n\nHeader files providing column names for each table are in each table\u2019s folder.\nThis can be prefixed to any CSV file for that table if needed.\nFor example: `mainnet/csv/1/messages/messages.header`\n\nA general schema definition for each table will be published in each table\u2019s folder. \nThis uses postgresql compatible DDL to document the table's column names and expected types. \nFor example: `mainnet/csv/1/messages/messages.schema`\n\nJSON is encoded as a string field in the CSV. A null value is represented by the token `null` (without quotes).\n\nThe following tables have json fields:\n - actor_states.state\n - internal_parsed_messages.params\n - parsed_messages.params\n - visor_processing_reports.errors_detected\n\nDateTime fields are formatted in RFC3339 format to millisecond granularity in UTC. For example 2021-08-12T23:20:50.522Z\n\nThe following tables have datetime fields:\n - visor_processing_reports.started_at\n - visor_processing_reports.completed_at\n\nRefer to the [Lily project](https://github.com/filecoin-project/lily) for precise details of the CSV export.\n\n## Code of Conduct\n\nLily Archiver follows the [Filecoin Project Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md). Before contributing, please acquaint yourself with our social courtesies and expectations.\n\n\n## Contributing\n\nWelcoming [new issues](https://github.com/filecoin-project/lily-archiver/issues/new) and [pull requests](https://github.com/filecoin-project/lily-archiver/pulls).\n\n\n## License\n\nThe Filecoin Project and Lily Archiver is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/sentinel-visor/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/sentinel-visor/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "lotus", "description": "Reference implementation of the Filecoin protocol, written in Go", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "<p align=\"center\">\n  <a href=\"https://lotus.filecoin.io/\" title=\"Filecoin Docs\">\n    <img src=\"documentation/images/lotus_logo_h.png\" alt=\"Project Lotus Logo\" width=\"244\" />\n  </a>\n</p>\n\n<h1 align=\"center\">Project Lotus - \u83b2</h1>\n\n<p align=\"center\">\n  <a href=\"https://circleci.com/gh/filecoin-project/lotus\"><img src=\"https://circleci.com/gh/filecoin-project/lotus.svg?style=svg\"></a>\n  <a href=\"https://codecov.io/gh/filecoin-project/lotus\"><img src=\"https://codecov.io/gh/filecoin-project/lotus/branch/master/graph/badge.svg\"></a>\n  <a href=\"https://goreportcard.com/report/github.com/filecoin-project/lotus\"><img src=\"https://goreportcard.com/badge/github.com/filecoin-project/lotus\" /></a>  \n  <a href=\"\"><img src=\"https://img.shields.io/badge/golang-%3E%3D1.18.8-blue.svg\" /></a>\n  <br>\n</p>\n\nLotus is an implementation of the Filecoin Distributed Storage Network. For more details about Filecoin, check out the [Filecoin Spec](https://spec.filecoin.io).\n\n## Building & Documentation\n\n> Note: The default `master` branch is the dev branch, please use with caution. For the latest stable version, checkout the most recent [`Latest release`](https://github.com/filecoin-project/lotus/releases).\n \nFor complete instructions on how to build, install and setup lotus, please visit [https://lotus.filecoin.io](https://lotus.filecoin.io/lotus/install/prerequisites/#supported-platforms). Basic build instructions can be found further down in this readme.\n\n## Reporting a Vulnerability\n\nPlease send an email to security@filecoin.org. See our [security policy](SECURITY.md) for more details.\n\n## Related packages\n\nThese repos are independent and reusable modules, but are tightly integrated into Lotus to make up a fully featured Filecoin implementation:\n\n- [go-fil-markets](https://github.com/filecoin-project/go-fil-markets) which has its own [kanban work tracker available here](https://app.zenhub.com/workspaces/markets-shared-components-5daa144a7046a60001c6e253/board)\n- [builtin-actors](https://github.com/filecoin-project/builtin-actors)\n\n## Contribute\n\nLotus is a universally open project and welcomes contributions of all kinds: code, docs, and more. However, before making a contribution, we ask you to heed these recommendations:\n\n1. If the proposal entails a protocol change, please first submit a [Filecoin Improvement Proposal](https://github.com/filecoin-project/FIPs).\n2. If the change is complex and requires prior discussion, [open an issue](github.com/filecoin-project/lotus/issues) or a [discussion](https://github.com/filecoin-project/lotus/discussions) to request feedback before you start working on a pull request. This is to avoid disappointment and sunk costs, in case the change is not actually needed or accepted.\n3. Please refrain from submitting PRs to adapt existing code to subjective preferences. The changeset should contain functional or technical improvements/enhancements, bug fixes, new features, or some other clear material contribution. Simple stylistic changes are likely to be rejected in order to reduce code churn.\n\nWhen implementing a change:\n\n1. Adhere to the standard Go formatting guidelines, e.g. [Effective Go](https://golang.org/doc/effective_go.html). Run `go fmt`.\n2. Stick to the idioms and patterns used in the codebase. Familiar-looking code has a higher chance of being accepted than eerie code. Pay attention to commonly used variable and parameter names, avoidance of naked returns, error handling patterns, etc.\n3. Comments: follow the advice on the [Commentary](https://golang.org/doc/effective_go.html#commentary) section of Effective Go.\n4. Minimize code churn. Modify only what is strictly necessary. Well-encapsulated changesets will get a quicker response from maintainers.\n5. Lint your code with [`golangci-lint`](https://golangci-lint.run) (CI will reject your PR if unlinted).\n6. Add tests.\n7. Title the PR in a meaningful way and describe the rationale and the thought process in the PR description.\n8. Write clean, thoughtful, and detailed [commit messages](https://chris.beams.io/posts/git-commit/). This is even more important than the PR description, because commit messages are stored _inside_ the Git history. One good rule is: if you are happy posting the commit message as the PR description, then it's a good commit message.\n\n## Basic Build Instructions\n**System-specific Software Dependencies**:\n\nBuilding Lotus requires some system dependencies, usually provided by your distribution.\n\nUbuntu/Debian:\n```\nsudo apt install mesa-opencl-icd ocl-icd-opencl-dev gcc git bzr jq pkg-config curl clang build-essential hwloc libhwloc-dev wget -y && sudo apt upgrade -y\n```\n\nFedora:\n```\nsudo dnf -y install gcc make git bzr jq pkgconfig mesa-libOpenCL mesa-libOpenCL-devel opencl-headers ocl-icd ocl-icd-devel clang llvm wget hwloc hwloc-devel\n```\n\nFor other distributions you can find the required dependencies [here.](https://lotus.filecoin.io/lotus/install/prerequisites/#supported-platforms) For instructions specific to macOS, you can find them [here.](https://lotus.filecoin.io/lotus/install/macos/)\n\n#### Go\n\nTo build Lotus, you need a working installation of [Go 1.21.7 or higher](https://golang.org/dl/):\n\n```bash\nwget -c https://golang.org/dl/go1.21.7.linux-amd64.tar.gz -O - | sudo tar -xz -C /usr/local\n```\n\n**TIP:**\nYou'll need to add `/usr/local/go/bin` to your path. For most Linux distributions you can run something like:\n\n```shell\necho \"export PATH=$PATH:/usr/local/go/bin\" >> ~/.bashrc && source ~/.bashrc\n```\n\nSee the [official Golang installation instructions](https://golang.org/doc/install) if you get stuck.\n\n### Build and install Lotus\n\nOnce all the dependencies are installed, you can build and install the Lotus suite (`lotus`, `lotus-miner`, and `lotus-worker`).\n\n1. Clone the repository:\n\n   ```sh\n   git clone https://github.com/filecoin-project/lotus.git\n   cd lotus/\n   ```\n   \nNote: The default branch `master` is the dev branch where the latest new features, bug fixes and improvement are in. However, if you want to run lotus on Filecoin mainnet and want to run a production-ready lotus, get the latest release[ here](https://github.com/filecoin-project/lotus/releases).\n\n2. To join mainnet, checkout the [latest release](https://github.com/filecoin-project/lotus/releases).\n\n   If you are changing networks from a previous Lotus installation or there has been a network reset, read the [Switch networks guide](https://lotus.filecoin.io/lotus/manage/switch-networks/) before proceeding.\n\n   For networks other than mainnet, look up the current branch or tag/commit for the network you want to join in the [Filecoin networks dashboard](https://network.filecoin.io), then build Lotus for your specific network below.\n\n   ```sh\n   git checkout <tag_or_branch>\n   # For example:\n   git checkout <vX.X.X> # tag for a release\n   ```\n\n   Currently, the latest code on the _master_ branch corresponds to mainnet.\n\n3. If you are in China, see \"[Lotus: tips when running in China](https://lotus.filecoin.io/lotus/configure/nodes-in-china/)\".\n4. This build instruction uses the prebuilt proofs binaries. If you want to build the proof binaries from source check the [complete instructions](https://lotus.filecoin.io/lotus/install/prerequisites/). Note, if you are building the proof binaries from source, [installing rustup](https://lotus.filecoin.io/lotus/install/linux/#rustup) is also needed.\n\n5. Build and install Lotus:\n\n   ```sh\n   make clean all #mainnet\n\n   # Or to join a testnet or devnet:\n   make clean calibnet # Calibration with min 32GiB sectors\n\n   sudo make install\n   ```\n\n   This will put `lotus`, `lotus-miner` and `lotus-worker` in `/usr/local/bin`.\n\n   `lotus` will use the `$HOME/.lotus` folder by default for storage (configuration, chain data, wallets, etc). See [advanced options](https://lotus.filecoin.io/lotus/configure/defaults/#environment-variables) for information on how to customize the Lotus folder.\n\n6. You should now have Lotus installed. You can now [start the Lotus daemon and sync the chain](https://lotus.filecoin.io/lotus/install/linux/#start-the-lotus-daemon-and-sync-the-chain).\n\n7. (Optional) Follow the [Setting Up Prometheus and Grafana](https://github.com/filecoin-project/lotus/tree/master/metrics/README.md) guide for detailed instructions on setting up a working monitoring system running against a local running lotus node.\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/lotus/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/lotus/blob/master/LICENSE-APACHE)\n", "release_dates": ["2024-01-11T15:38:45Z", "2023-12-09T15:42:51Z", "2023-12-09T14:48:29Z", "2023-12-09T12:30:49Z", "2023-12-05T21:54:02Z", "2023-11-22T13:46:24Z", "2023-11-22T10:49:30Z", "2023-11-16T20:04:23Z", "2023-11-16T19:04:22Z", "2023-11-08T16:49:18Z", "2023-11-08T15:59:39Z", "2023-11-02T00:30:09Z", "2023-11-01T23:53:32Z", "2023-10-31T22:55:25Z", "2023-10-31T22:55:34Z", "2023-10-18T15:33:45Z", "2023-10-17T14:50:39Z", "2023-10-13T01:22:21Z", "2023-09-27T18:49:53Z", "2023-09-05T22:06:01Z", "2023-08-09T22:03:40Z", "2023-07-11T17:52:40Z", "2023-07-04T22:49:51Z", "2023-06-28T19:42:42Z", "2023-06-28T19:46:36Z", "2023-06-20T20:18:50Z", "2023-06-05T23:10:00Z", "2023-05-31T20:50:51Z", "2023-05-10T21:40:37Z", "2023-05-03T23:13:32Z"]}, {"name": "lotus-archived", "description": "Archive of stale lotus branches", "language": "Go", "license": null, "readme": "## Lotus Archive\n\nThis repo contains an archive of branches from lotus.\n", "release_dates": []}, {"name": "lotus-badges", "description": null, "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "lotus-docs", "description": "Documentation for Lotus", "language": "HTML", "license": null, "readme": "# Lotus docs \n\nThis repository contains the documentation, build scripts, and issue tracking for the Lotus project. If you'd just like to read the Lotus docs, head to [lotus.filecoin.io](https://lotus.filecoin.io).\n\n## Get involved\n\nWe would **love \u2764\ufe0f your help** to improve existing items or make new ones even better!\n\n### Issues\n\nIf you find something wrong within this repository, please raise an [issue here \u2192](https://github.com/filecoin-project/lotus-docs/issues). \n\nIf you are attempting to close an issue, great! Thanks for the help! Please leave a comment within the issue requesting to be assigned to that issue **before** submitting a pull request. This minimizes the chance of multiple different contributors duplicating work by submitting pull requests for the same issue. If you submit a pull request to an issue _without_ first being assigned to it, that pull request may not be accepted.\n\n### Suggestions\n\nEveryone has an opinion when it comes to docs, and **that's a good thing**! Having folks from different backgrounds add to a discussion empowers everyone within that discussion. So if you've got something to add or would like to bring up a topic for discussion about the Lotus Docs project, please do so! [Just create an issue using the `kind/discussion` tag!](https://github.com/filecoin-project/lotus-docs/labels/kind%2Fdiscussion).\n\n#### Pull requests welcome\n\nFeel free to submit pull requests with any changes you'd like to see! If you're simply changing a typo or editing out a styling bug, you can add `ciskip` to the title of your pull request to stop Filecorgi from running.\n\n## Project set up\n\nIf you want to build this site locally, run the following:\n\n1. Clone this repository:\n\n   ```shell\n   git clone https://github.com/filecoin-project/lotus-docs.git\n   ```\n\n1. Move into the `lotus-docs` folder and install the NPM dependencies:\n\n   ```shell\n   cd lotus-docs\n   npm install\n   ```\n\n1. Boot up the application in _developer mode_:\n\n   ```shell\n   npm start\n   ```\n\n1. Open [localhost:1313](http://localhost:1313/) in your browser.\n1. Close the local server with `CTRL` + `c`.\n1. To restart the local server, run `npm start` from within the `lotus-docs` folder.\n1. Run `npm run build` to publish the site. The project will be built and saved to the `public` folder.\n\n## License\n\nDual-licensed by Protocol Labs under [Apache 2.0](http://www.apache.org/licenses/LICENSE-2.0) and [MIT](http://opensource.org/licenses/MIT) terms, as explained in the [Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/):\n", "release_dates": []}, {"name": "lua-filecoin", "description": "Prototype of Filecoin in Lua", "language": "Lua", "license": null, "readme": "## Multihash\n\nThere is a basic implementation of multihash here as seen in [multihash.lua](multihash.lua) and [test-multihash.lua](test-multihash.lua).\n\nCurrently this supports the following multihash types: `identity`, `sha`, `sha2-256`, `sha2-512`, `blake2b-*` (8-512), and `blake2s-*` (8-256).\n\nUsage sample:\n\n```lua\nlocal Multihash = require 'multihash'\n\n-- Multihash.encode(input, hash-name, [length-override]) -> multihash, hash-name\nlocal multihash = Multihash.encode('Hello World', 'blake2b-256')\n\n-- Multihash.decode(multihash, [index]) -> hash, hash-name, index\nlocal hash, name = Multihash.decode(multihash)\n\n-- Multihash.verify(input, multihash, [index]) -> verified, index\nassert(Multihash.verify('Hello World', multihash), 'Multihash mismatch')\n```\n\nThe actual implementations of the hash functions are hand-written in lua using luajit's bit and ffi libraries.  See [sha256.lua](sha256.lua), [sha512.lua](sha512.lua), [sha1.lua](sha1.lua), [blake2b.lua](blake2b.lua), and [blake2s.lua](blake2s.lua) for details.  The main module lazy requires these so only hashes actually used at runtime are ever loaded and compiled.\n\n## Multibase\n\nThere is a basic implementation of multibase here as seen in [multibase.lua](multibase.lua) and [test-multibase.lua](test-multibase.lua).\n\nCurrently this supports the following multibase encodings: `identity`, `base2`, `base8`, `base10`, `base16`, `base16upper`, `base32`, `base32upper`, `base32pad`, `base32padupper`, `base32hex`, `base32hexupper`, `base32hexpad`, `base32hexpadupper`, `base32z`, `base58flickr`, `base58btc`, `base64`, `base64pad`, `base64url`, and `base64urlpad`.\n\nUsage sample:\n\n```lua\nlocal Multibase = require 'multibase'\n\n-- Multibase.encode(raw, name-or-code) -> encoded, name\nlocal encoded = Multibase.encode('Hello World', 'hex')\n\n-- Multibase.decode(encoded) -> raw, name\nlocal original = Multibase.decode(encoded)\n```\n\nThe actual implementations of the base functions are hand-written in lua using luajit's bit and ffi libraries.  See [base-2.lua](base-2.lua), [base-8.lua](base-8.lua), [base-16.lua](base-16.lua), [base-32.lua](base-32.lua), [base-64.lua](base-64.lua), and [base-x.lua](base-x.lua) for details.  The main module lazy requires these so only bases actually used at runtime are ever loaded and compiled.", "release_dates": []}, {"name": "mapr", "description": "cross-platform Rust API for memory mapped IO", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# mapr\n\n> Fork of the great [memmap](https://github.com/danburkert/memmap-rs) library.\n\nA Rust library for cross-platform memory mapped IO.\n\n[![Documentation](https://docs.rs/mapr/badge.svg)](https://docs.rs/mapr)\n[![Crate](https://img.shields.io/crates/v/mapr.svg)](https://crates.io/crates/mapr)\n\n## Features\n\n- [x] file-backed memory maps\n- [x] anonymous memory maps\n- [x] synchronous and asynchronous flushing\n- [x] copy-on-write memory maps\n- [x] read-only memory maps\n- [x] stack support (`MAP_STACK` on unix)\n- [x] executable memory maps\n- [ ] huge page support\n\n## Platforms\n\n`mapr` should work on any platform supported by\n[`libc`](https://github.com/rust-lang-nursery/libc#platforms-and-documentation).\n`mapr` requires Rust stable 1.13 or greater.\n\n`mapr` is continuously tested on:\n  * `x86_64-unknown-linux-gnu` (Linux)\n  * `i686-unknown-linux-gnu`\n  * `x86_64-unknown-linux-musl` (Linux MUSL)\n  * `x86_64-apple-darwin` (OSX)\n  * `i686-apple-darwin`\n  * `x86_64-pc-windows-msvc` (Windows)\n  * `i686-pc-windows-msvc`\n  * `x86_64-pc-windows-gnu`\n  * `i686-pc-windows-gnu`\n\n`mapr` is continuously cross-compiled against:\n  * `arm-linux-androideabi` (Android)\n  * `aarch64-unknown-linux-gnu` (ARM)\n  * `arm-unknown-linux-gnueabihf`\n  * `mips-unknown-linux-gnu` (MIPS)\n  * `x86_64-apple-ios` (iOS)\n  * `i686-apple-ios`\n\n## License\n\n`mapr` is primarily distributed under the terms of both the MIT license and the\nApache License (Version 2.0).\n\nSee [LICENSE-APACHE](LICENSE-APACHE), [LICENSE-MIT](LICENSE-MIT) for details.\n\nCopyright (c) 2015 Dan Burkert.\n", "release_dates": []}, {"name": "merkletree", "description": "_merkle_ is a lightweight Rust implementation of a Merkle tree, external dependencies agnostic, std::hash compatible with efficient memory layout", "language": "Rust", "license": {"key": "bsd-3-clause", "name": "BSD 3-Clause \"New\" or \"Revised\" License", "spdx_id": "BSD-3-Clause", "url": "https://api.github.com/licenses/bsd-3-clause", "node_id": "MDc6TGljZW5zZTU="}, "readme": "# merkle\n\n[![Build Status](https://travis-ci.com/filecoin-project/merkle_light.svg?branch=master&style=flat)](https://travis-ci.com/filecoin-project/merkle_light)\n[![Issues](http://img.shields.io/github/issues/filecoin-project/merkle_light.svg?style=flat)](https://github.com/filecoin_project/merkle_light/issues)\n![License](https://img.shields.io/badge/license-bsd3-brightgreen.svg?style=flat)\n\n*merkle* is a lightweight Rust implementation of a [Merkle tree](https://en.wikipedia.org/wiki/Merkle_tree).\n\n## Features\n\n- external dependency agnostic\n- `std::hash::Hasher` compatibility\n- standard types hasher implementations\n- `#[derive(Hashable)]` support for simple struct\n- customizable merkle leaf/node hashing algorithm\n- support for custom hash types (e.g. [u8; 16], [u64; 4], [u128; 2], struct)\n- customizable hashing algorithm\n- linear memory layout, no nodes on heap\n- buildable from iterator, objects or hashes\n- certificate transparency style merkle hashing support\n- SPV support included (via proof type)\n- supports power of 2 arity merkletrees (only)\n- supports compound merkletrees (a tree of merkletrees)\n- supports compound-compound merkletrees (a tree of compound merkletrees)\n\n\n## Documentation\n\nDocumentation is [available](https://docs.rs/merkletree).\n\n# Examples\n\nThe most relevant examples are located in the following files:\n\n* `test_common.rs`: custom hash example xor128, misc shared utils\n* `test_xor128.rs`: most comprehensive tests for library features\n* `proof.rs`: contains impl and tests for proofs across pow2 arity trees\n\n# Building and testing\n\n```\n# Run tests in release mode\ncargo test --release --all\n\n# Run ignored tests in release mode\ncargo test --release --all -- --ignored\n```\n\n\n\n## Bug Reporting\n\nPlease report bugs either as pull requests or as issues in [the issue\ntracker](https://github.com/filecoin-project/merkle_light). *merkle* has a\n**full disclosure** vulnerability policy. **Please do NOT attempt to report\nany security vulnerability in this code privately to anybody.**\n\n## License\n\nSee [LICENSE](LICENSE).\n", "release_dates": []}, {"name": "meta-aggregator-frontend", "description": null, "language": "TypeScript", "license": null, "readme": "This is a [Next.js](https://nextjs.org/) project bootstrapped with [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app).\n\n## Getting Started\n\nFirst, run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nYou can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.\n\nThis project uses [`next/font`](https://nextjs.org/docs/basic-features/font-optimization) to automatically optimize and load Inter, a custom Google Font.\n\n## Learn More\n\nTo learn more about Next.js, take a look at the following resources:\n\n- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\n- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\n\nYou can check out [the Next.js GitHub repository](https://github.com/vercel/next.js/) - your feedback and contributions are welcome!\n\n## Deploy on Vercel\n\nThe easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.\n\nCheck out our [Next.js deployment documentation](https://nextjs.org/docs/deployment) for more details.\n", "release_dates": []}, {"name": "motion", "description": ":motorcycle: Accelerating Data onto FileCoin", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# :motorcycle: DeStor REST API for Filecoin\n\n*Accelerating data onto Filecoin!*\n\n## Table of Contents\n\n- [Background](#background)\n- [Install and setup](#install-and-setup)\n- [Usage](#usage)\n- [API Specification](#api-specification)\n- [Status](#status)\n- [Local Development](#local-development)\n- [License](#license)\n\n## Background\n\nThe DeStor REST API for Filecoin is an interface to easily propel data onto the Filecoin network. The REST API is implemented here in a service named 'motion'. This service aims to create an easy path for independent software vendors to integrate Filecoin as a storage layer.\n\n## Install and setup\n\n### Prerequisites\n\n\n1. A Filecoin wallet to make deals with, for which you are in possession of the private key. Various options for obtaining a wallet can be found here (https://docs.filecoin.io/basics/assets/wallets/). \n\n2. A server (bare metal or VM) to run Motion on, with Docker Engine installed on that server with the Docker Compose plugin included. Recommended hardware requirements for servers are:\n- Because we run docker, Linux variants are preferred for the OS\n- Recommend at least >500GB disk space available for staging data. The complete Filecoin deal making process takes up to 3 days, and you will need to hold all data until deal making is complete. So the amount of free space you will need is roughly the amount of data you want to onboard per day times 3.\n- In general, we do not believe Motion is processor or memory intensive, but a machine with at least 32GB of RAM is optimal\n- You will also need `git` installed on this machine.\n- The server must have a static IP and/or a domain name that points to it, with a port open so you can transfer data from Motion to Filecoin storage providers\n\n### Setting up motion for the first time\n\nStart by cloning this repository:\n\n```shell\ngit clone https://github.com/filecoin-project/motion.git\n```\n\nBefore you can run motion, you must configure it. First, from the motion directory, copy `.env.example` to `.env`:\n\n```shell\ncp .env.example .env\n```\n\nNow open `.env` and set the required values for your instance of motion. At minimum, you need to set the following values (excerpt from `.env.example` file):\n\n```yaml\n# Comma seperated list of storage providers motion should make storage deals with\n# You must set this value to contain at least one storage provider for motion to\n# work\nMOTION_STORAGE_PROVIDERS=\n\n# The private key of the wallet you will use with motion, in hexadecimal format.\n# This is the output of `lotus wallet export ~address~` if you are using lotus\n# If you are obtaining a wallet through another method follow your wallet providers\n# instructions to get your wallet's provider key.\n# This wallet must exist on the chain. If it is a newly created wallet, you may send 0 FIL to it\n# to ensure it is on chain.\nMOTION_WALLET_KEY=\n\n# This is the domain/IP you will expose publicly to transfer data to storage providers\n# When you initialize the singularity docker setup, it will start a server to deliver\n# content to storage providers on localhost:7778. However, you will need to either \n# open this specific port on your firewall, and set this value to http://~your-static-ip~:7778\n# or you will need to setup reverse proxying from a dedicated web server like NGinx\nSINGULARITY_CONTENT_PROVIDER_DOMAIN=\n```\n\nAgain, you could open an issue if you need assistance setting up your wallet, your server to expose a port for data transfers publicly on your server.\n\nAs needed, you can also set additional values in your motion `.env`` file for more custom configurations.\n\n## Usage\n\nOnce you've configured your `.env`, you're ready to start motion. From the local repository, simply run \n\n```shell\ndocker compose up\n```\n(if you don't want to see log messages directly in your terminal, run `docker compose up -d`)\n\nYou'll know your motion is up an running when you see a message like this in the docker logs:\n\n```\n2023-09-07 17:49:57 motion-motion-1                        | 2023-09-08T00:49:57.530Z   INFO    motion/api/server       server/server.go:53  HTTP server started successfully.        {\"address\": \"[::]:40080\"}\n```\n\nYour copy of motion is now running. The Motion HTTP API is now running on port 40080 of your server's localhost.\n\n### Store blobs\n \nTo store an example blob, use the following `curl` command :\n```shell\necho \"fish\" | curl -X POST -H \"Content-Type: application/octet-stream\" -d @- http://localhost:40080/v0/blob\n```\nThe response should include a blob ID which you can then use the fetch the blob back. Example:\n```json\n{\"id\":\"ad7ef987-a932-495c-aa0c-7ffcabeda45f\"}\n```\n\n### Storing onto Filecoin\n\nMotion will begin saving data to Filecoin when it's holding at least 16GB of data that hasn't been backed up with a storage provider.\n\nIf you want to test storing an actual filecoin deal, the following simple script will put about 20GB of random data into motion:\n\n```shell\nfor i in {0..20}; do head -c 1000000000 /dev/urandom | curl -X POST --data-binary @- -H \"Content-Type: application/octet-stream\" http://localhost:40080/v0/blob; done\n```\n\nThis should be enough to trigger at least 1 Filecoin deal being made from Motion\n\n### Retrieve a stored blob\n\nTo retrieve a stored blob, send a `GET` request to the Motion API with the desired blob ID.\nThe following command retrieves the blob stored earlier:\n\n```shell\ncurl http://localhost:40080/v0/blob/ad7ef987-a932-495c-aa0c-7ffcabeda45f\n```\nThis should print the content of the blob on the terminal:\n\n```\nfish\n```\n\nAlternatively, you can browse the same URL in a web browser, which should prompt you to download the binary file.\n\n### Check the status of an uploaded blob\n\nIn addition to retrieving data for a blob, you can also check the status of its storage on Filecoin:\n\n```shell\ncurl http://localhost:40080/v0/blob/ad7ef987-a932-495c-aa0c-7ffcabeda45f/status | jq .\n```\n(`jq` being used to pretty print here -- make sure it's installed on your machine. you don't need to pipe to jq but the output will be more readable)\n\n```json\n{\n  \"id\": \"ad7ef987-a932-495c-aa0c-7ffcabeda45f\",\n  \"replicas\": [\n    {\n      \"provider\": \"f1234\",\n      \"status\": \"active\",\n      \"lastVerified\": \"2020-12-01T22:48:00Z\",\n      \"expiration\": \"2021-08-18T22:48:00Z\"\n    }\n  ]\n}\n```\n\n## API Specification\n\nSee the [Motion OpenAPI specification](openapi.yaml).\n\n## Status\n\n:construction: This project is currently under active development.\n\n## Local Development\n\nTo run all containers with locally built motion, run:\n\n```shell\ndocker compose -f ./docker-compose-local-dev.yml up --build\n```\n\nTo run all containers with locally built motion as well as Singularity, run:\n\n```shell\ndocker compose -f ./docker-compose-local-dev-with-singularity.yml up --build\n```\n\n### Full devnet for local testing\n\nThe [./integration/test](./integration/test/) directory contains a full local devnet for running integration tests (see the [README](./integration/test/README.md) for more information) and can also be used to manually test the Motion API locally.\n\nThe `motionlarity/up` make target in the integration test directory can be used to deploy a full Lotus, Boost, Singularity and Motion stack to execute against a devnet with Lotus sector size of 8MiB, Singularity CAR size of 7MiB and a Motion minimum deal threshold of 4MiB. The Motion API is exposed on port 40080 and the Singularity API is exposed on port 7778. The `motionlarity/up` build target builds using a Docker Compose file that will compile Motion from the local source directory. The `motionlarity/down` make target can be used to tear down the stack.\n\nWith a Motion minimum deal threshold of 4Mib, the following command can be used (instead of the 20GB form above) to submit a blob large enough to trigger a deal:\n\n```shell\nhead -c 5000000 /dev/urandom | curl -X POST --data-binary @- -H \"Content-Type: application/octet-stream\" http://localhost:40080/v0/blob\n```\n\nUse the `/status` `curl` command as above to check the Motion status of the blob. It should appear as `\"proposed\"` across replicas which means it's pending publishing in Boost.\n\nYou can check the local Boost instance for the status of deals ready to publish:\n\n```shell\necho '{\"operationName\":\"AppDealPublishQuery\",\"variables\":{},\"query\":\"query AppDealPublishQuery{dealPublish{Deals{ID __typename}__typename}}\"}' \\\n  | curl -X GET -d @- http://localhost:8080/graphql/query | jq .\n```\n\nNote that Boost does not automatically publish the deals on the devnet, so you will need to manually trigger deal publishing:\n\n```shell\necho '{\"operationName\":\"AppDealPublishNowMutation\",\"variables\":{},\"query\":\"mutation AppDealPublishNowMutation{dealPublishNow}\"}' \\\n  | curl -X GET -d @- http://localhost:8080/graphql/query | jq .\n```\n\nRunning the Motion `/status` `curl` command again should show that the deal replicas have been published and the status is now `\"published\"`.\n\n## License\n\n[SPDX-License-Identifier: Apache-2.0 OR MIT](LICENSE.md)\n", "release_dates": ["2023-11-09T21:03:33Z", "2023-11-03T23:20:19Z", "2023-10-05T18:40:08Z", "2023-09-08T20:02:55Z"]}, {"name": "motion-arsenal", "description": null, "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Arsenal\n\n[![codecov](https://codecov.io/gh/scality/Arsenal/branch/development/8.1/graph/badge.svg?token=X0esXhJSwb)](https://codecov.io/gh/scality/Arsenal)\n\nCommon utilities for the S3 project components\n\nWithin this repository, you will be able to find the shared libraries for the\nmultiple components making up the whole Project.\n\n* [Guidelines](#guidelines)\n* [Shuffle](#shuffle) to shuffle an array.\n* [Errors](#errors) load an object of errors instances.\n    - [errors/arsenalErrors.json](errors/arsenalErrors.json)\n\n## Guidelines\n\nPlease read our coding and workflow guidelines at\n[scality/Guidelines](https://github.com/scality/Guidelines).\n\n### Contributing\n\nIn order to contribute, please follow the\n[Contributing Guidelines](\nhttps://github.com/scality/Guidelines/blob/master/CONTRIBUTING.md).\n\n## Shuffle\n\n### Usage\n\n``` js\nimport { shuffle } from 'arsenal';\n\nlet array = [1, 2, 3, 4, 5];\n\nshuffle(array);\n\nconsole.log(array);\n\n//[5, 3, 1, 2, 4]\n```\n\n## Errors\n\n### Usage\n\n``` js\nimport { errors } from 'arsenal';\n\nconsole.log(errors.AccessDenied);\n\n//{ [Error: AccessDenied]\n//    code: 403,\n//    description: 'Access Denied',\n//    AccessDenied: true }\n\n```\n\n## Clustering\n\nThe clustering class can be used to set up a cluster of workers. The class will\ncreate at least 1 worker, will log any worker event (started, exited).\nThe class also provides a watchdog which restarts the workers in case of\nfailure until the stop() method is called.\n\n### Usage\n\n#### Simple\n\n```\nimport { Clustering } from 'arsenal';\n\nconst cluster = new Clustering(clusterSize, logger);\ncluster.start(current => {\n    // Put here the logic of every worker.\n    // 'current' is the Clustering instance, worker id is accessible by\n    // current.getIndex()\n});\n```\n\nThe callback will be called every time a worker is started/restarted.\n\n#### Handle exit\n\n```\nimport { Clustering } from 'arsenal';\n\nconst cluster = new Clustering(clusterSize, logger);\ncluster.start(current => {\n    // Put here the logic of every worker.\n    // 'current' is the Clustering instance, worker id is accessible by\n    // current.getIndex()\n}).onExit(current => {\n    if (current.isMaster()) {\n        // Master process exiting\n    } else {\n        const id = current.getIndex();\n        // Worker (id) exiting\n    }\n});\n```\n\nYou can handle exit event on both master and workers by calling the\n'onExit' method and setting the callback. This allows release of resources\nor save state before exiting the process.\n\n#### Silencing a signal\n\n```\nimport { Clustering } from 'arsenal';\n\nconst cluster = new Clustering(clusterSize, logger);\ncluster.start(current => {\n    // Put here the logic of every worker.\n    // 'current' is the Clustering instance, worker id is accessible by\n    // current.getIndex()\n}).onExit((current, signal) => {\n    if (signal !== 'SIGTERM') {\n        process.exit(current.getStatus());\n    }\n});\n```\n\nYou can silence stop signals, by simply not exiting on the exit callback\n\n#### Shutdown timeout\n\n```\nimport { Clustering } from 'arsenal';\n\nconst cluster = new Clustering(clusterSize, logger, 1000);\ncluster.start(current => {\n    // Put here the logic of every worker.\n    // 'current' is the Clustering instance, worker id is accessible by\n    // current.getIndex()\n}).onExit((current, signal) => {\n    if (signal === 'SIGTERM') {\n        // releasing resources\n    }\n});\n```\n\nBy default, the shutdown timeout is set to 5000 milliseconds. This timeout is\nused only when you explicitly call the stop() method. This window is\nused to let the application release its resources, but if timeout occurs\nbefore the application has finished it's cleanup, a 'SIGKILL' signal is send\nto the process (which results in an immediate termination, and this signal\ncan't be caught).\n\n[badgepub]: https://circleci.com/gh/scality/Arsenal.svg?style=svg\n[badgepriv]: http://ci.ironmann.io/gh/scality/Arsenal.svg?style=svg&circle-token=c3d2570682cba6763a97ea0bc87521941413d75c\n", "release_dates": []}, {"name": "motion-cloudserver", "description": null, "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Zenko CloudServer\n\n![Zenko CloudServer logo](res/scality-cloudserver-logo.png)\n\n[![Docker Pulls][badgedocker]](https://hub.docker.com/r/zenko/cloudserver)\n[![Docker Pulls][badgetwitter]](https://twitter.com/zenko)\n\n## Overview\n\nCloudServer (formerly S3 Server) is an open-source Amazon S3-compatible\nobject storage server that is part of [Zenko](https://www.zenko.io),\nScality\u2019s Open Source Multi-Cloud Data Controller.\n\nCloudServer provides a single AWS S3 API interface to access multiple\nbackend data storage both on-premise or public in the cloud.\n\nCloudServer is useful for Developers, either to run as part of a\ncontinous integration test environment to emulate the AWS S3 service locally\nor as an abstraction layer to develop object storage enabled\napplication on the go.\n\n## Learn more at [www.zenko.io/cloudserver](https://www.zenko.io/cloudserver/)\n\n## [May I offer you some lovely documentation?](http://s3-server.readthedocs.io/en/latest/)\n\n## Docker\n\n[Run your Zenko CloudServer with Docker](https://hub.docker.com/r/zenko/cloudserver/)\n\n## Contributing\n\nIn order to contribute, please follow the\n[Contributing Guidelines](\nhttps://github.com/scality/Guidelines/blob/master/CONTRIBUTING.md).\n\n## Installation\n\n### Dependencies\n\nBuilding and running the Zenko CloudServer requires node.js 10.x and yarn v1.17.x\n. Up-to-date versions can be found at\n[Nodesource](https://github.com/nodesource/distributions).\n\n### Clone source code\n\n```shell\ngit clone https://github.com/scality/S3.git\n```\n\n### Install js dependencies\n\nGo to the ./S3 folder,\n\n```shell\nyarn install --frozen-lockfile\n```\n\nIf you get an error regarding installation of the diskUsage module,\nplease install g++.\n\nIf you get an error regarding level-down bindings, try clearing your yarn cache:\n\n```shell\nyarn cache clean\n```\n\n## Run it with a file backend\n\n```shell\nyarn start\n```\n\nThis starts a Zenko CloudServer on port 8000. Two additional ports 9990 and\n9991 are also open locally for internal transfer of metadata and data,\nrespectively.\n\nThe default access key is accessKey1 with\na secret key of verySecretKey1.\n\nBy default the metadata files will be saved in the\nlocalMetadata directory and the data files will be saved\nin the localData directory within the ./S3 directory on your\nmachine.  These directories have been pre-created within the\nrepository.  If you would like to save the data or metadata in\ndifferent locations of your choice, you must specify them with absolute paths.\nSo, when starting the server:\n\n```shell\nmkdir -m 700 $(pwd)/myFavoriteDataPath\nmkdir -m 700 $(pwd)/myFavoriteMetadataPath\nexport S3DATAPATH=\"$(pwd)/myFavoriteDataPath\"\nexport S3METADATAPATH=\"$(pwd)/myFavoriteMetadataPath\"\nyarn start\n```\n\n## Run it with multiple data backends\n\n```shell\nexport S3DATA='multiple'\nyarn start\n```\n\nThis starts a Zenko CloudServer on port 8000.\nThe default access key is accessKey1 with\na secret key of verySecretKey1.\n\nWith multiple backends, you have the ability to\nchoose where each object will be saved by setting\nthe following header with a locationConstraint on\na PUT request:\n\n```shell\n'x-amz-meta-scal-location-constraint':'myLocationConstraint'\n```\n\nIf no header is sent with a PUT object request, the\nlocation constraint of the bucket will determine\nwhere the data is saved. If the bucket has no location\nconstraint, the endpoint of the PUT request will be\nused to determine location.\n\nSee the Configuration section in our documentation\n[here](http://s3-server.readthedocs.io/en/latest/GETTING_STARTED/#configuration)\nto learn how to set location constraints.\n\n## Run it with an in-memory backend\n\n```shell\nyarn run mem_backend\n```\n\nThis starts a Zenko CloudServer on port 8000.\nThe default access key is accessKey1 with\na secret key of verySecretKey1.\n\n## Run it with Vault user management\n\nNote: Vault is proprietary and must be accessed separately.\n\n```shell\nexport S3VAULT=vault\nyarn start\n```\n\nThis starts a Zenko CloudServer using Vault for user management.\n\n[badgetwitter]: https://img.shields.io/twitter/follow/zenko.svg?style=social&label=Follow\n[badgedocker]: https://img.shields.io/docker/pulls/scality/s3server.svg\n[badgepub]: https://circleci.com/gh/scality/S3.svg?style=svg\n[badgepriv]: http://ci.ironmann.io/gh/scality/S3.svg?style=svg&circle-token=1f105b7518b53853b5b7cf72302a3f75d8c598ae\n", "release_dates": ["2023-10-16T22:17:43Z", "2023-09-11T12:00:40Z"]}, {"name": "motion-s3-connector", "description": null, "language": "Shell", "license": null, "readme": "# Motion S3 Connector\n\nThe Motion S3 Connector showcases a bridge between the Amazon S3 client libraries and [Motion](https://github.com/filecoin-project/motion). By leveraging this connector, users can seamlessly store and fetch data through Motion, an API layer crafted to facilitate Filecoin storage layer integration. This connector utilizes a [Zenko CloudServer](https://www.zenko.io/cloudserver/) - an Amazon S3-compatible storage server - and integrates a tailored Motion client. This client is responsible for converting S3 requests to Motion requests and vice versa.\n\n## Demos\n\nThis repository contains two demo setups:\n1. [**local**](./local): local storage without Filecoin interaction.\n2. [**local-devnet**](./local-devnet): full end-to-end S3 <-> Filecoin SP interaction using a local Boost Devnet.\n\nTo run the demos, see README within each corresponding directory.\n\n## Setting Up Zenko CloudServer with Motion Storage Backend\n\n### Prerequisites\n\n- [Docker](https://docs.docker.com/install/) for deploying via `docker-compose`.\n- [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html) to communicate with the CloudServer.\n- AWS test credentials provided in `.env` are required for CloudServer authentication. For alternative methods, refer to [AWS CLI Configuration](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html).\n- one or more FileCoin Storage provider address specified as comma separated list under `MOTION_STORAGE_PROVIDERS` environment variable.\n- Filecoin wallet key with sufficient FileCoin funds specified as hex encoded string under `MOTION_WALLET_KEY` environment variable.\n\n### Launching Motion and CloudServer\n\nInitiate both the Motion API server and the CloudServer with:\n\n```bash\ndocker compose up\n```\n\nThis starts the Motion HTTP API at `http://localhost:40080` and the CloudServer at `https://localhost:8000`.\n\n### Configuring AWS CLI with Test Credentials\n\nTo set up the AWS CLI with the designated test credentials, execute:\n\n```bash\nexport AWS_ACCESS_KEY_ID=accessKey1\nexport AWS_SECRET_ACCESS_KEY=verySecretKey1\nexport AWS_DEFAULT_REGION=location-motion-v1\n```\n\nThese credentials correspond to a test user on our local CloudServer. The predefined region `location-motion-v1` directs CloudServer to employ the Motion storage backend.\n\nSee [Overriding Default AWS Credentials](#overriding-default-aws-credentials) for instructions on how to override the default credentials accepted by the server side.\n\n### Bucket Operations\n\n1. **Creating a Bucket**  \n   After starting the servers, generate a bucket using:\n\n   ```bash\n   aws --endpoint-url http://localhost:8000 s3 mb s3://mybucket\n   ```\n\n2. **Uploading Objects**  \n   Transfer a file to the new bucket:\n\n   ```bash\n   aws --endpoint-url http://localhost:8000 s3 cp README.md s3://mybucket\n   ```\n\n   Alternatively, utilize:\n\n   ```bash\n   aws --endpoint-url http://localhost:8000 s3api put-object --bucket mybucket --key README.md --body README.md\n   ```\n\n3. **Listing Objects**  \n   To view the contents of your bucket:\n\n   ```bash\n   aws --endpoint-url http://localhost:8000 s3 ls s3://mybucket\n   ```\n\n4. **Downloading Objects**  \n   Retrieve an uploaded object with:\n\n   ```bash\n   aws --endpoint-url http://localhost:8000 s3 cp s3://mybucket/README.md README.md\n   ```\n\n   Or, use:\n\n   ```bash\n   aws --endpoint-url http://localhost:8000 s3api get-object --bucket mybucket --key README.md README.md\n   ```\n## Overriding Default AWS Credentials\n\nIn scenarios where you wish to use different credentials than the default ones, the Motion S3 Connector allows users to override the default AWS credentials. This can be particularly useful for more advanced use-cases, testing, or specific security measures.\n\n### ***How to Override Credentials***\n\nTo update the AWS credentials, edit the [`authdata.json`](authdata.json) file with your preferred access credentials. After making the changes, restart Docker Compose to apply the updated credentials on the server.\n", "release_dates": []}, {"name": "motion-sp-test", "description": "A simple production test suite for filecoin-project/motion", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# motion-sp-test\n\nA simple production test suite for [Motion](https://github.com/filecoin-project/motion). Make deals using a fixed corpus of data, then test and record the data onboarding process.\n\nIntended to be used on an EC2 instance that has an IAM role that lets it access the data corpus on S3. Alternatively AWS credentials can be provided in the config file or in a credentials.json file.\n\nStatus data is written to status.json, which is updated as the test progresses. The test is able to be resumed and should work out where it was up to by using this file.\n\nstatus.json can be used to determine timings for the various stages of the test; including data onboarding time, replica status progress and timing for each change, and details about the replicas themselves. It also includes a sha2-256 digest of each onboarded file, which can be used to test retrievals through Motion to ensure the data is intact.\n\n```\nnpm install\nnpm start\n# or just ./sptest.js\n```\n\n## Retrieval testing\n\nRunning `./retrieve.js` will perform retrievals against the Motion instance configured in config.json against the stored files recorded in the status file (status.json by default). It will retrieve files in random order, and will only retrieve files that have been successfully onboarded. The retrieved files are checked against the stored sha2-256 digest to ensure they are intact. Speed, TTFB and TTLB are recorded and the averages are printed.\n\n```\nUsage: retrieve.js [options]\nOptions:\n    --min <size>              Minimum file size to consider (optional, default 0)\n    --max <size>              Maximum file size to consider (optional, default Infinity)\n    --duration <time>         Duration to run for (optional, default 5m)\n    --state any|local|remote  Only consider files with this state (optional, default any)\n```\n\n### Example\n\n```\n./retrieve.js --min 50MiB --max 100MiB --duration 30s --state local\nTesting retrieval using random selection from 99 local files between 52.43 MB and 104.86 MB for 30 seconds\nFetching ..........................\nFiles fetched: 26\nAverage size:  69.47 MB\nAverage speed: 58.80 MB / s\nAverage TTFB:  4.55367 ms\nAverage TTLB:  1184.647486 ms\n```\n", "release_dates": []}, {"name": "near-blake2", "description": "Pure Rust implementation of the BLAKE2 hash function family.", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# RustCrypto: BLAKE2\n\n[![crate][crate-image]][crate-link]\n[![Docs][docs-image]][docs-link]\n![Apache2/MIT licensed][license-image]\n![Rust Version][rustc-image]\n[![Project Chat][chat-image]][chat-link]\n[![Build Status][build-image]][build-link]\n\nPure Rust implementation of the [BLAKE2 hash function][1] family with changes to\nthe compression function to specify an amount of rounds.\n\n[Documentation][docs-link]\n\n## Minimum Supported Rust Version\n\nRust **1.41** or higher.\n\nMinimum supported Rust version can be changed in the future, but it will be\ndone with a minor version bump.\n\n## SemVer Policy\n\n- All on-by-default features of this library are covered by SemVer\n- MSRV is considered exempt from SemVer as noted above\n\n## License\n\nLicensed under either of:\n\n * [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0)\n * [MIT license](http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in the work by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n\n[//]: # (badges)\n\n[crate-image]: https://img.shields.io/crates/v/blake2.svg\n[crate-link]: https://crates.io/crates/blake2\n[docs-image]: https://docs.rs/blake2/badge.svg\n[docs-link]: https://docs.rs/blake2/\n[license-image]: https://img.shields.io/badge/license-Apache2.0/MIT-blue.svg\n[chat-image]: https://img.shields.io/badge/zulip-join_chat-blue.svg\n[chat-link]: https://rustcrypto.zulipchat.com/#narrow/stream/260041-hashes\n[rustc-image]: https://img.shields.io/badge/rustc-1.41+-blue.svg\n[build-image]: https://github.com/RustCrypto/hashes/workflows/blake2/badge.svg?branch=master\n[build-link]: https://github.com/RustCrypto/hashes/actions?query=workflow%3Ablake2\n\n[//]: # (general links)\n\n[1]: https://blake2.net/\n", "release_dates": []}, {"name": "network-info", "description": "Information about active Filecoin networks and a place to report network issues ", "language": "SCSS", "license": null, "readme": "# DEPRECATED 2021-09-28\n\nfunctionality replaced by https://status.filecoin.io\n\n<br>\n\n# Filecoin Network Information\n\nThis repo is the source of https://network.filecoin.io and contains information about all the active Filecoin networks. It is the source of truth for all network information, related links etc. and should be the only place where this information is maintained.\n\nFor information about how to connect to a network using a Filecoin node (i.e. Lotus), check the Filecoin documentation: https://docs.filecoin.io\n## Network Information Data Model\n\nFor each Filecoin network, we include the following information:\n- Network name\n- Network summary and description\n- Network status:\n  - \ud83d\udd34 Network down for all participants\n  - \ud83d\udfe1 Network is unstable (down for some participants, but not all)\n  - \ud83d\udfe2 Network up and stable\n- Link to the genesis CAR files for the network\n- Link to the faucet for the network (if the network is not `mainnet`)\n- Supported sector sizes on this network\n- The minimum miner power required to participate in Filecoin consensus on this network\n- Chain genesis information, including when this network was last reset and the hash of the genesis block\n- Addresses for the bootstrap peers on this network\n\nInformation for each network is stored in a JSON file. Currently information for each network can be found on the [this page](https://docs.filecoin.io/how-to/networks/) on the Filecoin Documentation Site, or on the respective information page for each network:\n- `butterfly` network: https://www.butterfly.fildev.network/\n- `calibration` network: https://www.calibration.fildev.network/\n\n## Build & Deploy\n\nThis application builds a static site using Nuxt.js/Vue.js. The site is generated to the `/dist/` directory during the build process. Only this directory needs to be published.\n\n**This application fetches schemas and network information directly from `https://raw.githubusercontent.com/filecoin-project/network-info/master/...`. This means you cannot see or preview the changes you made until you merge to master** or change the fetch manually to a local urls. Master is automatically deployed so, good luck! For major changes, you can deploy to the develop branch instead. The preview for this branch is generated at a different URL.\n\n### Nuxt settings\n- Remove `mode` property from `nuxt.config.js`\n- Set `target: 'static'` in `nuxt.config.js`\n\n### Fleek configuration\n- A `.fleek.json` configuration file is included which should pre-populate these settings\n- Build command: `npm ci && npm run generate`\n- Base directory can be left empty\n- Publish directory: `dist`\n- Environment variables:\n  - NODE_ENV=production\n\n### Deployment process\n- Commit to a repo on GitHub\n- Login to Fleek, click on \"Hosting\" and click on \"Add new site\"\n- Connect your GitHub repo\n- The remaining information should populate automatically, however, if it doesn't:\n - Select NuxtJS as the framework\n - Input the settings as defined in `#fleek-settings`\n- Select \"Deploy Site\"\n- \ud83c\udf89\n", "release_dates": []}, {"name": "notary-governance", "description": null, "language": null, "license": null, "readme": "\nThe purpose of this repository is to manage the governance and evolution of specific Mechanisms and Operations of the program as insantiated in this [FIP](https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0003.md) and illustrated in the following diagram.\n\n<img src=\"images/governance-layers.jpg\" alt=\"governance-layers\" width=\"70%\" height=\"70%\">\n\nWithin this repository, you will find: \n- Increased specification, governance, and evolution for Mechanisms and Operations layers.\n- Information on Root Key Holders, available actions, roles and responsibility.\n- Information on how to become a Notary, selection rubric, recommended guidelines, active Notaries.\n- Information on how to file a Dispute, and the steps for how disputes are resolved. \n\n#### If you are looking to request DataCap or to find a list of active Notaries please go to the [Filecoin Plus Registry](https://plus.fil.org).\n\n## Overview\n- Principles\n  - Decentralization and Diversity\n  - Tranparency and Accountability\n  - Community Governance\n  - Low-Cost Dispute Resolution\n  - Limited Trust Earned over Time\n  - Terms of Service\n  - A Useful Storage Network\n- Roles & Responsibilities\n  - [Root Key Holders](/root-key-holders#overview)\n  - [Notaries](/notaries#overview)\n  - Clients\n- Interaction Diagram\n\n<img src=\"images/interaction-diagram.jpg\" alt=\"interaction-diagram\" width=\"70%\" height=\"70%\">\n\n## Dispute / Audit Framework\n\n Last updated: 2023-05-05\t\n\n**The person opening the dispute is referred to as \u2018Claimant\u2019 and the stakeholder against which the dispute is opened is referred to as \u2018Responder'**\n\nOverview of the Dispute resolution process: \n- Claimant submits [form](https://forms.gle/WTPCxsi12PLVzjWh8) in the [T&T Dispute Tracker](https://www.notion.so/filecoin/T-T-Dispute-Tracker-d28b93677cb544b48e77b585856601cf).\n- Responder is notified by the T&T WG Lead and allowed to submit additional details in the [T&T WG slack](https://filecoinproject.slack.com/archives/C0405HANNBT) or present at the [T&T WG Call](https://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=cXZkdjZ1MThkZ2w3MHFkMTM0YTdoZ2RtbmFfMjAyMzA1MTZUMTUzMDAwWiByYWdoYXYuYWdnYXJ3YWxAcHJvdG9jb2wuYWk&tmsrc=raghav.aggarwal%40protocol.ai&scp=ALL).\n- T&T WG reviews all relevant data.\n- Repercussions announced and enacted.\n\nThe process for filing a Dispute request is as follows:\n\nAn issue must be filed on the [T&T Dispute Tracker](https://www.notion.so/filecoin/T-T-Dispute-Tracker-d28b93677cb544b48e77b585856601cf)using the [form](https://forms.gle/WTPCxsi12PLVzjWh8)\n\n*Although the WG prefers and strongly encourage full transparency, we understand some situations may require more discretion, so disputes can be submitted as 'anonymous'.*\n\nOnce a dispute is filed, the T&T WG Lead will discuss it in the WG calls. The average time for a dispute to be resolved is two weeks based on the principles of optimistic governance but some disputes may take longer depending on the complexity and response times of the claimant and responder. The status will be trackable and updated at all times in the public dispute tracker.\n\n*Claimants are encouraged to cross-post the dispute in the T&T WG channel to bring the community\u2019s attention to the dispute.*\n\nThe claimant is requested to complete all fields including a description of the issue at hand. Notably, some specific abuse must be detailed, such as:\n\n- A violation of the overarching principles\n- A violation of a Notary's own attested allocation plan\n- A violation of the agreed-upon [operating guidelines](https://github.com/filecoin-project/notary-governance/blob/main/notaries#operational-guidelines), or some other act of impropriety \n\nSupporting the dispute with substantiating evidence is highly encouraged, such as links to the relevant transaction ids on-chain, screenshots, or other evidence.\n\nClaimants are discouraged from making personal attacks against any stakeholder when submitting details in the T&T dispute tracker and follow the [Fil+ Code of Conduct](https://medium.com/filecoin-plus/fil-code-of-conduct-9cd044e7bcaf).\n\nBased on the evidence, the response to a dispute, and discussions of the situation in the T&T WG calls, some possible repercussions and outcomes may include but are not limited to:\n\n- Removal from the program \n- Losing rights as a notary\n- Revoking of allocated DataCap\n- Being asked to step away from the Fil+ community \n- A warning coupled with restrictions\n\n\n## Governance, Contributing and Iteration Process \nWithin this repository are the governing documents, selection criteria, and processes for Notaries and Root Key Holders. Areas for discussion or improvement, should be filed as issues. Please use the Modification template (for proposed improvements) or create a blank issue for topics for discussion!\n\nAfter community discussion, pull requests are encouraged where open discussion can happen asynchronously via the community - please be sure to link the relevant issues to the changes in your PR. Similar to a FIP, any proposed changes must be done within the constraints of improving the Mechanisms and Operations to better meet the overarching Principles.\n\nPlease note our community governance calls will take place every other Tuesday - there are (2) calls each day to accomodate time zones. 8am PT // 1400 UTC AND 1800PT // 0000am UTC. Please see the community calendar for the accurate dates/times relative to your local timezone, follow the repo (where agenda issues will be filed), or join our Slack channel!\n- [Community Calendar](https://calendar.google.com/calendar/u/1?cid=Y19rMWdrZm9vbTE3ZzBqOGM2YmFtNnVmNDNqMEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t)\n- [Zoom link](https://fil-org.zoom.us/my/filecoinplus?pwd=VHpNSnd0dkJRdWozNi9Xc3NmeGFhZz09), Passcode: *N*otary\n- Please join our Slack channel, #fil-plus, if you have questions. \n\n### Previous governance calls\n\n#### Recordings\n- ALL: [Meeting recording](https://www.youtube.com/playlist?list=PL_0VrY55uV1-cwaAU8lcChONxYQ_Bj9hx)\n\n#### Presentations\n- ALL: [Presentation Files](https://drive.google.com/drive/u/0/folders/1zTy6YZWlG0KH6eQCEoKA8nDRP2JZnnp1)\n\n", "release_dates": []}, {"name": "oni", "description": "\ud83d\udc79 (DEPRECATED; see README) Project Oni | Network Validation", "language": "Go", "license": null, "readme": "# Project Oni \ud83d\udc79\n\n---\n\n## \ud83c\udf11 Deprecated\n\n- Testground testkit and test plans have moved to [filecoin-project/lotus](https://github.com/filecoin-project/lotus/tree/master/testplans)\n- Test vectors spun off to [filecoin-project/test-vectors](https://github.com/filecoin-project/test-vectors)\n- statediff is maintained at [filecoin-project/statediff](https://github.com/filecoin-project/statediff)\n\n---\n\nOur mandate is:\n\n> To verify the successful end-to-end outcome of the filecoin protocol and filecoin implementations, under a variety of real-world and simulated scenarios. \n\n\u27a1\ufe0f  Find out more about our goals, requirements, execution plan, and team culture, in our [Project Description](https://docs.google.com/document/d/16jYL--EWYpJhxT9bakYq7ZBGLQ9SB940Wd1lTDOAbNE).\n\n## Table of Contents\n\n- [Testing topics](#testing-topics)\n- [Repository contents](#repository-contents)\n- [Running the test cases](#running-the-test-cases)\n- [Catalog](#catalog)\n- [Debugging](#debugging)\n- [Dependencies](#dependencies)\n- [Docker images changelog](#docker-images-changelog)\n- [Team](#team)\n\n## Testing topics\n\nThese are the topics we are currently centering our testing efforts on. Our testing efforts include fault induction, stress tests, and end-to-end testing.\n\n* **slashing:** [_(view test scenarios)_](https://github.com/filecoin-project/oni/issues?q=is%3Aissue+sort%3Aupdated-desc+label%3Atopic%2Fslashing)\n    * We are recreating the scenarios that lead to slashing, as they are not readily seen in mono-client testnets.\n    * Context: slashing is the negative economic consequence of penalising a miner that has breached protocol by deducing FIL and/or removing their power from the network.\n* **windowed PoSt/sector proving faults:** [_(view test scenarios)_](https://github.com/filecoin-project/oni/issues?q=is%3Aissue+sort%3Aupdated-desc+label%3Atopic%2Fsector-proving)\n    * We are recreating the proving fault scenarios and triggering them in an accelerated fasion (by modifying the system configuration), so that we're able to verify that the sector state transitions properly through the different milestones (temporary faults, termination, etc.), and under chain fork conditions.\n    * Context: every 24 hours there are 36 windows where miners need to submit their proofs of sector liveness, correctness, and validity. Failure to do so will mark a sector as faulted, and will eventually terminate the sector, triggering slashing consequences for the miner.\n* **syncing/fork selection:** [_(view test scenarios)_](https://github.com/filecoin-project/oni/issues?q=is%3Aissue+sort%3Aupdated-desc+label%3Atopic%2Fsync-forks)\n    * Newly bootstrapped clients, and paused-then-resumed clients, are able to latch on to the correct chain even in the presence of a large number of forks in the network, either in the present, or throughout history.\n* **present-time mining/tipset assembly:** [_(view test scenarios)_](https://github.com/filecoin-project/oni/issues?q=is%3Aissue+sort%3Aupdated-desc+label%3Atopic%2Fmining-present)\n    * Induce forks in the network, create network partitions, simulate chain halts, long-range forks, etc. Stage many kinds of convoluted chain shapes, and network partitions, and ensure that miners are always able to arrive to consensus when disruptions subside.\n* **catch-up/rush mining:** [_(view test scenarios)_](https://github.com/filecoin-project/oni/issues?q=is%3Aissue+sort%3Aupdated-desc+label%3Atopic%2Fmining-rush)\n    * Induce network-wide, or partition-wide arrests, and investigate what the resulting chain is after the system is allowed to recover.\n    * Context: catch-up/rush mining is a dedicated pathway in the mining logic that brings the chain up to speed with present time, in order to recover from network halts. Basically it entails producing backdated blocks in a hot loop. Imagine all miners recover in unison from a network-wide disruption; miners will produce blocks for their winning rounds, and will label losing rounds as _null rounds_. In the current implementation, there is no time for block propagation, so miners will produce solo-chains, and the assumption is that when all these chains hit the network, the _fork choice rule_ will pick the heaviest one. Unfortunately this process is brittle and unbalanced, as it favours the miner that held the highest power before the disruption commenced.\n* **storage and retrieval deals:** [_(view test scenarios)_](https://github.com/filecoin-project/oni/issues?q=is%3Aissue+sort%3Aupdated-desc+label%3Atopic%2Fdeals)\n    * end-to-end flows where clients store and retrieve pieces from miners, including stress testing the system.\n* **payment channels:** [_(view test scenarios)_](https://github.com/filecoin-project/oni/issues?q=is%3Aissue+sort%3Aupdated-desc+label%3Atopic%2Fpaych)\n    * stress testing payment channels via excessive lane creation, excessive payment voucher atomisation, and redemption.\n* **drand incidents and impact on the filecoin network/protocol/chain:** [_(view test scenarios)_](https://github.com/filecoin-project/oni/issues?q=is%3Aissue+sort%3Aupdated-desc+label%3Atopic%2Fdrand)\n    * drand total unavailabilities, drand catch-ups, drand slowness, etc.\n* **mempool message selection:** [_(view test scenarios)_](https://github.com/filecoin-project/oni/issues?q=is%3Aissue+sort%3Aupdated-desc+label%3Atopic%2Fmempool)\n    * soundness of message selection logic; potentially targeted attacks against miners by flooding their message pools with different kinds of messages.\n* **presealing:** [_(view test scenarios)_](https://github.com/filecoin-project/oni/issues?q=is%3Aissue+sort%3Aupdated-desc+label%3Atopic%2Fpresealing)\n    * TBD, anything related to this worth testing?\n\n## Repository contents\n\nThis repository consists of [test plans](https://docs.testground.ai/concepts-and-architecture/test-structure) built to be run on [Testground](https://github.com/testground/testground).\n\nThe source code for the various test cases can be found in the [`lotus-soup` directory](https://github.com/filecoin-project/oni/tree/master/lotus-soup).\n\n## Running the test cases\n\nIf you are unfamiliar with Testground, we strongly suggest you read the Testground [Getting Started guide](https://docs.testground.ai/getting-started) in order to learn how to install Testground and how to use it.\n\nYou can find various [composition files](https://docs.testground.ai/running-test-plans#composition-runs) describing various test scenarios built as part of Project Oni at [`lotus-soup/_compositions` directory](https://github.com/filecoin-project/oni/tree/master/lotus-soup/_compositions).\n\nWe've designed the test cases so that you can run them via the `local:exec`, `local:docker` and the `cluster:k8s` runners. Note that Lotus miners are quite resource intensive, requiring gigabytes of memory. Hence you would have to run these test cases on a beafy machine (when using `local:docker` and `local:exec`), or on a Kubernetes cluster (when using `cluster:k8s`).\n\nHere are the basics of how to run the baseline deals end-to-end test case:\n\n### Running the baseline deals end-to-end test case\n\n1. Compile and Install Testground from source code.\n    * See the [Getting Started](https://github.com/testground/testground#getting-started) section of the README for instructions.\n\n2. Run a Testground daemon\n\n```\ntestground daemon\n```\n\n3. Download required Docker images for the `lotus-soup` test plan\n\n```\nmake pull-images\n```\n\nAlternatively you can build them locally with\n\n```\nmake build-images\n```\n\n4. Import the `lotus-soup` test plan into your Testground home directory\n\n```\ntestground plan import --from ./lotus-soup\n```\n\n5. Init the `filecoin-ffi` Git submodule in the `extra` folder.\n\n```\ngit submodule update --init --recursive\n```\n\n6. Compile the `filecoin-ffi` version locally (necessary if you use `local:exec`)\n\n```\ncd extra/filecoin-ffi\nmake\n```\n\n7. Run a composition for the baseline deals end-to-end test case\n\n```\ntestground run composition -f ./lotus-soup/_compositions/baseline-docker-5-1.toml\n```\n\n## Batch-running randomised test cases\n\nThe Oni testkit supports [range parameters](https://github.com/filecoin-project/oni/blob/master/lotus-soup/testkit/testenv_ranges.go),\nwhich test cases can use to generate random values, either at the instance level\n(each instance computes a random value within range), or at the run level (one\ninstance computes the values, and propagates them to all other instances via the\nsync service).\n\nFor example:\n\n```toml\nlatency_range   = '[\"20ms\", \"500ms\"]'\nloss_range      = '[0, 0.2]'\n```\n\nCould pick a random latency between 20ms and 500ms, and a packet loss\nprobability between 0 and 0.2. We could apply those values through the\n`netclient.ConfigureNetwork` Testground SDK API.\n\nRandomized range-based parameters are specially interesting when combined with\nbatch runs, as it enables Monte Carlo approaches to testing.\n\nThe Oni codebase includes a batch test run driver in package `lotus-soup/runner`.\nYou can point it at a composition file that uses range parameters and tell it to\nrun N iterations of the test:\n\n```shell script\n$ go run ./runner -runs 5 _compositions/net-chaos/latency.toml\n```\n\nThis will run the test as many times as instructed, and will place all outputs\nin a temporary directory. You can pass a concrete output directory with\nthe `-output` flag. \n\n## Catalog\n\n### Test cases part of `lotus-soup`\n\n* `deals-e2e` - Deals end-to-end test case. Clients pick a miner at random, start a deal, wait for it to be sealed, and try to retrieve from another random miner who offers back the data.\n* `drand-halting` - Test case that instructs Drand with a sequence of halt/resume/wait events, while running deals between clients and miners at the same time.\n* `deals-stress` - Deals stress test case. Clients pick a miner and send multiple deals (concurrently or serially) in order to test how many deals miners can handle.\n* `paych-stress` - A test case exercising various payment channel stress tests.\n\n### Compositions part of `lotus-soup`\n\n* `baseline-docker-5-1.toml` - Runs a `baseline` test (deals e2e test) with a network of 5 clients and 1 miner targeting `local:docker`\n* `baseline-k8s-10-3.toml` - Runs a `baseline` test (deals e2e test) with a network of 10 clients and 3 miner targeting `cluster:k8s`\n* `baseline-k8s-3-1.toml` - Runs a `baseline` test (deals e2e test) with a network of 3 clients and 1 miner targeting `cluster:k8s`\n* `baseline-k8s-3-2.toml` - Runs a `baseline` test (deals e2e test) with a network of 3 clients and 2 miner targeting `cluster:k8s`\n* `baseline.toml` - Runs a `baseline` test (deals e2e test) with a network of 3 clients and 2 miner targeting `local:exec`. You have to manually download the proof parameters and place them in `/var/tmp`.\n* `deals-stress-concurrent-natural-k8s.toml`\n* `deals-stress-concurrent-natural.toml`\n* `deals-stress-concurrent.toml`\n* `deals-stress-serial-natural.toml`\n* `deals-stress-serial.toml`\n* `drand-halt.toml`\n* `local-drand.toml`\n* `natural.toml`\n* `paych-stress.toml`\n* `pubsub-tracer.toml`\n\n\n## Debugging\n\nFind commands and how-to guides on debugging test plans at [DELVING.md](https://github.com/filecoin-project/oni/blob/master/DELVING.md)\n\n1. Querying the Lotus RPC API\n\n2. Useful commands / checks\n\n* Making sure miners are on the same chain\n\n* Checking deals\n\n* Sector queries\n\n* Sector sealing errors\n\n## Dependencies\n\nOur current test plan `lotus-soup` is building programatically the Lotus filecoin implementation and therefore requires all it's dependencies. The build process is slightly more complicated than a normal Go project, because we are binding a bit of Rust code. Lotus codebase is in Go, however its `proofs` and `crypto` libraries are in Rust (BLS signatures, SNARK verification, etc.).\n\nDepending on the runner you want to use to run the test plan, these dependencies are included in the build process in a different way, which you should be aware of should you require to use the test plan with a newer version of Lotus:\n\n### Filecoin FFI libraries\n\n* `local:docker`\n\nThe Rust libraries are included in the Filecoin FFI Git submodule, which is part of the `iptestground/oni-buildbase` image. If the FFI changes on Lotus, we have to rebuild this image with the `make build-images` command, where X is the next version (see [Docker images changelog](#docker-images-changelog)\nbelow).\n\n* `local:exec`\n\nThe Rust libraries are included via the `extra` directory. Make sure that the test plan reference to Lotus in `go.mod` and the `extra` directory are pointing to the same commit of the FFI git submodule. You also need to compile the `extra/filecoin-ffi` libraries with `make`.\n\n* `cluster:k8s`\n\nThe same process as for `local:docker`, however you need to make sure that the respective `iptestground/oni-buildbase` image is available as a public Docker image, so that the Kubernetes cluster can download it.\n\n### proof parameters\n\nAdditional to the Filecoin FFI Git submodules, we are also bundling `proof parameters` in the `iptestground/oni-runtime` image. If these change, you will need to rebuild that image with `make build-images` command, where X is the next version.\n\n## Docker images changelog\n\n### oni-buildbase\n\n* `v1` => initial image locking in Filecoin FFI commit ca281af0b6c00314382a75ae869e5cb22c83655b.\n* `v2` => no changes; released only for aligning both images to aesthetically please @nonsense :D\n* `v3` => locking in Filecoin FFI commit 5342c7c97d1a1df4650629d14f2823d52889edd9.\n* `v4` => locking in Filecoin FFI commit 6a143e06f923f3a4f544c7a652e8b4df420a3d28.\n* `v5` => locking in Filecoin FFI commit cddc56607e1d851ea6d09d49404bd7db70cb3c2e.\n* `v6` => locking in Filecoin FFI commit 40569104603407c999d6c9e4c3f1228cbd4d0e5c.\n* `v7` => add Filecoin-BLST repo to buildbase.\n* `v8` => locking in Filecoin FFI commit f640612a1a1f7a2d.\n* `v9` => locking in Filecoin FFI commit 57e38efe4943f09d3127dcf6f0edd614e6acf68e and Filecoin-BLST commit 8609119cf4595d1741139c24378fcd8bc4f1c475.\n\n\n### oni-runtime\n\n* `v1` => initial image with 2048 parameters.\n* `v2` => adds auxiliary tools: `net-tools netcat traceroute iputils-ping wget vim curl telnet iproute2 dnsutils`.\n* `v3` => bump proof parameters from v27 to v28\n\n### oni-runtime-debug\n\n* `v1` => initial image\n* `v2` => locking in Lotus commit e21ea53\n* `v3` => locking in Lotus commit d557c40\n* `v4` => bump proof parameters from v27 to v28\n* `v5` => locking in Lotus commit 1a170e18a\n\n\n## Team\n\n* [@raulk](https://github.com/raulk) (Captain + TL)\n* [@nonsense](https://github.com/nonsense) (Testground TG + engineer)\n* [@yusefnapora](https://github.com/yusefnapora) (engineer and technical writer)\n* [@vyzo](https://github.com/vyzo) (engineer)\n* [@schomatis](https://github.com/schomatis) (advisor)\n* [@willscott](https://github.com/willscott) (engineer)\n* [@alanshaw](https://github.com/alanshaw) (engineer)\n\n", "release_dates": []}, {"name": "openzeppelin-contracts", "description": "OpenZeppelin Contracts is a library for secure smart contract development.", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# <img src=\"logo.svg\" alt=\"OpenZeppelin\" height=\"40px\">\n\n[![NPM Package](https://img.shields.io/npm/v/@openzeppelin/contracts.svg)](https://www.npmjs.org/package/@openzeppelin/contracts)\n[![Coverage Status](https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts/graph/badge.svg)](https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts)\n[![GitPOAPs](https://public-api.gitpoap.io/v1/repo/OpenZeppelin/openzeppelin-contracts/badge)](https://www.gitpoap.io/gh/OpenZeppelin/openzeppelin-contracts)\n[![Docs](https://img.shields.io/badge/docs-%F0%9F%93%84-yellow)](https://docs.openzeppelin.com/contracts)\n[![Forum](https://img.shields.io/badge/forum-%F0%9F%92%AC-yellow)](https://docs.openzeppelin.com/contracts)\n\n**A library for secure smart contract development.** Build on a solid foundation of community-vetted code.\n\n * Implementations of standards like [ERC20](https://docs.openzeppelin.com/contracts/erc20) and [ERC721](https://docs.openzeppelin.com/contracts/erc721).\n * Flexible [role-based permissioning](https://docs.openzeppelin.com/contracts/access-control) scheme.\n * Reusable [Solidity components](https://docs.openzeppelin.com/contracts/utilities) to build custom contracts and complex decentralized systems.\n\n:mage: **Not sure how to get started?** Check out [Contracts Wizard](https://wizard.openzeppelin.com/) \u2014 an interactive smart contract generator.\n\n:building_construction: **Want to scale your decentralized application?** Check out [OpenZeppelin Defender](https://openzeppelin.com/defender) \u2014 a secure platform for automating and monitoring your operations.\n\n## Overview\n\n### Installation\n\n```\n$ npm install @openzeppelin/contracts\n```\n\nOpenZeppelin Contracts features a [stable API](https://docs.openzeppelin.com/contracts/releases-stability#api-stability), which means that your contracts won't break unexpectedly when upgrading to a newer minor version.\n\nAn alternative to npm is to use the GitHub repository (`openzeppelin/openzeppelin-contracts`) to retrieve the contracts. When doing this, make sure to specify the tag for a release such as `v4.5.0`, instead of using the `master` branch.\n\n### Usage\n\nOnce installed, you can use the contracts in the library by importing them:\n\n```solidity\npragma solidity ^0.8.0;\n\nimport \"@openzeppelin/contracts/token/ERC721/ERC721.sol\";\n\ncontract MyCollectible is ERC721 {\n    constructor() ERC721(\"MyCollectible\", \"MCO\") {\n    }\n}\n```\n\n_If you're new to smart contract development, head to [Developing Smart Contracts](https://docs.openzeppelin.com/learn/developing-smart-contracts) to learn about creating a new project and compiling your contracts._\n\nTo keep your system secure, you should **always** use the installed code as-is, and neither copy-paste it from online sources nor modify it yourself. The library is designed so that only the contracts and functions you use are deployed, so you don't need to worry about it needlessly increasing gas costs.\n\n## Learn More\n\nThe guides in the [documentation site](https://docs.openzeppelin.com/contracts) will teach about different concepts, and how to use the related contracts that OpenZeppelin Contracts provides:\n\n* [Access Control](https://docs.openzeppelin.com/contracts/access-control): decide who can perform each of the actions on your system.\n* [Tokens](https://docs.openzeppelin.com/contracts/tokens): create tradeable assets or collectives, and distribute them via [Crowdsales](https://docs.openzeppelin.com/contracts/crowdsales).\n* [Utilities](https://docs.openzeppelin.com/contracts/utilities): generic useful tools including non-overflowing math, signature verification, and trustless paying systems.\n\nThe [full API](https://docs.openzeppelin.com/contracts/api/token/ERC20) is also thoroughly documented, and serves as a great reference when developing your smart contract application. You can also ask for help or follow Contracts's development in the [community forum](https://forum.openzeppelin.com).\n\nFinally, you may want to take a look at the [guides on our blog](https://blog.openzeppelin.com/guides), which cover several common use cases and good practices. The following articles provide great background reading, though please note that some of the referenced tools have changed, as the tooling in the ecosystem continues to rapidly evolve.\n\n* [The Hitchhiker\u2019s Guide to Smart Contracts in Ethereum](https://blog.openzeppelin.com/the-hitchhikers-guide-to-smart-contracts-in-ethereum-848f08001f05) will help you get an overview of the various tools available for smart contract development, and help you set up your environment.\n* [A Gentle Introduction to Ethereum Programming, Part 1](https://blog.openzeppelin.com/a-gentle-introduction-to-ethereum-programming-part-1-783cc7796094) provides very useful information on an introductory level, including many basic concepts from the Ethereum platform.\n* For a more in-depth dive, you may read the guide [Designing the Architecture for Your Ethereum Application](https://blog.openzeppelin.com/designing-the-architecture-for-your-ethereum-application-9cec086f8317), which discusses how to better structure your application and its relationship to the real world.\n\n## Security\n\nThis project is maintained by [OpenZeppelin](https://openzeppelin.com) with the goal of providing a secure and reliable library of smart contract components for the ecosystem. We address security through risk management in various areas such as engineering and open source best practices, scoping and API design, multi-layered review processes, and incident response preparedness.\n\nThe security policy is detailed in [`SECURITY.md`](./SECURITY.md), and specifies how you can report security vulnerabilities, which versions will receive security patches, and how to stay informed about them. We run a [bug bounty program on Immunefi](https://immunefi.com/bounty/openzeppelin) to reward the responsible disclosure of vulnerabilities.\n\nThe engineering guidelines we follow to promote project quality can be found in [`GUIDELINES.md`](./GUIDELINES.md).\n\nPast audits can be found in [`audits/`](./audits).\n\nSmart contracts are a nascent techology and carry a high level of technical risk and uncertainty. Although OpenZeppelin is well known for its security audits, using OpenZeppelin Contracts is not a substitute for a security audit.\n\nOpenZeppelin Contracts is made available under the MIT License, which disclaims all warranties in relation to the project and which limits the liability of those that contribute and maintain the project, including OpenZeppelin. As set out further in the Terms, you acknowledge that you are solely responsible for any use of OpenZeppelin Contracts and you assume all risks associated with any such use.\n\n## Contribute\n\nOpenZeppelin Contracts exists thanks to its contributors. There are many ways you can participate and help build high quality software. Check out the [contribution guide](CONTRIBUTING.md)!\n\n## License\n\nOpenZeppelin Contracts is released under the [MIT License](LICENSE).\n\n## Legal\n\nYour use of this Project is governed by the terms found at www.openzeppelin.com/tos (the \"Terms\").\n", "release_dates": []}, {"name": "orient", "description": "\u21bbObserve-Orient-Decide-Act\u21a9", "language": "Common Lisp", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Orient(able)\n(\u21bbObserve-Orient-Decide-Act\u21a9)\n\n[![CircleCI](https://circleci.com/gh/filecoin-project/orient/tree/master.svg?style=svg&circle-token=e06461d4c5ca9731534a1e238c77e575d368798c)](https://circleci.com/gh/filecoin-project/orient/tree/master)\n\nOrient began life as a proof-of-concept reference implementation intended as a lightweight way to explore and clarify\nthe (now somewhat outdated) [Orientable specification](https://docs.google.com/document/d/1zjWHegvZwTgvU4fOAjUbIwMwQyfPzHoXJVTX8iR--2E/edit#heading=h.2jf8rxk263pw).\n\nThe underlying framework has been developed alongside the [Filecoin \u00dcbercalc](ubercalc/ubercalc.org). Eventually the repositories\nfor these two projects will be split. In the meantime, for ease of development and deployment, they are colocated\nhere.\n\nFor a brief introduction to Orient, see the [tutorial](tutorial.org).\n\n## Installation\n\n### sbcl\n\nCode is in Common Lisp, developed and (to the extent it is) tested with SBCL.\n```bash\n> brew install sbcl\n```\n\nor\n```bash\n> apt-get install sbcl\n```\n\n### QuickLisp & ASDF\n\nInstall [QuickLisp](https://www.quicklisp.org):\n\n- Download the file for installation. (https://beta.quicklisp.org/quicklisp.lisp)\n- Then run sbcl with that file loaded by this command.\n\n```sh\nsbcl --load path/of/quicklisp.lisp\n```\n\nAfter sbcl launched, type in the command below.\n\n```lisp\n(quicklisp-quickstart:install)\n```\n\nNow Quicklisp has been installed. To ensure Quicklisp is loaded every time you start Lisp, type in the command below.\n\n```lisp\n(ql:add-to-init-file)\n```\n\n### Optional for Emacs Users\n*NOTE:* If you intend to develop on or with Orient (as opposed to just use CLI or web interfaces), then use of Emacs +\nSlime is strongly recommended.\n\nType in the command which will create a file you can load in Emacs to configure the right load-path for loading\nQuicklisp's installation of SLIME.\n\n```lisp\n(ql:quickload \"quicklisp-slime-helper\")\n```\n\nThen configure Emacs to use Slime. Here is a simple but helpful configuration to place in you `.emacs` file:\n\n```lisp\n(use-package slime\n  :init\n  (global-set-key (kbd \"C-c z\") 'slime-repl)\n  (load (expand-file-name \"~/quicklisp/slime-helper.el\"))\n  (setq inferior-lisp-program \"/usr/local/bin/sbcl\")\n  (add-to-list 'slime-contribs 'slime-repl))\n```\n\nEnsure the path to your sbcl installation is correct.\n\nYou may also need to first [install use-package](https://jwiegley.github.io/use-package/installation/) by carefully\nfollowing the linked instructions. This is strongly recommended.\n\n### Integrate the project with quicklisp\n\nQuickLisp needs to find the project, so add a symlink:\n\n```bash\n> cd ~/quicklisp/local-projects\n> ln -s ~/<installdir>/orient/orient.asd orient.asd\n```\n\n### Test the Setup\n\nWhen configured correctly, this should work and show no failures:\n\n```bash\n> sbcl\nThis is SBCL 1.4.14, an implementation of ANSI Common Lisp.\nMore information about SBCL is available at <http://www.sbcl.org/>.\n\nSBCL is free software, provided as is, with absolutely no warranty.\nIt is mostly in the public domain; some portions are provided under\nBSD-style licenses.  See the CREDITS and COPYING files in the\ndistribution for more information.\n* (ql:quickload :orient)\nTo load \"orient\":\n  Load 1 ASDF system:\n    orient\n; Loading \"orient\"\n.....................................\n(:ORIENT)\n* (asdf:test-system :orient)\n\nRunning test suite ORIENT-SUITE\n Running test RENAME-ATTRIBUTES ..\n Running test RESTRICT .\n Running test PROJECT-TUPLE .\n Running test PROJECT-RELATION .\n Running test MULTIPLICATION-CONSTRAINT .......\n Running test DIVISION-CONSTRAINT ....\n Running test ADDITION-CONSTRAINT .......\n Running test SUBTRACTION-CONSTRAINT ...\n Running test LOG-CONSTRAINT ....\n Running test INTEGER-CONSTRAINT .......\n Running test EQUALITY-CONSTRAINT ...\n Running test LESS-THAN-CONSTRAINT ..\n Running test LESS-THAN-OR-EQUAL-CONSTRAINT ...\n Running test GREATER-THAN-CONSTRAINT ..\n Running test GREATER-THAN-OR-EQUAL-CONSTRAINT ...\n Running test AND-CONSTRAINT .............\n Running test CONSTRAINT-CONSTANTS ..\n Running test ORIENT-TESTS ............\n Running test JOIN ....\n Running test RENAME-TUPLE .\n Running test RENAME-RELATION .\n Running test SIMPLE-BIDIRECTIONAL ..\n Running test PLANNING-TERMINATES .\n Did 86 checks.\n    Pass: 86 (100%)\n    Skip: 0 ( 0%)\n    Fail: 0 ( 0%)\n\n\nRunning test suite INTERFACE-SUITE\n Running test ROUNDTRIP-TRANSFORMATION .\n Running test ROUNDTRIP-SIGNATURE .\n Running test ROUNDTRIP-TUPLE .\n Running test ROUNDTRIP-SCHEMA .\n Running test ROUNDTRIP-PARAMETER .\n Running test ROUNDTRIP-COMPONENT .\n Running test ROUNDTRIP-SYSTEM .\n Did 7 checks.\n    Pass: 7 (100%)\n    Skip: 0 ( 0%)\n    Fail: 0 ( 0%)\n\n\nRunning test suite FILECOIN-SUITE\n Running test PERFORMANCE-TEST .\n Running test MERKLE-TREE-CONSTRAINT-SYSTEM ...\n Running test SELECT-MERKLE-HASH-FUNCTION .\n Running test SELECT-KDF-HASH-FUNCTION .\n Running test MULTIPLE-HASH-FUNCTION-SELECTORS .\n Running test ZIGZAG-SYSTEM .\n Running test FILECOIN-DEFAULTS .\n Did 9 checks.\n    Pass: 9 (100%)\n    Skip: 0 ( 0%)\n    Fail: 0 ( 0%)\n\n\nRunning test suite WEB-SUITE\n Running test TEST-ECONOMIC-PERFORMANCE .\n Running test TEST-ZIGZAG .\n Running test TEST-FILECOIN-SECURITY .\n Running test TEST-FILECOIN .\n Did 4 checks.\n    Pass: 4 (100%)\n    Skip: 0 ( 0%)\n    Fail: 0 ( 0%)\n\nT\n*\n```\n\nYou should get similar output from the shell:\n\n```bash\n>  make test\n```\n\nTo start a web server, from REPL:\n\n```lisp\n(orient.web:start-web)\n```\n\nThen navigate to `http://localhost:8888`.\n\nTo generate graphs, you will need [Graphviz](https://www.graphviz.org/).\n\nTo generate and view graphs, `graphviz` must be installed locally, and `dot` must be in the path.\n\n\n## CLI\n\nThere are severals ways to run the CLI.\n\n### Development Mode\n\n- Install [cl-launch](https://www.cliki.net/cl-launch), so `/usr/local/bin/cl`\n\nFor example, you may need to create a symlink:\n```bash\n> ln -s /<installdir>cl-launch.sh /usr/local/bin/cl\n>  cl\ncl-launch.sh 4.1.5\n\nFor help, invoke script with help argument:\n        /usr/local/bin/cl -h\n```\n\nNow you can run the CLI and source changes will be immediately reflected, but startup is a bit slow.\n```bash\n> ./bin/orient ... <args>\n```\n\n### Executable Image\n\nIf you just want to *use* the CLI, first dump an image:\n\n```bash\n> make image\n```\n\nNow startup should be very fast:\n\n```bash\n> ./bin/orient ... <args>\n```\n\n### Docker\n\nIf you're having a hard time setting up a development environment, Docker might be easiest, but startup is a bit slow.\n\n```docker\n> make docker\n> ./bin/dcalc ... <args>\n```\n\n### Tests from shell\n\n```bash\n> make test\n```\n\n### Tutorial\n\nFor a brief introduction to Orient, see the [tutorial](tutorial.org).\n\n## License\n\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": ["2019-05-31T09:11:11Z"]}, {"name": "paired", "description": "Pairing-friendly elliptic curve library", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# paired [![Crates.io](https://img.shields.io/crates/v/paired.svg)](https://crates.io/crates/paired)\n\n> This is a fork of the great [pairing](https://github.com/zkcrypto/pairing) library.\n\n`pairing` is a crate for using pairing-friendly elliptic curves.\n\nCurrently, only the [BLS12-381](https://z.cash/blog/new-snark-curve.html)\nconstruction is implemented.\n\n## Roadmap\n\n`pairing` is being refactored into a generic library for working with\npairing-friendly curves. After the refactor, `pairing` will provide basic traits\nfor pairing-friendly elliptic curve constructions, while specific curves will be\nin separate crates.\n\n## [Documentation](https://docs.rs/paired/)\n\nBring the `paired` crate into your project just as you normally would.\n\n## Security Warnings\n\nThis library does not make any guarantees about constant-time operations, memory\naccess patterns, or resistance to side-channel attacks.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "parity-wasm", "description": "WebAssembly serialization/deserialization in rust", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# parity-wasm\n\nLow-level WebAssembly format library.\n\n[![Build Status](https://travis-ci.org/paritytech/parity-wasm.svg?branch=master)](https://travis-ci.org/paritytech/parity-wasm)\n[![crates.io link](https://img.shields.io/crates/v/parity-wasm.svg)](https://crates.io/crates/parity-wasm)\n\n[Documentation](https://docs.rs/parity-wasm)\n\n## Rust WebAssembly format serializing/deserializing\n\nAdd to Cargo.toml\n\n```toml\n[dependencies]\nparity-wasm = \"0.42\"\n```\n\nand then\n\n```rust\nlet module = parity_wasm::deserialize_file(\"./res/cases/v1/hello.wasm\").unwrap();\nassert!(module.code_section().is_some());\n\nlet code_section = module.code_section().unwrap(); // Part of the module with functions code\n\nprintln!(\"Function count in wasm file: {}\", code_section.bodies().len());\n```\n\n## Wabt Test suite\n\n`parity-wasm` supports full [wasm testsuite](https://github.com/WebAssembly/testsuite), running asserts that involves deserialization.\n\nTo run testsuite:\n\n- checkout with submodules (`git submodule update --init --recursive`)\n- run `cargo test --release --workspace`\n\nDecoder can be fuzzed with `cargo-fuzz` using [`wasm-opt`](https://github.com/WebAssembly/binaryen):\n\n- make sure you have all prerequisites to build `binaryen` and `cargo-fuzz` (`cmake` and a C++11 toolchain)\n- checkout with submodules (`git submodule update --init --recursive`)\n- install `cargo fuzz` subcommand with `cargo install cargo-fuzz`\n- set rustup to use a nightly toolchain, because `cargo fuzz` uses a rust compiler plugin: `rustup override set nightly`\n- run `cargo fuzz run deserialize`\n\n## `no_std` crates\n\nThis crate has a feature, `std`, that is enabled by default. To use this crate\nin a `no_std` context, add the following to your `Cargo.toml` (still requires allocator though):\n\n```toml\n[dependencies]\nparity-wasm = { version = \"0.41\", default-features = false }\n```\n\n## License\n\n`parity-wasm` is primarily distributed under the terms of both the MIT\nlicense and the Apache License (Version 2.0), at your choice.\n\nSee LICENSE-APACHE, and LICENSE-MIT for details.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in parity-wasm by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n", "release_dates": []}, {"name": "pc2_cuda", "description": "CUDA implementation of Filecoin's PC2 operation", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Optimized Filecoin PC2\nStandalone C++ GPU implementation of Filecoin's PreCommit2 function\n\n**This repository is for demonstration purposes only. Feel free to modify as needed to support your specific setup.**\n\n## Build and Running\n```\n1. ./build.sh\n2. ./run_pc2 -i <path> -o <path> -s <sector_size>\n-i Directory containing all the layer data files from PC1\n-o Output directory for tree c and tree r data\n-s Sector size, for example 2KiB or 32GiB\n```\n\n## Various Notes\n- The pc2 performance for 32GB sectors is ~150 seconds (2.5 min) on a 3090 GPU.\n- Currently only CC sectors are supported. In order to work with non-CC sectors, the code needs to be updated to add the piece_file with the final layer prior to building tree r.\n- The test includes timed pinned memory allocation and deallocation. If used in an application, the pinning only needs to performed once then reused across many different sectors.\n- The test will check the tree c and tree r output data against the files in the input path. If run on non-CC sectors then tree c should match although tree r will fail.\n", "release_dates": []}, {"name": "PebblingAndDepthReductionAttacks", "description": null, "language": "C#", "license": null, "readme": "Build and run:\n\n```\nxbuild /p:Configuration=Debug /p:TargetFrameworkVersion=v4.5 &&\nmono ConsoleApplication1/bin/Debug/ConsoleApplication1.exe\n```\n\nReviewing code and trying to replicate the comparisons between the Valiant and greedy attacks. Uncommented `depthExperiment3` in `main` to compare Valiant in `BestDepthReducingSetExcludeGreedy` with `myGreedyDRSetsApxNoSortingNew`.\n", "release_dates": []}, {"name": "phase2", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# phase21 [![Crates.io](https://img.shields.io/crates/v/phase21.svg)](https://crates.io/crates/phase21)\n\n> This is fork of the great [phase2](https://github.com/ebfull/phase2) library.\n\nThis library is still under development.\n\n## [Documentation](https://docs.rs/phase21/)\n\n## Security Warnings\n\nThis library does not make any guarantees about constant-time operations, memory access patterns, or resistance to side-channel attacks.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "phase2-attestations", "description": null, "language": "Standard ML", "license": null, "readme": "# Filecoin Phase2 Attestations\n\nThis repo contains the attestation files for participants who participated in Filecoin's trusted-setups (multiparty computations which generate Groth16 parameters for each Filecoin proof). This repo is specific to phase2 of Filecoin's trusted-setups; more info regarding phase1 (i.e. \"Powers-of-Tau\") can be found [below](#phase1).\n\n## Filecoin's Phase2 Ceremonies\n\nEach Filecoin circuit requires its own phase2 trusted-setup. As new proofs are added (and old proofs are upgraded) to the Filecoin network, new directories will be added to this repo. Each of these directories is named after a Git commit in either [`rust-fil-proofs`](https://github.com/filecoin-project/rust-fil-proofs) or [`filecoin-phase2`](https://github.com/filecoin-project/filecoin-phase2) pointing to a place in Git history where each phase2 trusted-setup took place.\n\n| Trusted-Setup | Ceremony Dates | Circuits | Directory |\n| :-----------: | :----------: | :------: | :-------: |\n| Mainnet | July - August 2020 | SDR-PoRep <br /> Winning-PoSt <br /> Window-PoSt | [b288702](/b288702) |\n| SnapDeals | December 2021 - January 2022 | EmptySectorUpdate <br /> EmptySectorUpdate-Poseidon | [934fe8c](/934fe8c) |\n\n**Note:** two phase2 trusted-setups were run for each circuit in the above table; one for the 32GiB sector-size and another for the 64GiB sector-size.\n\n## Phase2 Validation\n\nFilecoin publishes all files generated during its trusted-setups at: https://trusted-setup.filecoin.io.\n\nOnce a circuit's trusted-setup is complete, anyone can verify that the circuit's Groth16 parameters used by the Filecoin network were in fact generated during the attested to trusted-setup. The authenticity of each file can be verified using its published GPG signature and the corresponding participant's signing public-key.\n\nFollow the verification instructions in each trusted-setup directory's README to verify the Groth16 parameters generated by the phase2 ceremony.\n\n## Description of Trusted-Setup Phases\n\nEach Filecoin trusted-setup proceeds in two \"phases\"; phase1, also called \"Powers-of-Tau\", and phase2. Both trusted-setup phases are run as a multiparty computation; anyone is able to participate and this contribute to the proof's security. Phase1 is run once and is used for all Filecoin circuits, whereas a phase2 ceremony is run for each circuit. Each time the Filecoin network adds a proof type or upgrades an old proof type, a phase2 ceremony must be run to establish that proof type's security.\n\n### Phase1\n\nFilecoin ran one phase1 trusted-setup; the output of which is used in each circuit's phase2 trusted-setup.\n\nThe phase1 code can be found in the [`powersoftau`](https://github.com/arielgabizon/powersoftau) repo. Filecoin's phase1 participant attestation files and verification instructions can be found in the [`perpetualpowersoftau`](https://github.com/arielgabizon/perpetualpowersoftau) repo.\n\nAn intermediary step called \"phase1.5\" is run at the end of the phase1 trusted-setup. This step makes phase1's output usable by phase2. The output of phase1 is the file [`challenge19`](http://trusted-setup.filecoin.io/phase1/challenge_19); phase1.5 consists of running the [`create_lagrange`](https://github.com/filecoin-project/powersoftau/blob/master/src/bin/create_lagrange.rs) binary on `challenge19`. The outputs of phase1.5 are the files `phase1radix2m{0..27}` which are used by phase2 to generate each circuit's Groth16 parameters.\n\n#### Phase1 Randomness Beacon\n\nFilecoin did not use a randomness beacon during its phase1 trusted-setup for the following reason:\n\n> Applying the random beacon, enables proving security of the MPC under the Knowledge of Exponent assumption as shown in\n> the [paper of Bowe, Gabizon and Miers](https://eprint.iacr.org/2017/1050.pdf). However, there is no known attack when\n> the random beacon is omitted; and in fact, Mary Maller showed (see [A Proof of Security for the Sapling Generation of\n> zk-SNARK Parameters in the Generic Group\n> Model](https://github.com/zcash/sapling-security-analysis/blob/master/MaryMallerUpdated.pdf) and [Reinforcing the\n> Security of the Sapling MPC](https://electriccoin.co/blog/reinforcing-the-security-of-the-sapling-mpc/)) that the MPC\n> can be proven secure in the generic group model even when the random beacon is not used. Though the generic group\n> model is a stronger assumption than the knowledge of exponent, this is arguably not a big issue in this context, as\n> the generic group model is needed in any case for the security of the Groth16 zk-SNARK [\u2014Ariel\n> Gabizon](https://github.com/arielgabizon/perpetualpowersoftau)\n\n### Phase2\n\nEach circuit's phase2 proceeds as follows:\n\n1. Initial Groth16 parameters are deterministically generated for the circuit using the phase1 file `phase1radix2m<exp>` corresponding to the circuit's size; note that these initial Groth16 parameters are insecure\n2. The first participant generates secret randomness and updates the initial parameters using their generated randomness\n3. The first participant's contribution is verified using a variety of techniques including file checksum validation, participant signature validation, hash chains, and a probabilistic technique which ensures that all Groth16 parameters were updated using the same randomness (without the verifier learning the participant's randomness)\n4. Repeat steps 3 and 4 for each remaining participant; each participant generates secret randomness and mutates the previous participant's parameters\n5. The circuit's Groth16 proving and verifying keys are split out of the final participant's phase2 parameters\n\nThe code used to run phase2 can be found in the [`filecoin-phase2`](https://github.com/filecoin-project/filecoin-phase2) repo.\n\n#### Files Generated During Phase2\n\nEach participant generates a parameters file, a `.contrib` contribution file, and two `.sig` signature files.\n\n- **Parameters File:** each participant generates a parameters file `<proof>_poseidon_<sector>_<commit>_<num>_<size>` by mutating the previous participant's parameters file using secretly generated randomness.\n    - `proof` is the proof/circuit's name (`sdr`, `winning`, `window`, `update`, `updatep`)\n    - `poseidon` is Filecoin's TreeR hash function\n    - `sector` is the sector-size with which the circuit is compatible (`32gib`, `64gib`)\n    - `commit` is a 7-character git commit digest pointing to the phase2 code and circuit\n    - `num` is an unsigned integer incremented once for each phase2 participant; each circuit's initial parameters have participant number `0`, likewise the first participant has number `1` and so on\n    - `size` indicates the parameters file's size; a `large` parameters file contains all of a circuit's Groth16 parameters, whereas a `small` file contains only the subset of Groth16 parameters updated by the participant\n\n- **Contribution File:** when updating the phase2 parameters, a participant generates a `.contrib` contribution file which stores a checksum of the previous participant's parameters, the current participant's parameters, and data about how the participant mutated the parameters; the `.contrib` files generated during each circuit's trusted-setup function as a hash chain used to verify the trusted-setup.\n\n- **Signature Files:** each participant signs their generated parameters and `.contrib` files using GPG; signing produces two detached signature files having extensions `.sig` and `.contrib.sig`. These signature files ensure that the phase2 files published by Filecoin were in fact created by the attested to participant. Verifying a participant's signatures requires downloading the participant's GPG signing public-key; this repo contains a link to each participant's published public-key.\n\n## Contact Us\n\nA slack channel has been set up to discuss Filecoin's trusted-setup; please join the **#fil-trustedsetup** channel in our Slack workspace `filecoinproject.slack.com` or email us at `trustedsetup@protocol.ai`.\n", "release_dates": []}, {"name": "phase2-attestations-internal-verification", "description": null, "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "powersoftau", "description": "Communal zk-SNARK MPC for Public Parameters", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Powers of Tau\r\n\r\n## Original story\r\n\r\nThis is a [multi-party computation](https://en.wikipedia.org/wiki/Secure_multi-party_computation) (MPC) ceremony which constructs partial zk-SNARK parameters for _all_ circuits up to a depth of 2<sup>21</sup>. It works by taking a step that is performed by all zk-SNARK MPCs and performing it in just one single ceremony. This makes individual zk-SNARK MPCs much cheaper and allows them to scale to practically unbounded numbers of participants.\r\n\r\nThis protocol is described in a [forthcoming paper](https://eprint.iacr.org/2017/1050). It produces parameters for an adaptation of [Jens Groth's 2016 pairing-based proving system](https://eprint.iacr.org/2016/260) using the [BLS12-381](https://github.com/ebfull/pairing/tree/master/src/bls12_381) elliptic curve construction. The security proof relies on a randomness beacon being applied at the end of the ceremony.\r\n\r\n## Contributions\r\n\r\nExtended to support Ethereum's BN256 curve and made it easier to change size of the ceremony. In addition proof generation process can be done in memory constrained environments now. Benchmark is around `1.3 Gb` of memory and `3 hours` for a `2^26` power of tau on BN256 curve on my personal laptop\r\n\r\n## Instructions\r\n\r\nInstructions for a planned ceremony will be posted when everything is tested and finalized.\r\n\r\n---\r\n## To run the ceremony on your laptop:\r\n\r\n1. Preparation:\r\n\r\n```\r\nrustup update # tested on rustup 1.17.0\r\ncargo build\r\n```\r\n\r\n2. Put `response` file from the previous ceremony to root directory.\r\n3. To generate `new_challenge` run:\r\n\r\n```\r\ncargo run --release --bin verify_transform_constrained # this will generate new_challenge from response file\r\n```\r\n\r\n4. Backup old files and replace `challenge` file:\r\n\r\n```\r\nmv challenge challenge_old\r\nmv response response_old\r\nmv new_challenge challenge\r\n```\r\n\r\n5. Run ceremony:\r\n\r\n```\r\ncargo run --release --bin compute_constrained # generate response file\r\n```\r\n\r\nPut your hash from output response to private gist (example: https://gist.github.com/skywinder/c35ab03c66c6b200b33ea2f388a6df89)\r\n\r\n6. Reboot laptop to clean up toxic waste.\r\n\r\n7. Save `response` file and give it to the next participant.\r\n\r\n## Recommendations from original ceremony\r\n\r\nParticipants of the ceremony sample some randomness, perform a computation, and then destroy the randomness. **Only one participant needs to do this successfully to ensure the final parameters are secure.** In order to see that this randomness is truly destroyed, participants may take various kinds of precautions:\r\n\r\n* putting the machine in a Faraday cage\r\n* destroying the machine afterwards\r\n* running the software on secure hardware\r\n* not connecting the hardware to any networks\r\n* using multiple machines and randomly picking the result of one of them to use\r\n* using different code than what we have provided\r\n* using a secure operating system\r\n* using an operating system that nobody would expect you to use (Rust can compile to Mac OS X and Windows)\r\n* using an unusual Rust toolchain or [alternate rust compiler](https://github.com/thepowersgang/mrustc)\r\n* lots of other ideas we can't think of\r\n\r\nIt is totally up to the participants. In general, participants should beware of side-channel attacks and assume that remnants of the randomness will be in RAM after the computation has finished.\r\n\r\n## License\r\n\r\nLicensed under either of\r\n\r\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\r\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\r\n\r\nat your option.\r\n\r\n### Contribution\r\n\r\nUnless you explicitly state otherwise, any contribution intentionally\r\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\r\nlicense, shall be dual licensed as above, without any additional terms or\r\nconditions.\r\n", "release_dates": []}, {"name": "product", "description": "A place to discuss Filecoin product ideas that are not immediately associated with an existing protocol, implementation, or product", "language": null, "license": null, "readme": "# product\nA place to discuss Filecoin product ideas that are not immediately associated with an existing protocol, implementation, or product\n", "release_dates": []}, {"name": "pubsub", "description": "A simple pubsub package for go.", "language": "Go", "license": null, "readme": "Install pubsub with,\n\n    go get github.com/tuxychandru/pubsub\n\nView the [API Documentation](http://godoc.org/github.com/tuxychandru/pubsub).\n\n## License\n\nCopyright (c) 2013, Chandra Sekar S  \nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n", "release_dates": ["2022-05-10T20:49:42Z"]}, {"name": "raas-starter-kit", "description": null, "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Replication/Renewal-as-a-Service Starter Kit\n\n## Introduction\n\nThis repository consists of two components to build a tool to renew or replicate storage deals.\n\n* DealStatus Contract: a smart contract to query the status of storage deals.\n* Service.js: a RaaS aplication that renew, replicate, or repair storage deals when necessary.\n\nPlease refer to this [doc](https://www.notion.so/pl-strflt/Data-FVM-234b7f4c17624cd8b972f92806732ca9) to understand more.\n\n## Cloning the Repo\n\nOpen up your terminal (or command prompt) and navigate to a directory you would like to store this code on. Once there type in the following command:\n\n\n```bash\ngit clone --recurse-submodules git@github.com:filecoin-project/raas-starter-kit.git\ncd raas-starter-kit\nyarn install\n```\n\n\nThis will clone the hardhat kit onto your computer, switch directories into the newly installed kit, and install the dependencies the kit needs to work.\n\n\n## Get a Private Key\n\nYou can get a private key from a wallet provider [such as Metamask](https://metamask.zendesk.com/hc/en-us/articles/360015289632-How-to-export-an-account-s-private-key).\n\n\n## Setting Environment Variables\n\nAdd your private key as an environment variable inside the `.env` file:\n\n```bash\nPRIVATE_KEY='abcdef'\n```\n\nDon't commit and push any changes to .env files that may contain sensitive information, such as a private key! If this information reaches a public GitHub repository, someone can use it to check if you have any Mainnet funds in that wallet address, and steal them!\n\n\n## Get the Deployer Address\n\nRun this command:\n```bash\nyarn hardhat get-address\n```\n\nThis will show you the ethereum-style address associated with that private key and the filecoin-style f4 address (also known as t4 address on testnets)! The Ethereum address can now be exclusively used for almost all FEVM tools, including the faucet.\n\n\n## Fund the Deployer Address\n\nGo to the [Calibrationnet testnet faucet](https://calibration.yoga/#faucet), and paste in the Ethereum address from the previous step. This will send some calibration testnet FIL to the account.\n\n\n## Deploy the DealStatus Contract\n\nType in the following command in the terminal to deploy all contracts:\n\n```bash\nyarn hardhat deploy\n```\n\nThis will compile the DealStatus contract and deploy it to the Calibrationnet test network automatically!\n\nKeep note of the deployed contract address - the service node will need it to interact with the contract.\n**Update the `contractInstance` variable in `api/service.js` with the deployed contract address.**\n\nThere's a contract interface in the `contracts/interfaces` directory that `DealStatus` inherits from. If you would like to create your own contract different from `DealStatus`, be sure to inherit from and override the methods in the interface.\n\n## Interacting with the RaaS application\n\nThe RaaS application is a server that handles REST API requests for renewing, replicating, or repairing storage deals. It is located in the `api` directory.\n\nBefore starting the frontend, ensure that you have already started your RaaS node service.\n\nTo start the server, run the following commands:\n\n```bash\nyarn service # This starts up the node service backend. Must be performed before using the frontend.\nyarn start # This starts up the frontend\n```\n\nYou can access a frontend of the app at [localhost:1337](http://localhost:1337/). \n\n**Note: some processes that the service performs (such as uploading deals to lighthouse) may take up to 24 hours. Once you submit the deal, you do not need to keep the node running.** The node will attempt to finish incomplete jobs on startup by reading from the state-persisting files it creates in cache whenever jobs are registered.\n\nSeveral test cases for the service's functionality are located in `api/tests`. To run them, run the following command:\n\n```bash\n# Tests the interaction for API calls into service\nyarn test-service\n# Tests interactions between service and aggregator nodes\nyarn test-edge\nyarn test-lighthouse\n```\n\n### How RaaS Works\n\nTo innovate new use cases, you'll have to take apart your app. The RaaS application has two components: the API frontend and the smart contract backend. \n\nThe backend stores the CID of the file and the infos used to complete the storage deal (e.g. the proof that the file is included on chain). It also has functionality to return active deals made with a particular CID, as well as deals that are about to expire.\n\nThe API frontend performs the following:\n- **Allows users to register various jobs to be performed by the service (performed by default every 12 hours)**.\n  - **Replication**: When building a storage solution with FVM on Filecoin, storage deals need to be replicated across geo location, policy sizes and reputation. Replication deals ensure that data can be replicated N times across a number of storage providers.\n  - **Renewal**: When building storage solutions with FVM on Filecoin, storage deals need to be live for a long time. This service should be able to take an existing deal and renew it with the same or a different storage provider.\n  - **Repair**: When building storage solutions with FVM on Filecoin, storage deals need to be stable. Repair jobs ensure that data can be maintained when it comes close to the end of its lifetime, or if the data somehow becomes inactive and needs to be repaired via. another storage provider.\n  - **Monitors Smart Contract**: The node listens to the `SubmitAggregatorRequest` event in aggregators\u2019 smart contract, and trigger the following workflow whenever it sees a new SubmitAggregatorRequest event. \n    - 1. A new`SubmitAggregatorRequest` event comes in, the node saves save the `txId` and `cid`, and go to the next step\n    - 2. Create a new deal with aggregators by retrieving and uploading the data\n      - The response contains an ID, which is the `content_id`\n    - 3. [Use the content_id to check the upload\u2019s status](https://github.com/application-research/edge-ur/blob/car-gen/docs/aggregation.md#checking-the-status-by-content-id)\n    - 4. Periodically poll the API above, and once `deal_id` becomes non-zero, proceed to the next step\n    - 5. Post the `deal_id`, `inclusion_proof`, and `verifier_data` back to [the aggregators\u2019 smart contract](https://github.com/application-research/fevm-data-segment/blob/main/contracts/aggregator-oracle/edge.sol#L52) by calling the `complete` method, along with the `txId` and `cid`\n\nFor a more detailed guide, check out the [documentation](https://www.notion.so/Renew-Replication-Starter-Kit-f57af3ebd221462b8b8ef2714178865a).\n\n## API Usage\n\nOnce you start up the server, the POST endpoint will be available at the designated port.\n\nYou can then send jobs to the server with the following information:\n\n```json\n{\n  \"job\": {\n    \"cid\": \"value_of_cid\",\n    \"endDate\": \"value_of_end_date\",\n    \"jobType\": \"value_of_job_type\",\n    \"replicationTarget\": \"value_of_replication_target\", // (required for replication jobs)\n    \"aggregator\": \"type_of_aggregator\", // Recommended to be \"lighthouse\"\n    \"epochs\": \"value_of_epochs\" // (required for renewal jobs)\n    }\n}\n```\n\nThe below is an example of a POST request to the server:\n\n```bash\ncurl --location 'http://localhost:1337/api/register_job' \\\n--header 'Accept: application/json' \\\n--header 'User-Agent: SMB Redirect/1.0.0' \\\n--header 'Content-Type: application/x-www-form-urlencoded' \\\n--header 'Authorization: Basic ZDU5MWYyYzQtMzk0MS00ZWM4LTkyNTQtYjgzZDg1NmI2YmU5Om1xZkU5eklsVFFOdGVIUnY2WDEwQXVmYkNlN0pIUXVC' \\\n--data-urlencode 'cid=QmYSNU2i62v4EFvLehikb4njRiBrcWqH6STpMwduDcNmK6' \\\n--data-urlencode 'endDate=2023-07-15' \\\n--data-urlencode 'jobType=replication' \\\n--data-urlencode 'replicationTarget=1' \\\n--data-urlencode 'aggregator=lighthouse' \\\n--data-urlencode 'epochs=1000'\n```\n\nThe `aggregator` field can be one of the following: `edge`, or `lighthouse`. This changes the type of aggregator node that the service will use to interact with the Filecoin network.\n\nThe `jobType` field can be one of the following: `renew`, `replicate`, or `repair`. This changes the type of job that the service will perform.\n\nFind more information [here](https://www.notion.so/Renew-Replication-Starter-Kit-f57af3ebd221462b8b8ef2714178865a#fc387e4c63114459b2583572c823a4c5)", "release_dates": []}, {"name": "ref-fvm", "description": "Reference implementation of the Filecoin Virtual Machine", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Reference Filecoin VM implementation (v4; dev)\n\n[![Continuous integration](https://github.com/filecoin-project/ref-fvm/actions/workflows/ci.yml/badge.svg)](https://github.com/filecoin-project/ref-fvm/actions/workflows/ci.yml)\n\nThis repository contains the reference implementation of the Filecoin VM ([specs](https://github.com/filecoin-project/fvm-project)). It is written in Rust, and intended to be integrated via FFI into non-Rust clients (e.g. Lotus, Fuhon), or directly into Rust clients (e.g. Forest). FFI bindings for Go are provided in-repo, and developers are encouraged to contribute bindings for other languages.\n\n\nSee the [Project Website](https://fvm.filecoin.io/) for details.\n\n## Build requirements\n\n* Install [rustup](https://rustup.rs/).\n\n## Build instructions\n\n```sh\n$ git clone https://github.com/filecoin-project/ref-fvm.git\n$ cd ref-fvm\n$ make\n```\n\n## Code structure\n\nHere's what you'll find in each directory:\n\n- `/fvm`\n  - The core of the Filecoin Virtual Machine. The key concepts are:\n    - `Machine`: an instantiation of the machine, anchored at a specific state root and epoch, ready to intake messages to be applied.\n    - `Executor`: an object to execute messages on a `Machine`.\n    - `CallManager`: tracks and manages the call stack for a given message.\n    - Invocation container (conceptual layer, not explicitly appearing in code): the WASM instance + sandbox under which a given actor in the call stack runs.\n    - `Kernel`: the environment attached to an invocation container for external interactions.\n  - There are two API boundaries in the system:\n    1. the boundary between the actor code and the Kernel, which is traversed by invoking `Syscalls`.\n    2. the boundary between the FVM and the host node, represented by `Externs`.\n  - Some parts of the FVM are based on the [Forest](https://github.com/ChainSafe/forest) implementation.\n- `/sdk`\n  - Reference SDK implementation to write Filecoin native actors, used by the canonical built-in actors through the Actors FVM Runtime shim.\n  - User-defined FVM actors written in Rust can also use this SDK, although it is currently quite rough around the edges. In the next weeks, we expect to sweeten it for improved developer experience.\n  - Alternative SDKs will emerge in the community. We also expect community teams to develop SDKs in other WASM-compilable languages such as Swift, Kotlin (using Kotlin Native), and even Go (via the TinyGo compiler).\n- `/shared`\n  - A crate of core types and primitives shared between the FVM and the SDK.\n- `/ipld`\n  - IPLD libraries. Some of which are based on, and adapted from, the [Forest](https://github.com/ChainSafe/forest) implementation.\n- `/testing/conformance`\n  - Contains the test vector runner, as well as benchmarking utilities on top of it.\n  - The conformance test runner feeds the test vector corpus located at https://github.com/filecoin-project/fvm-test-vectors into ref-fvm, in order to validate spec conformance.\n  - The benchmarking utilities use the `criterion` Rust library to measure the performance and overhead of ref-fvm across various facets.\n  - See the [instructions](./testing/conformance/README.md#instructions) about how to run the tests and the benchmarks.\n  - Disclaimers\n    - Benchmarks are currently very slow to run, setup and teardown. This is due to using default WASM cache, and will be fixed soon.\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the\n[Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n\n---\n\nactors and vm forked from [ChainSafe/forest](https://github.com/ChainSafe/forest)\ncommit: [`73e8f95a108902c6bef44ee359a8478663844e5b`](https://github.com/ChainSafe/forest/commit/73e8f95a108902c6bef44ee359a8478663844e5b)\n", "release_dates": []}, {"name": "ref-fvm-fuzz-corpora", "description": "Fuzzing corpoa for ref-fvm and connected libraries", "language": null, "license": null, "readme": "### Fuzzing Corpoa for ref-fvm\n", "release_dates": []}, {"name": "release-metrics-gitops", "description": "A gitops repo for configuring the release-metrics namespace.", "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "replication-game", "description": "Compete on the fastest replication algorithm", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# The Replication Game\n\n> Compete on the fastest replication algorithm - [Participate here!](http://replication-game.herokuapp.com/)\n\n![](https://ipfs.io/ipfs/Qmdr2HMghfsknH9nfrRU2fjcdqZK8bjM8xa2JShBkehsCF/giphy.gif)\n\n## Introduction\n\n**What is this \"game\"?** The Replication Game is a competition where participants compete to outperform the default implementation of Proof-of-Replication. To participate in the game, you can run the current replication algorithm (or your own implementation) and post your proof on our server.\n\n**What is Proof-of-Replication?** Proof of Replication is the proof that: (1) the Filecoin Storage Market is secure: it ensures that miners cannot lie about storing users' data, (2) the Filecoin Blockchain is secure: it ensures that miners cannot lie about the amount of storage they have (remember, miners win blocks based on their storage power!). In Filecoin, we use the Proof of Replication inside \"Sealing\" during mining.\n\n**How does Proof of Replication work?** The intuition behind Proof of Replication is the following: the data from the Filecoin market is encoded via a slow sequential computation that cannot be parallelized.\n\n**How can I climb up in the leaderboard?** There are some strategies to replicate \"faster\", some are practical (software and hardware optimizations), some are believe to be impractical or impossible (get ready to win a price and be remembered in the history of cryptography if you do so!)\n\n- *Practical attempts*: Implement a faster replication algorithm with better usage of memory, optimize some parts of the algorithm (e.g. Pedersen, Blake2s) in hardware (e.g. FPGA, GPU, ASICs), performing attacks on Depth Robust Graphs (the best known attacks are [here](https://eprint.iacr.org/2017/443)).\n- *Impractical attempts*: Find special datasets that allow for faster replication, break the sequentiality assumption, generate the proof storing less data, break Pedersen hashes.\n\n## Play the Replication Game\n\nThis executes an actual game, using [rust-proofs](https://github.com/filecoin-project/rust-proofs), feel free to implement your own version.\n\nMake sure you have all required dependencies installed:\n\n- [rustup](https://www.rust-lang.org/tools/install)\n- Rust nightly (usually `rustup install nightly`)\n- [PostgreSQL](https://www.postgresql.org/)\n- Clang and libclang\n- [jq](https://stedolan.github.io/jq/download/) (optional) - prettify json output on the command-line, for viewing the leaderbord\n- gzip\n\nFrom the replication-game/ directory, compile the game binary:\n\n```bash\ncargo +nightly build --release --bin replication-game\n```\n\n### Play the game from the command line\n\nThere are two ways to play:\n- **Method 1:** Run the `play` helper script\n- **Method 2:** Run each individual command\n\n#### Method 1: Run the `play` helper script\n\nFrom the replication-game/ directory, run the `play` helper script in `bin/`, specifying:\n- `NAME`: your player name\n- `SIZE`: the size in KB of the data you want to replicate\n- `TYPE`: the type of algorithm you want to run (current options are `zigzag` and `drgporep`)\n\n```bash\n# Run like this:\n# bin/play NAME SIZE TYPE\n\n# E.g.\n\n# Zigzag 10MiB\nbin/play NAME 10240 zigzag\n\n# Zigzag 1GiB\nbin/play NAME 1048576 zigzag\n\n# DrgPoRep 10MiB\nbin/play NAME 10240 drgporep\n\n# DrgPoRep 1GiB\nbin/play NAME 1048576 drgporep\n```\n\nThe `play` script will retrieve the seed from the game server, replicate the data, generate a proof, and then post that proof to the game server. The script runs each of the commands in **Method 2**, but wraps them in an easy-to-use shell script.\n\n#### Method 2: Run each individual command\n\nSet your player name:\n\n```bash\nexport REPL_GAME_ID=\"ReadyPlayerOne\"\n```\n\nGet the seed from our server:\n\n```bash\ncurl https://replication-game.herokuapp.com/api/seed > seed.json\nexport REPL_GAME_SEED=$(cat seed.json| jq -r '.seed')\nexport REPL_GAME_TIMESTAMP=$(cat seed.json| jq -r '.timestamp')\n```\n\nPlay the game:\n\n```bash\n./target/release/replication-game \\\n\t--prover $REPL_GAME_ID \\\n\t--seed $REPL_GAME_SEED \\\n\t--timestamp $REPL_GAME_TIMESTAMP \\\n\t--size 10240 \\\n\tzigzag > proof.json\n```\n\nSend your proof:\n\n```bash\ncurl -X POST -H \"Content-Type: application/json\" -d @./proof.json https://replication-game.herokuapp.com/api/proof\n```\n\n### Check the current leaderboard\n\nThere are three ways to check the leaderboard, two from the command line and one from the browser:\n- **Method 1:** (From the command line) Run the `show-leaderboard` helper script\n- **Method 2:** (From the command line) Curl the leaderboard\n- **Method 3:** View the leaderboard in the browser\n\n#### Method 1: Run the `show-leaderboard` helper script\n\nFrom the replication-game/ directory, run the `show-leaderboard` helper script in `bin/`, specifying `SIZE`, which is the size in KB by which you want to filter the leaderboard results. The leaderboard shows all results across all parameters in a single list, so filtering by `SIZE` allows you to see only those results that match a particular size.\n\n```bash\nbin/show-leaderboard SIZE\n```\n\n#### Method 2: Curl the leaderboard\n\nTo check the current leaderboard using `curl`:\n\n```bash\ncurl https://replication-game.herokuapp.com/api/leaderboard | jq\n```\n\n#### Method 3: View the leaderboard in the browser\n\nYou can also directly view the leaderboard in the browser at https://replication-game.herokuapp.com/.\n\n## FAQ\n\n>  What parameters should I be using for the replication?\n\nOur leaderboard will track the parameters you will be using, feel free to experiment with many. We are targeting powers of two, in particular: 1GiB (`--size 1048576`), 16GiB (`--size 16777216`), 1TB (`--size 1073741824`)\n\n> How do I know what the parameters mean?\n\n```bash\n./target/debug/replication-game --help\n```\n\n> What do I win if I am first?\n\nSo far, we have no bounty set up for this, but we are planning on doing so. If you beat the replication game (and you can prove it by being in the leaderboard), reach out to [filecoin-research@protocol.ai](mailto:filecoin-research@protocol.ai).\n\n\n\n------\n\n\n\n## Replication Game Server\n\n```bash\n$ cargo +nightly run --bin replication-game-server\n```\n\nThis server requires Postgresql to work. The details of the expected configuration can be found in [`Rocket.toml`](Rocket.toml). The default environment is `development`.\n\n### API\n\n- GET `/api/seed`:\n  - Returns a `timestamp` (unix time) and a `seed` to be used as `replica_id` in the proof of replication\n- POST `/api/proof`\n  - Inputs: `timestamp`, `seed`, `prover_id` and `proof`\n  - Checks authenticity of the seed (using the timestamp and a secret on the server)\n  - Checks that the `proof` is correct\n  - Computes `replication_time = timestamp - current_time`\n  - If `replication_time < times[prover_id]`, then `times[prover_id] = replication_time`\n- GET `/api/leaderboard`:\n  - Shows a leaderboard of all the miners sorted by replication time\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "replication-game-leaderboard", "description": "Leaderboard for the replication game", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Replication Game Leaderboard\n\n> Frontend to the [replication game](https://github.com/filecoin-project/replication-game)\n\n[![build status](https://img.shields.io/circleci/project/github/filecoin-project/replication-game-leaderboard/master.svg?style=flat-square)](https://circleci.com/gh/filecoin-project/replication-game-leaderboard)\n\nView the leaderboard at https://replication-game.herokuapp.com/\n\n![screenshot](./screenshot.png)\n\n## Usage\n\nFirst, clone the project and install dependencies. You'll need [Git](https://git-scm.com/) and [Node.js](https://nodejs.org/en/) installed.\n\n```console\n$ git clone git@github.com:filecoin-project/replication-game-leaderboard.git\n$ npm install\n```\n\n### Development\n\nStart a development server:\n\n```console\n$ npm start\n$ # ... server now running at http://localhost:3000\n```\n\n### Production\n\nBuild for production:\n\n```console\n$ REACT_APP_API_URL=/api/leaderboard npm run build\n```\n\n---\n\nThis project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).\n\n## Available Scripts\n\nIn the project directory, you can run:\n\n### `npm start`\n\nRuns the app in the development mode.<br>\nOpen [http://localhost:3000](http://localhost:3000) to view it in the browser.\n\nThe page will reload if you make edits.<br>\nYou will also see any lint errors in the console.\n\n### `npm test`\n\nLaunches the test runner in the interactive watch mode.<br>\nSee the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.\n\n### `npm run build`\n\nBuilds the app for production to the `build` folder.<br>\nIt correctly bundles React in production mode and optimizes the build for the best performance.\n\nThe build is minified and the filenames include the hashes.<br>\nYour app is ready to be deployed!\n\nSee the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information.\n\n### `npm run eject`\n\n**Note: this is a one-way operation. Once you `eject`, you can\u2019t go back!**\n\nIf you aren\u2019t satisfied with the build tool and configuration choices, you can `eject` at any time. This command will remove the single build dependency from your project.\n\nInstead, it will copy all the configuration files and the transitive dependencies (Webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except `eject` will still work, but they will point to the copied scripts so you can tweak them. At this point you\u2019re on your own.\n\nYou don\u2019t have to ever use `eject`. The curated feature set is suitable for small and middle deployments, and you shouldn\u2019t feel obligated to use this feature. However we understand that this tool wouldn\u2019t be useful if you couldn\u2019t customize it when you are ready for it.\n\n## Learn More\n\nYou can learn more in the [Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started).\n\nTo learn React, check out the [React documentation](https://reactjs.org/).\n\n### Code Splitting\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting\n\n### Analyzing the Bundle Size\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size\n\n### Making a Progressive Web App\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app\n\n### Advanced Configuration\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration\n\n### Deployment\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/deployment\n\n### `npm run build` fails to minify\n\nThis section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify\n", "release_dates": []}, {"name": "research", "description": "Home for Filecoin Research", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin Research\n\n<img src=\"https://lh3.googleusercontent.com/oe0fJWHIcpXy5eFcOYLA0YFjwXnXGz4lPQv4-szxhrdxeUBKZmJJHjwsveOvkqBBfT9koSOCw8TYoNd78h4zAcpeD4UL0olne2AgwEittt54xRj8sTWBsBi3Xx4SI8DAfz-0lyhA\" width=\"150px\"> \n\n---\n\nThis repository is the main hub leading to the various efforts in Filecoin Research and should provide you with the means to engage in this work.\n\n**Disclaimer:** While we work hard to document our work as it progresses, research progress may not be fully reflected here for some time, or may be worked out out-of-band.\n\n## Table of Contents\n\n- [What is Filecoin Research?](#what-is-filecoin-research)\n- [Filecoin Research Endeavours](#filecoin-research-endeavours)\n  - [Overview](#overview)\n  - [Area: Consensus](#area-consensus)\n  - [Area: Filecoin Protocol Improvements](#area-filecoin-protocol-improvements)\n  - [Area: Generic Blockchain Infrastructure](#area-generic-blockchain-infrastructure)\n  - [Area: Primitives](#area-primitives)\n  - [Area: Practical zk-SNARKs ](SNARK/SNARK.md)\n  - [Area: Practial PoRep](porep/porep.md)\n  - [Key Open Problems](#key-open-problems)\n- [Contributing](#contributing)\n- [Community](#community)\n- [Useful Docs](#useful-docs)\n- [License](#license)\n\n## What is Filecoin Research?\n\n- **Make breakthroughs in the Filecoin protocol**\n- **Support devs to develop Filecoin**\n\nThe purpose of Filecoin Research is to design or build the predicates enabling Filecoin: a decentralized storage network. We work to prove Filecoin constructions correct, or to improve them. The work here should provide some motivations for decisions about how Filecoin works; its output is [the Filecoin spec](https://github.com/filecoin-project/specs), from which a filecoin network can be implemented.\n\n## Filecoin Research Endeavours\n\nFilecoin Research work is conducted by area of focus, with current efforts ongoing in:\n- [Specs](https://github.com/filecoin-project/specs): The Filecoin Spec is the main interface between research and Filecoin development. Research work is only complete once it finds its way into the spec.\n- General Research (you're already here): This repo generally regroups unsolved-problems with Filecoin Research and helps organize our research work.\n- [Proofs](https://github.com/filecoin-project/rust-proofs): Dedicated to shaping and building out the Filecoin Proving Subsystem (FPS), whose API can be called by a Filecoin node to Seal disk sectors, or generate PoSTs for instance.\n- [Consensus](https://github.com/filecoin-project/consensus): Dedicated to finalizing the construction and proving the security of Filecoin's Consensus protocol, through which leaders are elected to mine new blocks and extend the Filecoin blockchain.\n\n#### Overview\n\nHere is a list of the Filecoin project's research endeavours, we split them by projects for discoverability and further highlight select problems [below](#key-open-problems). We also specify scope and priority in this table, you can find exact definitions for these [here](problems-glossary.md).\n\n- [Area: Consensus](#area-consensus)\n- [Area: Filecoin Protocol Improvements](#area-filecoin-protocol-improvements)\n- [Area: Generic Blockchain Infrastructure](#area-generic-blockchain-infrastructure)\n- [Area: Primitives](#area-primitives)\n\n#### Area: Consensus\n\nThis endeavour deals with the Filecoin consensus layer broadly. It encompassed projects dealing with precise constructions Filecoin uses or could use (like Expected Consensus or Single Secret Leader Election) as well as the broader classification of Storage-Power-based Consensus in the field, for instance in relation to PoW and PoS. See the [consensus repo](https://github.com/filecoin-project/consensus) for more.\n\n<table style=\"width:100%\">\n  <col width=\"15%\">\n  <col width=\"35%\">\n  <col width=\"40%\">\n  <col width=\"10%\">\n  <tr>\n    <th><b>Project</b></th>\n    <th><b>Description</b></th> \n    <th><b>Problems</b></th>\n    <th><b>Status</b></th>\n  </tr>\n  <tr>\n    <td><b>Expected Consensus (EC)</b></td>\n    <td>Expected Consensus is a consensus protocol that includes a block proposer and a way to achieve agreement (PoS Nakamoto consensus) on a particular block. It yields one secret leader per round on expectation, but may yield 0 or multiple.</td> \n    <td>Short-term/Ongoing:<br>- Formal analysis of EC Security<br>- <a href=\"./open-problems.md#ec-attacks\">Heuristic Security and attack simulations</a></td>\n    <td>Working on/Collaboration</td>\n  </tr>\n  <tr>\n    <td><b>Secret Single Leader Election (SSLE)</b></td>\n    <td>SSLE is a leader election protocol that guarantees that at each round only a single leader is elected (as opposed to one on expectation) and its identity remains secret until announced.</td>\n    <td>Short-term:<br>- A practical <a href=\"./open-problems.md#ssle\">SSLE Construction</a><br><br>Medium-term:<br>- A consensus protocol that uses SSLE as leader election (and adaptation into Filecoin)</td>\n    <td>Collaboration/RFP</td>\n  </tr>\n  <tr>\n    <td><b>Storage Power Consensus (SPC)</b></td>\n    <td>Storage Power Consensus is the intermediate layer of consensus in the Filecoin system, bridging the gap between a storage network and Proof of Stake consensus to elect leaders based on storage committed to the network.</td>\n    <td>Short-term:<br>- <a href=\"open-problems.md#committing-power-to-a-particular-fork\">Committing power to a particular fork</a> (e.g. through reseal)<br><br>Medium-term:<br>- Efficient 51% block signing via all-to-all communications<br>- Proof-of-Space before SEAL<br><br>Long-term:<br>- Formally defining the EC/SPC interface</td>\n    <td>Working on/Collaboration/RFP</td>\n  </tr>\n  <tr>\n    <td><b>Power Fault Tolerance (PFT)</b></td>\n    <td>PFT is abstracted in terms of influence over the protocol rather than machines</td>\n    <td>Medium-term:<br>- Formal framework for PFT in third gen blockchains</td>\n    <td>Working on/Collaboration</td>\n  </tr>\n</table>\n\n## Area: Filecoin Protocol Improvements\n\nThis area deals with the transaction layer of the Filecoin protocol and encompasses endeavours across the various parts that come together to make up Filecoin. We quickly present our research interests here.\n\n<table style=\"width:100%\">\n  <col width=\"15%\">\n  <col width=\"35%\">\n  <col width=\"40%\">\n  <col width=\"10%\">\n  <tr>\n    <th><b>Endeavour</b></th>\n    <th><b>Description</b></th> \n    <th><b>Problems</b></th>\n    <th><b>Status</b></th>\n  </tr>\n  <tr>\n    <td><b>Mining</b></td>\n    <td>Mining here refers to the work of storage miners in the Filecoin network, who use proofs to store files on a client's behalf. This section deals with the ways miners interact with proofs as part of storage and retrieval mining in Filecoin.</td>\n    <td>Short-term/Ongoing:<br>- PoST difficulty adjustment<br>- Tolerating faults for honest miners<br><br>- Medium-term:<br>- PoSpace after Pledge (before SEAL)<br>- Mining Pools in Filecoin</td>\n    <td>Working on/Collaboration (Curious for medium-term)</td>\n  </tr>\n  <tr>\n    <td><b>Repair</b></td>\n    <td>Repair miners ensure that as storage miners go offline, clients' orders remain secure. They are verifiers of the chain, catching faults and ensuring orders are re-assigned when storage miners fail.</td>\n    <td>Medium-term:<br>- Repair proofs<br>- Scaling Repair<br><br>Long-term:<br>- Watchtowers for storage repair</td>\n    <td>RFP/Curious</td>\n  </tr>\n  <tr>\n    <td><b>Securing Filecoin</b></td>\n    <td>Filecoin protocol security (to be distinguished from the security of an implementation) is a major endeavour of Filecoin research. It touches our consensus layer, primitives, and transaction layer more broadly. We break this work down into three broad categories: economic security (or incentive compatibility), formal security (provable guarantees), and heuristic security (attack analysis and parameter setting). We detail a few of our endeavours in the space here.</td>\n    <td>Short-term:<br>- Cryptoeconomic simulator<br>- PoST security proofs<br>- Formally analyzing Filecoin through the lens of PoS and PoW<br>- Filecoin DoS analysis<br>- Formal analysis of Filecoin finality<br><br>Medium-term:<br>- Filecoin checkpointing</td>\n    <td>Working on/Collaboration</td>\n  </tr>\n  <tr>\n    <td><b>Storage Market</b></td>\n    <td>The Filecoin's storage market refers to market dynamics around miners' monetization of disk space. Storage market questions concern the tools Filecoin provides miners to manage their disk in filling orders on the network.</td>\n    <td>Short-term:<br>- Multiple Sector sizes<br><br>Medium-term:<br>- PoST alternatives for proving storage</td>\n    <td>Working on/Collaboration, Curious for long-term</td>\n  </tr>\n</table>\n\n\n## Area: Generic Blockchain Infrastructure\n\nWe plan to improve the state of the art of generic blockchain constructions. As part of developing Filecoin, we've uncovered open problems that may interest the community at large.\n\n<table style=\"width:100%\">\n  <col width=\"15%\">\n  <col width=\"35%\">\n  <col width=\"40%\">\n  <col width=\"10%\">\n  <tr>\n    <th><b>Endeavour</b></th>\n    <th><b>Description</b></th> \n    <th><b>Problems</b></th>\n    <th><b>Status</b></th>\n  </tr>\n  <tr>\n    <td><b>Chain Scalability and Throughput</b></td>\n    <td>Blockchain design is constrained by limitations of what data can be stored on-chain.</td>\n    <td>Short-term/Ongoing:<br>- Signature Aggregation<br><br>Medium-term:<br>- Dedicated Nodes for transaction batching<br>- Accumulator-based chain state<br>Long-term:<br>- Snarking the chain</td>\n    <td>Working on/Curious (for long-term)</td>\n  </tr>\n  <tr>\n    <td><b>Blockchain VMs</b></td>\n    <td>Filecoin will integrate smart contract functionality through a Filecoin VM. As we look towards this, we are interested in better models for VM execution in the context of a blockchain.</td>\n    <td>Medium-term:<br>- WASM<br><br>Long-term:<br>- Privacy-supporting smart contracts<br>- Efficient VM execution model</td>\n    <td>Working on/Curious</td>\n  </tr>\n  <tr>\n    <td><b>Other Projects of Interest</b></td>\n    <td>This endeavour regroups other insights or problems we've uncovered as part of our work on Filecoin that is likely relevant to other architects and developers working on blockchain-based systems.</td>\n    <td>Short-term:<br>- Investigating the necessity of block delay for blockchains<br>- Trustless network joining/node bootstrapping<br><br>Medium-term:<br>- Formal treatment of the impact of cryptoeconomics on protocol security<br>- Exploration of transfer freezing for public keys as an alternative to slashing<br>- Off-chain random beacons<br></td>\n    <td>Working on (short-term), Collaboration/RFP (medium-term), Curious (long-term)</td>\n  </tr>\n</table>\n\n\n#### Area: Primitives\n\nFilecoin itself relies on the performance and security of cryptographic primitives. We quickly discuss the main open problems we are thinking about with regards to Filecoin primitives below.\n\n<table style=\"width:100%\">\n  <col width=\"15%\">\n  <col width=\"35%\">\n  <col width=\"40%\">\n  <col width=\"10%\">\n  <tr>\n    <th><b>Endeavour</b></th>\n    <th><b>Description</b></th> \n    <th><b>Problems</b></th>\n    <th><b>Status</b></th>\n  </tr>\n  <tr>\n    <td><b>Proof of Replication (PoRep)/Proof of SpaceTime(PoST)</b></td>\n    <td>Proof-of-Replication is a key component of Filecoin as a storage-based marketplace. PoReps are assembled into Proofs of SpaceTime to ensure that miners are indeed storing client data.</td>\n    <td>Short-term:<br>- Reducing hardware costs for Porep/PoST<br>-<a href=\"open-problems.md#asic-resistant-porep-hash-functions\">ASIC-resistant PoRep hash function</a><br/>- <a href=\"./open-problems.md#post-aggregation\">PoST Aggregation</a><br/><br>Medium-term:<br>- Updateable PoRep<br>- Better PoRep: fast replication & verification, small & fast proof, flexible sector size<br>- <a href=\"./open-problems.md#porep-without-timing-assumptions\">PoRep/PoST without timing assumptions</a><br>- <a href=\"./open-problems.md#vertical-porep-post-proving-system\">Vertical PoRep/PoST proving system</a></td>\n    <td>Working on/Collaboration/RFP</td>\n  </tr>\n  <tr>\n    <td><b>SEALSTACK</b></td>\n    <td>SEALSTACK refers to a specific attack that breaks PoRep by allowing a miner to cheat on space. The Filecoin team has a few candidate mitigations for SEALSTACK but is working to identify the optimal solution.</td>\n    <td>Short-term:<br>- SEALSTACK: Symmetric Proof of replication construction<br>- SEALSTACK: Asymetric PoRep<br><br>Medium-term:<br>- SEALSTACK with fast decode</td>\n    <td>Working on/RFP</td>\n  </tr>\n  <tr>\n    <td><b>SNARKS and other key primitives</b></td>\n    <td>Filecoin relies on SNARKS to aggregate PoSTs (proof compression of data going to the chain). We are looking into improvements in this space as well as alternative primitives we could use.</td>\n    <td>Short-term:<br>- Practical Circuits<br/>- <a href=\"./open-problems.md#faster-snarks-on-gpu-and-off-the-shelf-hardware\">Faster SNARKS on GPU and off-the-shelf hardware</a><br/><br>Medium-term:<br>- <a href=\"./open-problems.md#sector-aggregation\">Sector Aggregation</a> (with aggregation nodes)<br>- ZK-cryptographic compression (with easy set membership verification for random variables)<br>- Succinct file inclusion proofs<br>- <a href=\"./open-problems.md#snark-friendly-accumulators\">SNARK-friendly accumulators</a></td>\n    <td>Collaboration/RFP</td>\n  </tr>\n  <tr>\n    <td><b>VDFs</b></td>\n    <td>One of Filecoin's PoST candidate constructions uses VDFs in order to ensure appropriate delay between various challenges to the miner. Thus, the security of a candidate construction for Filecoin (as well as Filecoin consensus) relies on certain guarantees provided by VDFs. As such, we are interested in advancements in the field, as well as alternative constructions.</td>\n    <td>Short-term:<br>- Fastest Hash/VDF Function<br>- Removing VDFs from Filecoin<br>- Using a hash function that re-uses the same VDF hardware<br>- VDF pools</td>\n    <td>Collaboration/RFP/Curious</td>\n  </tr>\n  <tr>\n    <td><b>Other Primitives of Interest</b></td>\n    <td>Other key primitives would prove highly useful to Filecoin's development. We detail a few here.</td>\n    <td>Medium-term:<br>- Proof of data delivery to assure constrain assured price<br/>- Better Big Number Library<br>- <a href=\"./open-problems.md#weighted-threshold-signatures\">Weighted Threshold Signatures</a><br><br>Long-term:<br>- Proof of Location</td>\n    <td>Collaboration/RFP/Curious</td>\n  </tr>\n</table>\n\n\n\n#### Key Open Problems\n\nWe break down a few open problems of high priority for the team below. Some have open [RFPs](https://github.com/protocol/research-RFPs). For all, we welcome any collaborations (potentially leading to new constructions, discoveries and publications). Please reach out at [filecoin-research@protocol.ai](filecoin-research@protocol.ai). \n\n[See our open problems](./open-problems.md).\n\nYou can also check out slides from talks given about Research Problems in Filecoin:\n- [Filecoin: Open Problems building storage-based consensus](https://drive.google.com/a/protocol.ai/file/d/1TeoRVRTDzMvPfYbty0WZ_V75zIyHinke/view?usp=sharing) given by Henri Stern at EPFL Crypto WinterSchool in February 2019.\n- [Filecoin Research Problems](https://drive.google.com/a/protocol.ai/file/d/16-74tC09jJeMdgXgKukmTHtmyTGHFkI3/view?usp=sharing) given by Nicola Greco at IC3 Winter Retreat in February 2019.\n\n## Contributing\n\nThe purpose of this repo is for Filecoin Research questions to be open to researchers around the world who may be interested in working on them.\n\nIf you want to dive into these topics, please see [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## Community\n\n- Github over Google Docs!\n- Join the [Public Filecoin Slack](https://github.com/filecoin-project/community#chat):\n  - General Filecoin Research: #fil-research\n  - Proofs development: #fil-proofs\n  - General Filecoin: #general\n- Our [Discussion Forum](discuss.filecoin.io)\n\n## Useful docs\n\n- [**Research Notes**](https://github.com/filecoin-project/research/tree/master/research-notes) that have not yet found a home\n- [**Calculators**](https://github.com/filecoin-project/research/tree/master/calculators.md) used to estimate some results ahead of spending cycles on a construction\n- [**Spec/Design docs**](https://github.com/filecoin-project/specs) for the Filecoin protocol\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/research/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/research/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT/)\n", "release_dates": []}, {"name": "retrieval-load-testing", "description": null, "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# retrieval-load-testing\n\n> A simple load tester for booster-http\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Setup](#setup)\n- [Usage](#usage)\n- [Contribute](#contribute)\n- [License](#license)\n\n## Overview\n\nThis is a simple docker setup that uses [K6](k6.io) to run a series of load tests of piece downloading against a booster-http instance.\n\nOptionally, it can also run the same tests against a static file service serving\nthe same pieces as flat files, for comparison purposes\n\n## Setup\n\n### Prequisites\n\nDocker Engine must be installed on the machine running load tests, along with the Docker Compose plugin. See [Docker Engine installation overview](https://docs.docker.com/engine/install/)\n\n### Configuration\n\n#### Piece list\n\nThe load test needs a list of pieces from which to attempt downloads against. Create a file in this directory called `pieces.txt`, and enter the Piece CIDs you want to test against, one per line.\n\n#### (Optional) Data Onboarding Script\n\nIf you don't already have pieces you can test downloads against, `generateDeals.sh` is a utility script you can run on your own SP to generate self-deals of random data quickly, using offline imports to avoid data transfer. To use this\ncommand run:\n\n```\n$ ./generateDeals.sh [number of deals] [folder to store car files] [minerID]\n```\n\nStorage deals are a sensitive process and this script may require additional configuration on your miner\n\n#### Docker .env\n\nThe load test reads configuration from environment variables in the .env file used by `docker compose`.\n\nBefore you run the load test for the first time, you should run:\n\n```\n$ cp .env.example .env\n```\n\nYou will need to edit .env to set at least one of the config options -- the BOOST_FETCH_URL which is the base URL which piece IDs are appended to fetch pieces from Boost\n\n## Load Testing\n\nTo run a load test using the host machine's local k6 runner, run:\n\n```\n$ ./loadtest.sh\n```\n\noptionally, if you'd like to run your load test using the docker image, you can run\n\n```\n$ USE_DOCKER_K6=1 ./loadtest.sh\n```\n\nYour load test will display output as it runs. Once it's complete, you can view\nperformance data in grafana, which will remain running after the load test shuts down.\n\nVisit: `http://localhost:3000/` and navigate to the `k6 performance test` dashboard.\n\nAlternatively, a load test summary JSON file will also be created in the `/out` directory of the project.\n\n## Developing Scripts\n\nDuring development, it might be easier to run scripts without the load testing setup that `loadtest.sh` provides. In this case, you can use the `runscript.sh` command to run any k6 script.\n\nTo run a k6 script, run:\n\n```\n$ ./runscript.sh <absolute-path-of-script-on-container>\n```\n\nThe scripts in the local `./scripts` directory are loaded onto the k6 container in the root directory `/scripts` when the image is started. To run the local script `./scripts/example.js`, the argument would be `/scripts/example.js`. Notice the lack of the period (.) at the start of the path since we're referencing the absolute path to the script on the k6 container.\n\n```\n$ ./runscript.sh /scripts/example.js\n```\n\n## Contribute\n\nEarly days PRs are welcome!\n\n## License\n\nThis library is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2022. Protocol Labs, Inc.\n", "release_dates": []}, {"name": "retrieval-market", "description": "Homepage for the Retrieval Market Working Group", "language": "TypeScript", "license": null, "readme": "# Retrieval.Market\n\nThe Homepage for the community working on the retrieval of data from the content addressable ecosystem (IPFS and Filecoin).\n\n## Usage\n\n- `npm install`\n- `npm run dev`\n\nBuilt with [nextjs], styled with [tailwind]\n\n## Contributing\n\n## Inspiration\n\n- https://arewedistributedyet.com\n- https://identity.foundation\n\n## License\n\nDocuments are [CC-BY-SA 3.0] license \u00a9 2018 Protocol Labs Inc.\nCode is [MIT](./LICENSE) \u00a9 2018 Protocol Labs Inc.\n\n[nextjs]: https://nextjs.org\n[tailwind]: https://tailwindcss.com\n", "release_dates": []}, {"name": "retrieval-market-spec", "description": "Provisional WIP spec for Filecoin Retrieval Market", "language": "Shell", "license": null, "readme": "# retrieval-market-spec\n\n> Specification For Components In A Filecoin Retrieval Market\n\n## Development\n\n```bash\nyarn dev\nyarn build\n```\n\nFor more details, please head VuePress's [documentation](https://v1.vuepress.vuejs.org/).\n\n## Deployment\n\nAny new commits on master pushed to Github will get deployed by Netlify. The rendered site can be found at:\n\nhttps://filecoin-retrieval-spec.netlify.app/\n", "release_dates": []}, {"name": "rhea-load-testing", "description": null, "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# rhea-load-testing\n\n> A simple load tester for booster-http\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Setup](#setup)\n- [Usage](#usage)\n- [Contribute](#contribute)\n- [License](#license)\n\n## Overview\n\nThis is a simple docker setup that uses [K6](k6.io) to run a series of load tests of finding providers and fetching content against the Saturn most common CIDs list:\n- The Kubo HTTP API for finding providers\n- The Network Indexer for finding providers (with DHT fallback)\n- A Lassie Daemon for fetching content\n- A Kubo Gateway URL for fetching content\n\n## Setup\n\n### Prequisites\n\n- Docker Engine must be installed on the machine running load tests, along with the Docker Compose plugin. See [Docker Engine installation overview](https://docs.docker.com/engine/install/)\n- Running Kubo Daemon\n- Running Lassie Daemon\n\n### Configuration\n\n#### Docker .env\n\nThe load test reads configuration from environment variables in the .env file .\n\nBefore you run the load test for the first time, you should run:\n\n```\n$ cp .env.example .env\n```\n\nYou will need to edit .env to set the relevant config options\n\ne.g:\n\n```\nKUBO_API_BASE=http://127.0.0.1:5001\nLASSIE_FETCH_URL=http://127.0.0.1:8888\nKUBO_GATEWAY_URL=http://127.0.0.1:8080\n```\n\nThese values can be determined a few ways. Kubo daemon startup output typically looks like this:\n\n```\nInitializing daemon...\nKubo version: 0.17.0\nRepo version: 12\nSystem version: arm64/darwin\nGolang version: go1.19.1\nSwarm listening on /ip4/10.0.0.8/tcp/4001\nSwarm listening on /ip4/10.0.0.8/udp/4001/quic\nSwarm listening on /ip4/127.0.0.1/tcp/4001\nSwarm listening on /ip4/127.0.0.1/udp/4001/quic\nSwarm listening on /ip6/::1/tcp/4001\nSwarm listening on /ip6/::1/udp/4001/quic\nSwarm listening on /p2p-circuit\nSwarm announcing /ip4/10.0.0.8/tcp/4001\nSwarm announcing /ip4/10.0.0.8/udp/4001/quic\nSwarm announcing /ip4/127.0.0.1/tcp/4001\nSwarm announcing /ip4/127.0.0.1/udp/4001/quic\nSwarm announcing /ip6/::1/tcp/4001\nSwarm announcing /ip6/::1/udp/4001/quic\nAPI server listening on /ip4/127.0.0.1/tcp/5001\nWebUI: http://127.0.0.1:5001/webui\nGateway (readonly) server listening on /ip4/127.0.0.1/tcp/8080\nDaemon is ready\n```\n\nThe relevant lines to pull from are `API Server Listening on ...` for KUBO_API_BASE and `Gateway (readonly) server listening on ...` for KUBO_GATEWAY_URL\n\nFor lassie, start the API daemon with `-p` and use the values you used for port at startup.\n\n## Load Testing\n\nTo run a load test using the host machine's local k6 runner, run:\n\n```\n$ ./loadtest.sh\n```\n\nYour load test will display output as it runs. Once it's complete, you can view\nperformance data in grafana, which will remain running after the load test shuts down.\n\nAlternatively, a load test summary CSV file will also be created in the `/results` directory of the project.\n\n## Contribute\n\nEarly days PRs are welcome!\n\n## License\n\nThis library is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2022. Protocol Labs, Inc.\n", "release_dates": []}, {"name": "roadmap", "description": "Filecoin Community Roadmap", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Filecoin Community Roadmap\n\nThis repo is designed as a collaborative space to create, track, and update a community roadmap for the Filecoin project.\n\n## About the Roadmap\n\nThis is a high-level roadmap (at zoom levels 3 and 4):\n<img width=\"1184\" alt=\"CleanShot 2023-09-27 at 01 31 23@2x\" src=\"https://github.com/filecoin-project/roadmap/assets/618519/fe86814d-43aa-41b7-930b-0d0f34672722\">\n\nIt includes top-level milestones across many aspects of the Filecoin protocol, tooling ecosystem, and network capabilities - focused on how they benefit and unlock notable added capabilities of Filecoin.\n\nIt is generated by creating different github issues (across multiple projects/repos) for each major milestone, improvement category, and roadmap \"root\" - and visualizing them via starmap.site/<roadmap root url> (ex https://github.com/filecoin-project/roadmap/issues/1)\n\n## About Starmap\n\nYou can learn more about how to create a new Starmap at https://starmap.site/. We are using the new tasklist syntax.\n\nYou can see some reference starmaps at:\n- https://github.com/filecoin-project/roadmap/issues/1\n- https://starmap.site/roadmap/github.com/filecoin-station/roadmap/issues/1#view=list\n- https://starmap.site/roadmap/github.com/protocol/engres/issues/9#view=detail\n\n", "release_dates": []}, {"name": "rust-fil-ffi-toolkit", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Rust Filecoin FFI Toolkit\n\n> A collection of tools useful for working with the Rust Filecoin FFI.\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "rust-fil-logger", "description": "A logging library used by Filecoin", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# A logging library used by Filecoin\n\nThis crate is used to make sure that all Filecoin related crates log in the same format.\n\nBy default the `fil_logger` doesn't log anything. You can change this by setting the `RUST_LOG`\nenvironment variable to another level. This will show log output on stderr. Example:\n\n```console\n$ RUST_LOG=info cargo run --example simple\n    Finished dev [unoptimized + debuginfo] target(s) in 0.02s\n     Running `target/debug/examples/simple`\n2019-11-11T20:26:09.448 INFO simple > logging on into level\n2019-11-11T20:26:09.448 WARN simple > logging on warn level\n2019-11-11T20:26:09.448 ERROR simple > logging on error level\n```\n\nIt is also possible to ouput the log as JSON. Simply set the `GOLOG_LOG_FMT` environment variable\nto `json`. It is a bit more verbose and also contains the line file and line number of the log\ncall:\n\n```console\n$ GOLOG_LOG_FMT=json RUST_LOG=info cargo run --example simple\n    Finished dev [unoptimized + debuginfo] target(s) in 0.03s\n     Running `target/debug/examples/simple`\n{\"level\":\"info\",\"ts\":\"2019-11-11T20:59:31.168+0100\",\"logger\":\"simple\",\"caller\":\"examples/simple.rs:30\",\"msg\":\"logging on into level\"}\n{\"level\":\"warn\",\"ts\":\"2019-11-11T20:59:31.168+0100\",\"logger\":\"simple\",\"caller\":\"examples/simple.rs:31\",\"msg\":\"logging on warn level\"}\n{\"level\":\"error\",\"ts\":\"2019-11-11T20:59:31.168+0100\",\"logger\":\"simple\",\"caller\":\"examples/simple.rs:32\",\"msg\":\"logging on error level\"}\n```\n\n## Example\n\n```rust\nuse fil_logger;\nuse log::{debug, error, info, trace, warn};\n\nfn main() {\n    fil_logger::init();\n\n    trace!(\"logging on trace level\");\n    debug!(\"logging on debug level\");\n    info!(\"logging on into level\");\n    warn!(\"logging on warn level\");\n    error!(\"logging on error level\");\n}\n```\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "rust-fil-nse-gpu", "description": "Rust interface to GPU implementation of Filecoin's Narrow Stacked Expander (NSE) sealing algorithm", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# rust-fil-nse-gpu [![Crates.io](https://img.shields.io/crates/v/rust-fil-nse-gpu.svg)](https://crates.io/crates/rust-fil-nse-gpu)\n\nRust interface to GPU implementation of Filecoin's Narrow Stacked Expander (NSE) sealing algorithm.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "rust-fil-proofs", "description": "Proofs for Filecoin in Rust", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin Proving Subsystem\n\nThe **Filecoin Proving Subsystem** (or FPS) provides the storage proofs required by the Filecoin protocol. It is implemented entirely in Rust, as a series of partially inter-dependent crates \u2013 some of which export C bindings to the supported API.\n\nThere are currently several different crates:\n\n- [**Storage Proofs Core (`storage-proofs-core`)**](./storage-proofs-core)\n    A set of common primitives used throughout the other storage-proofs sub-crates, including crypto, merkle tree, hashing and gadget interfaces.\n\n- [**Storage Proofs PoRep (`storage-proofs-porep`)**](./storage-proofs-porep)\n    `storage-proofs-porep` is intended to serve as a reference implementation for _**Proof-of-Replication**_ (**PoRep**), while also performing the heavy lifting for `filecoin-proofs`.\n\n    Primary Components:\n     -   **PoR** (**_Proof-of-Retrievability_**: Merkle inclusion proof)\n     -   **DrgPoRep** (_Depth Robust Graph_ **_Proof-of-Replication_**)\n     -   **StackedDrgPoRep**\n\n- [**Storage Proofs PoSt (`storage-proofs-post`)**](./storage-proofs-post)\n    `storage-proofs-post` is intended to serve as a reference implementation for _**Proof-of-Space-time**_ (**PoSt**), for `filecoin-proofs`.\n\n    Primary Components:\n     -   **PoSt** (Proof-of-Spacetime)\n\n\n- [**Filecoin Proofs (`filecoin-proofs`)**](./filecoin-proofs)\n    Filecoin-specific values of setup parameters are included here. The API is wrapped in [`rust-filecoin-proofs-api`](https://github.com/filecoin-project/rust-filecoin-proofs-api), which then is the basis for the FFI-exported API in [`filecoin-ffi`](https://github.com/filecoin-project/filecoin-ffi) callable from C (and in practice called by [lotus](https://github.com/filecoin-project/lotus) via cgo).\n\nThe dependencies between those crates look like this:\n\n```\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                             filecoin-proofs                        \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n             \u2502                            \u2502              \u2502             \u2502\n             \u2502                            \u2502              \u2502             \u2502\n             \u2502                            \u2502              \u2502             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 storage-proofs-update \u251c\u2500\u2500\u2500\u2500\u2500\u25b6 storage-proofs-porep \u2502   \u2502   \u2502 storage-proofs-post \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                            \u2502              \u2502             \u2502\n             \u2502                            \u2502              \u2502             \u2502\n             \u2502                            \u2502              \u2502             \u2502\n       \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n       \u2502                           storage-proofs-core                      \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThings shared between crates, should go into `storage-proofs-core`. An exception is the `storage-proofs-update`, which needs the needs the stacked DRG from `storage-proofs-porep`. All crates are free to use other crates for the workspace like [`filecoin-hashers`](./filecoin-hashers) or [`fr32`](./fr32).\n\n## Security Audits\n\nThe `rust-fil-proofs` proofs code and the [Filecoin Spec](https://spec.filecoin.io/algorithms/sdr/) has undergone a [proofs security audit](audits/Sigma-Prime-Protocol-Labs-Filecoin-Proofs-Security-Review-v2.1.pdf) performed by [Sigma Prime](https://sigmaprime.io/) and been deemed free of *critical* or *major* security issues.  In addition to the security review, the document provides the summary of findings, vulnerability classifications, and recommended resolutions.  All known issues have been resolved to date in both the code and the specification.\n\n`rust-fil-proofs` has also undergone a [SNARK proofs security audit performed by Dr. Jean-Philippe Aumasson and Antony Vennard](audits/protocolai-audit-20200728.pdf) and been deemed free of *critical* or *major* security issues.  In addition to the security analysis, the document provides the audit goals, methodology, functionality descriptions and finally observations on what could be improved.  All known issues have been resolved to date.\n\n## Design Notes\n\nEarlier in the design process, we considered implementing what has become the **FPS** in Go \u2013 as a wrapper around potentially multiple SNARK circuit libraries. We eventually decided to use [bellman](https://github.com/zkcrypto/bellman) \u2013 a library developed by Zcash, which supports efficient pedersen hashing inside of SNARKs. Having made that decision, it was natural and efficient to implement the entire subsystem in Rust. We considered the benefits (self-contained codebase, ability to rely on static typing across layers) and costs (developer ramp-up, sometimes unwieldiness of borrow-checker) as part of that larger decision and determined that the overall project benefits (in particular ability to build on Zcash\u2019s work) outweighed the costs.\n\nWe also considered whether the **FPS** should be implemented as a standalone binary accessed from Filecoin nodes either as a single-invocation CLI or as a long-running daemon process. Bundling the **FPS** as an FFI dependency was chosen for both the simplicity of having a Filecoin node deliverable as a single monolithic binary, and for the (perceived) relative development simplicity of the API implementation.\n\nIf at any point it were to become clear that the FFI approach is irredeemably problematic, the option of moving to a standalone **FPS** remains. However, the majority of technical problems associated with calling from Go into Rust are now solved, even while allowing for a high degree of runtime configurability. Therefore, continuing down the same path we have already invested in, and have begun to reap rewards from, seems likely.\n\n## Install and configure Rust\n\n**NOTE:** If you have installed `rust-fil-proofs` incidentally, as a submodule of `lotus`, then you may already have installed Rust.\n\nThe instructions below assume you have independently installed `rust-fil-proofs` in order to test, develop, or experiment with it.\n\n[Install Rust using rustup.](https://www.rust-lang.org/en-US/install.html)\n\n## Build\n\n**NOTE:** `rust-fil-proofs` can only be built for and run on 64-bit platforms; building will panic if the target architecture is not 64-bits.\n\nBefore building you will need OpenCL to be installed. On Ubuntu, this can be achieved with `apt install ocl-icd-opencl-dev`.  Other system dependencies such as 'gcc/clang', 'wall' and 'cmake' are also required.\n\nFor the `multicore sdr` feature (enabled by default), you will also need to install the `hwloc` library. On Ubuntu, this can be achieved with `apt install hwloc libhwloc-dev`. For other platforms, please see the [hwloc-rs Prerequisites section](https://github.com/daschl/hwloc-rs).\n\n\n```\n> cargo build --release --all\n```\n\nThe `hwloc` dependency is optional and may be disabled.  Disabling it will not allow the `multicore sdr` feature to be used.  The fallback is single core replication, which is the default unless specified otherwise.\n\nTo disable `multicore sdr` so that `hwloc` is not required, you can build proofs like this:\n\n```\n> cargo build --release --all --no-default-features --features opencl\n```\n\nNote that the `multicore-sdr` feature is omitted from the specified feature list, which removes it from being used by default.\n\nThere is experimental support for CUDA behind the `cuda` feature (disabled by default). You will need to install `nvcc`.  On Ubuntu, this can be achieved with `apt install nvidia-cuda-toolkit`.  To enable CUDA support, you can build proofs like this:\n\n```\n> cargo build --release --all --features cuda\n```\n\nIt now builds it with both, CUDA and OpenCL support, CUDA will then be preferred at runtime, but can be disabled with the `FIL_PROOFS_GPU_FRAMEWORK` environment variable (see more information in the `GPU usage` section below).\n\n\n## Building for Arm64\n\nIn order to build for arm64 the current requirements are\n\n- nightly rust compiler\n\nExample for building `filecoin-proofs`\n\n```\n$ rustup +nightly target add aarch64-unknown-linux-gnu\n$ cargo +nightly build -p filecoin-proofs --release --target aarch64-unknown-linux-gnu\n```\n\n## Test\n\n```\n> cargo test --all\n```\n\n## Benchmarks\n\nThe main benchmarking tool is called `benchy`.  `benchy` has several subcommands, including `merkleproofs`, `prodbench`, `winning_post`, `window_post` and `window_post_fake` (uses fake sealing for faster benching).  Note that `winning_post` now has a `--fake` option for also running fake sealing for faster benching.  You can run them with various configuration options, but some examples are below:\n\n```\n> cargo run --release --bin benchy -- merkleproofs --size 2KiB\n> cargo run --release --bin benchy -- winning-post --size 2KiB\n> cargo run --release --bin benchy -- winning-post --size 2KiB --fake\n> cargo run --release --bin benchy -- window-post --size 2KiB\n> cargo run --release --bin benchy -- window-post-fake --size 2KiB --fake\n> cargo run --release --bin benchy -- prodbench\n# After a preserved cache is generated, this command tests *only* synthetic proof generation\n> cargo run --release --bin benchy -- porep --size 2KiB --synthetic --cache /d1/nemo/tmp/cache-2k --skip-precommit-phase1 --skip-precommit-phase2 --skip-commit-phase1 --skip-commit-phase2\n```\n\n### Window PoSt Bench usages\n\nThe Window PoSt bench can be used a number of ways, some of which are detailed here.\n\nFirst, you can run the benchmark and preserve the working directory like this:\n```\ncargo run --release --bin benchy -- window-post --size 2KiB --cache window-post-2KiB-dir --preserve-cache\n```\n\nThen if you want to run the benchmark again to test commit-phase2, you can quickly run it like this:\n```\ncargo run --release --bin benchy -- window-post --size 2KiB --skip-precommit-phase1 --skip-precommit-phase2 --skip-commit-phase1 --cache window-post-2KiB-dir\n```\n\nAlternatively, if you want to test just GPU tree building, you can run it like this:\n```\ncargo run --release --bin benchy -- window-post --size 2KiB --skip-precommit-phase1 --skip-commit-phase1 --skip-commit-phase2 --cache window-post-2KiB-dir\n```\n\nNote that some combinations of arguments will cause destructive changes to your cached directory.  For larger benchmark sector sizes, it is recommended that once you create an initial cache, that it be saved to an alternate location in the case that it is corrupted by a test run.  For example, the following run sequence will be guaranteed to corrupt your cache:\n\n```\n# Do NOT run this sequence.  For illustrative purposes only:\n# Generate clean cache\ncargo run --release --bin benchy -- window-post --size 2KiB --cache window-post-2KiB-dir --preserve-cache\n# Skip all stages except the first\ncargo run --release --bin benchy -- window-post --size 2KiB --skip-precommit-phase2 --skip-commit-phase1 --skip-commit-phase2 --cache broken-cache-dir\n```\n\nThe reason this fails is because new random piece data is generated (rather than loaded from disk from a previous run) in the first step, and then we attempt to use it in later sealing steps using data from previously preserved run.  This cannot work.\n\nThere is also a bench called `gpu-cpu-test`:\n\n```\n> cargo run --release --bin gpu-cpu-test\n```\n\nSome results are displayed at the command line, or alternatively written as JSON files.  Logging can be enabled using the `RUST_LOG=trace` option (see more Logging options in the `Logging` section below).\n\nNote: On macOS you need `gtime` (`brew install gnu-time`), as the built in `time` command is not enough.\n\n## Logging\n\nFor better logging with backtraces on errors, developers should use `expects` rather than `expect` on `Result<T, E>` and `Option<T>`.\n\nThe crate use [`log`](https://crates.io/crates/log) for logging, which by default does not log at all. In order to log output crates like [`fil_logger`](https://crates.io/crates/fil_logger) can be used.\n\nFor example\n\n```rust\nfn main() {\n    fil_logger::init();\n}\n```\n\nand then when running the code setting\n\n```sh\n> RUST_LOG=filecoin_proofs=info\n```\n\nwill enable all logging.\n\nFor advanced/verbose/debug logging, you can use the code setting\n\n```sh\n> RUST_LOG=trace\n```\n\n## Settings\n\nFurther down in this README, various settings are described that can be adjusted by the end-user.  These settings are summarized in `rust-fil-proofs.config.toml.sample` and this configuration file can be used directly if copied to `./rust-fil-proofs.config.toml`.  Alternatively, each setting can be set by using environment variables of the form \"FIL_PROOFS_<setting name here>\", in all caps.  For example, to set `rows_to_discard` to the value 2, you would set `FIL_PROOFS_ROWS_TO_DISCARD=2` in your environment.\n\nAny configuration setting that is not specified has a reasonable default already chosen.\n\nTo verify current environment settings, you can run:\n\n```\ncargo run --bin settings\n```\n\n## Parameter File Location\n\nFilecoin proof parameter files are expected to be located in `/var/tmp/filecoin-proof-parameters`.  If they are located in an alternate location, you can point the system to that location using an environment variable\n\n```\nFIL_PROOFS_PARAMETER_CACHE=/path/to/parameters\n```\n\nIf you are running a node that is expected to be using production parameters (i.e. the ones specified in the parameters.json file within this repo), you can optionally verify your on-disk parameters using an environment variable\n\n```\nFIL_PROOFS_VERIFY_PRODUCTION_PARAMS=1\n```\n\nBy default, this verification is disabled.\n\n## Optimizing for either speed or memory during replication\n\nWhile replicating and generating the Merkle Trees (MT) for the proof at the same time there will always be a time-memory trade-off to consider, we present here strategies to optimize one at the cost of the other.\n\n### Speed\n\nOne of the most computationally expensive operations during replication (besides the encoding itself) is the generation of the indexes of the (expansion) parents in the Stacked graph, implemented through a Feistel cipher (used as a pseudorandom permutation). To reduce that time we provide a caching mechanism to generate them only once and reuse them throughout replication (across the different layers).\n\n```\nFIL_PROOFS_SDR_PARENTS_CACHE_SIZE=2048\n```\n\nThis value is defaulted to 2048 nodes, which is the equivalent of 112KiB of resident memory (where each cached node consists of DEGREE (base + exp = 6 + 8) x 4 byte elements = 56 bytes in length).  Given that the cache is now located on disk, it is memory mapped when accessed in window sizes related to this variable.  This default was chosen to minimize memory while still allowing efficient access to the cache.  If you would like to experiment with alternate sizes, you can modify the environment variable\n\nIncreasing this value will increase the amount of resident RAM used.\n\nLastly, the parent's cache data is located on disk by default in `/var/tmp/filecoin-parents`.  To modify this location, use the environment variable\n\n```\nFIL_PROOFS_PARENT_CACHE=/path/to/parent/cache\n```\n\nUsing the above, the cache data would be located at `/path/to/parent/cache/filecoin-parents`.\n\nAlternatively, use `FIL_PROOFS_CACHE_DIR=/path/to/parent/cache`, in which the parent cache will be located in `$FIL_PROOFS_CACHE_DIR/filecoin-parents`.  Note that if you're using `FIL_PROOFS_CACHE_DIR`, it must be set through the environment and cannot be set using the configuration file.  This setting has no effect if `FIL_PROOFS_PARENT_CACHE` is also specified.\n\nIf you are concerned about the integrity of your on-disk parent cache files, they can be verified at runtime when accessed for the first time using an environment variable\n\n```\nFIL_PROOFS_VERIFY_CACHE=1\n```\n\nIf they are inconsistent (compared to the manifest in storage-proofs/porep/parent-cache.json), they will be automatically re-generated at runtime.  If that cache generation fails, it will be reported as an error.\n\n```\nFIL_PROOFS_USE_MULTICORE_SDR\n```\n\nWhen performing SDR replication (Precommit Phase 1) using only a single core, memory access to fetch a node's parents is\na bottleneck. Multicore SDR uses multiple cores (which should be restricted to a single core complex for shared cache) to\nassemble each nodes parents and perform some prehashing. This setting is not enabled by default but can be activated by\nsetting `FIL_PROOFS_USE_MULTICORE_SDR=1`.\n\nBest performance will also be achieved when it is possible to lock pages which have been memory-mapped. This can be\naccomplished by running the process as a non-root user, and increasing the system limit for max locked memory with `ulimit\n-l`. Alternatively, the process can be run as root, if its total locked pages will fit inside physical memory. Otherwise, the OOM-killer may be invoked. Two sector size's worth of data (for current and previous layers) must be locked -- along with 56 *\n`FIL_PROOFS_PARENT_CACHE_SIZE` bytes for the parent cache.\n\nDefault parameters have been tuned to provide good performance on the AMD Ryzen Threadripper 3970x. It may be useful to\nexperiment with these, especially on different hardware. We have made an effort to use sensible heuristics and to ensure\nreasonable behavior for a range of configurations and hardware, but actual performance or behavior of multicore\nreplication is not yet well tested except on our target. The following settings may be useful, but do expect some\nfailure in the search for good parameters. This might take the form of failed replication (bad proofs), errors during\nreplication, or even potentially crashes if parameters prove pathological. For now, this is an experimental feature, and\nonly the default configuration on default hardware (3970x) is known to work well.\n\n`FIL_PROOFS_MULTICORE_SDR_PRODUCERS`: This is the number of worker threads loading node parents in parallel. The default is `3` so the producers and main thread together use a full core complex (but no more).\n`FIL_PROOFS_MULTICORE_SDR_PRODUCER_STRIDE`: This is the (max) number of nodes for which a producer thread will load parents in each iteration of its loop. The default is`128`.\n`FIL_PROOFS_MULTICORE_SDR_LOOKAHEAD`: This is the size of the lookahead buffer into which node parents are pre-loaded by the producer threads. The default is 800.\n\n### GPU Usage\n\nThe column hashed tree 'tree_c' can optionally be built using the GPU with noticeable speed-up over the CPU.  To activate the GPU for this, use the environment variable\n\n```\nFIL_PROOFS_USE_GPU_COLUMN_BUILDER=1\n```\n\nSimilarly, the 'tree_r_last' tree can also be built using the GPU, which provides at least a 2x speed-up over the CPU.  To activate the GPU for this, use the environment variable\n\n```\nFIL_PROOFS_USE_GPU_TREE_BUILDER=1\n```\n\nNote that *both* of these GPU options can and should be enabled if a supported GPU is available.\n\n### Advanced GPU Usage\n\nWhen using the GPU to build 'tree_r_last' (using `FIL_PROOFS_USE_GPU_TREE_BUILDER=1`), an experimental variable can be tested for local optimization of your hardware.\n\n```\nFIL_PROOFS_MAX_GPU_TREE_BATCH_SIZE=Z\n```\n\nThe default batch size value is 700,000 tree nodes.\n\nWhen using the GPU to build 'tree_c' (using `FIL_PROOFS_USE_GPU_COLUMN_BUILDER=1`), two experimental variables can be tested for local optimization of your hardware.  First, you can set\n\n```\nFIL_PROOFS_MAX_GPU_COLUMN_BATCH_SIZE=X\n```\n\nThe default value for this is 400,000, which means that we compile 400,000 columns at once and pass them in batches to the GPU.  Each column is a \"single node x the number of layers\" (e.g. a 32GiB sector has 11 layers, so each column consists of 11 nodes).  This value is used as both a reasonable default, but it's also measured that it takes about as much time to compile this size batch as it does for the GPU to consume it (using the 2080ti for testing), which we do in parallel for maximized throughput.  Changing this value may exhaust GPU RAM if set too large, or may decrease performance if set too low.  This setting is made available for your experimentation during this step.\n\nThe second variable that may affect overall 'tree_c' performance is the size of the parallel write buffers when storing the tree data returned from the GPU.  This value is set to a reasonable default of 262,144, but you may adjust it as needed if an individual performance benefit can be achieved.  To adjust this value, use the environment variable\n\n```\nFIL_PROOFS_COLUMN_WRITE_BATCH_SIZE=Y\n```\n\nNote that this value affects the degree of parallelism used when persisting the column tree to disk, and may exhaust system file descriptors if the limit is not adjusted appropriately (e.g. using `ulimit -n`).  If persisting the tree is failing due to a 'bad file descriptor' error, try adjusting this value to something larger (e.g. 524288, or 1048576).  Increasing this value processes larger chunks at once, which results in larger (but fewer) disk writes in parallel.\n\nWhen the library is built with both CUDA and OpenCL support, you can choose which one to use at run time.  Use the environment variable:\n\n```\nFIL_PROOFS_GPU_FRAMEWORK=cuda\n```\n\nYou can set it to `opencl` to use OpenCL instead.  The default value is `cuda`, when you set nothing or any other (invalid) value.\n\nCUDA kernels are compiled and build time.  By default, they are built for recent architectures, Turing (`sm_75` and Ampere (`sm_80`, `sm_86`).  This increases the overall build time by several minutes.  You can reduce it by compiling it only for the specific architecture you need.  For example if you only need the CUDA kernels to work on the Turing architecture, you can set on all dependencies that use CUDA kernels:\n\n```\nBELLMAN_CUDA_NVCC_ARGS=\"--fatbin --gpu-architecture=sm_75 --generate-code=arch=compute_75,code=sm_75\"\nNEPTUNE_CUDA_NVCC_ARGS=\"--fatbin --gpu-architecture=sm_75 --generate-code=arch=compute_75,code=sm_75\"\n```\n\n### Memory\n\nAt the moment the default configuration is set to reduce memory consumption as much as possible so there's not much to do from the user side. We are now storing Merkle trees on disk, which were the main source of memory consumption.  You should expect a maximum RSS between 1-2 sector sizes, if you experience peaks beyond that range please report an issue (you can check the max RSS with the `/usr/bin/time -v` command).\n\n### Advanced Storage Tuning\n\nWith respect to the 'tree_r_last' cached Merkle Trees persisted on disk, a value is exposed for tuning the amount of storage space required.  Cached merkle trees are like normal merkle trees, except we discard some number of rows above the base level.  There is a trade-off in discarding too much data, which may result in rebuilding almost the entire tree when it's needed.  The other extreme is discarding too few rows, which results in higher utilization of disk space.  The default value is chosen to carefully balance this trade-off, but you may tune it as needed for your local hardware configuration.  To adjust this value, use the environment variable\n\n```\nFIL_PROOFS_ROWS_TO_DISCARD=N\n```\n\nNote that if you modify this value and seal sectors using it, it CANNOT be modified without updating all previously sealed sectors (or alternatively, discarding all previously sealed sectors).  A tool is provided for this conversion, but it's considered an expensive operation and should be carefully planned and completed before restarting any nodes with the new setting.  The reason for this is because all 'tree_r_last' trees must be rebuilt from the sealed replica file(s) with the new target value of FIL_PROOFS_ROWS_TO_DISCARD in order to make sure that the system is consistent.\n\nAdjusting this setting is NOT recommended unless you understand the implications of modification.\n\n## Generate Documentation\n\nFirst, navigate to the `rust-fil-proofs` directory.\n\n- If you cloned `rust-fil-proofs` manually, it will be wherever you cloned it:\n\n```\n> git clone https://github.com/filecoin-project/rust-fil-proofs.git\n> cd rust-fil-proofs\n```\n\nFor documentation corresponding to the latest source, you should clone `rust-fil-proofs` yourself.\n\nNow, generate the documentation:\n\n```\n> cargo doc --all --no-deps\n```\n\nView the docs by pointing your browser at: `\u2026/rust-fil-proofs/target/doc/proofs/index.html`.\n\n---\n\n## API Reference\n\nThe **FPS** is accessed from [**lotus**](https://github.com/filecoin-project/lotus) via FFI calls to its API, which is the union of the APIs of its constituents:\n\n The source of truth defining the **FPS** APIs is a separate repository of Rust source code. View the source directly:\n\n- [**filecoin-proofs-api**](https://github.com/filecoin-project/rust-filecoin-proofs-api)\n\nThe above referenced repository contains the consumer facing API and it provides a versioned wrapper around the `rust-fil-proofs` repository's internal APIs.  End users should not be using the internal APIs of `rust-fil-proofs` directly, as they are subject to change outside of the formal API provided.\n\nTo generate the API documentation locally, follow the instructions to generate documentation above. Then navigate to:\n- **Filecoin Proofs API:** `\u2026/rust-filecoin-proofs-api/target/doc/filecoin_proofs_api/index.html`\n\n- [Go implementation of filecoin-proofs sectorbuilder API](https://github.com/filecoin-project/go-sectorbuilder/blob/master/sectorbuilder.go) and [associated interface structures](https://github.com/filecoin-project/go-sectorbuilder/blob/master/interface.go).\n\n\n## Contributing\n\nSee [Contributing](CONTRIBUTING.md)\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": ["2019-12-04T18:28:44Z", "2019-12-03T14:13:43Z", "2019-12-03T21:14:10Z", "2019-12-02T21:22:37Z", "2019-12-02T22:56:24Z", "2019-12-01T22:22:26Z", "2019-11-27T17:25:07Z", "2019-11-27T21:30:59Z", "2019-11-27T18:17:27Z", "2019-11-26T22:18:51Z", "2019-11-26T19:44:02Z", "2019-11-24T15:27:36Z", "2019-11-20T02:31:35Z", "2019-11-20T21:19:04Z", "2019-11-20T17:51:47Z", "2019-11-19T20:36:58Z", "2019-11-19T01:44:17Z", "2019-11-19T19:43:43Z", "2019-11-15T23:07:02Z", "2019-11-14T19:48:44Z", "2019-11-08T10:46:49Z", "2019-11-08T13:32:30Z", "2019-11-08T13:34:20Z", "2019-11-08T15:48:02Z", "2019-11-06T11:28:16Z", "2019-11-05T23:21:57Z", "2019-11-04T17:24:34Z", "2019-11-02T17:42:56Z", "2019-11-01T17:17:01Z", "2019-10-31T20:52:57Z"]}, {"name": "rust-fil-proofs-ffi", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# DEPRECATED\n\nThis repo is no longer supported. Please consider using\n[filecoin-ffi](https://github.com/filecoin-project/filecoin-ffi) instead.\n\n## License\n\nMIT or Apache 2.0\n", "release_dates": ["2019-11-30T20:50:19Z", "2019-11-22T18:58:28Z", "2019-11-20T22:02:03Z", "2019-11-20T03:23:26Z", "2019-11-19T20:11:01Z", "2019-11-19T18:10:09Z", "2019-11-05T22:49:31Z", "2019-11-04T22:27:42Z", "2019-11-02T18:14:16Z", "2019-10-24T17:53:36Z", "2019-10-23T15:17:10Z", "2019-10-21T16:26:56Z", "2019-10-17T17:31:48Z", "2019-10-11T17:34:07Z", "2019-10-11T17:40:41Z", "2019-10-08T23:17:33Z", "2019-09-27T22:58:58Z", "2019-09-19T17:28:02Z", "2019-08-30T22:37:59Z", "2019-08-28T16:00:41Z", "2019-08-22T23:08:43Z", "2019-08-22T23:14:48Z", "2019-08-22T21:36:49Z", "2019-08-22T21:29:59Z", "2019-08-17T00:12:40Z", "2019-08-16T23:43:00Z", "2019-08-14T16:21:58Z", "2019-08-13T21:33:42Z", "2019-08-13T20:29:40Z", "2019-07-29T13:17:53Z"]}, {"name": "rust-fil-secp256k1", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Secp256k1 Library\n\n[![CircleCI][circleci-shield]][circleci] [![License][license-shield]][license]\n\n> Library for secp256k1, with a FFI definitions.\n\n## Development\n\n### Tests\n\n```\n> cargo test\n```\n\n\n\n## LICENSE\n\nMIT or Apache 2.0\n\n## Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in rust-accumulators by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n\n[circleci-shield]: https://img.shields.io/circleci/project/github/filecoin-project/rust-fil-secp256k1.svg?style=flat-square\n[circleci]: https://circleci.com/gh/filecoin-project/rust-fil-secp256k1\n[license-shield]: https://img.shields.io/badge/License-MIT%2FApache2.0-green.svg?style=flat-square\n[license]: https://github.com//filecoin-project/rust-fil-secp256k1/blob/master/README.md#LICENSE\n[crate-shield]: https://img.shields.io/crates/v/accumulators.svg?style=flat-square\n[crate]: https://crates.io/crates/accumulators\n", "release_dates": []}, {"name": "rust-fil-sector-builder", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# DEPRECATED\n\nThis repo is no longer supported. Please consider using\n[filecoin-ffi](https://github.com/filecoin-project/filecoin-ffi) instead.\n\n## Contributing\n\nSee [Contributing](CONTRIBUTING.md)\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": ["2019-11-30T20:50:15Z", "2019-11-22T21:13:36Z", "2019-11-20T04:24:30Z", "2019-11-20T23:22:21Z", "2019-11-20T21:06:44Z", "2019-11-19T20:39:10Z", "2019-11-19T14:50:16Z", "2019-11-14T02:49:43Z", "2019-11-11T19:26:03Z", "2019-11-10T13:41:39Z", "2019-11-08T20:24:00Z", "2019-11-06T20:51:10Z", "2019-11-06T01:43:28Z", "2019-11-05T01:23:21Z", "2019-11-05T23:34:11Z", "2019-11-02T18:52:55Z", "2019-10-31T20:17:52Z", "2019-10-31T22:53:16Z", "2019-10-30T22:11:51Z", "2019-10-29T22:37:41Z", "2019-10-25T22:34:26Z", "2019-10-22T21:09:27Z", "2019-10-21T23:31:16Z", "2019-10-21T20:12:47Z", "2019-10-17T17:56:35Z", "2019-10-16T01:30:42Z", "2019-10-16T16:58:53Z", "2019-10-08T22:25:37Z", "2019-09-20T18:53:46Z", "2019-09-20T20:37:31Z"]}, {"name": "rust-filbase", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filbase\n\n[![CircleCI][circleci-shield]][circleci] [![License][license-shield]][license]\n\n> Filecoin proofs & sector management in a convenient package.\n\n\n**Warning**: Requires a _new_ rust nightly.\n\n\n## Building\n\n```sh\n> cargo build --release\n```\n\nIn case you have errors during the build try to update your nightly version:\n\n```sh\nrustup update && rustup toolchain install nightly && cargo build --release\n```\n\n## Usage\n\n```sh\n# Start the daemon\n> filbase daemon\n\n# In another terminal\n> filbase sector size\n  1024\n```\n\n## Benchmarks\n\nIn order to use this tool to run benchmarks, it needs to be compiled with the `benchy` feature.\n\n```sh\n> cargo build --release --features benchy\n> ./target/release/filbase benchy --help\n```\n\n\n## Testing\n\n```sh\n> cargo test\n```\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\n\n[circleci-shield]: https://img.shields.io/circleci/project/github/filecoin-project/rust-filbase.svg?style=flat-square\n[circleci]: https://circleci.com/gh/filecoin-project/rust-filbase\n[license-shield]: https://img.shields.io/badge/License-MIT%2FApache2.0-green.svg?style=flat-square\n[license]: https://github.com/dignifiedquire/rust-accumulators/blob/master/LICENSE.md\n", "release_dates": []}, {"name": "rust-filecoin-proofs-api", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin Proofs API\n\nThis library is meant to be the official public API into the proofs library.\n\n[![CircleCI](https://circleci.com/gh/filecoin-project/rust-filecoin-proofs-api/tree/master.svg?style=svg)](https://circleci.com/gh/filecoin-project/rust-filecoin-proofs-api/tree/master)\n\n> The main API to interact with the proofs system in [Filecoin](https://filecoin.io).\n\n## Default build options\n\nThe build options enabled by default are `cuda` and `opencl`.\n\n## Running the tests\n\nRunning the tests with the default features can be done like this:\n\n```\ncargo test --release --all\n```\n\nRunning with the `opencl` feature only can be done like this:\n\n```\ncargo test --no-default-features --features opencl --release --all\n```\n\n## License\n\nMIT or Apache 2.0\n", "release_dates": []}, {"name": "rust-gpu-tools", "description": "Rust tools for OpenCL and GPU management.", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# rust-gpu-tools [![Crates.io](https://img.shields.io/crates/v/rust-gpu-tools.svg)](https://crates.io/crates/rust-gpu-tools)\n\nAn abstraction library to run kernels on both CUDA and OpenCL.\n\n## Example\n\nYou need to write the code that interacts with the GPU only once. Below is such code that runs a\nkernel on CUDA and/or OpenCL. For a full working example, please see the [`examples`](examples)\ndirectory. You can run it via `cargo run --example add`.\n\n```rust\nlet closures = program_closures!(|program, _args| -> Result<Vec<u32>, GPUError> {\n    // Make sure the input data has the same length.\n    assert_eq!(aa.len(), bb.len());\n    let length = aa.len();\n\n    // Copy the data to the GPU.\n    let aa_buffer = program.create_buffer_from_slice(&aa)?;\n    let bb_buffer = program.create_buffer_from_slice(&bb)?;\n\n    // The result buffer has the same length as the input buffers.\n    let result_buffer = unsafe { program.create_buffer::<u32>(length)? };\n\n    // Get the kernel.\n    let kernel = program.create_kernel(\"add\", 8, 4)?;\n\n    // Execute the kernel.\n    kernel\n        .arg(&(length as u32))\n        .arg(&aa_buffer)\n        .arg(&bb_buffer)\n        .arg(&result_buffer)\n        .run()?;\n\n    // Get the resulting data.\n    let mut result = vec![0u32; length];\n    program.read_into_buffer(&result_buffer, &mut result)?;\n\n    Ok(result)\n});\n```\n\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "rust-sha2ni", "description": null, "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Sha2Ni\n\n![Build and test](https://github.com/filecoin-project/rust-sha2ni/workflows/Build%20and%20test/badge.svg)\n[![License](https://img.shields.io/badge/license-MIT%2FApache--2.0-blue.svg)](\nhttps://github.com/filecoin-project/rust-sha2ni)\n[![Cargo](https://img.shields.io/crates/v/sha2ni.svg)](\nhttps://crates.io/crates/sha2ni)\n[![Documentation](https://docs.rs/sha2ni/badge.svg)](\nhttps://docs.rs/sha2ni)\n\n> Sha2 implemention in Rust, aimed at performance. \n> Forked from [Sha2](https://github.com/rustcrypto/hashes).\n\nThis fork is no longer needed as the upstream [`sha2` crate](https://crates.io/crates/sha2) now supports the SHA-NI extension.\n\n## License\n\nDual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\n", "release_dates": []}, {"name": "sample-data", "description": "Sample data for learning how to use Filecoin", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin sample data\n\nLearn how to store and retrieve data on Filecoin using the sample data in this repository.\n\nAll files in this folder are covered under Creative Commons (CC) licenses that allow data to be used for commercial purposes and to be reused with modification.\n\n## Storing data in Filecoin\n\nFor documentation on how to store data in Filecoin, go to the [go-filecoin wiki](https://github.com/filecoin-project/go-filecoin/wiki/4.-Storing-on-Filecoin).\n\n## Data in this folder\n\n`angry-cat.jpg`<br />\n![Angry cat](/angry-cat.jpg)\n\n`baby-elephant.jpg`<br />\n![Baby elephant](/baby-elephant.jpg)\n\n`camel.jpg`<br />\n![Camel](/camel.jpg)\n\n`corgi.jpg`<br />\n![Corgi](/corgi.jpg)\n\n`dolan.png`<br />\n![Dolan](/dolan.png)\n\n`dolphin.jpg`<br />\n![Dolphin](/dolphin.jpg)\n\n`happy-puppy.jpg`<br />\n![Happy puppy](/happy-puppy.jpg)\n\n`invictus.txt`<br />\n```\n\"Invictus\" \nby William Ernest Henley\n\n\nOut of the night that covers me, \n      Black as the pit from pole to pole, \nI thank whatever gods may be \n      For my unconquerable soul. \n\nIn the fell clutch of circumstance \n      I have not winced nor cried aloud. \nUnder the bludgeonings of chance \n      My head is bloody, but unbowed. \n\nBeyond this place of wrath and tears \n      Looms but the Horror of the shade, \nAnd yet the menace of the years \n      Finds and shall find me unafraid. \n\nIt matters not how strait the gate, \n      How charged with punishments the scroll, \nI am the master of my fate, \n      I am the captain of my soul. \n```\n\n`kitten.jpg`<br />\n![Kitten](/kitten.jpg)\n\n`krakow-animated.jpg`<br />\n![Krakow animated](/krakow-animated.jpg)\n\n`lemur.jpg`<br />\n![Lemur](/lemur.jpg)\n\n`nasa-andromeda.jpg`<br />\n![Andromeda](/nasa-andromeda.jpg)\n\n`nasa-coronas-black-holes.jpg`<br />\n![Coronas/Black holes](/nasa-coronas-black-holes.jpg)\n\n`nasa-earth.jpg`<br />\n![Earth](/nasa-earth.jpg)\n\n`nasa-high-energy-x-rays.jpg`<br />\n![High energy X-rays](/nasa-high-energy-x-rays.jpg)\n\n`neurotic-puppy.jpg`<br />\n![Neurotic puppy](/neurotic-puppy.jpg)\n\n`panda-hug.jpg`<br />\n![Pandas hugging](/panda-hug.jpg)\n\n`puppy.jpg`<br />\n![Puppy](/puppy.jpg)\n\n`rotating-earth.gif`<br />\n![Rotating Earth](/rotating-earth.gif)\n\n`sick-shel-silverstein.txt`<br />\n```\n\"Sick\"\nby Shel Silverstein\n\n\u201cI cannot go to school today,\"\nSaid little Peggy Ann McKay.\n\u201cI have the measles and the mumps,\nA gash, a rash and purple bumps.\nMy mouth is wet, my throat is dry,\nI\u2019m going blind in my right eye.\nMy tonsils are as big as rocks,\nI\u2019ve counted sixteen chicken pox\nAnd there\u2019s one more\u2014that\u2019s seventeen,\nAnd don\u2019t you think my face looks green?\nMy leg is cut\u2014my eyes are blue\u2014\nIt might be instamatic flu.\nI cough and sneeze and gasp and choke,\nI\u2019m sure that my left leg is broke\u2014\nMy hip hurts when I move my chin,\nMy belly button\u2019s caving in,\nMy back is wrenched, my ankle\u2019s sprained,\nMy \u2018pendix pains each time it rains.\nMy nose is cold, my toes are numb.\nI have a sliver in my thumb.\nMy neck is stiff, my voice is weak,\nI hardly whisper when I speak.\nMy tongue is filling up my mouth,\nI think my hair is falling out.\nMy elbow\u2019s bent, my spine ain\u2019t straight,\nMy temperature is one-o-eight.\nMy brain is shrunk, I cannot hear,\nThere is a hole inside my ear.\nI have a hangnail, and my heart is\u2014what?\nWhat\u2019s that? What\u2019s that you say?\nYou say today is. . .Saturday?\nG\u2019bye, I\u2019m going out to play!\u201d\n```\n\n`swiral-testav.gif`<br />\n![Swiral Testav](/swiral-testav.gif)\n\n`woke-puppy.jpg`<br />\n![Woke puppy](/woke-puppy.jpg)\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/sample-data/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/sample-data/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "sapling-crypto", "description": "Zcash \"Sapling\" cryptography", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# fil-sapling-crypto\n\n> This repo is fork of the great [sapling-crpyto](https://github.com/zcash-hackworks/sapling-crypto/) library.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": []}, {"name": "sector-storage", "description": "A concrete implementation of the specs-storage interface", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# NOTE: Moved to filecoin-project/lotus\n\nThe code currently lives, and is developed in https://github.com/filecoin-project/lotus/tree/next/extern/sector-storage\n\nDO NOT OPEN PRs IN THIS REPOSITORY\n\n# sector-storage\n\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/sector-storage.svg?style=svg)](https://circleci.com/gh/filecoin-project/sector-storage)\n[![standard-readme compliant](https://img.shields.io/badge/standard--readme-OK-green.svg?style=flat-square)](https://github.com/RichardLitt/standard-readme)\n\n> a concrete implementation of the [specs-storage](https://github.com/filecoin-project/specs-storage) interface\n\nThe sector-storage project provides a implementation-nonspecific reference implementation of the [specs-storage](https://github.com/filecoin-project/specs-storage) interface.\n\n## Disclaimer\n\nPlease report your issues with regards to sector-storage at the [lotus issue tracker](https://github.com/filecoin-project/lotus/issues)\n\n## Architecture\n\n![high-level architecture](docs/sector-storage.svg)\n\n### `Manager`\n\nManages is the top-level piece of the storage system gluing all the other pieces\ntogether. It also implements scheduling logic.\n\n### `package stores`\n\nThis package implements the sector storage subsystem. Fundamentally the storage\nis divided into `path`s, each path has it's UUID, and stores a set of sector\n'files'. There are currently 3 types of sector files - `unsealed`, `sealed`,\nand `cache`.\n\nPaths can be shared between nodes by sharing the underlying filesystem.\n\n### `stores.Local`\n\nThe Local store implements SectorProvider for paths mounted in the local\nfilesystem. Paths can be shared between nodes, and support shared filesystems\nsuch as NFS.\n\nstores.Local implements all native filesystem-related operations \n\n### `stores.Remote`\n\nThe Remote store extends Local store, handles fetching sector files into a local\nstore if needed, and handles removing sectors from non-local stores.\n\n### `stores.Index`\n\nThe Index is a singleton holding metadata about storage paths, and a mapping of\nsector files to paths\n\n### `LocalWorker`\n\nLocalWorker implements the Worker interface with ffiwrapper.Sealer and a\nstore.Store instance\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/sector-storage/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/sector-storage/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "security-analysis", "description": null, "language": "TeX", "license": null, "readme": "# security-analysis\nrelated links:\n1. Joe Zimmerman's attacks on EC  https://github.com/filecoin-project/research-private/tree/master/papers\n", "release_dates": []}, {"name": "sentinel", "description": "Filecoin Network monitoring and analysis tools.", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Sentinel\n\nThe Sentinel Team provides Filecoin chain monitoring and analysis tools.\n\n## Projects\n- [Lily](https://lilium.sh/software/lily/introduction/): Performs chain data extraction and indexing, exporting to TimescaleDB or CSV.\n- [Sentinel-tick](https://github.com/filecoin-project/sentinel-tick): Collects Filecoin pricing and volume information from exchanges and inserts it into Postgres/Timescale DB.\n- [Sentinel-locations](https://github.com/filecoin-project/sentinel-locations): Uses Lily-extracted miner data to create a table mapping miner_ids to geographical locations.\n- [Filcryo](https://github.com/filecoin-project/filcryo): Create archival-grade snapshots as used by the Sentinel/Data Engineering Team at Protocol Labs for further processing.\n\n## Data\n- BigQuery dataset: [protocol-labs-data.lily](https://console.cloud.google.com/bigquery?ws=!1m4!1m3!3m2!1sprotocol-labs-data!2slily)\n- Batch dump data: gs://fil-mainnet-archive\n- Daily archival snapshots: gs://fil-mainnet-archival-snapshots\n\n## Communications\n- [Filecoin slack](https://filecoin.io/slack)\n    - team channel: [#fil-sentinel](https://filecoinproject.slack.com/archives/C0174P5M11T)\n    - group mention: `@sentinel-team`\n- [Request for collaboration](https://github.com/filecoin-project/sentinel/blob/master/REQUEST.md)\n\n## Documentation and support\n\nVisit https://lilium.sh for the latest documentation on the software.\n\n- For questions and support, we are available in the `#fil-sentinel` on Filecoin's slack (https://filecoin.io/slack/).\n\nTo build the documentation site locally, you need:\n- [Hugo](https://gohugo.io/getting-started/installing/), `>=v0.9.0`.\n- [npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm), `>=v8.5.0`\n\nTo run the Hugo server locally:\n\n```\n$ cd docs\n$ npm install\n$ hugo server\n```\n\n## Code of Conduct\n\nSentinel follows the [Filecoin Project Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md). Before contributing, please acquaint yourself with our social courtesies and expectations.\n\n\n## License\n\nThe Filecoin Project and Sentinel projects are dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/sentinel/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/sentinel/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "sentinel-drone", "description": "An analytics capture agent for lotus daemon which is forked from Telegraf (https://github.com/influxdata/telegraf) to support custom input/output plugins.", "language": "Go", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Sentinel Drone\n\n> Telegraf metrics agent for Lotus\n\n[![build status](https://circleci.com/gh/filecoin-project/sentinel-drone.svg?style=svg)](https://app.circleci.com/pipelines/github/filecoin-project/sentinel-drone)\n\n**Sentinel Drone** is a fork of Telegraf with input and processing plugins for Lotus, and the postgres output plugin. It's deployed as part of [Sentinel](https://github.com/filecoin-project/sentinel), the Filecoin Network Monitoring and Analysis System. \n\n**Telegraf** is an agent for collecting and writing metrics see https://github.com/influxdata/telegraf/\n\n## Custom Plugins\n\nDrone packages Telegraf with the following custom plugins:\n\n* `input` [lotus](./plugins/inputs/lotus)\n* `processor` [lotus_peer_id](./plugins/processors/lotus_peer_id)\n* `output` [postgresql](./plugins/outputs/postgresql)\n\n## Minimum Requirements\n\nTelegraf shares the same [minimum requirements][] as Go:\n- Linux kernel version 2.6.23 or later\n- Windows 7 or later\n- FreeBSD 11.2 or later\n- MacOS 10.11 El Capitan or later\n\n[minimum requirements]: https://github.com/golang/go/wiki/MinimumRequirements#minimum-requirements\n\n## Installation:\n\n### From Source:\n\nTelegraf requires Go version 1.12 or newer, the Makefile requires GNU make.\n\n1. [Install Go](https://golang.org/doc/install) >=1.12 (1.13 recommended)\n2. Clone the repository: `git clone https://github.com/filecoin-project/sentinel-drone.git`\n3. Run `make` from the source directory\n\n## How to use it:\n\nSee usage with:\n\n```\ntelegraf --help\n```\n\n#### Generate a telegraf config file:\n\n```\ntelegraf config > telegraf.conf\n```\n\n#### Generate config with only cpu input & influxdb output plugins defined:\n\n```\ntelegraf --section-filter agent:inputs:outputs --input-filter cpu --output-filter influxdb config\n```\n\n#### Run a single telegraf collection, outputing metrics to stdout:\n\n```\ntelegraf --config telegraf.conf --test\n```\n\n#### Run telegraf with all plugins defined in config file:\n\n```\ntelegraf --config telegraf.conf\n```\n\n#### Run telegraf, enabling the cpu & memory input, and influxdb output plugins:\n\n```\ntelegraf --config telegraf.conf --input-filter cpu:mem --output-filter influxdb\n```\n\n## Documentation\n\n[Latest Release Documentation][release docs].\n\nFor documentation on the latest development code see the [documentation index][devel docs].\n\n[release docs]: https://docs.influxdata.com/telegraf\n[devel docs]: docs\n", "release_dates": []}, {"name": "sentinel-locations", "description": null, "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Sentinel Locations\n\n[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white&style=flat-square)](https://pkg.go.dev/github.com/filecoin-project/sentinel-locations)\n[![docker build status](https://img.shields.io/docker/cloud/build/filecoin/sentinel-locations?style=flat-square)](https://hub.docker.com/repository/docker/filecoin/sentinel-locations)\n![Go](https://github.com/filecoin-project/sentinel-locations/workflows/Go/badge.svg)\n\nA component of [**Sentinel**](https://github.com/filecoin-project/sentinel), a collection of services which monitor the health and function of the Filecoin network. \n\n**Sentinel-Locations** lookups and stores location information for miners based on the IPv4s declared on their on-chain multiaddresses.\n\n## Usage\n\nDefine an environment variable `SENTINEL_DB` with the full sentinel db connection string and then run:\n\n`./sentinel-locations`\n\nThe program will create the `locations` schema and `miners` table automatically.\n\n## Code of Conduct\n\nSentinel Locations follows the [Filecoin Project Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md). Before contributing, please acquaint yourself with our social courtesies and expectations.\n\n\n## Contributing\n\nWelcoming [new issues](https://github.com/filecoin-project/sentinel-locations/issues/new) and [pull requests](https://github.com/filecoin-project/sentinel-locations/pulls).\n\n\n## License\n\nSentinel Locations is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/sentinel-locations/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/sentinel-locations/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "sentinel-tick", "description": "Fetch FIL pricing and ingest it into a Sentinel database", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Sentinel Tick\n\n[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white&style=flat-square)](https://pkg.go.dev/github.com/filecoin-project/sentinel-tick)\n[![docker build status](https://img.shields.io/docker/cloud/build/filecoin/sentinel-tick?style=flat-square)](https://hub.docker.com/repository/docker/filecoin/sentinel-tick)\n![Go](https://github.com/filecoin-project/sentinel-tick/workflows/Go/badge.svg)\n\nA component of [**Sentinel**](https://github.com/filecoin-project/sentinel), a collection of services which monitor the health and function of the Filecoin network. \n\n**Sentinel-Tick** collects price information for exchanges where Filecoin is traded and writes it to a PostgreSQL (normally the same one as other Sentinel components).\n\n## Usage\n\n`sentinel-tick --help`\n\n## Code of Conduct\n\nSentinel Tick follows the [Filecoin Project Code of Conduct](https://github.com/filecoin-project/community/blob/master/CODE_OF_CONDUCT.md). Before contributing, please acquaint yourself with our social courtesies and expectations.\n\n\n## Contributing\n\nWelcoming [new issues](https://github.com/filecoin-project/sentinel-tick/issues/new) and [pull requests](https://github.com/filecoin-project/sentinel-tick/pulls).\n\n\n## License\n\nSentinel Tick is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/sentinel-tick/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/sentinel-tick/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "serialization-vectors", "description": "Test vectors of serialized filecoin datastructures", "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "slate", "description": "WIP - We're building the place you go to discover, share, and sell files on the web.", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "![Slate](https://user-images.githubusercontent.com/310223/92346209-e368d580-f080-11ea-8693-0fb64f8d3b97.jpg)\n\n# Slate\n\n### An open source storage system for your data that makes it easy to collect, organize, and share them anywhere on the web.\n\n- [Create an account and try it out!](https://slate.host)\n- [Filecoin](https://filecoin.io)\n- [Textile](https://textile.io)\n- [Twitter](https://twitter.com/_slate)\n\n### Introduction\n\n![Slate Preview](https://user-images.githubusercontent.com/310223/92346093-94bb3b80-f080-11ea-8ac6-c4cce3cd1aec.gif)\n\nSlate is the first open source file storage application designed to encourage collaboration and research across a distributed network. It is a first step towards enabling a thriving network for data storage and transactions powered by IPFS, Filecoin and Textile that is open and usable for everyone. Our goal is to provide a meaningful story for every feature the protocol provides today and in the future. The Slate Project is the byproduct of a growing community of contributors from around the world.\n\nSlate is tightly scoped for the present and more broadly thought out for the future. Our primary objective is to create a best-in-class experience for uploading, collecting, and sharing media. Additional filetypes will be supported, but our focus is to start with the pieces that apply to everyone and then dial into more specific formats.\n\n- Example collection: https://slate.host/tara/loom\n- Example user profile: https://slate.host/gndclouds\n- New brand: https://slate.host/narative/slate-brand-identity\n- Monet on Filecoin: https://slate.host/slate/monet\n\n[Create an account and try it out!](https://slate.host/_)\n\n# Get involved\n\nSlate is built by a growing community of collaborators and contributors. We\u2019d love for you to join us! You can reach out to us by email at hello@slate.host\n\n\n## Developer API\n\nSlate has a Developer API that allows you upload files using code and HTTP. Every user who creates an account on Slate can use the API. The documentation is visible after logging in, under the API tab.\n", "release_dates": []}, {"name": "slate-react-system", "description": "A component, constants, and experience library for the Filecoin Network / Textile Services", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# DEPRECATED\n", "release_dates": ["2020-11-26T01:57:25Z", "2020-08-19T07:01:12Z", "2020-07-29T00:05:41Z", "2020-07-21T02:21:19Z", "2020-07-20T06:55:38Z", "2020-07-10T07:31:23Z", "2020-07-07T08:31:40Z", "2020-07-02T09:45:05Z", "2020-07-02T07:41:15Z"]}, {"name": "slate-stats", "description": "Live heartbeat of the network available for everyone.", "language": "JavaScript", "license": null, "readme": "# slate-stats\n", "release_dates": []}, {"name": "snapcraft-exporter", "description": "A prometheus exporter for fetching data from `snapcraft metrics`", "language": "Go", "license": null, "readme": "# homebrew-exporter\nA Snapcraft Exporter for parsing the metrics provided by Snapcraft: https://snapcraft.io/docs/snapcraft-metrics\n\n### To configure\n\n| ENV variable | Default value | Description |\n|--------------|---------------|-------------|\n| `METRICS_PATH` | `\"/metrics\"`| The path to publish the metrics to. |\n| `LISTEN_PORT`  | `\"9888\"`    | The port the metrics exporter listens on. |\n| `SNAP_NAMES` | REQUIRED | The list of Snaps to grab metrics for. If blank, the exporter will exit immediately. |\n", "release_dates": []}, {"name": "solidity-data-segment", "description": null, "language": "JavaScript", "license": null, "readme": "# Solidity Data Segment\n\nThis project provides a Verifier solidity library for users to verify the proof generated by aggregators\n\n## Install\n\n```shell\nnpm install\n```\n\n## Unit tests\n\n```shell\nnpx hardhat test\n```\n", "release_dates": []}, {"name": "sp-automation", "description": null, "language": "Jinja", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# SP Automation Stack for Ansible\nThe SP Automation Stack, based on earlier work on a set of Bash scripts called `lotus-automation`, is a set of Ansible playbooks and tools that deploys and manages a complete Filecoin Storage Provider installation, including wallet management and bootstrapping.\n\nIt is intended to be able to be run against the same SP over and over again, bringing the SP into alignment with where it should be.\n\nAt the moment the SP Automation Stack is targeting new and small-sized SPs, as well as larger SPs who wish to experiment - over time, a Porting Guide will be published and improved which allows existing SPs to begin using the Stack and manage their existing deployments.\n\n## Requirements\n- Ansible (2.12 or newer)\n- Python3 (3.9 or newer)\n- Passwordless sudo enabled on your Lotus node (alternatively, add the flags --become and --ask-become-pass when running ansible-playbook)\n- If you are using Secure Boot on your Lotus node, please read [the note on Secure Boot](#nvidia-support-and-secure-boot).\n\n## Upgrading\nOnce we have begun publishing releases for SP Automation, please read the release notes *every time you upgrade!* \n\nWe may release breaking changes over time you need to be aware of, and your group_vars/ files in particular may need changes over time to keep up with the playbook.\n\n## Usage\n- Clone this repository and `cd` into it\n```\ngit clone https://github.com/filecoin-project/sp-automation.git && cd sp-automation\n```\n- Run the setup script to symlink Ansible Galaxy roles into place. This will not be needed once we make the roles available via Galaxy.\n```\n./setup_ansible_roles.sh\n```\n- Copy `inventory.example` to `inventory` and edit it to suit your needs.\n```\ncp inventory.example inventory && editor inventory\n```\n- Copy the global configuration - `ansible/group_vars/all.example` to `ansible/group_vars/all` and edit it to suit your needs.\n```\ncp group_vars/all.example group_vars/all && editor group_vars/all\n```\n- Copy the YugabyteDB configuration - `group_vars/yugabytedb.example` to `group_vars/yugabytedb` and edit it to suit your needs.\n```\ncp group_vars/yugabytedb.example group_vars/yugabytedb && editor group_vars/yugabytedb\n```\n- Copy the Boost configuration - `group_vars/boost.example` to `group_vars/boost` and edit it to suit your needs.\n```\ncp group_vars/boost.example group_vars/boost && editor group_vars/boost\n```\n- If this is your first time running lotus-automation for Ansible on this machine, run the Ansible Galaxy install process.\n```\nansible-galaxy install -r roles/requirements.yml ; ansible-galaxy install -r collections/requirements.yml\n```\n- Now run the playbook and deploy your Storage Provider. (Note: If any of your nodes do not have **passwordless sudo** enabled, add --ask-become-pass to the command below)\n```\nansible-playbook deploy.yml\n```\n- The playbook will automatically deploy everything, and ask you questions if it needs any more information from you. If you run into any issues, please let us know by opening an issue on this repository.\n\n## Things to note\nThere are some important things you should know while using this playbook.\n\n### NVIDIA support and Secure Boot\nSet `install_nvidia_driver: true` in `group_vars/all` if you want to have the playbook handle installing the NVIDIA drivers for you.\n\nIt will also handle figuring out your GPU's details and ask the compiler to take that into account while building Lotus.\n\nIf you are using Ubuntu with Secure Boot enabled (likely if you are on a modern UEFI machine), due to a bug in the NVIDIA driver packages (or possibly their Ansible role), you may find yourself unable to use the NVIDIA driver after installation. \n\nIf you run into this, please run `sudo dpkg-reconfigure nvidia-dkms-525-server` (replacing 525 with your driver version - for example, 515 on Ubuntu 20.04) and follow the steps, then reboot and select \"Enroll MOK\", then reboot one last time, then re-run the playbook.\n\n### Wallet management\nThis Ansible playbook will perform basic wallet management for you. This utilises Ansible facts (via `facts.d` in `/etc/ansible/facts.d`) and is still undergoing improvements.\n\n# Credits\nThe SP Automation Stack was originally written by contributors to Protocol Labs & Filecoin Foundation. It is made available under the Dual Stack Permissive Licence.\n\nWe are:\n\n* Bob Dubois: @bobdubois\n* Anjor Kanekar: @anjor\n* Angelo Schalley: @Angelo-gh3990\n* Orjan Roren: @rjan90\n* Benjamin Arntzen: @zorlin\n", "release_dates": ["2023-10-03T02:27:10Z", "2023-09-21T17:22:25Z"]}, {"name": "sp-mentorship-grants", "description": null, "language": null, "license": null, "readme": "# >>> [APPLY HERE](https://5ufz7ber0fd.typeform.com/sp-onboarding) <<<\n\n# Storage Provider Mentorship Grants\n## About\nOur mission is to support businesses getting started on their journey as storage providers as smoothly and efficiently as possible. To accomplish this goal, we have established a grant program to ease Storage Providers (SPs) through the onboarding process via in person consulting and technical support from trusted ecosystem partners who are proven, dedicated, and technically adept SPs themselves. \n\nBelow you will find our current list of SP consulting partners, as well as the various grant offerings that are available to qualified Storage Providers. Make sure to continue to check back at this page, as more consultants and options will become available over time. You are also encouraged to [become a member of the Filecoin slack](https://filecoin.io/slack) and join [#fil-sp-mentorship-grants](https://filecoinproject.slack.com/archives/C03C86E3WU8) for instant updates.\n\n## NOTICE\n\nThe FSPM Grant program is being restructured right now.  More information will be published soon. Thanks for your understanding.\n\n## Questions\nWe would love to hear from you! The world of Filecoin is fast paced, so we tend to prefer live communication channels. Please [join the Filecoin slack](https://filecoin.io/slack) and head over to the the program channel [#fil-sp-mentorship-grants](https://filecoinproject.slack.com/archives/C03C86E3WU8).\n", "release_dates": []}, {"name": "specs", "description": "The Filecoin protocol specification", "language": "SCSS", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Filecoin Specification\n\n![CI](https://github.com/filecoin-project/specs/workflows/CI/badge.svg)\n\nThis is the [Filecoin Specification](https://github.com/filecoin-project/specs), a repository that contains documents, code, models, and diagrams that constitute the specification of the [Filecoin Protocol](https://filecoin.io). This repository is the singular source of truth for the Filecoin Protocol. All implementations of the Filecoin Protocol should match and comply with the descriptions, interfaces, code, and models defined in this specification.\n\n<https://spec.filecoin.io> is the user-friendly website rendering, which we recommend for reading this repository. The website is updated automatically with every merge to `master`.\n\n## Table of Contents\n\n- [Install](#install)\n- [Writing the spec](#writing-the-spec)\n- [Check your markdown](#check-your-markdown)\n- [Page Template](#page-template)\n- [Code](#code)\n- [Images](#images)\n- [Links](#links)\n- [Shortcodes](#shortcodes)\n  - [`embed`](#embed)\n  - [`listing`](#listing)\n  - [`mermaid`](#mermaid)\n  - [`hint`](#hint)\n  - [`katex`](#katex)\n- [Math mode](#math-mode)\n  - [Wrap `def`, `gdef`, etc.](#wrap-def-gdef-etc)\n  - [Wrap inline math text with code blocks](#wrap-inline-math-text-with-code-blocks)\n  - [Wrap math blocks with code fences](#wrap-math-blocks-with-code-fences)\n- [Front-matter](#front-matter)\n- [References](#references)\n\n## Install\n\nTo build the spec website you need\n\n- [`node` & `npm`](https://nodejs.org/en/download)\n\nOn macOS you can get node from Homebrew\n\n```bash\nbrew install node\n```\n\nClone the repo, and use `npm install` to fetch the dependencies\n\n```sh\ngit clone https://github.com/filecoin-project/specs.git\nnpm install\n```\n\nTo run the development server with live-reload locally, run:\n\n```sh\nnpm start\n```\n\nThen open <http://localhost:1313> in the browser\n\n## Writing the spec\n\nThe spec is written in markdown. Each section is markdown document in the `content` directory. The first level of the directory structure denotes the top level sections of the spec; (Introduction, Systems, etc.) The `_index.md` file in each folder is used as the starting point for each section. For example the **Introduction** starts in `content/intro/_index.md`.\n\nSections can be split out into multiple markdown documents. The build process combines them into a single html page. The sections are ordered by the `weight` front-matter property. The introduction appears at the start of the html page because `content/intro/_index.md` has `weight: 1`, while `content/systems/_index.html` has `weight: 2` so it appears as the second section.\n\nYou can split out sub-sections by adding additional pages to a section directory. The `content/intro/concepts.md` defines the Key Concepts sub-section of the the Introduction. The order of sub-sections within a section is again controlled by setting the `weight` property. This pattern repeats for sub sub folders which represent sub sub sections.\n\nThe markdown documents should all be well formed, with a single h1, and headings should increment by a single level.\n\n> Note: Regular markdown files like `content/intro/concepts.md` can't reference resources such as images, or other files. Such resources can be referenced only from `_index.md` files. Given that a folder will have an `_index.md` file already, there is the following work around to reference resources from any file: create a new sub-folder in the same folder where the initial .md file was, e.g., `content/intro/concepts/_index.md`, include the content from `concepts.md` in the `_index.md` file, add the resource files (for example, images) in the new folder and reference the resource file from the new `_index.md` file inside the `concepts` folder. The referencing syntax and everything else works the same way.\n\n## Check your markdown\n\nUse `npm test` to run a markdown linter and prettier to check for common errors. It runs in CI and you can run it locally with:\n\n```bash\nnpm test\ncontent/algorithms/crypto/randomness.md\n  15:39-15:46  warning  Found reference to undefined definition  no-undefined-references  remark-lint\n  54:24-54:31  warning  Found reference to undefined definition  no-undefined-references  remark-lint\n\n\u26a0 2 warnings\n```\n\nFormat errors can be fixed by running `npm run format`.\n\n```bash\nChecking formatting...\n[warn] content/systems/filecoin_token/block_reward_minting.md\n[warn] Code style issues found in the above file(s). Forgot to run Prettier?\n```\n\n## Page Template\n\nA spec document should start with a YAML front-matter section and contain at least a single h1, as below.\n\n```md\n---\ntitle: Important thing\nweight: 1\ndashboardState: wip\ndashboardAudit: missing\n---\n\n# Important thing\n```\n\n## Code\n\nWrap code blocks in _code fences_. Code fences should **always** have a lang. It is used to provide syntax highlighting. Use `text` as the language flag for pseudocode for no highlighting.\n\n````text\n```text\nYour algorithm here\n```\n````\n\nYou can embed source code from local files or external other repos using the `embed` [shortcode](#embed).\n\n```text\n{{<embed src=\"/path/to/local/file/types.go\"  lang=\"go\" symbol=\"Channel\">}}\n\n{{<embed src=\"https://github.com/filecoin-project/lotus/blob/master/build/bootstrap.go\" lang=\"go\">}}\n```\n\n## Images\n\nUse normal markdown syntax to include images.\n\nFor `dot` and `mermaid` diagrams you link to the source file and the pipelines will handle converting that to `svg`.\n\n```md\n# relative to the markdown file\n\n![Alt text](picture.jpg)\n\n# relative to the content folder\n\n![Alt text](/content/intro/diagram1.mmd)\n\n![Alt text](graph.dot 'Graph title')\n```\n\n> The alt text is used as the title if not provided.\n\n## Links\n\nUse markdown syntax `[text](markdown-document-name)`.\n\nThese links use \"portable links\" just like `relref`. Just give it the name of the file and it will fetch the correct relative path and title automatically. You can override the title by passing a second `string` in the link definition.\n\n> **Note**: When using anchors the title can't be fetched automatically.\n\n```md\n[](storage_power_consensus)\n\n# Renders to\n\n<a href=\"/systems/filecoin_blockchain/storage_power_consensus\" title=\"Storage Power Consensus\">Storage Power Consensus</a>\n\n[Storage Power](storage_power_consensus 'Title to override the page original title')\n\n# Renders to\n\n<a href=\"/systems/filecoin_blockchain/storage_power_consensus\" title=\"Title to override the page original title\">Storage Power</a>\n\n[Tickets](storage_power_consensus#the-ticket-chain-and-drawing-randomness 'The Ticket chain and drawing randomness')\n\n# Renders to\n\n<a href=\"/systems/filecoin_blockchain/storage_power_consensus#the-ticket-chain-and-drawing-randomness\" title=\"The Ticket chain and drawing randomness\">Tickets</a>\n```\n\n## Shortcodes\n\nhugo shortcodes you can add to your markdown.\n\n### `embed`\n\n```md\n# src relative to the page\n\n{{<embed src=\"piece_store.go\" lang=\"go\">}}\n\n# src relative to content folder\n\n{{<embed src=\"/systems/piece_store.go\" lang=\"go\">}}\n\n# can just embed a markdown file\n\n{{<embed src=\"section.md\" markdown=\"true\">}}\n\n# can embed symbols from Go files\n\n# extracts comments and symbol body\n\n{{<embed src=\"types.go\"  lang=\"go\" symbol=\"Channel\">}}\n\n# can embed from external sources like github\n\n{{<embed src=\"https://github.com/filecoin-project/lotus/blob/master/build/bootstrap.go\" lang=\"go\">}}\n```\n\nThis shortcode also supports the property `title` to add a permalink below the embed.\n\n### `listing`\n\nThe listing shortcode creates tables from externals sources, supports Go `struct`.\n\n```md\n# src relative to the page\n\n{{<listing src=\"piece_store.go\" symbol=\"Channel\">}}\n\n# src relative to content folder\n\n{{<listing src=\"/systems/piece_store.go\" symbol=\"Channel\">}}\n\n# src can also be from the externals repos\n\n{{<listing src=\"/externals/go-data-transfer/types.go\"  symbol=\"Channel\">}}\n```\n\n### `mermaid`\n\nInline mermaid syntax rendering\n\n```html\n{{< mermaid >}}\ngraph TD\n  A[Christmas] -->|Get money| B(Go shopping)\n  B --> C{Let me think}\n  C -->|One| D[Laptop]\n  C -->|Two| E[iPhone]\n  C -->|Three| F[fa:fa-car Car]\n\n{{</ mermaid >}}\n```\n\n### `hint`\n\n```md\n<!-- info|warning|danger -->\n\n{{< hint info >}}\n**Markdown content**  \nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat\nstringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa\n{{< /hint >}}\n```\n\n### `katex`\n\nWe should **only** use `inline` mode for now! Display mode has a bug and is not responsive the formulas don't break in small screen. Track: <https://github.com/KaTeX/KaTeX/issues/2271>\n\n```md\n<!-- Use $ math $ for inline mode-->\n\n{{<katex>}}\n$SectorInitialConsensusPledge = \\\\[0.2cm] 30\\% \\times FILCirculatingSupply \\times \\frac{SectorQAP}{max(NetworkBaseline, NetworkQAP)}$\n{{</katex >}}\n\n<!-- Use $$ math $$ for display mode-->\n\n{{<katex>}}\n$$SectorInitialConsensusPledge = \\\\[0.2cm] 30\\% \\times FILCirculatingSupply \\times \\frac{SectorQAP}{max(NetworkBaseline, NetworkQAP)}$$\n{{</katex >}}\n```\n\n## Math mode\n\nFor short snippets of math text (e.g., inline reference to parameters, or single formulas) it is easier to use the `{{<katex>}}`/`{{/katex}}` shortcode (as described just [above](specs#katex)). Check how KaTeX parses math typesetting [here](https://katex.org/docs/api.html).\n\nFor extensive blocks of math content it is more convenient to use `math-mode` to avoid having to repeat the katex shortcode for every math formula.\n\nCheck this example [example](https://spec.filecoin.io/math-mode/)\n\n> Some syntax like `\\_` can't go through HUGO markdown parser and for that reason we need to wrap math text with code blocks, code fendes or the shortcode `{{<plain>}}`. See examples below.\n>\n> ### Add `math-mode` prop to the Frontmatter\n>\n> ```md\n> ---\n> title: Math Mode\n> math-mode: true\n> ---\n> ```\n\n### Wrap `def`, `gdef`, etc.\n\nMath text needs to be wrapped to avoid Hugo's Markdown parser. When wrapping defs or any math block that doesn't need to be rendered the recommended option is to use the shortcode `{{<plain hidden}}` with the hidden argument.\n\n```md\n{{<plain hidden>}}\n\n$$\n\\gdef\\createporepbatch{\\textsf{create_porep_batch}}\n\\gdef\\GrothProof{\\textsf{Groth16Proof}}\n\\gdef\\Groth{\\textsf{Groth16}}\n\\gdef\\GrothEvaluationKey{\\textsf{Groth16EvaluationKey}}\n\\gdef\\GrothVerificationKey{\\textsf{Groth16VerificationKey}}\n{{</plain>}}\n$$\n```\n\n### Wrap inline math text with code blocks\n\n```md\nThe index of a node in a `$\\BinTree$` layer `$l$`. The leftmost node in a tree has `$\\index_l = 0$`.\n```\n\n### Wrap math blocks with code fences\n\n````md\n```text\n$\\overline{\\underline{\\Function \\BinTree\\dot\\createproof(c: \\NodeIndex) \\rightarrow \\BinTreeProof_c}}$\n$\\line{1}{\\bi}{\\leaf: \\Safe = \\BinTree\\dot\\leaves[c]}$\n$\\line{2}{\\bi}{\\root: \\Safe = \\BinTree\\dot\\root}$\n\n$\\line{3}{\\bi}{\\path: \\BinPathElement^{[\\BinTreeDepth]}= [\\ ]}$\n$\\line{4}{\\bi}{\\for l \\in [\\BinTreeDepth]:}$\n$\\line{5}{\\bi}{\\quad \\index_l: [\\len(\\BinTree\\dot\\layer_l)] = c \\gg l}$\n$\\line{6}{\\bi}{\\quad \\missing: \\Bit = \\index_l \\AND 1}$\n$\\line{7}{\\bi}{\\quad \\sibling: \\Safe = \\if \\missing = 0:}$\n$\\quad\\quad\\quad \\BinTree\\dot\\layer_l[\\index_l + 1]$\n$\\quad\\quad\\thin \\else:$\n$\\quad\\quad\\quad \\BinTree\\dot\\layer_l[\\index_l - 1]$\n$\\line{8}{\\bi}{\\quad \\path\\dot\\push(\\BinPathElement \\thin \\{\\ \\sibling, \\thin \\missing\\ \\} \\thin )}$\n\n$\\line{9}{\\bi}{\\return \\BinTreeProof_c \\thin \\{\\ \\leaf, \\thin \\root, \\thin \\path\\ \\}}$\n```\n````\n\n## Front-matter\n\nDescription for all the available frontmatter properties\n\n```yaml\n# Page Title to be used in the navigation\ntitle: Libraries\n# Small description for html metadata, if not present the first couple of paragraphs will be used instead\ndescription: Libraries used from Filecoin\n# This will be used to order the ToC, navigation and any other listings of pages\nweight: 3\n# This will make a page section collapse in the navigation\nbookCollapseSection: true\n# This will hidden the page from the navigation\nbookhidden: true\n# This is used in the dashboard to describe the importance of the page content\ndashboardWeight: 2\n# This is used in the dashboard to describe the state of the page content options are \"missing\", \"incorrect\", \"wip\", \"reliable\", \"stable\" or \"n/a\"\ndashboardState: stable\n# This is used in the dashboard to describe if the theory of the page has been audited, options are \"missing\", \"wip\", \"done\" or \"n/a\"\ndashboardAudit: wip\n# When dashboardAudit is stable we should have a report url\ndashboardAuditURL: https://url.to.the.report\n# The date that the report at dashboardAuditURL was completed\ndashboardAuditDate: '2020-08-01'\n# This is used in the dashboard to describe if the page content has compliance tests, options are 0 or numbers of tests\ndashboardTests: 0\n```\n\n## References\n\n- [hugo theme book](https://themes.gohugo.io//theme/hugo-book/docs/shortcodes/columns/)\n- [Katex](https://katex.org/)\n- [Mermaid](https://mermaid-js.github.io/mermaid/#/)\n  - [config](https://github.com/mermaid-js/mermaid/blob/master/docs/mermaidAPI.md#mermaidapi-configuration-defaults)\n  - [editor](https://mermaid-js.github.io/mermaid-live-editor)\n- [Pan/Zoom for SVG](https://github.com/anvaka/panzoom)\n- [Icons](https://css.gg/)\n", "release_dates": ["2020-11-03T12:57:36Z", "2020-11-03T12:36:18Z", "2020-10-27T11:21:48Z", "2020-08-31T16:37:03Z", "2020-08-31T16:32:58Z"]}, {"name": "specs-actors", "description": "DEPRECATED Specification of builtin actors, in the form of executable code.", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# This repo is deprecated\n\nTo support the transition to FVM the specs-actors logic is now actively developed in the [builtin actors](https://github.com/filecoin-project/builtin-actors) code base.  \n\n(Read only) specs-actors code is still called by historical chain syncing but its logic will never change.\n\nIssues in this repo may still be relevant for filecoin protocol and builtin actors development.\n\n# Filecoin actors\n[![CircleCI](https://circleci.com/gh/filecoin-project/specs-actors.svg?style=svg)](https://circleci.com/gh/filecoin-project/specs-actors)\n[![codecov](https://codecov.io/gh/filecoin-project/specs-actors/branch/master/graph/badge.svg)](https://codecov.io/gh/filecoin-project/specs-actors)\n[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white)](https://pkg.go.dev/github.com/filecoin-project/specs-actors)\n\nThis repo is the specification of the Filecoin builtin actors, in the form of executable code.\n\nThis is a companion to the rest of the [Filecoin Specification](https://github.com/filecoin-project/specs), \nbut also directly usable by Go implementations of Filecoin.\n\n## Versioning\n\nReleases of this repo follow semantic versioning rules, with consideration of distributed state machines.\n- The major version will remain `0` or `1` for the forseeable future. \n  We do not bump the major version every time there's a backwards-incompatible change in state machine evaluation, \n  or actor interfaces, because this interacts very poorly with Go's module resolution, \n  requiring a change of all import paths.\n  After `1.0` we may consider using the major version number to version the `Runtime` interface, which is the link between\n  the actors and the system in which they are embedded.\n- A minor version change indicates a backwards-incompatible change in the state machine evaluation, including\n  actor exported methods or constant values, while retaining compatibility of the `Runtime` interface.\n  This means that the same sequence of messages might produce different states at two different versions.\n  In a blockchain, this would usually require a coordinated network upgrade or \"hard fork\".\n  After `1.0`, a minor version change may alter behaviour but not exported code or actor interfaces.\n- A patch version change may alter state evaluation (but not exported code or actor interfaces).\n  After `1.0`, a patch version change indicates a backward compatible fix or improvement that doesn't change\n  state evaluation semantics or exported interfaces. \n\n## License\nThis repository is dual-licensed under Apache 2.0 and MIT terms.\n\nCopyright 2019-2020. Protocol Labs, Inc.\n", "release_dates": []}, {"name": "specs-storage", "description": "Specification of the sector storage interface ", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# specs-storage\n\nSpecification of the sector storage interface \n\n## Disclaimer\n\nPlease report your issues with regards to storage-fsm at the [lotus issue tracker](https://github.com/filecoin-project/lotus/issues)\n", "release_dates": ["2022-05-30T22:10:33Z", "2022-05-30T22:06:16Z", "2022-05-12T01:26:24Z", "2022-03-29T18:07:15Z", "2022-03-29T18:04:24Z", "2022-02-09T10:27:39Z"]}, {"name": "starling", "description": "Demo storage client for archival video data", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Starling\n\nA command-line interface for simplified, coordinated, decentralized storage on the Filecoin network. This is a work in progress and is not yet production-ready. Use at your own risk.\n\n## Requirements\n\nStarling CLI requires a machine running a Filecoin Lotus node and NodeJS v10.16.0 +\n\n## Development\n\nTo run locally\n\n```js\n> npm install\n```\n\nDuring development it\u2019s convenient to make the symlink on our path point to the index.js we\u2019re actually working on, using `npm link`.\n\n```js\n> npm link\n```\n\nTest by running\n\n```js\n> starling <command>\n```\n\n### database\n\nStarling uses an [sqlite3](https://www.npmjs.com/package/sqlite3) database. The db is created in `HOME/.starling/starling.db`\n\n## API Address Config\n\nStarling uses the Lotus configuration files for getting the API's url and authorization token (~/.lotus/api and ~/.lotus/token).\nPlease make sure that an authorization token with admin permissions has been generated beforehand (`lotus auth api-info --perm admin`)\n\nStarling will use the optional `FULLNODE_API_INFO` variable in case it has been set. \n## Commands\n\nModify the config file `HOME/.starling/config.json`\n\n```js\n> starling config\n```\n\nStore a single file\n\n```js\n> starling store full/path/to/file\n```\n\nStore a folder\n\n```js\n> starling store full/path/to/folder\n```\n\nLaunch interactive monitoring interface\n\n```js\n> starling monitor\n\n// up/down keys: scroll through the list\n// ^S sort by size, ^V sort by filename\n// ^F: filter all files\n```\n\nGenerate a CSV report of all files stored\n\n```js\n// outputs file in the working directory\n> starling list\n\n// outputs file in the specified directory\n> starling list <path>\n```\n\nGenerate a CSV report of file fixity\n\n```js\n// outputs file in the working directory\n> starling verify\n\n// outputs file in the specified directory\n> starling verify <path>\n```\n\nOutput the version number\n\n```js\n> starling --version | -v\n```\n\nOutput usage information\n\n```js\n> starling --help | -h | help\n\n> starling [command] --help\n```\n", "release_dates": []}, {"name": "state-storage-starter-kit", "description": "The PoC to retrieve, store and interact with small pieces of data on IPFS through FVM smart contracts", "language": "JavaScript", "license": null, "readme": "# State/Storage Integration PoC\n\nBefore diving into coding, it is essential to take a few minutes to understand the concept and design behind this Proof of Concept (PoC) by reviewing the provided [specification](https://www.notion.so/State-Storage-Integration-with-Filecoin-Virtual-Machine-IPFS-263f8e13509a44ce8b2e627fe0391a9e).\n\n**Key Components**:\n\n- **Client application/smart contract**\n\n  - sends the request to the Data Management Contract (DMC) to retrieve content from IPFS for consumption.\n  - continue any process in the smart contract once the content is served to DMC by relayer.\n\n- **Data Management Contract (DMC)**\n\n  The main functions of DMC include:\n\n  - taking retrieval requests from client/application\n  - temporarily storing data severed by Relayer from IPFS\n  - serving data back to the client/application to continue their process\n\n- **Relayer**: \n\n  listen to the event logs emitted from the Data Management Contract. If there is an IPFS content request event log - `BlobLoadReq`, the relayer will retrieve content from IPFS and send it to the Data management Contract. \n\n![workflow](./workflow.png)\n\nThis repository contains the DMC, minimal functions of the client/application, and relayer. Its purpose is to demonstrate the end-to-end workflow of this Proof of Concept (PoC). \n\nYou are welcome to enhance this PoC by adding more features and building products that consume the IPFS data served in the smart contract.\n\n## Project Structure\n\nThe repository is organized as follows:\n\n- `contracts/`: This directory contains the Data Management Contract (DMC).\n\n- `scripts/`: This directory houses scripts used for deploying the DMC smart contract and scripts to simulate the functions of the client and relayer.\n  - `dmc/`: the scripts to deploy DMC on Filecoin.\n\n  - `client/`: the scripts to simulate the function from client/application, including sendDataRetrieve Request, check the status of the retrieve request, and continue the data process after receiving data on IPFS.\n\n  - `relayer.js`: simulate the minimal function of a relayer to listen to the event, retrieve content from IPFS and send the data to the DMC.\n\n- `test/`: This directory contains test files for the contracts. \n\n## Getting Started\n> **Note:**\n> Before getting started, we will need a local IPFS node to serve content. Make sure you install an [IPFS Desktop App](https://docs.ipfs.tech/install/ipfs-desktop/) on your local computer.\n>\n> You can also retrieve data through a [public IPFS gateway](https://docs.ipfs.tech/quickstart/retrieve/#fetching-the-cid-with-an-ipfs-gateway) using any generic HTTP request client.\n\nTo get started with the project, follow these steps:\n\n1. Clone the repository\n\n   ```shell\n   git clone https://github.com/filecoin-project/state-storage-starter-kit.git\n   ```\n\n2. Install the project dependencies\n\n   ```shell\n   cd state-storage-starter-kit\n   npm install\n   ```\n   Create a `.env` file in the project so you can add your wallet key and contract address in there for this project to use.  Make sure you have enough tFIL in your wallet for testing.\n   ```shell\n   PRIVATE_KEY=<your-wallet-key>\n   ```\n\n3. Deploy the Data Management Contract\n\n   Let's deploy the data management contract to the Filecoin calibration network.\n\n   ```\n   npx hardhat run scripts/dmc/deploy.js --network calibration\n   ```\n   Copy & paste the smart contract address and add it to your `.env` file. \n   ```\n   DMC_ADDR=<your-dataManagementContract-address>\n   ```\n\n4. Run the relayer daemon \n\n   The relayer will listen to the `BlobLoadReq` event emitted from the DMC. \n\n   ```\n   npx hardhat run scripts/relayer.js\n   ```\n\n5. Simulate the client to send a request to load an NFT metadata JSON file from IPFS.\n\n   > **Note:**\n   > In this PoC, we only consider processing the request to retrieve small data (under 256 kb) from IPFS, such as a metaData.json or text file.\n\n   You need to add your CID in the `scripts/client/sendRequest.js` . \n\n   ```\n   const cid = '<replace the CID you want to retreive from IPFS>';\n   ```\n\n   Then run the `scripts/client/sendRequest.js` to send the request to the Data Management Contract. Once the transaction is executed on chain, a `LoadBlobReq` event will be emitted carrying the following args:\n   - **correlationId**:can be used to check the request status in the smart contract.\n   - **cidHex**\uff1a CID in hexString format.\n   - reward\n   - timeout\n\n   ```shell\n   npx hardhat run scripts/client/sendRequest.js\n   ```\n   The expected output looks like this:\n   ```\n   0xb1ed3d8944953e9217d4f22d80ce5400e1727e7b62662010bd63fb193f0c3c32\n   requestBlobLoad transaction is confirmed on Chain.\n   Event args 4,0x00015512204aac179adc23fded7923cd9d06b2057637d03fe2da9d2fbcd5a7eb59473f6b48,1000000000000000000,1000000000000000000\n   ```\n\n6. Relayer will capture the `LoadBlobReq` event and process the request\n\n   Once there is a `BlobLoadReq` emitted, the relayer will \n\n   - read the CID in the log \n   - fetch the content from a IPFS node\n   - send the data to DMC for this request \n\n7. Once the data process is finished, the client can check the status of their request.\n\n   In step-5, there is a `correlationId` being emitted and it represents your request in the smart contract. So we can use it to check the status of the client's request. \n   In `script/client/checkRequestStatus.js `, add the `correlationId` from step-5 and run the script to check the status of your request.\n\n   ```shell\n   npx hardhat run scripts/client/checkRequestStatus.js\n   ```\n   The expected output looks like this:\n   ```\n   Request status:  1\n   Requested CID:  bafkreickvqlzvxbd7xwxsi6ntudleblwg7id7yw2tux3zvnh5nmuop3lja\n   ```\n\n8. After the client's data is served in the smart contract, the client can call the `retrieve` function to acquire data inside the smart contract to process.\n\n   In the `retrieve` function, data can be returned or be re-sent to another smart contract to process using `delegateCall`.  It's up to builders to build more logic here to handle their own unique use case.\n\n\n## Contributing\n\nContributions to the project are welcome! If you find any issues, have suggestions for improvements, or would like to add new features, please feel free to open an issue or submit a pull request. Make sure to follow the established coding conventions and provide clear descriptions for your contributions.\n\n## License\n\nThe project is available under the [MIT License](LICENSE). Feel free to use, modify, and distribute the code as per the terms of the license.\n", "release_dates": []}, {"name": "statediff", "description": "State Inspector \ud83d\udd75\ufe0f\u200d", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# State exploration for filecoin (lotus centric)\n\nThis tool provides functionality for exploration and comparing changes to filecoin state.\n\n**Contents**\n\n- [Installation](#installation)\n- [Usage](#usage)\n- [API](#API)\n- [License](#license)\n\n\n## CLI\n\n```bash\ngo get github.com/filecoin-project/statediff/cmd/statediff\n```\n\n### Usage\n\nSee what state change is expected by a [test vector](https://github.com/filecoin-project/test-vectors):\n\n```\nstatediff vector --file vector.json \n```\n\nSee what state changed on the local lotus chain across a block or message:\n\n```\nstatediff chain --expand-actors all bafy...\n```\n\nCompare two roots in a CAR\n```\nstatediff car --file export.car <left CID> <right CID>\n```\n\n## API\n\nOther tools working with state trees can access statediff by importing `github.com/filecoin-project/statediff`.\n\n* `Diff(context.Context, blockstore.Blockstore, a, b cid.Cid, ...Option) string`\nDiff generates a textual unified diff between stateroots `a` and `b`.\nState objects are retreived out of the provided [blockstore](https://github.com/ipfs/go-ipfs-blockstore). \n  * Options can be used to control the amount of recursion / expansion performed.\n    In particular, `ExpandActors` will perform recursive introspection into each\n    individual actor account with a differing HEAD state, and `ExpandActorByCid`\n    will selectively expand actor accounts based on provided CIDs.\n\n## Web\n\nThe web viewer (`stateexplorer`) provides a JSON transformation layer and interactive\nstate tree exploration.\n\n```bash\ngit clone https://github.com/filecoin-project/statediff\ngo generate ./...\n```\nNote: you need `npm` installed for `go generate` to properly bundle frontend assets.\n\nWhen running in production, either use the provided docker image,\nor run the explorer in its self-contained-binary form\n(assets are bundled via the `go generate` above.)\n\n```\ngo run ./cmd/stateexplorer explore --bind 0.0.0.0:33333 --api $(cat ~/.lotus/token):$(cat ~/.lotus/api)\n```\n\nIf not explicitly provided as an argument, statediff/stateexplorer will attempt to locate a lotus instance running on the same host by probing your home directory.\n\nIn development mode, assets can be loaded from disk so that changes are reflected on reload.\n\n```\ngo run ./cmd/stateexplorer explore --bind 0.0.0.0:33333 --assets .\n```\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/statediff/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/statediff/blob/master/LICENSE-APACHE)\n", "release_dates": ["2021-10-21T21:53:53Z", "2021-10-21T21:37:55Z", "2021-10-21T14:52:22Z", "2021-06-30T23:31:48Z", "2021-04-29T03:53:53Z", "2021-04-29T03:15:45Z", "2021-03-04T23:10:32Z", "2021-03-04T17:14:42Z", "2021-03-04T17:03:47Z", "2021-03-04T16:45:32Z", "2021-02-22T18:36:02Z", "2021-02-22T18:19:17Z", "2021-02-22T17:51:37Z", "2020-12-23T17:30:44Z", "2020-12-23T17:04:48Z", "2020-12-22T17:26:03Z", "2020-11-13T16:42:19Z", "2020-11-13T16:24:07Z", "2020-11-12T22:00:50Z", "2020-11-12T21:53:55Z", "2020-11-12T21:12:59Z", "2020-10-16T19:38:09Z", "2020-09-16T00:56:13Z", "2020-09-11T22:57:04Z", "2020-09-10T18:14:28Z", "2020-09-09T20:06:24Z", "2020-08-24T16:02:13Z"]}, {"name": "storage-fsm", "description": "A finite state machine used for sector storage", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# NOTE: Moved to filecoin-project/lotus\n\nThe code currently lives, and is developed in https://github.com/filecoin-project/lotus/tree/next/extern/storage-fsm\n\nDO NOT OPEN PRs IN THIS REPOSITORY\n\n# storage-fsm\n\n[![](https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square)](http://ipn.io)\n[![CircleCI](https://circleci.com/gh/filecoin-project/storage-fsm.svg?style=svg)](https://circleci.com/gh/filecoin-project/storage-fsm)\n[![standard-readme compliant](https://img.shields.io/badge/standard--readme-OK-green.svg?style=flat-square)](https://github.com/RichardLitt/standard-readme)\n\n> A finite state machine used for sector storage\n\n## Disclaimer\n\nPlease report your issues with regards to storage-fsm at the [lotus issue tracker](https://github.com/filecoin-project/lotus/issues)\n\n## License\n\nThe Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](https://github.com/filecoin-project/storage-fsm/blob/master/LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](https://github.com/filecoin-project/storage-fsm/blob/master/LICENSE-MIT) or http://opensource.org/licenses/MIT)\n", "release_dates": []}, {"name": "storage.filecoin.io", "description": null, "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": []}, {"name": "sturdy-journey", "description": "Hopefully a better way to manage event / api integration between repositories.", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Sturdy Journey\n\nSturdy journey is a generic event / api handler with the goal of providing a simple way to connect automation between\nprojects in the filecoin project organization. Uses can range from helping to keep senseitive secrets out of public CircleCI\nprojects to redirect webhook events from any services, but most notably Github webhook events.\n\n## Install\n\nA kubernetes resource file is provided with our primarly deployment configured. In addtion to install the file, the secrets\nrequired for using the sturdy journey need to be installed manually. Requirements for the secrets are document in the resource\nfile.\n\nSee `./manifests/sturdy-journey.yaml` for some additional information.\n\n```\nkubectl create namespace sturdy-journey\nkubectl -n sturdy-journey apply -f ./manifests/sturdy-journey.yaml\n```\n\n## Contributing\n\nPRs accepted.\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/sturdy-journey/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/sturdy-journey/blob/master/LICENSE-APACHE)\n", "release_dates": ["2021-08-05T21:52:23Z"]}, {"name": "system-test-matrix", "description": "The Filecoin System Test Matrix is a dashboard with a detailed list of Filecoin features and behaviors and a mapping between those features and test suites, systems and subsystems that those features are related to.", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Filecoin System Test Matrix\n\n> \ud83d\udc8a\ud83d\ude0e  The \"Red Pill\" for Filecoin node implementations\n\nThe Filecoin System Test Matrix is a dashboard with a detailed list of Filecoin features and behaviors and a mapping between those features and test suites, systems and subsystems that those features are related to.\n\nThe main goal of this project is closing the discrepancy between specification and the actual state of implementations.\n\n- The *official* resource for the expected behavior of Filecoin node implementations is the Filecoin Specification [^1]. It is written as *prose* and it's quite verbose (*and that's the way it should be*).\n- The System Test Matrix can be used to evaluate the state of Filecoin node implementations (such as lotus [^2], venus [^3] etc) *at a glance* and help new contributors understand how the Filecoin network works. \n\n## Components\n\n### Behavior Catalog\n\nFilecoin contributors with domain knowledge write new behaviors (test scenarios) and submit them via a PR to this repository. The features are enumerated inside one or more large YAML files. Every scenario has an unique ID.\n\nThe default location of the catalog is: `frontend/apps/web/scripts/data`.\n\nThe catalog has it's own [README file](frontend/apps/web/scripts/data/README.md)\n\n### Test Crawler\n\nThe Test Crawler\u2122\ufe0f\u00ae (jk no trademark \ud83d\ude42) scans the repository for tests and parses test annotations (written in our custom format) that map test functions to test behaviors from the previous step. It outputs a JSON report.\n\n\ud83d\udca1 TIP: By default, the UI expects the crawler results to be placed at `frontend/apps/web/src/tests.json`\n\nThe Test Crawler has it's own [README file](test-crawler/README.md).\n\n### UI (System Test Matrix)\n\nThe **System Test Matrix** is a rich UI where you can explore the full database of behaviors and tests and perform various queries and visualizations.\n\nThe UI has it's own [README file](frontend/README.md)\n\n### CI scraper\n\nThe scraper \"scrapes\" lotus tests and their statuses from the latest CI pipeline, using the CircleCI API, and outputs them to stdout.\n\n\ud83d\udca1 TIP: By default, the UI expects the scraper results to be placed at `frontend/apps/web/src/ci.json`\n\nThe CI scraper has it's own [README file](scraper/README.md)\n\n## Deployments\n\n- Lotus System Test Matrix: https://lotus.systemtestmatrix.com/\n- Venus System Test Matrix: https://venus.systemtestmatrix.com/\n\n---\n[^1]: https://spec.filecoin.io/\n[^2]: https://github.com/filecoin-project/lotus\n[^3]: https://github.com/filecoin-project/venus\n[^4]: https://spec.filecoin.io/#section-systems.filecoin_files.piece.data-representation\n", "release_dates": []}, {"name": "taupipp", "description": "Repo about the SRS for Inner Pairing Product arguments from Filecoin and Zcash powers of tau", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Taupipp: Powers of Tau aggregator for Inner Pairing Product\n\nTaupipp is a tool that allows to aggregate two powers of tau into a combined one\nto be used as a CRS for Groth16 aggregation protocol (see [here](https://github.com/filecoin-project/bellperson/tree/feat-ipp2/src/groth16/aggregate) for more info). Specifically, it takes as\ninput:\n```\ng,g^alpha, g^(alpha^2), ... in G1\nh,h^alpha, h^(alpha^2), ... in G2\n```\nand\n```\ng,g^beta, g^(beta^2), ... in G1\nh,h^beta, h^(beta^2), ... in G2\n```\nand then outputs\n```\ng,g^alpha, g^(alpha^2), ... in G1\nh,h^alpha, h^(alpha^2), ... in G2\ng,g^beta, g^(beta^2), ... in G1\nh,h^beta, h^(beta^2), ... in G2\n```\n\nBy default, this tool will download (or read on file) Filecoin and Zcash's last\npower of tau partcipation and returns the combination of the two.\n**Note**: Groth16 CRS is more complex than shown here, this tool discard all the other components of the CRS and only concerns itself with the secret exponents bases.\n\n## Aggregate\n\nSimply run \n```\ncargo run --release --bin assemble\n```\nBy default it tries to look for the files `zcash_powers` and `filecoin_powers`\nthat corresponds to the releveant files of the powers of tau. \nIt outputs the combined power of tau to `ipp_srs` as well as **the hash of both\ninputs and output**.\n\n## Verify\n\nIf you rebuild the aggregated CRS yourself and want to check consistency with\none already published, you can run\n```\ncargo run --release --bin verify\n```\nIt looks for the file `ipp_srs` or downloads the default filecoin-zcash one and\noutputs the hash of it.\n", "release_dates": []}, {"name": "terraform-google-lily-starter", "description": null, "language": "HCL", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# lily-starter\n\nAn opinionated Terraform module to deploy Lily on the Google Cloud Platform.\n\n## Caveat\n\nConfiguring non-boot attached disks is not included. For the disk to automatically mount on VM restarts, [read the docs](https://cloud.google.com/compute/docs/disks/add-persistent-disk#configuring_automatic_mounting_on_vm_restart).\n", "release_dates": []}, {"name": "test-vectors", "description": "\ud83d\udc8e  VM and Chain test vectors for Filecoin implementations", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# [DEPRECATED] VM and chain test vectors for Filecoin implementations\n\nThis repo contains a corpus of interoperable test vectors for Filecoin implementations to test their\ncorrectness and compliance with the [Filecoin specifications](https://beta.spec.filecoin.io/), prior\nto the introduction of the FVM.\n\nSee the [fvm-test-vectors](https://github.com/filecoin-project/fvm-test-vectors/) for test vectors for network-versions  16+.\n\n## License\n\nDual-licensed under [MIT](https://github.com/filecoin-project/test-vectors/blob/master/LICENSE-MIT) + [Apache 2.0](https://github.com/filecoin-project/test-vectors/blob/master/LICENSE-APACHE)\n\n", "release_dates": ["2020-10-15T11:47:57Z", "2020-10-08T13:59:40Z", "2020-09-30T09:59:16Z", "2020-09-28T21:36:34Z", "2020-09-08T21:04:13Z"]}, {"name": "testnet-calibration", "description": "Meta info about the Calibration testnet for Filecoin developers", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Calibration Testnet\n\nCalibration was reset on Feb 19, 2021.\n\nThis page contains meta info for Filecoin developers about the Calibration testnet.\n\n![spacex--p-KCm6xB9I-unsplash](https://github.com/filecoin-project/testnet-calibration/blob/ded02ebe39ab7e9dd76e8afef84d29245e53ea4c/spacex--p-KCm6xB9I-unsplash.jpg)\n<br><sup><sub>photo by [SpaceX on Unsplash]([https://unsplash.com/@davidclode](https://unsplash.com/@spacex))<sup><sub>  \n\n\n## Overview\n\nThe Filecoin Calibration testnet is a stable testnet that follows Filecoin mainnet closely. It has fewer resets and is intended for longer-term testing efforts from storage providers and developers.\n\n- Like mainnet, Calibration supports `32 GiB`, and `64 GiB` storage sectors.\n- It has a Storage Provider auto-accepting new deals from developers (see [Resources](#resources) - *Calibration Storage Providers* below).\n\n## Join Quickstart\n\n- **Build:** https://lotus.filecoin.io/lotus/manage/switch-networks/\n- **Stats:** https://stats.calibration.fildev.network or see [Resources](#resources) - *Block Explorers* below\n- **Faucet:** https://faucet.calibration.fildev.network\n- **Snapshot:** https://snapshots.calibrationnet.filops.net/minimal/latest\n\n## User Quickstart\n\n1. Add the Calibration testnet to your wallet (e.g. MetaMask).\n    - Go to https://chainlist.org/chain/314159\n    - Click on \"Connect wallet\"\n2. Create a new account in MetaMask to use with Filecoin.\n3. Use [https://faucet.calibration.fildev.network/](https://faucet.calibration.fildev.network/) to request funds to your Ethereum address (it will be converted behind the scenes to a Filecoin f410 address)\n4. Follow the transaction in one of the recommended Calibration testnet explorers:\n    - https://calibration.filfox.info/en \n    - https://beryx.zondax.ch \n    - https://explorer.glif.io/?network=calibration\n5. Your account is now funded and can be used in Ethereum tools such as Hardhat, Foundry, Remix, etc.\n\n*Looking for a Storage Provider on Calibration?* - See https://github.com/benjaminh83/fvm-calib-deal-miners\n\n&nbsp;\n\n## Technical details\n\n**Maintainer:** [Protocol Labs](https://protocol.ai)\n\n#### **Genesis**:\n\n- CAR File: `QmY581cXXtNwHweiC69jECupu9EBx274huHjSgxPNv1zAAj`\n- Reset Timestamp: `2021-02-19T23:10:00Z`\n- Genesis Block CID: `bafy2bzaceapb7hfdkewspic7udnogw4xnhjvhm74xy5snwa24forre5z4s2lm`\n- sha1 Digest: `944c0c13172b9f552dfed5dfaffaba95113c8254`\n\n#### **Network parameters**:\n\n- Supported Sector Sizes: `32 GiB` and `64 GiB`\n- Consensus Miner Min Power: `32 GiB`\n- Epoch Duration Seconds: `30`\n- Expected Leaders per Epoch: `5`\n- WindowPoSt Proving Period: `2880`\n- WindowPoSt Challenge Window: `60`\n- WindowPoSt Period Deadlines: `48`\n- Pre-Commit Challenge Delay: `150`\n\n#### **Bootstrap peers**:\n\n```\n/dns4/bootstrap-0.calibration.fildev.network/tcp/1347/p2p/12D3KooWRLZAseMo9h7fRD6ojn6YYDXHsBSavX5YmjBZ9ngtAEec\n/dns4/bootstrap-1.calibration.fildev.network/tcp/1347/p2p/12D3KooWJFtDXgZEQMEkjJPSrbfdvh2xfjVKrXeNFG1t8ioJXAzv\n/dns4/bootstrap-2.calibration.fildev.network/tcp/1347/p2p/12D3KooWP1uB9Lo7yCA3S17TD4Y5wStP5Nk7Vqh53m8GsFjkyujD\n/dns4/bootstrap-3.calibration.fildev.network/tcp/1347/p2p/12D3KooWLrPM4WPK1YRGPCUwndWcDX8GCYgms3DiuofUmxwvhMCn\n```\n\n#### **Resources**:\n\n- **Slack Channel for Updates:** [#fil-net-calibration-discuss](https://filecoinproject.slack.com/archives/C01D42NNLMS)\n\n- **Network Status**: https://status.filecoin.io/\n- **Calibration Docs**: [https://docs.filecoin.io/networks/calibration/details/](https://docs.filecoin.io/networks/calibration/details/)\n- **Faucets**: \n  - [https://faucet.calibration.fildev.network/](https://faucet.calibration.fildev.network/)\n    - This faucet currently emits 100 tFIL per request.\n  - https://beryx.zondax.ch/faucet\n- **Block Explorers**:\n  - Filfox - [https://calibration.filfox.info/en](https://calibration.filfox.info/en)\n  - Beryx - [https://beryx.zondax.ch](https://beryx.zondax.ch) => select Calibration\n  - Glif Explorer - [https://explorer.glif.io/?network=calibration](https://explorer.glif.io/?network=calibration)\n  - Starboard - [https://fvm.starboard.ventures/](https://fvm.starboard.ventures/) => select Calibration\n  - Filscan - [https://calibration.filscan.io/](https://calibration.filscan.io/)\n- **RPC - Public Endpoints**:\n  - See https://chainlist.org/chain/314159\n  - **Glif Nodes RPC:**\n    - https://api.calibration.node.glif.io/rpc/v1\n    - web socket endpoint: wss://wss.calibration.node.glif.io/apigw/lotus/rpc/v1\n    - For Lotus Lite use `FULLNODE_API_INFO=wss://wss.calibration.node.glif.io/apigw/lotus lotus daemon --lite`\n  - **ChainStack RPC:**\n    - https://filecoin-calibration.chainstacklabs.com/rpc/v1\n    - web socket endpoint: wss://ws-filecoin-calibration.chainstacklabs.com/rpc/v1\n    - Info page: https://chainstack.com/labs/#filecoin\n  - **Ankr RPC:**\n    - https://rpc.ankr.com/filecoin_testnet\n- **Calibration Storage Providers (miners):**\n  - See https://github.com/benjaminh83/fvm-calib-deal-miners - auto-accepts storage deals\n- **SP Reputation Systems**\n  - https://calibration.filrep.io/ \n     - API example: https://api.calibration.filrep.io/api/v1/miners?region=Europe\n- **Filecoin CID Checker**:\n  - [https://calibration.filecoin.tools/](https://calibration.filecoin.tools/) - check your storage deal or piece CID\u2019s storage status\n- **Calibration Fil+ Data Cap Requests**\n  - Apply for Data Cap: https://faucet.calibration.fildev.network/\n    - (for Calibration only, on mainnet this is handled by https://filplus.storage/apply)\n  - [Fil+ Data Cap Dashboard for Calibration](https://calibration.filplus.d.interplanetary.one/)\n    - [API reference](https://documenter.getpostman.com/view/131998/Tzsim4NU#introhttps://documenter.getpostman.com/view/131998/Tzsim4NU#intro) but use http://api.calibration.filplus.d.interplanetary.one\n- **Zondax Filecoin Solidity Libs**\n  - https://www.npmjs.com/package/@zondax/filecoin-solidity\n  - https://github.com/Zondax/filecoin-solidity\n  - https://github.com/Zondax/fevm-solidity-precompiles\n- **Calibration Chain Index APIs**\n  - https://beryx.zondax.ch/ \n    - API Docs: https://docs.zondax.ch/Beryx\n    - GraphQL UI: https://docs.zondax.ch/beryx/graphql\n- **Calibration Chain Data**\n  - http://calibration.filinfo.io/\n- **MetaMask** (HowTo):\n  - Open MetaMask and add a new network:\n    - Name: Filecoin Calibration\n    - RPC URL: https://api.calibration.node.glif.io/rpc/v1\n    - ChainID: [**314159**](https://github.com/ethereum-lists/chains/blob/master/_data/chains/eip155-314159.json) (Filecoin - Calibration testnet)\n    - Currency symbol: tFIL (Test FIL).\n  - Create a new account in MetaMask to use with Filecoin.\n  - (OPTIONAL - Go to any block explorer, and enter the account to see its native Filecoin f410 address.)\n  - Use the [faucet](https://faucet.calibration.fildev.network/) to draw funds to your 0x ir f410 address\n  - Wait until the transaction gets processed by the network, and verify that the funds appear in MetaMask.\n- **Docs and Developer Tools**:\n  - [FVM Hackathon Cheatsheet](https://github.com/filecoin-project/community/discussions/585)\n  - [Filecoin Hackathon Schedule](https://hackathons.filecoin.io/)\n  - [Filecoin Docs on FVM](https://docs.filecoin.io/smart-contracts/fundamentals/the-filecoin-virtual-machine/)\n- **Snapshots**\n  - [Lightweight Calibration chain snapshot](https://lotus.filecoin.io/lotus/manage/chain-management/#lightweight-snapshot)\n\n<hr>\n\n", "release_dates": []}, {"name": "testnet-hyperspace", "description": "Meta info about the developer-focused Hyperspace testnet for Filecoin developers", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Hyperspace Testnet\n\n:warning: The Hyperspace Testnet has been **discontinued** as of May 31, 2023. :warning:\n\nPlease use the [Calibration testnet](https://github.com/filecoin-project/testnet-calibration/blob/main/README.md).\n<hr>\n\nMeta info about the Hyperspace testnet for Filecoin developers\n\n![hyperspace-testnet-image](images/hyperspace-testnet-image.png)\n\n&nbsp;\n\n## Overview\n\nThe Filecoin Hyperspace testnet is a stable testnet with fewer resets intended for developers' longer-term testing efforts.\n\n- As of Jan 16, Hyperspace will support the penultimate FEVM release, and will be upgraded to the the final FEVM release on Feb 2. ([List of FEVM releases](https://github.com/filecoin-project/ref-fvm/issues/692))\n- Hyperspace supports `512 MiB`, `32 GiB`, and `64 GiB` storage sectors with 2 miners auto-accepting new deals from developers (see [Resources](#resources) - Hyperspace Storage Providers below).\n- A comparison of Filecoin's various testnets is available in [FIP #544](https://github.com/filecoin-project/FIPs/discussions/544).\n\n\n&nbsp;\n\n## Quickstart\n\n1. Add the Hyperspace testnet to your wallet (e.g. MetaMask).\n    - Go to https://chainlist.org/chain/3141\n    - Click on \"Connect wallet\"\n2. Create a new account in MetaMask to use with Filecoin.\n3. Use https://hyperspace.yoga/#faucet to request funds to your Ethereum address (it will be converted behind the scenes to a Filecoin f4 address)\n4. Follow the transaction in one of the recommended Hyperspace testnet explorers:\n    - https://hyperspace.filfox.info/en \n    - https://beryx.zondax.ch \n    - https://explorer.glif.io/?network=hyperspace \n5. Your account is now funded and can be used in Ethereum tools such as Hardhat, Foundry, Remix, etc.\n\n## Technical details\n\n**Maintainer:** offline, unmaintained\n\n#### **Genesis**:\n\n- CAR File: `Qmbu9g75GMjbokCNHPQPXAyKZoY8NqVYtkY4PQT7Zvp2T6`\n- Reset Timestamp: `2023-01-16T6:00:00Z`\n- Genesis Block CID: `bafy2bzacebqfpeylmrl4h3pq4ofbdj2bfbw2i45fuy6qm4wxcyebpsxhrpqhu`\n- sha1 Digest: `52d82b6fcad138a726477152ff2543a91f2b83f8`\n\n#### **Network parameters**:\n\n- Supported Sector Sizes: `512 MiB` and `32 GiB` and `64 GiB`\n- Consensus Miner Min Power: `16 GiB`\n- Epoch Duration Seconds: `30`\n- Expected Leaders per Epoch: `5`\n- WindowPoSt Proving Period: `2880`\n- WindowPoSt Challenge Window: `60`\n- WindowPoSt Period Deadlines: `48`\n- Pre-Commit Challenge Delay: `10`\n\n#### **Bootstrap peers**:\n\n```\n\n```\n\n\n#### **FVM release**:\n\n- [FVM M2.1 Carbonado.3 (rr12) - Final FVM release!](https://github.com/filecoin-project/ref-fvm/issues/1372)\n- Lotus commit: [cf152e19bda7be289fd531be689279aa5f598899](https://github.com/filecoin-project/lotus/commit/cf152e19bda7be289fd531be689279aa5f598899)\n- [List of FVM releases](https://github.com/filecoin-project/ref-fvm/issues/692)\n\n#### **Resources**:\n\n- Slack Channel for Updates: [#fil-net-hyperspace-discuss](https://filecoinproject.slack.com/archives/C04JEJB82RY)\n\n- **Network Status**: https://status.filecoin.io/\n- **Hyperspace Docs**: \n- **Faucets**: \n  - https://beryx.zondax.ch/faucet\n- **Block Explorers**:\n  - Filfox - [https://hyperspace.filfox.info/en](https://hyperspace.filfox.info/en)\n  - Beryx - [https://beryx.zondax.ch](https://beryx.zondax.ch)\n  - Glif Explorer - [https://explorer.glif.io/?network=hyperspace](https://explorer.glif.io/?network=hyperspace)\n  - Starboard - [https://fvm.starboard.ventures/](https://fvm.starboard.ventures/)\n  - Filscan - [https://hyperspace.filscan.io/](https://hyperspace.filscan.io/)\n- **RPC - Public Endpoints**:\n  - **Glif Nodes RPC:**\n    - https://api.hyperspace.node.glif.io/rpc/v1\n    - web socket endpoint: wss://wss.hyperspace.node.glif.io/apigw/lotus/rpc/v1\n    - For Lotus Lite use `FULLNODE_API_INFO=wss://wss.hyperspace.node.glif.io/apigw/lotus lotus daemon --lite`\n  - **ChainStack RPC:**\n    - https://filecoin-hyperspace.chainstacklabs.com/rpc/v0\n    - web socket endpoint: wss://ws-filecoin-hyperspace.chainstacklabs.com/rpc/v0\n    - Info page: https://chainstack.com/labs/#filecoin\n  - **Ankr RPC:**\n    - https://rpc.ankr.com/filecoin_testnet\n- **Hyperspace Fil+ Data Cap Requests**\n  - Apply for Data Cap:  \n  - Check Data Cap allocations: \n  - [Fil+ Data Cap Dashboard for Hyperspace](https://hyperspace.filplus.d.interplanetary.one/notaries/t01227)\n    - [API reference](https://documenter.getpostman.com/view/131998/Tzsim4NU#introhttps://documenter.getpostman.com/view/131998/Tzsim4NU#intro) but use http://api.hyperspace.filplus.d.interplanetary.one\n- **Hyperspace Storage Providers (miners) auto-accepting storage deals / simulating faults:**\n  - \n- **SP Reputation Systems**\n  - https://hyperspace.filrep.io/ - info about deals and sectors is currently being updated\n     - API example: https://api.hyperspace.filrep.io/api/v1/miners?region=Europe\n- **Filecoin CID Checker**:\n  - [https://hyperspace.filecoin.tools/](https://hyperspace.filecoin.tools/) - check your deal or piece CID\u2019s storage status\n- **Zondax Filecoin Solidity Libs**\n  - https://www.npmjs.com/package/@zondax/filecoin-solidity\n  - https://github.com/Zondax/filecoin-solidity\n  - https://github.com/Zondax/fevm-solidity-precompiles\n- **Hyperspace Chain Index APIs**\n  - https://beryx.zondax.ch/ \n    - API Docs: https://docs.zondax.ch/Beryx\n    - GraphQL UI: https://docs.zondax.ch/beryx/graphql\n- **MetaMask** (HowTo):\n  - Open MetaMask and add a new network:\n    - Name: Filecoin Hyperspace\n    - RPC URL: https://api.hyperspace.node.glif.io/rpc/v1\n    - ChainID: [**3141**](https://github.com/ethereum-lists/chains/blob/master/_data/chains/eip155-3141.json) (Filecoin - Hyperspace testnet)\n    - Currency symbol: tFIL (Test FIL).\n  - Create a new account in MetaMask to use with Filecoin.\n  - (OPTIONAL - the faucet accepts 0x style addresses now) Go to https://explorer.glif.io/ethereum/, and select the account to see its f4 address.\n  - Use the [faucet]() to draw funds to your f4 (0x style addresses are translated automatically to f4's in the backend) or alternatively use `lotus send` to transfer funds to the f4 address.\n  - Wait until the transaction process, and verify that the funds appear in MetaMask.\n  - Create another new account in MetaMask, (optional) obtain its f4 address again.\n  - Use MetaMask to send funds from your first account to your second account.\n  - **Notes on MM**\n    - Note that you may need to increase the gas limit manually because there's something strange going on with gas estimation at the moment.\n  - **Note on GLIF**:\n    - The GLIF explorer seems to have some problems with f4 addresses right now, please refer to the #fil-net-hyperspace-discuss for questions/solutions\n- **Docs and Developer Tools**:\n  - [Space Warp Hackathon Schedule](https://ethglobal.com/events/spacewarp#schedule)\n  - [Space Warp Developer Cheat Sheet](https://docs.google.com/document/d/1EecX8XOqOF6MNaouXL0qZAuCEK1WF5UWA5LMSlWe3RI/edit#)\n  - [FEVM Hardhat Kit, Filecoin Solidity library and Data DAO example](https://docs.filecoin.io/developers/smart-contracts/hardhat/)\n  - [Space Warp Developer Resources](https://spacewarp.fvm.dev/#resources)\n- **Snapshots**\n\n<hr>\n\n:warning: [TODO - SAMPLE INFO BELOW] :warning:\n\n\n- [Status page and incidents](https://filecoin.statuspage.io/)\n- [Stats dashboard](https://stats.filecoin.io/)\n- [Block explorer: Filscan](https://filscan.io/)\n\n:warning: [TODO - SAMPLE INFO ABOVE] :warning:\n", "release_dates": []}, {"name": "testnet-wallaby", "description": "Meta info about the Wallaby testnet for FVM developers", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": ":warning: The Hyperspace Testnet has been **discontinued** as of May 31, 2023. :warning:\n\nPlease use the [Calibration testnet](https://github.com/filecoin-project/testnet-calibration/blob/main/README.md).\n\nWallaby has been shut down until further notice and Hyperspace is the main testnet for Filecoin developers and testing FEVM releases. \n\nIn the future, Wallaby will be used for testing bleeding-edge Wasm FVM releases (see the FVM Roadmap at https://fvm.filecoin.io).\n\n# Wallaby Testnet\n\nMeta info about Wallaby Weekly, a *bleeding edge* testnet for FVM development\n\n- Not sure which testnet to use? Start with **[Hyperspace](https://github.com/filecoin-project/testnet-hyperspace)** - a stable testnet for Filecoin developers. **Wallaby is only for future experimental releases.**\n\n- [Info about all testnets](https://github.com/filecoin-project/FIPs/discussions/544)\n\n![david-clode-ko-v55B2xOw-unsplash](https://user-images.githubusercontent.com/1017762/189190624-cb1179cd-4b1e-437c-947b-493ebd2568f0.png)\n<br><sup><sub>photo by [David Clode on Unsplash](https://unsplash.com/@davidclode)<sup><sub>\n\n&nbsp;\n\n## Quickstart\n\n1. Add the Wallaby testnet to your wallet (e.g. MetaMask).\n    - Go to https://chainlist.org/chain/31415\n    - Click on \"Connect wallet\"\n2. Create a new account in MetaMask to use with Filecoin.\n3. Use the [faucet](https://wallaby.network/#faucet) to draw funds to your Ethereum address (it will be converted behind the scenes to a Filecoin f4 address)\n4. Follow the transaction in one of the recommended Wallaby testnet explorers:\n    - https://wallaby.filfox.info/en\n    - https://explorer.glif.io/ (select Wallaby from the networks dropdown)\n5. Your account is now funded and can be used in Ethereum tools such as Hardhat, Foundry, Remix, etc.\n\n## Technical details\n\n**Maintainer:** offline, unmaintained\n\n**Genesis**:\n\n- CAR File: `QmavrNRhTMbUNFtSJA6VVMMcSyCwQzUpJbSPRjZzKjy3Jg`\n- Reset Timestamp: `2023-01-09T14:54:09Z`\n- Genesis Block CID: `bafy2bzaceaq7a2nole6qaje33tydbvumeykjs4vjh2sh7hunsxwdsblpibxf2`\n- sha1 Digest: `104a283cf7f3e805790c1e4fc02e50ed0f673981`\n\n**Network parameters**:\n\n- Supported Sector Sizes: `512 MiB` and `32 GiB` and `64 GiB`\n- Consensus Miner Min Power: `16 GiB`\n- Epoch Duration Seconds: `30`\n- Expected Leaders per Epoch: `5`\n- WindowPoSt Proving Period: `2880`\n- WindowPoSt Challenge Window: `60`\n- WindowPoSt Period Deadlines: `48`\n- Pre-Commit Challenge Delay: `10`\n\n**Bootstrap peers**:\n\n```\n\n```\n\n**FVM release**:\n\n- [FVM M2.1 Carbonado (r10)](https://github.com/filecoin-project/ref-fvm/issues/1052)\n- Lotus commit: [f2d5afc09431daea43291c52e38945b3147a7079](https://github.com/filecoin-project/lotus/commit/f2d5afc09431daea43291c52e38945b3147a7079)\n- [List of FVM releases](https://github.com/filecoin-project/ref-fvm/issues/692)\n\n**Resources**:\n\n- Slack Channel for Updates: [#fil-net-wallaby-discuss](https://filecoinproject.slack.com/archives/C03KGBTJ0BY)\n\n- **Wallaby Docs**:\n- **Faucet**: \n- **Block Explorers**:\n  - [https://wallaby.filscan.io](https://wallaby.filscan.io)\n  - [https://explorer.glif.io/actor/?network=wallaby](https://explorer.glif.io/actor/?network=wallaby)\n- **Filecoin CID Checker**: [https://wallaby.filecoin.tools](https://wallaby.filecoin.tools/) - check your deal CID\u2019s storage status. This is **not a real-time** application and refreshes every 5 minutes.\n- If you want to play with marketdeals on your own you can access them directly [here](https://marketdeals-wallaby.s3.ap-northeast-1.amazonaws.com/StateMarketDeals.json)\n\n- **JSON RPC API - Public Endpoints**:\n  - Limited to all read API calls + `MPoolPush` (for sending already signed messages)\n  - https://wallaby.node.glif.io/rpc/v0 (for stable API v0)\n  - https://wallaby.node.glif.io/rpc/v1 (for new API v1 - see [API README](https://github.com/filecoin-project/lotus/blob/422f66776fa07827f2cfa9d2f8142ef29dcd2a95/api/README.md))\n  - web socket endpoint: wss://wss.wallaby.node.glif.io/apigw/lotus/rpc/v0\n- **JSON RPC API - Private Endpoints**:\n  - Protected by JWT authorization. Ping @glif-nodes-team in wallaby slack channels to obtain the token.\n  - https://wallaby.dev.node.glif.io/archive/lotus/rpc/v0\n  - https://wallaby.dev.node.glif.io/archive/lotus/rpc/v1\n- **Wallaby SPs auto-accepting storage deals:**\n  - \n- **Schedule**: \n  - Normally reset every Tuesday with [bleeding edge FEVM releases](https://github.com/filecoin-project/ref-fvm/issues/692)\n  - Follow [#fil-net-wallaby-discuss](https://filecoinproject.slack.com/archives/C03KGBTJ0BY) for updates\n- **MetaMask** (HowTo): \n  - Open MetaMask and add a new network:\n    - Name: Filecoin Wallaby\n    - RPC URL: https://wallaby.node.glif.io/rpc/v0 (once the public RPC has been updated, otherwise use appropriate private URL - **please see the note below**)\n    - ChainID: [**31415**](https://github.com/ethereum-lists/chains/blob/master/_data/chains/eip155-31415.json) (Wallaby's )\n    - Currency symbol: tFIL (Test FIL).\n  - Create a new account in MetaMask to use with Filecoin.\n  - (OPTIONAL - the faucet accepts 0x style addresses now) Go to https://explorer.glif.io/ethereum/, and select the account to see its f4 address.\n  - Use the [faucet](https://wallaby.filtest.network/#faucet) to draw funds to your f4 (0x style addresses are translated automatically to f4's in the backend) or alternatively use `lotus send` to transfer funds to the f4 address.\n  - Wait until the transaction process, and verify that the funds appear in MetaMask.\n  - Create another new account in MetaMask, (optional) obtain its f4 address again.\n  - Use MetaMask to send funds from your first account to your second account. \n  - **Notes on MM**\n    - Note that you may need to increase the gas limit manually because there's something strange going on with gas estimation at the moment.\n  - **Note on GLIF**:\n    - The GLIF explorer seems to have some problems with f4 addresses right now, please refer to the #fil-net-wallaby-discuss for questions/solutions \n\n\n<hr>\n\n:warning: [TODO - SAMPLE INFO BELOW] :warning: \n\n- [Latest chain snapshot (pruned)](https://fil-chain-snapshots-fallback.s3.amazonaws.com/mainnet/minimal_finality_stateroots_latest.car)\n- [Latest chain snapshot (full)](https://fil-chain-snapshots-fallback.s3.amazonaws.com/mainnet/complete_chain_with_finality_stateroots_latest.car)\n- [Status page and incidents](https://filecoin.statuspage.io/)\n- [Stats dashboard](https://stats.filecoin.io/)\n- [Block explorer: Filscan](https://filscan.io/)\n\n:warning: [TODO - SAMPLE INFO ABOVE] :warning: \n", "release_dates": []}, {"name": "tla-f3", "description": "PlusCal/TLA+ spec for GossiPBFT", "language": "TLA", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# F3 (Fast Finality Filecoin) PlusCal/TLA+ spec\n\nCurrently, the Filecoin Expected Consensus protocol offers only probabilistic finality. By convention, a tipset 900 epochs old (approximately 7.5h) is considered \"final\", based on a protocol parameter that determines the longest fork that a node will consider re-organising.\n\nThe long time to finality considerably hinders the user experience and limits applications built on Filecoin, and the fact that finality is only probabilistic is a significant risk to any external effects or cross-chain transactions. \n\nThe goal of the F3 project is to introduce deterministic finality with low latency, equaling 1 epoch on expectation. \n\n## Project details\n\nRefer to the [F3 Indexer](https://docs.google.com/document/d/10IE6hfK16dbrH9lPWlPS7vGcFRRTAtYzjXEEeYhdkek/edit#heading=h.7u0l42ugupr9) for additional information and links.\n\n## This repository\n\nThis repository stores a PlusCal/TLA+ specification for GossiPBFT.\n", "release_dates": []}, {"name": "TODOnotes", "description": "Filecoin Docs", "language": null, "license": null, "readme": "[![Contributors][contributors-shield]][contributors-url]\r\n[![Forks][forks-shield]][forks-url]\r\n[![Issues][issues-shield]][issues-url]\r\n[![MIT License][license-shield]][license-url]\r\n[![Website status][website-status]][website-status-url]\r\n\r\n<br>\r\n\r\n<picture align=center>\r\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://bafybeiaqdbd5zbl55x5vjmkwpjhqapt3ks3q4ykaclqkajhsdwyzlbz3g4.ipfs.w3s.link/Filecoin-logo-blue-white.svg\">\r\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://bafybeihuk3hsy6d43dn36tqnvf6tvzleiijd5idbf2q7maw3nshnfm6wiu.ipfs.w3s.link/filecoin-logo-black-type.svg\">\r\n    <img alt=\"The Filecoin project logo.\" src=\"https://bafybeihuk3hsy6d43dn36tqnvf6tvzleiijd5idbf2q7maw3nshnfm6wiu.ipfs.w3s.link/filecoin-logo-black-type.svg\">\r\n</picture>\r\n\r\n<br>\r\n<br>\r\n\r\n<h4 align=\"center\"> This repository manages the documentation for the <a href=\"https://filecoin.io\">Filecoin network</a>. This repo also contains the build scripts and tools to create the Filecoin docs website. <a href=\"https://docs.filecoin.io/\">Explore the docs \u2192</a></h4>\r\n\r\n<!-- /HEADER -->\r\n\r\n\r\n\r\n<!-- TABLE OF CONTENTS -->\r\n## Table of contents\r\n\r\n- [Getting started](#getting-started)\r\n    - [Prerequisites](#prerequisites)\r\n    - [Installation](#installation)\r\n- [About the project](#about-the-project)\r\n    - [Files and folders](#files-and-folders)\r\n- [Contributing](#contributing)\r\n    - [Video guides for site management](#video-guides-for-site-management)\r\n    - [Front-matter variables](#front-matter-variables)\r\n        - [Title](#title)\r\n        - [Description](#description)\r\n        - [Lead](#lead)\r\n        - [Weight](#weight)\r\n        - [Menu](#menu)\r\n            - [Sidebar menu](#sidebar-menu)\r\n            - [Sub-menu](#sub-menu)\r\n        - [Aliases](#aliases)\r\n        - [Draft](#draft)\r\n    - [Features](#features)\r\n        - [Archived content](#archived-content)\r\n        - [Code tabs](#code-tabs)\r\n        - [Tooltips](#tooltips)\r\n- [Issues](#issues)\r\n- [License](#license)\r\n- [Acknowledgments](#acknowledgments)\r\n<!-- /TABLE OF CONTENTS -->\r\n\r\n\r\n\r\n<!-- GETTING STARTED-->\r\n## Getting Started\r\n\r\nFollow these simple example steps to get a local version of the site up and running.\r\n<!-- /GETTING STARTED-->\r\n\r\n\r\n\r\n<!-- PREREQUISITES -->\r\n### Prerequisites\r\n\r\nTo run these commands, you must have [NPM installed](https://www.npmjs.com/). If you already have NPM installed, make sure you are running the latest version:\r\n\r\n```shell\r\nnpm install npm@latest -g\r\n```\r\n<!-- /PREREQUISITES -->\r\n\r\n\r\n\r\n<!-- INSTALLATION -->\r\n### Installation\r\n\r\nFollow these steps to run a copy of this site on your local computer. \r\n\r\n1. Clone this repo:\r\n\r\n    ```shell\r\n    git clone https://github.com/filecoin-project/filecoin-docs\r\n    ```\r\n\r\n1. Move into the new folder and download the dependencies:\r\n\r\n    ```shell\r\n    cd filecoin-docs\r\n    npm install\r\n    ```\r\n\r\n1. Build and serve the project locally: \r\n\r\n    ```shell\r\n    npm run start\r\n    ```\r\n    \r\n1. Visit [localhost:1313](http://localhost:1313) to view the site.\r\n1. Press `CTRL` + `c` in the terminal to stop the local server.\r\n\r\nIf you want to just build the site but _not_ serve it locally, run:\r\n\r\n```shell\r\nnpm run build\r\n```\r\n\r\nA static site will be built and stored in the `/public` directory.\r\n<!-- /INSTALLATION -->\r\n\r\n\r\n\r\n<!-- ABOUT THE PROJECT -->\r\n## About the project\r\n\r\n<picture align=center>\r\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://bafybeick5a6esj6qqtw35jdgrouyn3nrg5ckrmjptuvx3jjjnih7vkdzre.ipfs.w3s.link/filecoin-homepage-dark.png\">\r\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://bafybeib2c67ernhjnqzrdcmtzn5cvi45qrftz6qlo37wr5cnnhvrs6ocg4.ipfs.w3s.link/filecoin-homepage-light.png\">\r\n    <img alt=\"The Filecoin project logo.\" src=\"https://bafybeib2c67ernhjnqzrdcmtzn5cvi45qrftz6qlo37wr5cnnhvrs6ocg4.ipfs.w3s.link/filecoin-homepage-light.png\">\r\n</picture>\r\n\r\nThis repository manages the documentation for the Filecoin project. This repo also contains the build scripts and tools to create the Filecoin docs website and the API documentation. If you want to learn about Filecoin, how it works, or how to build on it, then you're in the right place.\r\n\r\n### Files and folders\r\n\r\nThis section lists the various files and folders and defines the purpose for each of them.\r\n\r\n| Name | Purpose |\r\n| --- | --- |\r\n| `.git`, `.github` | Manage the git configurations and contain information for GitHub constant integrations. |\r\n| `README.md` | This file. Acts as an introduction to this repo and how to spin up a local copy of the `docs.filecoin.io` site. |\r\n| `archetypes/` | Used by Hugo to programmatically create new pages. |\r\n| `assets/` | Assets like JavaScript and fonts used by Hugo to create the static site. These assets are not explorable in a built site. You must reference them in code before building the site. |\r\n| `babel.config.js` | A configuration file used for the Babel JS compiler. |\r\n| `config/` | Contains the configuration files for Hugo. You can manage things like the top-bar menu and site title within this directory. |\r\n| `content/` | This is where all the `.md` files live that control the content of this site. Most contributions happen in this directory. |\r\n| `data/` | You can supply extra variables for Hugo to use when building pages in this directory. These variables act just like front-matter variables. See [Data Templates](https://gohugo.io/templates/data-templates/) in the Hugo docs for more info. |\r\n| `functions/` | Functions callable from any template, partial, or shortcode within Hugo. |\r\n| `i18n/` | Contains files specific to managing different languages. |\r\n| `layouts/` | This is where web developers will likely spend most of their time. This folder contains the shortcodes and partials that Hugo uses to scaffold and build the site. |\r\n| `node_modules/` | Where NPM throws its packages. If you see this in GitHub, something's gone wrong. It should only exist on your computer after you run `npm install`. |\r\n| `package-lock.json` | One of the NPM configuration files. Specify which version of packages to download. |\r\n| `package.json` | Another one of the NPM configuration files. Specifies which packages to download but doesn't specify which _version_ of the package to grab.\r\n| `resources/` | A cache where Hugo throws generated files like CSS and JSON after `npm run build` has been called. Unless `npm run clean` is called, Hugo will re-use these files when calling `npm run build`. |\r\n| `static/` | Images, CSS, fonts, and other misc files available at `docs.filecoin.io/` when the site is built. For example, `docs.filecoin.io/site.webmanifest`.\r\n| `theme.toml` | A Hugo configuration file that specifies which theme to use. This file should not change that often. |\r\n<!-- /ABOUT THE PROJECT -->\r\n\r\n\r\n\r\n<!-- CONTRIBUTING -->\r\n## Contributing\r\n\r\nWant to help out? Pull requests (PRs) are always welcome! If you want to help out but aren't sure where to start, check out the [issues board](https://github.com/filecoin-project/filecoin-docs/issues).\r\n\r\n### Video guides for site management\r\n\r\n\r\nHere's a collection of guides you can use to help manage and contribute to this site:\r\n\r\n- [Managing the top-bar navigation](https://bafybeidn4wxz44rssgdlu3p2dzh4tbyevuqd27xv7avioyf2m65jzlhnj4.ipfs.w3s.link/DaaS%20-%20Managing%20the%20topbar%20navigation%20-%20HD%201080p.mov)\r\n- [Move a page and add a redirect](https://bafybeibuwipv4rk2tzcqvouu2xlnebh4d7ol47mvmegtispbvlcruuwmhi.ipfs.w3s.link/Move%20and%20page%20and%20add%20a%20redirect.mp4)\r\n\r\n### Creating sidebar labels and content pages\r\n\r\nTo create sidebar labels, use the `npm create` command:\r\n\r\n```shell\r\nnpm run create -- --kind sidebar storage-provider/hardware \r\n```\r\n\r\nThe above command will create the folder structure and a `_index.md` file containing the front-matter for the label.\r\n\r\n### Creating content pages\r\n\r\nTo create content pages, use the `npm create` command:\r\n\r\n```shell\r\nnpm run create -- --kind page storage-provider/hardware/architectures\r\n```\r\n\r\nThe above command will create a folder and an `index.md` file containing the front-matter for that page, that can then be edited.\r\n\r\nIf you make a mistake and need to remove a page, or section, just delete the folder.\r\n\r\nTo move content from one place to another, create the new pages using `npm create`, copy the text across to the newly created pages and delete the originals.\r\n\r\n\r\n\r\n### Front-matter variables \r\n\r\nThe front-matter is that small section of metadata you can find at the top of each `.md` file within the [`/content` folder](https://github.com/filecoin-project/filecoin-docs/tree/main/content/en). Each variable has a specific purpose, and while not all are necessary, it's useful to know what they do and why they exist. \r\n\r\n```YAML\r\n---\r\ntitle: \"Get started\"\r\ndescription: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to maintaining the Filecoin blockchain, obtaining storage services, and receiving rewards in the process. This section walks you through how to get started, build a node, and create a simple application.\"\r\nlead: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to maintaining the Filecoin blockchain, obtaining storage services, and receiving rewards in the process. This section walks your through how to get started, build a node, and create a simple application.\"\r\nmenu:\r\n    getstarted:\r\n        parent: \"getstarted-overview\"\r\naliases:\r\n    - /get-started\r\n    - /how-to/install-filecoin\r\n---\r\n```\r\n\r\nIt's also good to note that we use the YAML as our front-matter format. We could use [JSON or TOML](https://gohugo.io/content-management/front-matter#front-matter-formats) if we really wanted, but we found YAML the easiest to read. Plus, _yammal_ is fun to say.\r\n\r\nThis list has been created in order of commonality; variables you will come across most often are closer to the top of this list.\r\n\r\n#### Title\r\n\r\nThe `title` variable defines what the `<h1>` tag on this page will say, along with the contents of `<title>` in this page's `<head>`. This variable also defines what is shown as the sidebar item; however, this can be overwritten in the `menus` config file.\r\n\r\n```YAML\r\n---\r\ntitle: \"Get started\"\r\n---\r\n```\r\n\r\n![](./static/images/front-matter-variables-title.png)\r\n\r\n#### Description\r\n\r\nThe `description` variable defines what is in the [meta `<description>`](https://moz.com/learn/seo/meta-description) tag within the `<head>` tag of this page's HTML.  This description often shows up in search engine results, and social network embeds. This description is meant to give the reader an idea of the content on this page and how it relates to their search query.\r\n\r\n```YAML\r\n---\r\ndescription: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to [...]\"\r\n---\r\n```\r\n\r\n![](./static/images/front-matter-variables-description.png)\r\n\r\n#### Lead\r\n\r\nThe `lead` variable defines the content of the first paragraph on a page. This is usually an introduction, informing the reader what this page is referring to, what they're about to learn, and any prerequisites for understanding the content on this page. Often, the content of this variable is the same as the `description` variable.\r\n\r\n```YAML\r\n---\r\nlead: \"The Filecoin Network is made with storage providers and clients. They make deals and contribute to [...]\"\r\n---\r\n```\r\n\r\n![](./static/images/front-matter-variables-lead.png)\r\n\r\n#### Weight\r\n\r\nThe `weight` variable defines where this page or menu item should be in a menu. The lower the number, the closer to the start of the menu this page will be. If set, `weight` should be non-zero, as `0` is interpreted as an unset weight. There is no upper limit for a weight value.\r\n\r\nIn the top-bar menu, a lower number will cause the menu item to be further to the left in a regular view or further to the top in a mobile view.\r\n\r\nThis example is from the `/config/_default/menus/menus.en.toml` file:\r\n\r\n```\r\n[[main]]\r\n  name = \"About Filecoin\"\r\n  url = \"/about-filecoin/what-is-filecoin\"\r\n  weight = 10\r\n  \r\n[[main]]\r\n  name = \"Networks\"\r\n  url = \"/networks/overview\"\r\n  weight = 20\r\n\r\n[[main]]\r\n  name = \"Get started\"\r\n  url = \"/get-started/overview\"\r\n  weight = 30\r\n```\r\n\r\n![](./static/images/front-matter-variables-weight-1.png)\r\n\r\nIn the sidebar menu, a lower number will cause the menu item or page to be higher up.\r\n\r\n![](./static/images/front-matter-variables-weight-2.png)\r\n\r\nThe weight of a page also defines the _next_ and _previous_ buttons at the bottom of the page. The _previous_ page will be the page with the closest weight _below_ the current page's weight. The _next_ page will be the page with the closest weight _above_ the current page's weight.\r\n\r\n![](./static/images/front-matter-variables-weight-3.png)\r\n\r\n#### Menu\r\n\r\nThe `menu` variable defines which sidebar menu this page is assigned to, along with which sub-menu this page falls under. This variable is made of three parts:\r\n\r\n1. The `menu` delimiter. This tells Hugo that were are about to define the menu object for this page.\r\n1. The section/top-bar menu that this page falls under.\r\n1. The sub-menu within the sidebar that this page falls under.\r\n\r\n```YAML\r\n---\r\nmenu:\r\n    store:\r\n        parent: \"store-filecoin-plus\"\r\n---\r\n```\r\n\r\n##### Sidebar menu\r\n\r\nEach section has its own sidebar menu. The name of each sidebar menu is usually a lowercase version of the name of the section. For sections that contain a space, the sidebar menu name is a lowercase version of the section without the space:\r\n\r\n| Section | Sidebar menu name |\r\n| --- | --- |\r\n| About Filecoin | `about` |\r\n| Build | `build` |\r\n| Get started | `getstarted` |\r\n| Networks | `networks` |\r\n| Reference | `reference` |\r\n| Storage provider | `storageprovider` |\r\n| Store | `store` |\r\n\r\n\r\n```YAML\r\n---\r\nmenu:\r\n    storageprovider:\r\n---\r\n```\r\n\r\n##### Sub-menu\r\n\r\nYou can think of a sub-menu as the dropdown item in the sidebar menu. Sub-menus are defined in `/config/\\_default/menus/menus.en.toml`. \r\nEach sub-menu is a _child_ of a sidebar menu. A sidebar menu can contain multiple sub-menus, but a sub-menu can only belong to one sidebar menu.\r\n\r\nSub-menus are made up of:\r\n\r\n- `name`: The visible text shown to the user.\r\n- `weight`: How high or low this sub-menu is shown within the sidebar.\r\n- `identifier`: A unique string used in the front-matter to specify this particular sub-menu.\r\n- `url`: The default page a user will go to if they click on this sub-menu link.\r\n\r\n```YAML\r\n[[about]]\r\n  name = \"Basics\"\r\n  weight = 10\r\n  identifier = \"about-filecoin-basics\"\r\n  url = \"/about-filecoin/what-is-filecoin\"\r\n\r\n...\r\n\r\n[[networks]]\r\n  name = \"Overview\"\r\n  weight = 10\r\n  identifier = \"networks-overview\"\r\n  url = \"/networks/\"\r\n\r\n...\r\n\r\n[[getstarted]]\r\n  name = \"Overview\"\r\n  weight = 1 \r\n  identifier = \"getstarted-overview\"\r\n  url = \"/get-started/overview/\"\r\n```\r\n\r\nTo assign a page to a sub-menu, you must supply both the menu object name and the `identifier` value into the front-matter:\r\n\r\n```YAML\r\nmenu:\r\n    getstarted:\r\n        parent: \"getstarted-overview\"\r\n```\r\n\r\nThe identifier of each sub-menu is usually the menu object name and the title of the sub-menu, all in lowercase with dashes `-`:\r\n\r\n![](/.static/images/front-matter-variables-sub-menus.png)\r\n\r\n#### Aliases\r\n\r\nThe `aliases` variable defines URLs will redirect to this page. Each page can have multiple `aliases`, but each alias can only appear once throughout all the `.md` files within the `/content` folder.\r\n\r\nFor example, the `/get-started/overview` page can list `/get-started` as one of its aliases. However, no other page can list `/get-started` as an alias. If you attempt to assign another page the `/get-started` alias, Hugo will throw an error when you or Fleek try to build the website.\r\n\r\nAliases only work for internal links. You cannot assign a redirect to an external website using an alias.\r\n\r\n```YAML\r\n---\r\naliases:\r\n    - /get-started\r\n    - /how-to/install-filecoin\r\n---\r\n```\r\n\r\n#### Draft\r\n\r\nThe `draft` variable, when set to `true`, will hide the page from all site navigation. The page will still be accessible by visiting its URL. If this variable is not set, Hugo will assume that it is set to `false`.\r\n\r\n```YAML\r\ndraft: true\r\n```\r\n\r\nThis feature is generally used when we need to share content that isn't fully complete, but some users could benefit from its information at this exact moment.\r\n\r\n### Features\r\n\r\nThis project contains some handy features you can include within your project.\r\n\r\n#### Archived content\r\n\r\nOld pages can be archived and hidden from the sidebar view. However, the can still be accessed for historical purposes. \r\n\r\n![](/.static/images/archived-page.png)\r\n\r\nTo archive a page:\r\n\r\n1. Move the page and any associated images into the `/content/en/archive` directory.\r\n1. Add an alias redirect using the original location of this file:\r\n\r\n    ```markdown\r\n    ---\r\n    ...\r\n    aliases:\r\n        - \"/build/tools/filecoin-pinning-services/\"\r\n    ---\r\n    ```\r\n\r\n1. Add the following shortcode to the top of the page, just below the front-matter\r\n\r\n    ```markdown\r\n    ---\r\n\r\n    {{< archived-content >}}\r\n\r\n    ...\r\n    ```\r\n\r\nTake a look at the `/content/en/archive` directory for examples.\r\n\r\n<!-- #### Code tabs -->\r\n\r\n\r\n\r\n#### Tooltips\r\n\r\nTo make understanding terms in the docs a bit easier, users can hover over certain terms to get a short definition. These descriptions are located within a `dict` variable at the top of the `layouts/shortcodes/tooltip.html` shortcode:\r\n\r\n```go\r\n<!-- Create array/map of all possible tooltips. -->\r\n{{ $tooltips := dict\r\n    \"dApps\" \"Decentralized applications that don't rely on centralized infrastructure.\"\r\n    \"IPFS\" \"The InterPlanetary File System (IPFS) is a peer-to-peer protocol for sharing and storing files on the internet, designed to be decentralized and distributed.\"\r\n    \"Lotus\" \"The reference node implementation for the filecoin network.\"\r\n    \"Lily\" \"Software designed to simplify the recording of blockchain data.\"\r\n    \"web3\" \"A new iteration of the World Wide Web which incorporates concepts such as decentralization, blockchain technologies, and token-based economics.\"\r\n}}\r\n\r\n...\r\n```\r\n\r\nWithin your markdown you can use one of these tooltips with the following syntax:\r\n\r\n```markdown\r\n[...] storage on {{< tooltip \"IPFS\" >}} with blockchain-powered [...]\r\n```\r\n\r\nThe tooltip should show up once the site has built:\r\n\r\n![](static/images/tooltip-example.png)\r\n\r\n<!-- /CONTRIBUTING -->\r\n\r\n\r\n\r\n<!-- ISSUES -->\r\n## Issues \r\n\r\nFound a problem with the Filecoin docs site? [Please raise an issue](https://github.com/filecoin-project/filecoin-docs/issues/new). Be as specific and descriptive as possible; screenshots help!\r\n<!-- /ISSUES -->\r\n\r\n\r\n\r\n<!-- LICENSE -->\r\n## License\r\n\r\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the [Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\r\n<!-- /LICENSE -->\r\n\r\n\r\n<!-- TODO\r\n## Contact\r\n\r\nProject Link: [https://github.com/filecoin-project/filecoin-docs](https://github.com/filecoin-project/filecoin-docs)\r\n-->\r\n\r\n\r\n\r\n<!-- ACKNOWLEDGMENTS -->\r\n## Acknowledgments\r\n\r\n- [Fleek](https://fleek.co) web hosting\r\n- [Hugo](https://gohugo.io) static site generator \r\n- [Doks](https://getdoks.org) starter theme \r\n<!-- /ACKNOWLEDGMENTS -->\r\n\r\n\r\n\r\n<!-- MARKDOWN LINKS & IMAGES -->\r\n[contributors-shield]: https://img.shields.io/github/contributors/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[contributors-url]: https://github.com/filecoin-project/filecoin-docs/graphs/contributors\r\n[forks-shield]: https://img.shields.io/github/forks/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[forks-url]: https://github.com/filecoin-project/filecoin-docs/network/members\r\n[stars-shield]: https://img.shields.io/github/stars/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[stars-url]: https://github.com/filecoin-project/filecoin-docs/stargazers\r\n[issues-shield]: https://img.shields.io/github/issues/filecoin-project/filecoin-docs.svg?style=for-the-badge\r\n[issues-url]: https://github.com/filecoin-project/filecoin-docs/issues\r\n[license-shield]: https://img.shields.io/badge/license-MIT-blueviolet?style=for-the-badge\r\n[license-url]: https://github.com/filecoin-project/filecoin-docs/blob/master/LICENSE.txt\r\n[product-screenshot]: ./static/images/filecoin-docs-homepage.png\r\n[website-status]: https://img.shields.io/website.svg?down_color=red&style=for-the-badge&url=https%3A%2F%2Flotus.filecoin.io\r\n[website-status-url]: https://docs.filecoin.io/\r\n<!-- /MARKDOWN LINKS & IMAGES -->\r\n\r\n<!-- markdownlint-disable-file -->\r\n", "release_dates": []}, {"name": "tornado-deploy", "description": "Bedrock autoretrieve deployment scripts", "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "venus", "description": "Filecoin Full Node Implementation in Go", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "<p align=\"center\">\n  <a href=\"https://venus.filecoin.io/Overview.html\" title=\"Filecoin Docs\">\n    <img src=\"documentation/images/venus_logo_big2.jpg\" alt=\"Project Venus Logo\" width=\"330\" />\n  </a>\n</p>\n\n\n\n<h1 align=\"center\">Project Venus - \u542f\u660e\u661f</h1>\n\n<p align=\"center\">\n <a href=\"https://github.com/filecoin-project/venus/actions\"><img src=\"https://github.com/filecoin-project/venus/actions/workflows/build_upload.yml/badge.svg\"/></a>\n <a href=\"https://codecov.io/gh/filecoin-project/venus\"><img src=\"https://codecov.io/gh/filecoin-project/venus/branch/master/graph/badge.svg?token=J5QWYWkgHT\"/></a>\n <a href=\"https://goreportcard.com/report/github.com/filecoin-project/venus\"><img src=\"https://goreportcard.com/badge/github.com/filecoin-project/venus\"/></a>\n <a href=\"https://github.com/filecoin-project/venus/tags\"><img src=\"https://img.shields.io/github/v/tag/filecoin-project/venus\"/></a>\n  <br>\n</p>\n\n\nVenus is an implementation of the Filecoin Distributed Storage Network. For more details about Filecoin, check out the [Filecoin Spec](https://spec.filecoin.io).\n\n## Building & Documentation\n\nFor instructions on how to build, install and join a venus storage pool, please visit [here](https://venus.filecoin.io/intro/).\n\n## Venus architecture\n\nWith key features like security, ease of use and distributed storage pool, the deployment of a node using Venus is quite different from the one using [Lotus](https://github.com/filecoin-project/lotus). Details of mining architecture can be found [here](https://venus.filecoin.io/intro/#how-venus-works).\n\n## Related modules\n\nVenus loosely describes a collection of modules that work together to realize a fully featured Filecoin implementation. List of stand-alone venus modules repos can be found [here](https://venus.filecoin.io/intro/#how-venus-works), each assuming different roles in the functioning of Filecoin.\n\n## Contribute\n\nVenus is a universally open project and welcomes contributions of all kinds: code, docs, and more. However, before making a contribution, we ask you to heed these recommendations:\n\n1. If the proposal entails a protocol change, please first submit a [Filecoin Improvement Proposal](https://github.com/filecoin-project/FIPs).\n2. If the change is complex and requires prior discussion, [open an issue](https://github.com/filecoin-project/venus/issues) or a [discussion](https://github.com/filecoin-project/venus/discussions) to request feedback before you start working on a pull request. This is to avoid disappointment and sunk costs, in case the change is not actually needed or accepted.\n3. Please refrain from submitting PRs to adapt existing code to subjective preferences. The changeset should contain functional or technical improvements/enhancements, bug fixes, new features, or some other clear material contribution. Simple stylistic changes are likely to be rejected in order to reduce code churn.\n\nWhen implementing a change:\n\n1. Adhere to the standard Go formatting guidelines, e.g. [Effective Go](https://golang.org/doc/effective_go.html). Run `go fmt`.\n2. Stick to the idioms and patterns used in the codebase. Familiar-looking code has a higher chance of being accepted than eerie code. Pay attention to commonly used variable and parameter names, avoidance of naked returns, error handling patterns, etc.\n3. Comments: follow the advice on the [Commentary](https://golang.org/doc/effective_go.html#commentary) section of Effective Go.\n4. Minimize code churn. Modify only what is strictly necessary. Well-encapsulated changesets will get a quicker response from maintainers.\n5. Lint your code with [`golangci-lint`](https://golangci-lint.run) (CI will reject your PR if unlinted).\n6. Add tests.\n7. Title the PR in a meaningful way and describe the rationale and the thought process in the PR description.\n8. Write clean, thoughtful, and detailed [commit messages](https://chris.beams.io/posts/git-commit/). This is even more important than the PR description, because commit messages are stored _inside_ the Git history. One good rule is: if you are happy posting the commit message as the PR description, then it's a good commit message.\n\n## License\n\nThis project is dual-licensed under [Apache 2.0](https://github.com/filecoin-project/venus/blob/master/LICENSE-APACHE) and [MIT](https://github.com/filecoin-project/venus/blob/master/LICENSE-MIT).\n", "release_dates": ["2024-01-11T02:35:28Z", "2023-12-11T02:35:47Z", "2023-11-30T03:16:26Z", "2023-11-23T07:43:15Z", "2023-11-17T02:56:55Z", "2023-11-09T03:28:23Z", "2023-11-02T06:49:49Z", "2023-10-18T02:50:46Z", "2023-10-13T08:47:28Z", "2023-10-13T07:54:47Z", "2023-08-30T07:58:47Z", "2023-08-18T01:19:54Z", "2023-06-29T09:16:52Z", "2023-06-13T08:21:02Z", "2023-04-24T02:59:45Z", "2023-04-23T03:42:13Z", "2023-04-20T03:45:43Z", "2023-04-18T05:23:18Z", "2023-03-29T08:31:08Z", "2023-03-08T03:22:59Z", "2023-03-02T02:54:54Z", "2023-02-22T05:07:48Z", "2023-02-21T02:16:49Z", "2023-02-17T06:58:56Z", "2023-02-16T08:12:56Z", "2022-12-30T01:27:50Z", "2022-12-16T02:29:01Z", "2022-11-23T06:01:45Z", "2022-11-16T07:24:05Z", "2022-11-03T02:56:33Z"]}, {"name": "venus-common-types", "description": "shared types among venus components", "language": null, "license": null, "readme": "# venus-common-types\nshared types among venus components\n", "release_dates": []}, {"name": "venus-docs", "description": "Content for Venus tutorial", "language": "Shell", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Venus Docs\n\nThis repository contains documentation content for the [Venus](https://github.com/filecoin-project/venus) implementation **only**. It is hosted at **[venus.filecoin.io](https://venus.filecoin.io)**. For mandarin speakers, please visit [https://venus.filecoin.io/zh/](https://venus.filecoin.io/zh/).\n\nFor general [Filecoin Documentation](https://docs.filecoin.io), please visit [docs.filecoin.io](https://docs.filecoin.io). The repository with its source can be found in [/filecoin-project/filecoin-docs](https://github.com/filecoin-project/filecoin-docs).\n\n\n## Contributing\n\nPRs, bug reports, and issue suggestions are welcome! For major changes, please propose in an issue first so benefits and impacts can be discussed.\n\n\ud83d\udc49 You can also click on click on :pencil: `Suggest an Edit` links at the bottom of each page to jump directly to Edit mode.\n\n## Deployment\n\n### Running locally:\n\n```\n  $ yarn install\n  $ yarn docs:dev \n```\n\n### Building:\n\n```\n  $ yarn docs:links   # verify all links are well-formed\n  $ yarn docs:build\n```\n\nThen deploy the `docs/.vuepress/dist` directory to the `gh-pages` branch of this repo.\n\n### Notes:\n\n- When new documentation pages are added `./docs/.vuepress/config.js` will need to be **manually updated** in this repo\n\n## Licenses\n\nThe Filecoin Project's software code is dual-licensed under Apache 2.0 and MIT terms:\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT License ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nDocumentation and other written content is copyright (c) Protocol Labs under the [CC-BY-4.0](https://creativecommons.org/licenses/by/4.0/) license.\n\nSee the [LICENSE.md](LICENSE.md) file for details.\n\n\n", "release_dates": []}, {"name": "venus-sealer", "description": null, "language": "Go", "license": null, "readme": "# \u26a0\ufe0fWARNING\u26a0\ufe0f\n\n`venus-sealer` has been [deprecated](https://filecoinproject.slack.com/archives/C0283DTH1NK/p1656295820397749) since `network version 16` and is no longer maintained. For Venus users, please use [venus-cluster](https://github.com/ipfs-force-community/venus-cluster) (`Damocles`) instead for growing and maintaining your storage power. Please feel free to reach out to us on Slack [#fil-venus](https://filecoinproject.slack.com/archives/CEHHJNJS3) if you have any questions!\n\n# Venus Sealer\n\nThis project is a mining system supporting venus.\n\nUse [Venus Issues](https://github.com/filecoin-project/venus/issues) for reporting issues about this repository.\n\n## How to Build\n\n```sh\n    make deps\n    make build\n```\n\n## Run a local net\n\n### init miner \n```shell script\n# --network: Choose from calibration for testnets. Leave out this flag for mainnet\n./venus-sealer --network <network type> init \\\n--worker <WORKER_ADDRESS> \\\n--owner <OWNER_ADDRESS>  \\\n# Choose between 32G or 64G for mainnet\n--sector-size <sector size> \\\n# Config for different shared venus modules\n--node-url /ip4/<IP_ADDRESS_OF_VENUS>/tcp/3453 \\\n--messager-url /ip4/<IP_ADDRESS_OF_VENUS_MESSAGER>/tcp/<PORT_OF_VENUS_MESSAGER> \\\n--gateway-url /ip4/<IP_ADDRESS_OF_VENUS_GATEWAY>/tcp/<PORT_OF_VENUS_GATEWAY> \\\n--auth-token <AUTH_TOKEN_FOR_ACCOUNT_NAME> \\\n# Flags sealer to not storing any sealed sectors on the machine it runs on\n# You can leave out this flag if you are on testnet\n--no-local-storage\n```\n### run miner\n\n```shell script\n    ./venus-sealer run\n```\n\n### Command\n\nThe command line is the same as lotus-miner, but note that the commands related to deal is removed, and this part will be implemented in another tool\n\n```shell script\n    ./venus-sealer info               # show miner infomation\n    ./venus-sealer sectors pledge     # do a pledge sector\n    ./venus-sealer sectors list       # show local sectors status\n    ./venus-sealer secctors stats 1   # show infomation of sector 1\n```\n\n", "release_dates": ["2022-06-28T10:28:41Z", "2022-06-27T01:18:36Z", "2022-06-17T05:10:51Z", "2022-06-15T10:17:32Z", "2022-06-07T12:05:41Z", "2022-06-07T08:44:11Z", "2022-02-28T06:48:43Z", "2022-02-21T12:26:36Z", "2022-02-11T07:39:00Z", "2022-02-09T06:23:57Z", "2022-01-28T10:16:32Z", "2022-01-13T13:50:22Z", "2021-11-17T02:21:26Z", "2021-11-10T09:01:30Z", "2021-11-04T06:57:43Z", "2021-11-03T09:30:38Z", "2021-10-14T02:42:42Z", "2021-10-12T09:05:55Z", "2021-09-16T09:44:43Z", "2021-08-05T09:47:40Z", "2021-07-30T04:26:44Z", "2021-07-22T09:38:50Z", "2021-07-20T02:07:12Z", "2021-07-14T03:07:48Z", "2021-07-12T06:14:12Z", "2021-06-29T03:11:41Z", "2021-06-28T03:02:21Z", "2021-06-21T06:50:52Z", "2021-06-18T08:08:18Z", "2021-04-28T03:03:21Z"]}, {"name": "venus-wallet", "description": "a remote wallet for provider sign service", "language": "Go", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<h1 align=\"center\">Venus Wallet</h1>\n\n<p align=\"center\">\n <a href=\"https://github.com/filecoin-project/venus-wallet/actions\"><img src=\"https://github.com/filecoin-project/venus-wallet/actions/workflows/build_upload.yml/badge.svg\"/></a>\n <a href=\"https://codecov.io/gh/filecoin-project/venus-wallet\"><img src=\"https://codecov.io/gh/filecoin-project/venus-wallet/branch/master/graph/badge.svg?token=J5QWYWkgHT\"/></a>\n <a href=\"https://goreportcard.com/report/github.com/filecoin-project/venus-wallet\"><img src=\"https://goreportcard.com/badge/github.com/filecoin-project/venus-wallet\"/></a>\n <a href=\"https://github.com/filecoin-project/venus-wallet/tags\"><img src=\"https://img.shields.io/github/v/tag/filecoin-project/venus-wallet\"/></a>\n  <br>\n</p>\n\n- A remote wallet for Filecoin and supports JsonRPC2.0 call. \n- The project is decoupled from Lotus and Venus independently, and can be called by different implementations of Filecoin.\n- It can dynamically configure strategy to limit the signature rules of the Wallet group.\n- Through the configuration of signature strategy, it can achieve environmental isolation of different wallet groups\n\nUse [Venus Issues](https://github.com/filecoin-project/venus/issues) for reporting issues about this repository.\n\n---\n### Get Started\n#### 1. Build\n```\nexport CGO_CFLAGS_ALLOW=\"-D__BLST_PORTABLE__\"\nexport CGO_CFLAGS=\"-D__BLST_PORTABLE__\"\n\nmake \n```\n- If the test or target application crashes with an \"illegal instruction\" exception [after copying to an older system], rebuild with `CGO_CFLAGS` environment variable set to `-O -D__BLST_PORTABLE__`. Don't forget `-O`!\n\n#### 2. Setup \n```\n# start daemon\n$ ./venus-wallet run\n\n# set password to protect wallet security (Used for AES encryption, private key, root token seed)\n$ ./venus-wallet set-password\nPassword:******\nEnter Password again:******\n```\n\n#### 3. Get remote connect string\n> JWT Token restricts access to RPC interface calls\n```\n# --perm \n# \"read\",\"write\",\"sign\",\"admin\" \n./venus-wallet auth api-info --perm admin\n```\n\n#### 4. Get strategy token\n- Strategy token restricts the authority of business execution\n- How to generate strategy token for remote service [Venus wallet cli](https://venus.filecoin.io/Venus%20wallet.html#basic-operation-of-venus-wallet)\n- URL append strategy token `<JWT token>:/ip4/0.0.0.0/tcp/5678/http:<Strategy token>`\n\n\n\n> Once we have a connection string, we can connect to the remote wallet through it.\n\n---\n\n### [How to access remote wallet](./example)\n\n---\n### Config\n```\n[API]\nListenAddress = \"/ip4/0.0.0.0/tcp/5678/http\"\n\n[DB]\nConn = \"[homePath]/keystore.sqlit\"\nType = \"sqlite\"\nDebugMode = true\n\n[Factor]\n# aes variable\nScryptN = 262144\nScryptP = 1\n\n[JWT]\n#  hex JWT token, generate by secret\nToken = \"\" \n# hex JWT secret, randam generate first init\nSecret = \"\"\n```\n\n---\n\n### Package concept\n\n```\n+-- api // RPC service interface permission setting\n|\n+-- build // dependency injection\n|\n+-- cli  // shell cmd\n|\n+-- cmd  // service startup entry\n|\n+-- config // config provider\n|\n+-- core // constant \n|\n+-- crypto // private key \n|\n+-- filemgr // local file manager, Ps:config,database\n|\n+-- log // log set\n|\n+-- middeleware // middleware such as link tracking, data reporting\n|\n+-- signature // signature verification\n|\n+-- sotrage // the wallet keystore implementation\n|\n+-- version // git version by ldflags\n\n```\n\n\n", "release_dates": ["2023-11-24T01:48:19Z", "2023-11-20T05:58:57Z", "2023-10-16T05:55:56Z", "2023-08-31T06:48:25Z", "2023-08-18T07:55:23Z", "2023-06-30T01:59:13Z", "2023-04-23T05:58:56Z", "2023-04-18T08:58:23Z", "2023-03-08T08:53:09Z", "2023-03-02T05:08:22Z", "2023-02-17T08:54:05Z", "2023-02-16T09:33:53Z", "2022-12-30T03:52:57Z", "2022-12-16T07:47:53Z", "2022-11-16T08:56:15Z", "2022-11-03T05:40:35Z", "2022-10-19T08:30:52Z", "2022-10-17T11:13:28Z", "2022-09-02T13:39:54Z", "2022-06-28T06:02:10Z", "2022-06-24T07:44:01Z", "2022-06-15T06:31:38Z", "2022-06-07T04:05:48Z", "2022-02-21T12:44:08Z", "2022-01-13T09:59:07Z", "2021-11-04T06:42:58Z", "2021-10-12T09:50:33Z", "2021-07-23T08:46:47Z", "2021-06-28T01:35:17Z", "2021-06-18T08:06:17Z"]}, {"name": "wasm-tools", "description": "Low level tooling for WebAssembly in Rust", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<div align=\"center\">\n  <h1><code>wasm-tools</code></h1>\n\n<strong>A <a href=\"https://bytecodealliance.org/\">Bytecode Alliance</a> project</strong>\n\n  <p>\n    <strong>Rust tooling for low-level manipulation of WebAssembly modules</strong>\n  </p>\n</div>\n\n# Installation\n\nThis project can be installed and compiled from source with this Cargo command:\n\n```\n$ cargo install wasm-tools\n```\n\nInstallation can be confirmed with:\n\n```\n$ wasm-tools --version\n```\n\nSubcommands can be explored with:\n\n```\n$ wasm-tools help\n```\n\n# Tools included\n\nThe `wasm-tools` binary internally contains a number of subcommands for working\nwith wasm modules. Many subcommands also come with Rust crates that can be use\nprogrammatically as well:\n\n| Tool | Crate | Description |\n|------|------|------------|\n| `wasm-tools validate` | [wasmparser] | Validate a WebAssembly file |\n| `wasm-tools parse` | [wat] and [wast] | Translate the WebAssembly text format to binary |\n| `wasm-tools print` | [wasmprinter] | Translate the WebAssembly binary format to text |\n| `wasm-tools smith` | [wasm-smith] | Generate a \"random\" valid WebAssembly module |\n| `wasm-tools mutate` | [wasm-mutate] | Mutate an input wasm file into a new valid wasm file |\n| `wasm-tools shrink` | [wasm-shrink] | Shrink a wasm file while preserving a predicate |\n| `wasm-tools dump` |   | Print debugging information about the binary format |\n| `wasm-tools objdump` |   | Print debugging information about section headers |\n| `wasm-tools strip` |   | Remove custom sections from a WebAssembly file |\n| `wasm-tools demangle` |   | Demangle Rust and C++ symbol names in the `name` section |\n| `wasm-tools compose` |   | Compose wasm components together |\n\n[wasmparser]: https://crates.io/crates/wasmparser\n[wat]: https://crates.io/crates/wat\n[wast]: https://crates.io/crates/wast\n[wasmprinter]: https://crates.io/crates/wasmprinter\n[wasm-smith]: https://crates.io/crates/wasm-smith\n[wasm-mutate]: https://crates.io/crates/wasm-mutate\n[wasm-shrink]: https://crates.io/crates/wasm-shrink\n\nThe `wasm-tools` CLI is primarily intended to be a debugging aid. The various\nsubcommands all have `--help` explainer texts to describe more about their\nfunctionality as well.\n\n# Libraries\n\nAs mentioned above many of the tools of the `wasm-tools` CLI have libraries\nimplemented in this repository as well. These libraries are:\n\n* [**`wasmparser`**](crates/wasmparser) - a library to parse WebAssembly binaries\n* [**`wat`**](crates/wat) - a library to parse the WebAssembly text format\n* [**`wast`**](crates/wast) - like `wat`, except provides an AST\n* [**`wasmprinter`**](crates/wasmprinter) - prints WebAssembly binaries in their\n  string form\n* [**`wasm-mutate`**](crates/wasm-mutate) - a WebAssembly test case mutator\n* [**`wasm-shrink`**](crates/wasm-shrink) - a WebAssembly test case shrinker\n* [**`wasm-smith`**](crates/wasm-smith) - a WebAssembly test case generator\n* [**`wasm-encoder`**](crates/wasm-encoder) - a crate to generate a binary\n  WebAssembly module\n\nIt's recommended to use the libraries directly rather than the CLI tooling when\nembedding into a separate project.\n\n# C/C++ bindings\n\nUsing the `CMakeLists.txt` in `crates/c-api`, `wasm-tools` can be used from the [`wasm-tools.h` header](crates/c-api/include/wasm-tools.h).\n\n# License\n\nThis project is licensed under the Apache 2.0 license with the LLVM exception.\nSee [LICENSE](LICENSE) for more details.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in this project by you, as defined in the Apache-2.0 license,\nshall be licensed as above, without any additional terms or conditions.\n", "release_dates": []}, {"name": "wasmtime", "description": "Standalone JIT-style runtime for WebAssembly, using Cranelift", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<div align=\"center\">\n  <h1><code>wasmtime</code></h1>\n\n  <p>\n    <strong>A standalone runtime for\n    <a href=\"https://webassembly.org/\">WebAssembly</a></strong>\n  </p>\n\n  <strong>A <a href=\"https://bytecodealliance.org/\">Bytecode Alliance</a> project</strong>\n\n  <p>\n    <a href=\"https://github.com/bytecodealliance/wasmtime/actions?query=workflow%3ACI\"><img src=\"https://github.com/bytecodealliance/wasmtime/workflows/CI/badge.svg\" alt=\"build status\" /></a>\n    <a href=\"https://bytecodealliance.zulipchat.com/#narrow/stream/217126-wasmtime\"><img src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\" alt=\"zulip chat\" /></a>\n    <img src=\"https://img.shields.io/badge/rustc-stable+-green.svg\" alt=\"supported rustc stable\" />\n    <a href=\"https://docs.rs/wasmtime\"><img src=\"https://docs.rs/wasmtime/badge.svg\" alt=\"Documentation Status\" /></a>\n  </p>\n\n  <h3>\n    <a href=\"https://bytecodealliance.github.io/wasmtime/\">Guide</a>\n    <span> | </span>\n    <a href=\"https://bytecodealliance.github.io/wasmtime/contributing.html\">Contributing</a>\n    <span> | </span>\n    <a href=\"https://wasmtime.dev/\">Website</a>\n    <span> | </span>\n    <a href=\"https://bytecodealliance.zulipchat.com/#narrow/stream/217126-wasmtime\">Chat</a>\n  </h3>\n</div>\n\n## Installation\n\nThe Wasmtime CLI can be installed on Linux and macOS (locally) with a small install\nscript:\n\n```sh\ncurl https://wasmtime.dev/install.sh -sSf | bash\n```\n\nWindows or otherwise interested users can download installers and\nbinaries directly from the [GitHub\nReleases](https://github.com/bytecodealliance/wasmtime/releases) page.\n\n## Example\n\nIf you've got the [Rust compiler\ninstalled](https://www.rust-lang.org/tools/install) then you can take some Rust\nsource code:\n\n```rust\nfn main() {\n    println!(\"Hello, world!\");\n}\n```\n\nand compile/run it with:\n\n```sh\n$ rustup target add wasm32-wasi\n$ rustc hello.rs --target wasm32-wasi\n$ wasmtime hello.wasm\nHello, world!\n```\n\n(Note: make sure you installed Rust using the `rustup` method in the official\ninstructions above, and do not have a copy of the Rust toolchain installed on\nyour system in some other way as well (e.g. the system package manager). Otherwise, the `rustup target add...`\ncommand may not install the target for the correct copy of Rust.)\n\n## Features\n\n* **Fast**. Wasmtime is built on the optimizing [Cranelift] code generator to\n  quickly generate high-quality machine code either at runtime or\n  ahead-of-time. Wasmtime is optimized for efficient instantiation, low-overhead\n  calls between the embedder and wasm, and scalability of concurrent instances.\n\n* **[Secure]**. Wasmtime's development is strongly focused on correctness and\n  security. Building on top of Rust's runtime safety guarantees, each Wasmtime\n  feature goes through careful review and consideration via an [RFC\n  process]. Once features are designed and implemented, they undergo 24/7\n  fuzzing donated by [Google's OSS Fuzz]. As features stabilize they become part\n  of a [release][release policy], and when things go wrong we have a\n  well-defined [security policy] in place to quickly mitigate and patch any\n  issues. We follow best practices for defense-in-depth and integrate\n  protections and mitigations for issues like Spectre. Finally, we're working to\n  push the state-of-the-art by collaborating with academic researchers to\n  formally verify critical parts of Wasmtime and Cranelift.\n\n* **[Configurable]**. Wasmtime uses sensible defaults, but can also be\n  configured to provide more fine-grained control over things like CPU and\n  memory consumption. Whether you want to run Wasmtime in a tiny environment or\n  on massive servers with many concurrent instances, we've got you covered.\n\n* **[WASI]**. Wasmtime supports a rich set of APIs for interacting with the host\n  environment through the [WASI standard](https://wasi.dev).\n\n* **[Standards Compliant]**. Wasmtime passes the [official WebAssembly test\n  suite](https://github.com/WebAssembly/testsuite), implements the [official C\n  API of wasm](https://github.com/WebAssembly/wasm-c-api), and implements\n  [future proposals to WebAssembly](https://github.com/WebAssembly/proposals) as\n  well. Wasmtime developers are intimately engaged with the WebAssembly\n  standards process all along the way too.\n\n[Wasmtime]: https://github.com/bytecodealliance/wasmtime\n[Cranelift]: https://cranelift.dev/\n[Google's OSS Fuzz]: https://google.github.io/oss-fuzz/\n[security policy]: https://bytecodealliance.org/security\n[RFC process]: https://github.com/bytecodealliance/rfcs\n[release policy]: https://docs.wasmtime.dev/stability-release.html\n[Secure]: https://docs.wasmtime.dev/security.html\n[Configurable]: https://docs.rs/wasmtime/latest/wasmtime/struct.Config.html\n[WASI]: https://docs.rs/wasmtime-wasi/latest/wasmtime_wasi/\n[Standards Compliant]: https://docs.wasmtime.dev/stability-wasm-proposals-support.html\n\n## Language Support\n\nYou can use Wasmtime from a variety of different languages through embeddings of\nthe implementation.\n\nLanguages supported by the Bytecode Alliance:\n\n* **[Rust]** - the [`wasmtime` crate]\n* **[C]** - the [`wasm.h`, `wasi.h`, and `wasmtime.h` headers][c-headers], [CMake](crates/c-api/CMakeLists.txt) or [`wasmtime` Conan package]\n* **C++** - the [`wasmtime-cpp` repository][wasmtime-cpp] or use [`wasmtime-cpp` Conan package]\n* **[Python]** - the [`wasmtime` PyPI package]\n* **[.NET]** - the [`Wasmtime` NuGet package]\n* **[Go]** - the [`wasmtime-go` repository]\n* **[Ruby]** - the [`wasmtime` gem]\n\nLanguages supported by the community:\n\n* **[Elixir]** - the [`wasmex` hex package]\n\n[Rust]: https://bytecodealliance.github.io/wasmtime/lang-rust.html\n[C]: https://bytecodealliance.github.io/wasmtime/examples-c-embed.html\n[`wasmtime` crate]: https://crates.io/crates/wasmtime\n[c-headers]: https://bytecodealliance.github.io/wasmtime/c-api/\n[Python]: https://bytecodealliance.github.io/wasmtime/lang-python.html\n[`wasmtime` PyPI package]: https://pypi.org/project/wasmtime/\n[.NET]: https://bytecodealliance.github.io/wasmtime/lang-dotnet.html\n[`Wasmtime` NuGet package]: https://www.nuget.org/packages/Wasmtime\n[Go]: https://bytecodealliance.github.io/wasmtime/lang-go.html\n[`wasmtime-go` repository]: https://pkg.go.dev/github.com/bytecodealliance/wasmtime-go\n[wasmtime-cpp]: https://github.com/bytecodealliance/wasmtime-cpp\n[`wasmtime` Conan package]: https://conan.io/center/wasmtime\n[`wasmtime-cpp` Conan package]: https://conan.io/center/wasmtime-cpp\n[Ruby]: https://bytecodealliance.github.io/wasmtime/lang-ruby.html\n[`wasmtime` gem]: https://rubygems.org/gems/wasmtime\n[Elixir]: https://docs.wasmtime.dev/lang-elixir.html\n[`wasmex` hex package]: https://hex.pm/packages/wasmex\n\n## Documentation\n\n[\ud83d\udcda Read the Wasmtime guide here! \ud83d\udcda][guide]\n\nThe [wasmtime guide][guide] is the best starting point to learn about what\nWasmtime can do for you or help answer your questions about Wasmtime. If you're\ncurious in contributing to Wasmtime, [it can also help you do\nthat][contributing]!\n\n[contributing]: https://bytecodealliance.github.io/wasmtime/contributing.html\n[guide]: https://bytecodealliance.github.io/wasmtime\n\n---\n\nIt's Wasmtime.\n", "release_dates": []}, {"name": "website-bounty.filecoin.io", "description": null, "language": "JavaScript", "license": null, "readme": "# Preact example\n\nThis is a fully working example of Next.js 9.3 running on [Preact](https://github.com/preactjs/preact) instead of React.\n\nThis reduces the base JavaScript weight of pages to 21kB.\n\n> \ud83d\udd2d In the future, this can be even smaller with some additional Webpack optimizations.\n\n## How to use\n\nClone this repo and run `npm install`:\n\n```sh\ngit clone https://github.com/developit/nextjs-preact-demo.git\ncd nextjs-preact-demo\nnpm install\n```\n\nThere are three commands available:\n\n```sh\n# start a development server:\nnpm run dev\n\n# create a production build:\nnpm run build\n\n# start a production server:\nnpm start\n```\n\n## How does it work?\n\nThe example takes advantage of npm/yarn aliases, which essentially allow installing `preact/compat` at `node_modules/react`.\n\nHere's how this example repo was set up:\n\n- Set up a basic Next.js app using `create-next-app`\n- Install `preact`, uninstall `react` and `react-dom`.\n- Install [preact-compat/react](https://github.com/preact-compat/react) and [preact-compat/react-dom](https://github.com/preact-compat/react-dom) for aliasing.\n- Use an [npm alias](https://github.com/npm/rfcs/blob/latest/implemented/0001-package-aliases.md#detailed-explanation) to replace `react-ssr-prepass` with `preact-ssr-prepass` (also [works](https://twitter.com/sebmck/status/873958247304232961) with Yarn).\n", "release_dates": []}, {"name": "website-security.filecoin.io", "description": "Source code for security.filecoin.io ", "language": "CSS", "license": null, "readme": "# security.filecoin.io\n\n## Building Hugo\n\n```\nhugo -D\n```\n\nor to run a server\n\n```\nhugo server\n```\n\n\n## Pushing to gh-pages branch\n\nThe `public/` directory for the compiled site has been added to `.gitignore`.\n\nYou can create a local `dist/` folder, copy compiled contents to it, commit the folder then run:\n\n```\ngit subtree push --prefix dist origin gh-pages\n```\n\n", "release_dates": []}, {"name": "wge-post-deployment-template-renderer", "description": null, "language": "Shell", "license": null, "readme": "# post-deployment-template-healper", "release_dates": []}, {"name": "zexe", "description": "Rust library for decentralized private computation", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<h1 align=\"center\">ZEXE (Zero knowledge EXEcution)</h1>\n<p align=\"center\">\n    <a href=\"https://circleci.com/gh/filecoin-project/zexe/tree/master\"><img src=\"https://circleci.com/gh/filecoin-project/zexe/tree/master.svg?style=svg\"></a>\n    <a href=\"https://github.com/scipr-lab/zexe/blob/master/AUTHORS\"><img src=\"https://img.shields.io/badge/authors-SCIPR%20Lab-orange.svg\"></a>\n    <a href=\"https://github.com/scipr-lab/zexe/blob/master/LICENSE-APACHE\"><img src=\"https://img.shields.io/badge/license-APACHE-blue.svg\"></a>\n   <a href=\"https://github.com/scipr-lab/zexe/blob/master/LICENSE-MIT\"><img src=\"https://img.shields.io/badge/license-MIT-blue.svg\"></a>\n</p>\n\n\n___ZEXE___ (pronounced */zeks\u0113/*) is a Rust library for decentralized private computation.\n\n\nThis library was initially developed as part of the paper *\"[ZEXE: Enabling Decentralized Private Computation][zexe]\"*, and it is released under the MIT License and the Apache v2 License (see [License](#license)).\n\n**WARNING:** This is an academic proof-of-concept prototype, and in particular has not received careful code review. This implementation is NOT ready for production use.\n\n## Overview\n\nThis library implements a ledger-based system that enables users to execute offline computations and subsequently produce publicly-verifiable transactions that attest to the correctness of these offline executions. The transactions contain *zero-knowledge succinct arguments* (zkSNARKs) attesting to the correctness of the offline computations, and provide strong notions of privacy and succinctness.\n\n- **Privacy** - transactions reveal no information about the offline computation.\n- **Succinctness** - transactions can be validated in time that is independent of the offline computation.\n- **Application isolation** - malicious applications cannot affect the execution of honest applications.\n- **Application interaction** -  applications can safely communicate with each other.\n\nInformally, the library provides the ability to create transactions that run arbitrary (Turing-complete) scripts on hidden data stored on the ledger. In more detail, the library implements a cryptographic primitive known as *decentralized private computation* (DPC) schemes, which are described in detail in the [ZEXE paper][zexe].\n\n## Directory structure\n\nThis repository contains several Rust crates that implement the different building blocks of ZEXE. The high-level structure of the repository is as follows.\n\n* [`algebra`](algebra): Rust crate that provides finite fields and elliptic curves\n* [`dpc`](dpc): Rust crate that implements DPC schemes (the main cryptographic primitive in this repository)\n* [`snark`](snark): Rust crate that provides succinct zero-knowledge arguments\n* [`snark-gadgets`](snark-gadgets): Rust crate that provides various gadgets used to construct constraint systems\n\nIn addition, there is a  [`bench-utils`](bench-utils) crate which contains infrastructure for benchmarking. This crate includes macros for timing code segments and is used for profiling the building blocks of ZEXE.\n\n## Build guide\n\nThe library compiles on the `stable` toolchain of the Rust compiler. To install the latest version of Rust, first install `rustup` by following the instructions [here](https://rustup.rs/), or via your platform's package manager. Once `rustup` is installed, install the Rust toolchain by invoking:\n```bash\nrustup install stable\n```\n\nAfter that, use `cargo`, the standard Rust build tool, to build the library:\n```bash\ngit clone https://github.com/scipr-lab/zexe.git\ncd zexe/dpc\ncargo build --release\n```\n\nThis library comes with unit tests for each of the provided crates. Run the tests with:\n```bash\ncargo test\n```\n\nLastly, this library comes with benchmarks for the following crates:\n\n- [`algebra`](algebra)\n- [`dpc`](dpc)\n\nThese benchmarks require the nightly Rust toolchain; to install this, run `rustup install nightly`. Then, to run benchmarks, run the following command:\n```bash\ncargo +nightly bench\n```\n\n## License\n\nZEXE is licensed under either of the following licenses, at your discretion.\n\n * Apache License Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nUnless you explicitly state otherwise, any contribution submitted for inclusion in ZEXE by you shall be dual licensed as above (as defined in the Apache v2 License), without any additional terms or conditions.\n\n[zexe]: https://ia.cr/2018/962\n\n## Reference paper\n\n[_ZEXE: Enabling Decentralized Private Computation_][zexe]\n[Sean Bowe](https://www.github.com/ebfull), Alessandro Chiesa, Matthew Green, Ian Miers, [Pratyush Mishra](https://www.github.com/pratyush), [Howard Wu](https://www.github.com/howardwu)\n*IACR ePrint Report 2018/962*\n\n## Acknowledgements\n\nThis work was supported by:\na Google Faculty Award;\nthe National Science Foundation;\nthe UC Berkeley Center for Long-Term Cybersecurity;\nand donations from the Ethereum Foundation, the Interchain Foundation, and Qtum.\n\nSome parts of the finite field arithmetic, elliptic curve arithmetic, FFTs, and multi-threading infrastructure in the `algebra` crate have been adapted from code in the [`ff`](https://github.com/zkcrypto/ff), [`pairing`](https://github.com/zkcrypto/pairing), and [`bellman`](https://github.com/zkcrypto/bellman) crates, developed by [Sean Bowe](https://www.github.com/ebfull) and others from Zcash.\n", "release_dates": []}]