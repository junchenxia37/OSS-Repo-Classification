[{"name": "-test-git-poap-integration-2", "description": null, "language": null, "license": null, "readme": "# -test-git-poap-integration-2", "release_dates": []}, {"name": ".github", "description": "zkSync Frontend Team workflow configuration", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# .github\nzkSync Organization\n", "release_dates": []}, {"name": "aa-signature-checker", "description": null, "language": "TypeScript", "license": null, "readme": "# Account abstraction signature checker\n\nA library for convenient, universal signature checking for zkSync 2.0.\n\nCurrently, it is a copy of the OpenZeppelin's [SignatureChecker](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/74738721dc9cfa820687f6b700d2583b16a21c0d/contracts/utils/cryptography/SignatureChecker.sol#L17) library. In the future, it will be slightly edited to avoid emitting warnings about `ecrecover` during compilation.\n", "release_dates": []}, {"name": "action-hosting-deploy", "description": "Automatically deploy shareable previews for your Firebase Hosting sites", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# \ud83d\udd25\ud83c\udf0e Firebase Hosting GitHub Action\n\n- Creates a new preview channel (and its associated preview URL) for every PR on your GitHub repository.\n- Adds a comment to the PR with the preview URL so that you and each reviewer can view and test the PR's changes in a \"preview\" version of your app.\n- Updates the preview URL with changes from each commit by automatically deploying to the associated preview channel. The URL doesn't change with each new commit.\n- (Optional) Deploys the current state of your GitHub repo to your live channel when the PR is merged.\n\n## Setup\n\nA full setup guide can be found [in the Firebase Hosting docs](https://firebase.google.com/docs/hosting/github-integration).\n\nThe [Firebase CLI](https://firebase.google.com/docs/cli) can get you set up quickly with a default configuration.\n\n- If you've NOT set up Hosting, run this version of the command from the root of your local directory:\n\n```bash\nfirebase init hosting\n```\n\n- If you've ALREADY set up Hosting, then you just need to set up the GitHub Action part of Hosting.\n  Run this version of the command from the root of your local directory:\n\n```bash\nfirebase init hosting:github\n```\n\n## Usage\n\n### Deploy to a new preview channel for every PR\n\nAdd a workflow (`.github/workflows/deploy-preview.yml`):\n\n```yaml\nname: Deploy to Preview Channel\n\non:\n  pull_request:\n    # Optionally configure to run only for specific files. For example:\n    # paths:\n    # - \"website/**\"\n\njobs:\n  build_and_preview:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      # Add any build steps here. For example:\n      # - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: \"${{ secrets.GITHUB_TOKEN }}\"\n          firebaseServiceAccount: \"${{ secrets.FIREBASE_SERVICE_ACCOUNT }}\"\n          expires: 30d\n          projectId: your-Firebase-project-ID\n```\n\n### Deploy to your live channel on merge\n\nAdd a workflow (`.github/workflows/deploy-prod.yml`):\n\n```yaml\nname: Deploy to Live Channel\n\non:\n  push:\n    branches:\n      - main\n    # Optionally configure to run only for specific files. For example:\n    # paths:\n    # - \"website/**\"\n\njobs:\n  deploy_live_website:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      # Add any build steps here. For example:\n      # - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: \"${{ secrets.GITHUB_TOKEN }}\"\n          firebaseServiceAccount: \"${{ secrets.FIREBASE_SERVICE_ACCOUNT }}\"\n          projectId: your-Firebase-project-ID\n          channelId: live\n```\n\n## Options\n\n### `firebaseServiceAccount` _{string}_ (required)\n\nThis is a service account JSON key. The easiest way to set it up is to run `firebase init hosting:github`. However, it can also be [created manually](./docs/service-account.md).\n\nIt's important to store this token as an\n[encrypted secret](https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets)\nto prevent unintended access to your Firebase project. Set it in the \"Secrets\" area\nof your repository settings and add it as `FIREBASE_SERVICE_ACCOUNT`:\n`https://github.com/USERNAME/REPOSITORY/settings/secrets`.\n\n### `repoToken` _{string}_\n\nAdding `repoToken: \"${{secrets.GITHUB_TOKEN}}\"` lets the action comment on PRs\nwith the preview URL for the associated preview channel. You don't need to set\nthis secret yourself - GitHub sets it automatically.\n\nIf you omit this option, you'll need to find the preview URL in the action's\nbuild log.\n\n### `expires` _{string}_\n\nThe length of time the preview channel should remain active after the last deploy.\nIf left blank, the action uses the default expiry of 7 days.\nThe expiry date will reset to this value on every new deployment.\n\n### `projectId` _{string}_\n\nThe Firebase project that contains the Hosting site to which you\nwant to deploy. If left blank, you need to check in a `.firebaserc`\nfile so that the Firebase CLI knows which Firebase project to use.\n\n### `channelId` _{string}_\n\nThe ID of the channel to deploy to. If you leave this blank,\na preview channel and its ID will be auto-generated per branch or PR.\nIf you set it to **`live`**, the action deploys to the live channel of your default Hosting site.\n\n_You usually want to leave this blank_ so that each PR gets its own preview channel.\nAn exception might be that you always want to deploy a certain branch to a\nlong-lived preview channel (for example, you may want to deploy every commit\nfrom your `next` branch to a `preprod` preview channel).\n\n### `target` _{string}_\n\nThe target name of the Hosting site to deploy to. If you leave this blank,\nthe default target or all targets defined in the `.firebaserc` will be deployed to.\n\nYou usually want to leave this blank unless you have set up multiple sites in the Firebase Hosting UI\nand are trying to target just one of those sites with this action.\n\nRefer to the Hosting docs about [multiple sites](https://firebase.google.com/docs/hosting/multisites)\nfor more information about deploy targets.\n\n### `entryPoint` _{string}_\n\nThe directory containing your [`firebase.json`](https://firebase.google.com/docs/cli#the_firebasejson_file)\nfile relative to the root of your repository. Defaults to `.` (the root of your repo).\n\n### `firebaseToolsVersion` _{string}_\n\nThe version of `firebase-tools` to use. If not specified, defaults to `latest`.\n\n## Outputs\n\nValues emitted by this action that can be consumed by other actions later in your workflow\n\n### `urls`\n\nThe url(s) deployed to\n\n### `expire_time`\n\nThe time the deployed preview urls expire\n\n### `details_url`\n\nA single URL that was deployed to\n\n## Status\n\n![Status: Experimental](https://img.shields.io/badge/Status-Experimental-blue)\n\nThis repository is maintained by Googlers but is not a supported Firebase product. Issues here are answered by maintainers and other community members on GitHub on a best-effort basis.\n", "release_dates": []}, {"name": "awesome-zero-knowledge-proofs", "description": "A curated list of awesome things related to learning Zero-Knowledge Proofs (ZKP).", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Awesome zero knowledge proofs (zkp)\n\n> [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)\n> A curated list of awesome things related to learning zero knowledge proofs\n\n## Contents\n\n- [Awesome zero knowledge proofs (zkp)](#awesome-zero-knowledge-proofs-zkp)\n  - [Contents](#contents)\n  - [General introduction](#general-introduction)\n  - [Courses](#courses)\n  - [Use cases](#use-cases)\n  - [Applications](#applications)\n    - [Ethereum](#ethereum)\n    - [Other blockchains](#other-blockchains)\n    - [Non-blockchain](#non-blockchain)\n  - [Comparison of the most popular zkp systems](#comparison-of-the-most-popular-zkp-systems)\n  - [Bulletproofs](#bulletproofs)\n    - [Try](#try)\n    - [Proof system implementations](#proof-system-implementations)\n    - [Halo](#halo)\n  - [SNARKs](#snarks)\n    - [Learn](#learn)\n    - [Try](#try-1)\n    - [Scaling the prover](#scaling-the-prover)\n    - [Multi-Party Ceremony (MPC) for Trusted Setup](#multi-party-ceremony-mpc-for-trusted-setup)\n  - [SNORKs](#snorks)\n    - [Sonic](#sonic)\n    - [PLONK](#plonk)\n    - [Marlin](#marlin)\n  - [STARKS](#starks)\n    - [Learn](#learn-1)\n    - [FRI-STARKs](#fri-starks)\n    - [SuperSonic](#supersonic)\n    - [Fractal](#fractal)\n  - [Social media](#social-media)\n\n## General introduction\n\n[Zero-Knowledge Proofs Starter Pack](https://ethresear.ch/t/zero-knowledge-proofs-starter-pack/4519): alternative introductory list for beginners (more videos).\n\n- [Zero Knowledge Proofs: An illustrated primer by Matthew Green](https://blog.cryptographyengineering.com/2014/11/27/zero-knowledge-proofs-illustrated-primer/)\n- [Demystifying zero-knowledge proofs](https://docs.google.com/presentation/d/1gfB6WZMvM9mmDKofFibIgsyYShdf0RV_Y8TLz3k1Ls0/edit#slide=id.p) ([video](https://www.youtube.com/watch?v=_6TqUNVLChc)) (math-heavy, awesome introduction into underlying cryptography)\n- [Introduction to SNARKs/STARKs by Eli Ben-Sasson](https://www.youtube.com/watch?v=VUN35BC11Qw) (YouTube)\n- [On Interactive Proofs and Zero-Knowledge: A Primer](https://medium.com/magicofc/interactive-proofs-and-zero-knowledge-b32f6c8d66c3)\n- [ZK Basics Cheatsheet](https://github.com/baro77/ZKbasicsCS) - a \"for (not too much) dummies\" poster, trying to not miss core concepts despite the simplified approach and topics selection\n- [A Non-Mathematical Introduction to Zero Knowledge Proof](https://mirror.xyz/krinza.eth/5_Cr91cBK3XdkeHPQ9yjc7z_4NoTNxyqBiM4Jz4d5VE) - a ZKP primer for those who flunked algebra\n\n[ZK whiteboard sessions by ZK Hack](https://zkhack.dev/whiteboard/):\n\n- [Part 1: What is a SNARK?](https://zkhack.dev/whiteboard/module-one/)\n- [Part 2: Building a SNARK (Part I):](https://zkhack.dev/whiteboard/module-one/)\n- [Part 3: Building a SNARK (Part 2)](https://zkhack.dev/whiteboard/module-three/)\n- [Part 4: SNARKS vs. STARKS](https://zkhack.dev/whiteboard/module-four/)\n- [Part 5: PLONK and Custom Gates with Adrian Hamelink](https://zkhack.dev/whiteboard/module-five/)\n- [Part 6: Lookup Arguments for Performance Optimisation](https://zkhack.dev/whiteboard/module-six/)\n- [Part 7: Zero Knowledge Virtual Machines (zkVM)](https://zkhack.dev/whiteboard/module-seven/)\n- [Part 8: Achieving Decentralised Private Computation](https://zkhack.dev/whiteboard/module-eight/)\n- [Part 9: Introduction to zkRollups](https://zkhack.dev/whiteboard/module-nine/)\n\nA Hands-On Tutorial for Zero-Knowledge Proofs by Shir Peled (StarkWare):\n\n- [Part I](https://www.shirpeled.com/2018/09/a-hands-on-tutorial-for-zero-knowledge.html)\n- [Part II](https://www.shirpeled.com/2018/10/a-hands-on-tutorial-for-zero-knowledge.html)\n- [Part III](https://www.shirpeled.com/2018/10/a-hands-on-tutorial-for-zero-knowledge_2.html)\n- [Appendix](https://www.shirpeled.com/2018/10/a-hands-on-tutorial-for-zero-knowledge_4.html)\n\nZero-Knowledge Proofs for Engineers (Dark Forest)\n\n- [Part I](https://blog.zkga.me/intro-to-zksnarks)\n- [Part II](https://blog.zkga.me/df-init-circuit)\n\nMore complete curated list of implementations and scientific resources:\n[https://zkp.science](https://zkp.science)\n\n## Courses\n\n- [The 9th BIU Winter School on Cryptography: Zero Knowledge](https://cyber.biu.ac.il/event/the-9th-biu-winter-school-on-cryptography/)\n- [UIUC: ECE498AC/CS498AM: Applied Cryptography, Fall 2019](http://soc1024.ece.illinois.edu/teaching/ece498ac/fall2019/)\n- [Zero Knowledge Proof, MOOC Spring 2023](https://zk-learning.org/)\n- [[MIT IAP 2023] Modern Zero Knowledge Cryptography](https://zkiap.com/)\n\n## Use cases\n\n- [Awesome Privacy on Blockchains](https://github.com/Mikerah/awesome-privacy-on-blockchains)\n\n## Applications\n\n### Ethereum\n\n- [ZK Sync](https://medium.com/matter-labs/introducing-zk-sync-the-missing-link-to-mass-adoption-of-ethereum-14c9cea83f58) by [Matter Labs](https://matter-labs.io)\n  - [ZK SDK](https://zksync.io)\n  - [ZK Sync code](https://github.com/matter-labs/zksync)\n  - [ZK Sync live demo](https://demo.matter-labs.io)\n- [SNARK-based permissioned database: rollup by BarryWhitehat](https://github.com/barryWhiteHat/roll_up)\n- [Gnosis dFusion: DEX on SNARKs](https://github.com/gnosis/dex-research/tree/master/dFusion)\n- [Loopring DEX Protocol (v3)](https://github.com/Loopring/protocols/blob/master/packages/loopring_v3/DESIGN.md)\n- [zkPoD: A Practical Decentralized System for Data Exchange](https://github.com/sec-bit/zkPoD-node)\n- [Dark Forest: zkSNARK space warfare strategy game](https://zkga.me/)\n\n### Other blockchains\n\n- [Zcash: Privacy-Protecting Digital Currency](https://z.cash) (SNARKs)\n  - [Community Chat](https://discord.com/invite/zcash)\n  - [Forums](https://forum.zcashcommunity.com)\n- [Monero: Private Digital Currency](https://www.getmonero.org) (Bulletproofs)\n- [Mina Protocol: A Constant-Size Blockchain](https://minaprotocol.com/) (recursive SNARKs)\n  - [YouTube introduction](https://www.youtube.com/watch?v=qCVACpgQSjo)\n- [Grin: Simple, privacy-focused, scalable MimbleWimble chain implementation](https://grin.mw/) (Bulletproofs)\n- [Beam: Private and Scalable Coin based on MimbleWimble](https://www.beam.mw)\n- [Namada: Asset Agnostic, Multichain privacy](https://namada.net/) (SNARKs)\n  - [Youtube Introduction](https://youtu.be/F2cPd7nwG7A?si=iHw93A3ziLc9neH5)\n  - [Specs Documentation](https://specs.namada.net/masp)\n\n### Non-blockchain\n\n- Zero-Knowledge Machine Learning - [awesome-zkml](https://github.com/worldcoin/awesome-zkml)\n- [zk-email](https://github.com/zkemail)\n- [Proof of Passport](https://github.com/zk-passport/proof-of-passport)\n- [Semaphore](https://github.com/semaphore-protocol/semaphore)\n\n## Comparison of the most popular zkp systems\n\n|                                       | SNARKs                     | STARKs                        | Bulletproofs    |\n| ------------------------------------: | -------------------------: | ----------------------------: | --------------: |\n| Algorithmic complexity: prover        | O(N * log(N))              | O(N * poly-log(N))            | O(N * log(N))   |\n| Algorithmic complexity: verifier      | ~O(1)                      | O(poly-log(N))                | O(N)            |\n| Communication complexity (proof size) | ~O(1)                      | O(poly-log(N))                | O(log(N))       |\n| - size estimate for 1 TX              | Tx: 200 bytes, Key: 50 MB  | 45 kB                         | 1.5 kb          |\n| - size estimate for 10.000 TX         | Tx: 200 bytes, Key: 500 GB | 135 kb                        | 2.5 kb          |\n| Ethereum/EVM verification gas cost    | ~600k (Groth16)            | ~2.5M (estimate, no impl.)    | N/A             |\n| Trusted setup required?               | YES :unamused:             | NO :smile:                    | NO :smile:      |\n| Post-quantum secure                   | NO :unamused:              | YES :smile:                   | NO :unamused:   |\n| Crypto assumptions                    | DLP + secure bilinear pairing :unamused:          | Collision resistant hashes :smile: | Discrete log :smirk: |\n\n## Bulletproofs\n\n- [Introduction and collection of resources](https://crypto.stanford.edu/bulletproofs/)\n- [From Zero (Knowledge) to Bulletproofs](https://github.com/AdamISZ/from0k2bp) - a long and very nice gradual explanation\n- [Bulletproofs](http://sikoba.com/docs/SKOR_DK_Bulletproofs_201905.pdf) - succinct and complete description of the protocol\n\n### Try\n\n- [Implementation in Haskell](https://github.com/adjoint-io/bulletproofs)\n- [Implementation in Rust](https://github.com/dalek-cryptography/bulletproofs)\n- [Implementation in C](https://github.com/Tongsuo-Project/Tongsuo)\n\n### Proof system implementations\n\n- [Programmable Constraint Systems for Bulletproofs](https://medium.com/interstellar/programmable-constraint-systems-for-bulletproofs-365b9feb92f7)\n\n### Halo\n\n- [Halo: Recursive bullet proof composition](https://www.coindesk.com/you-can-now-prove-a-whole-blockchain-with-one-math-problem-really)\n\n## SNARKs\n\n> SNARK = **S**uccinct **N**on-interactive **AR**guments of **K**nowledge\n\n### Learn\n\nGet started:\n\n- [Introduction to zk-SNARKs with examples](https://consensys.io/blog/introduction-to-zk-snarks)\n- [What are zk-SNARKs (Zcash blog)](https://z.cash/technology/zksnarks)\n- [BabySNARK- The simplest possible SNARK for NP. You know, for kids!](https://github.com/initc3/babySNARK)\n- [The MoonMath Manual to zk-SNARKs (A free learning resource for beginners to experts)](https://leastauthority.com/community-matters/moonmath-manual/)\n\nWhy and How zk-SNARK Works:\n\n- [Why and How zk-SNARK Works 1: Introduction & the Medium of a Proof](https://medium.com/@imolfar/why-and-how-zk-snark-works-1-introduction-the-medium-of-a-proof-d946e931160)\n- [Why and How zk-SNARK Works 2: Proving Knowledge of a Polynomial](https://medium.com/@imolfar/why-and-how-zk-snark-works-2-proving-knowledge-of-a-polynomial-f817760e2805)\n- [Why and How zk-SNARK Works 3: Non-interactivity & Distributed Setup](https://medium.com/@imolfar/why-and-how-zk-snark-works-3-non-interactivity-distributed-setup-c0310c0e5d1c)\n- [Why and How zk-SNARK Works 4: General-Purpose Computation](https://medium.com/@imolfar/why-and-how-zk-snark-works-4-general-purpose-computation-dcdc8081ee42)\n- [Why and How zk-SNARK Works 5: Variable Polynomials](https://medium.com/@imolfar/why-and-how-zk-snark-works-5-variable-polynomials-3b4e06859e30)\n- [Why and How zk-SNARK Works 6: Verifiable Computation Protocol\n](https://medium.com/@imolfar/why-and-how-zk-snark-works-6-verifiable-computation-protocol-1aa19f95a5cc)\n- [Why and How zk-SNARK Works 7: Constraints and Public Inputs](https://medium.com/@imolfar/why-and-how-zk-snark-works-7-constraints-and-public-inputs-e95f6596dd1c)\n- [Why and How zk-SNARK Works 8: Zero-Knowledge Computation](https://medium.com/@imolfar/why-and-how-zk-snark-works-8-zero-knowledge-computation-f120339c2c55)\n\nZkStudyClub:\n\n- [ZkStudyClub Part 1: Polynomial Commitments with Justin Drake](https://www.youtube.com/watch?v=bz16BURH_u8)\n- [ZkStudyClub Part 2: Polynomial Commitments with Justin Drake](https://www.youtube.com/watch?v=BfV7HBHXfC0)\n- [ZkStudyClub Part 3: Polynomial Commitments with Justin Drake](https://www.youtube.com/watch?v=TbNauD5wgXM)\n\nElectric Coin blog series:\n\n- [Explaining SNARKs Part I: Homomorphic Hidings](https://electriccoin.co/blog/snark-explain/)\n- [Explaining SNARKs Part II: Blind Evaluation of Polynomials](https://electriccoin.co/blog/snark-explain2/)\n- [Explaining SNARKs Part III: The Knowledge of Coefficient Test and Assumption](https://electriccoin.co/blog/snark-explain3/)\n- [Explaining SNARKs Part IV: How to make Blind Evaluation of Polynomials Verifiable](https://electriccoin.co/blog/snark-explain4/)\n- [Explaining SNARKs Part V: From Computations to Polynomials](https://electriccoin.co/blog/snark-explain5/)\n- [Explaining SNARKs Part VI: The Pinocchio Protocol](https://electriccoin.co/blog/snark-explain6/)\n- [Explaining SNARKs Part VII: Pairings of Elliptic Curves](https://electriccoin.co/blog/snark-explain7/)\n\nVitalik Buterin's blog series on SNARKs:\n\n- [Part 1: Quadratic Arithmetic Programs: from Zero to Hero](https://medium.com/@VitalikButerin/quadratic-arithmetic-programs-from-zero-to-hero-f6d558cea649)\n- [Part 2: Exploring Elliptic Curve Pairings](https://medium.com/@VitalikButerin/exploring-elliptic-curve-pairings-c73c1864e627)\n- [Part 3: Zk-SNARKs: Under the Hood](https://medium.com/@VitalikButerin/zk-snarks-under-the-hood-b33151a013f6)\n\nProtocol descriptions:\n\n- [zkSNARKs in a Nutshell](https://chriseth.github.io/notes/articles/zksnarks/zksnarks.pdf)\n- [Groth16 protocol](https://eprint.iacr.org/2016/260.pdf) (original paper)\n- [Zcash Sapling protocol spec](https://github.com/zcash/zips/blob/master/protocol/protocol.pdf) (very useful as detailed cheat-sheet of all cryptography used)\n\n### Try\n\n- [libsnark (C++)](https://github.com/scipr-lab/libsnark)\n  - [great tutorial](https://github.com/christianlundkvist/libsnark-tutorial)\n- [bellman (rust)](https://github.com/zkcrypto/bellman/)\n  - [demo circuit](https://github.com/ebfull/bellman-demo)\n- [jsnark (Java, bindings to libsnark)](https://github.com/akosba/jsnark)\n- [snarky (Ocaml, from O(1) labs, team behind Mina Protocol)](https://github.com/o1-labs/snarky)\n- [zokrates (toolbox for zkSNARKs on Ethereum)](https://github.com/Zokrates/ZoKrates)\n  - [ZoKrates Remix plugin tutorial](https://medium.com/coinmonks/zokrates-zksnarks-on-ethereum-made-easy-8022300f8ba6)\n  - [Zero Knowledge Proof Application Demo, with libsnarks, truffle and docker](https://medium.com/hackernoon/zero-knowledge-proof-application-demo-2a457cfc73c1)\n- [ethsnarks by HarryR (alternative toolkit for viable zk-SNARKS on Ethereum, Web, Mobile and Desktop)](https://github.com/HarryR/ethsnarks)\n- [gnark - library for zero-knowledge proof protocols written in Go](https://github.com/ConsenSys/gnark)\n- [circom and snarkjs tutorial](https://github.com/iden3/circom_old/blob/master/TUTORIAL.md)\n  - [Roll-up tutorial using Circom and SnarkJS by Ying Tong](https://github.com/therealyingtong/roll_up_circom_tutorial)\n  - [A circuit and zk-snark implement using Circom and SnarkJS by Luozhu](https://github.com/LuozhuZhang/zkps-circuit-snark)\n- [SnarkyJS - a TypeScript framework for writing zk-SNARKs in the browser and developing Snapps for Mina Protocol by O(1) labs - WIP](https://github.com/o1-labs/snarkyjs)\n\n### Scaling the prover\n\n- [DIZK: Java library for distributed zero knowledge proof systems with Apache Spark](https://github.com/scipr-lab/dizk) (see the [research paper](https://eprint.iacr.org/2018/691))\n- [SnarkyGPU: distributed GPU based zkSNARKs prover](https://github.com/matterinc/snarkyGPU) (work in progress)\n\n### Multi-Party Ceremony (MPC) for Trusted Setup\n\n- [\u201cPowers of Tau\u201d protocol for scalable generation of structured reference string](https://eprint.iacr.org/2017/1050)\n- [Implementation of ZCash MPC Ceremony, Part I: \"Powers of Tau\"](https://github.com/ebfull/powersoftau)\n  - [Archived independent implementation in Go](https://github.com/FiloSottile/powersoftau/)\n- [Implementation of ZCash MPC Ceremony, Part I: \"Sapling Circuit\"](https://github.com/zcash-hackworks/sapling-mpc)\n\n## SNORKs\n\n> SNORK = **S**uccinct **N**on-interactive **O**ecumenical (Universal) a**R**guments of **K**nowledge\n\nSNORKs are SNARKs with universal and updateable trusted setup.\n\n### Sonic\n\n- [Introducing Sonic: A Practical zk-SNARK with a Nearly Trustless Setup](https://www.benthamsgaze.org/2019/02/07/introducing-sonic-a-practical-zk-snark-with-a-nearly-trustless-setup/)\n- [Sonic: Zero-Knowledge SNARKs from Linear-Size Universal and Updateable Structured Reference Strings](https://eprint.iacr.org/2019/099)\n- [Sonic MPC implementation by Matter Labs](https://github.com/matter-labs/alpha_line)\n\n### PLONK\n\n(This is a recent development. Contributions are welcome!)\n\n- [Awesome PLONK](https://github.com/Fluidex/awesome-plonk): A curated list of awesome things related to plonk proof system.\n- [Understanding PLONK by Vitalik Buterin](https://vitalik.eth.limo/general/2019/09/22/plonk.html)\n- [Ignition: Trusted Setup MPC Ceremony for PLONK](https://medium.com/aztec-protocol/aztec-announcing-our-ignition-ceremony-757850264cfe)\n- [Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge](https://eprint.iacr.org/2019/953.pdf)\n\n\n### Marlin\n\n(This is a recent development. Contributions are welcome!)\n\n- [A Marlin is One of the Fastest SNARKs in the Ocean](https://www.benthamsgaze.org/2019/09/19/a-marlin-is-one-of-the-fastest-snarks-in-the-ocean/)\n- [Marlin: Preprocessing zkSNARKs with Universal and Updatable SRS](https://eprint.iacr.org/2019/1047.pdf)\n\n## STARKS\n\n> STARK = **S**uccinct (**S**calable) **T**ransparent **AR**guments of **K**nowledge\n\nSTARKs are SNARKs without Trusted Setup.\n\n### Learn\n\nGet started:\n\n- [STARK @ Home {video playlist}](https://www.youtube.com/playlist?list=PLcIyXLwiPilUFGw7r2uyWerOkbx4GFMXq)\n\n### FRI-STARKs\n\nIntroduction:\n\n- [Transparent Succinct Arguments by Alessandro Chiesa (Oct 2018)](https://gist.github.com/Haseeb-Qureshi/f552fdbbb649ed4bbfeb681beb4091e1)\n- [State of the STARK by Eli Ben-Sasson (Devcon IV, Oct 2018)](https://drive.google.com/file/d/1Osa0MXu-04dfwn1YOSgN6CXOgWnsp-Tu/view) ([video](https://www.youtube.com/watch?v=1KSwVIZ82hs))\n- [Introduction to ZK-STARKs by remco@0x.org](https://hackmd.io/s/rJHYnQ3Z4)\n\nVitalik Buterin's blog series on STARKs:\n\n- [Part I: Proofs with Polynomials](https://vitalik.eth.limo/general/2017/11/09/starks_part_1.html)\n- [Part II: Thank Goodness It's FRI-day](https://vitalik.eth.limo/general/2017/11/22/starks_part_2.html)\n- [Part III: Into the Weeds](https://vitalik.eth.limo/general/2018/07/21/starks_part_3.html)\n\nAcademic resources:\n\n- [The STARK paper](https://eprint.iacr.org/2018/046.pdf)\n- [libstark implementation](https://github.com/elibensasson/libSTARK)\n\nMore resources available at [starkware.co](https://www.starkware.co)\n\n### SuperSonic\n\n(This is a recent development. Contributions are welcome!)\n\n- [Transparent SNARKs from DARK Compilers (Dec 2019)](https://eprint.iacr.org/2019/1229.pdf)\n- [Introducing Sonic: A Practical zk-SNARK with a Nearly Trustless Setup](https://www.benthamsgaze.org/2019/02/07/introducing-sonic-a-practical-zk-snark-with-a-nearly-trustless-setup/)\n\n### Fractal\n\n(This is a recent development. Contributions are welcome!)\n\n- [Fractal: Post-Quantum and Transparent Recursive Proofs from Holography](https://eprint.iacr.org/2019/1076)\n\n## Social media\n\nStay tuned!\n\n- [Awesome zero knowledge twitter list](https://twitter.com/gluk64/lists/awesome-zkp)\n- [Zero-knowledge podcast](https://www.zeroknowledge.fm)\n- [ZKProof, an academic and industry initiative for standardizing Zero Knowledge Proofs](https://zkproof.org/)\n", "release_dates": []}, {"name": "bellman", "description": "Bellman zkSNARK library for community with Ethereum's BN256 support", "language": "C", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# bellman \"Community edition\"\n \nOriginally developed for ZCash, it has diverged now and focuses solely on the [PLONK](https://eprint.iacr.org/2019/953) proof system. Uses our \"community edition\" pairing for Ethereum's BN256 curve. \n\n## Features\n\nAllows one to design PLONK circuits with custom gates and lookup tables with junction with [franklin-crypto](https://github.com/matter-labs/franklin-crypto) gadget library. At the moment the lookup argument implies using the lookup over the first three state columns (usually refered as A/B/C) and allows to have simultaneously a gate and a lookup applied on the same row of the trace.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Code Examples:\n\n- [Edcon2019_material](https://github.com/matter-labs/Edcon2019_material)\n- [EDCON Workshop record (youtube): Intro to bellman: Practical zkSNARKs constructing for Ethereum](https://www.youtube.com/watch?v=tUY0YGTpehg&t=74s)\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": ["2020-04-09T10:32:10Z", "2019-07-15T11:34:54Z", "2019-03-31T14:48:19Z", "2019-03-05T09:27:47Z"]}, {"name": "Best-README-Template", "description": "An awesome README template to jumpstart your projects! ", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<div id=\"top\"></div>\n<!--\n*** Thanks for checking out the Best-README-Template. If you have a suggestion\n*** that would make this better, please fork the repo and create a pull request\n*** or simply open an issue with the tag \"enhancement\".\n*** Don't forget to give the project a star!\n*** Thanks again! Now go create something AMAZING! :D\n-->\n\n\n\n<!-- PROJECT SHIELDS -->\n<!--\n*** I'm using markdown \"reference style\" links for readability.\n*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).\n*** See the bottom of this document for the declaration of the reference variables\n*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.\n*** https://www.markdownguide.org/basic-syntax/#reference-style-links\n-->\n[![Contributors][contributors-shield]][contributors-url]\n[![Forks][forks-shield]][forks-url]\n[![Stargazers][stars-shield]][stars-url]\n[![Issues][issues-shield]][issues-url]\n[![MIT License][license-shield]][license-url]\n[![LinkedIn][linkedin-shield]][linkedin-url]\n\n\n\n<!-- PROJECT LOGO -->\n<br />\n<div align=\"center\">\n  <a href=\"https://github.com/othneildrew/Best-README-Template\">\n    <img src=\"images/logo.png\" alt=\"Logo\" width=\"80\" height=\"80\">\n  </a>\n\n  <h3 align=\"center\">Best-README-Template</h3>\n\n  <p align=\"center\">\n    An awesome README template to jumpstart your projects!\n    <br />\n    <a href=\"https://github.com/othneildrew/Best-README-Template\"><strong>Explore the docs \u00bb</strong></a>\n    <br />\n    <br />\n    <a href=\"https://github.com/othneildrew/Best-README-Template\">View Demo</a>\n    \u00b7\n    <a href=\"https://github.com/othneildrew/Best-README-Template/issues\">Report Bug</a>\n    \u00b7\n    <a href=\"https://github.com/othneildrew/Best-README-Template/issues\">Request Feature</a>\n  </p>\n</div>\n\n\n\n<!-- TABLE OF CONTENTS -->\n<details>\n  <summary>Table of Contents</summary>\n  <ol>\n    <li>\n      <a href=\"#about-the-project\">About The Project</a>\n      <ul>\n        <li><a href=\"#built-with\">Built With</a></li>\n      </ul>\n    </li>\n    <li>\n      <a href=\"#getting-started\">Getting Started</a>\n      <ul>\n        <li><a href=\"#prerequisites\">Prerequisites</a></li>\n        <li><a href=\"#installation\">Installation</a></li>\n      </ul>\n    </li>\n    <li><a href=\"#usage\">Usage</a></li>\n    <li><a href=\"#roadmap\">Roadmap</a></li>\n    <li><a href=\"#contributing\">Contributing</a></li>\n    <li><a href=\"#license\">License</a></li>\n    <li><a href=\"#contact\">Contact</a></li>\n    <li><a href=\"#acknowledgments\">Acknowledgments</a></li>\n  </ol>\n</details>\n\n\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\n[![Product Name Screen Shot][product-screenshot]](https://example.com)\n\nThere are many great README templates available on GitHub; however, I didn't find one that really suited my needs so I created this enhanced one. I want to create a README template so amazing that it'll be the last one you ever need -- I think this is it.\n\nHere's why:\n* Your time should be focused on creating something amazing. A project that solves a problem and helps others\n* You shouldn't be doing the same tasks over and over like creating a README from scratch\n* You should implement DRY principles to the rest of your life :smile:\n\nOf course, no one template will serve all projects since your needs may be different. So I'll be adding more in the near future. You may also suggest changes by forking this repo and creating a pull request or opening an issue. Thanks to all the people have contributed to expanding this template!\n\nUse the `BLANK_README.md` to get started.\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n### Built With\n\nThis section should list any major frameworks/libraries used to bootstrap your project. Leave any add-ons/plugins for the acknowledgements section. Here are a few examples.\n\n* [Next.js](https://nextjs.org/)\n* [React.js](https://reactjs.org/)\n* [Vue.js](https://vuejs.org/)\n* [Angular](https://angular.io/)\n* [Svelte](https://svelte.dev/)\n* [Laravel](https://laravel.com)\n* [Bootstrap](https://getbootstrap.com)\n* [JQuery](https://jquery.com)\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- GETTING STARTED -->\n## Getting Started\n\nThis is an example of how you may give instructions on setting up your project locally.\nTo get a local copy up and running follow these simple example steps.\n\n### Prerequisites\n\nThis is an example of how to list things you need to use the software and how to install them.\n* npm\n  ```sh\n  npm install npm@latest -g\n  ```\n\n### Installation\n\n_Below is an example of how you can instruct your audience on installing and setting up your app. This template doesn't rely on any external dependencies or services._\n\n1. Get a free API Key at [https://example.com](https://example.com)\n2. Clone the repo\n   ```sh\n   git clone https://github.com/your_username_/Project-Name.git\n   ```\n3. Install NPM packages\n   ```sh\n   npm install\n   ```\n4. Enter your API in `config.js`\n   ```js\n   const API_KEY = 'ENTER YOUR API';\n   ```\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- USAGE EXAMPLES -->\n## Usage\n\nUse this space to show useful examples of how a project can be used. Additional screenshots, code examples and demos work well in this space. You may also link to more resources.\n\n_For more examples, please refer to the [Documentation](https://example.com)_\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- ROADMAP -->\n## Roadmap\n\n- [x] Add Changelog\n- [x] Add back to top links\n- [ ] Add Additional Templates w/ Examples\n- [ ] Add \"components\" document to easily copy & paste sections of the readme\n- [ ] Multi-language Support\n    - [ ] Chinese\n    - [ ] Spanish\n\nSee the [open issues](https://github.com/othneildrew/Best-README-Template/issues) for a full list of proposed features (and known issues).\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- CONTRIBUTING -->\n## Contributing\n\nContributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.\n\nIf you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\nDon't forget to give the project a star! Thanks again!\n\n1. Fork the Project\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- LICENSE -->\n## License\n\nDistributed under the MIT License. See `LICENSE.txt` for more information.\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- CONTACT -->\n## Contact\n\nYour Name - [@your_twitter](https://twitter.com/your_username) - email@example.com\n\nProject Link: [https://github.com/your_username/repo_name](https://github.com/your_username/repo_name)\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- ACKNOWLEDGMENTS -->\n## Acknowledgments\n\nUse this space to list resources you find helpful and would like to give credit to. I've included a few of my favorites to kick things off!\n\n* [Choose an Open Source License](https://choosealicense.com)\n* [GitHub Emoji Cheat Sheet](https://www.webpagefx.com/tools/emoji-cheat-sheet)\n* [Malven's Flexbox Cheatsheet](https://flexbox.malven.co/)\n* [Malven's Grid Cheatsheet](https://grid.malven.co/)\n* [Img Shields](https://shields.io)\n* [GitHub Pages](https://pages.github.com)\n* [Font Awesome](https://fontawesome.com)\n* [React Icons](https://react-icons.github.io/react-icons/search)\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- MARKDOWN LINKS & IMAGES -->\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n[contributors-shield]: https://img.shields.io/github/contributors/othneildrew/Best-README-Template.svg?style=for-the-badge\n[contributors-url]: https://github.com/othneildrew/Best-README-Template/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/othneildrew/Best-README-Template.svg?style=for-the-badge\n[forks-url]: https://github.com/othneildrew/Best-README-Template/network/members\n[stars-shield]: https://img.shields.io/github/stars/othneildrew/Best-README-Template.svg?style=for-the-badge\n[stars-url]: https://github.com/othneildrew/Best-README-Template/stargazers\n[issues-shield]: https://img.shields.io/github/issues/othneildrew/Best-README-Template.svg?style=for-the-badge\n[issues-url]: https://github.com/othneildrew/Best-README-Template/issues\n[license-shield]: https://img.shields.io/github/license/othneildrew/Best-README-Template.svg?style=for-the-badge\n[license-url]: https://github.com/othneildrew/Best-README-Template/blob/master/LICENSE.txt\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555\n[linkedin-url]: https://linkedin.com/in/othneildrew\n[product-screenshot]: images/screenshot.png\n", "release_dates": []}, {"name": "block-explorer", "description": "zkSync Era Block Explorer", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<h1 align=\"center\">zkSync Era Block Explorer</h1>\n\n<p align=\"center\">Online blockchain browser for viewing and analyzing <a href=\"https://zksync.io\">zkSync Era</a> blockchain.</p>\n\n## \ud83d\udccc Overview\nThis repository is a monorepo consisting of 4 packages:\n- [Worker](./packages/worker) - an indexer service for [zkSync Era](https://zksync.io) blockchain data. The purpose of the service is to read blockchain data in real time, transform it and fill in it's database with the data in a way that makes it easy to be queried by the [API](./packages/api) service.\n- [Data Fetcher](./packages/data-fetcher) - a service that exposes and implements an HTTP endpoint to retrieve aggregated data for a certain block / range of blocks from the blockchain. This endpoint is called by the [Worker](./packages/worker) service.\n- [API](./packages/api) - a service providing Web API for retrieving structured [zkSync Era](https://zksync.io) blockchain data collected by [Worker](./packages/worker). It connects to the Worker's database to be able to query the collected data.\n- [App](./packages/app) - a front-end app providing an easy-to-use interface for users to view and inspect transactions, blocks, contracts and more. It makes requests to the [API](./packages/api) to get the data and presents it in a way that's easy to read and understand.\n\n## \ud83c\udfdb Architecture\nThe following diagram illustrates how are the block explorer components connected:\n\n```mermaid\nflowchart\n  subgraph blockchain[Blockchain]\n    Blockchain[zkSync Era JSON-RPC API]\n  end\n\n  subgraph explorer[Block explorer]\n    Database[(\"Block explorer DB<br/>(PostgreSQL)\")]\n    Worker(Worker service)\n    Data-Fetcher(Data Fetcher service)\n    API(API service)\n    App(App)\n    \n    Worker-.\"Request aggregated data (HTTP)\".->Data-Fetcher\n    Data-Fetcher-.\"Request data (HTTP)\".->Blockchain\n    Worker-.Save processed data.->Database\n\n    API-.Query data.->Database\n    App-.\"Request data (HTTP)\".->API\n    App-.\"Request data (HTTP)\".->Blockchain\n  end\n\n  Worker-.\"Request data (HTTP)\".->Blockchain\n```\n\n[Worker](./packages/worker) service retrieves aggregated data from the [Data Fetcher](./packages/data-fetcher) via HTTP and also directly from the blockchain using [zkSync Era JSON-RPC API](https://era.zksync.io/docs/api/api.html), processes it and saves into the database. [API](./packages/api) service is connected to the same database where it gets the data from to handle API requests. It performs only read requests to the database. The front-end [App](./packages/app) makes HTTP calls to the Block Explorer [API](./packages/api) to get blockchain data and to the [zkSync Era JSON-RPC API](https://era.zksync.io/docs/api/api.html) for reading contracts, performing transactions etc.\n\n## \ud83d\ude80 Features\n\n- \u2705 View transactions, blocks, transfers and logs.\n- \u2705 Inspect accounts, contracts, tokens and balances.\n- \u2705 Verify smart contracts.\n- \u2705 Interact with smart contracts.\n- \u2705 Standalone HTTP API.\n- \u2705 Local node support.\n\n## \ud83d\udccb Prerequisites\n\n- Ensure you have `node >= 18.0.0` and `npm >= 9.0.0` installed.\n\n## \ud83d\udee0 Installation\n\n```bash\nnpm install\n```\n\n## \u2699\ufe0f Setting up env variables\n\n### Manually set up env variables\nMake sure you have set up all the necessary env variables. Follow setting up env variables instructions for [Worker](./packages/worker#setting-up-env-variables), [Data Fetcher](./packages/data-fetcher#setting-up-env-variables) and [API](./packages/api#setting-up-env-variables). For the [App](./packages/app) package you might want to edit environment config, see [Environment configs](./packages/app#environment-configs).\n\n### Build env variables based on your [zksync-era](https://github.com/matter-labs/zksync-era) local repo setup\nMake sure you have [zksync-era](https://github.com/matter-labs/zksync-era) repo set up locally. You must have your environment variables files present in the [zksync-era](https://github.com/matter-labs/zksync-era) repo at `/etc/env/*.env` for the build envs script to work.\n\nThe following script sets `.env` files for [Worker](./packages/worker), [Data Fetcher](./packages/data-fetcher) and [API](./packages/api) packages as well as environment configuration file for [App](./packages/app) package based on your local [zksync-era](https://github.com/matter-labs/zksync-era) repo setup.\n```bash\nnpm run hyperchain:configure\n```\nYou can review and edit generated files if you need to change any settings.\n\n## \ud83d\udc68\u200d\ud83d\udcbb Running locally\n\nBefore running the solution, make sure you have a database server up and running, you have created a database and set up all the required environment variables.\nTo create a database run the following command:\n```bash\nnpm run db:create\n```\n\nTo run all the packages (`Worker`, `Data Fetcher`, `API` and front-end `App`) in `development` mode run the following command from the root directory.\n```bash\nnpm run dev\n```\n\nFor `production` mode run:\n```bash\nnpm run build\nnpm run start\n```\n\nEach component can also be started individually. Follow individual packages `README` for details.\n\n## \ud83d\udc33 Running in Docker\nThere is a docker compose configuration that allows you to run Block Explorer and all its dependencies in docker. Just run the following command to spin up the whole environment:\n```\ndocker compose up\n```\nIt will run local Ethereum node, ZkSync Era, Postgres DB and all Block Explorer services.\n\n## \u26d3\ufe0f Connection to your Hyperchain\nTo get block-explorer connected to your ZK Stack Hyperchain you need to set up all the the necessary environment and configuration files with your Hyperchain settings. You can use a script to build them. See [Setting up env variables](#%EF%B8%8F-setting-up-env-variables).\n\n## \ud83d\udd0d Verify Block Explorer is up and running\n\nTo verify front-end `App` is running open http://localhost:3010 in your browser. `API` should be available at http://localhost:3020, `Worker` at http://localhost:3001 and `Data Fetcher` at http://localhost:3040.\n\n## \ud83d\udd75\ufe0f\u200d\u2642\ufe0f Testing\nRun unit tests for all packages:\n```bash\nnpm run test\n```\nRun e2e tests for all packages:\n```bash\nnpm run test:e2e\n```\nRun tests for a specific package:\n```bash\nnpm run test -w {package}\n```\nFor more details on testing please check individual packages `README`.\n\n## \ud83d\udcbb Conventional Commits\nWe follow the Conventional Commits [specification](https://www.conventionalcommits.org/en/v1.0.0/#specification).\n\n## \ud83d\udcd8 License\nzkSync Era Block Explorer is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## \ud83d\udd17 Production links\n- Testnet Goerli API: https://block-explorer-api.testnets.zksync.dev\n- Testnet Sepolia API: https://block-explorer-api.sepolia.zksync.dev\n- Mainnet API: https://block-explorer-api.mainnet.zksync.io\n- Testnet Goerli App: https://goerli.explorer.zksync.io\n- Testnet Sepolia App: https://sepolia.explorer.zksync.io\n- Mainnet App: https://explorer.zksync.io\n", "release_dates": ["2024-03-01T14:15:33Z", "2024-02-29T13:46:25Z", "2024-02-28T19:10:24Z", "2024-02-26T09:49:44Z", "2024-02-24T11:34:16Z", "2024-02-24T13:20:21Z", "2024-02-07T14:12:06Z", "2024-02-06T06:10:01Z", "2024-01-18T12:53:19Z", "2024-01-16T12:46:09Z", "2024-01-03T10:01:12Z", "2023-12-22T16:05:40Z", "2023-12-20T07:03:12Z", "2023-12-19T16:27:11Z", "2023-12-19T16:01:36Z", "2023-12-19T14:59:13Z", "2023-12-19T14:12:40Z", "2023-12-19T13:23:24Z", "2023-12-19T11:37:56Z", "2023-12-17T06:21:46Z", "2023-12-16T19:50:44Z", "2023-12-16T18:55:28Z", "2023-12-16T17:43:29Z", "2023-12-16T16:38:54Z", "2023-12-15T12:12:09Z", "2023-12-13T15:14:39Z", "2023-12-12T16:06:31Z", "2023-12-12T10:47:40Z", "2023-12-11T18:38:11Z", "2023-12-11T10:19:47Z"]}, {"name": "blockscout", "description": "Blockchain explorer for Ethereum based network and a tool for inspecting and analyzing EVM based blockchains. ", "language": "Elixir", "license": {"key": "gpl-3.0", "name": "GNU General Public License v3.0", "spdx_id": "GPL-3.0", "url": "https://api.github.com/licenses/gpl-3.0", "node_id": "MDc6TGljZW5zZTk="}, "readme": "<h1 align=\"center\">BlockScout</h1>\n<p align=\"center\">Blockchain Explorer for inspecting and analyzing EVM Chains.</p>\n<div align=\"center\">\n\n[![Blockscout](https://github.com/blockscout/blockscout/workflows/Blockscout/badge.svg?branch=master)](https://github.com/blockscout/blockscout/actions) [![Join the chat at https://gitter.im/poanetwork/blockscout](https://badges.gitter.im/poanetwork/blockscout.svg)](https://gitter.im/poanetwork/blockscout?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n</div>\n\nBlockScout provides a comprehensive, easy-to-use interface for users to view, confirm, and inspect transactions on EVM (Ethereum Virtual Machine) blockchains. This includes the POA Network, xDai Chain, Ethereum Classic and other **Ethereum testnets, private networks and sidechains**.\n\nSee our [project documentation](https://docs.blockscout.com/) for detailed information and setup instructions.\n\nVisit the [POA BlockScout forum](https://forum.poa.network/c/blockscout) for FAQs, troubleshooting, and other BlockScout related items. You can also post and answer questions here.\n\nYou can also access the dev chatroom on our [Gitter Channel](https://gitter.im/poanetwork/blockscout).\n\n## About BlockScout\n\nBlockScout is an Elixir application that allows users to search transactions, view accounts and balances, and verify smart contracts on the Ethereum network including all forks and sidechains.\n\nCurrently available full-featured block explorers (Etherscan, Etherchain, Blockchair) are closed systems which are not independently verifiable.  As Ethereum sidechains continue to proliferate in both private and public settings, transparent, open-source tools are needed to analyze and validate transactions.\n\n## Supported Projects\n\nBlockScout supports a number of projects. Hosted instances include POA Network, xDai Chain, Ethereum Classic, Sokol & Kovan testnets, and other EVM chains. \n\n- [List of hosted mainnets, testnets, and additional chains using BlockScout](https://docs.blockscout.com/for-projects/supported-projects)\n- [Hosted instance versions](https://docs.blockscout.com/about/use-cases/hosted-blockscout)\n\n\n## Getting Started\n\nSee the [project documentation](https://docs.blockscout.com/) for instructions:\n- [Requirements](https://docs.blockscout.com/for-developers/information-and-settings/requirements)\n- [Ansible deployment](https://docs.blockscout.com/for-developers/ansible-deployment)\n- [Manual deployment](https://docs.blockscout.com/for-developers/manual-deployment)\n- [ENV variables](https://docs.blockscout.com/for-developers/information-and-settings/env-variables)\n- [Configuration options](https://docs.blockscout.com/for-developers/configuration-options)\n\n\n## Acknowledgements\n\nWe would like to thank the [EthPrize foundation](http://ethprize.io/) for their funding support.\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for contribution and pull request protocol. We expect contributors to follow our [code of conduct](CODE_OF_CONDUCT.md) when submitting code or comments.\n\n## License\n\n[![License: GPL v3.0](https://img.shields.io/badge/License-GPL%20v3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n\nThis project is licensed under the GNU General Public License v3.0. See the [LICENSE](LICENSE) file for details.\n", "release_dates": ["2023-10-13T14:00:30Z", "2023-10-13T13:19:49Z", "2023-10-13T12:41:35Z", "2023-10-13T12:05:13Z", "2023-10-13T08:48:09Z", "2023-10-10T21:47:10Z", "2022-12-05T11:36:21Z", "2022-11-30T12:11:34Z", "2022-11-30T10:34:28Z", "2022-11-29T08:59:36Z", "2022-10-13T09:10:17Z", "2022-09-16T09:56:59Z", "2022-07-21T10:08:33Z", "2022-04-27T08:18:37Z", "2022-04-21T11:19:36Z", "2022-04-15T05:41:36Z", "2022-04-14T13:51:28Z", "2022-04-11T17:17:10Z", "2022-04-09T14:14:16Z", "2022-03-28T13:27:53Z", "2022-03-28T12:27:10Z", "2022-03-23T00:16:42Z", "2022-03-10T09:14:15Z", "2021-12-10T09:25:36Z", "2021-12-06T16:41:30Z"]}, {"name": "bn254", "description": null, "language": null, "license": null, "readme": "# bn254\n[![](https://img.shields.io/crates/v/bn254.svg)](https://crates.io/crates/bn254) [![](https://docs.rs/bn254/badge.svg)](https://docs.rs/bn254)\n\n`bn254` is an open-source Rust implementation of aggregate signatures over the pairing-friendly elliptic curve BN254 ([Barreto-Naehrig (BN)](https://www.cryptojedi.org/papers/pfcpo.pdf)).\n\nThis curve is also known as `bn256` or `bn128` (`alt-bn128`) referred to the bits of security. The bits of security of `bn254` dropped from 128 to around 100 after the new algorithms of [Kim-Barbulescu](https://eprint.iacr.org/2015/1027.pdf).\n\n_DISCLAIMER_: This is experimental software. Be careful!\n\n## Usage\n\nThis module uses the [substrate-bn](https://github.com/paritytech/bn) library to perform elliptic curve operations over the appropriate fields. It provides the following functionalities:\n\n* `sign`: Sign a message given a secret key.\n* `verify`: Given a public key, a signature, and a message it verifies whether the signature is valid.\n\nSignature and public aggregation can be done directly with the `+` or `-` operators.\n\n## Hashing to G1\n\nThe algorithm used for hashing a given message into a point in G1 follows the \"try-and-increment\" method. We discourage its usage in the cases of hashing secret messages since its running time leaks information about the input.\n\nIn other cases, where the message to be hashed is public, \"try-and-increment\" should be safe. The hashing algorithm utilized is `sha256`.\n\n## Example\n\nSign, aggregate and verify by using the `bn254` curve:\n\n```rust\nuse bn254::{PrivateKey, PublicKey, ECDSA};\n\nfn main() {\n    // Inputs: Secret Key, Public Key (derived) & Message\n\n    // Secret key one\n    let private_key_1_bytes = hex::decode(\"c9afa9d845ba75166b5c215767b1d6934e50c3db36e89b127b8a622b120f6721\").unwrap();\n    let private_key_1 = PrivateKey::try_from(private_key_1_bytes.as_ref()).unwrap();\n\n    // Secret key two\n    let private_key_2_bytes = hex::decode(\"a55e93edb1350916bf5beea1b13d8f198ef410033445bcb645b65be5432722f1\").unwrap();\n    let private_key_2 = PrivateKey::try_from(private_key_2_bytes.as_ref()).unwrap();\n\n    // Derive public keys from secret key\n    let public_key_1 = PublicKey::from_private_key(&private_key_1);\n    let public_key_2 = PublicKey::from_private_key(&private_key_2);\n\n    let message: &[u8] = b\"sample\";\n\n    // Sign identical message with two different secret keys\n    let signature_1 = ECDSA::sign(&message, &private_key_1).unwrap();\n    let signature_2 = ECDSA::sign(&message, &private_key_2).unwrap();\n\n    // Aggregate public keys\n    let aggregate_pub_key = public_key_1 + public_key_2;\n\n    // Aggregate signatures\n    let aggregate_sig = signature_1 + signature_2;\n\n    // Check whether the aggregate signature corresponds to the aggregated\n    // public_key\n    ECDSA::verify(&message, &aggregate_sig, &aggregate_pub_key).unwrap();\n    println!(\"Successful aggregate signature verification\");\n}\n```\n\n## License\n\n`bn254` is published under the [MIT license](https://github.com/sedaprotocol/bn254/blob/main/LICENSE.md)", "release_dates": []}, {"name": "cli-empty-template", "description": "Empty template project for zkSync CLI", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Hardhat project\n\nThis project was scaffolded with [zksync-cli](https://github.com/matter-labs/zksync-cli).\n\n## Project structure\n\n- `/contracts`: smart contracts.\n- `/deploy`: deployment and contract interaction scripts.\n- `/test`: test files\n- `hardhat.config.ts`: configuration file.\n\n## Commands\n\n- `yarn hardhat compile` will compile the contracts.\n- `yarn run deploy` will execute the deployment scripts inside the `/deploy` folder.\n- `yarn test`: run tests. **Check test requirements below.**\n\n\n### Environment variables\n\nIn order to prevent users to leak private keys, this project includes the `dotenv` package which is used to load environment variables. It's recommended to use it to load the wallet private key in different scripts like deploy.\n\nTo use it, rename `.env.example` to `.env` and enter your private key.\n\n```\nWALLET_PRIVATE_KEY=123cde574ccff....\n```\n\n### Local testing\n\nIn order to run test, you need to start the zkSync local environment. Please check [this section of the docs](https://v2-docs.zksync.io/api/hardhat/testing.html#prerequisites) which contains all the details.\n\nIf you do not start the zkSync local environment, the tests will fail with error `Error: could not detect network (event=\"noNetwork\", code=NETWORK_ERROR, version=providers/5.7.2)`\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n", "release_dates": []}, {"name": "cloudflare-access-grafana", "description": "Small proxy for automatically log in users from Cloudflare Access into Grafana", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# cloudflare-access-grafana\n\n![Docker pulls](https://badgen.net/docker/pulls/jorgelbg/cloudflare-access-grafana?icon=docker&color=purple)\n\n<p align=\"center\">\n    <img class=\"center\" src=\"docs/logo.svg\" width=\"150\" alt=\"cloudflare access grafana logo\"/>\n</p>\n\ncloudflare-access-grafana is an HTTP proxy implemented to run transparently behind [Cloudflare\nAccess](https://teams.cloudflare.com/access/) and forward the email of the signed-in user to Grafana.\nRunning this small proxy between Cloudflare Access and Grafana instance allows you to\nautomatically sign in the authenticated user from Cloudflare Access into Grafana.\n\n## \ud83d\udce5 Installation / Getting started\n\nTo accomplish this Grafana has to run in with the [Auth Proxy\nAuthentication](https://grafana.com/docs/grafana/latest/auth/auth-proxy/) mode enabled. This will\ndelegate the authentication to another component: Cloudflare Access + cloudflare-access-grafana in\nthis case.\n\nA minimal `grafana.ini` config could look like this:\n\n```ini\n[users]\nallow_sign_up = false\nauto_assign_org = true\nauto_assign_org_role = Editor\n\n[auth.proxy]\nenabled = true\nheader_name = X-WEBAUTH-USER\nheader_property = email\nauto_sign_up = true\n```\n\nRunning a Grafana docker container with the previous configuration can be done with the following command:\n\n```shell\n$ docker run --rm --name grafana -i -p 3000:3000 -v $(pwd)/grafana.ini:/etc/grafana/grafana.ini --name grafana grafana/grafana\n```\n\nIn this case, the `header_property` set to `email` is important because the email is the claim\nthat we get from the JWT token provided by Cloudflare Access. `header_name` can be configured to any\ndesired value and will need to match the `FORWARDHEADER` environment variable passed into\ncloudflare-access-grafana.\n\nYou can copy the template from [.env.template](.env.template) into your environment file and adjust\nthe required values. Now you can run the cloudflare-access-grafana container with the following command:\n\n```\n$ cp .env.template .env\n$ docker run --rm -d --env-file $(pwd)/.env --name cloudflare-proxy -p 3001:3001 jorgelbg/cloudflare-access-grafana\n```\n\nThis will start the proxy on the specified address and it will start to listen for incoming requests.\nWhen a new HTTP request is received it will validate the JWT token, extract the `email` claim from\nthe token and forward to the specified host the header with the email address. Grafana will then\nautomatically signup/sign in (depending on the configuration) the user.\n\n> Additional configuration on the Cloudflare Access is required to route your subdomain/DNS entry\n> into the cloudflare-access-grafana instance. Grafana doesn't need to be accessible externally since\n> all requests will go through the proxy.\n\n## \ud83d\udc7e Known Issues\n\nSince the authentication is no longer on the Grafana side, the logout action will not work as\nexpected. Although it will execute normally, you will find yourself logged in again. This happens\nbecause the current user has not been logged out of Cloudflare Access.\n\n## \ud83d\udee0 Configuration\n\nAll the configuration options are passed to cloudflare-access-proxy as environment variables:\n\n* `AUTHDOMAIN`: This is your cloudflare authentication domain. Normally in the form of `https://<your-own-domain>.cloudflareaccess.com`.\n* `POLICYAUD`: Application Audience (AUD) Tag.\n* `FORWARDHEADER`: The header to be forwarded to Grafana to indicate which user is currently logged in.\n* `FORWARDHOST`: URL where the Grafana instance (with `auth.proxy` enabled) is running.\n* `ADDR`: Address where the cloudflare-access-proxy will listen for incoming connections.\n\n## \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb Developing\n\n```shell\ngit clone https://github.com/jorgelbg/cloudflare-access-grafana\ncd cloudflare-access-grafana/\nmake\n```\n\nThis will build a binary placed in `bin/github.com/jorgelbg/cloudflare-access-grafana` for your native platform.\n\nIf you want to build a new Docker image use the following command:\n\n```shell\nmake docker\n```\n\n## \ud83e\udd1a\ud83c\udffb Contributing\n\nIf you'd like to contribute, please fork the repository and use a feature\nbranch. Pull requests are warmly welcome.\n\n## \ud83d\ude80 Links\n\n- The project logo is based on [Cloudflare icon](https://icons8.com/icons/set/cloudflare) by [Icons8](https://icons8.com). And the [Grafana icon](https://grafana.com/).\n", "release_dates": []}, {"name": "compiler-explorer", "description": "Run compilers interactively from your web browser and interact with the assembly", "language": "TypeScript", "license": {"key": "bsd-2-clause", "name": "BSD 2-Clause \"Simplified\" License", "spdx_id": "BSD-2-Clause", "url": "https://api.github.com/licenses/bsd-2-clause", "node_id": "MDc6TGljZW5zZTQ="}, "readme": "[![Build Status](https://github.com/compiler-explorer/compiler-explorer/workflows/Compiler%20Explorer/badge.svg)](https://github.com/compiler-explorer/compiler-explorer/actions?query=workflow%3A%22Compiler+Explorer%22)\n[![codecov](https://codecov.io/gh/compiler-explorer/compiler-explorer/branch/main/graph/badge.svg)](https://codecov.io/gh/compiler-explorer/compiler-explorer)\n\n![Compiler Explorer](views/resources/site-logo.svg)\n\n# Compiler Explorer\n\n**Compiler Explorer** is an interactive compiler exploration website. Edit code in C, C++, C#, F#, Rust, Go, D, Haskell,\nSwift, Pascal, [ispc](https://ispc.github.io/), Python, Java or in any of the other\n[30+ supported languages](https://godbolt.org/api/languages), and see how that code looks after being compiled in real\ntime. Multiple compilers are supported for each language, many different tools and visualisations are available, and the\nUI layout is configurable (thanks to [GoldenLayout](https://www.golden-layout.com/)).\n\nTry out at [godbolt.org](https://godbolt.org), or [run your own local instance](#running-a-local-instance).\n\n**Compiler Explorer** follows a [Code of Conduct](CODE_OF_CONDUCT.md) which aims to foster an open and welcoming\nenvironment.\n\n**Compiler Explorer** was started in 2012 to show how C++ constructs translated to assembly code. It started out as a\n`tmux` session with `vi` running in one pane and `watch gcc -S foo.cc -o -` running in the other.\n\nSince then, it has become a public website serving around\n[3,000,000 compilations per week](https://www.stathat.com/cards/Tk5csAWI0O7x).\n\nYou can financially support [this project on Patreon](https://patreon.com/mattgodbolt),\n[GitHub](https://github.com/sponsors/mattgodbolt/),\n[Paypal](https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=KQWQZ7GPY2GZ6&item_name=Compiler+Explorer+development&currency_code=USD&source=url),\nor by buying cool gear on the [Compiler Explorer store](https://shop.spreadshirt.com/compiler-explorer/).\n\n## Using Compiler Explorer\n\n### FAQ\n\nThere is now a FAQ section [in the repository wiki](https://github.com/compiler-explorer/compiler-explorer/wiki/FAQ). If\nyour question is not present, please contact us as described below, so we can help you. If you find that the FAQ is\nlacking some important point, please free to contribute to it and/or ask us to clarify it.\n\n### Videos\n\nThere are a number of videos that showcase some features of Compiler Explorer:\n\n- [Presentation for CppCon 2019 about the project](https://www.youtube.com/watch?v=kIoZDUd5DKw)\n- [Older 2 part series of videos](https://www.youtube.com/watch?v=4_HL3PH4wDg) which go into a bit more detail into the\n  more obscure features.\n- [Just Enough Assembly for Compiler Explorer](https://youtu.be/QLolzolunJ4): Practical introduction to Assembly with a\n  focus on usage on Compiler Explorer, from CppCon 2021.\n- [Playlist: Compiler Explorer](https://www.youtube.com/playlist?list=PL2HVqYf7If8dNYVN6ayjB06FPyhHCcnhG): A collection\n  of videos discussing Compiler Explorer; using it, installing it, what it's for, etc.\n\nA [Road map](docs/Roadmap.md) is available which gives a little insight into the future plans for **Compiler Explorer**.\n\n## Developing\n\n**Compiler Explorer** is written in [Node.js](https://nodejs.org/).\n\nAssuming you have a compatible version of `node` installed, on Linux simply running `make` ought to get you up and\nrunning with an Explorer running on port 10240 on your local machine:\n[http://localhost:10240/](http://localhost:10240/). If this doesn't work for you, please contact us, as we consider it\nimportant you can quickly and easily get running. Currently, **Compiler Explorer** requires\n[`node` 16 _(LTS version)_](CONTRIBUTING.md#node-version) installed, either on the path or at `NODE_DIR` (an environment\nvariable or `make` parameter).\n\nRunning with `make EXTRA_ARGS='--language LANG'` will allow you to load `LANG` exclusively, where `LANG` is one for the\nlanguage ids/aliases defined in `lib/languages.ts`. For example, to only run **Compiler Explorer** with C++ support,\nyou'd run `make EXTRA_ARGS='--language c++'`. The `Makefile` will automatically install all the third party libraries\nneeded to run; using `npm` to install server-side and client side components.\n\nFor development, we suggest using `make dev` to enable some useful features, such as automatic reloading on file changes\nand shorter startup times.\n\nYou can also use `npm run dev` to run if `make dev` doesn't work on your machine.\n\nSome languages need extra tools to demangle them, e.g. `rust`, `d`, or `haskell`. Such tools are kept separately in the\n[tools repo](https://github.com/compiler-explorer/compiler-explorer-tools).\n\nConfiguring compiler explorer is achieved via configuration files in the `etc/config` directory. Values are `key=value`.\nOptions in a `{type}.local.properties` file (where `{type}` is `c++` or similar) override anything in the\n`{type}.defaults.properties` file. There is a `.gitignore` file to ignore `*.local.*` files, so these won't be checked\ninto git, and you won't find yourself fighting with updated versions when you `git pull`. For more information see\n[Adding a Compiler](docs/AddingACompiler.md).\n\nCheck [CONTRIBUTING.md](./CONTRIBUTING.md) for detailed information about how you can contribute to **Compiler\nExplorer**, and the [docs](./docs) folder for specific details regarding various things you might want to do, such as\nhow to add new compilers or languages to the site.\n\n### Running a local instance\n\nIf you want to point it at your own GCC or similar binaries, either edit the `etc/config/LANG.defaults.properties` or\nelse make a new one with the name `LANG.local.properties`, substituting `LANG` as needed. `*.local.properties` files\nhave the highest priority when loading properties.\n\nWhen running in a corporate setting the URL shortening service can be replaced by an internal one if the default storage\ndriver isn't appropriate for your environment. To do this, add a new module in `lib/shortener/myservice.js` and set the\n`urlShortenService` variable in configuration. This module should export a single function, see the\n[tinyurl module](lib/shortener/tinyurl.js) for an example.\n\n### RESTful API\n\nThere's a simple restful API that can be used to do compiles to asm and to list compilers.\n\nYou can find the API documentation [here](docs/API.md).\n\n## Contact us\n\nWe run a [Compiler Explorer Discord](https://discord.gg/B5WacA7), which is a place to discuss using or developing\nCompiler Explorer. We also have a presence on the [cpplang](https://cppalliance.org/slack/) Slack channel\n`#compiler_explorer` and we have\n[a public mailing list](https://groups.google.com/forum/#!forum/compiler-explorer-discussion).\n\nThere's a development channel on the discord, and also a\n[development mailing list](https://groups.google.com/forum/#!forum/compiler-explorer-development).\n\nFeel free to raise an issue on [github](https://github.com/compiler-explorer/compiler-explorer/issues) or\n[email Matt directly](mailto:matt@godbolt.org) for more help.\n\n## Credits\n\n**Compiler Explorer** is maintained by the awesome people listed in the [AUTHORS](AUTHORS.md) file.\n\nWe would like to thank the contributors listed in the [CONTRIBUTORS](CONTRIBUTORS.md) file, who have helped shape\n**Compiler Explorer**.\n\nWe would also like to specially thank these people for their contributions to **Compiler Explorer**:\n\n- [Gabriel Devillers](https://github.com/voxelf) (_while working for [Kalray](http://www.kalrayinc.com/)_)\n- [Johan Engelen](https://github.com/JohanEngelen)\n- [Joshua Sheard](https://github.com/jsheard)\n- [Andrew Pardoe](https://github.com/AndrewPardoe)\n\nA number of [amazing sponsors](https://godbolt.org/#sponsors), both individuals and companies, have helped fund and\npromote Compiler Explorer.\n", "release_dates": []}, {"name": "compiler-explorer-infra", "description": "Infrastructure to set up the public Compiler Explorer instances and compilers", "language": null, "license": {"key": "bsd-2-clause", "name": "BSD 2-Clause \"Simplified\" License", "spdx_id": "BSD-2-Clause", "url": "https://api.github.com/licenses/bsd-2-clause", "node_id": "MDc6TGljZW5zZTQ="}, "readme": "# Compiler Explorer Infrastructure\n\nA whole bag of scripts and AWS config to run [Compiler Explorer](https://gcc.godbolt.org).\n\nOf most use to the casual observer is probably the code in `bin/ce_install` - a tool to install the\nCompiler Explorer compilers to `/opt/compiler-explorer`. In particular, the open source compilers can be\ninstalled by anyone by running:\n\n```bash\n$ make ce  # this installs python modules etc\n$ ./bin/ce_install install compilers\n```\n\nThis will grab all the open source compilers and put them in `/opt/compiler-explorer` (which must be writable by\nthe current user).  To get the beta and nightly-built latest compilers, add the parameter `--enable nightly` to the command.\n\nTo list installation candidates, use `./bin/ce_install list`. A single installation can be installed by name.\n\n# Built compilers\n\nStatus page to our daily built compilers https://compiler-explorer.github.io/compiler-workflows/build-status\n", "release_dates": []}, {"name": "compiler-infra", "description": "Docker images with build tools for compiler repos", "language": "Dockerfile", "license": null, "readme": "", "release_dates": []}, {"name": "cross-chain-tutorial", "description": null, "language": "TypeScript", "license": null, "readme": "# Cross-chain governance full example\n\nThis is the full example for the zkSync \"Cross-chain governance\" tutorial.\n\nIt consists of two folders:\n\n- `deploy-governance` which contains the hardhat project that is used to deploy the governance smart contract on G\u00f6rli.\n- `counter` which contains the hardhat project for the `Counter` L2 smart contract. It also contains scripts that are used to display the value of the counter as well as to call the governance to update the counter from L1.\n", "release_dates": []}, {"name": "curve-zinc", "description": "The Curve Stableswap smart contract implementation in Zinc v0.2.2.", "language": "Rust", "license": null, "readme": "# Curve on Zinc\r\n\r\nThe **Curve Stableswap** smart contract implementation in **Zinc v0.2.2**.\r\n\r\nThe official [Zinc book](https://zinc.zksync.io/).\r\n", "release_dates": []}, {"name": "custom-aa-tutorial", "description": "A full example for the tutorial on custom AA", "language": "Solidity", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Account abstraction tutorial\n\nCode for the \"Account abstraction\" tutorial from the [zkSync v2 documentation](https://v2-docs.zksync.io/dev/).\n\nYou can find a full step-by-step guide to build this project [in this article](https://v2-docs.zksync.io/dev/tutorials/custom-aa-tutorial.html#prerequisite).\n\n## Installation and compilation\n\nYou need Node.js and Yarn.\n\nInstall all dependencies with `yarn`.\n\nCompile contracts with `yarn hardhat compile`\n\n## Deployment and usage\n\nTo run the scripts to deploy and execute the contracts, use the `zksync-deploy` command:\n\n- `yarn hardhat deploy-zksync --script deploy-factory.ts`: deploys the factory contract\n- `yarn hardhat deploy-zksync --script deploy-multisig.ts`: deploys a multisig wallet and executes a transaction.\n\n## Support\n\nCheck out the [common errors section in the tutorial](https://v2-docs.zksync.io/dev/tutorials/custom-paymaster-tutorial.html#prerequisite), open an issue, or [contact us on Discord](https://discord.com/invite/px2aR7w).\n", "release_dates": []}, {"name": "custom-paymaster-tutorial", "description": "Full example for the custom paymaster tutorial in the documentation", "language": "TypeScript", "license": null, "readme": "# Custom Paymaster Tutorial \ud83d\udcd6\n\nWelcome aboard to the custom paymaster journey with zkSync! \ud83d\ude80\ud83c\udf0c\n\nThis repository is crafted to guide you through the process of building a custom paymaster on zkSync Era. Coupled with this, you'll find a practical, easy-to-follow guide to implement and understand every step [here](https://era.zksync.io/docs/dev/tutorials/custom-paymaster-tutorial.html).\n\n## Need Assistance? \ud83d\udca1\n\nIf you're stumbling upon any issues or uncertainties:\n\n- \ud83d\udcd6 Explore the [custom paymaster tutorial](https://era.zksync.io/docs/dev/tutorials/custom-paymaster-tutorial.html) for a comprehensive walkthrough of the code in this repository.\n- \ud83d\udde3\ufe0f Or simply [reach out on Discord](https://join.zksync.dev/). We're always here to help!\n\n## Repository Overview \ud83d\udcc2\n\nDive into the key sections of this repository:\n\n- `/contracts`: All the essential smart contracts you need are neatly stored here.\n\n- `/deploy`: Discover deployment and usage scripts tailored to assist your development process.\n\n- `/test`: Unit tests for the provided contracts.\n\n## Handy Commands \ud83d\udee0\ufe0f\n\nHere's a lineup of commands to assist you:\n\n- `yarn install`: Installs the required dependencies.\n- `yarn compile`: Compiles the contracts.\n- `yarn hardhat deploy-zksync --script deploy-paymaster.ts`: Deploys your contracts smoothly.\n- `yarn hardhat deploy-zksync --script use-paymaster.ts`: Executes the `use-paymaster.ts` script.\n- `yarn test`: Runs tests. **Make sure to check the test requirements below.**\n\n### Environment variables \ud83c\udf33\n\nTo prevent the leakage of private keys, we use the `dotenv` package to load environment variables. This is particularly used to load the wallet private key, which is required to run the deployment script.\n\nTo use it, rename `.env.example` to `.env` and input your private key.\n\n```\nWALLET_PRIVATE_KEY=123cde574ccff....\n```\n\n### Local testing \ud83e\uddea\n\nTo run tests, you'll need to start the zkSync local environment. Please refer to [this section of the docs](https://era.zksync.io/docs/tools/testing/) for details. It can be run with either the Dockerized setup or the In-memory node.\n\nWithout starting the zkSync local environment, the tests will fail with an error: `Error: could not detect network (event=\"noNetwork\", code=NETWORK_ERROR, version=providers/5.7.2)`\n\n## Stay Connected \ud83c\udf10\n\n- [zkSync's Documentation](https://era.zksync.io/docs/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter @zkSync](https://twitter.com/zksync)\n- [Join our Discord Community](https://join.zksync.dev)\n", "release_dates": []}, {"name": "daily-spendlimit-tutorial", "description": "Code of the zkSync account abstraction tutorial for an account with a daily spend limit", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Daily Spending Limit\n\nThis repository is the submission to [the zkSync bounty of the daily spending limit tutorial](https://github.com/matter-labs/zksync-web-v2-docs/issues/241).\n\n`TUTORIAL.md` is the tutorial documentation.\n\nDeployed Account contract that has the daily spending limit feature: [0x6b6B8ea196a6F27EFE408288a4FEeBE9A9e12005](https://zksync2-testnet.zkscan.io/address/0x6b6B8ea196a6F27EFE408288a4FEeBE9A9e12005/transactions) and owner pk:`0x957aff65500eda28beb7130b7c1bc48f783556bb84fa6874d2204c1d66a0ddc7`\n\n## Credits\n\nForked from [this original repository](https://github.com/porco-rosso-j/daily-spendlimit-tutorial) by [porco-rosso](https://linktr.ee/porcorossoj) \n\n## Deployment & Test\n\n### zkSync2.0 testnet\n\nAs for deployment and simple test on zkSync2.0 testnet, please take a look at the tutorial doc, TUTORIAL.md.\n\n### zkSync local network.\n\n`spend-limit.test.ts` in [the test folder](./test/) offers more detailed tests for each functionality of the SpendLimit contract.\n\n```shell\ngit clone git@github.com:porco-rosso-j/daily-spendlimit-tutorial.git\n```\n\n- Enter the repo and install dependencies.\n\n```shell\ncd daily-spendlimit-tutorial\nyarn\n```\n\n- To set up a local environment, Docker and docker-compose should be installed.  \n  If they are not installed on your computer: [Install](https://docs.docker.com/get-docker/).\n\n- To run zkSync local chain, do:\n\n```shell\ngit clone https://github.com/matter-labs/local-setup.git\ncd local-setup\n./start.sh\n```\n\n\\*check details and common errors for running local zksync chain [here](https://v2-docs.zksync.io/api/hardhat/testing.html#reset-the-zksync-state).\n\n- Compile:\n\n```shell\nyarn hardhat compile\n```\n\n- Additional configuration: rename .env.example to `.env` and add `NODE_ENV=test`.\n\nThen run:\n\n```shell\nyarn hardhat test\n```\n\n**Some tests are not passing due to different error messages returned by the zkSync Era node.** This repo will be updated to fix the remaining tests.\n", "release_dates": []}, {"name": "dapp-portal", "description": "zkSync Bridge and Wallet", "language": "Vue", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "![zkSync Portal](public/preview.png)\n\n# zkSync Portal \ud83d\ude80\n\n**zkSync Portal** is a state-of-the-art wallet dapp, merging the power of **zkSync Era\u220e** and **zkSync Lite** into one user-friendly interface. Designed with a stress on effortless user experience, it simplifies token management, making it your premier interface for interacting with both zkSync versions - every interaction smooth and efficient.\n\n## \u2728 Features\n\n- \ud83d\udda5\ufe0f Intuitive interface for managing, sending, and bridging zkSync Era and zkSync Lite tokens.\n- \ud83d\udcc7 Ability to add contacts for quick and easy access.\n- \ud83d\udd27 Effortless setup and connection to local zkSync nodes or ZK Stack Hyperchains.\n\n## \ud83c\udf89 Try it out!\n\n- \ud83c\udf10 Dive in now at [portal.zksync.io](https://portal.zksync.io/).\n- \ud83c\udf09 Also, explore the zkSync Era Bridge at [bridge.zksync.io](https://bridge.zksync.io).\n\n---\n\n## \ud83c\udf0d Connecting to local node\n\nHarness the Portal's power to connect to your [local zkSync Era node](https://era.zksync.io/docs/tools/testing/).\n\n**Prerequisites:** Node.js version 16+, npm version 7+\n\n1. \ud83d\udcda Follow the [documentation](https://era.zksync.io/docs/tools/testing/) for setting up either an **in-memory node** or **dockerized local setup**.\n2. \ud83d\udd04 Clone the Portal repository and set it up:\n    ```bash\n    git clone https://github.com/matter-labs/dapp-portal.git\n    cd dapp-portal\n    npm install\n    ```\n3. \ud83d\udee0\ufe0f Modify the default network settings in `data/networks.ts` if your network ID, RPC URL, or other info differs. Customize displayed tokens there if needed.\n    - Alternatively, use the [configuration form](./hyperchains/README.md#configure-automatically-with-form) for guided config setup.\n4. \ud83d\udd25 Launch the dev server:\n    - For in-memory node:\n      ```bash\n      npm run dev:node:memory\n      ```\n    - For dockerized setup:\n      ```bash\n      npm run dev:node:docker\n      ```\n  Navigate to the displayed Portal URL (typically http://localhost:3000).\n\n---\n\n## \ud83d\udd17 Connecting to Hyperchain\n\nTo use Portal with your ZK Stack Hyperchain, see the guide [here](./hyperchains/README.md).\n\n---\n\n## \ud83d\udee0 Development\n\n### Advanced configuration\n\n#### L1 Balances:\nBy default, L1 balances are fetched via a public RPC. For faster loading speeds and reduced load on your L1 RPC provider, consider using [Ankr's RPC service](https://www.ankr.com/rpc/). Obtain an Ankr token and update the `.env` file:\n```bash\nANKR_TOKEN=your_ankr_token_here\n```\n\n#### Wallet Connect Project Setup:\nBefore deploying your own version of the Portal, ensure you create your own Wallet Connect project on [walletconnect.com](https://walletconnect.com). After creating the project, update the project ID in the `.env` file:\n```bash\nWALLET_CONNECT_PROJECT_ID=your_project_id_here\n```\n\n\n### \ud83d\udd27 Setup\n\nEnsure you've installed the necessary dependencies:\n\n```bash\nnpm install\n```\n\n### \ud83c\udf10 Development Server\n\nActivate the dev server at http://localhost:3000:\n\n```bash\nnpm run dev\n```\n\n### \ud83c\udfed Production\n\nCompile for production:\n\n```bash\nnpm run generate\n```\n\n\ud83d\udcd8 Familiarize yourself with the [Nuxt 3 documentation](https://nuxt.com/docs/getting-started/introduction) for a deeper dive.\n\n---\n\n## \ud83e\udd1d Contributing\n\nOpen arms for contributions! Enhance our code and send your pull request [here](https://github.com/matter-labs/dapp-portal/pulls).\n\n---\n\n## \ud83d\udcdc License\n\nProudly under the [MIT License](https://github.com/matter-labs/dapp-portal/blob/main/LICENSE).", "release_dates": ["2024-02-29T14:23:59Z", "2024-02-29T14:10:07Z", "2024-02-16T13:45:56Z", "2024-02-16T13:35:34Z", "2024-02-16T11:06:48Z", "2024-02-16T10:55:01Z", "2024-02-16T10:29:42Z", "2024-02-05T10:29:58Z", "2024-02-01T09:24:22Z", "2024-01-29T19:57:03Z", "2024-01-29T14:17:54Z", "2024-01-19T20:36:11Z", "2024-01-19T20:29:32Z", "2024-01-18T16:04:46Z", "2024-01-17T23:21:54Z", "2024-01-17T16:36:12Z", "2024-01-17T14:04:52Z", "2023-12-07T17:52:34Z", "2023-11-15T14:26:15Z", "2023-10-23T18:29:10Z", "2023-10-23T18:01:10Z", "2023-10-23T12:41:29Z", "2023-10-10T14:52:01Z", "2023-10-10T13:13:20Z", "2023-10-10T12:59:15Z", "2023-10-06T17:10:02Z", "2023-10-06T12:33:43Z", "2023-10-04T12:31:22Z", "2023-09-29T08:52:31Z", "2023-09-13T13:50:31Z"]}, {"name": "data-restore", "description": null, "language": "Shell", "license": null, "readme": "Clone the repository:\n```sh\ngit clone https://github.com/matter-labs/data-restore.git\n```\n\n## Start restore node using docker \nPrerequisites: [docker](https://docs.docker.com/engine/install/), [docker-compose](https://docs.docker.com/compose/install/) \n\nCreate volumes for containers:\n```sh\n$ mkdir -p volumes/data-restore volumes/postgres\n```\n\nBefore starting containers configure `data-restore.env`:\n```sh\n# genesis or continue\nCOMMAND=\n\n# mainnet, rinkeby or ropsten\nNETWORK=\n\n# Ethereum node URL\nWEB3_URL=\n\n# Optionally, you can put a database dump into volumes/data-restore and specify its name here.\n# Make sure to run in continue mode.\nPG_DUMP=\n\n# Finite mode flag. Restore data until the last verified block and exit.\n# If set to false, the driver will continuously scan Ethereum blocks unless\n# it is manually interrupted.\n# true (default if left empty) or false\nFINITE_MODE=\n```\n\nTo run the restore:\n```sh\n$ docker-compose up\n```\n\nTo manually connect to the running `postgres` service:\n```sh\n$ psql -h localhost -p 5432 -U postgres -d plasma\n```\n\nOnce you're done, shut down the services:\n```sh\n$ docker-compose down\n```\n\n## Start restore node buiding from scratch\n\n\u0421lone zksync repository:\n`git clone https://github.com/matter-labs/zksync.git`\n\nSet `ZKSYNC_HOME` env to the folder with zksync\n\nAdd `$ZKSYNC_HOME/bin` to your $PATH\n\nBuild `zk`. You have to just run `zk` and it will install all necessary packages \n\nUnpack verification keys \n```sh\n$ zk run verify-keys unpack\n```\n\nBuild contracts \n```sh\n$ zk contracts build\n```\n\nBuild data-restore \n```sh \n$ cargo build --release --bin zksync_data_restore\n```\n\nSet environment vars which specified in `data_restore.env`\n\nRun script `https://github.com/matter-labs/zksync/blob/master/docker/data-restore/data-restore-entry.sh`\n\n\n\n## Restoring from dump\nPrerequisites: [gsutil](https://cloud.google.com/storage/docs/gsutil_install) or [awscli](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html).\nRestoring from genesis is quite expensive and takes a long time, so we publish nightly database dumps that you can download and use for `PG_DUMP`:\n```sh\n# Mainnet\nhttps://storage.googleapis.com/zksync-data-restore/data-restore-mainnet.dump\n\n# Rinkeby\nhttps://storage.googleapis.com/zksync-data-restore/data-restore-rinkeby.dump\n```\n\nOnce downloaded, just set `PG_DUMP=data_restore.dump`, which should save you a few days of syncing.\n*NOTE* if you are buidling data-restore from scratch you need to set env `PG_DUMP_PATH` - Path to the dump\n\n**Warning**: only set `PG_DUMP` for a single run, remove it for consequent usage. If data-restore is interrupted, it's advised to start again with the `PG_DUMP` set.\n\n\n## Running zkSync web3 read-only node\n\nSome use-cases may require you to read data from zkSync in a trustless manner. To bootstrap a local read-only zkSync node, which reads the data from Ethereum, run the following command:\n\n### Docker\n```\ndocker-compose -f docker-compose-zksync-node.yml up\n```\n\nThis will run the `data-restore` tool as well as `server`, which will read data directly from the database created by it.\n\nThe web3 API can be accessed via the following endpoint:\n\n```\nhttp://127.0.0.1:3002\n```\n\nTo change the port to which the zkSync node binds, you should modify the following parameter:\n\n```\nAPI_WEB3_PORT=3002\n```\n\nMake sure to change the port in the `docker-compose-zksync-node.yml` as well.\n\n### Build from sources\nYou can build our node from sources using `https://github.com/matter-labs/zksync`\n\nBuild server \n```sh\n$ cargo build --release --bin zksync_server\n```\n\nRun server \n```sh\n$ ./target/release/zksync_server --components web3-api\n```\n\n**WARNING** It's the only way how you should start sever otherwise you can corrupt your internal state \n", "release_dates": []}, {"name": "demo-circuit", "description": null, "language": "Rust", "license": null, "readme": "# Demo circuits\n\nThis project contains usage demonstration for `bellman` zkSNARK proving framework.  \n", "release_dates": []}, {"name": "discord-ban-appeal", "description": "Matter Labs fork of discord-ban-appeal", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "\nProject Status: [![Netlify Status](https://api.netlify.com/api/v1/badges/d045037a-6ed3-45a5-bfe5-b0d6e06bede9/deploy-status)](https://app.netlify.com/sites/tunic-ban-appeal/deploys)\n\nInspired by [sylveon](https://github.com/sylveon/discord-ban-appeals)\n\n# [Demo](https://wumpus-ban-appeal.netlify.app)\n## [Support Discord Server](https://discord.gg/EnKHckh6d2)\n\n##### Table of Contents\n1. [ Deploy on Netlify ](#netlify)\n2. [ Deploy on your own web server ](#vps)\n3. [ How to block users ](#block)\n4. [ How to create your own custom questions ](#questions)\n5. [ Adding Email Functionality to appeals form ](#emails)\n6. [ Generating a Personal Access Token ](#pat)\n7. [ Deny and Block Feature ](#deny)\n8. [ Differences between this repo and sylveon's ](#diff)\n9. [ Feature Roadmap ](#featureplan)\n\n\n![Home page](img_2.png)\n![](img_1.png)\n![webhook in action](img.png)\n![user blocked](img_3.png)\n\n# How to use this project:\n\n**REQUIREMENTS**\n\n- Have a server where you are able to:\n    - Make channels\n    - Create Webhooks\n    - Invite bots\n\n<a name=\"netlify\"></a>\n## Easy Way: Deploy on Netlify\n\n[![](https://www.netlify.com/img/deploy/button.svg)](https://app.netlify.com/start/deploy?repository=https://github.com/matter-labs/discord-ban-appeal)\n\n> **NOTE**: If you already have a custom bot in your server and access to its credentials, skip the first step\n- Create a custom bot inside your server. You can register/invite one [here](https://discord.com/developers/applications). Keep that window handy.\n- Click the \"Deploy to Netlify\" button.\n    - You will be asked to link your GitHub account then enter values for all the environment variables. (See Environment Variable Information Table)\n- Set the environment variables from your Discord bot application page (`REACT_APP_CLIENT_ID`, `REACT_APP_CLIENT_SECRET`, `REACT_APP_DISCORD_BOT_TOKEN`) \n- Choose a channel (or create a new one) where you want all the ban appeals to appear and copy its ID into `APPEALS_CHANNEL`\n- Copy your server's ID into `REACT_APP_GUILD_ID`\n- Make a random JWT Secret or generator one [here](https://1password.com/password-generator/) and set inside `REACT_APP_JWT_SECRET`\n- Set `REACT_APP_ENABLE_HCAPTCHA` to `false` unless you intend to add hCaptcha\n- Set `REACT_APP_ENABLE_SENDGRID` to `false` unless you intend to use Sendgrid for unban notifications. \n- Make and set the `GITHUB_PAT` (see table for information on how)\n- Deploy your application\n- Lastly we'll want to  make sure users can login using Discord\n  - First make any changes to the netlify.app deployment URL you wish, or set up your own custom one!\n  - From the [Discord Developer Application page](https://discord.com/developers/applications) Select the OAuth tab \n  - Click on Add Redirect and enter `https://[site-url]/callback` where `[site-url]` is the site name netlify assigned you, or the one you changed it to.\n\n### Environment Variable Information\n\n| Environment Variable          | Description                                                                                                                                                                                                                          | Optional? |\n|-------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------|\n| REACT_APP_CLIENT_ID           | Client ID of a Discord Application                                                                                                                                                                                                   | No        |\n| REACT_APP_CLIENT_SECRET       | Client Secret of a Discord Application                                                                                                                                                                                               | No        |\n| REACT_APP_DISCORD_BOT_TOKEN   | The Bot token of a Discord Application                                                                                                                                                                                               | No        |\n| REACT_APP_GUILD_ID            | The Server/Guild ID where you are accepting ban appeals                                                                                                                                                                              | No        |\n| REACT_APP_JWT_SECRET          | A really long string of characters used to establish <br>a secure line of communication with the API of this app.<br>I would recommend using a password generator to create this. <br>**You don't have to remember what its set to** | No        |\n| REACT_APP_SKIP_BAN_CHECK      | If set to \"true\" the application will not check if <br>a user is banned before allowing them to fill out <br>an appeal form                                                                                                          | Yes       |\n| REACT_APP_BANNER_URL          | Add a custom banner behind your server icon. <br>Must be a direct link to an image <br>(usually ends in .jpeg or .png etc.)                                                                                                          | Yes       |\n| REACT_APP_SITE_TITLE          | Use a custom title for your site (defaults to {server_name}'s Discord Ban Appeal Application if none is set)                                                                                                                         | Yes       |\n| REACT_APP_SITE_DESCRIPTION    | Use a custom SEO description for your site (defaults to {server_name}'s Discord Ban Appeal Application if none is set)                                                                                                               | Yes       |\n| APPEALS_CHANNEL               | The channel where you want appeals to appear in                                                                                                                                                                                      | No        |\n| REACT_APP_ENABLE_HCAPTCHA     | Do you want to use hCaptcha in the form? (true/false)                                                                                                                                                                                | Yes       |\n| REACT_APP_HCAPTCHA_SITE_KEY   | The hCaptcha site key generated by hCaptcha                                                                                                                                                                                          | Yes       |\n| REACT_APP_HCAPTCHA_SECRET_KEY | The secret on your hCaptcha profile                                                                                                                                                                                                  | Yes       |\n| REACT_APP_GOOGLE_ANALYTICS_ID | Google Analytics Tracking ID like UA-000000-01.                                                                                                                                                                                      | Yes       |\n| REACT_APP_ENABLE_SENDGRID     | Sends users an email when they are unbanned (true/false) See Wiki if you don't know how to set this up                                                                                                                               | No        |\n| SENDGRID_API_KEY              | [API Key for Sendgrid](https://app.sendgrid.com/settings/api_keys)                                                                                                                                                                   | Yes       |\n| SENDGRID_SENDER_EMAIL         | [Single Sender Verification Email](https://docs.sendgrid.com/ui/sending-email/sender-verification)                                                                                                                                   | Yes       |\n| INVITE_URL                    | Discord invite that can be used in email template to unbanned users                                                                                                                                                                  | Yes       |\n| GITHUB_PAT                    | [Github Personal Access Token](https://github.com/settings/tokens/new) for Deny and Block feature to work. Make sure it never expires and to select the `repo` scope                                                                 | No       |\n\n<a name=\"vps\"></a>\n## Hard Way: Deploy on your own web server\n\nThis if by far not the prettiest way to do this which is why I recommend you use netlify, but if you're smart enough to deploy this on your own then go for it!\n\n### Requirements:\n \nBe aware this project uses serverless functions as its API layer. \nAll the API requests are directed at /.netlify/functions because support issues with netlify's redirect rules. \nTo deploy this yourself you will need to create a serverless API using AWS Lambda or an equivalent from Azure or GCP.\nI will go into specifics below.\n\n### Web frontend\n- Fork this repo\n- Copy `.env.example` to `.env` and fill in each value\n- Run `yarn install` to install the dependencies\n- Run `yarn build` to compile a production build \n- Direct your webserver to serve the `./build/` directory\n\n### Serverless backend\n\n- Create a new serverless API in your cloud provider with 4 endpoints.\n    - Each File in `/functions` will be an endpoint, and most of them will require both the files in the `/functions/helpers` folder\n- Make sure all the packages from `package.json` are installed and available for each function\n- Find and replace all occurrences of `/.netlify/functions/` with your endpoint for each function\n\nI've oversimplified a lot of the serverless portion here since it will vary based on your cloud provider but this covers the jist of things.\n\n<a name=\"block\"></a>\n## Adding hCaptcha (like reCaptcha)\n[See Wiki article](https://github.com/jcsumlin/discord-ban-appeal/wiki/Adding-hCaptcha)\n\n## How to block users from abusing your ban appeal form.\n[See Wiki article](https://github.com/jcsumlin/discord-ban-appeal/wiki/Blocking-users-from-submitting-ban-appeals)\n\n<a name=\"questions\"></a>\n## How to create your own custom questions.\n[See Wiki article](https://github.com/jcsumlin/discord-ban-appeal/wiki/How-to-create-your-own-custom-questions)\n\n<a name=\"emails\"></a>\n## Adding Email Functionality to appeals form\n[See Wiki article](https://github.com/jcsumlin/discord-ban-appeal/wiki/How-to-email-users-when-theyre-unbanned)\n\n<a name=\"pat\"></a>\n## How to generate a Personal Access Token\n[See Wiki article](https://github.com/jcsumlin/discord-ban-appeal/wiki/How-to-make-a-Personal-Access-Token)\n\n<a name=\"diff\"></a>\n## Differences between this repo and sylveon's\n- Server icon and custom banner on landing page\n- Only allow users who are actually banned to submit an appeal\n  - Ability to disable this check\n- Custom meta tags for better SEO and visibility.\n- **IMO** a cleaner approach to custom questions.\n- Email integration for unban notification\n- Deny and block users from discord embed\n\n<a name=\"featureplan\"></a>\n## Feature roadmap\n- [x] Allow users to be blocked from submitting a ban appeal\n- [x] Add better meta tag support\n- [x] Custom Questions defined by the user\n- [x] add hCaptcha/reCaptcha\n- [x] Integrate some means of alerting users who are unbanned\n- [x] Additional Actions such as \"Deny Ban appeal\".\n- [x] Optional Google Analytics tracking\n", "release_dates": []}, {"name": "discourse", "description": "A platform for community discussion. Free, open, simple.", "language": null, "license": {"key": "gpl-2.0", "name": "GNU General Public License v2.0", "spdx_id": "GPL-2.0", "url": "https://api.github.com/licenses/gpl-2.0", "node_id": "MDc6TGljZW5zZTg="}, "readme": "<a href=\"https://www.discourse.org/\">\n  <img src=\"images/discourse-readme-logo.png\" width=\"300px\">\n</a>\n\nDiscourse is the 100% open source discussion platform built for the next decade of the Internet. Use it as a:\n\n- mailing list\n- discussion forum\n- long-form chat room\n\nTo learn more about the philosophy and goals of the project, [visit **discourse.org**](https://www.discourse.org).\n\n## Screenshots\n\n \n<a href=\"https://bbs.boingboing.net\"><img alt=\"Boing Boing\" src=\"https://user-images.githubusercontent.com/1681963/52239245-04ad8280-289c-11e9-9c88-8c173d4a0422.png\" width=\"720px\"></a>\n<a href=\"https://twittercommunity.com/\"><img src=\"https://user-images.githubusercontent.com/1681963/52239250-04ad8280-289c-11e9-9e42-574f6eaab9d7.png\" width=\"720px\"></a>\n<a href=\"https://forums.gearboxsoftware.com/\"><img src=\"https://user-images.githubusercontent.com/1681963/89088042-68ffb400-d364-11ea-93be-161ea04d8b29.png\" width=\"720px\"></a>\n\n\n<img src=\"https://user-images.githubusercontent.com/1681963/52239118-b304f800-289b-11e9-9904-16450680d9ec.jpg\" alt=\"Mobile\" width=\"414\">\n\nBrowse [lots more notable Discourse instances](https://www.discourse.org/customers).\n\n## Development\n\nTo get your environment setup, follow the community setup guide for your operating system.\n\n1. If you're on macOS, try the [macOS development guide](https://meta.discourse.org/t/beginners-guide-to-install-discourse-on-macos-for-development/15772).\n1. If you're on Ubuntu, try the [Ubuntu development guide](https://meta.discourse.org/t/beginners-guide-to-install-discourse-on-ubuntu-for-development/14727).\n1. If you're on Windows, try the [Windows 10 development guide](https://meta.discourse.org/t/beginners-guide-to-install-discourse-on-windows-10-for-development/75149).\n\nIf you're familiar with how Rails works and are comfortable setting up your own environment, you can also try out the [**Discourse Advanced Developer Guide**](docs/DEVELOPER-ADVANCED.md), which is aimed primarily at Ubuntu and macOS environments.\n\nBefore you get started, ensure you have the following minimum versions: [Ruby 2.7+](https://www.ruby-lang.org/en/downloads/), [PostgreSQL 13+](https://www.postgresql.org/download/), [Redis 6.0+](https://redis.io/download). If you're having trouble, please see our [**TROUBLESHOOTING GUIDE**](docs/TROUBLESHOOTING.md) first!\n\n## Setting up Discourse\n\nIf you want to set up a Discourse forum for production use, see our [**Discourse Install Guide**](docs/INSTALL.md).\n\nIf you're looking for business class hosting, see [discourse.org/buy](https://www.discourse.org/buy/).\n\nIf you're looking for our remote work solution, see [teams.discourse.com](https://teams.discourse.com/).\n\n## Requirements\n\nDiscourse is built for the *next* 10 years of the Internet, so our requirements are high.\n\nDiscourse supports the **latest, stable releases** of all major browsers and platforms:\n\n| Browsers              | Tablets      | Phones       |\n| --------------------- | ------------ | ------------ |\n| Apple Safari          | iPadOS       | iOS          |\n| Google Chrome         | Android      | Android      |\n| Microsoft Edge        |              |              |\n| Mozilla Firefox       |              |              |\n\n## Built With\n\n- [Ruby on Rails](https://github.com/rails/rails) &mdash; Our back end API is a Rails app. It responds to requests RESTfully in JSON.\n- [Ember.js](https://github.com/emberjs/ember.js) &mdash; Our front end is an Ember.js app that communicates with the Rails API.\n- [PostgreSQL](https://www.postgresql.org/) &mdash; Our main data store is in Postgres.\n- [Redis](https://redis.io/) &mdash; We use Redis as a cache and for transient data.\n- [BrowserStack](https://www.browserstack.com/) &mdash; We use BrowserStack to test on real devices and browsers.\n\nPlus *lots* of Ruby Gems, a complete list of which is at [/main/Gemfile](https://github.com/discourse/discourse/blob/main/Gemfile).\n\n## Contributing\n\n[![Build Status](https://github.com/discourse/discourse/actions/workflows/tests.yml/badge.svg)](https://github.com/discourse/discourse/actions)\n\nDiscourse is **100% free** and **open source**. We encourage and support an active, healthy community that\naccepts contributions from the public &ndash; including you!\n\nBefore contributing to Discourse:\n\n1. Please read the complete mission statements on [**discourse.org**](https://www.discourse.org). Yes we actually believe this stuff; you should too.\n2. Read and sign the [**Electronic Discourse Forums Contribution License Agreement**](https://www.discourse.org/cla).\n3. Dig into [**CONTRIBUTING.MD**](CONTRIBUTING.md), which covers submitting bugs, requesting new features, preparing your code for a pull request, etc.\n4. Always strive to collaborate [with mutual respect](https://github.com/discourse/discourse/blob/main/docs/code-of-conduct.md).\n5. Not sure what to work on? [**We've got some ideas.**](https://meta.discourse.org/t/so-you-want-to-help-out-with-discourse/3823)\n\n\nWe look forward to seeing your pull requests!\n\n## Security\n\nWe take security very seriously at Discourse; all our code is 100% open source and peer reviewed. Please read [our security guide](https://github.com/discourse/discourse/blob/main/docs/SECURITY.md) for an overview of security measures in Discourse, or if you wish to report a security issue.\n\n## The Discourse Team\n\nThe original Discourse code contributors can be found in [**AUTHORS.MD**](docs/AUTHORS.md). For a complete list of the many individuals that contributed to the design and implementation of Discourse, please refer to [the official Discourse blog](https://blog.discourse.org/2013/02/the-discourse-team/) and [GitHub's list of contributors](https://github.com/discourse/discourse/contributors).\n\n## Copyright / License\n\nCopyright 2014 - 2021 Civilized Discourse Construction Kit, Inc.\n\nLicensed under the GNU General Public License Version 2.0 (or later);\nyou may not use this work except in compliance with the License.\nYou may obtain a copy of the License in the LICENSE file, or at:\n\n   https://www.gnu.org/licenses/old-licenses/gpl-2.0.txt\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nDiscourse logo and \u201cDiscourse Forum\u201d \u00ae, Civilized Discourse Construction Kit, Inc.\n\n## Dedication\n\nDiscourse is built with [love, Internet style.](https://www.youtube.com/watch?v=Xe1TZaElTAs)\n", "release_dates": []}, {"name": "docker-kubectl", "description": "Docker image with Kubernetes deployment tools (kubectl, helmfile, helm and plugins)", "language": null, "license": null, "readme": "[![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/dysnix/docker-kubectl?label=version&sort=semver)](https://hub.docker.com/r/dysnix/kubectl)\n\n# kubectl\n\nDysnix kubectl Docker image ships with:\n\n  * helmfile\n  * helm (+ plugins)\n  * sops\n  * jq and yq\n\n## Flavors\n\nVarious flavors are provided by this project. For example gcloud.\n", "release_dates": []}, {"name": "eip1962", "description": "EIP1962 implementation effort", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Status\n\nThis Rust implementation of EIP1962 is complete to the large extend. If course it's possible to polish further (e.g. make it `no_std` compatible), but largest part is done:\n\nFeatures:\n- [x] Fields implementation\n- [x] Weierstrass curves implementation\n  - [x] a = 0\n  - [x] generic case (a != 0, b != 0)\n- [x] Extension towers\n  - [x] Fp2\n  - [x] Fp3\n  - [x] Fp4 as 2 over 2\n  - [x] Fp6 as 2 over 3\n  - [x] Fp6 as 3 over 2\n  - [x] Fp12 as 2 over 3 over 2\n- [x] Pairings\n  - [x] BLS12 curves family\n  - [x] BN family\n  - [x] MNT6 family\n  - [x] MNT4 family\n  - [x] Cocks-Pinch method generated curves in Weierstrass form (Ate pairing) with k=6\n\nTesting:\n\n- Basic properties are tested during development (whitebox testing) in a form of e.g. bilinearity checks for pairings\n- Fuzzy testing in cross-checks mode with C++ and Go implementations that catches both crashes in any of the libraries and tests for a consistent output (for consensus purposes) \n  - During such testing most of the checks are disabled, e.g. points are allowed to be not on the curve cause it would be difficult for a fuzzer to find a proper test vector. So such testing covers more edge cases then would be possible in production\n\n# Documentation about EIP1962\n\nSee [documentation](https://github.com/matter-labs/eip1962/tree/master/documentation) folder for a complete description and the single source of truth about EIP.\n\n## Original proposal\n\nOriginal EIP is [here](https://eips.ethereum.org/EIPS/eip-1962)\n\n# Contributors\n\n- Kobi Gurkan, [kobigurk@gmail.com](mailto://kobigurk@gmail.com)\n\n# Resources to consult and use \n\n- https://eprint.iacr.org/2012/072.pdf\n- https://eprint.iacr.org/2013/722.pdf\n- https://eprint.iacr.org/2016/130.pdf", "release_dates": []}, {"name": "eip1962_specs", "description": "Specification documents for EIP1962", "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "era-bellman-cuda", "description": "A library implementing GPU-accelerated cryptographic functionality for the zkSync prover", "language": "Cuda", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# bellman-cuda\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\nbellman-cuda is a library implementing GPU-accelerated cryptographic functionality for the zkSync prover. \n\n### Building the library\nThe library can be built by executing these steps:\n\n#### Initialize git submodules\n`git submodule update --init --recursive`\n#### Generate the build configuration by executing\n`cmake -B./build -DCMAKE_BUILD_TYPE=Release`\n#### Build the binary by executing\n`cmake --build ./build`\n\nThe library binary can be found in the `./build/src` folder. Change the path in the above commands if a different build location is desired.\n\nBy default, the library is built for Compute Architecture 8.0.\nIf a different Compute Architecture is required, the [CMAKE_CUDA_ARCHITECTURES](https://cmake.org/cmake/help/latest/variable/CMAKE_CUDA_ARCHITECTURES.html) variables can be set to the desired architecture(s) during the build configuration generation step.\n\nExample for Compute Architecture 8.6: \n```\ncmake -B./build -DCMAKE_BUILD_TYPE=Release -DCMAKE_CUDA_ARCHITECTURES=86\n```\n\n### Executing Tests\nBy default, the tests binary is not compiled.\n\nThis can be changed by setting the variable `BUILD_TESTS` to `ON` in the build configuration step like this:\n\n`cmake -B./build -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=ON`.\n\nThen, after executing the build step, the tests binary is located in the `./build/tests` folder and can be executed by calling:\n\n`./build/tests/tests`.  \n\n## License\n\nThe zkSync Era prover is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounty programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": ["2023-12-08T16:09:30Z", "2023-10-13T11:51:28Z", "2023-10-13T16:30:44Z", "2023-09-25T13:37:13Z", "2023-09-25T11:18:53Z"]}, {"name": "era-boojum", "description": "Boojum, the scariest SNARK implementation.", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Boojum\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## About\n\nThe purpose of this library is to work with a very specific arithmetization with additional assumptions about the field size. Roughly, we expect to have a field `F` with |F| ~ 64 bits (the size of a machine word) (the assumption about field size is not important for the strategy of arithmetization and gate placement, but it is asserted in gadget implementations for particular functions which rely on a specific field size).\n\nThe system has a hierarchy of logical function (gadgets) - gates (entities that can inscribe itself into trace) - and evaluators (relations between polynomials). Evaluators are written in the form of a trait that allows us to later on automatically compose functions to check satisfiability and compute proofs, as well as synthesize plain and recursive verifiers. Gates have additional tooling attached to them that allows the gates themselves to track the logic of where they should be placed in the trace. Note that we rely on Plonk's copy constraints and work on the copiable logical entities of \"variables\" to compose a final provable statement. The system is not intended for AIR arithmetization and doesn't allow to express constraints that span multiple rows of the trace.\n\nIn general, the trace contrains few varieties of columns. The main separation is between:\n- General purpose columns - where one can allow some columns of variables (copiable), witnesses (non-copiable, also sometimes called \"advice\" columns) and constants to be used by **DIFFERENT TYPES** of gates, leading to the necessity to place selectors in front of the corresponding terms in the quotient polynomial. For these general purpose columns, the placement logic is simple: we try to put in as many repetitions of the same relation as the gate/evaluator allows, based on the designated number of columns of the corresponding type in the system. Later on, when selectors are materialized, a few extra constant columns can be added. In general, the default behavoir of the gates is to try to \"amortize\" constants, in a sense that over the same row, we try to place gates that use same constants. This is a reasonable approach because most of the circuits are \"cycles\" in practice, so we can \"fill\" the row.\n- \"Specialized\" columns - where one can designate a separate set of columns to the particular gate/evaluator, so the relation enforced by evaluator must hold on every row in these columns. This may be beneficial in some circuits where a particular gate is used very often. One can specify few different modes of utilization of these columns in the case of multiple sets being spent for the same relations, namely to share constants or not between sets.\n\nIn addition, the trace allows you to add a lookup argument, which can also either use specialized columns to house the entries of the lookup tables, or just use general purpose columns. Tables are encoded as only one set of polynomials for now, so the total length of the trace must be larger than the total number of entries in the tables. \n\nNote that every \"gate\" (as a Rust type) is unique, and so a gate can only be placed into either specialized or general purpose columns, but not into both. If one needs such functionality then it's possible to make a newtype wrapper.\n\nHigher level logical functions (like boolean decompositions, range checks, zero checks, etc) are used to make a circuit internally inscribe themselves in different manners depending if some gates are allowed or not allowed in the particular instance of the CS. Instances of the CS with different sets of gates are considered a different type from the Rust perspective, and we rely on some inlining/constant prop/compiler work to reduce branching into static jumps.\n\n### Notes on subparts of construction\n\n- Only the 2^64 - 2^32 + 1 field is implemented. The non-vectorized math implementation is based on the implementation developed for Plonky2, but is reformulated for const traits\n- Auto-vectorization is performed mainly for additions, where benefits are clear\n- Poseidon MDS and round constants are equal to Plonky2 to have some compatibility for users\n- Poseidon2 round constants reuses the Poseidon constants\n- Arithmetization constraints only affect one row. The placement strategy is to amortize constants as much as possible by tiling row-wise or column-wise\n- Copy-permutation argument is taken from Plonk (the grand product based one). May be changed to log-derivative (the additive one) later on\n- Lookup argument is log-derivative (the additive one)\n- Lookup tables in a circuit must all be the same width for now\n- No columns can be separated from the oracles and fed into another proof yet\n- At the moment, the movement to the extension field is only done on FRI aggregation (so during previous stages challenges are of `|F|` and so we have to repeat arguments), but this will be changed so that we move to the extension field as fast as possible after committing to the witness to avoid a quite \"large\" chance of getting zeroes in denominator. The effect on computational expense in proving is quite negligible\n- Zero-knowledge is not yet implemented, but planned (gates will itself determine how to put a satisfying, but random witness in their yet unused rows)\n- FFT is not optimized\n- Hashes are somewhat optimized\n- Implemented gates are opinionated, as well as arithmetizations\n\n### Note on lookup argument\n\nWe use a lookup argument enforced via the relations `\\sum_i selector(x_i) / (witness(x_i) + beta) == \\sum_i multiplicity(x_i) / (table(x_i) + beta)` where a lookup over specialized columns `selector(x_i)` is just an identity. We also do not encode the tables as the polynomial of smaller degree to eliminate extra degree bound checks, and instead pad them with zeroes. Note that table entries never contain an element of `(0,0,...,0)` as we use separate ID columns for table types in case of multiple tables (even in the case of only one table being used), and an ID like this starts with 1.\n\nOne nice feature of a lookup argument like this is that, due to its additive nature, if we do lookups over multiple `witness` polynomials into the same table, instead of repeating the argument for every (tuple of) polynomial(s) (which would require a separate multiplicity column, as well as few a intermediate polynomials later on), we can \"add up\" multiplicities and transform the argument into something like `\\sum_i selector_0(x_i) / (witness_0(x_i) + beta) + \\sum_i selector_1(x_i) / (witness_1(x_i) + beta) == \\sum_i total_multiplicity(x_i) / (table(x_i) + beta)`, so that the total cost of a lookup is just 1 multiplicities column, and 2 (witness-related) + 1 (table-related) intermediate polynomials to encode the lhs and rhs relations on the roots of unity.\n\nThe correctness of this argument is clear.\nFor soundness, we use the original argument as in the [\"Cached quotients for fast lookups\" paper](https://eprint.iacr.org/2022/1763), Lemma 2.4.\nWe need to show that it suffices to commit to the `total_multiplicity` rather than to the multiplicities of `witness_0` and `witness_1` separately.\n\nSuppose the equation `\\sum_i selector_0(x_i) / (witness_0(x_i) + X) + \\sum_i selector_1(x_i) / (witness_1(x_i) + X) == \\sum_i total_multiplicity(x_i) / (table(x_i) + X)` holds. \nWe need to show that `witness_0` and `witness_1` are contained in the table `t`.\nLet `f = (witness_0 | witness_1)`, a concatenation of the values.\nThe equation above implies `\\sum_i selector_i / (f_i + X) == \\sum_i total_multiplicity_i / (t_i + X)` (note that the interval length of `i` on the LHS is double than the above).\nBy Lemma 2.4 we get `f \\subset t`: \"subset\" in the sense that every coordinate of the vector `f` is a coordinate of `t`.\nIn particular, `witness_0, witness_1 \\subset f \\subset t`.\n\nNote that the argument holds for several `witness_i` as well. The rest of the soundness argument, for a chosen `\\beta`, follows directly as in the work above.\n\n### Planned extensions\n- [ ] Allow lookup tables of different \"width\" (Unlikely now, we need to update type system a little)\n- [x] Split the CS into a \"configurable\" part (where one can allow gates and static tools), and an \"inscribable\" part (where one can put variables, gates, etc). So one first configures, then \"freezes\" and then inscribes, and can not make a mistake along the way\n- [ ] Allow an alternative selector mode (individual insteal of tree) for rare circuits that need it. Because we have a huge number of setup polynomials from copy-permutation anyways, flat selectors are not that expensive if they allow to avoid pushing quotient degree 2x\n- [ ] Make u16/u32 use \"static\" caches for decompositions instead of \"dynamic\" ones\n- [ ] Make \"dyn\" verifier, so all it's descendants are \"Self\". Note: most likely unnecessary\n- [x] Move to the field extension \"earlier\", because it only affects the copy-permutation product and lookup argument parts, and this tradeoff is acceptable in comparison to the `2^-40` chance to get `0` in denominators\n- [x] Switch to generic logging\n- [x] Switch to Poseidon2 by default\n    - Note on Monolith: even though it's blazing fast, it has a drawback where it's very hard to just unroll it into single \"row\" as it mixes lookups and algebraic relations. It may not be the best suited for circuit instances of large width\n- [ ] Actually optimize FFT\n- [ ] Check what's the most optimal strategy to evaluate gates over general purpose columns\n- [x] Merge new DAG resolver (10-100x faster)\n- [ ] Tune consistency check for auxilary lookup polynomials to utilize higher-degree constraint if it's \"free\" (if we would already do higher degree extension anyway for copy-permutation, or gates)\n\n### For curions in benchmarks only\n\nThere are benchmarks for 8kB of SHA256 using what we think is somewhat optimal configuration of gates + tables for SHA256 circuit. Note that even though the prover is kind-of fast, we didn't properly optimize the FFT and still use Poseidon (not Poseidon2) for configurations where we expect the proof to be used for recursion. Two scripts `sha256_bench_recursive.sh` and `sha256_bench_non_recursive.sh` allow you to run the corresponding tests (whether proof is expected to be used in recursion or not), and you should look for a line `Proving is done, taken ...` to see the proving time, because the verifier that runs after it is quite verbose. These benchmarks use an LDE factor of 8, even though all our constraints are of degree 4 or less - however, it's a parameter that is used in some other public benchmarks. We also do not use PoW in those proofs because PoW for 20 bits is negligible (30ms), and we do not support PoW over algebraic hashes yet (however those are only ~2x slower, so also negligible). Security level is roughly `100` bits, but the FRI soundness can be boosted by increaseing the number of queries, and an increase in number of queries doesn't increase prover time (not to be confused with changing the FRI rate). Trace length is `2^16` and it uses 60 general purpose columns and 8 lookup arguments of width 4.\n\nNote: benchmarks just try to compile to native arch and only AArch64 (read Apple M1) arch is normally tested end-to-end for now. x86-64 arithmetic implementations were tested for validity, but not end-to-end in full proofs. Note that max performance x86-64 requires extra compiler feature flags in addition to `cpu = native` (AVX512 set is not used by Rust compiler even on native CPUs)\n\n## License\n\nThe Boojum prover is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n\n### Third party notices\nThis software includes components from third parties. For a full list of these components and their licenses, see the [THIRD PARTY NOTICES file](ThirdPartyNotices.txt).\n\n", "release_dates": []}, {"name": "era-boojum-cuda", "description": "A library implementing GPU-accelerated cryptographic functionality for the zkSync prover.", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# zkSync Era: A ZK Rollup For Scaling Ethereum\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n\n## Boojum-CUDA\nBoojum-CUDA is a library implementing GPU-accelerated cryptographic functionality for the zkSync prover.\n\nPrerequisites: \n- CUDA 12.x\n- CMake 3.24 and up\n- clang\n- rust nightly toolchain\n\nBy default, the CUDA code is compiled for the GPU that is present in the system. If there is no GPU in the system or \nanother architecture is desired, the environment variable `CUDAARCHS` can be set to the desired architecture. \nSee https://cmake.org/cmake/help/latest/variable/CMAKE_CUDA_ARCHITECTURES.html.\n\n## Policies\n\n- [Security policy](SECURITY.md)\n- [Contribution policy](CONTRIBUTING.md)\n\n## License\n\nzkSync Era is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [ZK Credo](https://github.com/zksync/credo)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-boojum-validator-cli", "description": null, "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Era: Boojum verifier CLI\n\nTo run local test:\n\n\n```shell\ncargo test test_local_proof --  --nocapture\n```\n\nIt tries the local proof with all the fixes, on 24 bit. \nBoth proof and the vkey are in example_proofs/snark_wrapper\n\nIt also generates the test, that can be inserted in unittests for Verifier.sol.\n\n\n\n\n\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n# \nThis is an experimental command line tool to verify the proofs for zkSync Era's updated proof system, Boojum [https://github.com/matter-labs/era-boojum](https://github.com/matter-labs/era-boojum).\n\nThe CLI fetches Boojum proofs for a given batch, public inputs, and aux input all from L1 and verifies the proof off chain. For testnet and sepolia chains, there may not be proofs submitted on chian for batches.\n\nLearn more about the Boojum proof system in our blog post: [https://zksync.mirror.xyz/HJ2Pj45EJkRdt5Pau-ZXwkV2ctPx8qFL19STM5jdYhc](https://zksync.mirror.xyz/HJ2Pj45EJkRdt5Pau-ZXwkV2ctPx8qFL19STM5jdYhc)\n\n# Proof generation limitation\n\nWe are currently generating boojum proofs for all batches on sepolia, so at the moment this is the only chain supported. For mainnet and testnet, these will be updated once supported.\n\n# Running the CLI\n\nYou can verify that committed proofs are valid by running:\n\n```shell\ncargo run -- --batch <batch_number> --l1-rpc <your L1 rpc https endpoint>\n```\n\nFull example\n\n```shell\ncargo run -- --batch 109939 --network mainnet --l1-rpc https://rpc.ankr.com/eth\n```\n\nIf you need to update the verification key to the latest, run with the corresponding flag.\n```shell\ncargo run -- --batch 109939 --network mainnet --l1-rpc https://rpc.ankr.com/eth --update-verification-key true\n```\n\n## CLI Options\n\n```shell\n--batch - The L1 batch number you want to verify the generated proof\n--network - Along with batch number, defines if you want to verify a proof for Era testnet or mainnet. It defaults to mainnet. Accepts \"mainnet\" or \"testnet\"\n--l1-rpc - The RPC url required to pull data from L1.\n--json - Flag to specify if the output should be in json. Note that all the usual std out prints are silenced.\n```\n\n## Error Codes\n\nBelow is a list of the error codes that can be seen in the json output of the cli tool:\n- 0 => `Success`\n- 1 => `InvalidNetwork`\n- 2 => `NoRPCProvided`\n- 3 => `FailedToDeconstruct`\n- 4 => `FailedToGetDataFromL1`\n- 5 => `FailedToFindCommitTxn`\n- 6 => `InvalidLog`\n- 7 => `FailedToGetTransactionReceipt`\n- 8 => `FailedToGetBatchCommitment`\n- 9 => `ProofDoesntExist`\n- 10 => `FailedToFindProveTxn`\n- 11 => `InvalidTupleTypes`\n- 12 => `FailedToCallRPC`\n- 13 => `VerificationKeyHashMismatch`\n- 14 => `FailedToDownloadVerificationKey`\n- 15 => `FailedToWriteVerificationKeyToDisk`\n- 16 => `ProofVerificationFailed`\n- 17 => `FailedToLoadVerificationKey`,\n- 18 => `BadCalldataLength`,\n- 19 => `FailedToCallRPCJsonError`,\n- 20 => `FailedToCallRPCResponseError`,\n\n# Future plans\n\nCurrently this CLI verification keys are hardcoded or pulled from github, but the plan is to extend this tool to:\n* support all the 13 different circuits (and not only the 3 that are currently hardcoded)\n* add more debugging / explanations\n\n## License\n\nThe Era Boojum Cli is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n\n\n## More details\nThe proving process consists of three steps:\n\n* Pull data from L1 including: proof, public input, aux input, and verification key hash\n* Validates the verification key being used is in line with the one on L1.\n* Checking if the 'proof' is correct.\n\nThe example output looks like this:\n\n```\nFetching and validating the proof itself\nFetching batch 26 information from zkSync Era on network sepolia\nFetching batch 27 information from zkSync Era on network sepolia\nWill be verifying a proof for state transition from root 0xe61dfa88ffe6c44dd9469b81516d912b13f6f057ea132673813512e243b09d60 to root 0xda85816088b8b9efc62faff0f0e9f47f684f527d52a3624fc6427dbff2ce9101\nWill be using bootloader code hash 0x010009657432df24acfe7950b2d1a0707520ca6b7acb699e58c0f378c0ed7a11 and default AA code hash 0x01000651c5ae96f2aab07d720439e42491bb44c6384015e3a08e32620a4d582d\n\n\nFetching batch 27 information from zkSync Era on network sepolia\nVerifying SNARK wrapped FRI proof.\n=== Aux inputs:\n  L1 msg linear hash:                  0x7c89cb8c193258689329f3c909b7b17f0b2374c8a7f6d42f075af49f41f69ac1\n  Rollup state diff for compression:   0x071407206e21e82a93e534d50189296825811b98c49d3d11811d24c5e4312959\n  Bootloader heap initial content:     0x972c46d32b5ef1159ff7977162f9885db659f3e5454bc329bc2a9abac2d4bcde\n  Events queue state:                  0xa7b918ffb6690c6b3929a7c40dcafa5c46d5e9fc0c7f11ab5707ab1f00eeb9be\n=== Loading verification key.\n=== Verification Key Hash Check:\n  Verification Key Hash from L1:       0x750d8e21be7555a6841472a5cacd24c75a7ceb34261aea61e72bb7423a7d30fc\n  Computed Verification Key Hash:      0x750d8e21be7555a6841472a5cacd24c75a7ceb34261aea61e72bb7423a7d30fc\nVerifying the proof\nProof is VALID\nPublic input is: Fr(0x0000000052f5d9be73c67d37ecb295eb70924f700ed17d40ca0a48e7c89c5d83)\n```\n\n\nFirst, the CLI fetches the 'proof' from the calldata of `proveBatches` on L1. This proof is a `Proof` struct from the Boojum repository, which includes the configuration, public inputs, and additional data required for Fast Reed-Solomon Interactive Oracle (FRI), like oracle caps, values, and queries.\n\n\n\nOther data we collect data from L1 includes:\n* The hash of the previous block\n* The hash of the current block\n* The hash of the bootloader code\n* The hash of the default account code\n* BlockAuxilaryOutput:\n    * The hash of the system logs\n    * The hash of the state diffs\n    * The hash of bootloader initial contents\n    * The hash of the event queue\n* And other metadata like queue hashes\n\n\n\nFinally, we check that this proof is valid and matches a specific verification key, in this case, it's the `scheduler_key.json`. This key is like a fingerprint of the code of the circuit.\n\n# Advanced options\n\n## Snark proof verification\n\nCurrently we are planning to wrap the final FRI proof, into a SNARK (to lower the size of the proof and cost of verification in L1).\n\nTo verify that the wrapper is correct, you can use the ``verify-snark-wrapper`` command. \n\nWARNING: This verifier is still WIP, so command arguments will change.\n\n```shell\ncargo run  -- verify-snark-wrapper example_proofs/snark_wrapper/l1_batch_proof_1.bin example_proofs/snark_wrapper/snark_verification_scheduler_key.json\n```\n\nYou can also generate the solidity test for Verifier.sol, by running:\n\n```shell\ncargo run -- generate-solidity-test example_proofs/snark_wrapper/l1_batch_proof_1.bin\n```\n\nThere is also a larger test inside, that computes the public inputs hash:\n\n```shell\ncargo test test_local_proof --  --nocapture\n```", "release_dates": []}, {"name": "era-circuit_testing", "description": "vk-generator", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: A ZK Rollup For Scaling Ethereum\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## License\n\nThe zkSync Era prover is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go \nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it! \nIt is important to state that forking it now can potentially lead to missing important security updates, critical \nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-compiler-common", "description": "Shared constants of the compilers for EraVM.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: Compiler Common\n\n[![Logo](eraLogo.svg)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security\nor decentralization. As it's EVM-compatible (with Solidity/Vyper), 99% of Ethereum projects can redeploy without\nneeding to refactor or re-audit any code. zkSync Era also uses an LLVM-based compiler that will eventually enable\ndevelopers to write smart contracts in popular languages such as C++ and Rust.\n\nThis repository contains the common compiler constants.\n\n## License\n\nThis library is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through extensive testing and audits, and although it is live, it is still in alpha state and\nwill undergo further audits and bug bounty programs. We would love to hear our community's thoughts and suggestions\nabout it!\nIt's important to note that forking it now could potentially lead to missing important\nsecurity updates, critical features, and performance improvements.\n", "release_dates": []}, {"name": "era-compiler-llvm", "description": "The zkEVM fork of the LLVM framework", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# zkSync Era: The zkEVM LLVM Framework\n\n[![Logo](eraLogo.svg)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security\nor decentralization. As it's EVM-compatible (with Solidity/Vyper), 99% of Ethereum projects can redeploy without\nneeding to refactor or re-audit any code. zkSync Era also uses an LLVM-based compiler that will eventually enable\ndevelopers to write smart contracts in popular languages such as C++ and Rust.\n\nThis directory and its sub-directories contain the source code for the zkEVM fork of the [LLVM](https://llvm.org) framework,\na toolkit for the construction of highly optimized compilers, optimizers, and run-time environments\nused by the Solidity and Vyper compilers developed by Matter Labs.\n\n## Overview\n\nWelcome to the zkEVM LLVM project!\n\nThe project has multiple components. The core of the project is\nthe `llvm` directory. This contains all of the tools, libraries, and header\nfiles needed to process intermediate representations and convert them into\nobject files. Tools include an assembler, disassembler, bitcode analyzer, and\nbitcode optimizer. These tools are not yet officially supported for third-party front-ends.\nIt also contains zkEVM modifications of the standard [LLVM regression tests](https://llvm.org/docs/TestingGuide.html#regression-tests).\n\nThe zkEVM back-end is called `EraVM`, and the architecture is called `eravm`.\n\n## Building\n\nThe zkEVM LLVM framework must be built with our tool called `zkevm-llvm`:\n\n1. Install some tools system-wide:  \n   1.a. `apt install cmake ninja-build clang-13 lld-13` on a Debian-based Linux, with optional `musl-tools` if you need a `musl` build  \n   1.b. `pacman -S cmake ninja clang lld` on an Arch-based Linux  \n   1.c. On MacOS, install the [HomeBrew](https://brew.sh) package manager (being careful to install it as the appropriate user), then `brew install cmake ninja coreutils`. Install your choice of a recent LLVM/[Clang](https://clang.llvm.org) compiler, e.g. via [Xcode](https://developer.apple.com/xcode/), [Apple\u2019s Command Line Tools](https://developer.apple.com/library/archive/technotes/tn2339/_index.html), or your preferred package manager.  \n   1.d. Their equivalents with other package managers  \n\n2. [Install Rust](https://www.rust-lang.org/tools/install)\n\n   Currently we are not pinned to any specific version of Rust, so just install the latest stable build for your platform.\n   Also install the `musl` target if you are compiling on Linux in order to distribute the binaries:\n   `rustup target add x86_64-unknown-linux-musl`\n\n3. Install the zkEVM LLVM framework builder:  \n\n   3.a. `cargo install compiler-llvm-builder` on MacOS, or Linux for personal use  \n   3.b. `cargo install compiler-llvm-builder --target x86_64-unknown-linux-musl` on Linux for distribution  \n\n   The builder is not the zkEVM LLVM framework itself, but a tool that clones its repository and runs the sequence of build commands.\n   By default it is installed in `~/.cargo/bin/`, which is recommended to be added to your `$PATH`.\n\n4. In a directory in which you want the `llvm` directory, create an `LLVM.lock` file with the URL and branch or tag you want to build. For example:\n\n  ```\n  url = \"<THIS REPO URL>\"\n  branch = \"<THIS REPO BRANCH>\"\n  ```\n\n5. Run the builder to clone and build the zkevm LLVM framework:  \n   5.1. `zkevm-llvm clone`  \n   5.2. `zkevm-llvm build`  \n\n   The build artifacts will end up in the `./target-llvm/target-final/` directory.\n   You may point your `LLVM_SYS_150_PREFIX` to that directory to use this build as a compiler dependency.\n   If built with the `--enable-tests` option, test tools will be in the `./target-llvm/build-final/` directory, along with copies of the build artifacts.\n\n## Troubleshooting\n\n- If you get a \u201cfailed to authenticate when downloading repository\u2026 if the git CLI succeeds then net.git-fetch-with-cli may help here\u201d error,\nthen prepending the `cargo` command with `CARGO_NET_GIT_FETCH_WITH_CLI=true` may help.\n- Unset any LLVM-related environment variables you may have set.\n\n## License\n\nThe zkEVM fork of the LLVM framework is distributed under the terms of\nApache License, Version 2.0 with LLVM Exceptions, ([LICENSE](LICENSE) or <https://llvm.org/LICENSE.txt>)\n\n## Resources\n\n[Official LLVM documentation](https://llvm.org/docs/GettingStarted.html)\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through extensive testing and audits, and although it is live, it is still in alpha state and\nwill undergo further audits and bug bounty programs. We would love to hear our community's thoughts and suggestions\nabout it!\nIt's important to note that forking it now could potentially lead to missing important\nsecurity updates, critical features, and performance improvements.\n", "release_dates": []}, {"name": "era-compiler-llvm-builder", "description": "EraVM LLVM Framework Builder.", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Era: LLVM Framework Builder\n\n<p align=\"center\"><a href=\"https://zksync.io\" target=\"_blank\"><img alt=\"zkSync Era zkEVM is Ethereum\u2019s most user-centric ZK-rollup\" title=\"zkSync Era zkEVM is Ethereum\u2019s most user-centric ZK-rollup\" src=\"https://raw.githubusercontent.com/matter-labs/.github/main/header-image.png\" width=\"100%\">\n</a>\n</p>\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security\nor decentralization. As it's EVM-compatible (with Solidity/Vyper), 99% of Ethereum projects can redeploy without\nneeding to refactor or re-audit any code. zkSync Era also uses an LLVM-based compiler that will eventually enable\ndevelopers to write smart contracts in popular languages such as C++ and Rust.\n\nThis repository contains the builder of the EraVM fork of the LLVM framework.\n\n## License\n\nThis library is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through extensive testing and audits, and although it is live, it is still in alpha state and\nwill undergo further audits and bug bounty programs. We would love to hear our community's thoughts and suggestions\nabout it!\nIt's important to note that forking it now could potentially lead to missing important\nsecurity updates, critical features, and performance improvements.\n", "release_dates": []}, {"name": "era-compiler-llvm-context", "description": "Shared front end code of the EraVM compilers.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: Compiler LLVM context\n\n[![Logo](eraLogo.svg)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security\nor decentralization. As it's EVM-compatible (with Solidity/Vyper), 99% of Ethereum projects can redeploy without\nneeding to refactor or re-audit any code. zkSync Era also uses an LLVM-based compiler that will eventually enable\ndevelopers to write smart contracts in popular languages such as C++ and Rust.\n\nThis repository contains shared front end code of the EraVM compilers.\n\n## License\n\nThis library is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Resources\n\n[zkSync Era compiler toolchain documentation](https://era.zksync.io/docs/api/compiler-toolchain)\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through extensive testing and audits, and although it is live, it is still in alpha state and\nwill undergo further audits and bug bounty programs. We would love to hear our community's thoughts and suggestions\nabout it!\nIt's important to note that forking it now could potentially lead to missing important\nsecurity updates, critical features, and performance improvements.\n", "release_dates": []}, {"name": "era-compiler-solidity", "description": "EraVM Solidity compiler.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: Solidity Compiler\n\n[![Logo](eraLogo.svg)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security\nor decentralization. As it\u2019s EVM-compatible (with Solidity/Vyper), 99% of Ethereum projects can redeploy without\nneeding to refactor or re-audit any code. zkSync Era also uses an LLVM-based compiler that will eventually enable\ndevelopers to write smart contracts in popular languages such as C++ and Rust.\n\nThis repository contains the EraVM Solidity compiler.\n\n## System Requirements\n\nSupported platforms:\n- **Linux: x86_64**  \n   MUSL-based static builds do not depend on system libraries and can be run on any recent Linux distribution.\n- **MacOS 11+: x86_64, arm64 (M1, M2)**\n- **Windows: x86_64**  \n   Only Windows 10 has been tested so far, but other versions should be OK as well.\n\nWe recommend at least 4 GB of RAM available for the build process.\n\n## Delivery Methods\n\n1. **Install via npm**  \n   Use [zkSync CLI](https://era.zksync.io/docs/tools/zksync-cli/) to obtain a compiler package and prepare a project environment. After the installation you can modify a hardhat configuration file in the project and specify `zksolc` version there. Use `npx hardhat compile` or `yarn hardhat compile` to compile. [@matterlabs/hardhat-zksync-solc](https://era.zksync.io/docs/tools/hardhat/getting-started.html) package will be used from npm repo.\n2. **Download prebuilt binaries**  \n   Download [solc](https://github.com/ethereum/solc-bin) and [zksolc](https://github.com/matter-labs/zksolc-bin) binaries directly from GitHub. Use the CLI or Hardhat to compile contracts.\n3. **Build binaries from sources**  \n   Build binaries using the guide below. Use the CLI or Hardhat to compile contracts.\n\n## Building\n\n1. Install some tools system-wide:  \n   1.a. `apt install cmake ninja-build clang-13 lld-13 parallel` on a Debian-based Linux, with optional `musl-tools` if you need a `musl` build.  \n   1.b. `pacman -S cmake ninja clang lld parallel` on an Arch-based Linux.  \n   1.c. On MacOS, install the [HomeBrew](https://brew.sh) package manager (being careful to install it as the appropriate user), then `brew install cmake ninja coreutils parallel`. Install your choice of a recent LLVM/[Clang](https://clang.llvm.org) compiler, e.g. via [Xcode](https://developer.apple.com/xcode/), [Apple\u2019s Command Line Tools](https://developer.apple.com/library/archive/technotes/tn2339/_index.html), or your preferred package manager.  \n   1.d. Their equivalents with other package managers.  \n\n2. [Install Rust](https://www.rust-lang.org/tools/install)\n\n   Currently we are not pinned to any specific version of Rust, so just install the latest stable build for your platform.  \n   Also install the `musl` target if you are compiling on Linux in order to distribute the binary:  \n   `rustup target add x86_64-unknown-linux-musl`  \n\n3. [Download a version](https://github.com/ethereum/solc-bin) of [the solc compiler](https://docs.soliditylang.org/en/v0.8.21/) compiler.  \n   If it is not named exactly `solc` and in your `$PATH`, see the `--solc` option below.  \n\n4. Check out or clone the appropriate branch of this repository.  \n\n5. Go to the project root and run `git checkout <ref>` with the tag, branch, or commit you want to build.  \n\n6. Install the EraVM LLVM framework builder:  \n   6.a. `cargo install compiler-llvm-builder` on MacOS, or Linux for personal use.  \n   6.b. `cargo install compiler-llvm-builder --target x86_64-unknown-linux-musl` on Linux for distribution.  \n\n   The builder is not the [EraVM LLVM framework](https://github.com/matter-labs/era-compiler-llvm) itself; it is just a tool that clones our repository and runs the sequence of build commands. By default it is installed in `~/.cargo/bin/`, which is recommended to be added to your `$PATH`. Execute `zkevm-llvm --help` for more information.  \n   If you need a specific branch of EraVM LLVM, change it in the `LLVM.lock` file at the root of this repository.  \n\n7. Run the builder to clone and build the EraVM LLVM framework at this repository root:  \n   7.1. `zkevm-llvm clone`  \n   7.2. `zkevm-llvm build`  \n\n8. Build the Solidity compiler executable:  \n   8.a. `cargo build --release` on MacOS or Linux for personal use.  \n   8.b. `cargo build --release --target x86_64-unknown-linux-musl` on Linux for distribution.  \n\n9. If you need to move the built binary elsewhere, grab it from the build directory:  \n   9.a. On MacOS or Linux for the default target: `./target/release/zksolc`  \n   9.b. On Linux, if you are building for the target `x86_64-unknown-linux-musl`: `./target/x86_64-unknown-linux-musl/release/zksolc`  \n\n## Usage\n\nCheck `./target/*/zksolc --help` for the compiler usage.  \n\nThe `solc` compiler must be available in `$PATH`, or its path must be passed explicitly with the `--solc` option.\n\nFor big projects it is more convenient to use the compiler via the Hardhat plugin. For single-file contracts, or small\nprojects, the CLI suffices.  \n\n## Unit testing\n\nFor running unit tests, `zksolc` itself must also be available in `$PATH`, because it calls itself recursively to allow\ncompiling each contract in a separate process. To successfully run unit tests:\n\n1. Run `cargo build --release`.\n2. Move the binary from `./target/release/zksolc` to a directory from `$PATH`, or add the target directory itself to `$PATH`.\n3. Run `cargo test`.\n\n## CLI testing\n\nFor running command line interface tests, `zksolc` itself and `solc` must also be available in `$PATH`, because it calls itself recursively to allow compiling each contract in a separate processes. To successfully run CLI tests:\n\n1. Go to `cli-tests`.\n2. Make `npm i`.\n3. Add `solc` and `zksolc` to `$PATH`.\n4. Run `npm test`.\n\n## Troubleshooting\n\n- If you get a \u201cfailed to authenticate when downloading repository\u2026 if the git CLI succeeds then net.git-fetch-with-cli may help here\u201d error,\nthen prepending the `cargo` command with `CARGO_NET_GIT_FETCH_WITH_CLI=true`\nmay help.\n- On MacOS, `git config --global credential.helper osxkeychain` followed by cloning a repository manually with a personal access token may help.\n- Unset any LLVM-related environment variables you may have set, especially `LLVM_SYS_<version>_PREFIX` (see e.g. [https://crates.io/crates/llvm-sys](https://crates.io/crates/llvm-sys) and [https://llvm.org/docs/GettingStarted.html#local-llvm-configuration](https://llvm.org/docs/GettingStarted.html#local-llvm-configuration)). To make sure: `set | grep LLVM`\n\n## License\n\nThe Solidity compiler is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Resources\n\n[zkSync Era compiler toolchain documentation](https://era.zksync.io/docs/api/compiler-toolchain)\n\n[Solidity documentation](https://docs.soliditylang.org/en/latest/)\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through extensive testing and audits, and although it is live, it is still in alpha state and\nwill undergo further audits and bug bounty programs. We would love to hear our community's thoughts and suggestions\nabout it!\nIt's important to note that forking it now could potentially lead to missing important\nsecurity updates, critical features, and performance improvements.\n", "release_dates": ["2024-03-01T10:08:12Z", "2024-02-20T09:12:38Z"]}, {"name": "era-compiler-tester", "description": "zkEVM compilers integration test framework", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: The EraVM Compiler Integration Test Framework\n\n[![Logo](eraLogo.svg)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security\nor decentralization. As it's EVM-compatible (with Solidity/Vyper), 99% of Ethereum projects can redeploy without\nneeding to refactor or re-audit any code. zkSync Era also uses an LLVM-based compiler that will eventually enable\ndevelopers to write smart contracts in popular languages such as C++ and Rust.\n\nThe `compiler-tester` integration test framework runs tests for Matter Labs compilers which target the EraVM,\nfor supported languages listed below. It compiles source code via external API calls,\ne.g. to [Inkwell](https://thedan64.github.io/inkwell/inkwell/index.html). In software quality assurance jargon,\nthis makes it a whitebox testing framework.\n\nThe `compiler-tester` repository includes the Compiler Tests Collection repository as a submodule.\n\nBy default, the Tester SHOULD run the entire Collection in all possible combinations of compiler versions and settings,\nbut it MAY omit some subset of the combinations for the sake of saving time, e.g. when only front-end changes have been\nmade, and there is no point in running tests in all LLVM optimization modes.\n\n## Building\n\n1. Install some tools system-wide:  \n   1.a. `apt install cmake ninja-build clang-13 lld-13 parallel pkg-config` on a Debian-based Linux, with optional `musl-tools` if you need a `musl` build  \n   1.b. `pacman -S cmake ninja clang lld parallel` on an Arch-based Linux  \n   1.c. On MacOS, install the [HomeBrew](https://brew.sh) package manager (being careful to install it as the appropriate user), then `brew install cmake ninja coreutils parallel`. Install your choice of a recent LLVM/[Clang](https://clang.llvm.org) compiler, e.g. via [Xcode](https://developer.apple.com/xcode/), [Apple\u2019s Command Line Tools](https://developer.apple.com/library/archive/technotes/tn2339/_index.html), or your preferred package manager.  \n   1.d. Their equivalents with other package managers  \n\n2. [Install Rust](https://www.rust-lang.org/tools/install).\n\n3. Check out or clone the appropriate branch of this repository using the `--recursive` option.\n\n4. Install the LLVM building tool: `cargo install compiler-llvm-builder`.\n\n5. Pull and build the LLVM framework:  \n   5.a. If you have not cloned the LLVM repository yet:\n   ```\n   zkevm-llvm clone && zkevm-llvm build\n   ```\n   5.b. If you have already cloned the LLVM repository:  \n   ```\n   zkevm-llvm checkout\n   git -C './llvm/' pull\n   zkevm-llvm build\n   ```\n\n6. Build [zksolc](https://github.com/matter-labs/era-compiler-solidity) and [zkvyper](https://github.com/matter-labs/era-compiler-vyper) compilers and add the binaries to `$PATH`, or use the `--zksolc` or `--zkvyper` options to specify their paths.\n\n7. Build the Tester with `cargo build --release`.\n\n8. Run the tests using the examples below under \u201cUsage\u201d.\n\n## What is supported\n\n### Languages\n\n- Solidity\n- Yul\n- Vyper\n- LLVM IR\n- EraVM assembly\n\n### Optimizers\n\n- LLVM middle-end optimizer (levels 0 to 3, s, z, e.g. `M0`, `M1` etc.)\n- LLVM back-end optimizer (levels 0 to 3, e.g. `B0`, `B1` etc.)\n- `solc` optimizer (`-` or `+`)\n- `vyper` optimizer (`-` or `+`)\n\n### Solidity codegens\n\n- Yul pure (`Y`)\n- EVM assembly from Yul (`y`)\n- EVM assembly (`E`)\n\n### Compiler versions\n\n- `>=0.8` for compiling Solidity via Yul\n- `>=0.8.13` for compiling Solidity via EVM assembly from Yul\n- [0.4.10; latest] for compiling Solidity via EVM assembly\n- [0.3.3, 0.3.9] for compiling Vyper via LLL IR\n\n### Compiler pipelines\n\nCurrently only relevant for the Solidity compiler, where you can choose the IR:\n\n- Yul (preferred for Solidity \u22650.8)\n- EVM (supports Solidity \u22650.4)\n\n### Wildcards\n\nMost of the specifiers support wildcards `*` (any), `^` ('3' and 'z').\nWith no mode argument, iterates over all option combinations (approximately 800).\n\n## Usage\n\nEach command assumes you are at the root of the `compiler-tester` repository.\n\n### Generic command\n\n```bash\ncargo run --release --bin compiler-tester -- [-v] [-D] [-T[T]] \\\n\t[--path=\"${PATH}\"]* \\\n\t[--mode=\"${MODE}\"]*\n```\n\nThere are more rarely used options, which you may check out with `./target/release/compiler-tester --help`.\n\n### Example 1\n\nRun a simple Solidity test, dumping Yul, unoptimized and optimized LLVM IR, and EraVM assembly to the specified directory.\n\nUse:\n\n- Yul as the Solidity IR (`Y`)\n- Yul optimizations enabled (`+`)\n- level 3 optimizations in LLVM middle-end (`M3`)\n- level 3 optimizations in LLVM back-end (`B3`)\n- Solidity compiler version (`0.8.20`)\n\nOutput:\n\n- failed and invalid tests only (absence of `-v`)\n- the compiler debug data to the `./debug/` directory (`-D`)\n- the VM trace data to the `./trace/` directory (`-T`)\n\n```bash\ncargo run --release --bin compiler-tester -- -DT \\\n\t--path='tests/solidity/simple/default.sol' \\\n\t--mode='Y+M3B3 0.8.20' \\\n\t--zksolc '../compiler-solidity/target/release/zksolc'\n```\n\n### Example 2\n\nRun all simple Yul tests. This currently runs about three hundred tests and takes about eight minutes.\n\nUse:\n\n- level 1 optimizations in LLVM middle-end (`M1`)\n- level 2 optimizations in LLVM back-end (`B2`)\n\nOutput:\n\n- all tests, passed and failed (`-v`)\n- the VM trace data to the `./trace/` directory (`-T`)\n\n```bash\ncargo run --release --bin compiler-tester -- -vT \\\n\t--path='tests/yul/' \\\n\t--mode='M1B2'\n```\n\n### Example 3\n\nRun all tests (currently about three million) in all modes.\nThis takes a few hours on the CI server, and probably much longer on your personal machine.\n\n```bash\ncargo run --release --bin compiler-tester -- \\\n\t--zksolc '../compiler-solidity/target/release/zksolc' \\\n\t--zkvyper '../compiler-vyper/target/release/zkvyper'\n```\n\n## Tracing\n\nIf you run the tester with `-T` flag, JSON trace files will be written to the `./trace/` directory.\nThe trace files can be used with our [custom zkSync EraVM assembly tracer](https://staging-scan-v2.zksync.dev/tools/debugger) for debugging and research purposes.\n\n## Benchmarking\n\n1. Change the LLVM branch to the base in the `LLVM.lock` file at the repository root, checkout and build it:\n```\nzkevm-llvm checkout && zkevm-llvm build\n```\n\n2. Run the Tester with the desired filters and the output JSON path:\n```\n./target/release/compiler-tester \\\n\t--path='tests/solidity/simple/default.sol' \\\n\t--mode='Y+M^B3 0.8.20' \\\n\t--benchmark='reference.json'\n```\n\n3. Change the LLVM branch to your patch in the `LLVM.lock` file at the repository root, checkout and build it:\n```\nzkevm-llvm checkout && zkevm-llvm build\n```\n\n4. Run the Tester with the desired filters and the output JSON path:\n```\n./target/release/compiler-tester \\\n\t--path='tests/solidity/simple/default.sol' \\\n\t--mode='Y+M^B3 0.8.20' \\\n\t--benchmark='candidate.json'\n```\n\n5. Run the benchmark analyzer on the two JSONs:\n```\ncargo run --release --bin benchmark-analyzer -- --reference reference.json --candidate candidate.json\n```\n\nAfter you make any changes in LLVM, you only need to repeat steps 2-3 to update the working branch benchmark data.\n\n## Troubleshooting\n\n- If you get a \u201cfailed to authenticate when downloading repository\u2026 if the git CLI succeeds then net.git-fetch-with-cli may help here\u201d error,\nthen prepending the `cargo` command with `CARGO_NET_GIT_FETCH_WITH_CLI=true`\nmay help.\n- On MacOS, `git config --global credential.helper osxkeychain` followed by cloning a repository manually with a personal access token may help.\n- Unset any LLVM-related environment variables you may have set, especially `LLVM_SYS_<version>_PREFIX` (see e.g. [https://crates.io/crates/llvm-sys](https://crates.io/crates/llvm-sys) and [https://llvm.org/docs/GettingStarted.html#local-llvm-configuration](https://llvm.org/docs/GettingStarted.html#local-llvm-configuration)). To make sure: `set | grep LLVM`.\n\n## License\n\nThe Solidity compiler is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Resources\n\n[zkSync Era compiler toolchain documentation](https://era.zksync.io/docs/api/compiler-toolchain)\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through extensive testing and audits, and although it is live, it is still in alpha state and\nwill undergo further audits and bug bounty programs. We would love to hear our community's thoughts and suggestions\nabout it!\nIt's important to note that forking it now could potentially lead to missing important\nsecurity updates, critical features, and performance improvements.\n", "release_dates": []}, {"name": "era-compiler-tests", "description": "The collection of tests for the compilers for zkEVM", "language": "Solidity", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: The EraVM Compiler Tests Collection\n\n[![Logo](eraLogo.svg)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security\nor decentralization. As it's EVM-compatible (with Solidity/Vyper), 99% of Ethereum projects can redeploy without\nneeding to refactor or re-audit any code. zkSync Era also uses an LLVM-based compiler that will eventually enable\ndevelopers to write smart contracts in popular languages such as C++ and Rust.\n\nThis repository contains the collection of tests for the EraVM compilers.\n\n## Types\n\nThis repository contains three types of tests:\n\n- Ethereum - [Ethereum Solidity semantic tests format](https://github.com/ethereum/solidity/tree/develop/test/libsolidity/semanticTests).\n- Simple - single-contract tests created by Matter Labs.\n- Complex - multi-contract tests created by Matter Labs and vendored DeFi projects developed by other organizations.\n\nThe `solidity` and `vyper` directories have three subdirectories each, one for each type.\nThe `yul`, `llvm`, and `zkevm` directories only contain Matter Labs simple tests as multi-contract projects are not supported in these languages.\n\n## Matter Labs simple/complex format\n\nEach test comprises source code files and metadata.\nSimple tests have only one source file, and their metadata is written in comments that start with `!`, for example, `//!` for Solidity.\nComplex tests use the `test.json` file to describe their metadata and refer to source code files.\n\n## Metadata\n\nMetadata is a JSON file that contains the following fields:\n\n- `cases` - an array used to describe the test cases (more information below).\n- `contracts` - this field should only be used for complex tests to describe the contract instances to deploy. For example:\n```\n\"contracts\": {\n  \"Main\": \"main.sol:Main\",\n  \"Callable\": \"callable.sol:Callable\"\n}\n```\nIn simple tests, only one `Test` contract instance is deployed.\n- `libraries` - an optional field that specifies library addresses for the compiler linkage. Libraries can be described using the following format:\n```\n\"libraries\": {\n    \"libraries/UQ112x112.sol\": { \"UQ112x112\": \"UQ112x112\" },\n    \"libraries/Math.sol\": { \"Math\": \"Math\" }\n},\n```\n- `ignore` - an optional flag that disables a test.\n- `modes` - an optional field that specifies mode filters for tests. Compiler versions (for Solidity and Vyper) can be specified as SemVer range. For example:\n```\n\"modes\": [\n    \"Y-\",\n    \"E-\",\n    \"E+ >=0.4\",\n    \"E+ <0.5\"\n]\n```\n- `system_mode` - an optional system mode compiler flag (`false` by default). Set it to true if you need to enable the EraVM extensions.\n- `group` - an optional string field that specifies a test group. Currently, it is only used for benchmarking.\n\n## Case\n\nAll test cases are executed in a clean context, making them independent of each other.\n\nEach test case contains the following fields:\n\n- `name` - a string name.\n- `comment` - an optional string comment.\n- `inputs` - an array of inputs (described below).\n- `expected` - the expected return data for the last input (the format is described below in the input section).\n- `ignore`, `modes` - the same as in the test metadata.\n\n## Input\n\nInputs are utilized to specify the contract calls in the test case. The input fields are as follows:\n\n- `comment` - an optional string comment.\n- `instance` - an optional string field that represents the contract instance to call. By default, it is set to `Test`.\n- `caller` - an optional string field that denotes the caller address. By default, it is set to `0xdeadbeef01000000000000000000000000000000`.\n- `method` - a string field with three options:\n    1. `#deployer` for the deployer call.\n    2. `#fallback` to perform a call with the raw calldata.\n    3. Any other string will be recognized as a function name to call. The function selector will be appended at the beginning of the calldata.\n- `calldata` - the input calldata. There are two variants:\n    1. The hexadecimal string, for example: `\"calldata\": \"0x00\"`.\n    2. The numbers array. Hex and decimal (including negative) literals or instance addresses (like `Test.address`) are supported. Every number will be padded to 32 bytes. Example: `\"calldata\": [ \"1\", \"2\"]`.\n- `value` - an optional string field to specify `msg.value`, a decimal number with the ` wei` or ` ETH` suffix.\n- `storage` - storage values to set before the call. It is a mapping, where the key is the contract address (`InstanceName.address` can be used), and the value is an array or mapping. Example:\n```\n\"storage\": { \"Test.address\": [\n    \"1\", \"2\", \"3\", \"4\"\n] }\n```\n- `expected` - the expected return data for the input. There are two variants of the format:\n    1. An array of numbers, the same as calldata. Example: `\"expected\": [ \"1\", \"2\"]`.\n    2. Extended expected, which contains three main fields: `return_data` - an array, `exception` - a boolean flag indicating whether the revert is expected, `events` - an array of the expected events, where each event contains `address`(optional), `topics`, `values` fields. Example:\n```\n\"expected\": {\n    \"return_data\": [\n        \"Shit.address\"\n    ],\n    \"events\": [\n        {\n            \"topics\": [\n                \"0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef\",\n                \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n                \"0x000000000000000000000000deadbeef00000000000000000000000000000002\"\n            ],\n            \"values\": [\n                \"0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\"\n            ]\n        }\n    ],\n    \"exception\": false\n}\n```\n\nThe `expected` field can also be an array of the objects described above if different expected data is needed for different compiler versions.\nA `compiler_version` as a SemVer range can be specified for the extended expected.\nThe `expected` field is optional for the input, and the default value is empty return data.\n\nAdditional notes:\n\n- `InstanceName.address` can be used instead of numbers (in the expected, calldata, storage) to insert the contract instance address\n- If the deployer call is not specified for some instance, it will be generated automatically with empty calldata.\n\n## License\n\nThe Test Collection is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\nAdditionally, this repository vendors test projects preserving their original licenses:\n\n- [UniswapV2](./solidity/complex/defi/UniswapV2Router01)\n- [UniswapV3](./solidity/complex/defi/UniswapV3)\n- [StarkEx Verifier](./solidity/complex/defi/starkex-verifier)\n- [Curve](./vyper/complex/defi/Curve)\n- [Mooniswap](./solidity/complex/defi/Mooniswap)\n- [SHIT](./solidity/complex/defi/shitdao)\n\nThese projects are modified for the purposes of testing our compiler toolchain and are not used outside of this repository.  \nVisit the project directories to discover the terms of each license in detail. The projects are licensed in either per-file or\nper-project manner.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through extensive testing and audits, and although it is live, it is still in alpha state and\nwill undergo further audits and bug bounty programs. We would love to hear our community's thoughts and suggestions\nabout it!\nIt's important to note that forking it now could potentially lead to missing important\nsecurity updates, critical features, and performance improvements.\n", "release_dates": []}, {"name": "era-compiler-vyper", "description": "EraVM Vyper compiler.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: Vyper Compiler\n\n[![Logo](eraLogo.svg)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security\nor decentralization. As it\u2019s EVM-compatible (with Solidity/Vyper), 99% of Ethereum projects can redeploy without\nneeding to refactor or re-audit any code. zkSync Era also uses an LLVM-based compiler that will eventually enable\ndevelopers to write smart contracts in popular languages such as C++ and Rust.\n\nThis repository contains the EraVM Vyper compiler.\n\n## System Requirements\n\nSupported platforms:\n- **Linux: x86_64**  \n   MUSL-based static builds do not depend on system libraries and run on any recent Linux distribution.  \n- **MacOS 11+: x86_64, arm64 (M1, M2)**\n- **Windows: x86_64**  \n   Only Windows 10 has been tested so far, but other versions should be OK as well.  \n\nWe recommend at least 4 GB of RAM available for the build process.\n\n## Delivery Methods\n\n1. **Install via npm**  \n   Use [zkSync CLI](https://era.zksync.io/docs/tools/zksync-cli/) to obtain a compiler package and prepare a project environment. After the installation you can modify a hardhat configuration file in the project and specify `zkvyper` version there. Use `npx hardhat compile` or `yarn hardhat compile` to compile. [@matterlabs/hardhat-zksync-vyper](https://era.zksync.io/docs/tools/hardhat/getting-started.html) package will be used from npm repo.\n2. **Download prebuilt binaries**  \n   Download [v0.3.3, v0.3.9, or v0.3.10 of the Vyper compiler](https://github.com/vyperlang/vyper/releases) and [zkvyper](https://github.com/matter-labs/zkvyper-bin) binaries directly from GitHub. Use the CLI or Hardhat to compile contracts.\n3. **Build binaries from sources**  \n   Build binaries using the guide below. Use the CLI or Hardhat to compile contracts.\n\n## Building\n\n1. Install some tools system-wide:  \n   1.a. `apt install cmake ninja-build clang-13 lld-13 parallel` on a Debian-based Linux, with optional `musl-tools` if you need a `musl` build.  \n   1.b. `pacman -S cmake ninja clang lld parallel` on an Arch-based Linux.  \n   1.c. On MacOS, install the [HomeBrew](https://brew.sh) package manager (being careful to install it as the appropriate user), then `brew install cmake ninja coreutils parallel`. Install your choice of a recent LLVM/[Clang](https://clang.llvm.org) compiler, e.g. via [Xcode](https://developer.apple.com/xcode/), [Apple\u2019s Command Line Tools](https://developer.apple.com/library/archive/technotes/tn2339/_index.html), or your preferred package manager.  \n   1.d. Their equivalents with other package managers.  \n\n2. [Install Rust](https://www.rust-lang.org/tools/install)\n\n   Currently we are not pinned to any specific version of Rust, so just install the latest stable build for your platform.  \n   Also install the `musl` target if you are compiling on Linux in order to distribute the binary:  \n   `rustup target add x86_64-unknown-linux-musl`  \n\n3. Download [v0.3.3, v0.3.9, or v0.3.10 of the Vyper compiler](https://github.com/vyperlang/vyper/releases).  \n   If it is not named exactly `vyper` in your `$PATH`, see the `--vyper` option below.  \n   \n4. Check out or clone the appropriate branch of this repository.  \n\n5. Go to the project root and run `git checkout <ref>` with the tag, branch, or commit you want to build.  \n\n6. Install the EraVM LLVM framework builder:  \n   6.a. `cargo install compiler-llvm-builder` on MacOS, or Linux for personal use.  \n   6.b. `cargo install compiler-llvm-builder --target x86_64-unknown-linux-musl` on Linux for distribution.  \n\n   The builder is not the [EraVM LLVM framework](https://github.com/matter-labs/era-compiler-llvm) itself; it is just a tool that clones our repository and runs the sequence of build commands.  \n   By default it is installed in `~/.cargo/bin/`, which is recommended to be added to your `$PATH`. Execute `zkevm-llvm --help` for more information.  \n   If you need a specific branch of EraVM LLVM, change it in the `LLVM.lock` file at the root of this repository.  \n\n7. Run the builder to clone and build the EraVM LLVM framework at this repository root:  \n   7.1. `zkevm-llvm clone`  \n   7.2. `zkevm-llvm build`  \n\n8. Build the Vyper compiler executable:  \n   8.a. `cargo build --release` on MacOS or Linux for personal use.  \n   8.b. `cargo build --release --target x86_64-unknown-linux-musl` on Linux for distribution.  \n\n9. If you need to move the built binary elsewhere, grab it from the build directory:  \n   9.a. On MacOS or Linux for the default target: `./target/release/zkvyper`  \n   9.b. On Linux, if you are building for the target `x86_64-unknown-linux-musl`: `./target/x86_64-unknown-linux-musl/release/zkvyper`  \n\n## Usage\n\nCheck `./target/*/zkvyper --help` for compiler usage.  \n\nA support version of the Vyper compiler must be available in `$PATH`, or its path must be passed explicitly with the `--vyper` option.\n\nSupported versions:\n- 0.3.3\n- 0.3.9\n- 0.3.10\n\nFor big projects it is more convenient to use the compiler via the Hardhat plugin. For single-file contracts, or small\nprojects, the CLI suffices.\n\n## Unit testing\n\nFor running unit tests, `zkvyper` itself must also be available in `$PATH`, because it calls itself recursively to allow\ncompiling each contract in a separate process. To successfully run unit tests:\n\n1. Run `cargo build --release`.\n2. Move the binary from `./target/release/zkvyper` to a directory from `$PATH`, or add the target directory itself to `$PATH`.\n3. Run `cargo test`.\n\n## CLI testing\n\nFor running command line interface tests, `zkvyper` itself and `vyper` must also be available in `$PATH`, because it calls itself recursively to allow compiling each contract in a separate processes. To successfully run CLI tests:\n\n1. Go to `cli-tests`.\n2. Make `npm i`.\n3. Add `vyper` and `zkvyper` to `$PATH`.\n4. Run `npm test`. \n\n## Troubleshooting\n\n- If you get a \u201cfailed to authenticate when downloading repository\u2026 if the git CLI succeeds then net.git-fetch-with-cli may help here\u201d error, then prepending the `cargo` command with `CARGO_NET_GIT_FETCH_WITH_CLI=true` may help.\n- On MacOS, `git config --global credential.helper osxkeychain` followed by cloning a repository manually with a personal access token may help.\n- Unset any LLVM-related environment variables you may have set, especially `LLVM_SYS_<version>_PREFIX` (see e.g. [https://crates.io/crates/llvm-sys](https://crates.io/crates/llvm-sys) and [https://llvm.org/docs/GettingStarted.html#local-llvm-configuration](https://llvm.org/docs/GettingStarted.html#local-llvm-configuration)). To make sure: `set | grep LLVM`\n\n## License\n\nThe Vyper compiler is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Resources\n\n- [zkSync Era compiler toolchain documentation](https://era.zksync.io/docs/api/compiler-toolchain)\n- [Vyper v0.3.3 documentation](https://vyper.readthedocs.io/en/v0.3.3/)\n- [Vyper v0.3.9 documentation](https://vyper.readthedocs.io/en/v0.3.9/)\n- [Vyper v0.3.10 documentation](https://vyper.readthedocs.io/en/v0.3.10/)\n- [Vyper LLL IR](https://github.com/vyperlang/vyper/blob/master/vyper/ir/README.md)  \n\n> Some parts of the Vyper documentation may be outdated.  \n> Please contact the Vyper team for assistance.  \n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through extensive testing and audits, and although it is live, it is still in alpha state and\nwill undergo further audits and bug bounty programs. We would love to hear our community's thoughts and suggestions\nabout it!\nIt's important to note that forking it now could potentially lead to missing important\nsecurity updates, critical features, and performance improvements.\n", "release_dates": ["2024-02-20T09:17:25Z"]}, {"name": "era-consensus", "description": "Consensus layer implementation for zkSync Era", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era Consensus Layer\n\nThis repo implements the consensus algorithm for the era blockchain. We implement all the necessary components for a set of sequencers to reach consensus over blocks (which right now are represented just as binary blobs). In the future, this codebase will also be capable of running full nodes and, after we integrate with the rest of the server, of reaching consensus over real blocks.\n\n## Knowledge Index\n\nThe following questions will be answered by the following resources:\n\n| Question                                                | Resource                                |\n| ------------------------------------------------------- | --------------------------------------- |\n| What is the logical project structure and architecture? | [architecture.md](docs/architecture.md) |\n| How can I run the project?                              | [launch.md](docs/launch.md)             |\n| What is the style guide to contribute to this repo?     | [style.md](docs/style.md)               |\n\n## Policies\n\n- [Security policy](.github/SECURITY.md)\n- [Contribution policy](CONTRIBUTING.md)\n\n## License\n\nzkSync Era is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [ZK Credo](https://github.com/zksync/credo)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n", "release_dates": []}, {"name": "era-contracts", "description": "Smart Contract Submodule For zkSync Era", "language": "Solidity", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Era: Smart Contracts\n\n[![Logo](eraLogo.svg)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\nThis repository contains both L1 and L2 zkSync smart contracts. For their description see the\n[system overview](docs/Overview.md).\n\n## Disclaimer\n\nIt is used as a submodule of a private repo. Compilation and test scripts should work without additional tooling, but\nothers may not.\n\n## License\n\nzkSync Era contracts are distributed under the terms of the MIT license.\n\nSee [LICENSE-MIT](LICENSE-MIT) for details.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [ZK Credo](https://github.com/zksync/credo)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n- [Mirror](https://zksync.mirror.xyz/)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": ["2024-03-01T08:23:24Z", "2024-03-01T08:13:50Z", "2024-02-29T15:20:40Z", "2024-02-29T11:29:10Z", "2024-02-29T09:14:10Z", "2024-02-29T22:48:33Z", "2024-03-03T18:45:19Z", "2024-02-29T09:09:27Z", "2024-03-01T12:48:55Z", "2024-02-29T16:01:48Z", "2024-02-29T14:33:04Z", "2024-02-29T14:35:07Z", "2024-03-01T13:31:29Z", "2024-03-01T13:20:50Z", "2024-03-01T13:25:01Z", "2024-03-02T11:16:26Z", "2024-03-02T10:10:16Z", "2024-02-28T14:23:54Z", "2024-02-23T13:13:39Z", "2024-02-23T13:53:29Z", "2024-02-27T22:28:24Z", "2024-02-27T22:33:25Z", "2024-02-28T12:52:14Z", "2024-02-29T08:24:22Z", "2024-02-28T17:38:56Z", "2024-02-28T18:05:59Z", "2024-02-27T10:24:55Z", "2024-02-27T10:31:01Z", "2024-02-27T10:28:10Z", "2024-02-29T08:58:06Z"]}, {"name": "era-cuda", "description": "CUDA Runtime bindings, wrappers and helpers", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# zkSync Era: A ZK Rollup For Scaling Ethereum\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n\n## Era-CUDA\nEra-CUDA repository is a collection of rust crates that implement bindings, wrappers and helpers for the CUDA Runtime API.\n\nPrerequisites: \n- CUDA 12.x\n- clang\n- rust nightly toolchain\n\n## Policies\n\n- [Security policy](SECURITY.md)\n- [Contribution policy](CONTRIBUTING.md)\n\n## License\n\nzkSync Era is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [ZK Credo](https://github.com/zksync/credo)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-fee-withdrawer", "description": null, "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Fee withdrawer\n\nThis repository contains the fee withdrawer script: a utility that is capable of withdrawing funds\nfrom zkSync fee account in L2 to L1, and transferring funds to the\nzkSync operator account, withdrawal finalizer account and reserve account.\n\n## Utility lifecycle\n\nFee seller is expected to be run periodically, and upon each launch it sequentially does the following:\n\n1. Check whether withdrawing ETH is reasonable. If so, withdraw funds to L1 account.\n2. Check the L1 ETH balance on the fee account. If it's above configurable threshold, divide the amount between 3 accounts:\n  - If zkSync operator account balance is lower than the threshold, send necessary amount to zkSync operator account.\n  - If zkSync withdrawal finalizer account balance is lower than the threshold, send necessary amount to zkSync withdrawal finalizer account.\n  - Otherwise, send to reserve account.\n  \nThis way, script achieves the following goal:\nwe don't maintain all the funds on a single hot wallet (operator account). We keep the operator and withdrawer balances big\nenough to work on its own for several days (e.g. 15 ETH), but all the excessive funds are transferred to\nthe cold wallet (reserve account).\n\n## Configuration parameters\n\nConfiguration parameters should be set as environment variables.\nSee `index.ts` for details.\n\n## Notifications\n\nNotifications about operations performed by fee withdrawer are sent to mattermost (currently, to the `Notifications`\nchannel).\n", "release_dates": ["2023-06-07T10:52:35Z", "2023-02-13T10:41:17Z", "2022-11-29T13:03:23Z", "2022-11-24T19:22:44Z", "2022-11-19T10:51:41Z", "2022-09-05T12:44:29Z"]}, {"name": "era-hardhat-with-plugins", "description": "A zkSync Hardhat project configured with multiple plugins to improve the developer experience", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Hardhat project with plugins\n\n## hardhat-deploy\n\nFor this plugin you need to configure your accounts in the .env file. `zksync-web3` is integrated in hardhat-deploy so there's no need to use the `Deployer` class from `hardhat-zksync-deploy`. Check deployment script `001-deploy-greeter.ts` file for reference.\n\nRun `npx hardhat deploy --network zkSyncTestnet` \n\nCreates the `deployments` folder and saves info in different files so deployments can be cached and re-run.\n\n## hardhat-contract-sizer\n\nCreates a report of the contract bytecode size on compilation time.\n\n`yarn hardhat compile`\n\n## @typechain/hardhat\n\nCreates Typescript type definitions in the `/typechain` folder. Runs on compilation.\n\n## hardhat-abi-exporter\n\nExports contract ABI files to the `/abis` folder. Runs on compilation.\n\n\n---\n\nThis project was scaffolded with [zksync-cli](https://github.com/matter-labs/zksync-cli).\n\n\n\n### Environment variables\n\nIn order to prevent users to leak private keys, this project includes the `dotenv` package which is used to load environment variables. It's used to load the wallet private key, required to run the deploy script.\n\nTo use it, rename `.env.example` to `.env` and enter your private key.\n\n```\nWALLET_PRIVATE_KEY=123cde574ccff....\n```\n\n### Local testing\n\nIn order to run test, you need to start the zkSync local environment. Please check [this section of the docs](https://v2-docs.zksync.io/api/hardhat/testing.html#prerequisites) which contains all the details.\n\nIf you do not start the zkSync local environment, the tests will fail with error `Error: could not detect network (event=\"noNetwork\", code=NETWORK_ERROR, version=providers/5.7.2)`\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n", "release_dates": []}, {"name": "era-heavy-ops-service", "description": "Specialized GPU Prover for zkSync Era", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# CPU/GPU Based Prover for zkSync Era\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n##  Build\n```\ngit submodule update  --init --recursive\ncmake -Bbellman-cuda/build -Sbellman-cuda/ -DCMAKE_BUILD_TYPE=Release\ncmake --build bellman-cuda/build/\n```\n\n## Test\n`LOG_BASE=15 BELLMAN_CUDA_DIR=$PWD/bellman-cuda cargo test -package api-testing --release -- --nocapture`\n\n## License\n\nThe zkSync Era prover is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-observability", "description": "Grafana dashboards for zkSync Era", "language": null, "license": null, "readme": "# era-observability\nGrafana dashboards for zkSync Era\n", "release_dates": []}, {"name": "era-openzeppelin", "description": "OpenZeppelin Contracts is a library for secure smart contract development.", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# <img src=\"logo.svg\" alt=\"OpenZeppelin\" height=\"40px\">\n\n[![Docs](https://img.shields.io/badge/docs-%F0%9F%93%84-blue)](https://docs.openzeppelin.com/contracts)\n[![NPM Package](https://img.shields.io/npm/v/@openzeppelin/contracts.svg)](https://www.npmjs.org/package/@openzeppelin/contracts)\n[![Coverage Status](https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts/graph/badge.svg)](https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts)\n[![gitpoap badge](https://public-api.gitpoap.io/v1/repo/OpenZeppelin/openzeppelin-contracts/badge)](https://www.gitpoap.io/gh/OpenZeppelin/openzeppelin-contracts)\n\n**A library for secure smart contract development.** Build on a solid foundation of community-vetted code.\n\n * Implementations of standards like [ERC20](https://docs.openzeppelin.com/contracts/erc20) and [ERC721](https://docs.openzeppelin.com/contracts/erc721).\n * Flexible [role-based permissioning](https://docs.openzeppelin.com/contracts/access-control) scheme.\n * Reusable [Solidity components](https://docs.openzeppelin.com/contracts/utilities) to build custom contracts and complex decentralized systems.\n\n:mage: **Not sure how to get started?** Check out [Contracts Wizard](https://wizard.openzeppelin.com/) \u2014 an interactive smart contract generator.\n\n:building_construction: **Want to scale your decentralized application?** Check out [OpenZeppelin Defender](https://openzeppelin.com/defender) \u2014 a secure platform for automating and monitoring your operations.\n\n## Overview\n\n### Installation\n\n```console\n$ npm install @openzeppelin/contracts\n```\n\nOpenZeppelin Contracts features a [stable API](https://docs.openzeppelin.com/contracts/releases-stability#api-stability), which means that your contracts won't break unexpectedly when upgrading to a newer minor version.\n\nAn alternative to npm is to use the GitHub repository (`openzeppelin/openzeppelin-contracts`) to retrieve the contracts. When doing this, make sure to specify the tag for a release such as `v4.5.0`, instead of using the `master` branch.\n\n### Usage\n\nOnce installed, you can use the contracts in the library by importing them:\n\n```solidity\npragma solidity ^0.8.0;\n\nimport \"@openzeppelin/contracts/token/ERC721/ERC721.sol\";\n\ncontract MyCollectible is ERC721 {\n    constructor() ERC721(\"MyCollectible\", \"MCO\") {\n    }\n}\n```\n\n_If you're new to smart contract development, head to [Developing Smart Contracts](https://docs.openzeppelin.com/learn/developing-smart-contracts) to learn about creating a new project and compiling your contracts._\n\nTo keep your system secure, you should **always** use the installed code as-is, and neither copy-paste it from online sources nor modify it yourself. The library is designed so that only the contracts and functions you use are deployed, so you don't need to worry about it needlessly increasing gas costs.\n\n## Learn More\n\nThe guides in the [documentation site](https://docs.openzeppelin.com/contracts) will teach about different concepts, and how to use the related contracts that OpenZeppelin Contracts provides:\n\n* [Access Control](https://docs.openzeppelin.com/contracts/access-control): decide who can perform each of the actions on your system.\n* [Tokens](https://docs.openzeppelin.com/contracts/tokens): create tradeable assets or collectives, and distribute them via [Crowdsales](https://docs.openzeppelin.com/contracts/crowdsales).\n* [Gas Station Network](https://docs.openzeppelin.com/contracts/gsn): let your users interact with your contracts without having to pay for gas themselves.\n* [Utilities](https://docs.openzeppelin.com/contracts/utilities): generic useful tools including non-overflowing math, signature verification, and trustless paying systems.\n\nThe [full API](https://docs.openzeppelin.com/contracts/api/token/ERC20) is also thoroughly documented, and serves as a great reference when developing your smart contract application. You can also ask for help or follow Contracts's development in the [community forum](https://forum.openzeppelin.com).\n\nFinally, you may want to take a look at the [guides on our blog](https://blog.openzeppelin.com/guides), which cover several common use cases and good practices. The following articles provide great background reading, though please note that some of the referenced tools have changed, as the tooling in the ecosystem continues to rapidly evolve.\n\n* [The Hitchhiker\u2019s Guide to Smart Contracts in Ethereum](https://blog.openzeppelin.com/the-hitchhikers-guide-to-smart-contracts-in-ethereum-848f08001f05) will help you get an overview of the various tools available for smart contract development, and help you set up your environment.\n* [A Gentle Introduction to Ethereum Programming, Part 1](https://blog.openzeppelin.com/a-gentle-introduction-to-ethereum-programming-part-1-783cc7796094) provides very useful information on an introductory level, including many basic concepts from the Ethereum platform.\n* For a more in-depth dive, you may read the guide [Designing the Architecture for Your Ethereum Application](https://blog.openzeppelin.com/designing-the-architecture-for-your-ethereum-application-9cec086f8317), which discusses how to better structure your application and its relationship to the real world.\n\n## Security\n\nThis project is maintained by [OpenZeppelin](https://openzeppelin.com), and developed following our high standards for code quality and security. OpenZeppelin Contracts is meant to provide tested and community-audited code, but please use common sense when doing anything that deals with real money! We take no responsibility for your implementation decisions and any security problems you might experience.\n\nThe core development principles and strategies that OpenZeppelin Contracts is based on include: security in depth, simple and modular code, clarity-driven naming conventions, comprehensive unit testing, pre-and-post-condition sanity checks, code consistency, and regular audits.\n\nThe latest audit was done on October 2018 on version 2.0.0.\n\nWe have a [**bug bounty program** on Immunefi](https://www.immunefi.com/bounty/openzeppelin). Please report any security issues you find through the Immunefi dashboard, or reach out to security@openzeppelin.com.\n\nCritical bug fixes will be backported to past major releases.\n\n## Contribute\n\nOpenZeppelin Contracts exists thanks to its contributors. There are many ways you can participate and help build high quality software. Check out the [contribution guide](CONTRIBUTING.md)!\n\n## License\n\nOpenZeppelin Contracts is released under the [MIT License](LICENSE).\n", "release_dates": []}, {"name": "era-revm", "description": "revm (Rust Ethereum VM) translation for Era / zkEVM", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Revm - zkSync Era translation layer\n\nThis crate acts as a bridge between Revm (Rust EVM implementation) and zkSync Era VM.\n\nCurrently this is used by Foundry testing. \n\nThis repo is still in development.", "release_dates": []}, {"name": "era-shivini", "description": "A library implementing GPU-accelerated zkSync prover.", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# zkSync Era: A ZK Rollup For Scaling Ethereum\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## License\n\nzkSync Era is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-solidity", "description": "Solidity compiler and language tuned for EraVM", "language": "C++", "license": {"key": "gpl-3.0", "name": "GNU General Public License v3.0", "spdx_id": "GPL-3.0", "url": "https://api.github.com/licenses/gpl-3.0", "node_id": "MDc6TGljZW5zZTk="}, "readme": "# zkSync Era: Solidity Compiler\n\n[![Logo](eraLogo.svg)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security\nor decentralization. As it's EVM-compatible (with Solidity/Vyper), 99% of Ethereum projects can redeploy without\nneeding to refactor or re-audit any code. zkSync Era also uses an LLVM-based compiler that will eventually enable\ndevelopers to write smart contracts in popular languages such as C++ and Rust.\n\nThis repository contains the Solidity compiler and language tuned for EraVM.\n\n## License\n\nSolidity is licensed under [GNU General Public License v3.0](LICENSE.txt).\n\nSome third-party code has its [own licensing terms](cmake/templates/license.h.in).\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through extensive testing and audits, and although it is live, it is still in alpha state and\nwill undergo further audits and bug bounty programs. We would love to hear our community's thoughts and suggestions\nabout it!\nIt's important to note that forking it now could potentially lead to missing important\nsecurity updates, critical features, and performance improvements.\n", "release_dates": ["2024-01-31T13:27:00Z", "2024-01-17T04:04:55Z", "2024-01-17T03:57:13Z", "2024-01-17T03:48:44Z", "2024-01-17T03:39:57Z", "2024-01-17T03:23:09Z", "2024-01-17T03:31:19Z", "2024-01-17T03:14:07Z", "2024-01-17T03:04:43Z", "2024-01-17T02:56:11Z", "2024-01-17T02:48:34Z", "2024-01-17T02:31:50Z", "2024-01-17T02:40:07Z", "2024-01-17T02:22:30Z", "2024-01-17T02:15:25Z", "2024-01-17T02:05:40Z", "2024-01-17T01:58:24Z", "2024-01-17T01:42:54Z", "2024-01-17T01:50:17Z", "2024-01-17T01:33:43Z", "2024-01-17T01:25:58Z", "2024-01-17T01:19:08Z", "2024-01-17T01:10:32Z", "2024-01-17T00:56:26Z", "2024-01-17T01:04:06Z", "2024-01-17T00:48:57Z", "2024-01-17T00:41:31Z", "2024-01-17T00:34:07Z", "2024-01-17T00:26:44Z", "2024-01-17T00:19:19Z"]}, {"name": "era-sync_vm", "description": "Circuit Implementation of zkVM for zkSync Era", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# CPU/GPU Based Prover for zkSync Era\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## License\n\nThe zkSync Era prover is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-system-contracts", "description": "Implementation of the system contracts", "language": "Solidity", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Era: System Contracts\n\n[![Logo](eraLogo.svg)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## system-contracts\n\nTo keep the zero-knowledge circuits as simple as possible and enable simple extensions, we created the system contracts.\nThese are privileged special-purpose contracts that instantiate some recurring actions on the protocol level. Some of\nthe most commonly used contracts:\n\n`ContractDeployer` This contract is used to deploy new smart contracts. Its job is to make sure that the bytecode for\neach deployed contract is known. This contract also defines the derivation address. Whenever a contract is deployed, a\nContractDeployed event is emitted.\n\n`L1Messenger` This contract is used to send messages from zkSync to Ethereum. For each message sent, the L1MessageSent\nevent is emitted.\n\n`NonceHolder` This contract stores account nonces. The account nonces are stored in a single place for efficiency (the\ntx nonce and the deployment nonce are stored in a single place) and also for the ease of the operator.\n\n`Bootloader` For greater extensibility and to lower the overhead, some parts of the protocol (e.g. account abstraction\nrules) were moved to an ephemeral contract called a bootloader.\n\nWe call it ephemeral because it is not physically deployed and cannot be called, but it has a formal address that is\nused on msg.sender, when it calls other contracts.\n\n## Building\n\nThis repository is used as a submodule of the [zksync-era](https://github.com/matter-labs/zksync-era).\n\nCompile the solidity and yul contracts: `yarn build`\n\nCheck the system contracts hashes: `yarn calculate-hashes:check`\n\nUpdate the system contracts hashes: `yarn calculate-hashes:fix`\n\n## Update Process\n\nSystem contracts handle core functionalities and play a critical role in maintaining the integrity of our protocol. To\nensure the highest level of security and reliability, these system contracts undergo an audit before any release.\n\nHere is an overview of the release process of the system contracts which is aimed to preserve agility and clarity on the\norder of the upgrades:\n\n### `main` branch\n\nThe `main` branch contains the latest code that is ready to be deployed into production. It reflects the most stable and\naudited version of the protocol.\n\n### `dev` branch\n\nThe `dev` branch is for active development & the latest code changes. Whenever a new PR with system contract changes is\ncreated it should be based on the `dev` branch.\n\n### Creating a new release\n\nWhenever a new release is planned, a new branch named `release-vX-<name>` should be created off the `dev` branch, where\n`X` represents the release version, and `<name>` is a short descriptive name for the release. The PR with the new\nrelease should point to either the `main` branch or to the release branch with a lower version (in case the previous\nbranch has not been merged into `main` for some reason).\n\nOnce the audit for the release branch is complete and all the fixes from the audit are applied, we need to merge the new\nchanges into the `dev` branch. Once the release is final and merged into the `main` branch, the `main` branch should be\nmerged back into the `dev` branch to keep it up-to-date.\n\n### Updating Unaudited Code\n\nSince scripts, READMEs, etc., are code that is not subject to audits, these are to be merged directly into the `main`\nbranch. The rest of the release branches as well as the `dev` branch should merge `main` to synchronize with these\nchanges.\n\n## License\n\nThe zkSync Era system-contracts are distributed under the terms of the MIT license.\n\nSee [LICENSE-MIT](LICENSE-MIT) for details.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [ZK Credo](https://github.com/zksync/credo)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n- [Mirror](https://zksync.mirror.xyz/)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-test-node", "description": "In-memory node that can be used for integration testing and debugging.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<div align=\"center\">\n<a href=\"https://era.zksync.io/docs/tools/testing/era-test-node.html\">\n\n![era-test-node](./.github/assets/era_test_node_banner_light.png#gh-light-mode-only)\n![era-test-node](./.github/assets/era_test_node_banner_dark.png#gh-dark-mode-only)\n</a>\n\n  </div>\n\n# \ud83d\ude80 zkSync Era In-Memory Node \ud83d\ude80\n\nThis crate provides an in-memory node that supports forking the state from other networks.\n\nThe goal of this crate is to offer a fast solution for integration testing, bootloader and system contract testing, and prototyping.\n\n\ud83d\udd17 For a detailed walkthrough, refer to the [official documentation](https://era.zksync.io/docs/tools/testing/era-test-node.html).\n\n## \ud83d\udccc Overview\n\nThe In-Memory Node is designed for local testing and uses an in-memory database for storing state information. It also employs simplified hashmaps for tracking blocks and transactions. When in fork mode, it fetches missing storage data from a remote source if not available locally. Additionally, it uses the remote server (openchain) to resolve the ABI and topics to human-readable names.\n\n## \u26a0\ufe0f Caution\n\nPlease note that `era-test-node` is still in its **alpha** stage. Some features might not be fully supported yet and may not work as intended. However, it is open-sourced, and contributions are welcome!\n\n## \ud83d\udcca Limitations & Features\n\n| \ud83d\udeab Limitations                                  | \u2705 Features                                                 |\n| ----------------------------------------------- | ----------------------------------------------------------- |\n| No communication between Layer 1 and Layer 2.   | Can fork the state of mainnet, testnet, or custom network.  |\n| Many APIs are not yet implemented.              | Can replay existing mainnet or testnet transactions.        |\n| No support for accessing historical data.       | Uses local bootloader and system contracts.                 |\n| Only one transaction allowed per Layer 1 batch. | Operates deterministically in non-fork mode.                |\n| Fixed values returned for zk Gas estimation.    | Starts up quickly with pre-configured 'rich' accounts.      |\n| Redeploy requires MetaMask cache reset.         | Supports hardhat's console.log debugging.                   |\n|                                                 | Resolves names of ABI functions and Events using openchain. |\n\n## \ud83d\udee0 Prerequisites\n\n1. **Rust**: `era-test-node` is written in Rust. Ensure you have Rust installed on your machine. [Download Rust here](https://www.rust-lang.org/tools/install).\n\n2. **Other Dependencies**: This crate relies on rocksDB. If you face any compile errors due to rocksDB, install the necessary dependencies with:\n   ```bash\n   apt-get install -y cmake pkg-config libssl-dev clang\n   ```\n\n## \ud83d\udce5 Installation & Setup\n\n1. Download `era-test-node` from latest [Release](https://github.com/matter-labs/era-test-node/releases/latest)\n\n2. Extract the binary and mark as executable:\n   ```bash\n   tar xz -f era_test_node.tar.gz -C /usr/local/bin/\n   chmod +x /usr/local/bin/era_test_node\n   ```\n\n3. Start the node:\n   ```bash\n   era_test_node run\n   ```\n\n## \ud83e\uddd1\u200d\ud83d\udcbb Running Locally\n\n1. Compile Rust project and start the node:\n   ```bash\n   make run\n   ```\n\n## \ud83d\udcc4 System Contracts\n\nThe system contract within the node can be specified via the `--dev-system-contracts` option. \nIt can take one of the following options:\n   * `built-in`: Use the compiled built-in contracts\n   * `built-in-no-verify`: Use the compiled built-in contracts, but without signature verification\n   * `local`: Load contracts from `ZKSYNC_HOME`\n\n## \ud83d\udcc3 Logging\n\nThe node may be started in either of `debug`, `info`, `warn` or `error` logging levels via the `--log` option:\n```bash\nera_test_node --log=error run\n```\n\nAdditionally, the file path can be provided via the `--log-file-path` option (defaults to `./era_test_node.log`):\n```bash\nera_test_node --log=error --log-file-path=run.log run\n```\n\nThe logging can be configured during runtime via the [`config_setLogLevel`](./SUPPORTED_APIS.md#config_setloglevel) and [`config_setLogging`](./SUPPORTED_APIS.md#config_setlogging) methods.\n\n## \ud83d\udcc3 Caching\n\nThe node will cache certain network request by default to disk in the `.cache` directory. Alternatively the caching can be disabled or set to in-memory only\nvia the `--cache=none|memory|disk` parameter. \n\n```bash\nera_test_node --cache=none run\n```\n\n```bash\nera_test_node --cache=memory run\n```\n\nAdditionally when using `--cache=disk`, the cache directory may be specified via `--cache-dir` and the cache may\nbe reset on startup via `--reset-cache` parameters.\n```bash\nera_test_node --cache=disk --cache-dir=/tmp/foo --reset-cache run\n```\n\n## \ud83c\udf10 Network Details\n\n- L2 RPC: http://localhost:8011\n- Network Id: 260\n\n> Note: The existing implementation does not support communication with Layer 1. As a result, an L1 RPC is not available.\n\n## \ud83c\udf74 Forking Networks\n\nTo fork the mainnet:\n\n```bash\nera_test_node fork mainnet\n```\n\n> Tip: You can also fork the zkSync Sepolia testnet with `era_test_node fork sepolia-testnet`.\n\n## \ud83d\udd04 Replay Remote Transactions Locally\n\nIf you wish to replay a remote transaction locally for deep debugging, use the following command:\n\n```bash\nera_test_node replay_tx <network> <transaction_hash>\n```\n\n## \ud83d\udcde Sending Network Calls\n\nYou can send network calls against a running `era-test-node`. For example, to check the testnet LINK balance or mainnet USDT, use `curl` or `foundry-zksync`.\n\n```bash\ncurl -X POST -H \"Content-Type: application/json\" --data '{\"jsonrpc\":\"2.0\",\"method\":\"eth_call\",\"params\":[{\"to\":\"0x40609141Db628BeEE3BfAB8034Fc2D8278D0Cc78\", \"data\":\"0x06fdde03\"}, \"latest\"],\"id\":1}' http://localhost:8011\n```\n\n## \ud83d\udd0d Seeing more details of the transactions\n\nBy default, the tool is just printing the basic information about the executed transactions (like status, gas used etc).\n\nBut with --show-calls flag, it can print more detailed call traces, and with --resolve-hashes, it will ask openchain for ABI names.\n\n```bash\nera_test_node --show-calls=user --resolve-hashes replay_tx sepolia-testnet 0x7119045573862797257e4441ff48bf5a3bc4d133a00d167c18dc955eda12cfac\n\nExecuting 0x7119045573862797257e4441ff48bf5a3bc4d133a00d167c18dc955eda12cfac\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   TRANSACTION SUMMARY   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nTransaction: SUCCESS\nInitiator: 0x4eaf936c172b5e5511959167e8ab4f7031113ca3\nPayer: 0x4eaf936c172b5e5511959167e8ab4f7031113ca3\nGas - Limit: 2_487_330 | Used: 969_330 | Refunded: 1_518_000\nUse --show-gas-details flag or call config_setShowGasDetails to display more info\n\n==== Console logs: \n\n==== 22 call traces.  Use --show-calls flag or call config_setShowCalls to display more info.\n  Call(Normal) 0x4eaf936c172b5e5511959167e8ab4f7031113ca3           validateTransaction(bytes32, bytes32, tuple)   1830339\n    Call(Normal) 0x0000000000000000000000000000000000000001                 0x89c19e9b   1766835\n  Call(Normal) 0x4eaf936c172b5e5511959167e8ab4f7031113ca3           payForTransaction(bytes32, bytes32, tuple)   1789767\n  Call(Normal) 0x4eaf936c172b5e5511959167e8ab4f7031113ca3           executeTransaction(bytes32, bytes32, tuple)   1671012\n      Call(Mimic) 0x5d4fb5385ed95b65d1cd6a10ed9549613481ab2f           0x   1443393\n```\n\nYou can use the following options to get more granular information during transaction processing:\n\n- `--show-storage-logs <SHOW_STORAGE_LOGS>`: Show storage log information.  \n  [default: none]  \n  [possible values: none, read, paid, write, all]\n\n- `--show-vm-details <SHOW_VM_DETAILS>`: Show VM details information.  \n  [default: none]  \n  [possible values: none, all]\n\n- `--show-gas-details <SHOW_GAS_DETAILS>`: Show Gas details information.  \n  [default: none]  \n  [possible values: none, all]\n\nExample:\n\n```bash\nera_test_node --show-storage-logs=all --show-vm-details=all --show-gas-details=all run\n```\n\n## \ud83d\udcb0 Using Rich Wallets\n\nFor testing and development purposes, the `era-test-node` comes pre-configured with a set of 'rich' wallets. These wallets are loaded with test funds, allowing you to simulate transactions and interactions without the need for real assets.\n\nHere's a list of the available rich wallets:\n\n| Account Address                              | Private Key                                                          |\n| -------------------------------------------- | -------------------------------------------------------------------- |\n| `0x36615Cf349d7F6344891B1e7CA7C72883F5dc049` | `0x7726827caac94a7f9e1b160f7ea819f172f7b6f9d2a97f992c38edeab82d4110` |\n| `0xa61464658AfeAf65CccaaFD3a512b69A83B77618` | `0xac1e735be8536c6534bb4f17f06f6afc73b2b5ba84ac2cfb12f7461b20c0bbe3` |\n| `0x0D43eB5B8a47bA8900d84AA36656c92024e9772e` | `0xd293c684d884d56f8d6abd64fc76757d3664904e309a0645baf8522ab6366d9e` |\n| `0xA13c10C0D5bd6f79041B9835c63f91de35A15883` | `0x850683b40d4a740aa6e745f889a6fdc8327be76e122f5aba645a5b02d0248db8` |\n| `0x8002cD98Cfb563492A6fB3E7C8243b7B9Ad4cc92` | `0xf12e28c0eb1ef4ff90478f6805b68d63737b7f33abfa091601140805da450d93` |\n| `0x4F9133D1d3F50011A6859807C837bdCB31Aaab13` | `0xe667e57a9b8aaa6709e51ff7d093f1c5b73b63f9987e4ab4aa9a5c699e024ee8` |\n| `0xbd29A1B981925B94eEc5c4F1125AF02a2Ec4d1cA` | `0x28a574ab2de8a00364d5dd4b07c4f2f574ef7fcc2a86a197f65abaec836d1959` |\n| `0xedB6F5B4aab3dD95C7806Af42881FF12BE7e9daa` | `0x74d8b3a188f7260f67698eb44da07397a298df5427df681ef68c45b34b61f998` |\n| `0xe706e60ab5Dc512C36A4646D719b889F398cbBcB` | `0xbe79721778b48bcc679b78edac0ce48306a8578186ffcb9f2ee455ae6efeace1` |\n| `0xE90E12261CCb0F3F7976Ae611A29e84a6A85f424` | `0x3eb15da85647edd9a1159a4a13b9e7c56877c4eb33f614546d4db06a51868b1c` |\n\nFeel free to use these wallets in your tests, but remember, they are for development purposes only and should not be used in production or with real assets.\n\n## \ud83d\udd27 Supported APIs\n\nSee our list of [Supported APIs here](SUPPORTED_APIS.md).\n\n## \ud83e\udd16 CI/CD Testing with GitHub Actions\n\nA GitHub Action is available for integrating `era-test-node` into your CI/CD environments. This action offers high configurability and streamlines the process of testing your applications in an automated way.\n\nYou can find this GitHub Action in the marketplace [here](https://github.com/marketplace/actions/era-test-node-action).\n\n### \ud83d\udcdd Example Usage\n\nBelow is an example `yaml` configuration to use the `era-test-node` GitHub Action in your workflow:\n\n```yml\nname: Run Era Test Node Action\n\non:\n  push:\n    branches: [ main ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v2\n\n    - name: Run Era Test Node\n      uses: dutterbutter/era-test-node-action@latest\n```\n\n## \ud83e\udd1d Contributing\n\nWe welcome contributions from the community! If you're interested in contributing to the zkSync Era In-Memory Node, please take a look at our [CONTRIBUTING.md](./.github/CONTRIBUTING.md) for guidelines and details on the process.\n\nThank you for making zkSync Era In-Memory Node better! \ud83d\ude4c\n", "release_dates": ["2024-02-26T14:25:59Z", "2024-02-08T19:21:31Z", "2024-01-03T15:49:31Z", "2023-12-20T18:27:56Z", "2023-12-18T15:22:12Z", "2023-12-07T09:50:18Z", "2023-11-29T19:23:33Z", "2023-11-10T14:49:17Z", "2023-11-01T16:41:29Z", "2023-10-27T12:07:12Z", "2023-10-27T08:21:57Z", "2023-10-20T11:17:45Z", "2023-10-12T11:26:09Z", "2023-10-03T14:24:17Z", "2023-09-26T16:24:06Z", "2023-09-19T16:39:20Z", "2023-09-14T15:15:18Z", "2023-09-06T20:04:41Z", "2023-08-18T10:19:16Z", "2023-08-11T14:57:34Z"]}, {"name": "era-tutorial-examples", "description": "[DEPRECATED ]Full examples for tutorials in the zkSync Era documentation. Visit: https://github.com/matter-labs/tutorials", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# [DEPRECATED] zkSync Era Tutorial Examples Repo\n\n\u26a0\ufe0f This repository is deprecated and used to contain repositories of examples that interact with the zkSync Era network. For the actual examples repository please [follow this link](https://github.com/matter-labs/tutorials).\n", "release_dates": []}, {"name": "era-zkEVM-assembly", "description": "The zkEVM assembly tools", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkEVM Assembler\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync 2.0 is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync 2.0 also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\nThis repo contains the zkEVM assembly tools.\n\n## License\n\nThe zkSync 2.0 prover is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-zkevm_circuits", "description": null, "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# CPU/GPU Based Prover for zkSync Era\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## License\n\nThe zkSync Era prover is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n\n", "release_dates": []}, {"name": "era-zkevm_opcode_defs", "description": "Definitions of zkEVM opcodes (primary dependency for all other repos)", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# CPU/GPU Based Prover for zkSync Era\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## License\n\nThe zkSync Era prover is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-zkevm_tester", "description": "Assembly runner for zkEVM testing", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: A ZK Rollup For Scaling Ethereum\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## License\n\nzkSync Era is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n\n", "release_dates": []}, {"name": "era-zkevm_test_harness", "description": "Compare in-circuit and out-of-circuit VMs", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: A ZK Rollup For Scaling Ethereum\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n# How to use\n\nThis repo contains a mixture of witness generation harness (that runs block's code and produces circuit-specific witness parts) and basic examples of full block proof workflow execution, that is:\n- create a necessary number of circuits of each unique basic type (so called scheduling)\n- aggreagte proofs over them\n- run the final state \"scheduler\" circuit that verifies logical validity of scheduling (feeding outputs to inputs) and attest that aggregation is a result of recursive verification of the scheduled sequence\n\nIt's easy to run\n\nGet some modern Rust version (at least that supports Rust 2021 and const generics, but usually latest nightly is also a good option) and run\n\n```\ncargo test basic_test  --release -- --nocapture\n```\n\nIt may be a little verbose, but it's a full end to end test that:\n- sets up basic environment - empty state tree with added \"system\" level contracts \n- creates some dummy information about previous state of the chain (only state root is necessary)\n- runs a contract from [https://github.com/vladbochok/test-contract](https://github.com/vladbochok/test-contract) as from address 0x8001 that is a contract call without a calldata and particular meaning, but touches the most interesting parts of the system: external calls, reverts, precompiles, storage access, events, L2 to L1 messages\n- produces witness\n- makes as many circuits as needed given some (arbitrary) set of capacity parameters of the form \"principal operations per circuit of type T\"\n- generated verification keys for both basic circuits, recursive aggregation circuits, and \"scheduler\"\n- makes proofs of every stage - basic circuits -> aggregation (leafs and nodes) -> scheduler\n- each proof is verified against the corresponding verification key on creation\n\nOne can see a lot of `.json` files in the `setup` and `test_proofs` folders. Those are all the intermediate proofs, and if proof exists then example script will skip it's recomputation (whether it's a proof or verification key). So to run the full workflow one can remove all of those, or some of those.\n\n### Running regeneration of setup files\nWill regenerate setup parameters (geometry, verification keys, finalization hints and padding proofs)\n```shell\ncargo run --release --bin geometry_config_generator\ncargo test --release test_run_create_base_layer_vks_and_proofs\ncargo test --release test_run_create_recursion_layer_vks_and_proofs\n```\n\n## License\n\nzkSync Era is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-zk_evm", "description": "Out-of-circuit zkEVM implementation", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: A ZK Rollup For Scaling Ethereum\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## License\n\nzkSync Era is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": []}, {"name": "era-zk_evm_abstractions", "description": null, "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# CPU/GPU Based Prover for zkSync Era\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## License\n\nThe zkSync Era prover is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n\n", "release_dates": []}, {"name": "eravm-spec", "description": null, "language": "Coq", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: Formal Specification of EraVM instruction set\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security\nor decentralization. As it's EVM-compatible (with Solidity/Vyper), 99% of Ethereum projects can redeploy without\nneeding to refactor or re-audit any code. zkSync Era also uses an LLVM-based compiler that will eventually enable\ndevelopers to write smart contracts in popular languages such as C++ and Rust.\n\nThis repository contains the formal specification for EraVM instruction set written in Coq, along with some artifacts generated from it.\n\n## License\n\nThis library is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n\n## Disclaimer\n\nzkSync Era has been through extensive testing and audits, and although it is live, it is still in alpha state and\nwill undergo further audits and bug bounty programs. We would love to hear our community's thoughts and suggestions\nabout it!\nIt's important to note that forking it now could potentially lead to missing important\nsecurity updates, critical features, and performance improvements.\n\n\n\n# Setting up development environment\n\n1. Install `make`.\n2. Install Coq and required libraries:\n\n  - `coq-ext-lib`\n  - `coq-mathcomp-ssreflect`\n  - `coq-record-update`\n\n   We recommend [Opam](https://opam.ocaml.org/) (your packet manager probably has `opam` package).\n\n   The following will pin the packages to specific versions that we are using at\n   the time of development, preventing them from automatically updating via\n   `opam upgrade`.\n\n   ```\n   opam pin add coq 8.17.0\n   opam pin add coq-ext-lib 0.11.8\n   opam pin add coq-mathcomp-ssreflect 1.17.0\n   opam pin add coq-record-update 0.3.2\n   ```\n\n3. We consider the root directory of the project as the repository root.\n   Execute this command in the project root:\n\n   ```\n   coq_makefile -f _CoqProject -o CoqMakefile\n   ```\n\n   This will create a file `CoqMakefile` for `make`.\n\n# Build spec and proofs\n\n\n```\nmake -f CoqMakefile -j<number of threads> all\n```\n\n\n# Generating docs\n\nGenerating docs is cumbersome to setup ATM because we use a custom script and a\ncustom version of `coqdoc` to fully support Markdown in documentation blocks.\n\n1. Prepare the environment once\n   - install Pandoc\n   - install Python 3.6+\n   - install `pypandoc` by executing `python3 -m pip install pypandoc`\n   - clone and build `https://github.com/sayon/coq`\n   - setup the variables in `build-docs.sh`\n     + `COQDOC` -- point it to `coqdoc` that you have built from `https://github.com/sayon/coq`\n       The executable should be located in `_build/install/default/bin/coqdoc` after successful build.\n     + `COQLIB`. Put there the path to the directory with subdirectories `theories` and `user-contrib`. Usually `~/.opam/<ocaml-switch-name>/lib/coq/`.\n\n2. Generate docs with `./build-docs.sh`\n", "release_dates": []}, {"name": "ETHLisbon-2022-hackathon", "description": "Information about MatterLabs bounty program for ETH Lisbon 2022 hackathon", "language": "TypeScript", "license": null, "readme": "# ETHLisbon 2022 Hackathon\n\n![](./zksync-head-pt.png)\n\nIn this repository you'll find all the information you need to participate in the zkSync track of ETHLisbon 2022 Hackathon.\n\n## Dates\n\nETH Lisbon kicks-off on October 28th. Although the official hackathon ends on 30th October, we've decided to extend the submission period a few more days. Teams an individuals will be allowed to send submissions (following [the process detailed below](#how-to-send-your-submission)) until the end of November 4th. Winners will be announced on November 11th in our Discord and Twitter.\n\n## Who can participate?\n\nAnyone can participate, no matter if you're attending ETHLisbon in person or not. We'll create a **specific channel in [our Discord server](https://discord.com/invite/px2aR7w)** to talk and help buidlers that decide to participate online.\n\n## Prizes\n\nThe top three projects will receive a prize amount of $1000 for a total of $3000 in bounties.\n\n## Bounty\n\nWe're asking developers to work with one of the coolest features of zkSync v2: **account abstraction**.\n\nWe'll reward the best / most creative uses of this feature and we're giving you total freedom so you can focus on social recovery, multicalls, paymasters or whatever you want!\n\n### Resources\n\nHere is a list of resources about account abstraction:\n\n- zkSync v2 account abstraction support: [zkSync docs](https://v2-docs.zksync.io/dev/developer-guides/aa.html)\n- WTF is account abstraction @ Argent blog: [part 1](https://www.argent.xyz/blog/wtf-is-account-abstraction/), [part 2](https://www.argent.xyz/blog/part-2-wtf-is-account-abstraction/) and [part 3](https://www.argent.xyz/blog/part-3-wtf-is-account-abstraction/)\n- Creating a multisig wallet tutorial: [zkSync docs](https://v2-docs.zksync.io/dev/tutorials/custom-aa-tutorial.html)\n- Paymasters: [zkSync docs](https://v2-docs.zksync.io/dev/developer-guides/aa.html#paymasters)\n\n## How to send your submission\n\nAs requested by ETHLisbon, all projects should be submitted to [Taikai](https://taikai.network/ethlisbon/hackathons/ethlisbon-2022/projects?category=zkSync%20-%20Account%20Abstraction&filter_by=finalists).\n\nTo send a submissions after 31st October (and before 5th November), just fork this repo and create a PR with your changes. You should create your own subfolder inside `/submissions` (make sure to give it a unique name). Your submissions should contain the following files and information:\n\n- `README.md`: with a description of your project, requirements, installation guide, and how to run it. You can also record a video and upload to Youtube. Although that's optional, it'll be a nice touch \ud83d\ude09\n- `About.md`: include here information about yourself and how to contact you.\n- `/code`: create a subfolder with all the code of your submissions.\n\n**We will aggregate [all submissions from Taikai](https://taikai.network/ethlisbon/hackathons/ethlisbon-2022/projects?category=zkSync%20-%20Account%20Abstraction) and the repository PRs.**\n\n## FAQs\n\n> Do I have to provide my personal details?\n\nNo, just enough information to contact you. It could be an email address, Twitter handle, Telegram, etc.\n\n> Can I choose to get paid in crypto?\n\nYes. We can pay you in crypto via zkSync.\n\n> Will there be any support from Matter Labs during the hackathon?\n\nWe will create a specific channel in our [Discord server](https://discord.com/invite/px2aR7w) where all teams can reach out and ask questions.\n\n> Who and how will you choose the winners?\n\nMultiple members from different teams inside Matter Labs will vote and choose the projects they like most. The top three will be the winners.\n\n### Disclaimer\n\n**This document is a work in progress so changes may be applied**\n", "release_dates": []}, {"name": "example", "description": null, "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# example-public\n\n# DISCLAIMER\n\nzkSync Era is has been through lots of testing and audits. Although it is live, it is still in alpha state and will go though more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it, and it is important to state that forking it now can potentially lead to missing important security updates and performance improvements.\n", "release_dates": []}, {"name": "exploring-hack", "description": "This repository welcomes the Milestone 2 for the BuidlBox Hackathon", "language": null, "license": null, "readme": "## Exploring Phase\n\nThe second phase is about **Exploring via collaboration;** the attendees will team up and start working on their projects, but before moving forward. During this phase, the attendees will be able to collaborate and go through a ***todo*** list for you to put into action the amazing information you\u2019ve learned. This step is about Exploring, and the ***todo*** list includes:\n\nWe invite all the attendees of the **zkSync Hack Series** to go through the checklist below, in order to be eligible for the \ud83e\uddd1\u200d\ud83d\ude80**Building**\ud83e\uddd1\u200d\ud83d\ude80 period.\n\n- [ ]  Add Funds to zkSync with MetaMask\n- [ ]  Transfer Funds on zkSync\n- [ ]  Transfer Funds to Ethereum\n- [ ]  Get Goerli test ETH and bridge funds to zkSync\n- [ ]  Install zksync-cli and create a project\n- [ ]  Deploy Greeter contract\n- [ ]  Verify Contract in the explorer\n- [ ]  Copy the Contract and paste it into the Milestone check on BuidlBox\n", "release_dates": []}, {"name": "ff", "description": "Traits and utilities for working with finite fields", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# \"FF community edition\"\n\nThis library is community maintained fork of the original `ff` library by Sean Bowe. Name of the library is changed to allow publishing to the `crates.io`\n\n## Original ff\n\n`ff` is a finite field library written in pure Rust, with no `unsafe{}` code.\n\n## Disclaimers\n\n* This library does not provide constant-time guarantees.\n\n## Usage\n\nAdd the `ff_ce` crate to your `Cargo.toml`:\n\n```toml\n[dependencies]\nff_ce = \"0.6\"\n```\n\nThe `ff_ce` crate contains `Field`, `PrimeField`, `PrimeFieldRepr` and `SqrtField` traits. See the **[documentation](https://docs.rs/ff/0.4.0/ff/)** for more.\n\n### #![derive(PrimeField)]\n\nIf you need an implementation of a prime field, this library also provides a procedural macro that will expand into an efficient implementation of a prime field when supplied with the modulus. `PrimeFieldGenerator` must be an element of Fp of p-1 order, that is also quadratic nonresidue.\n\nFirst, enable the `derive` crate feature:\n\n```toml\n[dependencies]\nff = { ..., features = [\"derive\"] }\n```\n\nAnd then use the macro like so:\n\n```rust\nextern crate rand;\n#[macro_use]\nextern crate ff_ce;\n\n#[derive(PrimeField)]\n#[PrimeFieldModulus = \"52435875175126190479447740508185965837690552500527637822603658699938581184513\"]\n#[PrimeFieldGenerator = \"7\"]\nstruct Fp(FpRepr);\n```\n\nAnd that's it! `Fp` now implements `Field` and `PrimeField`. `Fp` will also implement `SqrtField` if supported. The library implements `FpRepr` itself and derives `PrimeFieldRepr` for it.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": ["2019-03-04T16:32:29Z"]}, {"name": "format-release-please-for-slack-action", "description": null, "language": "JavaScript", "license": null, "readme": "# Format release please for Slack\n\nFormat output from Release Please and send it to Slack\n\n## ENV\n\n### `RELEASE_PLEASE_OUTPUT`\n\n**REQUEIRED**  Release please output\n\n## Inputs\n\n### `slack-url`\n\n**REQUIRED**  The Slack Incoming Webhook\n\n### `slack-channel`\n\nThe name of the channel you want to post, by default will post in the channel that was setup in the webhook creation\n  \n### `slack-username`\n\nThe name of the sender of the message. ie, \"GitHubAction\"\n  \n### `slack-icon`\n\nUser/Bot icon shown with Slack message\n\n## Example usage\n\n```yaml\nuses: Deniallugo/format-release-for-mm-action@v1.0\nwith:\n  release-please-output: ${{ steps.release.outputs }}\n  slack-webhook-url: ${{ secrets.SLACK_WEBHOOK }}\n```\n", "release_dates": ["2023-09-13T07:08:55Z", "2023-08-09T15:16:32Z", "2023-08-07T16:09:08Z"]}, {"name": "foundry", "description": "Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<img src=\".github/logo.png\" alt=\"Foundry logo\" align=\"right\" width=\"120\" />\n\n## Foundry\n\n![Github Actions][gha-badge] [![Telegram Chat][tg-badge]][tg-url] [![Telegram Support][tg-support-badge]][tg-support-url]\n\n[gha-badge]: https://img.shields.io/github/actions/workflow/status/foundry-rs/foundry/test.yml?branch=master\n[tg-badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=chat&style=flat-square&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ffoundry_rs\n[tg-url]: https://t.me/foundry_rs\n[tg-support-badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=support&style=flat-square&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ffoundry_support\n[tg-support-url]: https://t.me/foundry_support\n\n**Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.**\n\nFoundry consists of:\n\n-   [**Forge**](./forge): Ethereum testing framework (like Truffle, Hardhat and DappTools).\n-   [**Cast**](./cast): Swiss army knife for interacting with EVM smart contracts, sending transactions and getting chain data.\n-   [**Anvil**](./anvil): Local Ethereum node, akin to Ganache, Hardhat Network.\n-   [**Chisel**](./chisel): Fast, utilitarian, and verbose solidity REPL.\n\n**Need help getting started with Foundry? Read the [\ud83d\udcd6 Foundry Book][foundry-book] (WIP)!**\n\n![Demo](.github/demo.gif)\n\n## Installation\n\nSee the [installation guide](https://book.getfoundry.sh/getting-started/installation) in the book.\n\nIf you're experiencing any issues while installing, check out [Getting Help](#getting-help) and the [FAQ](https://book.getfoundry.sh/faq).\n\n## Forge\n\n### Features\n\n-   **Fast & flexible compilation pipeline**\n    -   Automatic Solidity compiler version detection & installation (under `~/.svm`)\n    -   **Incremental compilation & caching**: Only changed files are re-compiled\n    -   Parallel compilation\n    -   Non-standard directory structures support (e.g. [Hardhat repos](https://twitter.com/gakonst/status/1461289225337421829))\n-   **Tests are written in Solidity** (like in DappTools)\n-   **Fast fuzz testing** with shrinking of inputs & printing of counter-examples\n-   **Fast remote RPC forking mode**, leveraging Rust's async infrastructure like tokio\n-   **Flexible debug logging**\n    -   DappTools-style, using `DsTest`'s emitted logs\n    -   Hardhat-style, using the popular `console.sol` contract\n-   **Portable (5-10MB) & easy to install** without requiring Nix or any other package manager\n-   **Fast CI** with the [Foundry GitHub action][foundry-gha].\n\n### How Fast?\n\nForge is quite fast at both compiling (leveraging [ethers-solc][ethers-solc]) and testing.\n\nSee the benchmarks below. More benchmarks can be found in the [v0.2.0 announcement post][benchmark-post] and in the [Convex Shutdown Simulation][convex] repository.\n\n**Testing Benchmarks**\n\n| Project                            | Forge | DappTools | Speedup |\n| ---------------------------------- | ----- | --------- | ------- |\n| [transmissions11/solmate][solmate] | 2.8s  | 6m34s     | 140x    |\n| [reflexer-labs/geb][geb]           | 0.4s  | 23s       | 57.5x   |\n| [Rari-Capital/vaults][vaults]      | 0.28s | 6.5s      | 23x     |\n\n_Note: In the above benchmarks, compilation was always skipped_\n\n**Compilation Benchmarks**\n\n<img alt=\"Compilation benchmarks\" src=\".github/compilation-benchmark.png\" width=\"693px\" />\n\n**Takeaway: Forge compilation is consistently faster by a factor of 1.7-11.3x, depending on the amount of caching involved.**\n\n## Cast\n\nCast is a swiss army knife for interacting with Ethereum applications from the command line.\n\nMore documentation can be found in the [cast package](./cast).\n\n## Configuration\n\n### Using `foundry.toml`\n\nFoundry is designed to be very configurable. You can configure Foundry using a file called [`foundry.toml`](./config) in the root of your project, or any other parent directory. See [config package](./config/README.md#all-options) for all available options.\n\nConfiguration can be arbitrarily namespaced by profiles. The default profile is named `default` (see [\"Default Profile\"](./config/README.md#default-profile)).\n\nYou can select another profile using the `FOUNDRY_PROFILE` environment variable. You can also override parts of your configuration using `FOUNDRY_` or `DAPP_` prefixed environment variables, like `FOUNDRY_SRC`.\n\n`forge init` creates a basic, extendable `foundry.toml` file.\n\nTo see your current configuration, run `forge config`. To see only basic options (as set with `forge init`), run `forge config --basic`. This can be used to create a new `foundry.toml` file with `forge config --basic > foundry.toml`.\n\nBy default `forge config` shows the currently selected foundry profile and its values. It also accepts the same arguments as `forge build`.\n\n### DappTools Compatibility\n\nYou can re-use your `.dapprc` environment variables by running `source .dapprc` before using a Foundry tool.\n\n### Additional Configuration\n\nYou can find additional setup and configurations guides in the [Foundry Book][foundry-book]:\n\n-   [Setting up VSCode][vscode-setup]\n-   [Shell autocompletions][shell-setup]\n\n## Contributing\n\nSee our [contributing guidelines](./CONTRIBUTING.md).\n\n## Getting Help\n\nFirst, see if the answer to your question can be found in [book][foundry-book], or in the relevant crate.\n\nIf the answer is not there:\n\n-   Join the [support Telegram][tg-support-url] to get help, or\n-   Open a [discussion](https://github.com/foundry-rs/foundry/discussions/new) with your question, or\n-   Open an issue with [the bug](https://github.com/foundry-rs/foundry/issues/new)\n\nIf you want to contribute, or follow along with contributor discussion, you can use our [main telegram](https://t.me/foundry_rs) to chat with us about the development of Foundry!\n\n## Acknowledgements\n\n-   Foundry is a clean-room rewrite of the testing framework [DappTools](https://github.com/dapphub/dapptools). None of this would have been possible without the DappHub team's work over the years.\n-   [Matthias Seitz](https://twitter.com/mattsse_): Created [ethers-solc](https://github.com/gakonst/ethers-rs/tree/master/ethers-solc/) which is the backbone of our compilation pipeline, as well as countless contributions to ethers, in particular the `abigen` macros.\n-   [Rohit Narurkar](https://twitter.com/rohitnarurkar): Created the Rust Solidity version manager [svm-rs](https://github.com/roynalnaruto/svm-rs) which we use to auto-detect and manage multiple Solidity versions.\n-   [Brock Elmore](https://twitter.com/brockjelmore): For extending the VM's cheatcodes and implementing [structured call tracing](https://github.com/foundry-rs/foundry/pull/192), a critical feature for debugging smart contract calls.\n-   All the other [contributors](https://github.com/foundry-rs/foundry/graphs/contributors) to the [ethers-rs](https://github.com/gakonst/ethers-rs) & [foundry](https://github.com/foundry-rs/foundry) repositories and chatrooms.\n\n[foundry-book]: https://book.getfoundry.sh\n[foundry-gha]: https://github.com/foundry-rs/foundry-toolchain\n[ethers-solc]: https://github.com/gakonst/ethers-rs/tree/master/ethers-solc/\n[solmate]: https://github.com/transmissions11/solmate/\n[geb]: https://github.com/reflexer-labs/geb\n[vaults]: https://github.com/rari-capital/vaults\n[benchmark-post]: https://www.paradigm.xyz/2022/03/foundry-02#blazing-fast-compilation--testing\n[convex]: https://github.com/mds1/convex-shutdown-simulation\n[vscode-setup]: https://book.getfoundry.sh/config/vscode.html\n[shell-setup]: https://book.getfoundry.sh/config/shell-autocompletion.html\n", "release_dates": []}, {"name": "foundry-zksync", "description": "Fork of Foundry tailored for zkSync environment", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Foundry with zkSync Era v0.1-alpha\n\nThis repository provides [Foundry](https://github.com/foundry-rs/foundry) functionality in Solidity for compiling, deploying, testing, and interacting with smart contracts on **zkSync Era**. \n\n**What is foundry?**\n\nFoundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.\n\nFoundry consists of:\n\n- **Forge:** Ethereum testing framework (like Truffle, Hardhat and DappTools).\n- **Cast:** Swiss army knife for interacting with EVM smart contracts, sending transactions and getting chain data.\n- **Anvil:** Local Ethereum node, akin to Ganache, Hardhat Network.\n- **Chisel:** Fast, utilitarian, and verbose solidity REPL.\n\nNeed help getting started with Foundry? Read the \ud83d\udcd6 [Foundry Book](https://book.getfoundry.sh/) (WIP)!\n\n### Foundry-zkSync adds:\n\n- **zkForge:** zkSync testing framework (like Hardhat and DappTools).\n- **zkCast:** Swiss army knife for interacting with zkEVM smart contracts, sending transactions and getting chain data.\n\nNeed help getting started with **Foundry-zkSync**? Read the \ud83d\udcd6 [Usage Guides](./docs/dev/zksync/) (WIP)!\n\n## \u26a0\ufe0f Caution\n\nPlease note that `foundry-zksync` is still in its **alpha** stage. Some features might not be fully supported yet and may not work as intended. However, it is open-sourced, and contributions are welcome!\n\n## \ud83d\udcca Features & Limitations\n\n### Features\n\n`Foundry-zksync` offers a set of features designed to work with zkSync Era, providing a comprehensive toolkit for smart contract deployment and interaction:\n\n- **Smart Contract Deployment**: Easily deploy smart contracts to zkSync Era mainnet, testnet, or a local test node.\n- **Asset Bridging**: Bridge assets between L1 and L2, facilitating seamless transactions across layers.\n- **Contract Interaction**: Call and send transactions to deployed contracts on zkSync Era testnet or local test node.\n- **Solidity Testing**: Write tests in Solidity, similar to DappTools, for a familiar testing environment.\n- **Fuzz Testing**: Benefit from fuzz testing, complete with shrinking of inputs and printing of counter-examples.\n- **Remote RPC Forking**: Utilize remote RPC forking mode, leveraging Rust's asynchronous infrastructure like tokio.\n- **Flexible Debug Logging**: Choose your debugging style:\n  - DappTools-style: Utilize DsTest's emitted logs for debugging.\n  - Hardhat-style: Leverage the popular console.sol contract.\n- **Configurable Compiler Options**: Tailor compiler settings to your needs, including LLVM optimization modes.\n\n### Limitations\n\nWhile `foundry-zksync` is **alpha stage**, there are some limitations to be aware of:\n\n- **Cheat Codes Support**: Not all cheat codes are fully supported. [View the list of supported cheat codes](./SUPPORTED_CHEATCODES.md).\n- **Compile Time**: Some users may experience slower compile times.\n- **Compiling Libraries**: Compiling non-inlinable libraries requires deployment and adding to configuration. For more information please refer to [official docs](https://era.zksync.io/docs/tools/hardhat/compiling-libraries.html).\n\n    ```\n    libraries = [\n        \"src/MyLibrary.sol:MyLibrary:0xfD88CeE74f7D78697775aBDAE53f9Da1559728E4\"\n    ]\n    ```\n- **Create2 Address Derivation**: There are differences in Create2 Address derivation compared to Ethereum. [Read the details](https://era.zksync.io/docs/reference/architecture/differences-with-ethereum.html#create-create2).\n- **Specific Foundry Features**: Currently features such as `--gas-report` may not work as intended. We are actively working on providing support for these feature types.\n\nFor the most effective use of our library, we recommend familiarizing yourself with these features and limitations. \n\n## \ud83d\udcdd Prerequisites\n\n- Install Rust with the following command:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n```\n\nThe current implementation makes use of `nightly-2023-09-30`. Please be sure to have the proper toolchain installed:\n\n```\n# rustup install nightly-2023-09-30-<YOUR-TARGET>\nrustup install nightly-2023-09-30-aarch64-apple-darwin\n```\n\n## \ud83d\udcbe Installation\n\nEach tool within our suite can be installed individually, or you can install the entire suite at once.\n\n### Installing `zkforge` \ud83d\udee0\ufe0f\n\nRun the following command:\n\n```bash\ncargo install --path ./crates/zkforge --profile local --force --locked\n```\n\nThis installs `zkforge` to `~/.cargo/bin`, making it available as an executable.\n\n### Installing `zkcast` \ud83d\udce1\n\nRun the following command:\n\n```bash\ncargo install --path ./crates/zkcast --profile local --force --locked\n```\n\nThis installs `zkcast` to `~/.cargo/bin`, allowing it to be used as an executable.\n\n### Installing the Entire Suite \ud83d\udce6\n\nTo install all the tools in the suite:\n\n```bash\ncargo build --release\n```\n\n## Quickstart \n\nRun:\n``` \nzkforge init hello_foundry\n```\n\nLet's check out what zkforge generated for us:\n\n```\n$ cd hello_foundry\n$ tree . -d -L 1\n.\n\u251c\u2500\u2500 abis\n\u251c\u2500\u2500 broadcast\n\u251c\u2500\u2500 interfaces\n\u251c\u2500\u2500 lib\n\u251c\u2500\u2500 script\n\u251c\u2500\u2500 src\n\u251c\u2500\u2500 test\n```\n\n#### Compiling contracts\n\nWe can build the project with zkforge zkbuild:\n```\n$ zkforge zkbuild\nCompiling smart contracts...\nCompiled Successfully\n```\n\n#### Running Tests\n\nYou can run the tests using `zkforge test`. \n\nThe command and its expected output are shown below:\n\n```bash\n$ zkforge test\n\nRunning 2 tests for Counter.t.sol:CounterTest\n[PASS] testFuzz_SetNumber(uint256) (runs: 256, \u03bc: 9223372034707527035, ~: 9223372034707527076)\n[PASS] test_Increment() (gas: 9223372034707527339)\nTest result: ok. 2 passed; 0 failed; 0 skipped; finished in 5.15s\n\nRan 1 test suites: 2 tests passed, 0 failed, 0 skipped (2 total tests)\n```\n\n## Configuration\n\n### Using `foundry.toml`\n\nFoundry is designed to be very configurable. You can configure Foundry using a file called [`foundry.toml`](./crates/config) in the root of your project, or any other parent directory. See [config package](./crates/config/README.md#all-options) for all available options.\n\nConfiguration can be arbitrarily namespaced by profiles. The default profile is named `default` (see [\"Default Profile\"](./crates/config/README.md#default-profile)).\n\nYou can select another profile using the `FOUNDRY_PROFILE` environment variable. You can also override parts of your configuration using `FOUNDRY_` or `DAPP_` prefixed environment variables, like `FOUNDRY_SRC`.\n\n`zkforge init` creates a basic, extendable `foundry.toml` file.\n\nTo see your current configuration, run `zkforge config`. To see only basic options (as set with `zkforge init`), run `zkforge config --basic`. This can be used to create a new `foundry.toml` file with `zkforge config --basic > foundry.toml`.\n\nBy default `zkforge config` shows the currently selected foundry profile and its values. It also accepts the same arguments as `zkforge build`. An example `foundry.toml` for zkSync with zksolc configurations may look like:\n\n```\n[profile.default]\nsrc = 'src'\nout = 'out'\nlibs = ['lib']\n\n[profile.zksync]\nsrc = 'src'\nlibs = ['lib']\nfallback_oz = true\nmode = \"3\"\n```\n\n### Additional Configuration\n\nYou can find additional setup and configurations guides in the [Foundry Book][foundry-book]:\n\n-   [Setting up VSCode][vscode-setup]\n-   [Shell autocompletions][shell-setup]\n\n## Contributing\n\nSee our [contributing guidelines](./CONTRIBUTING.md).\n\n## Troubleshooting\n\n### Verify arguments\n\nMake sure that:\n\n* You are using zksync specific methods (`zkcreate` not `create`, `zksend` not `send`).\n* You set the correct `--rpc-url`.\n* You have the proper contract address - the bytecodes in zkSync Era are different to in EVM - so the resulting contracts will be deployed at different addresses.\n\n### 'Method not found' when calling 'send'\n\nIf you get errors like `(code: -32601, message: Method not found, data: None)` - you are probably using a `send` method instead of `zksend`.\n\n## Acknowledgements\n\n-   Foundry is a clean-room rewrite of the testing framework [DappTools](https://github.com/dapphub/dapptools). None of this would have been possible without the DappHub team's work over the years.\n-   [Matthias Seitz](https://twitter.com/mattsse_): Created [ethers-solc](https://github.com/gakonst/ethers-rs/tree/master/ethers-solc/) which is the backbone of our compilation pipeline, as well as countless contributions to ethers, in particular the `abigen` macros.\n-   [Rohit Narurkar](https://twitter.com/rohitnarurkar): Created the Rust Solidity version manager [svm-rs](https://github.com/roynalnaruto/svm-rs) which we use to auto-detect and manage multiple Solidity versions.\n-   [Brock Elmore](https://twitter.com/brockjelmore): For extending the VM's cheatcodes and implementing [structured call tracing](https://github.com/foundry-rs/foundry/pull/192), a critical feature for debugging smart contract calls.\n-   All the other [contributors](https://github.com/foundry-rs/foundry/graphs/contributors) to the [ethers-rs](https://github.com/gakonst/ethers-rs) & [foundry](https://github.com/foundry-rs/foundry) repositories and chatrooms.\n\n### Acknowledgments - foundry-zksync\n- [Moonsong Labs](https://moonsonglabs.com/): Implemented [era-cheatcodes](./crates/era-cheatcodes/), and resolved a number of different challenges to enable zkSync support. \n\n[foundry-book]: https://book.getfoundry.sh\n[foundry-gha]: https://github.com/foundry-rs/foundry-toolchain\n[ethers-solc]: https://github.com/gakonst/ethers-rs/tree/master/ethers-solc/\n[vscode-setup]: https://book.getfoundry.sh/config/vscode.html\n[shell-setup]: https://book.getfoundry.sh/config/shell-autocompletion.html", "release_dates": ["2024-02-08T00:36:14Z"]}, {"name": "franklin-crypto", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# franklin-crypto: Gadget library for PLONK/Plookup\n\nThis repository contains only the gadgets for PLONK proofs system (to be used together with `dev` branch of our Bellman repo) including embedded curve/EcDSA support, RNS based field math, non-algebraic hashes via lookup tables, and base primitives.\n\n## Security Warnings\n\nThis library is under development and has not been reviewed.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": ["2020-04-09T10:31:32Z"]}, {"name": "gated-nft-tutorial", "description": null, "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# gated-nft-tutorial-starter \ud83d\udca5\ud83c\udf89\n\nThis repository serves as a starter template for developing a dApp that interacts with a \ngated NFT paymaster contract.\n\n## Official Links \ud83d\udd17\n\nFor more information and support, visit our official channels:\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n\nJump in, and let's make the most of paymasters together! \ud83d\ude80\n", "release_dates": []}, {"name": "gated-nft-tutorial-starter", "description": null, "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# gated-nft-tutorial-starter \ud83d\udca5\ud83c\udf89\n\nThis repository serves as a starter template for developing a dApp that interacts with a \ngated NFT paymaster contract.\n\n## Official Links \ud83d\udd17\n\nFor more information and support, visit our official channels:\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n\nJump in, and let's make the most of paymasters together! \ud83d\ude80\n", "release_dates": []}, {"name": "github-workflows", "description": "Dysnix Github Actions reusable workflows", "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "githubot", "description": "Github API access, tailored for Hubot", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": []}, {"name": "greeter-tutorial-starter", "description": null, "language": "Vue", "license": null, "readme": "# greeter-front-end\n\n## Project setup\n```\nyarn install\n```\n\n### Compiles and hot-reloads for development\n```\nyarn serve\n```\n\n### Compiles and minifies for production\n```\nyarn build\n```\n\n### Lints and fixes files\n```\nyarn lint\n```\n\n### Customize configuration\nSee [Configuration Reference](https://cli.vuejs.org/config/).\n", "release_dates": []}, {"name": "hackathon-winner-projects", "description": "A list of all the projects submitted in all zksync hackathons.", "language": null, "license": null, "readme": "# zkSync hackathon submissions\n\nThis is a list of all projects submited during zkSync sponsored hackathons.\n\nTo add your project, just create a PR and add your project in the table below following the format.\n\n\n\n## List of projects\n\n**Ownership of these projects belongs to the correspondent team and contributors and its usage is limited by their respective license.**\n\n\n| Project name  | Description (280 chars max)      | Hackathon    | Keywords                       | Other info |\n| ------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------ | ------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [ZKSync Patron](https://github.com/pycckuu/zk-onboarding-service) | Making new user's onboarding free and flawless by allowing platform to cover their first transactional fees. Paymaster that can be use for Patrons to sponsor applications using the app contract address | ETH Lisbon 2022 \ud83e\udd47 | Paymaster | [Slides](https://docs.google.com/presentation/d/1V9PC0Q7O4xqM1YCN0C5m_ic3JBXsvfQe4C2tlQ0c718), [Demo](https://www.loom.com/share/a0be318076d644a6ab2bf12cb76ca074) |\n| [Testamint](https://github.com/joaoferreiro/Web3Testament) | Using AA to allow/deny users to access a wallet if a specific amount of days have passed since the original owner used the account | ETH Lisbon 2022 \ud83e\udd47 | Account Abstraction | [Slides](https://docs.google.com/presentation/d/18o1Ctz9G2MbwqAgNVbCzqBD8q8Jbo2FX3KBK5BQTiHo/edit?usp=sharing), [Demo](https://www.youtube.com/watch?v=p6L8OAakbDg) |\n| [Session Wallet](https://github.com/matter-labs/ETHLisbon-2022-hackathon/tree/main/submissions/session-wallet) | I created a wallet that can issue session keys. You give the issued session key to a trusted institution (e.g., a gaming company) to send transactions on your behalf. In other words, your wallet is temporarily under the control of that institution. However, you do not need to give them your private key, you just need to give them your session key. Of course, you can deactivate the session key. | ETH Lisbon 2022 \ud83e\udd47 | Account Abstraction |  |\n| [Proof of Meet (POM)](https://github.com/fibo/pom-eth-lisbon) | Proof of Meet is a social dApp to collect moments of interaction between two people on-chain. It\u2019s a trustless way to save shared memories and build up social credibility in a decentralized society. | ETH Lisbon 2022 |  Account Abstraction, multisig | [Slides](https://docs.google.com/presentation/d/1brgiwN41w47rtD7tvLd2Au3-Mq0bZHg5e15EDSMg_z0/edit?usp=sharing), [Demo](https://www.youtube.com/watch?v=iiVoe7I9BJw) |\n| [PureFi custom Paymaster](https://github.com/matter-labs/ETHLisbon-2022-hackathon/tree/main/submissions/PureFiPaymaster) | delivers AML (Anti-money laundering) verification data into the smart contract, thus allowing smart contract designers and operators take the decision either to accept or to block incoming funds (due to a high risk associated with the address or transaction, for example). | ETH Lisbon 2022 | account abstraction, aml |  |  |\n| [Account abstraction plugins](https://github.com/0x3327/layerhack_2022) | allows users to set up rules which their account has to abide by when executing transactions while being able to reconfigure them in the future.  |  Encode Club Layer Hack 2022 \ud83e\udd47 | Paymaster | [Demo](https://www.youtube.com/watch?v=FNWH2i9Q31E) |\n| [Institutional Paymaster](https://github.com/peteruche21/inst-paymaster) | A single interface from which protocols, organisations etc can provide gas off-setting capabilities for their end users and specify terms of use. |  Encode Club Layer Hack 2022 \ud83e\udd47 | Paymaster | [Demo](https://www.youtube.com/watch?v=xE0ggVRIeJU) |\n| [DLay pay](https://github.com/ootsun/dlay-pay-server) | DLay Pay is a service that allows online stores (= consumers) to offer anonymous payments. It asks the customer to sign a purchase transaction with to field defined as the address of DLay Pay and does not immediately submit it to zkSync's network. Besides, the to field is set to DLay Pay's addres | Encode Club Layer Hack 2022 | payments, privacy | [Demo](https://www.youtube.com/watch?v=b9eePPSyHdE) |\n| [zkJoey Finance](https://github.com/credit-wallet/joey-mono) | zkJoey Finance is building a seamless and effortless way to borrow and pay. The zkJoey team created a wallet built using multi-sig Account Abstraction on zkSync Era. Users can make payments to the vendors and sellers directly from the Huma Pool via ZKBob to keep vendor details private. | ETHDenver 2023 \ud83e\udd47 | Account Abstraction | [Demo](https://www.youtube.com/watch?v=H68JBHasE44) |\n| [Rhinestone](https://github.com/kopy-kat/ethdenver-aa) | Current solutions for account abstraction have three main problems: opinionated smart contract wallets, vendor lock-in, and duplication of engineering work. Rhinestone solved the above challenges with a modular implementation of account abstraction that allows users to apply multiple plugins to the accounts in an easy-to-use interface. | ETHDenver 2023 \ud83e\udd48 | Account Abstraction | [Demo](https://www.youtube.com/watch?v=kiAcFDuTYw8) |\n| [Solforge](https://github.com/0xPT/solforge) | Solforge is a visual scripter for solidity, enabling distinguished engineers to build more complex systems on Ethereum, and onboarding less technical individuals into smart contracts, ultimately leading to more mainstream adoption of blockchains. This tool will enable engineers to import any smart contract and visualize the data flow in a more easy-to-consume, no-code format. | ETHDenver 2023 \ud83e\udd47 | Developer Tooling | [Demo](https://www.youtube.com/watch?v=LfCZAL6GQgo&t=121s) |\n| [GuardianUI](https://github.com/GuardianUI) | Guardian UI is a tool that automatically runs test definition files to simulate real-world tests. The tool build a way to convert text into end-to-end test code using natural language. The user stories are converted from markdown files into test code, and automatically run the tests. | ETHDenver 2023 \ud83e\udd48 | Developer Tooling | [Demo](https://www.youtube.com/watch?v=x95IAEvADvc) |\n| [Account Trade Limit](https://github.com/porco-rosso-j/zksync-account-trade-limit) | This project implements an Account Abstraction wallet contract with multiple unique features: swap & trade size limit, multicall, and meta-transaction via Paymaster; has a module called SwapModule that allows accounts to swap tokens on AMM DEX with limitations such as token whitelist, daily trade size limit, and maximum size per trade. The module is recommended for non-veteran users who ought to trade crypto assets as conservatively as possible. | zkSync Era Hack0 2023 \ud83e\udd47 | Account Abstraction | [Demo](https://github.com/porco-rosso-j/zksync-account-trade-limit#demo) |\n| [adv zksync cli](https://github.com/WangKehanK/zksync-cli) | The adv zksync cli project provides a command-line interface for managing wallets and accounts on the ZKSync network. It allows users to create new wallets, list all wallets, delete a wallet, add a new account, import an existing account (to the development environment), fund a wallet with the faucet, and fetch transaction history (WIP). It's built upon MatterLabs/zksync-cli. | zkSync Era Hack0 2023 \ud83e\udd47 | Developer Tooling | [Demo](https://www.youtube.com/watch?v=cXyf6Kci3Ic) |\n| [zkSync Oclif](https://github.com/0xStruct/zksync-oclif) | zkSync CLI built on Open CLI Framework (oclif) for better organization, extensibility and maintainability with tests. oclif is widely used by Heroku and Shopify. The objective is to cover zksync-web3 APIs extensively with more commands. | zkSync Era Hack0 2023 \ud83e\udd48 | Developer Tooling | [Demo](https://vimeo.com/807329509) |\n| [create zksync npm](https://github.com/sambitsargam/create-zksync-app) | A full-stack starter template with React & Hardhat to develop, deploy, and test Solidity smart contracts on the zk sync era network. The starter kit also includes pre-installed\u00a0zk sync hardhat full code,\u00a0tailwindcss,\u00a0web3.js, etc. packages. | zkSync Era Hack0 2023 \ud83e\udd49 | Developer Tooling | [Demo](https://www.youtube.com/watch?v=w2Hi53iaskw) |\n| [zkSinc Mix](https://github.com/metaversemoon/zkSinc-mix) | zkSinc Mix is an interface for zkSync smart contracts that allow users to interact with contracts on the zkSync network. It also, allows developers to interact with smart contracts, and deploy and verify them. Some of it\u2019s features include compiler to compile the code, verifier to verify the contract code, get ContractData for the contract. | zkSync Era Hack0 2023 4\ufe0f\u20e3 | Developer Tooling | [Demo](https://www.youtube.com/watch?v=zJw5hFbFH50) |\n| [Bye Bye Private Key](https://github.com/porco-rosso-j/zksync-account-webauthn) | In order for Ethereum to scale beyond its niche base, there must be an improvement to private key architecture. Protecting and managing private keys has too many pitfalls. Unfortunately, there are not many alternatives for the cryptographic security provided by private keys. With technologies like Webauthn zkSync's native account abstraction we could create a solution to sign ethereum transactions with your fingerprint. | Scaling Ethereum 2023 \ud83e\udd47 | Account Abstraction | [Demo](https://ethglobal.com/showcase/bye-bye-private-key-wm3aa) |\n| [Fuchsia](https://github.com/scaling-eth-2023/wallet-extension) | Fushsia Wallet aims to provide an\u00a0innovative payment experience\u00a0that offers users\u00a0on-chain benefits and rewards for their transactions. By creating a membership payment system that utilizes blockchain technology; using Account Abstraction for customization, users can potentially receive discounts on gas fees and even pay gas with native tokens, which can be anything! | Scaling Ethereum 2023 \ud83e\udd47 | Account Abstraction | [Demo](https://fuchsia-app.vercel.app/) |\n| [zAAp Protocol](https://github.com/tx-bundler/tx-bundler) | zAAp is a revolutionary tool that is designed to save time and money for users while interacting with any protocol on the blockchain. It achieves this through bundle transactions, where multiple transactions are combined into one and only one gas fee is charged, making it more affordable and convenient to interact with different protocols. | Scaling Ethereum 2023 \ud83e\udd49 | Account Abstraction | [Demo](https://fuchsia-app.vercel.app/) |\n| [AutoAudit](https://www.autoaudit.dev/) | AutoAudit: AI-driven Ethereum smart contract auditing. Paste code, get a full audit & tailored tests for a secure, reliable contract. Streamline your audit process with AutoAudit. | Scaling Ethereum 2023 \ud83e\udd47 | Developer Tooling | [Demo](https://www.autoaudit.dev/) |\n| [Solive](https://github.com/WTFAcademy/solive) | Solive is a flexible online playground for Solidity smart contracts, inspired by remix-IDE and react-live. You can edit, compile, deploy, and interact with solidity smart contracts in one React component. | Scaling Ethereum 2023 \ud83e\udd48 | Developer Tooling | [Demo](https://solive-demo.vercel.app/) |\n| [WillWallet](https://github.com/itublockchain/will-wallet-leading-privacy) | WillWallet aims to ensure the security of users' crypto assets while providing practical and flexible solutions to enhance user experience. Find more details in the repo attached above. | ETHPrivacy \ud83e\udd47 | Account Abstraction | [Demo](https://www.youtube.com/watch?v=mNokmwFcV-Y) |\n| [Bee Together](https://github.com/beetogether-work) | Bee Together is your all-in-one platform to launch and manage your own service DAO or freelance collective in web3 by implementing gasless transactions with zkSync Era. | ETHPrague \ud83e\udd47 | Wallets & Smart Accounts Track | [Demo](https://www.beetogether.work/) |\n| [FairTickets](https://github.com/ethprague23pl) | FairTickets; Create an event and  buy or sell tickets with just a few clicks while keeping royalties for those who deserve them. | ETHPrague \ud83e\udd48 | Wallets & Smart Accounts Track | [Demo](https://www.youtube.com/watch?v=tGZw7QNkk74&themeRefresh=1) |\n| [PeerUp](https://github.com/grmkris/peerlocal) | PeerUp; Decentralized resource sharing, P2P tools & equipment lending, yield farming, activism, and governance. | ETHPrague \ud83e\udd49 | Wallets & Smart Accounts Track | [Demo](https://www.youtube.com/watch?v=k8aOzRfOgYs) |\n", "release_dates": []}, {"name": "hardhat-zksync", "description": null, "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: Welcome to zkSync Hardhat plugins repository\n\n![Era Logo](https://github.com/matter-labs/era-contracts/raw/main/eraLogo.svg)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\nThis repository contains a collection of plugins to aid in the development and deployment of smart contracts on the zkSync network. These plugins are designed to integrate seamlessly with the [Hardhat](https://hardhat.org/) development environment, providing developers with an easy-to-use and powerful toolset.\n\nHere is an overview of the plugins currently available:\n\n| \ud83d\udd0c Plugin                     | \ud83d\udcc4 Description                                                                                                                    |\n|-------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|\n| hardhat-zksync-solc           | Simplifies compiling Solidity contracts for the zkSync network, streamlining deployment preparation.                              |\n| hardhat-zksync-deploy         | Facilitates the deployment of contracts on zkSync, utilizing artifacts from hardhat-zksync-solc/vyper.                            |\n| hardhat-zksync-verify         | Automates the process of verifying smart contracts on the zkSync network, enhancing transparency and trust.                       |\n| hardhat-zksync-verify-vyper   | Specialized for automating the verification of Vyper contracts on the zkSync network.                                             |\n| hardhat-zksync-vyper          | Streamlines the compilation of Vyper contracts for deployment on the zkSync network.                                              |\n| hardhat-zksync-chai-matchers  | Extends chai with additional matchers, aiding in testing zkSync-specific features more effectively.                               |\n| hardhat-zksync-toolbox        | Offers a suite of zkSync-related Hardhat plugins in one package, enhancing accessibility and efficiency.                          |\n| hardhat-zksync-upgradeable    | Enables easier deployment and upgrading of smart contracts on the zkSync network, improving contract lifecycle management.        |\n| hardhat-zksync-node           | Convenient plugin to run the zkSync era-test-node locally.                                                                        |\n| hardhat-zksync-ethers         | A zksync-ethers SDK wrapper providing additional methods for accelerated development on zkSync.                                   |\n\nYou can find more detailed explanations on how to use hardhat zkSync plugins on our [documentation page](https://v2-docs.zksync.io/api/hardhat/plugins.html#plugins) where each plugin has its own section:\n\n[hardhat-zksync-solc](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-solc.html)\\\n[hardhat-zksync-deploy](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-deploy.html)\\\n[hardhat-zksync-verify](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-verify.html)\\\n[hardhat-zksync-verify-vyper](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-verify-vyper.html)\\\n[hardhat-zksync-vyper](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-vyper.html)\\\n[hardhat-zksync-chai-matchers](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-chai-matchers.html)\\\n[hardhat-zksync-toolbox](https://era.zksync.io/docs/tools/hardhat/plugins.html)\\\n[hardhat-zksync-upgradeable](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-upgradable.html)\\\n[hardhat-zksync-node](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-node.html)\\\n[hardhat-zksync-ethers](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-ethers.html)\n\n\nWe hope you find these plugins useful in your development efforts.\\\nHappy coding!\ud83d\ude4c\ud83c\udf89\n## License\n\nhardhat-zkSync is distributed under the terms of both the MIT license and the Apache License (Version 2.0).\n\nSee [LICENSE-APACHE](LICENSE-APACHE), [LICENSE-MIT](LICENSE-MIT) for details.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev)\n", "release_dates": ["2024-02-29T10:07:46Z", "2024-02-29T10:31:27Z", "2024-02-26T10:43:58Z", "2024-02-26T13:44:52Z", "2024-02-26T13:34:46Z", "2024-02-26T11:05:38Z", "2024-02-26T13:14:04Z", "2024-02-23T11:28:50Z", "2024-02-23T13:58:40Z", "2024-02-22T09:19:25Z", "2024-02-21T16:37:51Z", "2024-02-16T15:59:51Z", "2024-02-16T14:59:31Z", "2024-02-09T09:50:55Z", "2024-02-05T16:16:32Z", "2024-02-01T15:31:38Z", "2024-02-01T16:32:42Z", "2024-01-31T16:19:37Z", "2024-01-31T15:49:00Z", "2024-01-29T13:52:35Z", "2024-01-29T14:01:11Z", "2024-01-26T14:54:08Z", "2024-01-25T22:19:55Z", "2024-01-25T21:26:54Z", "2024-01-25T14:21:13Z", "2024-01-25T23:37:35Z", "2024-01-22T13:58:24Z", "2024-01-22T13:42:02Z", "2024-01-15T14:13:10Z", "2023-12-22T17:24:34Z"]}, {"name": "hodor", "description": "Open source implementation of zkSTARKs in pure Rust", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Hodor\n\nOpen source zkSTARKs implementataion over prime fields. Initial focus should be on highly efficient prover implementation, with later developement of tools for AIR representation synthesis.\n\n## Release details\n\nMatter Labs has applied to present an open-source zkSTARK prover on Devcon5 with intended opening date of early/mid September. Due to publication of our transparent and quantum secure [commitment scheme](https://eprint.iacr.org/2019/1020) we think that even an alpha version of our prover/framework is now of a separate interest and will allow end-users to build an intuition on zkSTARK, FRI and IOP.\n\n## Challenges\n\nStark arithmetization - AIR - is much more difficult to design for than traditional R1CS or gate-based arithmetizations from Groth16, Sonic, Bulletproofs or PLONK due to lack of \"memory\" in a form of ability to always address a previously declared variable and being intrinsically non-suitable for one-off computations. As a result creation of a programming and (much more difficult) some form of gadget-composability approach is a non-trivial task and here the spirit of open source programming and community should help to find an optimal track. More material about the essence of Stark constraints and their \"density\" will be published soon.\n\n## Current state of affairs\n\nCurrent code is not yet cleaned and should not be used for anything but proofs of concept, but is close to production grade in a sense that it's designed from scratch by following the publications (it's not a port of some other code), mainly DEEP-FRI paper, and it multicore optimized from the day one. It's also commented so understand the workflow of the prover starting from the ARP step.\n\nIn the prover it's assumed that single round of FRI is enough to reach the target soundness error (e.g. 100 bits of security). It's not always the case, so implementation of simpler interface for FRI parametrization is a top priority (see below).\n\nAlso, only \"dense\" constraints are implemented for now - constraints that affect every next row of the AIR trace with may be few rows skipped at the benining and at the end. Other types of well-computable densities, e.g. one that happens at every 2nd, 4th, 8th, etc. row of the trace (due to implementation being over multiplicative subgroup of the size 2^k in a prime field for FFT purposes) and some other, are not implemented yet.\n\n## Prioritized TODO (contributions welcome)\n\n- [ ] Implement (and most likely rework the API) for the existing constraint densities\n- [ ] Provide more parametrizable FRI (more rounds, skipping intermediate commitment steps)\n- [ ] Provide some trivial AIR toolkit (e.g. step by step tracer and witness generator)\n- [ ] Decide on the programming model for gadget compositions\n- [ ] Abstract away more constraint \"densities\" (divisors for ALI step)\n- [ ] Cleanup traits and public interfaces\n- [ ] Add native Rust serialization (`serde` based) for constraint systems or at least constraint densities for non-trivial cases \n- [ ] Automate a workflow for \"constant\" registers (lookup tables for e.g. Pedersed hash) \n- [ ] Would be good, but not strictly: Ethereum verifier example or (hard way) synthesiser\n\n## Features\n- [x] Full feature set (ARP + ALI) for formulation with single witness per register\n- [x] DEEL-ALI as baseline for efficiency\n- [x] Multicore (including fancy FFT strategies)\n- [x] Radix-4 FFT\n- [x] ZK by no quering from the original domains, but LDEs only. Additional masking by non-constrained elements of witness applies for free\n- [ ] Mixed-radix FFT (2 and 4) for arbitrary domain lengths\n- [ ] Constant registers optimization (WIP)\n- [ ] One-shot and sparse constraints implementation (WIP)\n- [x] Prover and verifier with precomputations at initialization time\n- [ ] Carefull use of precomputations (WIP)\n- [ ] Serialization formats\n- [ ] Check if IOP Merkle trees should commit to natural domain indexing in addition to the evaluation result itself \n- [ ] Proof size optimization with coset combining\n- [ ] Sparse FRI with less commitments to intermediate values\n- [ ] Single FRI polynomial composition (WIP), pure proof size optimization that does not affect correctness and reduced proof speed\n- [ ] Perfect ZK by masking polynomials\n\n## License\n\nDual MIT/Apache-2.0\n\n## Authors\n\n- Alex Vlasov, [shamatar](https://github.com/shamatar)\n- Konstantin Panarin, [Konstantce](https://github.com/Konstantce)", "release_dates": ["2019-08-23T09:39:45Z"]}, {"name": "hubot-docker", "description": "Minimalistic Docker image with Hubot", "language": null, "license": null, "readme": "# hubot-docker\nMinimalistic Docker image with Hubot. \n\nEasy to use if you have a lot of custom scripts and external scripts, but don't want to bake them into image.\n\n\n# Environment variables\n\n* `HUBOT_NAME` - name of the Hubot. Not that necessary, defaults to `robot`.\n* `EXTRA_PACKAGES` - comma-separated list of NPM packages, required by your scripts.\n\n# Container creation\n\nFollowing arguments are getting passed to hubot command by default: `--name $HUBOT_NAME --adapter slack`. If you want to add something extra - rewrite those arguments in command, during a container creation (Eg.: `--name $HUBOT_NAME --adapter slack --alias \"\\!\"`).\n\nIf you want to use custom scripts, it's worth to mount it as a volume (`-v <your_path_to_scripts>:/home/hubot/scripts`). Also, add scripts dependecies to `EXTRA_PACKAGES` variable (Eg.: `-e EXTRA_PACKAGES=aws-sdk,cron`). The entrypoint will install at start-up.\n\nIf you want some external scripts to be used and enabled, mount `external-scripts.json` as a volume (`-v <your_path_to_external-scripts.json>:/home/hubot/external-scripts.json`).\n", "release_dates": []}, {"name": "hubot-github-deployments", "description": "\ud83d\ude80\ud83e\udd16 Integrate with the GitHub deployment API", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Hubot GitHub Deployments\n\n[![npm version](https://badge.fury.io/js/hubot-github-deployments.svg)](http://badge.fury.io/js/hubot-github-deployments) [![Build Status](https://travis-ci.org/stephenyeargin/hubot-github-deployments.png)](https://travis-ci.org/stephenyeargin/hubot-github-deployments)\n\nIntegrate with GitHub deployment API.\n\n## Getting Started\n\nThis package allows you to create payloads to send to the [GitHub Deployment API](https://developer.github.com/v3/repos/deployments/), then check on the status of the deployments. Combined with a deployment tool that listens to organizational or repository [DeploymentEvent](https://developer.github.com/v3/activity/events/types/#deploymentevent) webhooks, this module can help automate that process via ChatOps.\n\n## Installation\n\nIn your hubot repository, run:\n\n`npm install hubot-github-deployments --save`\n\nThen add **hubot-github-deployments** to your `external-scripts.json`:\n\n```json\n[\"hubot-github-deployments\"]\n```\n\n## Configuration:\n\n| Environment Variable          | Required? | Description                      |\n| ----------------------------- | :-------- | -------------------------------- |\n| `HUBOT_GITHUB_TOKEN`          | Yes       | GitHub application token         |\n| `HUBOT_GITHUB_USER`           | Yes       | GitHub bot user for deployments (IRC user will be noted in deployment description) |\n| `HUBOT_GITHUB_DEPLOY_TARGETS` | Yes       | Comma-separated list of environments, e.g. `production,staging` |\n| `HUBOT_GITHUB_DEPLOY_AUTO_MERGE` | No       | Passes auto_merge parameter to the deployment `true/false` |\n| `HUBOT_GITHUB_REPO`           | No        | Repository to deploy, in `:owner/:repository format` |\n\n## Commands:\n\n- `hubot deploy status [for :owner/:repo]` - List the status of most recent deployments\n- `hubot deploy status [id] [for :owner/:repo]` - List the statuses a particular deployment, or an optional specific status\n- `hubot deploy list targets [for :owner/:repo]` - List available deployment targets\n- `hubot deploy list branches [for :owner/:repo] [search]` - List available branches, filtered by optional search term\n- `hubot deploy <branch or SHA> to <server> [for :owner/:repo]` - Creates a Github deployment of a branch/SHA to a server\n", "release_dates": []}, {"name": "jetbrains-plugin", "description": "Hack4Impact's JetBrains plugin that provides recommended templates for quality project development", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<h1 align=\"center\">\n  <br>\n    <a href=\"https://hack4impact.org/\"><img src=\"https://raw.githubusercontent.com/hack4impact/jetbrains-plugin/main/src/main/resources/icons/rotating-icon.gif\" alt=\"Hack4Impact Icon\" width=\"100\"></a>\n  <br>\n  <b><a href=\"https://hack4impact.org/\">Hack4Impact</a>'s JetBrains Recommendations</b>\n</h1>\n\n<p align=\"center\">\n<a href=\"https://plugins.jetbrains.com/plugin/16260-hack4impact-s-recommendations\"><img src=\"https://img.shields.io/jetbrains/plugin/v/16260?style=flat-square&label=Version&logo=jetbrains&logoColor=FFFFFF&labelColor=000000\" alt=\"Version\" /></a>\n<a href=\"https://plugins.jetbrains.com/plugin/16260-hack4impact-s-recommendations/reviews\"><img src=\"https://img.shields.io/jetbrains/plugin/r/rating/16260?style=flat-square&label=Rating&logo=jetbrains&logoColor=FFFFFF&labelColor=000000\" alt=\"Rating\" /></a>\n<a href=\"https://github.com/hack4impact/jetbrains-plugin/actions?query=workflow%3A%22CI%22\"><img src=\"https://img.shields.io/github/workflow/status/hack4impact/jetbrains-plugin/CI?style=flat-square&label=Build&logo=github&logoColor=FFFFFF&labelColor=000000\" alt=\"Build\"/></a>\n</p>\n\n<!-- Plugin description -->\nHack4Impact's JetBrains plugin that provides recommended templates for quality project development:\n\n- ESLint Configuration (`.eslintrc.json`)\n- Prettier Configuration (`.prettierrc.json`)\n- MarkdownLint Configuration (`.markdownlint.json`)\n- EditorConfig Configuration (`.editorconfig`)\n- GitIgnore (`.gitignore`)\n- Changelog (`CHANGELOG.md`)\n- License (`LICENSE.md`)\n- CodeOwners (`CODEOWNERS`)\n\nIf you use VS Code instead, install the [VS Code Extension](https://github.com/hack4impact/vscode-extension).\n<!-- Plugin description end -->\n\n## Contents <!-- omit in toc -->\n\n- [Installation](#installation)\n- [Actions](#actions)\n  - [Create Template Files](#create-template-files)\n  - [Create ESLint Configuration Template](#create-eslint-configuration-template)\n  - [Create Prettier Configuration Template](#create-prettier-configuration-template)\n  - [Create MarkdownLint Configuration Template](#create-markdownlint-configuration-template)\n  - [Create EditorConfig Configuration Template](#create-editorconfig-configuration-template)\n  - [Create GitIgnore Template](#create-gitignore-template)\n  - [Create Changelog Template](#create-changelog-template)\n  - [Create License Template](#create-license-template)\n  - [Create CodeOwners Template](#create-codeowners-template)\n- [Contributors](#contributors)\n\n## Installation\n\n- Using IDE built-in plugin system:\n\n  <kbd>Settings/Preferences</kbd> > <kbd>Plugins</kbd> > <kbd>Marketplace</kbd> > <kbd>Search for \"Hack4Impact's\n  Recommendations\"</kbd> >\n  <kbd>Install Plugin</kbd>\n\n- Manually:\n\n  Download the [latest release](https://github.com/hack4impact/jetbrains-plugin/releases/latest) and install it manually\n  using\n  <kbd>Settings/Preferences</kbd> > <kbd>Plugins</kbd> > <kbd>\u2699\ufe0f</kbd> > <kbd>Install plugin from disk...</kbd>\n\n## Actions\n\nAll Actions can be found on the menu bar: <kbd>Tools</kbd> > <kbd>Hack4Impact</kbd>\n\n### Create Template Files\n\n#### Action ID\n\n`hack4impact.templates.create`\n\n#### Description\n\n- Opens a Dialog to choose the templates that should be created\n- Shows a File Picker Dialog to pick the folder where the templates should be created\n- Creates the templates with Hack4Impact's recommended configuration\n\n---\n\n### Create ESLint Configuration Template\n\n#### Action ID\n\n`hack4impact.templates.create.ESLintConfig`\n\n#### Description\n\n- Shows a File Picker Dialog to pick the folder where a `.eslintrc.json` file should be created\n- Creates a `.eslintrc.json` file with Hack4Impact's recommended configuration\n\n---\n\n### Create Prettier Configuration Template\n\n#### Action ID\n\n`hack4impact.templates.create.PrettierConfig`\n\n#### Description\n\n- Shows a File Picker Dialog to pick the folder where a `.prettierrc.json` file should be created\n- Creates a `.prettierrc.json` file with Hack4Impact's recommended configuration\n\n---\n\n### Create MarkdownLint Configuration Template\n\n#### Action ID\n\n`hack4impact.templates.create.MarkdownLintConfig`\n\n#### Description\n\n- Shows a File Picker Dialog to pick the folder where a `.markdownlint.json` file should be created\n- Creates a `.markdownlint.json` file with Hack4Impact's recommended configuration\n\n---\n\n### Create EditorConfig Configuration Template\n\n#### Action ID\n\n`hack4impact.templates.create.EditorConfigConfig`\n\n#### Description\n\n- Shows a File Picker Dialog to pick the folder where a `.editorconfig` file should be created\n- Creates a `.editorconfig` file with Hack4Impact's recommended configuration\n\n---\n\n### Create GitIgnore Template\n\n#### Action ID\n\n`hack4impact.templates.create.GitIgnore`\n\n#### Description\n\n- Shows a File Picker Dialog to pick the folder where a `.gitignore` file should be created\n- Creates a boilerplate `.gitignore` file\n\n---\n\n### Create Changelog Template\n\n#### Action ID\n\n`hack4impact.templates.create.Changelog`\n\n#### Description\n\n- Shows a File Picker Dialog to pick the folder where a `CHANGELOG.md` file should be created\n- Creates a boilerplate `CHANGELOG.md` file\n\n---\n\n### Create License Template\n\n#### Action ID\n\n`hack4impact.templates.create.License`\n\n#### Description\n\n- Shows a File Picker Dialog to pick the folder where a `LICENSE.md` file should be created\n- Creates a boilerplate `LICENSE.md` file\n\n### Create CodeOwners Template\n\n#### Action ID\n\n`hack4impact.templates.create.CodeOwners`\n\n#### Description\n\n- Shows a File Picker Dialog to pick the folder where a `CODEOWNERS` file should be created\n- Creates a boilerplate `CODEOWNERS` file\n\n## Contributors\n\nProject Contributors ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/YashTotale\"><img src=\"https://avatars.githubusercontent.com/u/30784592?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yash Totale</b></sub></a><br /><a href=\"https://github.com/hack4impact/jetbrains-plugin/commits?author=YashTotale\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-YashTotale\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"https://github.com/hack4impact/jetbrains-plugin/commits?author=YashTotale\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"https://bholmes.dev/\"><img src=\"https://avatars.githubusercontent.com/u/31811199?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>Benjamin Holmes</b></sub></a><br /><a href=\"#mentoring-Holben888\" title=\"Mentoring\">\ud83e\uddd1\u200d\ud83c\udfeb</a> <a href=\"#ideas-Holben888\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#projectManagement-Holben888\" title=\"Project Management\">\ud83d\udcc6</a></td>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/eric-newcomer/\"><img src=\"https://avatars.githubusercontent.com/u/20120289?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>Eric Newcomer</b></sub></a><br /><a href=\"#mentoring-eric-newcomer\" title=\"Mentoring\">\ud83e\uddd1\u200d\ud83c\udfeb</a> <a href=\"#projectManagement-eric-newcomer\" title=\"Project Management\">\ud83d\udcc6</a></td>\n  </tr>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!\n", "release_dates": []}, {"name": "jsonrpc", "description": "Rust JSON-RPC implementation", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Parity JSON-RPC\n\n**NOTE: This crate is no longer actively developed; please have a look at our \n[jsonrpsee](https://github.com/paritytech/jsonrpsee) crate if you're looking for an actively \nmaintained JSON RPC implementation.**\n\nRust implementation of JSON-RPC 2.0 Specification.\nTransport-agnostic `core` and transport servers for `http`, `ipc`, `websockets` and `tcp`.\n\n**New!** Support for [clients](#Client-support).\n\n[Documentation](https://docs.rs/jsonrpc-core/)\n\n## Sub-projects\n- [jsonrpc-core](./core) [![crates.io][core-image]][core-url]\n- [jsonrpc-core-client](./core-client) [![crates.io][core-client-image]][core-client-url]\n- [jsonrpc-http-server](./http) [![crates.io][http-server-image]][http-server-url]\n- [jsonrpc-ipc-server](./ipc) [![crates.io][ipc-server-image]][ipc-server-url]\n- [jsonrpc-tcp-server](./tcp) [![crates.io][tcp-server-image]][tcp-server-url]\n- [jsonrpc-ws-server](./ws) [![crates.io][ws-server-image]][ws-server-url]\n- [jsonrpc-stdio-server](./stdio) [![crates.io][stdio-server-image]][stdio-server-url]\n- [jsonrpc-derive](./derive) [![crates.io][derive-image]][derive-url]\n- [jsonrpc-server-utils](./server-utils) [![crates.io][server-utils-image]][server-utils-url]\n- [jsonrpc-pubsub](./pubsub) [![crates.io][pubsub-image]][pubsub-url]\n\n[core-image]: https://img.shields.io/crates/v/jsonrpc-core.svg\n[core-url]: https://crates.io/crates/jsonrpc-core\n[core-client-image]: https://img.shields.io/crates/v/jsonrpc-core-client.svg\n[core-client-url]: https://crates.io/crates/jsonrpc-core-client\n[http-server-image]: https://img.shields.io/crates/v/jsonrpc-http-server.svg\n[http-server-url]: https://crates.io/crates/jsonrpc-http-server\n[ipc-server-image]: https://img.shields.io/crates/v/jsonrpc-ipc-server.svg\n[ipc-server-url]: https://crates.io/crates/jsonrpc-ipc-server\n[tcp-server-image]: https://img.shields.io/crates/v/jsonrpc-tcp-server.svg\n[tcp-server-url]: https://crates.io/crates/jsonrpc-tcp-server\n[ws-server-image]: https://img.shields.io/crates/v/jsonrpc-ws-server.svg\n[ws-server-url]: https://crates.io/crates/jsonrpc-ws-server\n[stdio-server-image]: https://img.shields.io/crates/v/jsonrpc-stdio-server.svg\n[stdio-server-url]: https://crates.io/crates/jsonrpc-stdio-server\n[derive-image]: https://img.shields.io/crates/v/jsonrpc-derive.svg\n[derive-url]: https://crates.io/crates/jsonrpc-derive\n[server-utils-image]: https://img.shields.io/crates/v/jsonrpc-server-utils.svg\n[server-utils-url]: https://crates.io/crates/jsonrpc-server-utils\n[pubsub-image]: https://img.shields.io/crates/v/jsonrpc-pubsub.svg\n[pubsub-url]: https://crates.io/crates/jsonrpc-pubsub\n\n## Examples\n\n- [core](./core/examples)\n- [derive](./derive/examples)\n- [pubsub](./pubsub/examples)\n\n### Basic Usage (with HTTP transport)\n\n```rust\nuse jsonrpc_http_server::jsonrpc_core::{IoHandler, Value, Params};\nuse jsonrpc_http_server::ServerBuilder;\n\nfn main() {\n\tlet mut io = IoHandler::default();\n\tio.add_method(\"say_hello\", |_params: Params| async {\n\t\tOk(Value::String(\"hello\".to_owned()))\n\t});\n\n\tlet server = ServerBuilder::new(io)\n\t\t.threads(3)\n\t\t.start_http(&\"127.0.0.1:3030\".parse().unwrap())\n\t\t.unwrap();\n\n\tserver.wait();\n}\n```\n\n### Basic usage with derive\n\n```rust\nuse jsonrpc_core::Result;\nuse jsonrpc_derive::rpc;\n\n#[rpc]\npub trait Rpc {\n\t/// Adds two numbers and returns a result\n\t#[rpc(name = \"add\")]\n\tfn add(&self, a: u64, b: u64) -> Result<u64>;\n}\n\npub struct RpcImpl;\nimpl Rpc for RpcImpl {\n\tfn add(&self, a: u64, b: u64) -> Result<u64> {\n\t\tOk(a + b)\n\t}\n}\n\nfn main() {\n\tlet mut io = jsonrpc_core::IoHandler::new();\n\tio.extend_with(RpcImpl.to_delegate())\n}\n```\n\n### Client support\n\n```rust\nuse jsonrpc_core_client::transports::local;\nuse jsonrpc_core::{BoxFuture, IoHandler, Result};\nuse jsonrpc_core::futures::{self, future, TryFutureExt};\nuse jsonrpc_derive::rpc;\n\n/// Rpc trait\n#[rpc]\npub trait Rpc {\n\t/// Returns a protocol version\n\t#[rpc(name = \"protocolVersion\")]\n\tfn protocol_version(&self) -> Result<String>;\n\n\t/// Adds two numbers and returns a result\n\t#[rpc(name = \"add\", alias(\"callAsyncMetaAlias\"))]\n\tfn add(&self, a: u64, b: u64) -> Result<u64>;\n\n\t/// Performs asynchronous operation\n\t#[rpc(name = \"callAsync\")]\n\tfn call(&self, a: u64) -> BoxFuture<Result<String>>;\n}\n\nstruct RpcImpl;\n\nimpl Rpc for RpcImpl {\n\tfn protocol_version(&self) -> Result<String> {\n\t\tOk(\"version1\".into())\n\t}\n\n\tfn add(&self, a: u64, b: u64) -> Result<u64> {\n\t\tOk(a + b)\n\t}\n\n\tfn call(&self, _: u64) -> BoxFuture<Result<String>> {\n\t\tBox::pin(future::ready(Ok(\"OK\".to_owned())))\n\t}\n}\n\nfn main() {\n\tlet mut io = IoHandler::new();\n\tio.extend_with(RpcImpl.to_delegate());\n\n\tlet (client, server) = local::connect::<gen_client::Client, _, _>(io);\n\tlet fut = client.add(5, 6).map_ok(|res| println!(\"5 + 6 = {}\", res));\n\tfutures::executor::block_on(async move { futures::join!(fut, server) })\n\t\t.0\n\t\t.unwrap();\n}\n```\n", "release_dates": []}, {"name": "l2-intro-demo", "description": "Introduction to layer 2 protocols and smart contract examples on zkSync", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Intro to Layer 2s: buidl on the zkEVM\n\nThis repository contains all the code examples used in the \"Introduction to L2s\" workshop.\n\nSlides are available here: https://docs.google.com/presentation/d/14i1j_DiLD3pCtFsT4V6g9VX1T-XJqd0ue1GldybI2Lk/edit?usp=sharing\n\n## Workshop tasks\n\n### POAP NFTs\n\nTo receive a POAP NFT for completing these tasks, you need to follow the intructions mentioned during the workshop.\n\n### Workshop important links\n\n- [zkSync Portal](https://portal.zksync.io/)\n- [zkSync official faucet](https://portal.zksync.io/faucet)\n- [Goerli faucet](https://goerlifaucet.com/)\n- [zkSync explorer](https://goerli.explorer.zksync.io/)\n- [zkSync CLI documentation](https://v2-docs.zksync.io/api/tools/zksync-cli/)\n- [OpenZeppelin wizzard](https://wizard.openzeppelin.com/#erc20)\n\n### 1. zkSync portal and faucets\n\nThe [zkSync Portal](https://portal.zksync.io/) is the easiest way to deposit and withdraw funds from zkSync. If you have GoerliETH, you can use the [bridge section](https://portal.zksync.io/bridge) to deposit or withdraw funds to and from the zkSync testnet.\n\nHowever, if you don't have any GoerliETH, you can receive a small amount by using our [faucet](https://portal.zksync.io/faucet), which requires you to post a tweet as a way to verify your identity.\n\nOn the other hand, here are a few other faucets that you can use:\n\n- [Alchemy faucet](https://goerlifaucet.com/)\n- [PoW faucet](https://goerli-faucet.pk910.de/)\n\n### 2. Create a project with zksync-cli\n\nThe zkSync CLI tool is the easiest way to start developing applications and smart contracts on zkSync. You can [find the documentation here](https://v2-docs.zksync.io/api/tools/zksync-cli/).\n\nTo install it, just run `sudo npm i -g zksync-cli@latest` (enter your system password).\n\nTo create a new project, just run `zksync-cli create NAME_OF_YOUR_PROJECT`. This will create a new folder with the project name and download a sample project inside it.\n\nIt's very similar to any other Hardhat project, but the `hardhat.config.ts` file includes some zkSync-specific properties.\n\nFirst, it imports a few dependencies used to compile and deploy our contracts:\n\n```typescript\nimport \"@matterlabs/hardhat-zksync-solc\";\nimport \"@matterlabs/hardhat-zksync-deploy\";\n```\n\nSecondly, it includes the `zksolc` object which contains the properties of the compiler. It comes with the minimal configuration but you can learn more about the [zksolc configuration here](https://v2-docs.zksync.io/api/hardhat/plugins.html#hardhat-zksync-solc).\n\nAn last, the networks are defined with the following parameters:\n\n```js\n  url: \"https://zksync2-testnet.zksync.dev\",\n  ethNetwork: \"goerli\",\n  zksync: true,\n```\n\nThe `url` and `ethNetwork` are the RPC endpoints of the L2 and L1 and the `zksync` flag is used to indicate Hardhat if it should use the zksync compiler and deployment plugins.\n\n### 3. Deploy and verify the `Greeter` contract\n\nThe zkSync-CLI sample project includes a `Greeter` contract and a deploy script. The [`Greeter` contract](./contracts/Greeter.sol) stores a message on chain which can be retrieved by calling the read method `greet()` and can be updated by calling the method `setGreeting(_message)`.\n\nTo compile the contract, run `yarn hardhat compile`. You'll notice that the folders `artifacts-zk` and `cache-zk` will be created with the compiled artifact.\n\nTo deploy the contract, just set your wallet's private key in the `.env` file (you'll have to rename it first), and run the command `yarn hardhat deploy-zksync --script deploy-greeter.ts`.\n\nTo verify the contract you can use the [zkSync Explorer](https://goerli.explorer.zksync.io/). You'll have to select the solidity and zksolc compiler versions to match the ones from the [`hardhat.config.ts` file](./hardhat.config.ts) and also enter the constructor params, which are printed in the terminal by the [`deploy-greeter.ts` script](./deploy/deploy-greeter.ts).\n\n### 4. Create and deploy an ERC20 contract\n\nTo showcase the compatibility with the starndard token contract, we'll use the [OpenZeppeling contract wizard](https://wizard.openzeppelin.com/#erc20) to create an ERC20 contract.\n\nWe'll choose an ERC20, Burnable, Pausable and Snapshot. We can copy the contract code and the contract and put it in the `contracts` folder as is (check out file [zkToken.sol](./contracts/zkToken.sol)).\n\nTo compile the contract, just run `yarn hardhat compile` again.\n\n- The included [`deploy-erc20.ts`](./deploy/deploy-erc20.ts) script will deploy this contract.\n- The included [`use-erc20.ts`](./deploy/use-erc20.ts) script will do a transfer of tokens between two accounts and return its balances.\n\n### 5. Create and deploy an ERC721 contract\n\nTo showcase the compatibility with the standard NFT token, we'll use the [OpenZeppeling contract wizard](https://wizard.openzeppelin.com/#erc721) to create an ERC721 contract.\n\nWe'll select the following options: Mintable (with auto increments), Burnable, Enumerable and enter a Base URI. We can copy this contract into the `/contracts` folder (check out file [zkNFT.sol](./contracts/zkNFT.sol)).\n\nTo compile the contract, just run `yarn hardhat compile` again.\n\n- The included [`deploy-erc721.ts`](./deploy/deploy-erc721.ts) script will deploy this contract.\n- The included [`use-erc721.ts`](./deploy/use-erc721.ts) script will mint a new NFT and return the total supply and balance.\n\n## Project structure\n\nProjects created with the zkSync-CLI have the following structure.\n\n- `/contracts`: smart contracts.\n- `/deploy`: deployment and contract interaction scripts.\n- `/test`: test files\n- `hardhat.config.ts`: configuration file.\n\n## Commands\n\n- `yarn hardhat compile` will compile the contracts.\n- `yarn hardhat deploy-zksync --script scriptFILE.ts` will execute the script from the `/deploy` folder (e.g `yarn hardhat deploy-zksync --script deploy-greeter.ts`). Requires [environment variable setup](#environment-variables).\n\n### Environment variables\n\nIn order to prevent users to leak private keys, this project includes the `dotenv` package which is used to load environment variables. It's used to load the wallet private key, required to run the deploy script.\n\nTo use it, rename `.env.example` to `.env` and enter your private key.\n\n```\nWALLET_PRIVATE_KEY=123cde574ccff....\n```\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n", "release_dates": []}, {"name": "l2-intro-ethdenver", "description": "Introduction to layer 2 protocols and smart contract examples on zkSync for ETH Denver", "language": "Vue", "license": null, "readme": "\n# Intro to Layer 2s: buidl on the zkEVM _( ETHDenver edition)_\n\n![](./Era-ETHDenver.png)\n\nThis repository contains all the code examples used in the \"Introduction to L2s\" workshop for ETH Denver.\n\nSlides are available here: https://docs.google.com/presentation/d/1BzXiZf34-1zoj3hCvCt4PQIBeMiQSygr8nhcK8nnNrs/edit?usp=sharing\n\n## Project structure\n\nThis repository contains two folders:\n\n## cli-project\n\nThis is created with the zkSync-CLI and has the following structure.\n  - `/contracts`: smart contracts.\n  - `/deploy`: deployment and contract interaction scripts.\n  - `/test`: test files\n  - `hardhat.config.ts`: configuration file.\n  \n### Commands\n\n- `yarn`: install dependencies.\n- `yarn hardhat compile` will compile the contracts.\n- `yarn hardhat deploy-zksync --script scriptFILE.ts` will execute the script from the `/deploy` folder (e.g `yarn hardhat deploy-zksync --script deploy-greeter.ts`). Requires [environment variable setup](#environment-variables).\n\n### Environment variables\n\nIn order to prevent users to leak private keys, this project includes the `dotenv` package which is used to load environment variables. It's used to load the wallet private key, required to run the deploy scripts.\n\nTo use it, rename `.env.example` to `.env` and enter your private key.\n\n```\nWALLET_PRIVATE_KEY=123cde574ccff....\n```\n\n## web3-app\n\nIs a frontend build with Vue.js and it's a basic example of how to interact with the smart contracts deployed on zkSync Era.\n\n### Commands\n\n- `yarn`: install dependencies\n- `yarn dev`: runs the local server. Once run, visit http://localhost:3000/\n\n### Configuration\n\n- Enter the Greeter contract address in the `src/views/Home.vue` file.\n- Enter the ERC20 contract address in the `src/views/Token.vue` file.\n\n\n## Workshop tasks\n\n### Workshop important links\n\n- [zkSync Era Portal](https://portal.zksync.io/)\n- [zkSync Era official faucet](https://portal.zksync.io/faucet)\n- [Goerli faucet](https://goerlifaucet.com/)\n- [zkSync Era explorer](https://goerli.explorer.zksync.io/)\n- [zkSync CLI documentation](https://era.zksync.io/docs/api/tools/zksync-cli/)\n- [OpenZeppelin wizzard](https://wizard.openzeppelin.com/#erc20)\n- [Hardhat migration guide](https://era.zksync.io/docs/api/hardhat/migrating-to-zksync.html)\n\n### 1. zkSync portal and faucets\n\nThe [zkSync Portal](https://portal.zksync.io/) is the easiest way to deposit and withdraw funds from zkSync. If you have GoerliETH, you can use the [bridge section](https://portal.zksync.io/bridge) to deposit or withdraw funds to and from the zkSync testnet.\n\nHowever, if you don't have any GoerliETH, you can receive a small amount by using our [faucet](https://portal.zksync.io/faucet), which requires you to post a tweet as a way to verify your identity.\n\nOn the other hand, here are a few other faucets that you can use to get GoerLiETH, which then you can bridge to zkSync:\n\n- [Alchemy faucet](https://goerlifaucet.com/)\n- [PoW faucet](https://goerli-faucet.pk910.de/)\n\n### 2. Create a project with zksync-cli\n\nThe zkSync CLI tool is the easiest way to start developing applications and smart contracts on zkSync. You can [find the documentation here](https://era.zksync.io/docs/api/tools/zksync-cli/).\n\nTo install it, just run `sudo npm i -g zksync-cli@latest` (enter your system password).\n\nTo create a new project, just run `zksync-cli create NAME_OF_YOUR_PROJECT`. This will create a new folder with the project name and download a sample project inside it.\n\n**Note** Once created, run `cd NAME_OF_YOUR_PROJECT` to enter the project directory. You'll have to run the commands to compile contracts and run scripts from this folder.\n\nThe project created is very similar to any other Hardhat project, but the `hardhat.config.ts` file includes some zkSync-specific properties.\n\nFirst, it imports a few dependencies used to compile and deploy our contracts:\n\n```typescript\nimport \"@matterlabs/hardhat-zksync-solc\";\nimport \"@matterlabs/hardhat-zksync-deploy\";\n```\n\nSecondly, it includes the `zksolc` object which contains specific properties of the compiler. It comes with the minimal configuration but you can learn more about the [zksolc configuration here](https://era.zksync.io/docs/api/hardhat/plugins.html#hardhat-zksync-solc).\n\n```js\nzksolc: {\n  version: \"1.2.2\",\n  compilerSource: \"binary\",\n  settings: {},\n},\n```\n\nAn last, the networks are defined with the following parameters:\n\n```js\n  url: \"https://zksync2-testnet.zksync.dev\",\n  ethNetwork: \"goerli\",\n  zksync: true,\n```\n\nThe `url` and `ethNetwork` are the RPC endpoints of the L2 and L1 and the `zksync` flag is used to indicate Hardhat if it should use the zksync compiler and deployment plugins.\n\n**Note** With \"goerli\", the project will use the default providers from ethers, but you can change that for an RPC endpoint from\n\n### 3. Deploy and verify the `Greeter` contract\n\nThe zkSync-CLI sample project includes a `Greeter` contract and a deploy script. The [`Greeter` contract](./contracts/Greeter.sol) stores a message on chain which can be retrieved by calling the read method `greet()` and can be updated by calling the method `setGreeting(_message)`.\n\nTo compile the contract, run `yarn hardhat compile`. You'll notice that the folders `artifacts-zk` and `cache-zk` will be created with the compiled artifact.\n\nTo deploy the contract, just set your wallet's private key in the `.env` file (you'll have to rename it first), and run the command `yarn hardhat deploy-zksync --script deploy-greeter.ts`.\n\nTo verify the contract you can use the [zkSync Explorer](https://goerli.explorer.zksync.io/). You'll have to select the solidity and zksolc compiler versions to match the ones from the [`hardhat.config.ts` file](./hardhat.config.ts) and also enter the constructor params, which are printed in the terminal by the [`deploy-greeter.ts` script](./deploy/deploy-greeter.ts).\n\n**Note** Make sure you've configured your private key in the `.env` file [as described above](#environment-variables).\n\n### 4. Create and deploy an ERC20 contract\n\nTo showcase the compatibility with the standard token contract, we'll use the [OpenZeppeling contract wizard](https://wizard.openzeppelin.com/#erc20) to create an ERC20 contract.\n\nWe'll choose an ERC20, Burnable, Pausable and Snapshot. We can copy the contract code and the contract and put it in the `contracts` folder as is (check out file [zkToken.sol](./contracts/zkToken.sol)).\n\nAs this contract uses some dependencies from OpenZeppelin, we'll have to install them with `yarn add -D @openzeppelin/contracts`.\n\nTo compile the contract, just run `yarn hardhat compile` again.\n\n- The included [`deploy-erc20.ts`](./deploy/deploy-erc20.ts) script will deploy this contract.\n- The included [`use-erc20.ts`](./deploy/use-erc20.ts) script will do a transfer of tokens between two accounts and return its balances.\n\n**Note** To verify contracts that include imports of other contracts and libraries (like Openzeppelin contracts \ud83d\ude09), you'd need to flatten it first! Learn more about [flattening contracts in our docs](https://era.zksync.io/docs/api/tools/block-explorer/contract-verification.html#verifying-contracts-using-the-zksync-block-explorer)\n\n\n### 5. Create and deploy an ERC721 contract\n\nTo showcase the compatibility with the standard NFT token, we'll use the [OpenZeppeling contract wizard](https://wizard.openzeppelin.com/#erc721) to create an ERC721 contract.\n\nWe'll select the following options: Mintable (with auto increments), Burnable, Enumerable and enter a Base URI. We can copy this contract into the `/contracts` folder (check out file [zkNFT.sol](./contracts/zkNFT.sol)).\n\nTo compile the contract, just run `yarn hardhat compile` again.\n\n- The included [`deploy-erc721.ts`](./deploy/deploy-erc721.ts) script will deploy this contract.\n- The included [`use-erc721.ts`](./deploy/use-erc721.ts) script will mint a new NFT and return the total supply and balance.\n\n\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n", "release_dates": []}, {"name": "l2-intro-pre-ethdenver", "description": "Introduction to layer two and zkSync", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Intro to Layer 2s: buidl on the zkEVM _(pre ETH Denver edition)_\n\n![](./ETHDenver_2023.png)\n\nThis repository contains all the code examples used in the \"Introduction to L2s\" workshop previous to ETH Denver. \n\n\ud83c\udfac [Watch the recording here](https://www.youtube.com/watch?v=8oBbIjgT5mM)\n\nSlides are available here: https://docs.google.com/presentation/d/1_zWQRjUFX5ahiBMOjnoDiMAdjJ2-ozCs593HRCwflHU/edit?usp=sharing\n\n> This repo is no longer open to contributions & PRs.\n\n## Project structure\n\nProjects created with the zkSync-CLI have the following structure.\n\n- `/contracts`: smart contracts.\n- `/deploy`: deployment and contract interaction scripts.\n- `/test`: test files\n- `hardhat.config.ts`: configuration file.\n\n## Commands\n\n- `yarn hardhat compile` will compile the contracts.\n- `yarn hardhat deploy-zksync --script scriptFILE.ts` will execute the script from the `/deploy` folder (e.g `yarn hardhat deploy-zksync --script deploy-greeter.ts`). Requires [environment variable setup](#environment-variables).\n\n### Environment variables\n\nIn order to prevent users to leak private keys, this project includes the `dotenv` package which is used to load environment variables. It's used to load the wallet private key, required to run the deploy script.\n\nTo use it, rename `.env.example` to `.env` and enter your private key.\n\n```\nWALLET_PRIVATE_KEY=123cde574ccff....\n```\n\n## Workshop tasks\n\n\n### Workshop important links\n\n- [zkSync Portal](https://portal.zksync.io/)\n- [zkSync official faucet](https://portal.zksync.io/faucet)\n- [Goerli faucet](https://goerlifaucet.com/)\n- [zkSync explorer](https://goerli.explorer.zksync.io/)\n- [zkSync CLI documentation](https://v2-docs.zksync.io/api/tools/zksync-cli/)\n- [OpenZeppelin wizzard](https://wizard.openzeppelin.com/#erc20)\n\n### 1. zkSync portal and faucets\n\nThe [zkSync Portal](https://portal.zksync.io/) is the easiest way to deposit and withdraw funds from zkSync. If you have GoerliETH, you can use the [bridge section](https://portal.zksync.io/bridge) to deposit or withdraw funds to and from the zkSync testnet.\n\nHowever, if you don't have any GoerliETH, you can receive a small amount by using our [faucet](https://portal.zksync.io/faucet), which requires you to post a tweet as a way to verify your identity.\n\nOn the other hand, here are a few other faucets that you can use to get GoerLiETH, which then you can bridge to zkSync:\n\n- [Alchemy faucet](https://goerlifaucet.com/)\n- [PoW faucet](https://goerli-faucet.pk910.de/)\n\n### 2. Create a project with zksync-cli\n\nThe zkSync CLI tool is the easiest way to start developing applications and smart contracts on zkSync. You can [find the documentation here](https://v2-docs.zksync.io/api/tools/zksync-cli/).\n\nTo install it, just run `sudo npm i -g zksync-cli@latest` (enter your system password).\n\nTo create a new project, just run `zksync-cli create NAME_OF_YOUR_PROJECT`. This will create a new folder with the project name and download a sample project inside it.\n\n**Note** Once created, run `cd NAME_OF_YOUR_PROJECT` to enter the project directory. You'll have to run the commands to compile contracts and run scripts from this folder.\n\nThe project created is very similar to any other Hardhat project, but the `hardhat.config.ts` file includes some zkSync-specific properties.\n\nFirst, it imports a few dependencies used to compile and deploy our contracts:\n\n```typescript\nimport \"@matterlabs/hardhat-zksync-solc\";\nimport \"@matterlabs/hardhat-zksync-deploy\";\n```\n\nSecondly, it includes the `zksolc` object which contains specific properties of the compiler. It comes with the minimal configuration but you can learn more about the [zksolc configuration here](https://v2-docs.zksync.io/api/hardhat/plugins.html#hardhat-zksync-solc).\n\n```js\nzksolc: {\n  version: \"1.2.2\",\n  compilerSource: \"binary\",\n  settings: {},\n},\n```\n\nAn last, the networks are defined with the following parameters:\n\n```js\n  url: \"https://zksync2-testnet.zksync.dev\",\n  ethNetwork: \"goerli\",\n  zksync: true,\n```\n\nThe `url` and `ethNetwork` are the RPC endpoints of the L2 and L1 and the `zksync` flag is used to indicate Hardhat if it should use the zksync compiler and deployment plugins.\n\n**Note** With \"goerli\", the project will use the default providers from ethers, but you can change that for an RPC endpoint from\n\n### 3. Deploy and verify the `Greeter` contract\n\nThe zkSync-CLI sample project includes a `Greeter` contract and a deploy script. The [`Greeter` contract](./contracts/Greeter.sol) stores a message on chain which can be retrieved by calling the read method `greet()` and can be updated by calling the method `setGreeting(_message)`.\n\nTo compile the contract, run `yarn hardhat compile`. You'll notice that the folders `artifacts-zk` and `cache-zk` will be created with the compiled artifact.\n\nTo deploy the contract, just set your wallet's private key in the `.env` file (you'll have to rename it first), and run the command `yarn hardhat deploy-zksync --script deploy-greeter.ts`.\n\nTo verify the contract you can use the [zkSync Explorer](https://goerli.explorer.zksync.io/). You'll have to select the solidity and zksolc compiler versions to match the ones from the [`hardhat.config.ts` file](./hardhat.config.ts) and also enter the constructor params, which are printed in the terminal by the [`deploy-greeter.ts` script](./deploy/deploy-greeter.ts).\n\n**Note** Make sure you've configured your private key in the `.env` file [as described above](#environment-variables).\n\n### 4. Create and deploy an ERC20 contract\n\nTo showcase the compatibility with the standard token contract, we'll use the [OpenZeppeling contract wizard](https://wizard.openzeppelin.com/#erc20) to create an ERC20 contract.\n\nWe'll choose an ERC20, Burnable, Pausable and Snapshot. We can copy the contract code and the contract and put it in the `contracts` folder as is (check out file [zkToken.sol](./contracts/zkToken.sol)).\n\nAs this contract uses some dependencies from OpenZeppelin, we'll have to install them with `yarn add -D @openzeppelin/contracts`.\n\nTo compile the contract, just run `yarn hardhat compile` again.\n\n- The included [`deploy-erc20.ts`](./deploy/deploy-erc20.ts) script will deploy this contract.\n- The included [`use-erc20.ts`](./deploy/use-erc20.ts) script will do a transfer of tokens between two accounts and return its balances.\n\n**Note** To verify contracts that include imports of other contracts and libraries (like Openzeppelin contracts \ud83d\ude09), you'd need to flatten it first! Learn more about [flattening contracts in our docs](https://v2-docs.zksync.io/api/tools/block-explorer/contract-verification.html#verifying-contracts-using-the-zksync-block-explorer)\n\n### 5. Create and deploy an ERC721 contract\n\nTo showcase the compatibility with the standard NFT token, we'll use the [OpenZeppeling contract wizard](https://wizard.openzeppelin.com/#erc721) to create an ERC721 contract.\n\nWe'll select the following options: Mintable (with auto increments), Burnable, Enumerable and enter a Base URI. We can copy this contract into the `/contracts` folder (check out file [zkNFT.sol](./contracts/zkNFT.sol)).\n\nTo compile the contract, just run `yarn hardhat compile` again.\n\n- The included [`deploy-erc721.ts`](./deploy/deploy-erc721.ts) script will deploy this contract.\n- The included [`use-erc721.ts`](./deploy/use-erc721.ts) script will mint a new NFT and return the total supply and balance.\n\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n", "release_dates": []}, {"name": "local-setup", "description": "zkSync 2.0 setup for local development", "language": "Shell", "license": null, "readme": "# zkSync local development setup\n\nThis repository contains the tooling necessary to bootstrap zkSync locally.\n\n## Dependencies\n\nTo run zkSync locally, you must have `docker compose` and `Docker` installed on your machine. \n\n## Usage\n\nTo bootstrap zkSync locally, just run:\n\n```\n> docker compose up\n```\n\nThis command will bootstrap three docker containers:\n- Postgres (used as the database for zkSync).\n- Local Geth node (used as L1 for zkSync).\n- zkSync server itself.\n\nBy default, the HTTP JSON-RPC API will run on port `3050`, while WS API will run on port `3051`. \n\n*Note, that it is important that the first start script goes uninterrupted. If you face any issues after the bootstrapping process unexpectedly stopped, you should [reset](#resetting-zksync-state) the local zkSync state and try again.* \n\n## Resetting zkSync state\n\nTo reset the zkSync state, just run:\n\n```\n> docker compose down --volumes\n```\n\nThis command will stop and remove all of the pods and named volumes that contains the network state\n\nAfter this, you can run again:\n\n```\n> docker compose up\n```\n\n## Rich wallets\n\nLocal zkSync setup comes with some \"rich\" wallets with large amounts of ETH on both L1 and L2.\n\nThe full list of the addresses of these accounts with the corresponding private keys can be found [here](./rich-wallets.json).\n\nAlso, during the initial bootstrapping of the system, several ERC-20 contracts are deployed locally. Note, that large quantities of these ERC-20 belong to the wallet `0x36615Cf349d7F6344891B1e7CA7C72883F5dc049` (the first one in the list of the rich wallet). Right after bootstrapping the system, these ERC-20 funds are available only on L1.\n\n## Using custom database/L1\n\nTo use custom Postgres database or Layer 1, you should change the `environment` parameters in the docker-compose file:\n\n```yml\nenvironment:\n    - DATABASE_URL=postgres://postgres@postgres/zksync_local\n    - ETH_CLIENT_WEB3_URL=http://geth:8545\n```\n\n- `DATABASE_URL` is the URL to the Postgres database.\n- `ETH_CLIENT_WEB3_URL` is the URL to the HTTP JSON-RPC interface of the L1 node.\n\n## Local testing example\n\nYou can an example of hardhat project that utilizes local testing capabilities [here](https://github.com/matter-labs/tutorial-examples/tree/main/local-setup-testing).\n\nTo run tests, clone the repo and run `yarn test`:\n\n```\ngit clone https://github.com/matter-labs/tutorial-examples.git\ncd local-setup-testing\nyarn test\n```\n", "release_dates": []}, {"name": "M1_algebra", "description": null, "language": "Rust", "license": null, "readme": null, "release_dates": []}, {"name": "matterdb", "description": null, "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# MatterDB\n\n[![Docs.rs](https://docs.rs/matterdb/badge.svg)](https://docs.rs/matterdb)\n![rust 1.45.0+ required](https://img.shields.io/badge/rust-1.45.0+-blue.svg?label=Required%20Rust)\n\n**MatterDB** is a document-oriented persistent storage.\nUnder the hood, MerkleDB uses RocksDB as a key-value storage.\n\n## Features\n\n- Supports list, map and set collections (aka *indexes*),\n  as well as singular elements.\n  Further, indexes can be organized into groups, allowing to create\n  hierarchies of documents with arbitrary nesting.\n- Ability to define data layouts in an intuitive, declarative format.\n- Basic support of transactions: changes to the storage can be\n  aggregated into a fork and then merged to the database atomically.\n- Access control leveraging the Rust type system, allowing to precisely\n  define access privileges for different actors.\n- First-class support of long-running, fault-tolerant data migrations\n  running concurrently with other I/O to the storage.\n\n## Usage\n\nInclude `matterdb` as a dependency in your `Cargo.toml`:\n\n```toml\n[dependencies]\nmatterdb = \"1.0.0\"\n```\n\n## History notice\n\nMatterDB was initially created as [MerkleDB](https://github.com/exonum/exonum/tree/master/components/merkledb)\nby [Exonum](https://exonum.com/index).\n\nMerkleDB was initially created to support merklized collections atop of the persistent key-value storage.\nThis project does not have the same purpose: instead, it provides a generic convenient and (ideally) backend-agnostic\ninterface for the persistent NoSQL storage, without any bounds to the blockchain specifics.\n\n## License\n\n`matterdb` is licensed under the Apache License (Version 2.0).\nSee [LICENSE](LICENSE) for details.\n", "release_dates": []}, {"name": "module-template", "description": "Starter template for Nuxt.js Modules", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Using this template\n\n1. Clone this repo locally\n   ```bash\n   npx degit https://github.com/nuxt-community/module-template.git my-new-project\n   cd my-new-project\n   yarn # or npm install\n   ```\n2. Search and replace all templated names:\n   * `npm_package` => the name of your chosen npm package - e.g. `@nuxtjs/http`\n   * `myModule` => a camel-cased version of your npm package for namespacing your module options - e.g. `http`\n   * `github_repo` => your GitHub repo - e.g. `nuxt-community/http-module`\n\n3. Remove this section of the `README.md` and dive in!\n\n---\n\n# npm_package\n\n[![npm version][npm-version-src]][npm-version-href]\n[![npm downloads][npm-downloads-src]][npm-downloads-href]\n[![Github Actions CI][github-actions-ci-src]][github-actions-ci-href]\n[![Codecov][codecov-src]][codecov-href]\n[![License][license-src]][license-href]\n\n[\ud83d\udcd6 **Release Notes**](./CHANGELOG.md)\n\n## Setup\n\n1. Add `npm_package` dependency to your project\n\n```bash\nyarn add npm_package # or npm install npm_package\n```\n\n2. Add `npm_package` to the `modules` section of `nuxt.config.js`\n\n```js\n{\n  modules: [\n    'npm_package',\n  ],\n  myModule: {\n    // module options\n  }\n}\n```\n\n## Development\n\n1. Clone this repository\n2. Install dependencies using `yarn install`\n3. Start development server using `yarn dev`\n\n## License\n\n[MIT License](./LICENSE)\n\n<!-- Badges -->\n[npm-version-src]: https://img.shields.io/npm/v/npm_package/latest.svg\n[npm-version-href]: https://npmjs.com/package/npm_package\n\n[npm-downloads-src]: https://img.shields.io/npm/dm/npm_package.svg\n[npm-downloads-href]: https://npmjs.com/package/npm_package\n\n[github-actions-ci-src]: https://github.com/github_repo/workflows/ci/badge.svg\n[github-actions-ci-href]: https://github.com/github_repo/actions?query=workflow%3Aci\n\n[codecov-src]: https://img.shields.io/codecov/c/github/github_repo.svg\n[codecov-href]: https://codecov.io/gh/github_repo\n\n[license-src]: https://img.shields.io/npm/l/npm_package.svg\n[license-href]: https://npmjs.com/package/npm_package\n", "release_dates": []}, {"name": "multisig", "description": null, "language": "JavaScript", "license": null, "readme": "# MultiSig Scheme\nHere are step-by-step description of two multi-signature schemes: [MuSig: n-of-n Multi-Signature Scheme](##MuSig:-n-of-n-Multi-Signature-Scheme) and [ t-of-n Threshold Signature Scheme](##t-of-n-Threshold-Signature-Scheme)\n## MuSig: n-of-n Multi-Signature Scheme\n### Overview\nMuSig is effectively a multi-signature and key-aggregation scheme based on Schnorr Signatures. It provides security in plain public key model. \n\nA working full round **typescript** example can be found [here](##Examples)\n\n\n_Note: all codes  are actually pseudocode just for illustrations purpose. Available functions can be found in typescript example_\n\nA step-by-step description is as follows:\n\n### Setup\n#### step one\nUser generates public-private keypair and sends public key to broker\n```\n    private_key, public_key = generate_keypair();\n\n    for i in len(all_users)\n        send_to_user(public_key, all_users[i])\n    end for    \n```\n#### step two\nOnce the receives other parties' public keys, user computes and stores aggregated public key\n```\n    let all_pubkeys = [pubkey_1, .., pubkey_n]\n    let aggregated_pubkey = compute_aggregated_pubkey(all_pubkeys)\n    // store aggregated_pubkey\n```\n\n### Aggregated Commitment\n#### step one\nUser generates crytographically secure nonce\n```\n    nonce = generate_nonce()    \n```\nUser commits his nonce\n```\n    commitment = compute_commitment(nonce)        \n```\nUser hashes commitment\n```\n    pre_commitment = compute_pre_commitment(commitment)\n```\nUser sends pre-commitment to other users through broker\n```\n    for i in len(all_users)\n        send_to_user(pre_commitment, all_users[i])               \n    end for \n```\n#### step two\nOnce user receive the pre_commitment, user reveals his commitment to other users through broker\n```\n    for i in len(all_users)\n        send_to_user(commitment, all_users[i])               \n    end for \n```\nOnce user receives commitments from other parties, user computes aggregated commitment and stores it\n```\n    let all_commitments = [commitment from user 1, ... commitment from user n]\n    let aggregated_commitment = compute_aggregated_commitment(all_commitments)\n```\n\n\n_Note: By using [Pre-Shared Commitments](####Pre-Shared-Commitments), number of rounds can be decreased by one_\n\n### Signing\n#### step one\nInitiator prepares transaction and sends it to other users through broker\n```\n    let transaction = {from: 0xAA, to: 0xBB, ..}\n    let encoded_transaction = encode_transaction(transaction)\n    for i in len(all_users)\n        send_to_user(encoded_transaction, all_users[i])               \n    end for \n```\n#### step two\nOnce the user receives transaction signing message from initiator, user signs transaction with his private key and nonce and sends signature share to other users through broker\n```\n    let transaction = message.transaction\n    let signature_share = sign(private_key, nonce, all_pubkeys, commitment, aggregated_commitment)     \n    \n    \n    let signing_result = {\n        signature_shares: signature_share,\n        commitment: commitment,\n    } \n    \n    for i in len(all_users)\n        send_to_user(signing_result, all_users[i])               \n    end for \n```\n#### step three\nOnce the user receives all signing results from each user, user aggregates signature shares\n```\n    let all_signature_shares = [signature share from user 1, .. , signature share from user n]\n    let aggregated_signature = compute_aggregated_signature(all_signature_shares)\n    \n    let final_signature = {\n        r: aggregated_commitment,\n        s: aggregated_signature\n    }\n```\nUser sends final signature to the broker\n```\n    send_to_broker(final_signature)\n```\n\n#### step four\nBroker submits transaction to the network if each received signature equal and valid\n```\n    let all_final_signatures = [final signature from user 1, .. , final signature from user n]\n    for i in len(all_final_signatures)\n        if i == 0 \n            continue\n        end if \n        if all_final_signatures[i-1] != all_final_signatures[i]\n            exit\n        end if        \n    end for\n    if !is_signature_valid(all_final_signatures[0]) // verification of single sig is enough\n        exit\n    end if\n    \n    submit_transaction(transaction, final_signature)\n```\n\n\n## t-of-n Threshold Signature Scheme\n### Overview\nThe threshold signing algorithm is an signature aggregation scheme based on MuSig Schnorr signatures and the EdDSA signing procedure. Signatures are non-deterministic though as they include random participant commitments. \n\nIn order to achieve threshold, original private key essentially splitted into `n` secret shares and  each user needs to have `t` permuatation of them. \n\nFor example, for a `3-of-4` multisig (`t=3`, `N=4`), the permuations of size `t-1=2` are:\n\n```\n[1, 2], [1, 3], [1, 4], [2, 3], [2, 4], [3, 4]\n```\n\nEvery user computes the key distribution as follows:\n\n- For each permutation, a new private key share must be assigned to all users **who are not part of this permutation**:\n```\n[1, 2]: A => 3, 4\n[1, 3]: B => 2, 4\n[1, 4]: C => 2, 3\n[2, 3]: D => 1, 4\n[2, 4]: E => 1, 3\n[3, 4]: F => 1, 2\n\n```\n- For every secret share, one user from the user subset sharing it (the one with the lowest position number) must generate it and share with the others to whom it should be assigned. In our example:\n```\nShare A: generated by user 3, shared with user 4.\nShare B: generated by user 2, shared with user 4.\nShare C: generated by user 2, shared with user 3.\nShare D: generated by user 1, shared with user 4.\nShare E: generated by user 1, shared with user 3.\nShare F: generated by user 1, shared with user 2.\n```\n\n- So, each user has following secret shares\n\n```\nuser 1 has [D, E, F]\nuser 2 has [B, C, F]\nuser 3 has [A, C, E]\nuser 4 has [A, B, D]\n```\n\n- At the end any combination of three users can construct original private key\n\n```\n    user 1 + user 2 + user 3 = [A, B, C, C, D, E, E, F, F]\n    user 1 + user 3 + user 4 = [A, A, B, C, D, D, E, E, F]\n    user 2 + user 3 + user 4 = [A, A, B, B, C, C, D, E, F]\n```\n- Finally any combination of two users can not construct original private key \n```\n    user 1 + user 2 = [B, C, D, E, F, F] missing [A]\n    user 1 + user 3 = [A, C, D, E, E, F] missing [B]\n    user 1 + user 4 = [A, B, D, D, E, F] missing [C]\n    user 2 + user 3 = [A, B, C, C, E, F] missing [D]\n    user 2 + user 4 = [A, B, B, C, D, F] missing [E]\n    user 3 + user 4 = [A, A, B, C, D, E] missing [F]\n```\n_A full round example for t-of-n scheme will be implemented in typescript_\n\n### Setup \n#### Distributed Key Generation\nEvery user contributes computation of the key distribution as follows:\n##### step one\nUser generates the list of all possible permutations of users of size t-1 which he needs to generate the share. \n```        \n    let permutations = generate_permutations(n, t, user_index)\n    // permutations : [1,3] => [2,4], [1,4] => [2,3]\n```\n##### step two\nUser generates private keys and corresponding public keys for each remaining permutation generated in the first step\n```\n    let receiving_users = []\n    for p in permutations\n        receiving_users.push(p[1])\n    end for\n    // receiving_users: 4, 3\n    \n    let private_keys = []\n    let public_keys = []\n    for user in receiving_users\n        private_key, public_key = generate_keypair();\n        private_keys.push(private_key)\n        public_keys.push(public_key)            \n    end for\n    \n```\nUser sends each private key to user who needs that share  \n\n```    \n    for i in len(receiving_users)\n        send_to_user(private_keys[i], receiving_users[i])\n    end for\n    \n```\nUser sends each public key to all users and broker\n\n```\n    for i in len(all_users)\n        if i != user_index\n            send_to_user(public_keys[i], all_users[i])       \n        end if\n    end for\n    \n    send_to_broker(public_keys)\n```\n##### step three\nOnce the user receives public keys, user makes a unique list of public keys and stores computed aggregated public key from that unique list.\n```\n    let pubkey_list = unique(all_received_pubkeys)\n    aggregated_pubkey = compute_aggregated_pubkey(pubkey_list)\n    // store aggregated_pubkey\n```\n\n##### step four\nOnce broker receives all public keys, broker computes ethereum address and creates corresponding zksync account\n```\n    let ethereum_address = compute_eth_address(..) // !!\n    create_zksync_account(ethereum_address, aggregated_pubkey)\n```\n\n#### Pre-Shared Commitments\nHaving to go through the three rounds every time we want to sign a message is certainly inconvenient. Especially if the signature is time-critical and network messages are slow. So how about this, we do the first two rounds whenever it\u2019s convenient for us. And only once there is a message to sign, we exchange partial signatures. For example, the user of multisig exchange a bunch of (k) nonce commitments and pre-commitments immediately when establishing a connection. When it comes to signing a transaction, one of the pre-shared nonces is used and only one communication round is required to complete the signature.\n\n\n##### step one\nUser generates `k` cryptographically secure nonces and computes commitment and pre-commitment for each nonce. (`k` is the number of desired transactions)\n```\n    let nonces = []\n    let commitments = []\n    let pre_commitments = []\n    for i in range(k)\n        nonce = generate_nonce()    \n        commitment = compute_commitment(nonce)\n        pre_commitment = compute_pre_commitment(commitment)\n        \n        nonces.push(nonce)\n        commitments.push(commitment)\n        pre_commitments.push(pre_commitment)\n    end for\n```\n##### step two\nUser sends each pre-commitments to all users\n```        \n    for user in all_users\n        send_to_user(pre_commitments, user)    \n    end for\n```\n\nOnce the user receive pre-commitments from all other parties, user stores received pre-commitments\n\n```    \n    let received_pre_commitments = [[pre_commitments from user 1],..,[pre_commitments from user n]]\n    store_pre_commitments(received_pre_commitments)\n```\n\n##### step three\nUser sends each commitments to broker\n```\n    send_to_broker(commitments)\n```\n\nOnce the broker receives commitments, broker stores each list received from each user.\n```\n    let received_commitments = [[commitments from user 1],..,[commitments from user n]]\n    // store received_commitments\n```\n\n### Signing\n##### step one\nInitiator prepares transaction and sends it to broker\n```\n    let transaction = {from: 0xAA, to: 0xBB, ..}\n    let encoded_transaction = encode_transaction(transaction)\n    send_to_broker(encoded_transaction)\n```\n##### step two\nOnce the broker receive transaction signing message from initiator, broker queries nonce of multisig account from zksync\n```\n    let nonce = query_nonce_from_zksync(ethereum_address);    \n```\nBroker picks next commitment from each subset \n```\n    let current_commitments = []\n    for subset in received_commitments\n        current_commitments.push(subset[nonce])\n    end for\n```\nBroker queries latest block hash from ethereum network \n```\n    let latest_block_hash = query_latest_block_hash()\n```\nBroker constructs message and sends it to all users\n```\n    message = { \n        transaction: encoded_transaction, \n        latest_block_hash: latest_block_hash,\n        commitment_list: current_commitments,\n        nonce: nonce,\n    }\n    \n    for user in all_users\n        send_to_user(message, user) \n    end for\n    \n```\n\n##### step three\nOnce the user receives transaction signing message from broker, user picks next pre-commitment from each subset \n```\n    let current_pre_commitments = []\n    for subset in received_pre_commitments\n        current_pre_commitments.push(subset[nonce])\n    end for\n```\nUser compares received commitments with previously received pre-commitments\n```\n    for i in len(received_commitments)\n        if received_commitments[i] != current_pre_commitments[i]\n            exit\n        end if\n    end for\n```\n\nUser computes aggregated commitment\n\n```\n    let aggregated_commitment = compute_aggregated_commitment(received_commitments)    \n```\n\nUser signs transaction with each private key and sends them to the broker\n```\n    let transaction = message.transaction\n    let latest_block_hash = message.latest_block_hash\n    \n    let signature_shares = []\n    let public_keys = []\n    \n    for private_key in private_keys\n        let signature_share = sign(private_key, pubkey_list, aggregated_commitment, transaction, latest_block_hash)        \n        signature_shares.push(signature_share)\n        \n        let public_key = compute_pubkey(private_key)\n        public_keys.push(public_key)\n    end for\n    \n    let signing_result = {\n        signature_shares: signature_shares,\n        public_keys: public_keys,\n        aggregated_commitment: aggregated_commitment,\n    } \n    \n    // send signing_result to broker\n    send_to_broker(signing_result)\n```\n##### step four\nOnce the broker receives all signing results from each user, broker checks that each received aggregated commitments are same\n```\n    for i in len(messages)\n        if i == 0 \n            continue\n        end if\n        let previous_aggregated_commitment = messages[i-1].aggregated_commitment          \n        let current_aggregated_commitment = messages[i].aggregated_commitment\n        \n        if previous_aggregated_commitment != current_aggregated_commitment\n            exit\n        end if\n    end for\n    \n    let aggregated_commitment = messages[0].aggregated_commitment\n```\nBroker makes a unique list of received signatures by comparing public keys \n```        \n    let current_public_keys = []\n    let current_signature_shares = []\n    for message in messages\n        for i in len(signature_shares)\n            if !current_public_keys.has(public_keys[i])\n                current_signature_shares.push(signature_shares[i])\n            end if\n        end for\n    end for\n```\n\nBroker aggregates signature shares\n```\n    let aggregated_signature = compute_aggregated_signature(current_signature_shares)\n    \n    let final_signature = {\n        r: aggregated_commitment,\n        s: aggregated_signature\n    }\n```\nBroker completes ceremony by submitting  transaction to the zksync if signature is valid\n```\n    if !is_signature_valid(final_signature)\n        exit\n    end if\n    \n    submit_transaction(transaction, final_signature)\n```\n\n\n\n## Examples\nA working full round typescript example in a e2e fashion can be found [here](https://github.com/matter-labs/multisig/blob/master/typescript-example/test/example.test.ts)\nThis example illustrates only n-of-n scheme. (**It is not for t-of-n scheme!**)\n\n`musig-bindings` directory contains generated wasm-code. Rust sources can be found in [here](https://github.com/matter-labs/schnorr-musig/tree/dev)\n\n### Build\n```\ncd wasm/typescript-example\nyarn -D && yarn build\n```\n\n### Test\n```\nyarn test\n```\n\n## References\n\n- [Simple Schnorr Multi-Signatures with Applications to Bitcoin](https://eprint.iacr.org/2018/068.pdf)\n- [MuSig: A New Multisignature Standard](https://blockstream.com/2018/01/23/en-musig-key-aggregation-schnorr-signatures/)\n- [Key Aggregation for Schnorr Signatures](https://blockstream.com/2018/01/23/en-musig-key-aggregation-schnorr-signatures/)\n", "release_dates": []}, {"name": "nixsgx", "description": "Reproducible Nix packages for TEEs", "language": "Nix", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# nixsgx\n\nThis repository contains a Nix flake with up2date packages for the Intel SGX SDK and gramine.\n\nHopefully most of the packages will be upstreamed to nixpkgs at some point.\n\nAll package builds should be reproducible and therefore can be used to build reproducible enclave images.\n\n## Usage\n\nSee: https://github.com/haraldh/docker-era-fee-withdrawer\n\n\n", "release_dates": []}, {"name": "pairing", "description": "Pairing-friendly elliptic curve library", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# pairing \"community edition\"\n\nNow published as `pairing_ce` to `crates.io` for users convenience.\n\nOriginally developed by ZCash, with extensions from us to make it a little more pleasant. \n\nThis is a Rust crate for using pairing-friendly elliptic curves. Currently, only the [BLS12-381](https://z.cash/blog/new-snark-curve.html) and BN256 curves are implemented.\n\n## [Documentation](https://docs.rs/pairing/)\n\nBring the `pairing` crate into your project just as you normally would.\n\n## Security Warnings\n\nThis library does not make any guarantees about constant-time operations, memory access patterns, or resistance to side-channel attacks.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the Apache-2.0\nlicense, shall be dual licensed as above, without any additional terms or\nconditions.\n", "release_dates": ["2019-03-05T08:48:31Z", "2019-03-04T16:50:12Z", "2019-03-04T16:35:33Z"]}, {"name": "paymaster-examples", "description": "Ready to use paymaster contracts for zkSync Era", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "\n# Paymaster Examples Repository \ud83d\udcc1\n\n![](./paymaster-examples.png)\n\nWelcome to the world of Paymasters!! \ud83c\udf89 \ud83c\udf0d \ud83c\udf89\n\n> \u26a0\ufe0f **Work in Progress**: Please note that none of the contracts in this repository have been fully audited or extensively tested. These contracts are examples and, therefore, are **not** designed for production use.\n\nThis repository houses a variety of example Paymaster Contracts demonstrating different use cases. Plus, a user-friendly, configurable frontend to interact with these examples, developed using React and Next.js. \n\n## Repository structure \ud83c\udfd7\ufe0f\n\nThe repository is divided into two main sections:\n\n- `/contracts`: This directory contains the smart contracts, where each sub-directory represents a unique Paymaster use case. \n\n- `/frontend`: This directory hosts the frontend developed using React and Next.js. The frontend allows you to interact with the various Paymaster contracts provided.\n\n## Commands \ud83d\udcbb\n\nHere are some useful commands to get started:\n\n- `yarn compile:contracts`: Compiles the contracts.\n- `yarn deploy:contracts`: This command deploys contracts. Scripts for deployment can be found in the `/contracts/deploy` directory.\n- `yarn test:contracts`: Runs contract tests. **Please ensure to check the test requirements in /contracts directory.**\n- `yarn serve:ui`: Serves up frontend on `localhost:3000`\n- `yarn format`: Runs prettier formatter.\n\n## Have a request? \ud83d\ude4b\u200d\u2640\ufe0f\nDo you want to see a specific type of Paymaster contract included in this repository? Head over to the [zkync-developers/discussions](https://github.com/zkSync-Community-Hub/zksync-developers/discussions) and tell us about it! We highly value your feedback and are always open to new ideas for showcasing different use-cases and techniques.\n\n## Contributing \ud83d\ude4b\u200d\u2642\ufe0f\n\nWe welcome all contributors! If you're interested in contributing to this project, please review the [CONTRIBUTING](./CONTRIBUTING.md) guide but for a quick summary:\n\n1. Fork the repository\n2. Create a new branch for your changes\n3. Implement your changes and commit them\n4. Push your changes to your fork\n5. Submit a pull request to the main repository\n\nYour contribution will be reviewed and, if it's beneficial to the project, merged into the main branch. Thank you for your interest in our project!\n\n## Official links \ud83d\udd17\n\n- [Website](https://zksync.io/)\n- [Documentation](https://era.zksync.io/docs/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://join.zksync.dev)\n", "release_dates": []}, {"name": "proof_system_info_v1.0", "description": "Information about proof system used in zkSync v1.0", "language": null, "license": null, "readme": "# Description\n\nThis repository contrains a short information about the extension of the PLONK proof system used in zkSync v1.0. A PDF file contrains an unrolled protocol and below we also give a short intuitive description for interested readers.\n\n## Warning for Github viewers\n\nGithub's Markdown renderer does not support inline formulas used in this document, so you can open this file in your favorite Markdown viewer for better experience or open a PDF for the same short descriptions as the one made below.\n\n## Extensions\n\nCompared to the original PLONK [paper](https://eprint.iacr.org/2019/953.pdf) we use two extensions:\n- State width is four instead of three in the original paper. This requires one extra permutation polynomial at the setup $\\sigma_{3}(x)$ and does not change the copy-permutation argument that is generic over number of state (witness) polynomials.\n- Main gate equation is now $q_a(x) a(x) + q_b(x) b(x) + q_c(x) d(x) + q_d(x) d(x) + q_m(x) a(x) b(x) + q_{const}(x) + q_{d_{next}} d(x\\omega) = 0$ where $a(x),..,d(x)$ are state polynomials (witnesses) and $\\omega$ is a generator of the multiplicative domain $D$, such that for a circuit size $n$ one has $|D| = n+1$. Such gate equation allows one to work more efficiently with long linear combination by including up to three terms per gate compared to the original paper where it would be one term per gate ($q_{d_{next}} d(x\\omega)$ term allows one to \"peek\" into the next row for efficient placement of terms).\n\nA strict original source of this extension is unknown to us, but most likely it was first mentioned by Zachary Williamson in one of the Telegram chats along with his work on custom gates in PLONK \n\nWe also invite all interested readers to get the latest information about extensions of a PLONK proof system such as custom gates and lookup table in [PLONK Cafe](https://www.plonk.cafe/)", "release_dates": []}, {"name": "puppeteer-headful", "description": "Github Action for puppeteer that is headful.", "language": null, "license": null, "readme": "# Puppeteer Headful\n\n[Github Action](https://github.com/features/actions) for [Puppeteer](https://github.com/GoogleChrome/puppeteer) that can be ran \"headful\" or not headless.\n\n> Versioning of this container is based on the version of NodeJS in the container\n\n## Purpose\n\nThis container is available to Github Action because there is some situations ( mostly testing [Chrome Extensions](https://pptr.dev/#?product=Puppeteer&version=v1.18.1&show=api-working-with-chrome-extensions) ) where you can not run Puppeteer in headless mode.\n\n## Usage\n\nThis installs Puppeteer ontop of a [NodeJS](https://nodejs.org) container so you have access to run [npm](https://www.npmjs.com) scripts using args. For this hook we hyjack the entrypoint of the [Dockerfile](https://docs.docker.com/engine/reference/builder/) so we can startup [Xvfb](https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml) before your testing starts.\n\n```yaml\nname: CI\non: push\njobs:\n  installDependencies:\n    name: Install Dependencies\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@master\n    - name: Install Dependencies\n      uses: actions/setup-node@v1\n      env:\n        PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: 'true'\n      with:\n        args: install\n    - name: Test Code\n      uses: mujo-code/puppeteer-headful@master\n      env:\n        CI: 'true'\n      with:\n        args: npm test\n```\n\n> Note: You will need to let Puppeteer know not to download Chromium. By setting the env of your install task to PUPPETEER_SKIP_CHROMIUM_DOWNLOAD = 'true' so it does not install conflicting versions of Chromium.\n\nThen you will need to change the way you launch Puppeteer. We export out a nifty ENV variable `PUPPETEER_EXEC_PATH` that you set at your `executablePath`. This should be undefined locally so it should function perfectly fine locally and on the action.\n\n```javascript\nbrowser = await puppeteer.launch({\n  args: ['--no-sandbox'],\n  executablePath: process.env.PUPPETEER_EXEC_PATH, // set by docker container\n  headless: false,\n  ...\n});\n```\n", "release_dates": []}, {"name": "recursive_aggregation_circuit", "description": "Kate commitment based PLONK recursive aggregation circuit", "language": "Solidity", "license": null, "readme": null, "release_dates": []}, {"name": "rescue-poseidon", "description": "Rescue and Poseidon hash function implementations", "language": "Rust", "license": null, "readme": "# Rescue and Poseidon\n## Overview\nThis repo contains implementations of arithmetization oriented hash functions(Rescue, Poseidon, Rescue Prime) that constructed by a sponge construction over prime field for both out-of circuits and in-circuit usages. Each algebraic hash function uses same sponge construction with different round function or permutation function. Gadgets are optimal in the constraint systems while also supporting different scalar fields which supported by bellman. \n\n## Usage\nAdd dependency\n```toml\nrescue_poseidon = 0.1\n```\n\n```rust\n    use franklin_crypto::bellman::bn256::Fr;\n    use franklin_crypto::bellman::Field;\n    use rescue_poseidon::rescue_hash;\n\n    const L: usize = 2;\n    let input = [Fr::one(); L]; // dummy input\n\n    // fixed length rescue hash\n    let result = rescue_hash::<Bn256, L>(&input);\n    assert_eq!(result.len(), 2);\n```\nMore examples can be found in `examples` folder.\n\n\n## Testing\n`cargo test -- --nocapture`\n\n## Benchmarks & Constraint System Costs\n`cargo bench -- --nocapture`\n\n\n_CPU: 3,1 GHz Intel Core i5_\n\n| hashes    | 1x permutation runtime (\u03bcs) | 1x permutation gates | number of rounds |\n| --- | -------- | -------- | -------- |\n| Poseidon   | 13     | 166     | 8f + 33p     |\n| Rescue   | 680     | 266     | 44f     |\n| Rescue Prime   | 300     | 104     | 9f     |\n\n\n\n## References\n- [1] [Cryprographic sponge functions](https://keccak.team/files/CSF-0.1.pdf)\n- [2] [The sponge and duplex constructions](https://keccak.team/sponge_duplex.html)\n- [3] [STARK Friendly Hash \u2013 Survey and Recommendation](https://eprint.iacr.org/2020/948.pdf)\n- [4] [MARVELlous: a STARK-Friendly Family of Cryptographic Primitives](https://eprint.iacr.org/2018/1098.pdf)\n- [5] [POSEIDON: A New Hash Function for Zero-Knowledge Proof Systems](https://eprint.iacr.org/2019/458.pdf)\n- [6] [Rescue-Prime: a Standard Specification (SoK)](https://eprint.iacr.org/2020/1143.pdf)", "release_dates": []}, {"name": "risc_v_simulator", "description": null, "language": "Rust", "license": null, "readme": "# Purpose\n\nRISC-V 32 bit basic processor simulator for ZK purposes, with ZK-specific wrappers and functions. It supports only RV32IM basic set, and machine + use mode only (no atomic set). Inspired by the `https://github.com/cnlohr/mini-rv32ima`, but Rustified. Can be used for rough system overview while ZK circuit is being written and tested. Note that's it's not intended, and will not be a cycle-precise simulator for any hardware RISC-V processor.\n\nThe intention of the system to eventually run even untrusted user programs in \"native\" (RISC-V 32 or 64 bit) code (that requires good isolation), but so for a start we will do only machine mode.\n\nAlso note that circuit implementation will be radically different in many places implementation wise (e.g. we can use memory for registers actually), but both of them will be consistent. \n\n## Important notes\n\n- Even though SATP register is there, and settable, and usermore is supported, for now it's intended to be used as machine mode only! \n- This implementation is 32-bit, but in practice (production) it'll be 64 bit because register size (`XLEN`) doesn't so linearly affect the circuit size, and 64 bit instructions are beneficial for the software that we would like to run on it. And so memory translation scheme would change for SV39.\n- Even though unaligned memory access is a pain in ZK, in practice we have too much byte accesses all over the places, and though we could just work them out through exception handling, we pay small price and allow unaligned access!\n- `bin` folder contains an example of how to run the simulator\n- Non-deterministic ZK nature is implemented by quasi-UART (to be precise - just word-consuming/replying device) that is an \"oracle\" to ask for any witness that a programm running on the simulator may want. Writing to there is only intented for debug logging, but may be there are other good use cases\n- The ZK part will prove full execution trace without explicit/implicit breaks or continuations, memory dumps, etc. Just assume that your single core processors runs\n- MMIO for timer is not yet implemented, but it'll most likely be placed somewhere near the quasi-UART address\n- It also means no timer interrupts yet\n- It's expected that times will be the only interrupt actually for now\n- Interface for MMU and corresponding memory access implementation is actually not too correct and not good for the circuit correspondence too. We may have unaligned loads that cross the page boundaries, so at worst we would need 2 independent memory translations per read/write. In any case it's should not be used for now (so don't write to SATP and don't go usermode!)\n\n## How to run\n\nWe also have `zk_os` repo open with basic examples and logic, so it's possible to write Rust `no-std` code and just launch it. Start of the executable code is expected to be mapped directly into `DEFAULT_ENTRY_POINT: u32 = 0x01000000;` and execution starts from there. Note that loading of the initial (fixed) memory content is free in ZK part in our case (for reasonable sizes), so OS or app image can be expected to be always loaded by default. If you need to load more code you can use quasi-UART to read it from \"oracle\" and do whatever you want with it (remember - machine mode is there for you!)", "release_dates": []}, {"name": "rust-web3", "description": "Ethereum JSON-RPC multi-transport client. Rust implementation of web3 library.  ENS address: rust-web3.eth", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# web3\n\nEthereum JSON-RPC multi-transport client.\nRust implementation of Web3.js library.\n\n[![Build Status][ci-image]][ci-url] [![Crates.io](https://img.shields.io/crates/v/web3)](https://crates.io/crates/web3)\n\n[ci-image]: https://github.com/tomusdrw/rust-web3/workflows/Compilation%20and%20Testing%20Suite/badge.svg\n[ci-url]: https://github.com/tomusdrw/rust-web3/actions?query=workflow%3A%22Compilation+and+Testing+Suite%22\n[docs-rs-badge]: https://docs.rs/web3/badge.svg\n[docs-rs-url]: https://docs.rs/web3\n\nDocumentation: [crates.io][docs-rs-url]\n\n## Usage\n\nFirst, add this to your `Cargo.toml`:\n\n```toml\n[dependencies]\nweb3 = \"0.17.0\"\n```\n\n## Example\n```rust\n#[tokio::main]\nasync fn main() -> web3::Result<()> {\n    let transport = web3::transports::Http::new(\"http://localhost:8545\")?;\n    let web3 = web3::Web3::new(transport);\n\n    println!(\"Calling accounts.\");\n    let mut accounts = web3.eth().accounts().await?;\n    println!(\"Accounts: {:?}\", accounts);\n    accounts.push(\"00a329c0648769a73afac7f9381e08fb43dbea72\".parse().unwrap());\n\n    println!(\"Calling balance.\");\n    for account in accounts {\n        let balance = web3.eth().balance(account, None).await?;\n        println!(\"Balance of {:?}: {}\", account, balance);\n    }\n\n    Ok(())\n}\n```\n\nIf you want to deploy smart contracts you have written you can do something like this (make sure you have the solidity compiler installed):\n\n`solc -o build --bin --abi contracts/*.sol`\n\nThe solidity compiler is generating the binary and abi code for the smart contracts in a directory called contracts and is being output to a directory called build.\n\nFor more see [examples folder](./examples).\n\n## Futures migration\n- [ ] Get rid of parking_lot (replace with async-aware locks if really needed).\n- [ ] Consider getting rid of `Unpin` requirements. (#361)\n- [x] WebSockets: TLS support (#360)\n- [ ] WebSockets: Reconnecting & Pings\n- [x] Consider using `tokio` instead of `async-std` for `ws.rs` transport (issue with test).\n- [x] Restore IPC Transport\n\n## General\n- [ ] More flexible API (accept `Into<X>`)\n- [x] Contract calls (ABI encoding; `debris/ethabi`)\n- [X] Batch Requests\n\n## Transports\n- [x] HTTP transport\n- [x] IPC transport\n- [x] WebSockets transport\n\n## Types\n- [x] Types for `U256,H256,Address(H160)`\n- [x] Index type (numeric, encoded to hex)\n- [x] Transaction type (`Transaction` from Parity)\n- [x] Transaction receipt type (`TransactionReceipt` from Parity)\n- [x] Block type (`RichBlock` from Parity)\n- [x] Work type (`Work` from Parity)\n- [X] Syncing type (`SyncStats` from Parity)\n\n## APIs\n- [x] Eth: `eth_*`\n- [x] Eth filters: `eth_*`\n- [x] Eth pubsub: `eth_*`\n- [x] `net_*`\n- [x] `web3_*`\n- [x] `personal_*`\n- [ ] `traces_*`\n\n### Parity-specific APIs\n- [ ] Parity read-only: `parity_*`\n- [ ] Parity accounts: `parity_*` (partially implemented)\n- [x] Parity set: `parity_*`\n- [ ] `signer_*`\n\n- [x] Own APIs (Extendable)\n```rust\nlet web3 = Web3::new(transport);\nweb3.api::<CustomNamespace>().custom_method().wait().unwrap()\n```\n\n# Installation on Windows\n\nCurrently, Windows does not support IPC, which is enabled in the library by default.\nTo compile, you need to disable the IPC feature:\n```\nweb3 = { version = \"0.17.0\", default-features = false, features = [\"http\"] }\n```\n\n# Avoiding OpenSSL dependency\n\nOn Linux, `native-tls` is implemented using OpenSSL. To avoid that dependency\nfor HTTPS use the corresponding feature.\n```\nweb3 = { version = \"0.17.0\", default-features = false, features = [\"http-rustls-tls\"] }\n```\n\n# Cargo Features\n\nThe library supports following features:\n- `http` - Enables HTTP transport (requires `tokio` runtime, because of `hyper`).\n- `http-tls` - Enables TLS support via `reqwest/default-tls` for HTTP transport (implies `http`; default).\n- `http-native-tls` - Enables TLS support via `reqwest/native-tls` for HTTP transport (implies `http`).\n- `http-rustls-tls` - Enables TLS support via `reqwest/rustls-tls` for HTTP transport (implies `http`).\n- `ws-tokio` - Enables WS transport using `tokio` runtime.\n- `ws-tls-tokio` - Enables TLS support for WS transport (implies `ws-tokio`; default).\n- `ws-async-std` - Enables WS transport using `async-std` runtime.\n- `ws-tls-async-std` - Enables TLS support for WS transport (implies `ws-async-std`).\n- `ipc-tokio` - Enables IPC transport using `tokio` runtime (default).\n- `signing` - Enable account namespace and local-signing support (default).\n- `eip-1193` - Enable EIP-1193 support.\n- `wasm` - Compile for WASM (make sure to disable default features).\n- `arbitrary_precision` - Enable `arbitrary_precision` in `serde_json`.\n", "release_dates": []}, {"name": "scaffold-era", "description": null, "language": null, "license": null, "readme": "## \ud83c\udfd7 scaffold-era\n\n \ud83c\udf1f Open source forkable Ethereum/zkSync Era dev stack. \n\nInitiated at [BUIDLEra hackathon](https://app.buidlbox.io/zksync/zksync-buidlera).\n", "release_dates": []}, {"name": "schnorr-musig", "description": "Simple Schnorr Multi-Signatures", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Rust and Wasm Implementation of MuSig\nThis is a Rust implementation of [MuSig](https://eprint.iacr.org/2018/068.pdf) scheme. It also contains generated wasm code and a [typescript-example](https://github.com/matter-labs/schnorr-musig/blob/master/wasm/example/test/example.test.ts) which illustrates full multi-party signing flow.\n\n## MuSig \nMuSig is effectively a multi-signature and key-aggregation scheme based on Schnorr Signatures. It provides security in plain public key model.  For overview one can visit [article written by Blockstream](https://blockstream.com/2018/01/23/en-musig-key-aggregation-schnorr-signatures/).\n\n### Protocol \nIn order to produce a valid joint signature, each party needs to follow following steps:\n\n1. Signer receives all public keys `[X_1..X_n]` and stores aggregated public key `X'`.\n2. Signer generates a randomly sampled secret scalar nonce `r` and stores his committed nonce `R_i = r\u00b7B` and returns his computed precommitment `H_Ri = Hash(R_i)`\n4. Signer receives pre-commitments `[H_R1..H_Rn]` and reveals his commitment `R_i`.\n5. Signer receives commitments `[R_1..R_n]` and reveals aggregated commitment `R` if all pre-commitments match with commitment.\n6. Signer computes a Fiat-Shamir challenge scalar c using cryptographically secure RNG\nand computes his signature share by blinding the private key `x_i` using the nonce and the challenge: `s_i = r_i + c\u00b7x_i`.\n7. Signer receive signature shares `[s1..sn]` and computes aggregated signature if all signature shares are valid.\n8. Verifier checks the relation: `s\u00b7B  ==  R + c\u00b7X'` where `B` is group generator.\n\n\n## Client Broker Communication\n- Each client generate his own keypair and sends it public key to the server/broker\n- Server collects each parties public-keys and sends a tuple `(list_of_all_public_keys, position)`  to all clients\n- Then, signing ceremony starts as follows:\n    1. client initializes signer instance by calling ` let signer = MusigBN256WasmSigner.new(all_pubkeys, position)`\n    2. client generates a 128-bytes random seed and computes his pre-commitment `let pre_commitment = signers.compute_precommitment(seed)` then sends his pre commitment to the server\n    3. server receives and sends all pre commitment to all clients\n    4. client reveals his commitment `let commitment = signer.receive_precommitments(all_pre_commitments)` and  sends it to the server\n    5. server collects and sends each commitment to all clients(does server also need to aggregate commitments?)\n    6. client computes aggregated commitment by calling `let aggregated_commitment = signer.receive_commitments(all_commitments)` and sends it to the server\n    7. server collects each aggregated commitment and server sends aggregated commitment ot all clients if each received aggregated commitments are same\n    8. client produces signature share `let signature_share = signer.sign(privkeys[i], message)` and sends it to the server\n    9. server collects all shares and sends them to all clients\n    10. client computes aggregated signature `let aggregated_signature = signer.receive_signature_shares(all_signature_shares)` and sends it to the server\n    11. server collects all aggregated signatures and send a \"SIGNING CEREMONY FINISHED \" message to all clients if all signatures are valid\n\n\n## Client Broker Communication 1\nMusig signing basically consists of four rounds: \n1. All signers send pre-commitments t_i\n2. All signers reveal commitments, R_i and all parties verify that t_i = H(R_i)\n3. All signers compute and send their signature shares s_i\n\n### Setup\n- Each client generate his own keypair and sends it public key to the server/broker\n- Server collects each parties public-keys and sends a \"SIGNING CEREMONY STARTED\" message which containts `(list_of_all_public_keys, position)` to all clients\n- Client initializes signer instance by calling `let signer = MusigBN256WasmSigner.new(all_pubkeys, position)`\n\n### Signing\n\n#### Round 1    \n\n    1. client generates a 128-bytes random seed and computes his pre-commitment `let pre_commitment = signers.compute_precommitment(seed)` then sends his pre commitment to the server\n    2. server receives and sends all pre commitment to all clients\n\n#### Round 2\n    1. client reveals his commitment `let commitment = signer.receive_precommitments(all_pre_commitments)` and  sends it to the server\n    2. server collects and sends each commitment to all clients\n    3. client computes aggregated commitment by calling `let aggregated_commitment = signer.receive_commitments(all_commitments)` and sends it to the server\n    4. server collects each aggregated commitment and server sends aggregated commitment to all clients (check that each agg commitments are same)\n\n#### Round 3\n    1. client produces signature share `let signature_share = signer.sign(private_key, message)` and sends it to the server\n    2. server collects all shares and sends them to all clients\n    3. client computes aggregated signature `let aggregated_signature = signer.receive_signature_shares(all_signature_shares)` and sends it to the server\n    11. server collects all aggregated signatures and send a \"SIGNING CEREMONY FINISHED \" message to all clients (check that each agg signature are same)\n\n\n## Client Broker Communication 2\n### Setup\n- Each client generate his own keypair and sends it public key to the server/broker\n- Server collects each parties public-keys and sends a message which containts `(list_of_all_public_keys, position)`  to all clients\n\n### Signing\n- Then, signing ceremony starts as follows:\n    1. client initializes signer instance by calling ` let signer = MusigBN256WasmSigner.new(all_pubkeys, position)`\n    2. client generates a 128-bytes random seed and computes his pre-commitment `let pre_commitment = signers.compute_precommitment(seed)` then sends his pre commitment to the server\n    3. server receives and sends all pre commitment to all clients\n    4. client reveals his commitment `let commitment = signer.receive_precommitments(all_pre_commitments)` and  sends it to the server\n    5. **server collects and all commitments, computes aggregated commitments and sends it to all clients**\n    8. client produces signature share `let signature_share = signer.sign(privkeys[i], message)` and sends it to the server\n    9. server collects all shares and sends them to all clients\n    10. client computes aggregated signature `let aggregated_signature = signer.receive_signature_shares(all_signature_shares)` and sends it to the server\n    11. server collects all aggregated signatures and send a \"SIGNING CEREMONY FINISHED \" message to all clients if all signatures are valid\n\n\n\n## Rust\n\n### Definitions\n\n#### MuSigSigner\n\n` struct MuSigSigner`  Holds signer related private fields and implement functions for MPC steps.\n\n#### Functions\n\n- `MuSigSigner::new(..) -> Result<Self, MusigError>` instantiates MuSigSigner object.\n- `MuSigSigner::compute_precommitment(&mut self, rng: &mut impl Rng) -> Result<Vec<u8>, MusigError>` Pre-commitment is hash of serialized point which computed by multiplication of a randomly generated scalar with generator. rng must be a cryptographically secure one.\n- `MuSigSigner::receive_precommitments(&mut self, pre_commitments: &[Vec<u8>]) -> Result<Point<E, Unknown>, MusigError>` Receives pre-commitments of other parties and returns his revealed commitment which is a point in the group. These pre-commitments will be used to validate received revealed commitments in the next step.\n- `MuSigSigner::receive_commitments(&mut self, commitments: &[Point<E, Unknown>]) -> Result<Point<E, Unknown>, MusigError>`  Receives revealed commitments and compare them against pre-commitments that received previous step. If all commitments are valid then returns computed aggregated commitment which is sum of all commitments. Each party must produce same aggregated.\n - `MuSigSigner::sign(&mut self, private_key: &PrivateKey<E>, message: &[u8], rescue_params: &<E as RescueEngine>::Params) -> Result<E::Fs, MusigError>` Computes signature share with a challenge 'c'\n - `MuSigSigner::receive_signatures(&self, signature_shares: &[E::Fs]) -> Result<Signature<E>, MusigError> ` Receives signature shares and verifies them. If all signature shares are valid then returns an aggregated signature. Each party must produce same aggregated signature.\n- `MuSigSigner::receive_signatures(&self, signature_shares: &[E::Fs]) -> Result<Signature<E>, MusigError>` Receives signature shares and verifies them. If all signature shares are valid then returns an aggregated signature. Each party must produce same aggregated signature.\n\n#### MuSigVerifier\n\n` struct MuSigVerifier`  Implements verification functions\n\n#### Functions\n\n`MuSigVerifier::verify(message: &[u8], pubkeys: &[PublicKey<E>], signature: &Signature<E>, position: usize, jubjub_params: &<E as JubjubEngine>::Params, generator: FixedGenerators, rescue_params: &<E as RescueEngine>::Params) -> Result<bool, MusigError>` Verifies an aggregated signature according to its public keys.\n\n### Tests\n```\ncargo test --lib -- --nocapture test_musig_multiparty_full_round\n```\n\n\n## WASM\n\nIt contains wasm code for MuSig. All functions same with Rust code but inputs need to be serialized.\n\n### Build\n\n```\ncd wasm/\n./build.sh\n```\n\n### Tests\n\n```\ncd wasm/\nwasm-pack test --release --node\n```\n\n## TypeScript\n\n### Build\n\n```\ncd wasm/typescript-example\nyarn -D && yarn build\n```\n\n### Test\n\n```\ncd wasm/typescript-example\nyarn -D && yarn test\n```\n\n### Example Code\n\nA working full round typescript example in a e2e fashion can be found [here](https://github.com/matter-labs/schnorr-musig/blob/master/wasm/example/test/example.test.ts)\n\n## References\n\n- [Simple Schnorr Multi-Signatures with Applications to Bitcoin](https://eprint.iacr.org/2018/068.pdf)\n- [MuSig: A New Multisignature Standard](https://blockstream.com/2018/01/23/en-musig-key-aggregation-schnorr-signatures/)\n- [Key Aggregation for Schnorr Signatures](https://blockstream.com/2018/01/23/en-musig-key-aggregation-schnorr-signatures/)\n", "release_dates": []}, {"name": "simple-oracle-benchmarking", "description": "Deploy a simplified oracle, track gas usage.", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Simple Oracle Benchmarking \ud83d\udcca\n\nBenchmark the gas costs for a simple oracle contract across different networks!\n\n## How It Works \ud83d\udee0\n\n1. **Deploy**: The script deploys a simple oracle contract to a specified network.\n2. **Register Data Providers**: Three dataProviders are created, funded, and then registered.\n3. **Update Prices**: Each dataProvider updates the price with a random value X number of times. Default is 5 per data provider. (To adjust the max-updates, pass in `--max-updates x`).\n4. **Finalize Prices**: The `finalizePrice` function is called from the owner's account.\n5. **Review Results**: At the end, you get a detailed table showcasing the gas costs for each operation. \ud83d\udcc8\n\n## Prerequisites \ud83d\udccb\n\n- Node.js\n- Yarn\n\n## Setup and Execution \ud83d\ude80\n\n## 1. Install Dependencies\n\n```bash\nyarn install\n```\n\n## 2. Compile the Oracle Contract\n\n```bash\nyarn hardhat compile\n```\n\n## 3. Local Environments\n\nProvided in this repo are scripts that will clone and execute local dev environments for zkSync Era, Arbitrum, Optimism, and PolygonzkEVM. To run:\n\n```bash\ncd scripts/local-setups\n```\n\nThen execute the script you want to run:\n```bash\n./zksync.sh | ./optimism.sh | ./arbitrum.sh | ./polygonzkEVM.sh\n```\n\n**Note:** If you want to learn more about a local zkSync network, start the zkSync local environment first. \n\n\ud83d\udcd6 [zkSync Docs - Testing](https://era.zksync.io/docs/tools/testing/)\n\n## 4. Environment Variables Setup \ud83c\udf33\n\nRename `.env.example` to `.env` and fill in your details:\n\n```\n# Local private keys for testing these are RICH accounts created by the local node (under /scripts)\nLOCAL_ZKSYNC_KEY=\nLOCAL_OPTIMISM_KEY=\nLOCAL_POLYGONZK_KEY=\nLOCAL_ARBITRUM_KEY=\nLOCAL_LINEAR_KEY=\nLOCAL_SCROLL_KEY=\n\n# Private keys for the testnet, can be used for all networks\nTESTNET_KEY=\n\n# Private keys for the mainnet, can be used for all networks\nMAINNET_KEY=\n```\n\n## 5. Benchmark Execution\n\n### Benchmarking\n\nRun the benchmark task using:\n\n```bash\nnpx hardhat benchmark-simple-oracle --network <network> --data-provider-count <int> --fund-amount <int> --max-updates <int>\n```\n\n#### Default Parameters:\n- **Data Provider Count**: 3\n- **Fund Amount**: 0.004 ETH\n- **Max Updates**: 5 updatePrice call for each data provider\n\n#### Example:\n\n```bash\nnpx hardhat benchmark-simple-oracle --network zksync-local --max-updates 10\n```\n\nThis will deploy the `SimpleOracle.sol` contract to the specified network, proceed to register the data providers, then call update price with random numbers for the specified amount of times (e.g. 10 times per data provider), finalize the price, and provide a gas breakdown for each operation. \n\n### Additional Tasks\n\n- **Unit Testing**: `yarn test`\n- **Code Formatting**: `yarn fix:fmt`\n", "release_dates": []}, {"name": "snark-wrapper", "description": null, "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": null, "release_dates": []}, {"name": "solidity", "description": "The zkEVM fork of Solidity", "language": null, "license": {"key": "gpl-3.0", "name": "GNU General Public License v3.0", "spdx_id": "GPL-3.0", "url": "https://api.github.com/licenses/gpl-3.0", "node_id": "MDc6TGljZW5zZTk="}, "readme": "# The Solidity Contract-Oriented Programming Language\n\n[![Matrix Chat](https://img.shields.io/badge/Matrix%20-chat-brightgreen?style=plastic&logo=matrix)](https://matrix.to/#/#ethereum_solidity:gitter.im)\n[![Gitter Chat](https://img.shields.io/badge/Gitter%20-chat-brightgreen?style=plastic&logo=gitter)](https://gitter.im/ethereum/solidity)\n[![Solidity\u00a0Forum](https://img.shields.io/badge/Solidity_Forum%20-discuss-brightgreen?style=plastic&logo=discourse)](https://forum.soliditylang.org/)\n[![Twitter Follow](https://img.shields.io/twitter/follow/solidity_lang?style=plastic&logo=twitter)](https://twitter.com/solidity_lang)\n[![Mastodon Follow](https://img.shields.io/mastodon/follow/000335908?domain=https%3A%2F%2Ffosstodon.org%2F&logo=mastodon&style=plastic)](https://fosstodon.org/@solidity)\n\nYou can talk to us on Gitter and Matrix, tweet at us on Twitter or create a new topic in the Solidity forum. Questions, feedback, and suggestions are welcome!\n\nSolidity is a statically typed, contract-oriented, high-level language for implementing smart contracts on the Ethereum platform.\n\nFor a good overview and starting point, please check out the official [Solidity Language Portal](https://soliditylang.org).\n\n## Table of Contents\n\n- [Background](#background)\n- [Build and Install](#build-and-install)\n- [Example](#example)\n- [Documentation](#documentation)\n- [Development](#development)\n- [Maintainers](#maintainers)\n- [License](#license)\n- [Security](#security)\n\n## Background\n\nSolidity is a statically-typed curly-braces programming language designed for developing smart contracts\nthat run on the Ethereum Virtual Machine. Smart contracts are programs that are executed inside a peer-to-peer\nnetwork where nobody has special authority over the execution, and thus they allow anyone to implement tokens of value,\nownership, voting, and other kinds of logic.\n\nWhen deploying contracts, you should use the latest released version of\nSolidity. This is because breaking changes, as well as new features and bug fixes, are\nintroduced regularly. We currently use a 0.x version\nnumber [to indicate this fast pace of change](https://semver.org/#spec-item-4).\n\n## Build and Install\n\nInstructions about how to build and install the Solidity compiler can be\nfound in the [Solidity documentation](https://docs.soliditylang.org/en/latest/installing-solidity.html#building-from-source).\n\n\n## Example\n\nA \"Hello World\" program in Solidity is of even less use than in other languages, but still:\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity >=0.6.0 <0.9.0;\n\ncontract HelloWorld {\n    function helloWorld() external pure returns (string memory) {\n        return \"Hello, World!\";\n    }\n}\n```\n\nTo get started with Solidity, you can use [Remix](https://remix.ethereum.org/), which is a\nbrowser-based IDE. Here are some example contracts:\n\n1. [Voting](https://docs.soliditylang.org/en/latest/solidity-by-example.html#voting)\n2. [Blind Auction](https://docs.soliditylang.org/en/latest/solidity-by-example.html#blind-auction)\n3. [Safe remote purchase](https://docs.soliditylang.org/en/latest/solidity-by-example.html#safe-remote-purchase)\n4. [Micropayment Channel](https://docs.soliditylang.org/en/latest/solidity-by-example.html#micropayment-channel)\n\n## Documentation\n\nThe Solidity documentation is hosted at [Read the docs](https://docs.soliditylang.org).\n\n## Development\n\nSolidity is still under development. Contributions are always welcome!\nPlease follow the\n[Developers Guide](https://docs.soliditylang.org/en/latest/contributing.html)\nif you want to help.\n\nYou can find our current feature and bug priorities for forthcoming\nreleases in the [projects section](https://github.com/ethereum/solidity/projects).\n\n## Maintainers\n* [@axic](https://github.com/axic)\n* [@chriseth](https://github.com/chriseth)\n\n## License\nSolidity is licensed under [GNU General Public License v3.0](LICENSE.txt).\n\nSome third-party code has its [own licensing terms](cmake/templates/license.h.in).\n\n## Security\n\nThe security policy may be [found here](SECURITY.md).\n", "release_dates": []}, {"name": "solidity_plonk_verifier", "description": "Solidity verifier for Plonk", "language": "Solidity", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": null, "release_dates": []}, {"name": "teepot", "description": "Key Value store in a TEE with Remote Attestation for Authentication", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# teepot\nKey Value store in a TEE with Remote Attestation for Authentication\n\n## Introduction\n\nThis project is a key-value store that runs in a Trusted Execution Environment (TEE) and uses Remote Attestation for Authentication.\nThe key-value store is implemented using Hashicorp Vault running in an Intel SGX enclave via the Gramine runtime.\n\n## Parts of this project\n\n- `teepot`: The main rust crate that abstracts TEEs and key-value stores.\n- `tee-vault-unseal`: An enclave that uses the Vault API to unseal a vault as a proxy.\n- `vault-unseal`: A client utility, that talks to `tee-vault-unseal` to unseal a vault.\n- `tee-vault-admin`: An enclave that uses the Vault API to administer a vault as a proxy.\n- `vault-admin`: A client utility, that talks to `tee-vault-admin` to administer a vault.\n- `teepot-read` : A pre-exec utility that reads from the key-value store and passes the key-value pairs as environment variables to the enclave.\n- `teepot-write` : A pre-exec utility that reads key-values from the environment variables and writes them to the key-value store.\n- `verify-attestation`: A client utility that verifies the attestation of an enclave.\n- `tee-key-preexec`: A pre-exec utility that generates a p256 secret key and passes it as an environment variable to the enclave along with the attestation quote containing the hash of the public key.\n", "release_dates": []}, {"name": "terraform-google-kms", "description": "Simple Cloud KMS module that allows managing a keyring, zero or more keys in the keyring, and IAM role bindings on individual keys.", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Google KMS Terraform Module\n\nSimple Cloud KMS module that allows managing a keyring, zero or more keys in the keyring, and IAM role bindings on individual keys.\n\nThe resources/services/activations/deletions that this module will create/trigger are:\n\n- Create a KMS keyring in the provided project\n- Create zero or more keys in the keyring\n- Create IAM role bindings for owners, encrypters, decrypters\n\n## Compatibility\n\nThis module is meant for use with Terraform 0.12. If you haven't upgraded and need a Terraform 0.11.x-compatible\nversion of this module, the last released version intended for Terraform 0.11.x\nis [v0.1.0](https://registry.terraform.io/modules/terraform-google-modules/kms/google/0.1.0).\n\n## Usage\n\nBasic usage of this module is as follows:\n\n```hcl\nmodule \"kms\" {\n  source  = \"terraform-google-modules/kms/google\"\n  version = \"~> 1.2\"\n\n  project_id         = \"<PROJECT ID>\"\n  location           = \"europe\"\n  keyring            = \"sample-keyring\"\n  keys               = [\"foo\", \"spam\"]\n  set_owners_for     = [\"foo\", \"spam\"]\n  owners = [\n    \"group:one@example.com,group:two@example.com\",\n    \"group:one@example.com\",\n  ]\n}\n```\n\nFunctional examples are included in the\n[examples](./examples/) directory.\n\n<!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->\n## Inputs\n\n| Name | Description | Type | Default | Required |\n|------|-------------|:----:|:-----:|:-----:|\n| decrypters | List of comma-separated owners for each key declared in set_decrypters_for. | list(string) | `<list>` | no |\n| encrypters | List of comma-separated owners for each key declared in set_encrypters_for. | list(string) | `<list>` | no |\n| key\\_algorithm | The algorithm to use when creating a version based on this template. See the https://cloud.google.com/kms/docs/reference/rest/v1/CryptoKeyVersionAlgorithm for possible inputs. | string | `\"GOOGLE_SYMMETRIC_ENCRYPTION\"` | no |\n| key\\_protection\\_level | The protection level to use when creating a version based on this template. Default value: \"SOFTWARE\" Possible values: [\"SOFTWARE\", \"HSM\"] | string | `\"SOFTWARE\"` | no |\n| key\\_rotation\\_period |  | string | `\"100000s\"` | no |\n| keyring | Keyring name. | string | n/a | yes |\n| keys | Key names. | list(string) | `<list>` | no |\n| labels | Labels, provided as a map | map(string) | `<map>` | no |\n| location | Location for the keyring. | string | n/a | yes |\n| owners | List of comma-separated owners for each key declared in set_owners_for. | list(string) | `<list>` | no |\n| prevent\\_destroy | Set the prevent_destroy lifecycle attribute on keys. | string | `\"true\"` | no |\n| project\\_id | Project id where the keyring will be created. | string | n/a | yes |\n| set\\_decrypters\\_for | Name of keys for which decrypters will be set. | list(string) | `<list>` | no |\n| set\\_encrypters\\_for | Name of keys for which encrypters will be set. | list(string) | `<list>` | no |\n| set\\_owners\\_for | Name of keys for which owners will be set. | list(string) | `<list>` | no |\n\n## Outputs\n\n| Name | Description |\n|------|-------------|\n| keyring | Self link of the keyring. |\n| keyring\\_name | Name of the keyring. |\n| keyring\\_resource | Keyring resource. |\n| keys | Map of key name => key self link. |\n\n<!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->\n\n## Requirements\n\nThese sections describe requirements for using this module.\n\n### Software\n\nThe following dependencies must be available:\n\n- [Terraform][terraform] v0.12\n- [Terraform Provider for GCP][terraform-provider-gcp] plugin v3.0\n\n### Service Account\n\nA service account with one of the following roles must be used to provision\nthe resources of this module:\n\n- Cloud KMS Admin: `roles/cloudkms.admin` or\n- Owner: `roles/owner`\n\nThe [Project Factory module][project-factory-module] and the\n[IAM module][iam-module] may be used in combination to provision a\nservice account with the necessary roles applied.\n\n### APIs\n\nA project with the following APIs enabled must be used to host the\nresources of this module:\n\n- Google Cloud Key Management Service: `cloudkms.googleapis.com`\n\nThe [Project Factory module][project-factory-module] can be used to\nprovision a project with the necessary APIs enabled.\n\n## Contributing\n\nRefer to the [contribution guidelines](./CONTRIBUTING.md) for\ninformation on contributing to this module.\n\n[iam-module]: https://registry.terraform.io/modules/terraform-google-modules/iam/google\n[project-factory-module]: https://registry.terraform.io/modules/terraform-google-modules/project-factory/google\n[terraform-provider-gcp]: https://www.terraform.io/docs/providers/google/index.html\n[terraform]: https://www.terraform.io/downloads.html\n", "release_dates": ["2023-08-16T14:38:40Z"]}, {"name": "terraform-google-kubernetes-engine", "description": "Configures opinionated GKE clusters", "language": "HCL", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Terraform Kubernetes Engine Module\n\nThis module handles opinionated Google Cloud Platform Kubernetes Engine cluster creation and configuration with Node Pools, IP MASQ, Network Policy, etc.\nThe resources/services/activations/deletions that this module will create/trigger are:\n- Create a GKE cluster with the provided addons\n- Create GKE Node Pool(s) with provided configuration and attach to cluster\n- Replace the default kube-dns configmap if `stub_domains` are provided\n- Activate network policy if `network_policy` is true\n- Add `ip-masq-agent` configmap with provided `non_masquerade_cidrs` if `configure_ip_masq` is true\n\nSub modules are provided for creating private clusters, beta private clusters, and beta public clusters as well.  Beta sub modules allow for the use of various GKE beta features. See the modules directory for the various sub modules.\n\n## Compatibility\n\nThis module is meant for use with Terraform 0.13+ and tested using Terraform 1.0+.\nIf you find incompatibilities using Terraform `>=0.13`, please open an issue.\n\nIf you haven't [upgraded][terraform-0.13-upgrade] and need a Terraform\n0.12.x-compatible version of this module, the last released version\nintended for Terraform 0.12.x is [12.3.0].\n\n## Usage\nThere are multiple examples included in the [examples](https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/tree/master/examples) folder but simple usage is as follows:\n\n```hcl\n# google_client_config and kubernetes provider must be explicitly specified like the following.\ndata \"google_client_config\" \"default\" {}\n\nprovider \"kubernetes\" {\n  host                   = \"https://${module.gke.endpoint}\"\n  token                  = data.google_client_config.default.access_token\n  cluster_ca_certificate = base64decode(module.gke.ca_certificate)\n}\n\nmodule \"gke\" {\n  source                     = \"terraform-google-modules/kubernetes-engine/google\"\n  project_id                 = \"<PROJECT ID>\"\n  name                       = \"gke-test-1\"\n  region                     = \"us-central1\"\n  zones                      = [\"us-central1-a\", \"us-central1-b\", \"us-central1-f\"]\n  network                    = \"vpc-01\"\n  subnetwork                 = \"us-central1-01\"\n  ip_range_pods              = \"us-central1-01-gke-01-pods\"\n  ip_range_services          = \"us-central1-01-gke-01-services\"\n  http_load_balancing        = false\n  network_policy             = false\n  horizontal_pod_autoscaling = true\n  filestore_csi_driver       = false\n\n  node_pools = [\n    {\n      name                      = \"default-node-pool\"\n      machine_type              = \"e2-medium\"\n      node_locations            = \"us-central1-b,us-central1-c\"\n      min_count                 = 1\n      max_count                 = 100\n      local_ssd_count           = 0\n      spot                      = false\n      disk_size_gb              = 100\n      disk_type                 = \"pd-standard\"\n      image_type                = \"COS_CONTAINERD\"\n      enable_gcfs               = false\n      enable_gvnic              = false\n      auto_repair               = true\n      auto_upgrade              = true\n      service_account           = \"project-service-account@<PROJECT ID>.iam.gserviceaccount.com\"\n      preemptible               = false\n      initial_node_count        = 80\n    },\n  ]\n\n  node_pools_oauth_scopes = {\n    all = [\n      \"https://www.googleapis.com/auth/logging.write\",\n      \"https://www.googleapis.com/auth/monitoring\",\n    ]\n  }\n\n  node_pools_labels = {\n    all = {}\n\n    default-node-pool = {\n      default-node-pool = true\n    }\n  }\n\n  node_pools_metadata = {\n    all = {}\n\n    default-node-pool = {\n      node-pool-metadata-custom-value = \"my-node-pool\"\n    }\n  }\n\n  node_pools_taints = {\n    all = []\n\n    default-node-pool = [\n      {\n        key    = \"default-node-pool\"\n        value  = true\n        effect = \"PREFER_NO_SCHEDULE\"\n      },\n    ]\n  }\n\n  node_pools_tags = {\n    all = []\n\n    default-node-pool = [\n      \"default-node-pool\",\n    ]\n  }\n}\n```\n\n<!-- do not understand what this is about -->\nThen perform the following commands on the root folder:\n\n- `terraform init` to get the plugins\n- `terraform plan` to see the infrastructure plan\n- `terraform apply` to apply the infrastructure build\n- `terraform destroy` to destroy the built infrastructure\n\n<!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->\n## Inputs\n\n| Name | Description | Type | Default | Required |\n|------|-------------|------|---------|:--------:|\n| add\\_cluster\\_firewall\\_rules | Create additional firewall rules | `bool` | `false` | no |\n| add\\_master\\_webhook\\_firewall\\_rules | Create master\\_webhook firewall rules for ports defined in `firewall_inbound_ports` | `bool` | `false` | no |\n| add\\_shadow\\_firewall\\_rules | Create GKE shadow firewall (the same as default firewall rules with firewall logs enabled). | `bool` | `false` | no |\n| authenticator\\_security\\_group | The name of the RBAC security group for use with Google security groups in Kubernetes RBAC. Group name must be in format gke-security-groups@yourdomain.com | `string` | `null` | no |\n| cluster\\_autoscaling | Cluster autoscaling configuration. See [more details](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#clusterautoscaling) | <pre>object({<br>    enabled       = bool<br>    min_cpu_cores = number<br>    max_cpu_cores = number<br>    min_memory_gb = number<br>    max_memory_gb = number<br>    gpu_resources = list(object({ resource_type = string, minimum = number, maximum = number }))<br>    auto_repair   = bool<br>    auto_upgrade  = bool<br>  })</pre> | <pre>{<br>  \"auto_repair\": true,<br>  \"auto_upgrade\": true,<br>  \"enabled\": false,<br>  \"gpu_resources\": [],<br>  \"max_cpu_cores\": 0,<br>  \"max_memory_gb\": 0,<br>  \"min_cpu_cores\": 0,<br>  \"min_memory_gb\": 0<br>}</pre> | no |\n| cluster\\_dns\\_domain | The suffix used for all cluster service records. | `string` | `\"\"` | no |\n| cluster\\_dns\\_provider | Which in-cluster DNS provider should be used. PROVIDER\\_UNSPECIFIED (default) or PLATFORM\\_DEFAULT or CLOUD\\_DNS. | `string` | `\"PROVIDER_UNSPECIFIED\"` | no |\n| cluster\\_dns\\_scope | The scope of access to cluster DNS records. DNS\\_SCOPE\\_UNSPECIFIED (default) or CLUSTER\\_SCOPE or VPC\\_SCOPE. | `string` | `\"DNS_SCOPE_UNSPECIFIED\"` | no |\n| cluster\\_ipv4\\_cidr | The IP address range of the kubernetes pods in this cluster. Default is an automatically assigned CIDR. | `string` | `null` | no |\n| cluster\\_resource\\_labels | The GCE resource labels (a map of key/value pairs) to be applied to the cluster | `map(string)` | `{}` | no |\n| configure\\_ip\\_masq | Enables the installation of ip masquerading, which is usually no longer required when using aliasied IP addresses. IP masquerading uses a kubectl call, so when you have a private cluster, you will need access to the API server. | `bool` | `false` | no |\n| create\\_service\\_account | Defines if service account specified to run nodes should be created. | `bool` | `true` | no |\n| database\\_encryption | Application-layer Secrets Encryption settings. The object format is {state = string, key\\_name = string}. Valid values of state are: \"ENCRYPTED\"; \"DECRYPTED\". key\\_name is the name of a CloudKMS key. | `list(object({ state = string, key_name = string }))` | <pre>[<br>  {<br>    \"key_name\": \"\",<br>    \"state\": \"DECRYPTED\"<br>  }<br>]</pre> | no |\n| datapath\\_provider | The desired datapath provider for this cluster. By default, `DATAPATH_PROVIDER_UNSPECIFIED` enables the IPTables-based kube-proxy implementation. `ADVANCED_DATAPATH` enables Dataplane-V2 feature. | `string` | `\"DATAPATH_PROVIDER_UNSPECIFIED\"` | no |\n| default\\_max\\_pods\\_per\\_node | The maximum number of pods to schedule per node | `number` | `110` | no |\n| description | The description of the cluster | `string` | `\"\"` | no |\n| disable\\_default\\_snat | Whether to disable the default SNAT to support the private use of public IP addresses | `bool` | `false` | no |\n| disable\\_legacy\\_metadata\\_endpoints | Disable the /0.1/ and /v1beta1/ metadata server endpoints on the node. Changing this value will cause all node pools to be recreated. | `bool` | `true` | no |\n| dns\\_cache | The status of the NodeLocal DNSCache addon. | `bool` | `false` | no |\n| enable\\_binary\\_authorization | Enable BinAuthZ Admission controller | `bool` | `false` | no |\n| enable\\_cost\\_allocation | Enables Cost Allocation Feature and the cluster name and namespace of your GKE workloads appear in the labels field of the billing export to BigQuery | `bool` | `false` | no |\n| enable\\_kubernetes\\_alpha | Whether to enable Kubernetes Alpha features for this cluster. Note that when this option is enabled, the cluster cannot be upgraded and will be automatically deleted after 30 days. | `bool` | `false` | no |\n| enable\\_network\\_egress\\_export | Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created in the cluster to meter network egress traffic. | `bool` | `false` | no |\n| enable\\_resource\\_consumption\\_export | Whether to enable resource consumption metering on this cluster. When enabled, a table will be created in the resource export BigQuery dataset to store resource consumption data. The resulting table can be joined with the resource usage table or with BigQuery billing export. | `bool` | `true` | no |\n| enable\\_shielded\\_nodes | Enable Shielded Nodes features on all nodes in this cluster | `bool` | `true` | no |\n| enable\\_vertical\\_pod\\_autoscaling | Vertical Pod Autoscaling automatically adjusts the resources of pods controlled by it | `bool` | `false` | no |\n| filestore\\_csi\\_driver | The status of the Filestore CSI driver addon, which allows the usage of filestore instance as volumes | `bool` | `false` | no |\n| firewall\\_inbound\\_ports | List of TCP ports for admission/webhook controllers. Either flag `add_master_webhook_firewall_rules` or `add_cluster_firewall_rules` (also adds egress rules) must be set to `true` for inbound-ports firewall rules to be applied. | `list(string)` | <pre>[<br>  \"8443\",<br>  \"9443\",<br>  \"15017\"<br>]</pre> | no |\n| firewall\\_priority | Priority rule for firewall rules | `number` | `1000` | no |\n| gateway\\_api\\_channel | The gateway api channel of this cluster. Accepted values are `CHANNEL_STANDARD` and `CHANNEL_DISABLED`. | `string` | `null` | no |\n| gce\\_pd\\_csi\\_driver | Whether this cluster should enable the Google Compute Engine Persistent Disk Container Storage Interface (CSI) Driver. | `bool` | `true` | no |\n| gke\\_backup\\_agent\\_config | Whether Backup for GKE agent is enabled for this cluster. | `bool` | `false` | no |\n| grant\\_registry\\_access | Grants created cluster-specific service account storage.objectViewer and artifactregistry.reader roles. | `bool` | `false` | no |\n| horizontal\\_pod\\_autoscaling | Enable horizontal pod autoscaling addon | `bool` | `true` | no |\n| http\\_load\\_balancing | Enable httpload balancer addon | `bool` | `true` | no |\n| identity\\_namespace | The workload pool to attach all Kubernetes service accounts to. (Default value of `enabled` automatically sets project-based pool `[project_id].svc.id.goog`) | `string` | `\"enabled\"` | no |\n| initial\\_node\\_count | The number of nodes to create in this cluster's default node pool. | `number` | `0` | no |\n| ip\\_masq\\_link\\_local | Whether to masquerade traffic to the link-local prefix (169.254.0.0/16). | `bool` | `false` | no |\n| ip\\_masq\\_resync\\_interval | The interval at which the agent attempts to sync its ConfigMap file from the disk. | `string` | `\"60s\"` | no |\n| ip\\_range\\_pods | The _name_ of the secondary subnet ip range to use for pods | `string` | n/a | yes |\n| ip\\_range\\_services | The _name_ of the secondary subnet range to use for services | `string` | n/a | yes |\n| issue\\_client\\_certificate | Issues a client certificate to authenticate to the cluster endpoint. To maximize the security of your cluster, leave this option disabled. Client certificates don't automatically rotate and aren't easily revocable. WARNING: changing this after cluster creation is destructive! | `bool` | `false` | no |\n| kubernetes\\_version | The Kubernetes version of the masters. If set to 'latest' it will pull latest available version in the selected region. | `string` | `\"latest\"` | no |\n| logging\\_enabled\\_components | List of services to monitor: SYSTEM\\_COMPONENTS, WORKLOADS. Empty list is default GKE configuration. | `list(string)` | `[]` | no |\n| logging\\_service | The logging service that the cluster should write logs to. Available options include logging.googleapis.com, logging.googleapis.com/kubernetes (beta), and none | `string` | `\"logging.googleapis.com/kubernetes\"` | no |\n| maintenance\\_end\\_time | Time window specified for recurring maintenance operations in RFC3339 format | `string` | `\"\"` | no |\n| maintenance\\_exclusions | List of maintenance exclusions. A cluster can have up to three | `list(object({ name = string, start_time = string, end_time = string, exclusion_scope = string }))` | `[]` | no |\n| maintenance\\_recurrence | Frequency of the recurring maintenance window in RFC5545 format. | `string` | `\"\"` | no |\n| maintenance\\_start\\_time | Time window specified for daily or recurring maintenance operations in RFC3339 format | `string` | `\"05:00\"` | no |\n| master\\_authorized\\_networks | List of master authorized networks. If none are provided, disallow external access (except the cluster node IPs, which GKE automatically whitelists). | `list(object({ cidr_block = string, display_name = string }))` | `[]` | no |\n| monitoring\\_enable\\_managed\\_prometheus | Configuration for Managed Service for Prometheus. Whether or not the managed collection is enabled. | `bool` | `false` | no |\n| monitoring\\_enabled\\_components | List of services to monitor: SYSTEM\\_COMPONENTS, WORKLOADS (provider version >= 3.89.0). Empty list is default GKE configuration. | `list(string)` | `[]` | no |\n| monitoring\\_service | The monitoring service that the cluster should write metrics to. Automatically send metrics from pods in the cluster to the Google Cloud Monitoring API. VM metrics will be collected by Google Compute Engine regardless of this setting Available options include monitoring.googleapis.com, monitoring.googleapis.com/kubernetes (beta) and none | `string` | `\"monitoring.googleapis.com/kubernetes\"` | no |\n| name | The name of the cluster (required) | `string` | n/a | yes |\n| network | The VPC network to host the cluster in (required) | `string` | n/a | yes |\n| network\\_policy | Enable network policy addon | `bool` | `false` | no |\n| network\\_policy\\_provider | The network policy provider. | `string` | `\"CALICO\"` | no |\n| network\\_project\\_id | The project ID of the shared VPC's host (for shared vpc support) | `string` | `\"\"` | no |\n| node\\_metadata | Specifies how node metadata is exposed to the workload running on the node | `string` | `\"GKE_METADATA\"` | no |\n| node\\_pools | List of maps containing node pools | `list(map(any))` | <pre>[<br>  {<br>    \"name\": \"default-node-pool\"<br>  }<br>]</pre> | no |\n| node\\_pools\\_labels | Map of maps containing node labels by node-pool name | `map(map(string))` | <pre>{<br>  \"all\": {},<br>  \"default-node-pool\": {}<br>}</pre> | no |\n| node\\_pools\\_linux\\_node\\_configs\\_sysctls | Map of maps containing linux node config sysctls by node-pool name | `map(map(string))` | <pre>{<br>  \"all\": {},<br>  \"default-node-pool\": {}<br>}</pre> | no |\n| node\\_pools\\_metadata | Map of maps containing node metadata by node-pool name | `map(map(string))` | <pre>{<br>  \"all\": {},<br>  \"default-node-pool\": {}<br>}</pre> | no |\n| node\\_pools\\_oauth\\_scopes | Map of lists containing node oauth scopes by node-pool name | `map(list(string))` | <pre>{<br>  \"all\": [<br>    \"https://www.googleapis.com/auth/cloud-platform\"<br>  ],<br>  \"default-node-pool\": []<br>}</pre> | no |\n| node\\_pools\\_resource\\_labels | Map of maps containing resource labels by node-pool name | `map(map(string))` | <pre>{<br>  \"all\": {},<br>  \"default-node-pool\": {}<br>}</pre> | no |\n| node\\_pools\\_tags | Map of lists containing node network tags by node-pool name | `map(list(string))` | <pre>{<br>  \"all\": [],<br>  \"default-node-pool\": []<br>}</pre> | no |\n| node\\_pools\\_taints | Map of lists containing node taints by node-pool name | `map(list(object({ key = string, value = string, effect = string })))` | <pre>{<br>  \"all\": [],<br>  \"default-node-pool\": []<br>}</pre> | no |\n| non\\_masquerade\\_cidrs | List of strings in CIDR notation that specify the IP address ranges that do not use IP masquerading. | `list(string)` | <pre>[<br>  \"10.0.0.0/8\",<br>  \"172.16.0.0/12\",<br>  \"192.168.0.0/16\"<br>]</pre> | no |\n| notification\\_config\\_topic | The desired Pub/Sub topic to which notifications will be sent by GKE. Format is projects/{project}/topics/{topic}. | `string` | `\"\"` | no |\n| project\\_id | The project ID to host the cluster in (required) | `string` | n/a | yes |\n| region | The region to host the cluster in (optional if zonal cluster / required if regional) | `string` | `null` | no |\n| regional | Whether is a regional cluster (zonal cluster if set false. WARNING: changing this after cluster creation is destructive!) | `bool` | `true` | no |\n| registry\\_project\\_ids | Projects holding Google Container Registries. If empty, we use the cluster project. If a service account is created and the `grant_registry_access` variable is set to `true`, the `storage.objectViewer` and `artifactregsitry.reader` roles are assigned on these projects. | `list(string)` | `[]` | no |\n| release\\_channel | The release channel of this cluster. Accepted values are `UNSPECIFIED`, `RAPID`, `REGULAR` and `STABLE`. Defaults to `UNSPECIFIED`. | `string` | `null` | no |\n| remove\\_default\\_node\\_pool | Remove default node pool while setting up the cluster | `bool` | `false` | no |\n| resource\\_usage\\_export\\_dataset\\_id | The ID of a BigQuery Dataset for using BigQuery as the destination of resource usage export. | `string` | `\"\"` | no |\n| service\\_account | The service account to run nodes as if not overridden in `node_pools`. The create\\_service\\_account variable default value (true) will cause a cluster-specific service account to be created. | `string` | `\"\"` | no |\n| service\\_external\\_ips | Whether external ips specified by a service will be allowed in this cluster | `bool` | `false` | no |\n| shadow\\_firewall\\_rules\\_log\\_config | The log\\_config for shadow firewall rules. You can set this variable to `null` to disable logging. | <pre>object({<br>    metadata = string<br>  })</pre> | <pre>{<br>  \"metadata\": \"INCLUDE_ALL_METADATA\"<br>}</pre> | no |\n| shadow\\_firewall\\_rules\\_priority | The firewall priority of GKE shadow firewall rules. The priority should be less than default firewall, which is 1000. | `number` | `999` | no |\n| skip\\_provisioners | Flag to skip all local-exec provisioners. It breaks `stub_domains` and `upstream_nameservers` variables functionality. | `bool` | `false` | no |\n| stub\\_domains | Map of stub domains and their resolvers to forward DNS queries for a certain domain to an external DNS server | `map(list(string))` | `{}` | no |\n| subnetwork | The subnetwork to host the cluster in (required) | `string` | n/a | yes |\n| timeouts | Timeout for cluster operations. | `map(string)` | `{}` | no |\n| upstream\\_nameservers | If specified, the values replace the nameservers taken by default from the node\u2019s /etc/resolv.conf | `list(string)` | `[]` | no |\n| windows\\_node\\_pools | List of maps containing Windows node pools | `list(map(string))` | `[]` | no |\n| zones | The zones to host the cluster in (optional if regional cluster / required if zonal) | `list(string)` | `[]` | no |\n\n## Outputs\n\n| Name | Description |\n|------|-------------|\n| ca\\_certificate | Cluster ca certificate (base64 encoded) |\n| cluster\\_id | Cluster ID |\n| endpoint | Cluster endpoint |\n| gateway\\_api\\_channel | The gateway api channel of this cluster. |\n| horizontal\\_pod\\_autoscaling\\_enabled | Whether horizontal pod autoscaling enabled |\n| http\\_load\\_balancing\\_enabled | Whether http load balancing enabled |\n| identity\\_namespace | Workload Identity pool |\n| instance\\_group\\_urls | List of GKE generated instance groups |\n| location | Cluster location (region if regional cluster, zone if zonal cluster) |\n| logging\\_service | Logging service used |\n| master\\_authorized\\_networks\\_config | Networks from which access to master is permitted |\n| master\\_version | Current master kubernetes version |\n| min\\_master\\_version | Minimum master kubernetes version |\n| monitoring\\_service | Monitoring service used |\n| name | Cluster name |\n| network\\_policy\\_enabled | Whether network policy enabled |\n| node\\_pools\\_names | List of node pools names |\n| node\\_pools\\_versions | Node pool versions by node pool name |\n| region | Cluster region |\n| release\\_channel | The release channel of this cluster |\n| service\\_account | The service account to default running nodes as if not overridden in `node_pools`. |\n| type | Cluster type (regional / zonal) |\n| vertical\\_pod\\_autoscaling\\_enabled | Whether vertical pod autoscaling enabled |\n| zones | List of zones in which the cluster resides |\n\n<!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->\n\n## node_pools variable\n\n> Use this variable for provisioning linux based node pools. For Windows based node pools use [windows_node_pools](#windows\\_node\\_pools-variable)\n\nThe node_pools variable takes the following parameters:\n\n| Name | Description | Default | Requirement |\n| --- | --- | --- | --- |\n| accelerator_count | The number of the guest accelerator cards exposed to this instance | 0 | Optional |\n| accelerator_type | The accelerator type resource to expose to the instance | \" \" | Optional |\n| auto_repair | Whether the nodes will be automatically repaired | true | Optional |\n| autoscaling | Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage | true | Optional |\n| auto_upgrade | Whether the nodes will be automatically upgraded | true (if cluster is regional) | Optional |\n| boot_disk_kms_key | The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. | \" \" | Optional |\n| disk_size_gb | Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB | 100 | Optional |\n| disk_type | Type of the disk attached to each node (e.g. 'pd-standard' or 'pd-ssd') | pd-standard | Optional |\n| effect | Effect for the taint | | Required |\n| enable_gcfs | Google Container File System (gcfs) has to be enabled for image streaming to be active. Needs image_type to be set to COS_CONTAINERD. | false | Optional |\n| enable_gvnic | gVNIC (GVE) is an alternative to the virtIO-based ethernet driver. Needs a Container-Optimized OS node image. | false | Optional |\n| enable_integrity_monitoring | Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created. | true | Optional |\n| enable_secure_boot | Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails. | false | Optional |\n| gpu_partition_size | Size of partitions to create on the GPU | null | Optional |\n| image_type | The image type to use for this node. Note that changing the image type will delete and recreate all nodes in the node pool | COS_CONTAINERD | Optional |\n| initial_node_count | The initial number of nodes for the pool. In regional or multi-zonal clusters, this is the number of nodes per zone. Changing this will force recreation of the resource. Defaults to the value of min_count | \" \" | Optional |\n| key | The key required for the taint | | Required |\n| local_ssd_count | The amount of local SSD disks that will be attached to each cluster node and may be used as a `hostpath` volume or a `local` PersistentVolume.  | 0 | Optional |\n| machine_type | The name of a Google Compute Engine machine type | e2-medium | Optional |\n| min_cpu_platform | Minimum CPU platform to be used by the nodes in the pool. The nodes may be scheduled on the specified or newer CPU platform. | \" \" | Optional |\n| max_count | Maximum number of nodes in the NodePool. Must be >= min_count. Cannot be used with total limits. | 100 | Optional |\n| total_max_count | Total maximum number of nodes in the NodePool. Must be >= min_count. Cannot be used with per zone limits. | null | Optional |\n| max_pods_per_node | The maximum number of pods per node in this cluster | null | Optional |\n| max_surge | The number of additional nodes that can be added to the node pool during an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously. Can be set to 0 or greater. | 1 | Optional |\n| max_unavailable | The number of nodes that can be simultaneously unavailable during an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in parallel. Can be set to 0 or greater. | 0 | Optional |\n| min_count | Minimum number of nodes in the NodePool. Must be >=0 and <= max_count. Should be used when autoscaling is true. Cannot be used with total limits. | 1 | Optional |\n| total_min_count | Total minimum number of nodes in the NodePool. Must be >=0 and <= max_count. Should be used when autoscaling is true. Cannot be used with per zone limits. | null | Optional |\n| name | The name of the node pool |  | Required |\n| node_count | The number of nodes in the nodepool when autoscaling is false. Otherwise defaults to 1. Only valid for non-autoscaling clusters |  | Required |\n| node_locations | The list of zones in which the cluster's nodes are located. Nodes must be in the region of their regional cluster or in the same region as their cluster's zone for zonal clusters. Defaults to cluster level node locations if nothing is specified | \" \" | Optional |\n| node_metadata | Options to expose the node metadata to the workload running on the node | | Optional |\n| preemptible | A boolean that represents whether or not the underlying node VMs are preemptible | false | Optional |\n| spot | A boolean that represents whether the underlying node VMs are spot | false | Optional |\n| service_account | The service account to be used by the Node VMs | \" \" | Optional |\n| tags | The list of instance tags applied to all nodes | | Required |\n| value | The value for the taint | | Required |\n| version | The Kubernetes version for the nodes in this pool. Should only be set if auto_upgrade is false | \" \" | Optional |\n| location_policy | [Location policy](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_node_pool#location_policy) specifies the algorithm used when scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters. | \" \" | Optional |\n| logging_variant | Enables [MAX_THROUGHPUT](https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#throughput) for logging agents. | DEFAULT | Optional |\n\n## windows_node_pools variable\nThe windows_node_pools variable takes the same parameters as [node_pools](#node\\_pools-variable) but is reserved for provisioning Windows based node pools only. This variable is introduced to satisfy a [specific requirement](https://cloud.google.com/kubernetes-engine/docs/how-to/creating-a-cluster-windows#create_a_cluster_and_node_pools) for the presence of at least one linux based node pool in the cluster before a windows based node pool can be created.\n\n\n## Requirements\n\nBefore this module can be used on a project, you must ensure that the following pre-requisites are fulfilled:\n\n1. Terraform and kubectl are [installed](#software-dependencies) on the machine where Terraform is executed.\n2. The Service Account you execute the module with has the right [permissions](#configure-a-service-account).\n3. The Compute Engine and Kubernetes Engine APIs are [active](#enable-apis) on the project you will launch the cluster in.\n4. If you are using a Shared VPC, the APIs must also be activated on the Shared VPC host project and your service account needs the proper permissions there.\n\nThe [project factory](https://github.com/terraform-google-modules/terraform-google-project-factory) can be used to provision projects with the correct APIs active and the necessary Shared VPC connections.\n\n### Software Dependencies\n#### Kubectl\n- [kubectl](https://github.com/kubernetes/kubernetes/releases) 1.9.x\n#### Terraform and Plugins\n- [Terraform](https://www.terraform.io/downloads.html) 0.13+\n- [Terraform Provider for GCP][terraform-provider-google] v4.51\n#### gcloud\nSome submodules use the [terraform-google-gcloud](https://github.com/terraform-google-modules/terraform-google-gcloud) module. By default, this module assumes you already have gcloud installed in your $PATH.\nSee the [module](https://github.com/terraform-google-modules/terraform-google-gcloud#downloading) documentation for more information.\n\n### Configure a Service Account\nIn order to execute this module you must have a Service Account with the\nfollowing project roles:\n- roles/compute.viewer\n- roles/compute.securityAdmin (only required if `add_cluster_firewall_rules` is set to `true`)\n- roles/container.clusterAdmin\n- roles/container.developer\n- roles/iam.serviceAccountAdmin\n- roles/iam.serviceAccountUser\n- roles/resourcemanager.projectIamAdmin (only required if `service_account` is set to `create`)\n\nAdditionally, if `service_account` is set to `create` and `grant_registry_access` is requested, the service account requires the following role on the `registry_project_ids` projects:\n- roles/resourcemanager.projectIamAdmin\n\n### Enable APIs\nIn order to operate with the Service Account you must activate the following APIs on the project where the Service Account was created:\n\n- Compute Engine API - compute.googleapis.com\n- Kubernetes Engine API - container.googleapis.com\n\n[terraform-provider-google]: https://github.com/terraform-providers/terraform-provider-google\n[12.3.0]: https://registry.terraform.io/modules/terraform-google-modules/kubernetes-engine/google/12.3.0\n[terraform-0.13-upgrade]: https://www.terraform.io/upgrade-guides/0-13.html\n", "release_dates": ["2023-03-08T15:14:50Z"]}, {"name": "terraform-google-sql-db", "description": "Creates a Cloud SQL database instance", "language": "HCL", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# terraform-google-sql\n\nterraform-google-sql makes it easy to create Google CloudSQL instance and implement high availability settings.\nThis module consists of the following submodules:\n\n- [mssql](https://github.com/terraform-google-modules/terraform-google-sql-db/tree/master/modules/mssql)\n- [mysql](https://github.com/terraform-google-modules/terraform-google-sql-db/tree/master/modules/mysql)\n- [postgresql](https://github.com/terraform-google-modules/terraform-google-sql-db/tree/master/modules/postgresql)\n\nSee more details in each module's README.\n\n## Compatibility\nThis module is meant for use with Terraform 0.13+ and tested using Terraform 1.0+.\nIf you find incompatibilities using Terraform `>=0.13`, please open an issue.\n\nIf you haven't [upgraded](https://www.terraform.io/upgrade-guides/0-13.html) and need a Terraform\n0.12.x-compatible version of this module, the last released version\nintended for Terraform 0.12.x is [v5.0.0](https://registry.terraform.io/modules/GoogleCloudPlatform/sql-db/google/5.0.0).\n\n## Upgrading\n\nThe current version is 13.X. The following guides are available to assist with upgrades:\n\n- [1.X -> 2.0](./docs/upgrading_to_sql_db_2.0.0.md)\n- [2.X -> 3.0](./docs/upgrading_to_sql_db_3.0.0.md)\n- [3.X -> 4.0](./docs/upgrading_to_sql_db_4.0.0.md)\n- [10.X -> 11.0](./docs/upgrading_to_sql_db_11.0.0.md)\n- [11.X -> 12.0](./docs/upgrading_to_sql_db_12.0.0.md)\n\n## Root module\n\nThe root module has been deprecated. Please switch to using one of the submodules.\n\n## Requirements\n\n### Installation Dependencies\n\n- [Terraform](https://www.terraform.io/downloads.html) >= 1.3.0\n- [terraform-provider-google](https://github.com/terraform-providers/terraform-provider-google) plugin >= v4.45.0\n\nThe following dependency must be available for SQL Server module:\n\n- [Terraform Provider Beta for GCP](https://github.com/terraform-providers/terraform-provider-google-beta) plugin >= v4.45.0\n\n### Configure a Service Account\n\nIn order to execute this module you must have a Service Account with the following:\n\n#### Roles\n\n- Cloud SQL Admin: `roles/cloudsql.admin`\n- Compute Network Admin: `roles/compute.networkAdmin`\n\n### Enable APIs\n\nIn order to operate with the Service Account you must activate the following APIs on the project where the Service Account was created:\n\n- Cloud SQL Admin API: `sqladmin.googleapis.com`\n\nIn order to use Private Service Access, required for using Private IPs, you must activate\nthe following APIs on the project where your VPC resides:\n\n- Cloud SQL Admin API: `sqladmin.googleapis.com`\n- Compute Engine API: `compute.googleapis.com`\n- Service Networking API: `servicenetworking.googleapis.com`\n- Cloud Resource Manager API: `cloudresourcemanager.googleapis.com`\n\n#### Service Account Credentials\n\nYou can pass the service account credentials into this module by setting the following environment variables:\n\n* `GOOGLE_CREDENTIALS`\n* `GOOGLE_CLOUD_KEYFILE_JSON`\n* `GCLOUD_KEYFILE_JSON`\n\nSee more [details](https://www.terraform.io/docs/providers/google/provider_reference.html#configuration-reference).\n\n## Provision Instructions\n\nThis module has no root configuration. A module with no root configuration cannot be used directly.\n\nCopy and paste into your Terraform configuration, insert the variables, and run terraform init :\n\nFor MySQL :\n```\nmodule \"sql-db\" {\n  source  = \"GoogleCloudPlatform/sql-db/google//modules/mysql\"\n  version = \"8.0.0\"\n}\n```\n\nor for PostgreSQL :\n\n```\nmodule \"sql-db\" {\n  source  = \"GoogleCloudPlatform/sql-db/google//modules/postgresql\"\n  version = \"8.0.0\"\n}\n```\n\nor for MSSQL Server :\n\n```\nmodule \"sql-db\" {\n  source  = \"GoogleCloudPlatform/sql-db/google//modules/mssql\"\n  version = \"8.0.0\"\n}\n```\n\n\n## Contributing\n\nRefer to the [contribution guidelines](./CONTRIBUTING.md) for\ninformation on contributing to this module.\n", "release_dates": ["2023-05-09T08:50:36Z"]}, {"name": "test-contract", "description": null, "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "tutorials", "description": null, "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "![Gradient Banner](https://github.com/matter-labs/tutorials/assets/10233439/8efffb9b-ad1f-4bf2-8f73-9cab8f7ccd22)\n\n# zkSync Tutorials\n\nThis repository contains tutorials for developing on zkSync Era.\n\n## Tutorials\n\n| Name                                                | Time-to-complete | Difficulty |\n| --------------------------------------------------- | ---------------- | ---------- |\n| [Cross Chain Governance](./cross-chain/README.md)   | 3-4 Hours        | Moderate   |\n| [Custom Account Abstraction](./custom-aa/README.md) | 3-5 Hours        | Hard       |\n| [Gated NFT](./gated-nft/README.md)                  | 3-5 Hours        | Hard       |\n| [Hello World](./hello-world/README.md)              | 3-4 Hours        | Easy       |\n| [Daily Spend Limit](./spend-limit/README.md)        | 2-4 Hours        | Moderate   |\n\n## Contributing\n\nIf you want to contribute to this repository, please read the [contribution guidelines](./CONTRIBUTING.md).\n\n## License\n\nThis repository is licensed under the [MIT License](./LICENSE).\n\n## Acknowledgements\n\nThanks to the contributors that helped us create these tutorials:\n\n- [vanshwassan](https://github.com/vanshwassan)\n- [porco-rosso-j](https://github.com/porco-rosso-j)\n\n## Support\n\nIf you have any questions, feel free to ask them in our channels:\n\n- [zkSync's Documentation](https://era.zksync.io/docs/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter @zkSync](https://twitter.com/zksync)\n- [Join our Discord Community](https://join.zksync.dev)\n", "release_dates": []}, {"name": "uniswap-v3-proposal", "description": "Code and information to create a proposal to deploy Uniswap v3 on zkSync v2", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Uniswap v3 on zkSync\n\nThis repo contains the script to submit the governance proposal to deploy Uniswap v3 on zkSync.\n\nThe script has been created following the [governance documentation](https://docs.uniswap.org/protocol/guides/governance/liscense-modifications/) and includes a license modification to allow Matter Labs to deploy Uniswap.\n\n## Proposal information\n\nProposal information can be found at the end of the `utils.ts` file, an includes the new license record and the description.\n\nOn-Chain proposal: https://app.uniswap.org/#/vote/2/25\n\n## Prerequisites\n\nThis project requires Node.js and NPM. [Installation guide](https://nodejs.org/en/download/)\n\nInstall all dependencies with `npm i`\n\n## Testing: simulate proposal lifecycle\n\nThe `test/simulate-proposal-process.ts` file simulates the whole lifecycle of the proposal, from sending it, voting, queue and execution.\n\nBefore running the test, rename `.env.example` to `.env` and enter following params:\n\n- `SIGNER` wallet address that will send the proposal. Must have 2.5Mill UNI.\n\n> **Important**: this test runs against an Ethereum mainnet fork from block 15647465. You can change this block in the `hardhat.confg.ts` file.\n\nOnce configured, run `npx hardhat test`, to run the whole lifecycle script. You'll see the progress in the terminal and, if everything goes write you'll see something like this:\n\n```\n....\nProposal executed? :>>  true\n\u2705 All good.\nLicense in ENS now contains text:\n```\n\n## Run script: send the proposal\n\n**To actually send a proposal, you need a wallet with 2.5 million UNI tokens**\n\nBefore running the script to send the proposal, rename `.env.example` to `.env` and enter following params:\n\n- `WALLET_PRIVATE_KEY` wallet **private key** that will sign the transaction to send the proposal. Must have 2.5Mill UNI.\n- `MAINNET_RPC`: and RPC enpoint of the Ethereum mainnet. You can get one from Chainstack/Alchemy/Infura\n\nTo execute the proposal script, run `npm start`. This will execute the script using **ts-node** via `npx` so it'll require you to be online.\n\nYou'll see the progress in the console with a transaction id that you can search in [Etherscan](https://etherscan.io/)\n\n<!-- LICENSE -->\n\n## License\n\nDistributed under the MIT License. See `LICENSE.txt` for more information.\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n", "release_dates": []}, {"name": "v2-testnet-contracts", "description": null, "language": "Solidity", "license": null, "readme": "# zkSync Smart Contracts\n\nzkSync smart contracts. More detailed description to be added soon.\n", "release_dates": []}, {"name": "vault-auth-tee", "description": "Hashicorp Vault plugin for authenticating Trusted Execution Environments (TEE) like SGX enclaves", "language": "Go", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# vault-auth-tee\nTEE remote attestation plugin for Hashicorp Vault\n\n# \u26a0\ufe0f\u2622\ufe0f\u2623\ufe0f WARNING: not yet for production use \u2623\ufe0f\u2622\ufe0f\u26a0\ufe0f\n\n## License\n\nAll of the code is licensed under the Mozilla Public License 2.0 unless otherwise specified.\nMost of the vault plugin code is based on the vault `builtin/credential/cert` plugin. \n\n## Build Setup\n\n```bash\n$ wget -qO - https://download.01.org/intel-sgx/sgx_repo/ubuntu/intel-sgx-deb.key | sudo apt-key add -\n$ sudo bash -c 'echo \"deb [arch=amd64] https://download.01.org/intel-sgx/sgx_repo/ubuntu focal main\" > /etc/apt/sources.list.d/intel-sgx.list'\n$ sudo apt update\n$ sudo apt install -y --no-install-recommends \\\n    libsgx-headers \\\n    libsgx-enclave-common \\\n    libsgx-urts \\\n    libsgx-dcap-quote-verify \\\n    libsgx-dcap-quote-verify-dev\n```\n\n## Configuration\n\n`Create` or `Update` via the `${plugin}/tees/$name` endpoint\n\n```json\n{\n    \"name\": \"TEE_role_name\",\n    \"token_policies\": \"policy1,policy2,...\",\n    \"types\": \"sgx\",\n    \"sgx_mrsigner\": \"298037d88782e022e019b3020745b78aa40ed95c77da4bf7f3253d3a44c4fd7e\",\n    \"sgx_mrenclave\": \"18946b3547d3ca036f4df7b516857e28fd512d69fed3411dc660537912faabf8\",\n    \"sgx_isv_prodid\": 0,\n    \"sgx_min_isv_svn\": 0,\n    \"sgx_allowed_tcb_levels\": \"Ok,ConfigNeeded,OutOfDate,OutOfDateConfigNeeded,SwHardeningNeeded,ConfigAndSwHardeningNeeded\"\n}\n```\n\n* At least one of `sgx_mrsigner` or `sgx_mrenclave` must be set. If both are set, both are used for matching.\n* `sgx_isv_prodid` is optional and defaults to `0`.\n* `sgx_min_isv_svn` is optional and defaults to `0`.\n* `sgx_allowed_tcb_levels` is optional and defaults to `Ok`.\n\n## Authentication\n\n- Client TEE generates a self-signed TLS client certificate\n- Client TEE generates an attestation report, which includes the hash of the public key of the client certificate (in case of SGX, a sha256 sum of the public key)\n- Client TEE fetches all collateral material via e.g. Intel DCAP ([`tee_qv_get_collateral`](https://github.com/intel/SGXDataCenterAttestationPrimitives/blob/4cb5c8b81f126f9aa3ee921d7980a909a9bd676d/QuoteVerification/dcap_quoteverify/inc/sgx_dcap_quoteverify.h#L234-L238))\n- Client TEE sends POST request with a TLS connection using the client certificate\n  to Vault via the `${plugin}/login` endpoint with the name, attestation report and the attestation collateral material\n- An optional challenge can be included in the POST request, which is then included in the attestation report of the vault response\n```json\n{\n    \"name\": \"The name of the TEE role to authenticate against.\",\n    \"quote\": \"The quote Base64 encoded.\",\n    \"collateral\": \"The collateral Json string encoded.\",\n    \"challenge\": \"An optional challenge hex encoded.\"\n}\n```\n\nThe response contains the Vault token and, if a challenge was included,\nthe vault attestation report, which must contain the challenge bytes in the report_data of the quote.\n```json\n{\n    \"auth\": {\n        \"client_token\": \"The Vault token.\",\n        \"....\": \"....\"\n    },\n    \"data\": {\n        \"quote\": \"The vault quote Base64 encoded.\",\n        \"collateral\": \"The vault collateral Json string encoded.\"\n    }\n}\n```\n\n### Collateral Json encoding\n\nSee [sgx_ql_lib_common.h](https://github.com/intel/SGXDataCenterAttestationPrimitives/blob/4cb5c8b81f126f9aa3ee921d7980a909a9bd676d/QuoteGeneration/quote_wrapper/common/inc/sgx_ql_lib_common.h#L202-L227)\n\n```json\n{\n    \"major_version\": uint16,\n    \"minor_version\": uint16,\n    \"tee_type\": uint32,\n    \"pck_crl_issuer_chain\": []byte,\n    \"root_ca_crl\": []byte,\n    \"pck_crl\": []byte,\n    \"tcb_info_issuer_chain\": []byte,\n    \"tcb_info\": []byte,\n    \"qe_identity_issuer_chain\": []byte,\n    \"qe_identity\": []byte\n}\n```", "release_dates": []}, {"name": "vise", "description": "Tools to define and export metrics in Rust libraries and apps", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Vise \u2013 Typesafe Metrics Client and Exporter\n\n[![Build Status](https://github.com/matter-labs/vise/workflows/Rust/badge.svg?branch=main)](https://github.com/matter-labs/vise/actions)\n[![License: MIT OR Apache-2.0](https://img.shields.io/badge/License-MIT%2FApache--2.0-blue)](https://github.com/matter-labs/vise#license)\n![rust 1.66+ required](https://img.shields.io/badge/rust-1.66+-blue.svg?label=Required%20Rust)\n\nThis repository provides a collection of tools to define and export metrics in Rust\nlibraries and applications.\n\n## Overview\n\nThe following crates are included:\n\n- [`vise`](crates/vise) is the client library for typesafe metrics definition\n- [`vise-macros`](crates/vise-macros) is a collection of procedural macros used by `vise`\n- [`vise-exporter`](crates/vise-exporter) is a Prometheus exporter for `vise` metrics\n  supporting pull- and push-based data flows.\n\nFollow the [client library readme](crates/vise/README.md) for an overview of functionality.\n\n## Naming\n\n[Vise](https://en.wikipedia.org/wiki/Vise) is a mechanical tool used to secure an object in place,\nfor example to perform precise measurements on it.\n\n## License\n\nDistributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n", "release_dates": []}, {"name": "vm-benchmarks", "description": null, "language": "TypeScript", "license": null, "readme": "# opcodes usage analytics\njust run next commands\n\n\n```\nyarn install\nyarn opcodes-usage-analytics --nodeUrl ... --txHashes h1,h2,h3\nyarn opcodes-usage-analytics --nodeUrl ... --blockId 112233\n```\n\n\nas nodeUrl can be used https://white-bitter-breeze.quiknode.pro/a53ae019bc2182e0a144c51f8c04a2d6687cecb6/\n\nif this not works find another one\n\nhttps://old-summer-snow.quiknode.pro/6d8caca935e0d827cbd4374472816789d55096da/\n\nhttps://silent-weathered-glade.quiknode.pro/eada7406e79b5d0b29f91de2c7f89a9135036d0e/\n\n**For the blocks from the last 15 min use** https://damp-nameless-star.quiknode.pro/2325ca979d1d392813588dbe45ee90c293b03cf7/.\nThis is necessary because the new blocks were slowly being processed by the standard full Ethereum node.\n", "release_dates": []}, {"name": "vscode-extension", "description": "Hack4Impact's VS Code Extension that provides recommended extensions and templates for quality project development", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<h1 align=\"center\">\n  <br>\n    <a href=\"https://hack4impact.org/\"><img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/rotating-icon.gif\" alt=\"Hack4Impact Icon\" width=\"100\"></a>\n  <br>\n  <b><a href=\"https://hack4impact.org/\">Hack4Impact</a>'s VS Code Recommendations</b>\n</h1>\n<p align=\"center\">\n<a href=\"https://marketplace.visualstudio.com/items?itemName=hack4impact.h4i-recommendations\"><img src=\"https://img.shields.io/visual-studio-marketplace/v/hack4impact.h4i-recommendations?style=flat-square&label=Version&logo=visual-studio-code&logoColor=FFFFFF&labelColor=000000\"alt=\"Version\"></a>\n<a href=\"https://marketplace.visualstudio.com/items?itemName=hack4impact.h4i-recommendations&ssr=false#review-details\"><img src=\"https://img.shields.io/visual-studio-marketplace/r/hack4impact.h4i-recommendations?style=flat-square&label=Rating&logo=visual-studio-code&logoColor=FFFFFF&labelColor=000000\" alt=\"Rating\"></a>\n<a href=\"https://github.com/hack4impact/vscode-extension/actions?query=workflow%3A%22Node+CI%22\"><img src=\"https://img.shields.io/github/workflow/status/hack4impact/vscode-extension/Node%20CI?style=flat-square&label=Build&logo=github&logoColor=FFFFFF&labelColor=000000\" alt=\"Build\"/></a>\n<a href=\"https://lgtm.com/projects/g/hack4impact/vscode-extension/context:javascript\"><img src=\"https://img.shields.io/lgtm/grade/javascript/github/hack4impact/vscode-extension?style=flat-square&label=Code%20Quality&logo=lgtm&logoColor=FFFFFF&labelColor=000000\" alt=\"Code Quality\"/></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://codecov.io/gh/hack4impact/vscode-extension/\"><img src=\"https://img.shields.io/codecov/c/github/hack4impact/vscode-extension?style=flat-square&label=Coverage&logo=Codecov&logoColor=FFFFFF&labelColor=000000\" alt=\"Coverage\"/></a>\n<a href=\"https://hack4impact.github.io/vscode-extension/\"><img src=\"https://img.shields.io/website?url=https%3A%2F%2Fhack4impact.github.io%2Fvscode-extension%2F&style=flat-square&label=Coverage%20Website&logo=github&logoColor=FFFFFF&labelColor=000000\" alt=\"Coverage Website\"/></a>\n</p>\n\nHack4Impact's VS Code Extension that provides recommended extensions and templates for quality project development.\n\nIf you use JetBrains instead, install the [JetBrains plugin](https://github.com/hack4impact/jetbrains-plugin).\n\n## Contents <!-- omit in toc -->\n\n- [Installation](#installation)\n- [Included Extensions](#included-extensions)\n- [Commands](#commands)\n  - [Create Template Files](#create-template-files)\n  - [Create ESLint Configuration Template](#create-eslint-configuration-template)\n  - [Create Prettier Configuration Template](#create-prettier-configuration-template)\n  - [Create MarkdownLint Configuration Template](#create-markdownlint-configuration-template)\n  - [Create EditorConfig Configuration Template](#create-editorconfig-configuration-template)\n  - [Create GitIgnore Template](#create-gitignore-template)\n  - [Create Changelog Template](#create-changelog-template)\n  - [Create License Template](#create-license-template)\n  - [Create CodeOwners Template](#create-codeowners-template)\n- [Configuration](#configuration)\n  - [Keybindings](#keybindings)\n- [Language Support](#language-support)\n- [Contributors](#contributors)\n\n## Installation\n\n1. Open [Hack4Impact's Recommendations - Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=hack4impact.h4i-recommendations)\n2. Click \"Install\"\n\n**OR**\n\n1. Open [Visual Studio Code](https://code.visualstudio.com/)\n2. Open the Extensions View -> (`Shift+Cmd+P` or `F1` and type \"Extensions: Install Extensions\") or (`Shift+Cmd+X`)\n3. Type \"Hack4Impact's Recommendations\"\n4. Click \"Install\"\n\n**OR**\n\n1. Open a command-line prompt\n2. Run `code --install-extension hack4impact.h4i-recommendations`\n\n## Included Extensions\n\n| Name             | Icon                                                                                                                                                   | Links                                                       |\n| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------- |\n| **ESLint**       | <img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/pack-icons/eslint.png\" alt=\"ESLint Icon\" width=\"100\">             | [ESLint - Marketplace]<br>[ESLint - Repository]             |\n| **Prettier**     | <img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/pack-icons/prettier.png\" alt=\"Prettier Icon\" width=\"100\">         | [Prettier - Marketplace]<br>[Prettier - Repository]         |\n| **MarkdownLint** | <img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/pack-icons/markdownlint.png\" alt=\"MarkdownLint Icon\" width=\"100\"> | [MarkdownLint - Marketplace]<br>[MarkdownLint - Repository] |\n| **EditorConfig** | <img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/pack-icons/editorconfig.png\" alt=\"EditorConfig Icon\" width=\"100\"> | [EditorConfig - Marketplace]<br>[EditorConfig - Repository] |\n\n## Commands\n\n### Create Template Files\n\n#### Command Id\n\n`hack4impact.templates.create`\n\n#### Description\n\n- Opens a [Quick Pick] to choose the templates that should be created\n- Shows a [File Picker] Dialog to pick the folder where the templates should be created\n- Creates the templates with Hack4Impact's recommended configuration\n\n#### Demo\n\n<details>\n<summary>Create Template Files Demo</summary>\n\n<img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/demos/create-template-files.gif\" alt=\"Create Template Files Demo\">\n\n</details>\n\n#### Keybinding\n\n- **Mac**: `cmd+h t`\n\n- **Windows/Linux**: `ctrl+h t`\n\n---\n\n### Create ESLint Configuration Template\n\n#### Command Id\n\n`hack4impact.templates.create.ESLintConfig`\n\n#### Description\n\n- Shows a [File Picker] Dialog to pick the folder where a `.eslintrc.json` file should be created\n- Creates a `.eslintrc.json` file with Hack4Impact's recommended configuration\n\n#### Demo\n\n<details>\n<summary>Create ESLint Configuration Template Demo</summary>\n\n<img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/demos/create-eslint-config-template.gif\" alt=\"Create ESLint Configuration Template Demo\">\n\n</details>\n\n#### Keybinding\n\n- **Mac**: `cmd+h e`\n\n- **Windows/Linux**: `ctrl+h e`\n\n---\n\n### Create Prettier Configuration Template\n\n#### Command Id\n\n`hack4impact.templates.create.PrettierConfig`\n\n#### Description\n\n- Shows a [File Picker] Dialog to pick the folder where a `.prettierrc.json` file should be created\n- Creates a `.prettierrc.json` file with Hack4Impact's recommended configuration\n\n#### Demo\n\n<details>\n<summary>Create Prettier Configuration Template Demo</summary>\n\n<img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/demos/create-prettier-config-template.gif\" alt=\"Create Prettier Configuration Template Demo\">\n\n</details>\n\n#### Keybinding\n\n- **Mac**: `cmd+h p`\n\n- **Windows/Linux**: `ctrl+h p`\n\n---\n\n### Create MarkdownLint Configuration Template\n\n#### Command Id\n\n`hack4impact.templates.create.MarkdownLintConfig`\n\n#### Description\n\n- Shows a [File Picker] Dialog to pick the folder where a `.markdownlint.json` file should be created\n- Creates a `.markdownlint.json` file with Hack4Impact's recommended configuration\n\n#### Demo\n\n<details>\n<summary>Create MarkdownLint Configuration Template Demo</summary>\n\n<img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/demos/create-markdownlint-config-template.gif\" alt=\"Create MarkdownLint Configuration Template Demo\">\n\n</details>\n\n#### Keybinding\n\n- **Mac**: `cmd+h m`\n\n- **Windows/Linux**: `ctrl+h m`\n\n---\n\n### Create EditorConfig Configuration Template\n\n#### Command Id\n\n`hack4impact.templates.create.EditorConfigConfig`\n\n#### Description\n\n- Shows a [File Picker] Dialog to pick the folder where a `.editorconfig` file should be created\n- Creates a `.editorconfig` file with Hack4Impact's recommended configuration\n\n#### Demo\n\n<details>\n<summary>Create EditorConfig Configuration Template Demo</summary>\n\n<img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/demos/create-editorconfig-config-template.gif\" alt=\"Create EditorConfig Configuration Template Demo\">\n\n</details>\n\n#### Keybinding\n\n- **Mac**: `cmd+h d`\n\n- **Windows/Linux**: `ctrl+h d`\n\n---\n\n### Create GitIgnore Template\n\n#### Command Id\n\n`hack4impact.templates.create.GitIgnore`\n\n#### Description\n\n- Shows a [File Picker] Dialog to pick the folder where a `.gitignore` file should be created\n- Creates a boilerplate `.gitignore` file\n\n#### Demo\n\n<details>\n<summary>Create GitIgnore Template Demo</summary>\n\n<img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/demos/create-gitignore-template.gif\" alt=\"Create GitIgnore Template Demo\">\n\n</details>\n\n#### Keybinding\n\n- **Mac**: `cmd+h g`\n\n- **Windows/Linux**: `ctrl+h g`\n\n---\n\n### Create Changelog Template\n\n#### Command Id\n\n`hack4impact.templates.create.Changelog`\n\n#### Description\n\n- Shows a [File Picker] Dialog to pick the folder where a `CHANGELOG.md` file should be created\n- Creates a boilerplate `CHANGELOG.md` file\n\n#### Demo\n\n<details>\n<summary>Create Changelog Template Demo</summary>\n\n<img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/demos/create-changelog-template.gif\" alt=\"Create Changelog Template Demo\">\n\n</details>\n\n#### Keybinding\n\n- **Mac**: `cmd+h c`\n\n- **Windows/Linux**: `ctrl+h c`\n\n---\n\n### Create License Template\n\n#### Command Id\n\n`hack4impact.templates.create.License`\n\n#### Description\n\n- Shows a [File Picker] Dialog to pick the folder where a `LICENSE.md` file should be created\n- Creates a boilerplate `LICENSE.md` file\n\n#### Demo\n\n<details>\n<summary>Create License Template Demo</summary>\n\n<img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/demos/create-license-template.gif\" alt=\"Create License Template Demo\">\n\n</details>\n\n#### Keybinding\n\n- **Mac**: `cmd+h l`\n\n- **Windows/Linux**: `ctrl+h l`\n\n---\n\n### Create CodeOwners Template\n\n#### Command Id\n\n`hack4impact.templates.create.CodeOwners`\n\n#### Description\n\n- Shows a [File Picker] Dialog to pick the folder where a `CODEOWNERS` file should be created\n- Creates a boilerplate `CODEOWNERS` file\n\n#### Demo\n\n<details>\n<summary>Create CodeOwners Template Demo</summary>\n\n<img src=\"https://raw.githubusercontent.com/hack4impact/vscode-extension/main/static/demos/create-codeowners-template.gif\" alt=\"Create CodeOwners Template Demo\">\n\n</details>\n\n#### Keybinding\n\n- **Mac**: `cmd+h o`\n\n- **Windows/Linux**: `ctrl+h o`\n\n## Configuration\n\n### Keybindings\n\n#### Disable All\n\n- **Description**: Controls whether all keybindings are disabled\n- **Key**: `hack4impact.recommendations.keybindings.disableAll`\n- **Type**: `boolean`\n- **Default**: `false`\n\n## Language Support\n\nThis extension provides language support and syntax highlighting for the following:\n\n| Language/File | Docs                                                                                                           | Sample                                                                                                   | Source                                                                  |\n| ------------- | -------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------- |\n| `CODEOWNERS`  | [GitHub Docs](https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/about-code-owners) | [Sample `CODEOWNERS` file](https://github.com/python/cpython/blob/master/.github/CODEOWNERS)             | [Jason Nutter's Repo](https://github.com/jasonnutter/vscode-codeowners) |\n| `robots.txt`  | [Google Search Central](https://developers.google.com/search/docs/advanced/robots/intro)                       | [Sample `robots.txt` file](https://github.com/gitlabhq/gitlabhq/blob/master/public/robots.txt)           | [Nixinova's Repo](https://github.com/Nixinova/tmLanguage)               |\n| `_redirects`  | [Netlify Docs](https://docs.netlify.com/routing/redirects/)                                                    | [Sample `_redirects` file](https://github.com/netlify/netlify-cms/blob/master/website/static/_redirects) | [Nixinova's Repo](https://github.com/Nixinova/tmLanguage)               |\n\n## Contributors\n\nProject Contributors ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/YashTotale\"><img src=\"https://avatars.githubusercontent.com/u/30784592?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yash Totale</b></sub></a><br /><a href=\"https://github.com/hack4impact/vscode-extension/commits?author=YashTotale\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-YashTotale\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"https://github.com/hack4impact/vscode-extension/commits?author=YashTotale\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"https://bholmes.dev/\"><img src=\"https://avatars.githubusercontent.com/u/31811199?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>Benjamin Holmes</b></sub></a><br /><a href=\"#mentoring-Holben888\" title=\"Mentoring\">\ud83e\uddd1\u200d\ud83c\udfeb</a> <a href=\"#ideas-Holben888\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#projectManagement-Holben888\" title=\"Project Management\">\ud83d\udcc6</a></td>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/eric-newcomer/\"><img src=\"https://avatars.githubusercontent.com/u/20120289?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>Eric Newcomer</b></sub></a><br /><a href=\"#mentoring-eric-newcomer\" title=\"Mentoring\">\ud83e\uddd1\u200d\ud83c\udfeb</a> <a href=\"#projectManagement-eric-newcomer\" title=\"Project Management\">\ud83d\udcc6</a></td>\n  </tr>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!\n\n<!-- Start Reference Links -->\n\n[prettier - marketplace]: https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode\n[prettier - repository]: https://github.com/prettier/prettier-vscode\n[eslint - marketplace]: https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint\n[eslint - repository]: https://github.com/Microsoft/vscode-eslint\n[markdownlint - marketplace]: https://marketplace.visualstudio.com/items?itemName=DavidAnson.vscode-markdownlint\n[markdownlint - repository]: https://github.com/DavidAnson/vscode-markdownlint\n[editorconfig - marketplace]: https://marketplace.visualstudio.com/items?itemName=EditorConfig.EditorConfig\n[editorconfig - repository]: https://github.com/editorconfig/editorconfig-vscode\n[quick pick]: https://code.visualstudio.com/api/extension-capabilities/common-capabilities#quick-pick\n[file picker]: https://code.visualstudio.com/api/extension-capabilities/common-capabilities#file-picker\n", "release_dates": []}, {"name": "workflow-dispatch", "description": "A GitHub Action for triggering workflows, using the `workflow_dispatch` event", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# GitHub Action for Dispatching Workflows\n\nThis action triggers another GitHub Actions workflow, using the `workflow_dispatch` event.  \nThe workflow must be configured for this event type e.g. `on: [workflow_dispatch]`\n\nThis allows you to chain workflows, the classic use case is have a CI build workflow, trigger a CD release/deploy workflow when it completes. Allowing you to maintain separate workflows for CI and CD, and pass data between them as required.\n\nFor details of the `workflow_dispatch` even see [this blog post introducing this type of trigger](https://github.blog/changelog/2020-07-06-github-actions-manual-triggers-with-workflow_dispatch/)\n\n*Note 1.* The GitHub UI will report flows triggered by this action as \"manually triggered\" even though they have been run programmatically via another workflow and the API\n\n*Note 2.* If you want to reference the target workflow by ID, you will need to list them with the following REST API call `curl https://api.github.com/repos/{{owner}}/{{repo}}/actions/workflows -H \"Authorization: token {{pat-token}}\"`\n\n_This action is a fork of `benc-uk/workflow-dispatch` to add support for waiting for workflow completion._\n\n## Inputs\n### `workflow`\n**Required.** The name or the filename or ID of the workflow to trigger and run.\n\n### `token`\n\n**Required.** A GitHub access token (PAT) with write access to the repo in question. **NOTE.** The automatically provided token e.g. `${{ secrets.GITHUB_TOKEN }}` can not be used, GitHub prevents this token from being able to fire the  `workflow_dispatch` and `repository_dispatch` event. [The reasons are explained in the docs](https://docs.github.com/en/actions/reference/events-that-trigger-workflows#triggering-new-workflows-using-a-personal-access-token).  \n\nThe solution is to manually create a PAT and store it as a secret e.g. `${{ secrets.PERSONAL_TOKEN }}`\n\n### `inputs`\n**Optional.** The inputs to pass to the workflow (if any are configured), this must be a JSON encoded string, e.g. `{ \"myInput\": \"foobar\" }`.\n\nAll values must be strings (even if they are used as booleans or numbers in the triggered workflow). The triggered workflow should use `fromJson` function to get the right type\n\n### `ref`\n**Optional.** The Git reference used with the triggered workflow run. The reference can be a branch, tag, or a commit SHA. If omitted the context ref of the triggering workflow is used. If you want to trigger on pull requests and run the target workflow in the context of the pull request branch, set the ref to `${{ github.event.pull_request.head.ref }}`\n\n### `repo`\n**Optional.** The default behavior is to trigger workflows in the same repo as the triggering workflow, if you wish to trigger in another GitHub repo \"externally\", then provide the owner + repo name with slash between them e.g. `microsoft/vscode`\n\n### `wait-for-completion`\n**Optional.** If `true`, this action will actively poll the workflow run to get the result of the triggered workflow. It is enabled by default. If the triggered workflow fails due to either `failure`, `timed_out` or `cancelled` then the step that has triggered the other workflow will be marked as failed too.\n\n### `wait-for-completion-timeout`\n**Optional.** The time to wait to mark triggered workflow has timed out. The time must be suffixed by the time unit e.g. `10m`. Time unit can be `s` for seconds, `m` for minutes and `h` for hours. It has no effect if `wait-for-completion` is `false`. Default is `1h`\n\n### `wait-for-completion-interval`\n**Optional.** The time to wait between two polls for getting run status. The time must be suffixed by the time unit e.g. `10m`. Time unit can be `s` for seconds, `m` for minutes and `h` for hours. It has no effect if `wait-for-completion` is `false`. Default is `1m`.\n**/!\\ Do not use a value that is too small to avoid `API Rate limit exceeded`**\n\n### `display-worflow-run-url`\n**Optional.** If `true`, it displays in logs the URL of the triggered workflow. It is useful to follow the progress of the triggered workflow. It is enabled by default.\n\n### `display-worflow-run-url-timeout`\n**Optional.** The time to wait for getting the workflow run URL. If the timeout is reached, it doesn't fail and continues. Displaying the workflow URL is just for information purpose. The time must be suffixed by the time unit e.g. `10m`. Time unit can be `s` for seconds, `m` for minutes and `h` for hours. It has no effect if `display-worflow-run-url` is `false`. Default is `10m`\n\n### `display-worflow-run-url-interval`\n**Optional.** The time to wait between two polls for getting workflow run URL. The time must be suffixed by the time unit e.g. `10m`. Time unit can be `s` for seconds, `m` for minutes and `h` for hours. It has no effect if `display-worflow-run-url` is `false`. Default is `1m`.\n**/!\\ Do not use a value that is too small to avoid `API Rate limit exceeded`**\n\n## Outputs\n### `workflow-url`\nThe URL of the workflow run that has been triggered. It may be undefined if the URL couldn't be retrieved (timeout reached) or if `wait-for-completion` and `display-worflow-run-url` are both `false`\n\n### `workflow-conclusion`\nThe result of the triggered workflow. May be one of `success`, `failure`, `cancelled`, `timed_out`, `skipped`, `neutral`, `action_required`. The step in your workflow will fail if the triggered workflow completes with `failure`, `cancelled` or `timed_out`. Other workflow conlusion are considered success.\nOnly available if `wait-for-completion` is `true`\n\n\n## Example usage\n```yaml\n- name: Invoke workflow without inputs. Wait for result\n  uses: aurelien-baudet/workflow-dispatch@v2\n  with:\n    workflow: My Workflow\n    token: ${{ secrets.PERSONAL_TOKEN }}\n```\n\n```yaml\n- name: Invoke workflow without inputs. Don't wait for result\n  uses: aurelien-baudet/workflow-dispatch@v2\n  with:\n    workflow: My Workflow\n    token: ${{ secrets.PERSONAL_TOKEN }}\n    wait-for-completion: false\n```\n\n```yaml\n- name: Invoke workflow with inputs\n  uses: aurelien-baudet/workflow-dispatch@v2\n  with:\n    workflow: Another Workflow\n    token: ${{ secrets.PERSONAL_TOKEN }}\n    inputs: '{ \"message\": \"blah blah\", \"debug\": true }'\n```\n\n```yaml\n- name: Invoke workflow in another repo with inputs\n  uses: aurelien-baudet/workflow-dispatch@v2\n  with:\n    workflow: Some Workflow\n    repo: benc-uk/example\n    token: ${{ secrets.PERSONAL_TOKEN }}\n    inputs: '{ \"message\": \"blah blah\", \"debug\": true }'\n```\n\n```yaml\n- name: Invoke workflow and handle result\n  id: trigger-step\n  uses: aurelien-baudet/workflow-dispatch@v2\n  with:\n    workflow: Another Workflow\n    token: ${{ secrets.PERSONAL_TOKEN }}\n- name: Another step that can handle the result\n  if: always()\n  run: echo \"Another Workflow conclusion: ${{ steps.trigger-step.outputs.workflow-conclusion }}\"\n```\n", "release_dates": []}, {"name": "yubiset", "description": null, "language": "Shell", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# YUBISET  \nA collection of scripts to make OpenPGP key generation and YubiKey manipulation easy. \n\n# What does it do?\n\n- create GPG keys on Yubikey\n- Set user information for Yubikey (name, lang, etc)\n- Set User and Admin PIN for Yubikey\n\n# Table of Contents\n\n- [YUBISET](#yubiset)\n- [What does it do?](#what-does-it-do)\n- [Supported Environments](#supported-environments)\n- [Supported Yubikeys](#supported-yubikeys)\n- [Prerequisites](#prerequisites)\n  * [Linux](#linux)\n  * [Mac](#mac)\n- [Usage](#usage)\n  * [MacOS/Unix](#macos-unix)\n    + [Start here: Key generation & Yubikey setup (all in one script)](#start-here-key-generation--yubikey-setup-all-in-one-script-1)\n      - [Move PGP keys to Yubikey only](#move-pgp-keys-to-yubikey-only-1)\n      - [Reset Yubikey's OpenPGP module](#reset-yubikeys-openpgp-module-1)\n      - [Find Yubikey Slot](#find-yubikey-slot-1)\n- [For Developers](#for-developers)\n  * [Clone with git](#clone-with-git)\n  * [Flush issues](#flush-issues)\n  * [README.md Table of Contents](#readmemd-table-of-contents)\n\n# Supported Environments\n* Unix (Bash)\n\n# Supported Yubikeys\n* Yubikey 5 (firmware >5.2)\n\n# Prerequisites  \nThe only thing you'll need is a working gpg installation:\n\n## Linux  \nUse the *GnuPG* package provided with your distribution or follow the instructions on [https://gnupg.org](https://gnupg.org).\n\n## Mac  \n`brew install gnupg pinentry-mac ykman`\n\n# Usage\n\n## MacOS-Unix\n\n### Start here: Key generation & Yubikey setup (all in one script)\n```\ncd unix/bash\nsh yubiset.sh\n```\n\n\nThe following scripts may be used standalone but are also called from the `yubiset` main script:\n\n#### Move PGP keys to Yubikey only\n```\ncd unix/bash\nsh setupyubi.sh \"Given Name Surname\" \"my.email@provider.com\" \"PGP key id\" \"passphrase\"\n```\nDue to security reasons the passphrase may also be omitted. In this case the user will be prompted to enter it.\n\n#### Reset Yubikey's OpenPGP module\n**BE AWARE:** Only tested with Yubikey 4 NEO and Yubikey 5\n```\ncd unix/bash\nsh resetyubi.sh\n```\n\n#### Find Yubikey Slot\n```\ncd unix/bash\nsh findyubi.sh\n```\n\n### Key Branding  \nIt is possible to \"brand\" your generated keys, i. e. give the user name and the comment a custom touch e. g. for your company. This can be controlled by editing the file `unix/bash/lib/branding.sh`.\n\nThe default will produce a key like this:\n\n```\nsec   rsa4096/0x94AF5E3D1575AC6A 2019-07-01 [C] [expires: 2020-06-30]\n      Key fingerprint = 3B90 7B16 76E6 9F6F 59D1  D103 94AF 5E3D 1575 AC6A\nuid                   [ultimate] Max Muster <max.muster@host.de>\n```\n\nHowever a `branding.sh` like this:\n```\ndeclare -r branded_user_name=\"${user_name} (itemis AG)\"\ndeclare -r branded_user_comment=\"Vocational key of itemis AG's Max Muster\"\n```\nwill produce the following key:\n```\nsec   rsa4096/0x94AF5E3D1575AC6A 2019-07-01 [C] [expires: 2020-06-30]\n      Key fingerprint = 3B90 7B16 76E6 9F6F 59D1  D103 94AF 5E3D 1575 AC6A\nuid                   [ultimate] Max Muster (itemis AG) (Vocational OpenPGP key of itemis AG's Max Muster) <max.muster@host.de>\n```\n\n*Be aware:* GPG does not support arbitrary charaters in key comments. Especially parantheses '(' and ')' will cause problems. Don't use them.\n\n## Flush issues\nBe aware that on some file systems / operating systems generating (log) files may take some time and in order for the gpg-agent and scdaemon to recognize changes it may also take some time, so retrying probes etc. is advised in order to make sure the script does not unnecessarily fail.\n", "release_dates": []}, {"name": "z-prize-msm-gpu", "description": "Submission for https://www.zprize.io/prizes/accelerating-msm-operations-on-gpu-fpga", "language": "Cuda", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Accelerating MSM Operations on GPU/FPGA\n\nThis is a submission for **Z-Prize** category **Accelerating MSM Operations on GPU/FPGA** as\ndefined [here](https://www.zprize.io/prizes/accelerating-msm-operations-on-gpu-fpga).\n\nThis submission was developed by Matter Labs and is available at the following github repository: https://github.com/matter-labs/z-prize-msm-gpu\n\n## Performance\n\nThe runtime for a batch of 4 MSMs of size 2^26 is usually in the area of ***2500 milliseconds*** executing on a single Nvidia A40 GPU.\n\nPerformance can vary quite a bit depending on the physical machine on which the particular VM instance gets provisioned and varies also with a particular GPU in\na machine and other factors like for example temperature.\n\n## Building\n\nThe submission requires the [cuda toolkit](https://developer.nvidia.com/cuda-downloads) and [rustup](https://rustup.rs/)\n\nClone the repository and build using the following commands:\n\n```\ngit clone https://github.com/matter-labs/z-prize-msm-gpu\ncd z-prize-msm-gpu\ncargo build --release\n```\n\n## Running benchmark\n\nRun the benchmark using the following command:\n\n```\ncargo bench\n```\n\n## Running the correctness test\n\nRun the correctness test using the following command:\n\n```\ncargo test --release\n```\n\n## Algorithm outline and description of implemented optimizations\n\n- Workflow is based on the Pippenger algorithm with 23-bit windows\n- One-time pre-computation of the powers of the bases by a factor of 4 is performed allowing the reduction of the number of windows from 11 to 3\n- Initial scalars transfer is split into smaller chunks to allow processing while other scalar parts are still in transfer from host to device memory\n- The scalars array on the host is opportunisticaly pinned on first use, if this behaviour is not desired, it can be disabled by changing the value of the [`REGISTER_SCALARS`](https://github.com/matter-labs/z-prize-msm-gpu/blob/main/src/lib.rs#L19) constant to false\n- Scalars are processed, generating tuples of base-indexes window/bucket indexes\n- The above list is sorted and run length encoded, then a list of offsets is generated based on the list of runs\n- The lists are further sorted based on the run length to enable efficient usage of the GPU hardware\n- Once all the above pre-processing is done, the bucket aggregation is executed, adding bases into their respective buckets\n- After all the buckets have been processed, we employ a reduction algorithm that performs a series of window-splitting steps that leads to single-bit windows\n- The single-bit windows are then gathered and moved to the host where a final single-threaded double-and-add reduction is performed\n- The FF and EC routines have been heavily optimized:\n    - Based on Montgomery multiplication\n    - Minimized correction steps in the FF operations\n    - Use of XYZZ representation for the EC point accumulators\n    - Use of fast squaring\n    - Taking advantage of `reduce(a*b) +/- reduce(c*d)` = `reduce(a*b +/- c*d)` to save reduction steps\n\n## Further possible improvements\n\nThis solution is using CUB routines for sorting, run length encoding and offset calculations.\nWe are aware that CUB is not ideal for this task.\nIt would be beneficial to replace the CUB routines by custom implementations.\nCustom routines should lead to reduction in sorting/encoding runtime and also be better in terms of memory requirements which would in turn lead to further\npossible performance improvements.  \n\n", "release_dates": []}, {"name": "z-prize-msm-gpu-combined", "description": "Combined solution from Matter Labs and Yrrid based on their respective submissions for the Z-Prize category Accelerating MSM Operations on GPU/FPGA", "language": "Cuda", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Z-Prize MSM on the GPU \n\n## Introduction\n\nMatter Labs and Yrrid have joined forces to produce an improved version of MSM for the GPU that takes the best ideas\nand implementations from our separate MSM for the GPU submissions to the ZPrize.   Our improved solution is about 10% \n(240 ms) faster than either of our ZPrize submissions.   The improvements break down as follows:\n- Yrrid's custom scalar/point sorting routines (which are faster than CUB)\n- Yrrid's improved scalar preprocessing/windowing algorithms\n- Matter Lab's significantly faster FF and EC routines in the bucket accumulation phase (saves 150 ms)\n- Matter Lab's idea to break the first set of 2^26 scalars into pieces, which allows for copy and compute overlap (saves 90 ms)\n- We use the main driver routines from Yrrid's solution \n\nThe combined, improved solution is available from two github locations: [Matter Labs](https://github.com/matter-labs/z-prize-msm-gpu-combined)\nand [Yrrid Software](https://github.com/yrrid/combined-msm-gpu).\n\n## Source Directory Structure\n\n| Directory                 | Description                   |\n|---------------------------|-------------------------------|\n| combined-msm              | Top level kernel sources      |\n| combined-msm/ml-ff-ec     | Matter Lab's FF & EC routines |\n| combined-msm/yrrid-ff-ec  | Yrrid's FF & EC routines      |\n\n## Full Run Performance\n\nWe generally observe our running time to be between ***2200 milliseconds*** and ***2300 milliseconds*** for a full run\nof 4 MSMs of size 2^26. Performance is somewhat dependent on other workloads running on the same physical machine and\nthere is some GPU to GPU variation.\n\n## Building and running the submission\n\nInstall [CUDA 11.7](https://developer.nvidia.com/cuda-downloads). Install rust, for example, `rustup install stable`.\nNext clone the repository, and run the benchmark.\n\n```\ngit clone https://github.com/matter-labs/z-prize-msm-gpu-combined\ncd z-prize-msm-gpu-combined\ncargo bench\n```\n\nTo run the correctness test, use the following command. Note, it can take several hours to generate the input points for a full 2^26 run.\n\n```\ncargo test --release\n```\n\n## GPU requiments\n\nWe adopt the same GPU requirements as the ZPrize competition.  The software has been tuned to run a batch a batch of 4 x 2^26 MSMs on the \ntarget GPU, an NVIDIA A40. The solution requires Compute Capability 8.0 (Ampere) and roughly 46 GB (46 x 2^30 bytes) of memory.\n\n## Optimizations in our solution\n\nIn this section, we give a high level overview of the optimizations we have used to accelerate the computation:\n\n- Pippenger bucket algorithm with a 23-bit window.\n- Signed digits. Since 11 windows of 23-bits is exactly 253 bits, we employ the following trick. If the MSB of\n  the scalar is set, we negate the scalar and point, and continue processing normally. This works since:  \n  &nbsp;&nbsp; *(M - s) (-P)* = *-s (-P)* = *s P*\n- Pre-process all of the scalars to generate lists of points to add to each bucket.\n- The lists are further sorted by the number of points in each bucket. This allows the GPU warps to run convergent workloads.\n- For an input point Pi, we precompute 6 points: 2<sup>46</sup> Pi, 2<sup>92</sup> Pi, 2<sup>138</sup>, ..., 2<sup>230</sup> Pi. This allows us to\n  compress our 11 windows down to 2 windows, since, for example, adding Pi to window 4 is the same as adding 2<sup>92</sup> Pi to window 0.\n- The pre-processing sorting routines are custom written and are very fast and efficient. Much faster than CUB based solutions.\n- The FF and EC routines have been heavily optimized:\n    - Based on Montgomery multiplication\n    - Minimize correction steps in the FF operations\n    - Use an XYZZ representation for the EC point accumulators\n    - Use fast squaring\n    - Take advantage of `reduce(a*b) +/- reduce(c*d)` = `reduce(a*b +/- c*d)` to save reduction steps.\n- We break the first MSM of size 2^26 into two MSMs of size 2^24 and 3*2^24. This allows us to hide much of the PCIe copy time for the\n  first set of scalars.\n\n## Questions\n\nFor technical questions about our submission, please contact `rr at matterlabs.dev` and `nemmart at yrrid.com`.\n", "release_dates": []}, {"name": "zinc", "description": "The Zinc language public repository", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# The Zinc language\n\nThe Zinc programming language for Turing-complete smart contracts will be released soon.\n\nPlease, follow our official channels for more information.\n", "release_dates": ["2021-02-08T15:20:33Z", "2021-01-28T11:14:27Z", "2020-12-24T07:51:49Z", "2020-10-28T17:22:32Z", "2020-04-08T07:57:06Z", "2020-04-08T07:55:54Z", "2020-04-08T07:54:41Z", "2020-04-08T07:53:57Z"]}, {"name": "zinc.github.io", "description": "The Zinc circuit book, which corresponds to the version 0.1 of the Zinc language.", "language": "HTML", "license": null, "readme": "# Zinc v0.1 book\n\nThe Zinc circuit book, which corresponds to the version 0.1 of the Zinc language.\n", "release_dates": []}, {"name": "zk-paymaster-dapi-poc", "description": "Using API3's self-funded dAPIs with zkSync Paymaster example to pay gas fee in USDC on zkSync Era.", "language": null, "license": null, "readme": "# Paymaster Tutorial with API3 dAPIs\n\nThis tutorial shows you how to build a custom paymaster that allows users to pay fees with a `mockUSDC` ERC20 token. You will:\n\n- Create a paymaster that will take `mockUSDC` as gas to cover the transaction cost.\n\n- Create the `mockUSDC` token contract and send some tokens to a new wallet.\n\n- Send a `greet` transaction to update the greeting from the newly created wallet via the paymaster. Although the transaction normally requires ETH to pay the gas fee, our paymaster executes the transaction in exchange for the same USDC value.\n\n- Utilize API3 Data Feeds within a paymaster.\n\n## Using API3's self-funded dAPIs with zkSync paymaster example to pay gas fee in USDC on zkSync Era. \n\n[API3\u279a](https://api3.org/) is a collaborative project to deliver traditional API services to smart contract platforms in a decentralized and trust-minimized way. It is governed by a decentralized autonomous organization (DAO), namely the [API3 DAO](https://api3.org/dao).\n\nAPI3 data feeds are known as [dAPIs\u279a](https://docs.api3.org/guides/dapis/subscribing-self-funded-dapis/). These provide access to on-chain data feeds sourced from off-chain first-party oracles owned and operated by API providers themselves. Data feeds are continuously updated by first-party oracles using signed data.\n\nWithin a paymaster, price oracles can be used to provide price data on-chain for execution.\n\n**For this paymaster tutorial, we will use dAPIs to get the price of ETH/USD and USDC/USD datafeeds and use it to calculate gas in USDC value so that users can pay for their transactions with USDC.**\n\n## Project repo\n\nThe tutorial code is available [here](https://github.com/vanshwassan/zk-paymaster-dapi-poc)\n\n## Set up the project\n\n1. We're going to use zkSync CLI to set up an empty project. Install it globally:\n\n```sh\n$ yarn add global zksync-cli@latest\n```\n\n2. After installation, run the following command to create a new project:\n\n```sh\n$ yarn zksync-cli create paymaster-dapi\n```\n\n3. This will create a new zkSync project called `paymaster-dapi` with a basic `Greeter` contract. `cd` into the project directory:\n\n```sh\n$ cd paymaster-dapi\n```\n\n3. Add the project dependencies, including Hardhat, zkSync packages and API3 contracts:\n\n```sh\n$ yarn add -D typescript ts-node ethers@^5.7.2 zksync-web3 hardhat @matterlabs/hardhat-zksync-solc @matterlabs/hardhat-zksync-deploy @matterlabs/zksync-contracts @openzeppelin/contracts @openzeppelin/contracts-upgradeable @api3/contracts dotenv\n```\n\n## Design\n\nFor the sake of simplicity, we will use a modified OpenZeppelin ERC20 implementation. For that, we are going to code a basic ERC20 token `mockUSDC` which will be used to pay for the transactions.\n\n1. Create a new contract `mockUSDC.sol` under `/contracts` directory and add the following code:\n\n```solidity\n// SPDX-License-Identifier: UNLICENSED\n\npragma solidity ^0.8.8;\n\nimport \"@openzeppelin/contracts/token/ERC20/ERC20.sol\";\n\ncontract MyERC20 is ERC20 {\n    uint8 private _decimals;\n\n    constructor(\n        string memory name_,\n        string memory symbol_,\n        uint8 decimals_\n    ) ERC20(name_, symbol_) {\n        _decimals = decimals_;\n    }\n\n    function mint(address _to, uint256 _amount) public returns (bool) {\n        _mint(_to, _amount);\n        return true;\n    }\n\n    function decimals() public view override returns (uint8) {\n        return _decimals;\n    }\n}\n```\n\nUnder contracts, you will find `Greeter.sol`. This is the contract that we will be using to test our paymaster to set a greeting message on-chain.\n\n### Paymaster solidity contract\n\n\n2. We can now create our paymaster contract `MyPaymaster.sol` under `/contracts` directory. It is a custom implementation of the zkSync paymaster contract that uses dAPIs.\n\n- Add the following imports.\n\n```solidity\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\nimport \"@api3/contracts/v0.8/interfaces/IProxy.sol\";\n```\n\n- Inherit `Ownable` and declare the following public variables.\n\n```solidity\ncontract MyPaymaster is IPaymaster, Ownable {\n\n    address public allowedToken;\n    address public USDCdAPIProxy;\n    address public ETHdAPIProxy;\n    uint256 public requiredETH;\n\n}\n```\n\n- Make a `public` `onlyOwner` function to set dAPI proxies.\n\n```solidity\n    // Set dapi proxies for the allowed token/s\n    function setDapiProxy(address _USDCproxy, address _ETHproxy) \n    public onlyOwner {\n        USDCdAPIProxy = _USDCproxy;\n        ETHdAPIProxy = _ETHproxy;\n    }\n```\n\n- Make a `public` `view` function to read the dAPI values. We will use this to read the price of ETH/USD and USDC/USD datafeeds.\n\n```\n    function readDapi(address _dapiProxy) public view returns (uint256) {\n        (int224 value, ) = IProxy(_dapiProxy).read();\n        uint256 price = uint224(value);\n        return price;\n    }\n```\n\n- Under `validateAndPayForPaymasterTransaction()`, we will call the `readDapi()` function and add the logic to calculate the required USDC to be sent by the user.\n\n```solidity\n            // Read values from the dAPIs\n\n            uint256 ETHUSDCPrice = readDapi(ETHdAPIProxy);\n            uint256 USDCUSDPrice = readDapi(USDCdAPIProxy);\n\n            requiredETH = _transaction.gasLimit *\n                _transaction.maxFeePerGas;\n\n            // Calculate the required ERC20 tokens to be sent to the paymaster\n            // (Equal to the value of requiredETH)\n\n            uint256 requiredERC20 = (requiredETH * ETHUSDCPrice)/USDCUSDPrice;\n            require(\n                providedAllowance >= requiredERC20,\n                \"Min paying allowance too low\"\n            );\n```\n\n- Also update the `try catch` block to transfer the `requiredERC20` token from the user to the paymaster that covers the transaction cost.\n\n```solidity\n            try\n                IERC20(token).transferFrom(userAddress, thisAddress, requiredERC20)\n            {} catch (bytes memory revertReason) {\n                // If the revert reason is empty or represented by just a function selector,\n                // we replace the error with a more user-friendly message\n                if (requiredERC20 > amount) {\n                    revert(\"Not the required amount of tokens sent\");\n                }\n                if (revertReason.length <= 4) {\n                    revert(\"Failed to transferFrom from users' account\");\n                } else {\n                    assembly {\n                        revert(add(0x20, revertReason), mload(revertReason))\n                    }\n                }\n            }\n```\n\nHere's the full code for `MyPaymaster.sol` that uses dAPIs. You can copy/paste it directly.\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.8;\n\nimport \"@openzeppelin/contracts/token/ERC20/IERC20.sol\";\n\nimport {IPaymaster, ExecutionResult, PAYMASTER_VALIDATION_SUCCESS_MAGIC} \nfrom  \"@matterlabs/zksync-contracts/l2/system-contracts/interfaces/IPaymaster.sol\";\nimport {IPaymasterFlow} from  \"@matterlabs/zksync-contracts/l2/system-contracts/interfaces/IPaymasterFlow.sol\";\nimport {TransactionHelper, Transaction} from \"@matterlabs/zksync-contracts/l2/system-contracts/libraries/TransactionHelper.sol\";\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\nimport \"@api3/contracts/v0.8/interfaces/IProxy.sol\";\n\nimport \"@matterlabs/zksync-contracts/l2/system-contracts/Constants.sol\";\n\ncontract MyPaymaster is IPaymaster, Ownable {\n\n    address public allowedToken;\n    address public USDCdAPIProxy;\n    address public ETHdAPIProxy;\n    uint256 public requiredETH;\n\n    modifier onlyBootloader() {\n        require(\n            msg.sender == BOOTLOADER_FORMAL_ADDRESS,\n            \"Only bootloader can call this method\"\n        );\n        // Continue execution if called from the bootloader.\n        _;\n    }\n\n    constructor(address _erc20) {\n        allowedToken = _erc20;\n    }\n\n    // Set dapi proxies for the allowed token/s\n    function setDapiProxy(address _USDCproxy, address _ETHproxy) \n    public onlyOwner {\n        USDCdAPIProxy = _USDCproxy;\n        ETHdAPIProxy = _ETHproxy;\n    }\n\n    function readDapi(address _dapiProxy) public view returns (uint256) {\n        (int224 value, ) = IProxy(_dapiProxy).read();\n        uint256 price = uint224(value);\n        return price;\n    }\n\n    function validateAndPayForPaymasterTransaction (\n        bytes32,\n        bytes32,\n        Transaction calldata _transaction\n    ) onlyBootloader external payable returns (bytes4 magic, bytes memory context) {\n        // By default we consider the transaction as accepted.\n        magic = PAYMASTER_VALIDATION_SUCCESS_MAGIC;\n        require(\n            _transaction.paymasterInput.length >= 4,\n            \"The standard paymaster input must be at least 4 bytes long\"\n        );\n\n        bytes4 paymasterInputSelector = bytes4(\n            _transaction.paymasterInput[0:4]\n        );\n        if (paymasterInputSelector == IPaymasterFlow.approvalBased.selector) {\n            // While the transaction data consists of address, uint256 and bytes data,\n            // the data is not needed for this paymaster\n            (address token, uint256 amount, bytes memory data) = abi.decode(\n                _transaction.paymasterInput[4:],\n                (address, uint256, bytes)\n            );\n\n            // Verify if token is the correct one\n            require(token == allowedToken, \"Invalid token\");\n\n            // We verify that the user has provided enough allowance\n            address userAddress = address(uint160(_transaction.from));\n\n            address thisAddress = address(this);\n\n            uint256 providedAllowance = IERC20(token).allowance(\n                userAddress,\n                thisAddress\n            );\n            // Read values from the dAPIs\n\n            uint256 ETHUSDCPrice = readDapi(ETHdAPIProxy);\n            uint256 USDCUSDPrice = readDapi(USDCdAPIProxy);\n\n            requiredETH = _transaction.gasLimit *\n                _transaction.maxFeePerGas;\n\n            // Calculate the required ERC20 tokens to be sent to the paymaster\n            // (Equal to the value of requiredETH)\n\n            uint256 requiredERC20 = (requiredETH * ETHUSDCPrice)/USDCUSDPrice;\n            require(\n                providedAllowance >= requiredERC20,\n                \"Min paying allowance too low\"\n            );\n\n            // Note, that while the minimal amount of ETH needed is tx.gasPrice * tx.gasLimit,\n            // neither paymaster nor account are allowed to access this context variable.\n            try\n                IERC20(token).transferFrom(userAddress, thisAddress, requiredERC20)\n            {} catch (bytes memory revertReason) {\n                // If the revert reason is empty or represented by just a function selector,\n                // we replace the error with a more user-friendly message\n                if (requiredERC20 > amount) {\n                    revert(\"Not the required amount of tokens sent\");\n                }\n                if (revertReason.length <= 4) {\n                    revert(\"Failed to transferFrom from users' account\");\n                } else {\n                    assembly {\n                        revert(add(0x20, revertReason), mload(revertReason))\n                    }\n                }\n            }\n\n            // The bootloader never returns any data, so it can safely be ignored here.\n            (bool success, ) = payable(BOOTLOADER_FORMAL_ADDRESS).call{\n                value: requiredETH\n            }(\"\");\n            require(success, \"Failed to transfer funds to the bootloader\");\n        } else {\n            revert(\"Unsupported paymaster flow\");\n        }\n    }\n\n    function postTransaction  (\n        bytes calldata _context,\n        Transaction calldata _transaction,\n        bytes32,\n        bytes32,\n        ExecutionResult _txResult,\n        uint256 _maxRefundedGas\n    ) onlyBootloader external payable override {\n        // Refunds are not supported yet.\n    }\n\n    receive() external payable {}\n}\n```\n\n## Compile and Deploy the Contracts\n\nThe script below deploys the ERC20 (mockUSDC), Greeter and the Paymaster contract. It also creates an empty wallet and mints 5k `mockUSDC` tokens for the paymaster to use at a later step. It also sends 0.05 eth to the paymaster contract so it can pay for the transactions.\n\nThe script also calls the `setDapiProxy` to set the proxy addresses for the required dAPIs on-chain. It also sets the `greeting`.\n\n1. Create the file `deploy-paymaster.ts` under `deploy` and copy/paste the following:\n\n```ts\nimport { utils, Wallet } from \"zksync-web3\";\nimport * as ethers from \"ethers\";\nimport { HardhatRuntimeEnvironment } from \"hardhat/types\";\nimport { Deployer } from \"@matterlabs/hardhat-zksync-deploy\";\n\nrequire('dotenv').config();\n\nexport default async function (hre: HardhatRuntimeEnvironment) {\n  // The wallet that will deploy the token and the paymaster\n  // It is assumed that this wallet already has sufficient funds on zkSync\n  // \u26a0\ufe0f Never commit private keys to file tracking history, or your account could be compromised.\n\n  const wallet = new Wallet(process.env.PRIVATE_KEY);\n  // The wallet that will receive ERC20 tokens\n  const emptyWallet = Wallet.createRandom();\n  console.log(`Empty wallet's address: ${emptyWallet.address}`);\n  console.log(`Empty wallet's private key: ${emptyWallet.privateKey}`);\n\n  const deployer = new Deployer(hre, wallet);\n\n  // Deploying the ERC20 token\n  const erc20Artifact = await deployer.loadArtifact(\"MyERC20\");\n  const erc20 = await deployer.deploy(erc20Artifact, [\"USDC\", \"USDC\", 18]);\n  console.log(`ERC20 address: ${erc20.address}`);\n\n  // Deploying the paymaster\n  const paymasterArtifact = await deployer.loadArtifact(\"MyPaymaster\");\n  const paymaster = await deployer.deploy(paymasterArtifact, [erc20.address]);\n  console.log(`Paymaster address: ${paymaster.address}`);\n\n  // Supplying paymaster with ETH.\n  await (\n    await deployer.zkWallet.sendTransaction({\n      to: paymaster.address,\n      value: ethers.utils.parseEther(\"0.05\"),\n    })\n  ).wait();\n\n  // Setting the dAPIs in Paymaster. Head over to the API3 Market (https://market.api3.org) to verify dAPI proxy contract addresses and whether they're funded or not.\n    const ETHUSDdAPI = \"0x28ce555ee7a3daCdC305951974FcbA59F5BdF09b\";\n    const USDCUSDdAPI = \"0x946E3232Cc18E812895A8e83CaE3d0caA241C2AB\";\n  const setProxy = paymaster.setDapiProxy(USDCUSDdAPI, ETHUSDdAPI)\n  await (await setProxy).wait()\n  console.log(\"dAPI Proxies Set!\")\n\n  // Deploying the Greeter contract\n  const greeterContractArtifact = await deployer.loadArtifact(\"Greeter\");\n  const oldGreeting = \"old greeting\"\n  const deployGreeter = await deployer.deploy(greeterContractArtifact, [oldGreeting]);\n  console.log(`Greeter contract address: ${deployGreeter.address}`);\n\n  // Supplying the ERC20 tokens to the empty wallet:\n  await // We will give the empty wallet 5k mUSDC:\n  (await erc20.mint(emptyWallet.address, \"5000000000000000000000\")).wait();\n\n  console.log(\"Minted 5k mUSDC for the empty wallet\");\n\n  console.log(`Done!`);\n}\n```\n\n2. Create a `.env` file and add your private key:\n\n```sh\n$ echo 'PRIVATE_KEY=' > .env\n```\n\n3. Compile and deploy the contracts from the project root:\n\n```sh\nyarn hardhat compile\nyarn hardhat deploy-zksync --script deploy-paymaster.ts\n```\n\nThe output should be like this (Your values will be different):\n\n```\nEmpty wallet's address: 0xcc7527d2DCb86e5327C494b323af502aEFd76831\nEmpty wallet's private key: 0x1d79f139605b82f3597654f274273220514ec0994fabd9f205a0a56e907d14a5\nERC20 address: 0x4CbBd2FB4700a19A19d3be5b19609f8cA6187980\nPaymaster address: 0x991c592Cfc34406746b59eBA26E3D8e6f40c28bb\ndAPI Proxies Set!\nGreeter contract address: 0xbCC6aF86Ca5BAFedDDe922a64765Cbb438698C57\nMinted 5k mUSDC for the empty wallet\nDone!\n```\n\n4. Edit the `.env` file again to populate the following variables from the output:\n\n```\nPRIVATE_KEY=\nPAYMASTER_ADDRESS=\nTOKEN_ADDRESS=\nEMPTY_WALLET_PRIVATE_KEY=\nGREETER_CONTRACT=\n```\n\n:::tip\n* Addresses and private keys are different on each run.\n* Make sure you delete the `artifacts-zk` and `cache-zk` folders before recompiling.\n:::\n\n## Using the paymaster\n\n1. Create the `use-paymaster.ts` script in the `deploy` folder. \n\n```ts\nimport { ContractFactory, Provider, utils, Wallet } from \"zksync-web3\";\nimport * as ethers from \"ethers\";\nimport { HardhatRuntimeEnvironment } from \"hardhat/types\";\nimport { Deployer } from \"@matterlabs/hardhat-zksync-deploy\";\nimport { getDeployedContracts } from \"zksync-web3/build/src/utils\";\n\nrequire(\"dotenv\").config();\n\n// Put the address of the deployed paymaster and the Greeter Contract in the .env file\nconst PAYMASTER_ADDRESS = process.env.PAYMASTER_ADDRESS;\nconst GREETER_CONTRACT_ADDRESS = process.env.GREETER_CONTRACT;\n\n// Put the address of the ERC20 token in the .env file:\nconst TOKEN_ADDRESS = process.env.TOKEN_ADDRESS;\n\nfunction getToken(hre: HardhatRuntimeEnvironment, wallet: Wallet) {\n  const artifact = hre.artifacts.readArtifactSync(\"MyERC20\");\n  return new ethers.Contract(TOKEN_ADDRESS, artifact.abi, wallet);\n}\n\n// Greeter contract\nfunction getGreeter(hre: HardhatRuntimeEnvironment, wallet: Wallet) {\n  const artifact = hre.artifacts.readArtifactSync(\"Greeter\");\n  return new ethers.Contract(GREETER_CONTRACT_ADDRESS, artifact.abi, wallet);\n}\n\n// Wallet private key\n// \u26a0\ufe0f Never commit private keys to file tracking history, or your account could be compromised.\nconst EMPTY_WALLET_PRIVATE_KEY = process.env.EMPTY_WALLET_PRIVATE_KEY;\nexport default async function (hre: HardhatRuntimeEnvironment) {\n    const provider = new Provider(\"https://testnet.era.zksync.dev\");\n    const emptyWallet = new Wallet(EMPTY_WALLET_PRIVATE_KEY, provider);\n\n  // Obviously this step is not required, but it is here purely to demonstrate that indeed the wallet has no ether.\n  const ethBalance = await emptyWallet.getBalance();\n    if (!ethBalance.eq(0)) {\n      throw new Error(\"The wallet is not empty\");\n    }\n\n  const erc20Balance = await emptyWallet.getBalance(TOKEN_ADDRESS);\n  console.log(`ERC20 balance of the user before tx: ${erc20Balance}`);\n\n  const greeter = getGreeter(hre, emptyWallet);\n  const erc20 = getToken(hre, emptyWallet);\n\n  const gasPrice = await provider.getGasPrice();\n\n  // Loading the Paymaster Contract\n  const deployer = new Deployer(hre, emptyWallet);\n  const paymasterArtifact = await deployer.loadArtifact(\"MyPaymaster\");\n\n  const PaymasterFactory = new ContractFactory(\n    paymasterArtifact.abi,\n    paymasterArtifact.bytecode,\n    deployer.zkWallet\n  );\n  const PaymasterContract = PaymasterFactory.attach(PAYMASTER_ADDRESS);\n\n  // Estimate gas fee for the transaction\n  const gasLimit = await greeter.estimateGas.setGreeting(\n    \"new updated greeting\",\n    {\n      customData: {\n        gasPerPubdata: utils.DEFAULT_GAS_PER_PUBDATA_LIMIT,\n        paymasterParams: utils.getPaymasterParams(PAYMASTER_ADDRESS, {\n          type: \"ApprovalBased\",\n          token: TOKEN_ADDRESS,\n          // Set a large allowance just for estimation\n          minimalAllowance: ethers.BigNumber.from(`100000000000000000000`),\n          // Empty bytes as testnet paymaster does not use innerInput\n          innerInput: new Uint8Array(),\n        }),\n      },\n    }\n  );\n\n  // Gas estimation:\n  const fee = gasPrice.mul(gasLimit.toString());\n  console.log(`Estimated ETH FEE (gasPrice * gasLimit): ${fee}`);\n\n  // Calling the dAPI to get the ETH price:\n  const ETHUSD = await PaymasterContract.readDapi(\n    \"0x28ce555ee7a3daCdC305951974FcbA59F5BdF09b\"\n  );\n  const USDCUSD = await PaymasterContract.readDapi(\n    \"0x946E3232Cc18E812895A8e83CaE3d0caA241C2AB\"\n  );\n\n  // Checks old allowance (for testing purposes):\n  const checkSetAllowance = await erc20.allowance(\n    emptyWallet.address,\n    PAYMASTER_ADDRESS\n  );\n  console.log(`ERC20 allowance for paymaster : ${checkSetAllowance}`);\n\n  console.log(`ETH/USD dAPI Value: ${ETHUSD}`);\n  console.log(`USDC/USD dAPI Value: ${USDCUSD}`);\n\n  // Calculating the USD fee:\n  const usdFee = fee.mul(ETHUSD).div(USDCUSD);\n  console.log(`Estimated USD FEE: ${usdFee}`);\n\n  console.log(`Current message is: ${await greeter.greet()}`);\n\n  // Encoding the \"ApprovalBased\" paymaster flow's input\n  const paymasterParams = utils.getPaymasterParams(PAYMASTER_ADDRESS, {\n    type: \"ApprovalBased\",\n    token: TOKEN_ADDRESS,\n    // set minimalAllowance to the estimated fee in erc20\n    minimalAllowance: ethers.BigNumber.from(usdFee),\n    // empty bytes as testnet paymaster does not use innerInput\n    innerInput: new Uint8Array(),\n  });\n\n  await (\n    await greeter\n      .connect(emptyWallet)\n      .setGreeting(`new greeting updated at ${new Date().toUTCString()}`, {\n        // specify gas values\n        maxFeePerGas: gasPrice,\n        maxPriorityFeePerGas: 0,\n        gasLimit: gasLimit,\n        // paymaster info\n        customData: {\n          paymasterParams: paymasterParams,\n          gasPerPubdata: utils.DEFAULT_GAS_PER_PUBDATA_LIMIT,\n        },\n      })\n  ).wait();\n\n  const newErc20Balance = await emptyWallet.getBalance(TOKEN_ADDRESS);\n\n  console.log(`ERC20 Balance of the user after tx: ${newErc20Balance}`);\n  console.log(\n    `Transaction fee paid in ERC20 was ${erc20Balance.sub(newErc20Balance)}`\n  );\n  console.log(`Message in contract now is: ${await greeter.greet()}`);\n}\n```\n\n2. Run the script:\n\n```sh\nyarn hardhat deploy-zksync --script use-paymaster.ts\n```\n\nThe output should look something like this:\n\n```\nERC20 balance of the user before tx: 5000000000000000000000\nEstimated ETH FEE (gasPrice * gasLimit): 586134250000000\nERC20 allowance for paymaster : 0\nETH/USD dAPI Value: 1829590000000000000000\nUSDC/USD dAPI Value: 999957462579468500\nEstimated USD FEE: 1072430980905125770\nCurrent message is: old greeting\nERC20 Balance of the user after tx: 4998927569019094874230\nTransaction fee paid in ERC20 was 1072430980905125770\nMessage in contract now is: new greeting updated at Thu, 18 May 2023 07:40:22 GMT\n```\n\nThe wallet had 5000 mUSDC after running the deployment script. After sending the transaction to update the `Greeting` contract, we are now left with 4998.92 mUSDC. The script used mUSDC to cover the gas costs for the update transaction.", "release_dates": []}, {"name": "zkcli-block-explorer", "description": "zkSync Block Explorer module for zkcli", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": ["2024-02-22T14:13:33Z", "2024-01-13T23:35:46Z", "2024-01-13T23:21:52Z", "2024-01-08T16:36:19Z", "2024-01-08T16:33:22Z", "2024-01-08T16:31:02Z", "2023-12-01T10:22:55Z", "2023-11-21T20:44:40Z", "2023-10-17T16:17:13Z", "2023-10-17T10:45:46Z", "2023-10-16T14:10:36Z", "2023-10-16T13:30:04Z", "2023-10-13T15:37:24Z", "2023-10-13T13:15:59Z", "2023-10-10T12:17:47Z", "2023-10-10T12:04:59Z"]}, {"name": "zkcli-dockerized-node", "description": "zkSync Dockerized node module for zkcli", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": ["2024-01-13T23:04:50Z", "2023-12-01T10:23:28Z", "2023-12-01T10:21:53Z", "2023-12-01T09:18:58Z", "2023-11-21T21:55:15Z", "2023-10-16T13:43:51Z", "2023-10-13T14:47:09Z", "2023-10-03T11:06:29Z", "2023-09-29T16:23:32Z", "2023-09-29T13:20:15Z"]}, {"name": "zkcli-dummy-module", "description": "zkSync Dummy test/example module for zkcli", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": ["2024-01-13T23:05:47Z", "2023-12-01T10:22:16Z", "2023-12-01T10:19:49Z", "2023-10-03T11:06:56Z", "2023-10-02T13:19:23Z"]}, {"name": "zkcli-in-memory-node", "description": "zkSync In-memory node module for zkcli", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": ["2024-01-13T23:05:33Z", "2023-12-01T10:23:16Z", "2023-12-01T10:21:27Z", "2023-12-01T09:17:05Z", "2023-10-03T11:13:12Z", "2023-09-29T12:12:28Z"]}, {"name": "zkcli-portal", "description": "zkSync Portal module for zkcli", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": ["2024-01-13T23:05:44Z", "2023-12-01T13:36:23Z", "2023-10-03T11:06:42Z", "2023-09-29T13:20:09Z"]}, {"name": "zkfoundry-smoke-test", "description": null, "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkfoundry-smoke-test\n\n\nThis repository contains smoke tests for `zkfoundry`, ensuring that the functionality remains robust and does not regress through changes. These tests serve as an early warning mechanism to catch issues that could affect the zk features of `foundry-zksync`.\n\n## Getting Started\n\nTo run the smoke tests on your local environment, follow these steps:\n\n### Prerequisites\n\n- Ensure you have a compatible version of [Rust](https://www.rust-lang.org/tools/install) installed.\n- Clone the [`foundry-zksync`](https://github.com/matter-labs/foundry-zksync) repository and ensure it is up to date and built.\n\n### Installation\n\n1. Clone the `zkfoundry-smoke-test` repository:\n   ```bash\n   git clone https://github.com/your-org/zkfoundry-smoke-test.git\n   cd zkfoundry-smoke-test\n   ```\n\n2. Run against `foundry-zksync`\n   ```bash\n   zkforge zkbuild && zkforge test\n   ```\n\n## Contributing\n\nContributions to the `zkfoundry-smoke-test` suite are welcome. \n\nBefore submitting PRs, please read the `CONTRIBUTING.md` file.\n\n## License\n\nThis project is licensed under the [MIT License](LICENSE). For more details, see the `LICENSE` file in the root of the repository.", "release_dates": []}, {"name": "zksolc-bin", "description": "This repository contains current and historical builds of the zkEVM Solidity Compiler. ", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zksolc-bin\n\nThis repository contains current and historical builds of the zkEVM Solidity Compiler.\n\n[Compiler changelog](https://github.com/matter-labs/era-compiler-solidity/blob/-/CHANGELOG.md)\n\n## Troubleshooting \n- The binary may need to have its executable bit set:\n \n```chmod a+x <path to file>```\n\n- On macOS, the binary may need to have its quarantine attribute cleared: \n\n```xattr -d com.apple.quarantine <path to file>```\n", "release_dates": ["2024-02-21T14:28:23Z", "2024-02-14T19:39:55Z", "2024-01-12T21:41:34Z", "2024-01-05T13:26:20Z", "2023-12-18T15:47:43Z", "2023-12-06T09:49:45Z", "2023-11-13T14:28:08Z", "2023-10-28T17:07:11Z", "2023-09-06T11:05:01Z", "2023-09-06T11:10:37Z", "2023-09-06T11:11:43Z", "2023-09-06T11:12:32Z", "2023-09-06T11:14:50Z", "2023-09-06T11:16:04Z", "2023-09-06T11:17:31Z", "2023-09-06T11:18:14Z", "2023-09-06T11:19:02Z", "2023-09-06T11:19:47Z", "2023-09-06T11:22:58Z", "2023-09-06T11:24:53Z"]}, {"name": "zksolc-prerelease", "description": "Repository with unstable prereleases of zkEVM compiler", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zksolc prereleases\n\nRepository with unstable prereleases of zkEVM compiler. Binaries in this repo are for internal/testing use only and should not be used by outside users reliably.\n\nFor stable releases of zksolc, please refer to [zksolc-bin](https://github.com/matter-labs/zksolc-bin) repo.\n", "release_dates": []}, {"name": "zksync", "description": "zkSync: trustless scaling and privacy engine for Ethereum", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync: scaling and privacy engine for Ethereum\n\n[![Logo](zkSyncLogo.svg)](https://zksync.io/)\n\n[![Live on Mainnet](https://img.shields.io/badge/wallet-Live%20on%20Mainnet-blue)](https://wallet.zksync.io)\n[![Live on Rinkeby](https://img.shields.io/badge/wallet-Live%20on%20Rinkeby-blue)](https://rinkeby.zksync.io)\n[![Live on Ropsten](https://img.shields.io/badge/wallet-Live%20on%20Ropsten-blue)](https://ropsten.zksync.io)\n\nzkSync is a scaling and privacy engine for Ethereum. Its current functionality scope includes low gas transfers of ETH\nand ERC20 tokens in the Ethereum network.\n\n## Description\n\nzkSync is built on ZK Rollup architecture. ZK Rollup is an L2 scaling solution in which all funds are held by a smart\ncontract on the mainchain, while computation and storage are performed off-chain. For every Rollup block, a state\ntransition zero-knowledge proof (SNARK) is generated and verified by the mainchain contract. This SNARK includes the\nproof of the validity of every single transaction in the Rollup block. Additionally, the public data update for every\nblock is published over the mainchain network in the cheap calldata.\n\nThis architecture provides the following guarantees:\n\n- The Rollup validator(s) can never corrupt the state or steal funds (unlike Sidechains).\n- Users can always retrieve the funds from the Rollup even if validator(s) stop cooperating because the data is\n  available (unlike Plasma).\n- Thanks to validity proofs, neither users nor a single other trusted party needs to be online to monitor Rollup blocks\n  in order to prevent fraud.\n\nIn other words, ZK Rollup strictly inherits the security guarantees of the underlying L1.\n\nTo learn how to use zkSync, please refer to the [zkSync SDK documentation](https://zksync.io/api/sdk/).\n\n## Development Documentation\n\nThe following guides for developers are available:\n\n- Installing development dependencies: [docs/setup-dev.md](docs/setup-dev.md).\n- Launching zkSync locally: [docs/launch.md](docs/launch.md).\n- Development guide: [docs/development.md](docs/development.md).\n- Repository architecture overview: [docs/architecture.md](docs/architecture.md).\n\n## Projects\n\n- [zkSync server](core/bin/server)\n- [zkSync prover](core/bin/prover)\n- [JavaScript SDK](sdk/zksync.js)\n- [Rust SDK](sdk/zksync-rs)\n\n## Changelog\n\nSince the repository is big and is split into independent components, there is a different changelog for each of its\nmajor parts:\n\n- [Smart contracts](changelog/contracts.md)\n- [Core](changelog/core.md)\n- [Infrastructure](changelog/infrastructure.md)\n- [JavaScript SDK](changelog/js-sdk.md)\n- [Rust SDK](changelog/rust-sdk.md)\n\n## License\n\nzkSync is distributed under the terms of both the MIT license and the Apache License (Version 2.0).\n\nSee [LICENSE-APACHE](LICENSE-APACHE), [LICENSE-MIT](LICENSE-MIT) for details.\n", "release_dates": ["2021-11-12T14:27:35Z", "2021-08-25T08:13:48Z", "2021-07-20T09:12:01Z", "2019-08-28T08:15:34Z"]}, {"name": "zkSync-account-abstraction-template", "description": null, "language": null, "license": null, "readme": "# zkSync-account-abstraction-template\nAre you interested to explore the zkSync Era Account Abstraction native implementation? You're in the right place. Find below the developer resources around account abstraction, and we welcome all of you who are interested to add more tutorials, examples around account abstractions in this repo. \n\n## Account Abstraction Tutorials\n\nFirst things first, lets [on-board you to zkSync Era](https://github.com/matter-labs/zksync-starting-template) (soon to be public).\n\n1. Daily Spend Limit on [docs](https://era.zksync.io/docs/dev/tutorials/aa-daily-spend-limit.html), and on [GitHub](https://github.com/matter-labs/daily-spendlimit-tutorial)\n2. Building a custom paymaster, on [docs](https://era.zksync.io/docs/dev/tutorials/custom-paymaster-tutorial.html), and on [GitHub](https://github.com/matter-labs/custom-paymaster-tutorial)\n3. Account abstraction multisig, on [docs](https://era.zksync.io/docs/dev/tutorials/custom-aa-tutorial.html), and on [GitHub](https://github.com/matter-labs/custom-aa-tutorial)\n\n## Account Abstraction YouTube Presentations/Workshops\n\n1. [zkSync x LearnWeb3 DAO Account Abstraction on zkSync](https://www.youtube.com/watch?v=M8p5ucnOH5E)\n\n## More [zkSync Era Developer Resources](https://www.notion.so/matterlabs/zkSync-Era-Developer-Library-39300122639f459baf57f7880cce4fa9?pvs=4)\n\n## Community Contribution for Account Abstraction\n\nIf you're attending an Account Abstraction hackathon or hackerhouse, and want to contribute your experience by writing tutorials, building examples using Account Abstraction implementation from zkSync, this is the place to do it.\n\n### Workflow\n1. Star and fork this repo first.\n2. Open a PR with your project.\n3. DevRel team from zkSync Era will review it, and\n4. You might become eligible for a couple of next steps [TBA].\n5. Questions? Join our [Discord](https://join.zksync.dev/)\n", "release_dates": []}, {"name": "zksync-cli", "description": "CLI tool that simplifies zkSync development", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<div align=\"center\">\n\n# \u2023 zkSync CLI \n\n![zkSync CLI](./zksync-cli-banner.png)\n\nThis CLI tool simplifies the process of developing applications and interacting with zkSync.\n\n[Documentation](https://era.zksync.io/docs/tools/zksync-cli) | [Report a bug](https://github.com/matter-labs/zksync-cli/issues/new) | [Request a feature](https://github.com/matter-labs/zksync-cli/issues/new)\n\n[pr-welcome]: https://img.shields.io/static/v1?color=indigo&label=PRs&style=flat&message=welcome\n\n</div>\n\n## Table of Contents\n\n- [Prerequisites](#-prerequisites)\n- [Usage](#-usage)\n- [Commands List](#-commands)\n  - [Local Development](#local-development-commands)\n  - [Create Project](#create-project-commands)\n  - [Contract Interaction](#contract-interaction-commands)\n  - [Transaction](#transaction-commands)\n  - [Wallet](#wallet-commands)\n  - [Bridge](#bridge-commands)\n  - [Other Commands](#other-commands)\n- [Supported Chains](#-supported-chains)\n- [Developing New Features](#-developing-new-features)\n- [Official Links](#-official-links)\n- [License](#-license)\n- [Troubleshooting](#-troubleshooting)\n\n## \ud83d\udee0 Prerequisites\n\n- [Node.js v18 or higher](https://nodejs.org/en)\n- [Git](https://git-scm.com/downloads)\n- [Docker](https://www.docker.com/get-started/) (for `zksync-cli dev` commands)\n\n## \ud83d\udce5 Usage\n\nYou can run commands without installation: `npx zksync-cli`. For example: `npx zksync-cli dev start`.\n\n## \ud83d\udcbb Commands\n\n### Local development commands\n`npx zksync-cli dev` - Manage local zkSync development environment. It allows to easily start zkSync stack locally, for example: local Ethereum and zkSync nodes, Block Explorer, Wallet and Bridge.\n\n- `npx zksync-cli dev start` - start local development environment (will ask to configure if starting for the first time)\n- `npx zksync-cli dev clean` - clean data for configured modules\n- `npx zksync-cli dev config` - select modules to run in local development environment\n\nRun `npx zksync-cli dev` to see the full list of commands.\n\n### Create Project commands\n- `npx zksync-cli create`: Create a project using updated templates.\n  - **Frontend**: Rapid UI development with templates for Vue, React, Next.js, Nuxt, Vite, etc. Options include viem, ethers, web3modal, rainbowkit. [More Info](https://github.com/matter-labs/zksync-frontend-templates#readme)\n  - **Contracts**: Quick contract deployment and testing with tools like Hardhat on Solidity or Vyper. [Contract templates](https://github.com/matter-labs/zksync-contract-templates#readme)\n  - **Scripting**: Automated interactions and advanced zkSync operations using Node.js, with examples of wallet or contract interactions using viem, ethers or web3.js. [Scripting Templates](https://github.com/matter-labs/zksync-scripting-templates#readme)\n\n### Contract interaction commands\nSee full documentation and advanced examples [here](./docs/contract-interaction.md).\n- `npx zksync-cli contract read`: run read-only contract methods\n- `npx zksync-cli contract write`: send transactions to the contract\n- `npx zksync-cli contract encode`: get calldata from the contract method\n\n### Transaction commands\nSee full documentation and advanced examples [here](./docs/transaction-info.md).\n- `npx zksync-cli transaction info`: get information about a transaction\n\n### Wallet commands\n- `npx zksync-cli wallet transfer`: send funds on L2 to another account\n- `npx zksync-cli wallet balance`: displays token balance of the specified address\n\n### Bridge commands\n- `npx zksync-cli bridge deposit`: deposits funds from Ethereum (L1) to zkSync (L2)\n- `npx zksync-cli bridge withdraw`: withdraws funds from zkSync (L2) to Ethereum (L1)\n- `npx zksync-cli bridge withdraw-finalize`: finalizes withdrawal of funds from zkSync (L2) to Ethereum (L1)\n\n### Other commands\n- `npx zksync-cli config chains`: Add or edit custom chains\n- `npx zksync-cli help`: Provides information about all supported commands\n- `npx zksync-cli <command> --help`: Provides detailed information about how to use a specific command. Replace \\<command\\> with the name of the command you want help with (e.g., `create`, `dev config`, `bridge withdraw-finalize`)\n- `npx zksync-cli --version`: Returns the current version\n\n\n### \ud83d\udd17 Supported chains\n\nBy default zkSync CLI bridge commands support zkSync Sepolia Testnet, zkSync Goerli Testnet and zkSync Mainnet. You can also use other networks by using one the options below:\n- Adding custom chain using `npx zksync-cli config chains` command.\n- Overwriting L1 and L2 RPC URLs. For example: `npx zksync-cli deposit --rpc=http://... --l1-rpc=http://...`\n\nIf you're using [local setup (dockerized testing node)](https://github.com/matter-labs/local-setup) with default L1 and L2 RPC URLs, you can select `Local Dockerized node` option in the CLI or provide option `--chain local-dockerized`.\n\n## \ud83d\udc69\u200d\ud83d\udcbb Developing new features\n\n### Run in development mode\n\n1. Install all dependencies with `npm i`.\n2. To use CLI in development mode run `npm run dev -- [command] [options]` (e.g. `npm run dev -- bridge deposit --chain=zksync-sepolia`).\n\n### Building for production\n\n1. Install all dependencies with `npm i`.\n2. This project was build with Typescript. Run `npm run build` to compile the code into `/bin`.\n3. You can run your local build with `node ./bin`\n\n### Testing\n\nAt the moment, we don't have any tests, but we are working on it.\nIn the meantime, you can test the code manually by running the code in [development mode](#run-in-development-mode).\n\n## \ud83c\udf0d Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n- [Youtube](https://www.youtube.com/@zkSync-era)\n\n## \ud83d\udcdc License\n\nThis project is licensed under [MIT](./LICENSE-MIT).\n\n## \u2753 Troubleshooting\n\nEncountering issues with zkSync CLI? Below are some common problems with step-by-step recommendations for resolving them:\n\n<details>\n<summary><b>`unknown command` Error</b></summary>\n\nIf you encounter an `unknown command` error, follow these steps:\n\na. **Check the zkSync CLI Version**\n   - Run `npx zksync-cli --version` to check your current version.\n   - Compare it with the latest version available on [npm](https://www.npmjs.com/package/zksync-cli).\n   - If your version is lower than the one on npm follow the steps bellow. If your version is up-to-date, it's possible that the command was moved or renamed. Use `npx zksync-cli help` for a list of current commands or refer to the documentation.\n\nb. **Verify Local Installation**\n   - Use `npm list zksync-cli` to check if `zksync-cli` is installed in the current directory or any parent directories from where you are running your terminal.\n   - If it is indeed installed, make sure to uninstall it by running `npm uninstall zksync-cli` in its installation location. Remove all instances of `zksync-cli` until there are no more found by `npm list zksync-cli`.\n\nc. **Verify Global Installation**\n   - Use `npm list -g zksync-cli` to check if `zksync-cli` is installed globally.\n   - If it is installed globally, uninstall it using `npm uninstall -g zksync-cli`.\n\nd. **Clean npm Cache**\n   - Run `npm cache clean --force`.\n\ne. **Use the Latest Version**\n   - As a quick fix, or if the above steps don't resolve the issue, use `npx zksync-cli@latest [command]`, for example, `npx zksync-cli@latest dev start`.\n</details>\n\n<details>\n<summary><b>My Version is Outdated</b></summary>\n\nIf `npx zksync-cli` is not running the latest version:\n\n- Refer to the guide above to check and update your zkSync CLI version.\n</details>\n\n<details>\n<summary><b>`command not found: npx` Error</b></summary>\n\nIf you receive a `command not found: npx` error, it means Node.js is not installed or not correctly set up on your system:\n\n- Install Node.js from [https://nodejs.org/](https://nodejs.org/). This will also install `npm` and `npx`.\n- After installation, restart your terminal and try running `npx zksync-cli` again.\n</details>\n\nFor all other issues, we encourage you to ask for help or report them in our [GitHub Discussions](https://github.com/zkSync-Community-Hub/zksync-developers/discussions/new?category=general&title=[zksync-cli]%20<Title>).\n", "release_dates": ["2024-02-22T14:24:07Z", "2024-02-16T16:49:50Z", "2024-02-08T15:06:18Z", "2024-02-08T13:37:36Z", "2024-01-30T22:33:57Z", "2024-01-13T23:47:06Z", "2023-12-06T12:48:07Z", "2023-12-01T14:32:40Z", "2023-11-27T14:35:26Z", "2023-11-27T12:41:24Z", "2023-11-23T08:34:14Z", "2023-11-23T07:57:03Z", "2023-11-22T07:07:10Z", "2023-11-18T14:06:50Z", "2023-11-17T19:52:07Z", "2023-11-16T13:52:41Z", "2023-11-10T16:40:48Z", "2023-10-26T14:01:41Z", "2023-10-18T13:46:49Z", "2023-10-12T12:34:36Z", "2023-10-12T10:02:42Z", "2023-10-06T15:34:44Z", "2023-10-03T13:04:29Z", "2023-09-11T08:51:42Z", "2023-09-08T11:24:50Z", "2023-09-06T11:15:36Z"]}, {"name": "zksync-contract-templates", "description": "Contract Templates for zkSync: solidity, hardhat, vyper", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Contract Templates\n\nWelcome to the `zkSync Contract Templates` repository. This collection is designed for developers eager to build smart contracts on zkSync, featuring templates for Hardhat with Solidity and Vyper. These templates provide a robust starting point for contract development, testing and deployment.\n\n## \ud83d\udcc1 Available Templates\n\nCurrently, the repository offers specific templates for Hardhat, an Ethereum development environment, tailored for both Solidity and Vyper:\n\n### Hardhat Templates\n- Ethers v6 (latest)\n  - [Solidity Template](./templates/hardhat/solidity/)\n  - [Vyper Template](./templates/hardhat/vyper/)\n- Ethers v5\n  - [Solidity Template](./templates/hardhat_ethers5/solidity/)\n  - [Vyper Template](./templates/hardhat_ethers5/vyper/)\n\n## \ud83e\udd1d Contribution\n\nYour contributions are always welcome! Whether it's submitting PRs, suggesting improvements, or reporting issues, your feedback is invaluable in refining these templates.\n\n## \ud83c\udf0d Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://join.zksync.dev/)\n\n## \ud83d\udcdc License\n\nThis project is licensed under [MIT](./LICENSE-MIT).", "release_dates": []}, {"name": "zksync-dapp-checkout", "description": "zkCheckout \u2014 trustable permissionless DeFi payment gateway. Brand new zkSync dApp w/t all L2 perks:  fast&cheap transfers / simple&quick withdrawal", "language": "Vue", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# [zkSync Checkout dApp](https://checkout.zksync.io) &middot; [zkSync.io](https://zksync.io/)  [![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE-MIT) [![GitHub license](https://img.shields.io/badge/license-Apache%202-blue)](./LICENSE-APACHE)\n\n# zkSync Checkout \u2014 trustable permissionless DeFi payment gateway \n\nzkSync Checkout helps anyone permission-less adopt checkout backed by zkSync, receive payments automatically and benefit from all the advantage of zkSync Rollup: speed of the transaction, times lower cost of a single transaction, simplicity of withdrawal fund to the onchain-wallet.\n\n* **[SDK documentation](https://zksync.io/api/sdk/checkout/)** | [**Changelog**](CHANGELOG.md)\n\n## Deployment\n\nzkSync uses firebase hosting for all it's dApps.\nResource targets for the zkCheckout are:\n\n### Available Hosts\n\n* [```prod-mainnet```](https://checkout.zksync.io)\n* [```prod-goerli```](https://checkout-goerli.zksync.io)\n* [```staging```](https://staging-checkout-v1.zksync.dev/link)\n\n## Initial Setup / Static version generation\n\n``` bash\n# install dependencies\n$ sh cli-dev.sh ci\n\n# Populate .env file as of goerli connection && serve with hot reload at localhost:3000\n$ yarn dev\n\n# static version generation\n$ yarn ci:build:goerli\n# afterward you'll have prepared distributive in /public folder\n\n# generate static for the mainnet release\n$ sh cli-dev.sh ci\n$ yarn ci:build:mainnet\n# afterward you'll have prepared distributive in /public folder\n\n```\n\n## Dev toolset\n\n### cli-dev.sh\n\nThis helper-script is used to simplify regular tasks when developing or using the package:\n\n```bash\n# removes all generated directories & run package installation with the yarn2.* based on stored yarn.lock with the modifier --check-cache\n$ sh cli-dev.sh ci\n\n# drops node_modules, .yarn/cache .yarn/build-state.yml .yarn/install-state.gz & trigger cache flushing (yarn cache clean --all)\n$ sh cli-dev.sh clean yarn\n\n# drops .nuxt and clear public directory\n$ sh cli-dev.sh clean nuxt\n```\n\n### Linting & checking\n\n```bash\n# Run stylelint with --fix modifier\n$ yarn run lint-style:fix\n\n# Run eslint with --fix modifier\n$ yarn run lint-ts:fix\n\n# Formats all of the code w/t stored style rules by running prettier\n$ yarn format:prettier\n\n# Check spelling in src files\n$ yarn spell-check\n```\n\nFor detailed explanation on how things work, check out [Nuxt.js docs](https://nuxtjs.org).\n\n---\n\n\n## Release CI\n\n> This sharable configuration conforms to angular standard\n\n* Using [@semantic-release/commit-analyzer](https://github.com/semantic-release/commit-analyzer) ensures that commits are conformed to the [conventional commits](https://www.conventionalcommits.org/en/v1.0.0-beta.4/) specification. \n    * **PATCH** version created if any of **build**, **ci**, **chore**, **docs**, **refactor**, **style**, **test** commit types pushed to master \n    * **MINOR** version created if fix commit type pushed MAJOR version created if feat commit type pushed\n    * **MAJOR** version created if feat commit type pushed\n* By default, config used publishes the new version to NPM. But in zkSync's case release flow differs from the deployment flow.\n    * Bumps a version in package.json. \n    * Generates or updates a [changelog](CHANGELOG.md) file including all **PATCH** keywords (not included in default angular package). \n    * Releases new release for the GitHub repo\n\n## Solutions used\n\n* [Nuxt.js](https://nuxtjs.org)\n* [TS Lang](https://www.typescriptlang.org)\n* [Vue.js](https://vuejs.org)\n* [Vuex](https://vuex.vuejs.org)\n* [nuxt/Tailwind](https://tailwindcss.nuxtjs.org/)\n* [nuxt-build-optimisations](https://github.com/harlan-zw/nuxt-build-optimisations)\n* [Nuxt TypeScript](https://typescript.nuxtjs.org/)\n   * inc. [@nuxt/typescript-build](https://typescript.nuxtjs.org/guide/setup)\n   * inc. [@nuxt/typescript-runtime](https://typescript.nuxtjs.org/guide/runtime)\n   * w/t built-in linting [typescript-runtime-linting](https://typescript.nuxtjs.org/guide/lint)\n   * store is build on top of [Vanilla Vuex](https://typescript.nuxtjs.org/cookbook/store#vanilla)\n* [Axios Nuxtjs](https://axios.nuxtjs.org/) \n* [Nuxt social meta](https://github.com/AlekseyPleshkov/nuxt-social-meta) \n* [Sentry](https://sentry.nuxtjs.org/) \n* [Nuxt Webfontloader](https://github.com/Developmint/nuxt-webfontloader)\n\n  ...and others.\n\n### Libraries used  \n\n* [zkSync Checkout lib](https://www.npmjs.com/package/zksync-checkout): our open sourced NPM-package\n* [zkSync.js lib](https://www.npmjs.com/package/zksync-checkout): our open sourced NPM-package\n* [zkCheckout link builder](https://checkout.zksync.io/link): UI to create unique permissionless payment link and get paid in tokens\n* [SDK description](https://zksync.io/api/sdk/checkout/): details on how to use zkCheckout SDK\n* [ethers.js lib](https://docs.ethers.io/v5/): a simple to use Web3 Provider Bridge as a single JavaScript file\n", "release_dates": ["2024-02-01T20:04:29Z", "2024-02-01T19:53:57Z", "2023-08-15T17:46:49Z", "2023-08-15T14:39:28Z", "2023-08-14T18:21:20Z", "2023-06-26T09:03:48Z", "2023-03-28T17:28:57Z", "2023-01-23T09:02:39Z", "2023-01-20T11:17:17Z", "2022-12-29T18:46:50Z", "2022-12-21T11:09:33Z", "2022-12-19T10:30:29Z", "2022-12-12T09:03:38Z", "2022-12-06T10:19:44Z", "2022-09-12T10:21:18Z", "2022-08-30T08:43:24Z", "2022-08-19T07:13:34Z", "2022-08-04T14:33:42Z", "2022-06-29T13:46:06Z", "2022-06-10T10:11:56Z", "2022-04-25T09:13:45Z", "2022-04-19T04:37:48Z", "2022-04-06T08:02:49Z", "2022-03-21T17:48:55Z", "2022-03-11T11:50:36Z", "2022-03-08T11:38:11Z", "2022-01-24T16:04:10Z", "2022-01-14T19:45:52Z", "2022-01-12T10:02:22Z", "2022-01-04T23:24:32Z"]}, {"name": "zksync-dapp-forced-exit", "description": null, "language": "CSS", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# [zksync.io](https://zksync.io/) &middot; [![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/matter-labs/zksync-wallet/blob/master/LICENSE-MIT) [![GitHub license](https://img.shields.io/badge/license-Apache%202-blue)](https://github.com/matter-labs/zksync-wallet/blob/master/LICENSE-MIT) [![npm version](https://img.shields.io/npm/v/zksync.svg?style=flat)](https://www.npmjs.com/package/zksync) [![Live on Mainnet](https://img.shields.io/badge/wallet-Live%20on%20Mainnet-blue)](https://wallet.zksync.io) [![Live on Goerli](https://img.shields.io/badge/wallet-Live%20on%20Goerli-blue)](https://zksync.io?network=goerli)\n\n\n# Website zksync.io \n\nFirst public release of the updated zksync.io landing page design\n \n\n## CHANGELOG.md\n\n\u231b\ufe0f Coming soon\n\n## Build Setup\n\n``` bash\n# install dependencies && populate .env file as of GOERLI connection (clear install)\n$ yarn prepare_ci\n\n# serve with hot reload at localhost:3000\n$ yarn dev\n\n# build for dev\n$ build:stage\n# afterward you'll have prepared distributive in /public folder\n\n# build for production (only if you have firebase:auth) \n$ cli-deploy-production.sh  \n```\n\nFor detailed explanation on how things work, check out [Nuxt.js docs](https://nuxtjs.org).\n\n---\n\n## Solutions used\n\n* [Nuxt.js](https://nuxtjs.org)\n* [TS Lang](https://www.typescriptlang.org)\n* [Vue.js](https://vuejs.org)\n\n## License\n\nzksync.io is distributed under the terms of both the MIT license, and the Apache License (v.2.0).\n\nSee [LICENSE-APACHE](LICENSE-APACHE), [LICENSE-MIT](LICENSE-MIT) for details.\n", "release_dates": ["2024-02-21T13:32:54Z", "2023-02-21T09:00:06Z", "2023-02-20T09:16:17Z", "2023-01-23T09:04:33Z", "2022-12-02T13:24:24Z"]}, {"name": "zksync-era", "description": "zkSync era", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkSync Era: A ZK Rollup For Scaling Ethereum\n\n[![Logo](eraLogo.png)](https://zksync.io/)\n\nzkSync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or\ndecentralization. Since it's EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring\nor re-auditing a single line of code. zkSync Era also uses an LLVM-based compiler that will eventually let developers\nwrite smart contracts in C++, Rust and other popular languages.\n\n## Knowledge Index\n\nThe following questions will be answered by the following resources:\n\n| Question                                                | Resource                                       |\n| ------------------------------------------------------- | ---------------------------------------------- |\n| What do I need to develop the project locally?          | [development.md](docs/guides/development.md)   |\n| How can I set up my dev environment?                    | [setup-dev.md](docs/guides/setup-dev.md)       |\n| How can I run the project?                              | [launch.md](docs/guides/launch.md)             |\n| What is the logical project structure and architecture? | [architecture.md](docs/guides/architecture.md) |\n| Where can I find protocol specs?                        | [specs](docs/specs/README.md)                  |\n| Where can I find developer docs?                        | [docs](https://era.zksync.io/docs/)            |\n\n## Policies\n\n- [Security policy](SECURITY.md)\n- [Contribution policy](CONTRIBUTING.md)\n\n## License\n\nzkSync Era is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <https://opensource.org/blog/license/mit/>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [ZK Credo](https://github.com/zksync/credo)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Developers](https://twitter.com/zkSyncDevs)\n- [Discord](https://join.zksync.dev/)\n- [Mirror](https://zksync.mirror.xyz/)\n- [Youtube](https://www.youtube.com/@zkSync-era)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounty programs. We would love to hear our community's thoughts and suggestions about it! It\nis important to state that forking it now can potentially lead to missing important security updates, critical features,\nand performance improvements.\n", "release_dates": ["2024-03-01T20:36:35Z", "2024-02-26T08:56:25Z", "2024-02-16T10:01:08Z", "2024-02-08T14:57:57Z", "2024-02-04T16:40:27Z", "2024-02-02T15:15:22Z", "2024-02-02T12:06:32Z", "2024-01-31T15:36:20Z", "2024-01-31T12:01:01Z", "2024-01-30T12:48:46Z", "2024-01-29T20:28:46Z", "2024-01-23T16:21:48Z", "2024-01-19T14:53:03Z", "2024-01-17T13:31:57Z", "2024-01-12T10:41:11Z", "2024-01-11T09:56:00Z", "2024-01-05T12:27:37Z", "2024-01-05T12:39:38Z", "2024-01-02T14:20:08Z", "2023-12-25T23:56:33Z", "2023-12-25T21:03:33Z", "2023-12-25T17:27:00Z", "2023-12-25T14:20:23Z", "2023-12-25T11:30:29Z", "2023-12-25T10:30:54Z", "2023-12-21T17:04:43Z", "2023-12-21T11:59:09Z", "2023-12-19T17:42:14Z", "2023-12-13T13:58:18Z", "2023-12-12T08:20:23Z"]}, {"name": "zksync-frontend-templates", "description": "Frontend Templates for zkSync: vue, react, next, wagmi", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Frontend Templates\n\nWelcome to the `zkSync Frontend Templates` repository. This collection of frontend templates is designed to accelerate your zkSync project's setup, including templates tailored for all your favorite frameworks like Vue and React.\n\n## \ud83d\udcd8 Overview\n\nThe templates in this repository assist with various functionalities, such as network configuration, wallet connectivity, transaction handling, and more, to offer a smooth zkSync integration.\n\n## \ud83d\udcc1 Available Templates\n\nTo make navigation easier, the templates are structured based on their respective frameworks and configurations:\n\n### Vue\n\n- **Vue** \u2013 Harness the power of Vue with these templates for a seamless zkSync integration, suitable for all Vue enthusiasts and projects using Vue framework.\n  - Nuxt\n    - [Wagmi](./templates/vue/nuxt3-wagmi/)\n    - [Wagmi + Web3Modal](./templates/vue/nuxt3-wagmi-web3modal/)\n  - Vite\n    - [Wagmi](./templates/vue/vite-wagmi/)\n    - [Wagmi + Web3Modal](./templates/vue/vite-wagmi-web3modal/)\n- **Ethers v6 (latest)**\n  - [Nuxt](./templates/vue/nuxt3-ethers/)\n  - [Vite](./templates/vue/vite-ethers/)\n- **Ethers v5**\n  - [Nuxt](./templates/vue/nuxt3-ethers5/)\n  - [Vite](./templates/vue/vite-ethers5/)\n\n### React\n\n- **React Templates** \u2013 Jumpstart your zkSync project with our React templates, providing out-of-the-box solutions for React-based applications.\n  - Next\n    - [Wagmi](./templates/react/next-wagmi/)\n    - [Wagmi + Web3Modal](./templates/react/next-wagmi-web3modal/)\n    - [Wagmi + RainbowKit](./templates/react/next-wagmi-rainbowkit/)\n  - Vite\n    - [Wagmi](./templates/react/vite-wagmi/)\n    - [Wagmi + Web3Modal](./templates/react/vite-wagmi-web3modal/)\n- **Ethers v6 (latest)**\n  - [Next](./templates/react/next-ethers/)\n  - [Vite](./templates/react/vite-ethers/)\n- **Ethers v5**\n  - [Next](./templates/react/next-ethers5/)\n  - [Vite](./templates/react/vite-ethers5/)\n\n## \ud83e\udd1d Contribution\n\nYour contributions are always welcome! Whether it's submitting PRs, suggesting improvements, or reporting issues, your feedback is invaluable in refining these templates.\n\n## \ud83c\udf0d Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://join.zksync.dev/)\n\n## \ud83d\udcdc License\n\nThis project is licensed under [MIT](./LICENSE-MIT).", "release_dates": []}, {"name": "zksync-hardhat-ft-template", "description": "Template for a fungible token project on zkSync Era", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Hardhat project\n\nThis project was scaffolded with [zksync-cli](https://github.com/matter-labs/zksync-cli).\n\n## Project structure\n\n- `/contracts`: smart contracts.\n- `/deploy`: deployment and contract interaction scripts.\n- `/test`: test files\n- `hardhat.config.ts`: configuration file.\n\n## Commands\n\n- `yarn hardhat compile` will compile the contracts.\n- `yarn run deploy` will execute the deployment script `/deploy/deploy-greeter.ts`. Requires [environment variable setup](#environment-variables).\n- `yarn run greet` will execute the script `/deploy/use-greeter.ts` which interacts with the Greeter contract deployed.\n- `yarn test`: run tests. **Check test requirements below.**\n\nBoth `yarn run deploy` and `yarn run greet` are configured in the `package.json` file and run `yarn hardhat deploy-zksync`.\n\n### Environment variables\n\nIn order to prevent users to leak private keys, this project includes the `dotenv` package which is used to load environment variables. It's used to load the wallet private key, required to run the deploy script.\n\nTo use it, rename `.env.example` to `.env` and enter your private key.\n\n```\nWALLET_PRIVATE_KEY=123cde574ccff....\n```\n\n### Local testing\n\nIn order to run test, you need to start the zkSync local environment. Please check [this section of the docs](https://v2-docs.zksync.io/api/hardhat/testing.html#prerequisites) which contains all the details.\n\nIf you do not start the zkSync local environment, the tests will fail with error `Error: could not detect network (event=\"noNetwork\", code=NETWORK_ERROR, version=providers/5.7.2)`\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n", "release_dates": []}, {"name": "zksync-hardhat-nft-template", "description": "Template for a non-fungible token project on zkSync Era", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Hardhat project\n\nThis project was scaffolded with [zksync-cli](https://github.com/matter-labs/zksync-cli).\n\n## Project structure\n\n- `/contracts`: smart contracts.\n- `/deploy`: deployment and contract interaction scripts.\n- `/test`: test files\n- `hardhat.config.ts`: configuration file.\n\n## Commands\n\n- `yarn hardhat compile` will compile the contracts.\n- `yarn run deploy` will execute the deployment script `/deploy/deploy-greeter.ts`. Requires [environment variable setup](#environment-variables).\n- `yarn run greet` will execute the script `/deploy/use-greeter.ts` which interacts with the Greeter contract deployed.\n- `yarn test`: run tests. **Check test requirements below.**\n\nBoth `yarn run deploy` and `yarn run greet` are configured in the `package.json` file and run `yarn hardhat deploy-zksync`.\n\n### Environment variables\n\nIn order to prevent users to leak private keys, this project includes the `dotenv` package which is used to load environment variables. It's used to load the wallet private key, required to run the deploy script.\n\nTo use it, rename `.env.example` to `.env` and enter your private key.\n\n```\nWALLET_PRIVATE_KEY=123cde574ccff....\n```\n\n### Local testing\n\nIn order to run test, you need to start the zkSync local environment. Please check [this section of the docs](https://v2-docs.zksync.io/api/hardhat/testing.html#prerequisites) which contains all the details.\n\nIf you do not start the zkSync local environment, the tests will fail with error `Error: could not detect network (event=\"noNetwork\", code=NETWORK_ERROR, version=providers/5.7.2)`\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n", "release_dates": []}, {"name": "zksync-hardhat-template", "description": "[DEPRECATED] Template project for zksync-hardhat", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# This repository is deprecated and will no longer be maintained. This template is now available in [zkSync Contract Templates](https://github.com/matter-labs/zksync-contract-templates#readme)\n\n---\n\n# zkSync Hardhat project template\n\nThis project was scaffolded with [zksync-cli](https://github.com/matter-labs/zksync-cli).\n\n## Project Layout\n\n- `/contracts`: Contains solidity smart contracts.\n- `/deploy`: Scripts for contract deployment and interaction.\n- `/test`: Test files.\n- `hardhat.config.ts`: Configuration settings.\n\n## How to Use\n\n- `npm run compile`: Compiles contracts.\n- `npm run deploy`: Deploys using script `/deploy/deploy.ts`.\n- `npm run interact`: Interacts with the deployed contract using `/deploy/interact.ts`.\n- `npm run test`: Tests the contracts.\n\nNote: Both `npm run deploy` and `npm run interact` are set in the `package.json`. You can also run your files directly, for example: `npx hardhat deploy-zksync --script deploy.ts`\n\n### Environment Settings\n\nTo keep private keys safe, this project pulls in environment variables from `.env` files. Primarily, it fetches the wallet's private key.\n\nRename `.env.example` to `.env` and fill in your private key:\n\n```\nWALLET_PRIVATE_KEY=your_private_key_here...\n```\n\n### Network Support\n\n`hardhat.config.ts` comes with a list of networks to deploy and test contracts. Add more by adjusting the `networks` section in the `hardhat.config.ts`. To make a network the default, set the `defaultNetwork` to its name. You can also override the default using the `--network` option, like: `hardhat test --network dockerizedNode`.\n\n### Local Tests\n\nRunning `npm run test` by default runs the [zkSync In-memory Node](https://era.zksync.io/docs/tools/testing/era-test-node.html) provided by the [@matterlabs/hardhat-zksync-node](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-node.html) tool.\n\nImportant: zkSync In-memory Node currently supports only the L2 node. If contracts also need L1, use another testing environment like Dockerized Node. Refer to [test documentation](https://era.zksync.io/docs/tools/testing/) for details.\n\n## Useful Links\n\n- [Docs](https://era.zksync.io/docs/dev/)\n- [Official Site](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://join.zksync.dev/)\n\n## License\n\nThis project is under the [MIT](./LICENSE) license.", "release_dates": []}, {"name": "zksync-hardhat-vyper-ft-template", "description": "Template for a fungible token vyper project on zkSync Era", "language": "TypeScript", "license": null, "readme": "# zkSync Hardhat Vyper project\n\nThis project was scaffolded with [zksync-cli](https://github.com/matter-labs/zksync-cli).\n\n## Project structure\n\n- `/contracts`: smart contracts.\n- `/deploy`: deployment and contract interaction scripts.\n- `/test`: test files\n- `hardhat.config.ts`: configuration file.\n\n## Commands\n\n- `yarn hardhat compile` will compile the contracts.\n- `yarn run deploy` will execute the deployment script `/deploy/deploy-greeter.ts`. Requires [environment variable setup](#environment-variables).\n- `yarn run greet` will execute the script `/deploy/use-greeter.ts` which interacts with the Greeter contract deployed.\n- `yarn test`: run tests. **Check test requirements below.**\n\nBoth `yarn run deploy` and `yarn run greet` are configured in the `package.json` file and run `yarn hardhat deploy-zksync`.\n\n### Environment variables\n\nIn order to prevent users to leak private keys, this project includes the `dotenv` package which is used to load environment variables. It's used to load the wallet private key, required to run the deploy script.\n\nTo use it, rename `.env.example` to `.env` and enter your private key.\n\n```\nWALLET_PRIVATE_KEY=123cde574ccff....\n```\n\n### Local testing\n\nIn order to run test, you need to start the zkSync local environment. Please check [this section of the docs](https://v2-docs.zksync.io/api/hardhat/testing.html#prerequisites) which contains all the details.\n\nIf you do not start the zkSync local environment, the tests will fail with error `Error: could not detect network (event=\"noNetwork\", code=NETWORK_ERROR, version=providers/5.7.2)`\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n", "release_dates": []}, {"name": "zksync-hardhat-vyper-nft-template", "description": "Template for a non-fungible token Vyper project on zkSync Era", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Hardhat project\n\nThis project was scaffolded with [zksync-cli](https://github.com/matter-labs/zksync-cli).\n\n## Project structure\n\n- `/contracts`: smart contracts.\n- `/deploy`: deployment and contract interaction scripts.\n- `/test`: test files\n- `hardhat.config.ts`: configuration file.\n\n## Commands\n\n- `yarn hardhat compile` will compile the contracts.\n- `yarn run deploy` will execute the deployment script `/deploy/deploy-greeter.ts`. Requires [environment variable setup](#environment-variables).\n- `yarn run greet` will execute the script `/deploy/use-greeter.ts` which interacts with the Greeter contract deployed.\n- `yarn test`: run tests. **Check test requirements below.**\n\nBoth `yarn run deploy` and `yarn run greet` are configured in the `package.json` file and run `yarn hardhat deploy-zksync`.\n\n### Environment variables\n\nIn order to prevent users to leak private keys, this project includes the `dotenv` package which is used to load environment variables. It's used to load the wallet private key, required to run the deploy script.\n\nTo use it, rename `.env.example` to `.env` and enter your private key.\n\n```\nWALLET_PRIVATE_KEY=123cde574ccff....\n```\n\n### Local testing\n\nIn order to run test, you need to start the zkSync local environment. Please check [this section of the docs](https://v2-docs.zksync.io/api/hardhat/testing.html#prerequisites) which contains all the details.\n\nIf you do not start the zkSync local environment, the tests will fail with error `Error: could not detect network (event=\"noNetwork\", code=NETWORK_ERROR, version=providers/5.7.2)`\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [Documentation](https://v2-docs.zksync.io/dev/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n", "release_dates": []}, {"name": "zksync-hardhat-vyper-template", "description": "[DEPRECATED] Template project for zksync-cli. Includes a Vyper smart contract, tests and script to deploy to zkSync Era", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# This repository is deprecated and will no longer be maintained. This template is now available in [zkSync Contract Templates](https://github.com/matter-labs/zksync-contract-templates#readme)\n\n---\n\n# zkSync Hardhat Vyper template\n\nThis project was scaffolded with [zksync-cli](https://github.com/matter-labs/zksync-cli).\n\n## Project Layout\n\n- `/contracts`: Contains solidity smart contracts.\n- `/deploy`: Scripts for contract deployment and interaction.\n- `/test`: Test files.\n- `hardhat.config.ts`: Configuration settings.\n\n## How to Use\n\n- `yarn hardhat compile`: Compiles contracts.\n- `yarn deploy`: Deploys using script `/deploy/deploy.ts`.\n- `yarn interact`: Interacts with the deployed contract using `/deploy/interact.ts`.\n- `yarn test`: Tests the contracts.\n\nNote: Both `yarn deploy` and `yarn interact` are set in the `package.json`. You can also run your files directly, for example: `yarn hardhat deploy-zksync --script deploy.ts`\n\n### Environment Settings\n\nTo keep private keys safe, this project pulls in environment variables from `.env` files. Primarily, it fetches the wallet's private key.\n\nRename `.env.example` to `.env` and fill in your private key:\n\n```\nWALLET_PRIVATE_KEY=your_private_key_here...\n```\n\n### Network Support\n\n`hardhat.config.ts` comes with a list of networks to deploy and test contracts. Add more by adjusting the `networks` section in the `hardhat.config.ts`. To make a network the default, set the `defaultNetwork` to its name. You can also override the default using the `--network` option, like: `hardhat test --network dockerizedNode`.\n\n### Local Tests\n\nRunning `yarn test` by default runs the [zkSync In-memory Node](https://era.zksync.io/docs/tools/testing/era-test-node.html) provided by the [@matterlabs/hardhat-zksync-node](https://era.zksync.io/docs/tools/hardhat/hardhat-zksync-node.html) tool.\n\nImportant: zkSync In-memory Node currently supports only the L2 node. If contracts also need L1, use another testing environment like Dockerized Node. Refer to [test documentation](https://era.zksync.io/docs/tools/testing/) for details.\n\n## Useful Links\n\n- [Docs](https://era.zksync.io/docs/dev/)\n- [Official Site](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://join.zksync.dev/)\n\n## License\n\nThis project is under the [MIT](./LICENSE) license.", "release_dates": []}, {"name": "zksync-link", "description": "PayNow - Create payment links, get paid in tokens", "language": "Svelte", "license": null, "readme": "# zkLink\n\n> Create zkSync payment links, get paid in tokens.\n\n**Archival notice**: Please use https://checkout.zksync.io moving forward.\n\n#### Payment 3.0 made by you\nAccept payments instantly using payment links (provided by [zkSync](https://zksync.io)). Generate a link in one tap, copy your payment link and share it with your clients, friends and users to request payments and donations. \n\n#### Application\n* [https://link.zksync.io](https://link.zksync.io)\n\n#### Linked products\n* [zkCheckout](https://checkout.zksync.io)\n* [zkWallet](https://wallet.zksync.io)\n\n#### Features\n* Hand drafted frontend\n* Based on [zkSync Checkout](https://www.notion.so/zkSync-Checkout-docs-2bffd6f169e746d0b51873e4127992a6)\n* Get available tokens from zkSync API\n* Copy the payment link to clipboard\n* Share the payment link on social media\n* Update the payment link on changes\n* En-/Decryption by `btoa` / `atob`\n* No DB, no 3rd-party dependencies\n* Performance optimized application\n\n#### User Interface\n* Usability tested\n* Full responsive layout\n* Flat & clean user interface\n* Dark / Light themes (auto switch)\n\n#### Todos\n* CI tests\n* Additional infos\n* QR Code generator\n* `semanticType: FeeOrCommission`\n\n#### Contribution\n* [pch.vector](https://www.freepik.com) ```Illustration credit```\n\n#### Deployment\n\nOn commit: see the Github workflows.\n", "release_dates": []}, {"name": "zksync-lite-docs", "description": "zkSync documentation", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# [zkSync Lite Docs](https://docs.zksync.io/) ![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/matter-labs/zksync-docs) ![GitHub Workflow Status](https://img.shields.io/github/workflow/status/matter-labs/zksync-docs/Deploy%20production)\n\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/matter-labs/zksync-docs/blob/master/LICENSE) [![npm version](https://img.shields.io/npm/v/zksync.svg?style=flat)](https://www.npmjs.com/package/zksync) [![Follow us!](https://img.shields.io/twitter/follow/zksync?color=%238C8DFC&label=Follow%20%40zkSync&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iNDMiIGhlaWdodD0iMjUiIHZpZXdCb3g9IjAgMCA0MyAyNSIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00Mi42NTM5IDEyLjQ5MTVMMzAuODM3OCAwLjcxNjc0M1Y5LjM0TDE5LjEwNTUgMTcuOTczOUwzMC44Mzc4IDE3Ljk4MlYyNC4yNjYyTDQyLjY1MzkgMTIuNDkxNVoiIGZpbGw9IiM0RTUyOUEiLz4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0wLjk5ODA0NyAxMi40ODcyTDEyLjgxNDEgMjQuMjYxOVYxNS43MDhMMjQuNTQ2NSA3LjAwNDdMMTIuODE0MSA2Ljk5NjY0VjAuNzEyNDYzTDAuOTk4MDQ3IDEyLjQ4NzJaIiBmaWxsPSIjOEM4REZDIi8%2BCjwvc3ZnPgo%3D&style=flat)](https://twitter.com/zksync)\n\n\n## zkSync Documentation for the v1 | [CHANGELOG](./CHANGELOG.md)\n\nThis repository contains the zkSync documentation hosted at [docs.zksync.io](https://docs.zksync.io)\n\n## Development\n\n### Prerequisites\n\nA [Node.js](https://nodejs.org/en/download) installation running Node.js version 16.\n\n### Local run\n\n```bash\nyarn install --check-cache\nyarn docs:dev\n```\n\n### Development\n\nCI pipeline will check that the files are formatted according `markdownlint` founds no issues in document\nand spelling is correct. Also, there should be no dead links.\n\nYou can check it locally as follows:\n\n```bash\nyarn\nyarn md:lint\nyarn cspell\n```\n\nIf `cspell` doesn't recognize a word but you're sure that it's correct, consider adding it to the `cspell-zksync.txt`.\n\n## Deployment\n\n`master` branch is automatically deployed to <https://console.firebase.google.com/u/0/project/zksync-web-docs>\n\n### Deploying altogether\n\n> will do:\n\n* install node modules;\n* prepare, test and build documentation;\n* afterwards all contained into the `dist` folder will be deployed in form of the static website\n\n```bash\nyarn install --check-cache\nyarn docs:build\nyarn firebase deploy\n```\n\n## Extra documentation\n\n## cSpell\n\nConfiguration in `cspell.json`:\n\n* `version` \u2014 version of the setting file, always **0.1**\n* `language` \u2014 language - current active spelling language\n* `words[]` \u2014 words - list of words to be always considered correct\n* `dictionaries[]`\n\n```\n\"dictionaryDefinitions\": [\n    {\n      \"name\": \"zksync\", \"path\": \"./cspell-zksync.txt\"\n    }\n]\n```\n\n```bash\n{\n  \"version\": \"0.1\",\n  // language - current active spelling language\n  \"language\": \"en\",\n  // words - list of words to be always considered correct\n  \"words\": [],\n  \"dictionaries\": [\"typescript\", \"zksync\"],\n  //\n  \"dictionaryDefinitions\": [\n  { \n    \"name\": \"zksync\", \"path\": \"./cspell-zksync.txt\"\n  }\n]\n}\n```\n\n---\n\n# zkSync Ecosystem\n\n- [**Start building with zkSync v2 \ud83d\ude80**](https://portal.zksync.io)\n- [Integration Docs](https://zksync.io/dev)\n- [Available API & protocols](https://zksync.io/api/)\n- [zkWallet](https://wallet.zksync.io/)\n- [zkMint](https://mint.zksync.dev/)\n- [Alternative Withdrawal](https://withdraw.zksync.io/)\n- [zkScan](https://zkscan.io/)\n- [\u2019out-of-gas\u2019 issue solver ](https://withdraw.zksync.io/)\n\n---\n\n- [Matter Labs: creators of the zkSync](https://matter-labs.io)\n- [zkSync Lite Homepage](https://zksync.io)\n\n---\n> BTW, we're hiring: [See open positions](https://joinmatterlabs.com)\n\n## License\n\nzkWallet is distributed under the terms of both the MIT license, and the Apache License (v.2.0).\n\nSee [LICENSE-APACHE](LICENSE-APACHE), [LICENSE-MIT](LICENSE-MIT) for details.\n", "release_dates": ["2024-01-12T15:52:26Z", "2023-06-19T10:07:40Z", "2023-05-24T06:17:24Z", "2023-05-10T12:50:03Z", "2023-05-05T10:28:43Z", "2023-05-03T13:50:39Z", "2023-04-28T14:32:32Z", "2023-04-20T09:00:25Z", "2023-02-24T17:31:53Z", "2023-02-16T11:44:26Z", "2022-12-29T16:09:14Z", "2022-12-07T17:01:54Z", "2022-12-05T18:33:02Z", "2022-12-05T15:06:16Z", "2022-11-07T19:35:46Z", "2022-10-27T11:32:11Z", "2022-10-27T11:28:49Z", "2022-08-29T12:43:23Z", "2022-08-25T20:15:41Z", "2022-08-22T10:58:28Z", "2022-08-18T09:38:33Z", "2022-08-05T09:29:03Z", "2022-07-28T08:12:43Z", "2022-07-26T11:55:14Z", "2022-07-20T18:18:57Z", "2022-07-04T12:20:59Z", "2022-06-17T20:18:54Z", "2022-06-16T15:03:47Z", "2022-06-09T09:06:33Z", "2022-06-03T11:23:17Z"]}, {"name": "zksync-packages-info", "description": "Information about the different packages and SDKs by MatterLabs         to interact with zkSync Era", "language": "Vue", "license": null, "readme": "# zkSync Era devtools\n\nThis projects fetches information of multiple devtools used to build applications on zkSync.\n\nSite deployed to Netlify: https://zksync-packages.netlify.app/\n\n**Open to contributions**\n", "release_dates": []}, {"name": "zksync-scripting-templates", "description": "Scripting Templates for zkSync: node.js, viem, ethers", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Scripting Examples\n\nWelcome to the `zkSync Scripting Examples` repository. This collection is tailored for developers looking to create scripts for zkSync interactions and features templates for quick scaffolding that can be run in the console. For now, the repository hosts a growing list of templates for Node.js.\n\n#### Deploying and verifying contracts\nIf you are looking for scripts to deploy or verify contracts, please check out [zkSync Hardhat Template](https://github.com/matter-labs/zksync-hardhat-template)\n\n## \ud83d\udcc1 Available Templates\n\nCurrently, the repository includes templates for Node.js, with plans to expand to other scripting environments in the future:\n\n### Node.js\n\n- [Viem Template](./templates/nodejs/viem/)\n- [Ethers v6 Template](./templates/nodejs/ethers/)\n- [Ethers v5 Template](./templates/nodejs/ethers5/)\n\n\n## \ud83e\udd1d Contribution\n\nYour contributions are always welcome! Whether it's submitting PRs, suggesting improvements, or reporting issues, your feedback is invaluable in refining these templates.\n\n## \ud83c\udf0d Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Discord](https://join.zksync.dev/)\n\n## \ud83d\udcdc License\n\nThis project is licensed under [MIT](./LICENSE-MIT).", "release_dates": []}, {"name": "zksync-tool-locker", "description": null, "language": "Vue", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Locker Dev-tool \ud83d\udd12 CPK-lock &middot; [![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/matter-labs/zksync-tool-locker/blob/master/LICENSE-MIT) [![GitHub license](https://img.shields.io/badge/license-Apache%202-blue)](https://github.com/matter-labs/zksync-tool-locker/blob/main/LICENSE-MIT)  [![Changelog](https://img.shields.io/badge/release-changelog-4e529a)](https://github.com:matter-labs/zksync-tool-locker/CHANGELOG.MD)\n\n> \u2014 Thanks for your engagement!&nbsp;&nbsp;\u2764\ufe0f&nbsp;[zkSync](https://zksync.io)\n\nDevelopment UI-tool to lock up the account\n\nAvailable for the **rinkeby**, **ropsten** & **mainnet** at the [Firebase Hosting](https://lock-tool-zksync.web.app)\n\n## Build Setup\n\n``` bash\n# install dependencies\n$ yarn install\n\n# serve with hot reload at localhost:8080\n$ yarn serve\n\n# build static version\n$ yarn build\n```\n\nFor detailed explanation on setting the signing key (aKa _ChangePubKey_), check [zkSync v.1.x Docs](https://zksync.io/dev/payments/basic.html#setting-the-signing-key)\n\n## Solutions used\n\n- [Vue.js v3](https://vuejs.org)\n- [web3modal](https://web3modal.com/)\n- [TypeScript](https://www.typescriptlang.org)\n- [eslint.js](https://eslint.org/)\n- [Vue.js](https://vuejs.org)\n\nFor extended configuration see [Configuration Reference](https://cli.vuejs.org/config/).\n\n## zkSync Ecosystem\n\n- [Integration Docs](https://zksync.io/dev)\n- [Available API & protocols](https://zksync.io/api/)\n- [zkWallet](https://wallet.zksync.io/)\n- [zkCheckout](https://checkout.zksync.dev/)\n- [Alternative Withdrawal](https://withdraw.zksync.io/)\n- [zkScan](https://zkscan.io/)\n- [Explore our Hub](https://hub.zksync.dev/)\n\n## About\n\n- [Matter Labs: creators of the zkSync](https://matter-labs.io)\n- [zkSync Homepage](https://zksync.io)\n\n---\n> BTW, we're hiring: [See open positions](https://www.notion.so/matterlabs/Career-at-Matter-Labs-4a69ed0f7acb45c89f662cf12dbc2464)\n\n## License\n\n**zkSync Tool Locker** is distributed under the terms of both the MIT license, and the Apache License (v.2.0).\n\nSee [LICENSE-APACHE](LICENSE-APACHE), [LICENSE-MIT](LICENSE) for details.\n", "release_dates": []}, {"name": "zksync-v2-issues", "description": "Report issues encountered when using the zkSync 2.0 testnet.", "language": null, "license": null, "readme": "# zksync-v2-issues\n\nUse the [Issues](https://github.com/matter-labs/zksync-v2-issues/issues) tab to create and submit a report. \n\nYou can join the [zkSync Discord](https://join.zksync.dev/) to get support from other developers in the community and check on the status of your issue.\n", "release_dates": []}, {"name": "zksync-wallet-vue", "description": "zkSync web wallet", "language": "Vue", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# [zkSync Wallet](https://wallet.zksync.io/) \n\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/matter-labs/zksync-wallet-vue/blob/master/LICENSE-MIT) [![GitHub license](https://img.shields.io/badge/license-Apache%202-blue)](https://github.com/matter-labs/zksync-wallet-vue/blob/master/LICENSE-APACHE) [![Live on Mainnet](https://img.shields.io/badge/wallet-Live%20on%20Mainnet-blue)](https://wallet.zksync.io) [![Live on Goerli](https://img.shields.io/badge/wallet-Live%20on%20Goerli-blue)](https://zksync.io?network=goerli)\n\n\n## Description\n\nzkWallet was created to unleash the power of zkSync L2 operations and give everyone the access to L2 zkSync features. [Learn more](https://zksync.io/)\n\nIt's working perfectly on [**mainnet**](https://wallet.zksync.io) and [goerli](https://zksync.io?network=goerli), published and ready for mass adoption.\n\n---\n\n## Build Setup\n\n``` bash\n# install dependencies && populate .env file as of GOERLI connection (clear install)\n$ yarn ci:clear\n\n# serve with hot reload at localhost:3000 [goerli]\n$ yarn dev\n```\n\nFor detailed explanation on how things work, check out [Nuxt.js docs](https://nuxtjs.org).\n\n---\n\n## Changelog\n\nSee the latest changes [here](https://github.com/matter-labs/zksync-wallet-vue/blob/master/CHANGELOG.md)\n\n\n---\n\n## Solutions used\n\n- [Nuxt.js](https://nuxtjs.org)\n- [Rollup zkSync.io](https://zksync.io)\n- [prettier.js](https://prettier.io)\n- [eslint.js](https://eslint.org/)\n- [Vue.js](https://vuejs.org)\n- [Sentry.io](https://sentry.io)\n- [Onboarding.js](https://github.com/matter-labs-forks/onboard)\n- [Typed Vuex](https://typed-vuex.roe.dev/)\n- [Remix Icon](https://remixicon.com/)\n- [Oh, Vue Icons!](https://oh-vue-icons.netlify.app)\n- [Nuxt TypeScript](https://typescript.nuxtjs.org/)\n- [zksync.js](https://docs.lite.zksync.io/api/sdk/js/tutorial.html)\n- [EthersJs](https://docs.ethers.io/v5/)\n\nFor detailed explanation on how things work, check out [Nuxt.js docs](https://nuxtjs.org).\n\n---\n\n# zkSync Ecosystem\n\n- [Integration Docs](https://zksync.io/dev)\n- [Available API & protocols](https://zksync.io/api/)\n- [zkWallet](https://wallet.zksync.io/)\n- [zkCheckout](https://checkout.zksync.io/)\n- [zkScan](https://zkscan.io/)\n- [Alternative Withdrawal](https://withdraw.zksync.io/)\n- [\u2019out-of-gas\u2019 issue solver ](https://withdraw.zksync.io/)\n\n---\n\n- [Matter Labs: creators of the zkSync](https://matter-labs.io)\n- [zkSync Homepage](https://zksync.io)\n\n---\n> BTW, we're hiring: [See open positions](https://matter-labs.io/#jobs)\n\n## License\n\nzkWallet is distributed under the terms of both the MIT license, and the Apache License (v.2.0).\n\nSee [LICENSE-APACHE](LICENSE-APACHE), [LICENSE-MIT](LICENSE-MIT) for details.", "release_dates": ["2024-02-01T19:50:33Z", "2024-02-01T19:22:38Z", "2024-01-17T13:00:50Z", "2023-12-14T13:41:49Z", "2023-10-23T19:15:40Z", "2023-10-04T10:58:52Z", "2023-08-15T17:46:04Z", "2023-08-15T09:51:24Z", "2023-08-14T17:51:54Z", "2023-06-26T09:04:34Z", "2023-04-10T13:54:18Z", "2023-03-28T17:27:42Z", "2023-03-23T12:15:36Z", "2023-03-20T15:14:19Z", "2023-02-20T12:49:28Z", "2023-02-20T12:08:11Z", "2023-02-16T10:00:25Z", "2023-02-01T13:47:42Z", "2023-02-01T13:18:28Z", "2023-01-30T14:34:38Z", "2023-01-25T19:26:01Z", "2023-01-20T11:16:34Z", "2023-01-03T11:03:28Z", "2022-12-29T18:44:51Z", "2022-12-21T11:09:19Z", "2022-12-17T09:54:12Z", "2022-12-09T18:07:42Z", "2022-12-01T07:18:55Z", "2022-10-17T16:48:32Z", "2022-08-30T13:02:27Z"]}, {"name": "zksync-web-era-docs", "description": "zkSync Era Documentation", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync Documentation\n\n[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/matter-labs/zksync-web-v2-docs?color=%234E529A&label=changelog)](CHANGELOG.md)\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/matter-labs/zksync-web-era-docs/blob/main/LICENSE) [![GitHub license](https://img.shields.io/badge/license-Apache%202-blue)](https://github.com/matter-labs/zksync-web-era-docs/blob/main/LICENSE-APACHE)\n[![Follow us!](https://img.shields.io/twitter/follow/zksync?color=%234E529A&label=Follow%20%40zkSync&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iNDMiIGhlaWdodD0iMjUiIHZpZXdCb3g9IjAgMCA0MyAyNSIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00Mi42NTM5IDEyLjQ5MTVMMzAuODM3OCAwLjcxNjc0M1Y5LjM0TDE5LjEwNTUgMTcuOTczOUwzMC44Mzc4IDE3Ljk4MlYyNC4yNjYyTDQyLjY1MzkgMTIuNDkxNVoiIGZpbGw9IiM0RTUyOUEiLz4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0wLjk5ODA0NyAxMi40ODcyTDEyLjgxNDEgMjQuMjYxOVYxNS43MDhMMjQuNTQ2NSA3LjAwNDdMMTIuODE0MSA2Ljk5NjY0VjAuNzEyNDYzTDAuOTk4MDQ3IDEyLjQ4NzJaIiBmaWxsPSIjOEM4REZDIi8%2BCjwvc3ZnPgo%3D&style=flat)](https://twitter.com/zksync)\n\n## zkEVM\n\n> zkEVM is a virtual machine that executes smart contracts in a way that is compatible with zero-knowledge-proof computation.\n> Our zkEVM keeps EVM semantics, but is also ZK-friendly and adopts a traditional register-based CPU architecture.\n\n[zkSync Docs](https://docs.zksync.io) contain up-to-date information about **zkSync**.\nzkSync Era has built-in EVM compatibility which makes it a unified tool for releasing EVM-compatible ZK rollups.\nWe call it [zkEVM](https://zksync.io/zkevm): web3, Layer 2, scaling functionality that preserves your battle-tested code and knowledge gained after years of working with Solidity.\n\n## Build and setup\n\n### Initial setup\n\nThe frontend team chose the `yarn@berry` package manager, so ensure you install `node` version **LTS@14** after configuring `yarn`.\n\n```bash\n# configure yarn version: berry or specifically 3.1.1.\n$ yarn set version berry\n```\n\n### Main scripts\n\n```bash\n# install dependencies\n$ yarn add\n\n# serve with hot reload at localhost:8080\n$ yarn docs:dev\n# static generation to dist\n$ yarn docs:build\n```\n\n### Development\n\nThe continuous integration pipeline uses `prettier` and `markdownlint` to ensure there are no issues with your document, that spelling is correct, and there are no dead links.\n\nYou can check it locally as follows:\n\n```bash\n# check dead links\n$ yarn lint:dead\n# check spelling\n$ yarn lint:spell\n# check with markdownlint\n$ yarn lint:mdl\n# check with prettier\n$ yarn lint:fmt\n# fix with markdownlint\n$ yarn fix:mdl\n# fix with prettier\n$ yarn fix:fmt\n# run all checks\n$ yarn ci\n# run all fixes\n$ yarn ci:fix\n# build for production\n$ yarn ci:build\n```\n\nIf `lint:spell` doesn't recognize a word, and you\u2019re sure that it\u2019s correct, consider adding it to `cspell-zksync.txt`.\n\n## Search\n\nWe use Algolia to index our documentation. Know more about it [here](https://algolia.com). Dashboard is [here](https://dashboard.algolia.com/), and [Crawler Admin](https://crawler.algolia.com/) is here.\n\n## Contributions\n\n### Adding new tutorials\n\nTo add a new tutorial:\n\n- Fork the repository and create a new branch locally to add your changes.\n- Add the tutorial markdown file inside the `build/tutorials` folder.\n- Give the file an SEO-friendly name, as it is included in the live URL.\n- In the `.vuepress/sidebar/en.ts` file, add the tutorial inside this block:\n\n```js\n{\n  text: \"Tutorials\",\n  link: \"/dev/tutorials\",\n  children: [\n        \"/build/tutorials/cross-chain-tutorial.md\",\n        \"/build/tutorials/custom-aa-tutorial.md\",\n        \"/build/tutorials/aa-daily-spend-limit.md\",\n        \"/build/tutorials/custom-paymaster-tutorial.md\",\n        // ADD YOUR FILE HERE\n  ],\n},\n```\n\n- If your tutorial contains images, make sure to compress them using https://squoosh.app/ before adding them to the `assets/images` folder.\n- Finally, create a PR.\n\n### Deployment\n\nThe `main` branch is automatically deployed to <https://console.firebase.google.com/u/0/project/aqwzx-zksync-v2-docs>\n\nDeploying does the following:\n\n- Installs node modules.\n- Prepares, tests, and builds documentation.\n- Deploys everything contained in the `dist` folder as a static website.\n\n```bash\nyarn zk-ci-prepare\nyarn firebase deploy\n```\n\n## Extra documentation\n\n## cSpell\n\nConfiguration in `.cSpell.json`:\n\n- `version` \u2014 version of the setting file, always **0.1**.\n- `language` \u2014 current active spelling language.\n- `words[]` \u2014 list of correctly-spelled words.\n- `dictionaries[]`\n\n```json\n\"dictionaryDefinitions\": [\n  {\n    \"name\": \"zksync\", \"path\": \"./cspell-zksync.txt\"\n  }\n]\n```\n", "release_dates": ["2024-02-24T20:06:26Z", "2024-02-23T15:52:27Z", "2024-02-22T19:37:42Z", "2024-02-22T14:03:26Z", "2024-02-21T17:34:42Z", "2024-02-21T12:20:33Z", "2024-02-19T16:56:02Z", "2024-02-15T16:42:51Z", "2024-02-14T10:43:50Z", "2024-02-09T10:08:02Z", "2024-02-08T16:12:23Z", "2024-02-08T15:29:12Z", "2024-02-08T15:25:08Z", "2024-02-08T14:30:09Z", "2024-02-08T12:50:52Z", "2024-02-07T14:35:05Z", "2024-02-01T10:38:10Z", "2024-02-01T10:22:04Z", "2024-01-29T12:48:00Z", "2024-01-26T14:09:51Z", "2024-01-26T13:20:25Z", "2024-01-26T12:11:01Z", "2024-01-25T16:22:35Z", "2024-01-25T14:33:48Z", "2024-01-23T14:35:55Z", "2024-01-23T14:32:26Z", "2024-01-18T20:21:05Z", "2024-01-18T18:59:56Z", "2024-01-18T16:41:22Z", "2024-01-18T14:49:34Z"]}, {"name": "zksync-web-landing", "description": "zkSync.io landing page", "language": "CSS", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# [zkSync.io](https://zksync.io/) [![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/matter-labs/zksync-web-landing/blob/main/LICENSE-MIT) [![GitHub license](https://img.shields.io/badge/license-Apache%202-blue)](https://github.com/matter-labs/zksync-web-landing/blob/main/LICENSE-MIT)\n\n# Website zkSync.io\n\nFirst public release of the updated zkSync.io landing page design\n\n## [CHANGELOG](./CHANGELOG.md)\n\n## Build Setup\n\n```bash\n# clear possible cache && install dependencies (clear install)\n$ sh cli-dev.sh ci\n\n# populate .env file as dev environment && serve with hot reload at localhost:3000\n$ yarn dev\n\n# build for dev\n$ build:stage\n# afterward you'll have prepared distributive in /public folder\n\n# build for production (only if you have firebase:auth)\n$ bash cli-dev.sh ci && yarn zk-ci-prepare\n```\n\nFor detailed explanation on how things work, check out [Nuxt.js docs](https://nuxtjs.org).\n\n---\n\n## Solutions used\n\n- [Nuxt.js](https://nuxtjs.org)\n- [TS Lang](https://www.typescriptlang.org)\n- [Vue.js](https://vuejs.org)\n", "release_dates": ["2022-09-16T09:06:10Z", "2022-08-09T12:28:42Z", "2022-06-14T21:15:28Z", "2022-06-14T08:45:55Z", "2022-06-10T08:32:57Z", "2022-06-02T15:23:33Z", "2022-06-01T10:52:46Z", "2022-05-31T08:22:14Z", "2022-05-30T12:15:08Z", "2022-05-26T17:25:49Z", "2022-05-18T13:37:11Z"]}, {"name": "zksync-web-v2-docs-1", "description": "zkSync v2.0 Documentation", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# zkSync v2.0 Documentation \n[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/matter-labs/zksync-web-v2-docs?color=%234E529A&label=changelog)](CHANGELOG.md)\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/matter-labs/zksync-wallet/blob/master/LICENSE-MIT) [![GitHub license](https://img.shields.io/badge/license-Apache%202-blue)](https://github.com/matter-labs/zksync-wallet/blob/master/LICENSE-MIT)\n[![Follow us!](https://img.shields.io/twitter/follow/zksync?color=%234E529A&label=Follow%20%40zkSync&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iNDMiIGhlaWdodD0iMjUiIHZpZXdCb3g9IjAgMCA0MyAyNSIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00Mi42NTM5IDEyLjQ5MTVMMzAuODM3OCAwLjcxNjc0M1Y5LjM0TDE5LjEwNTUgMTcuOTczOUwzMC44Mzc4IDE3Ljk4MlYyNC4yNjYyTDQyLjY1MzkgMTIuNDkxNVoiIGZpbGw9IiM0RTUyOUEiLz4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0wLjk5ODA0NyAxMi40ODcyTDEyLjgxNDEgMjQuMjYxOVYxNS43MDhMMjQuNTQ2NSA3LjAwNDdMMTIuODE0MSA2Ljk5NjY0VjAuNzEyNDYzTDAuOTk4MDQ3IDEyLjQ4NzJaIiBmaWxsPSIjOEM4REZDIi8%2BCjwvc3ZnPgo%3D&style=flat)](https://twitter.com/zksync)\n\n\n## zkEVM\n\n> zkEVM is a virtual machine that executes smart contracts in a way that is compatible with zero-knowledge-proof computation. \n> Our zkEVM keeps EVM semantics, but is also ZK-friendly and takes on traditional CPU architectures.\n\nConstantly updated, [zkSync: Docs for 2.0](https://v2-docs.zksync.io/dev) offers the most complete knowledge about the upcoming **zkSync 2.0**. \nzkSync 2 release has built-in EVM-compatibility which makes it a single key to release EVM-compatible ZK rollup.\nWe call it [zkEVM](https://zksync.io/zkevm): long-awaited way to preserve the battle-tested code and knowledge\ngained after years of working with Solidity scaling it with the Layer 2.\n\n## Build and setup\n\n### Initial setup\n\nFrontend team chosen `yarn@berry` for packager, so don't forget to install `node` version **LTS@14** and after configure `yarn`\n\n``` bash\n# configure yarn version: berry or specifically 3.1.1.\n$ yarn set version berry\n\n# ...then assure no1deLinker is configured for node_modules\n$ yarn config set nodeLinker \"node_modules\"\n# you should see:\n# \u27a4 YN0000: Successfully set nodeLinker to 'node_modules'\n\n# the regular dependency installation (with re-validation of the local cache\n$ yarn install --check-cache\n```\n\n### Main scripts\n\n```bash\n# clear possible cache && install dependencies (clear install)\n$ sh cli-dev.sh ci\n\n# serve with hot reload at localhost:8080\n$ yarn docs:dev\n\n# static generation to dist\n$ yarn docs:build\n```\n\n### Development\n\nCI pipeline will check that the files are formatted according to `prettier`, `markdownlint` founds no issues in document\nand spelling is correct. Also, there should be no dead links.\n\nYou can check it locally as follows:\n\n```bash\n# check dead links\n$ yarn lint:dead\n\n# check spelling\n$ yarn lint:spell\n\n# check with markdownlint\n$ yarn lint:mdl\n\n# check with prettier\n$ yarn lint:fmt\n\n# fix with markdownlint\n$ yarn fix:mdl\n\n# fix with prettier\n$ yarn fix:fmt\n\n# run all checks\n$ yarn ci\n\n# run all fixes\n$ yarn ci:fix\n\n# build for production\n$ yarn ci:build\n```\n\nIf `lint:spell` doesn't recognize a word but you're sure that it's correct, consider adding it to the `cspell-zksync.txt`.\n\n### Deployment\n\n`main` branch is automatically deployed to <https://console.firebase.google.com/u/0/project/aqwzx-zksync-v2-docs>\n\n#### Deploying altogether\n\n> will do:\n\n* install node modules;\n* prepare, test and build documentation;\n* afterwards all contained into the `dist` folder will be deployed in form of the static website\n\n```bash\nyarn zk-ci-prepare\nyarn firebase deploy\n```\n\n## Extra documentation\n\n## cSpell\n\nConfiguration in `.cSpell.json`:\n * `version` \u2014 version of the setting file, always **0.1**\n * `language` \u2014 language - current active spelling language\n * `words[]` \u2014 words - list of words to be always considered correct\n * `dictionaries[]`\n\n```json\n\"dictionaryDefinitions\": [\n  {\n    \"name\": \"zksync\", \"path\": \"./cspell-zksync.txt\"\n  }\n]\n```\n", "release_dates": []}, {"name": "zksync-withdrawal-finalizer", "description": "zkSync 2.0 Withdrawal Finalizer", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zksync-era-withdrawal-finalizer\n\nA Withdrawal Finalizer in Rust.\n\n## Purpose\n\nWithdrawal Finalizer is a component of `zksync-era` responsible for monitoring and finalizing [L2->L1 withdrawals](https://github.com/matter-labs/zksync-era/blob/main/docs/advanced/03_withdrawals.md). It does so by continuously monitoring events happening on both L2 and L1, keeping some state in persistent storage (which is PostgreSQL) and sending withdrawal finalization transactions whenever necessary.\n\n## Building\n\nBuilding the project is straightforward:\n\n```\ncargo build\n```\n\n## Deploying\n\nTo deploy this service you will need the following prerequisites:\n\n1. Websocket RPC endpoint on Ethereum.\n2. Websocket RPC endpoint on zkSync Era.\n3. An instance of PostgreSQL database.\n\n### Running DB migrations\n\nPrior to deployment of the service the database migrations have to be run with [`sqlx-cli`](https://github.com/launchbadge/sqlx/tree/main/sqlx-cli) component of [`sqlx`](https://github.com/launchbadge/sqlx):\n\n```\n$ cd ./storage\n$ env DATABASE_URL=postgres://mycreds@myhost/mydb sqlx database create\n$ env DATABASE_URL=postgres://mycreds@myhost/mydb sqlx migrate run\n```\n### Configuration\n\nConfiguration is done via environment variables that can also be read from `.env` file if it is present. \nDeployment is done by deploying a dockerized image of the service.\n\n| Variable | Description |\n| -------- | ----------- |\n| `ETH_CLIENT_WS_URL` | The address of Ethereum WebSocket RPC endpoint |\n| `ETH_CLIENT_HTTP_URL` | The address of Ethereum HTTP RPC endpoint |\n| `CONTRACTS_L1_ERC20_BRIDGE_PROXY_ADDR` | Address of the L1 ERC20 bridge contract** |\n| `CONTRACTS_L2_ERC20_BRIDGE_ADDR` | Address of the L2 ERC20 bridge contract** |\n| `CONTRACTS_DIAMOND_PROXY_ADDR` | Address of the L1 diamond proxy contract** |\n| `CONTRACTS_WITHDRAWAL_FINALIZER_CONTRACT` | Address of the Withdrawal Finalizer contract ** |\n| `API_WEB3_JSON_RPC_WS_URL` | Address of the zkSync Era WebSocket RPC endpoint |\n| `API_WEB3_JSON_RPC_HTTP_URL` | Address of the zkSync Era HTTP RPC endpoint |\n| `DATABSE_URL` | The url of PostgreSQL database the service stores its state into |\n| `GAS_LIMIT` | The gas limit of a single withdrawal finalization within the batch of withdrawals finalized in a call to `finalizeWithdrawals` in WithdrawalFinalizerContract |\n| `BATCH_FINALIZATION_GAS_LIMIT` | The gas limit of the finalization of the whole batch in a call to `finalizeWithdrawals` in Withdrawal Finalizer Contract |\n| `WITHDRAWAL_FINALIZER_ACCOUNT_PRIVATE_KEY` | The private key of the account that is going to be submit finalization transactions |\n| `TX_RETRY_TIMEOUT_SECS` | Number of seconds to wait for a potentially stuck finalization transaction before readjusting its fees |\n| `TOKENS_TO_FINALIZE` | Configures the sets of tokens this instance of finalizer will finalize. It may be configured as a whitelist, a blacklist, a wildcard or completely disable any finalization. For more info see below. |\n| `FINALIZE_ETH_TOKEN` | (Optional) Configure, whether the Ethereum withdrawal events should be monitored. Useful to turn off for custom bridges that are only interested in a particular ERC20 token and have nothing to do with main Ethereum withdrawals |\n| `CUSTOM_TOKEN_DEPLOYER_ADDRESSES` | (Optional) Normally ERC20 tokens are deployed by the bridge contract. However, in custom cases it may be necessary to override that behavior with a custom set of addresses that have deployed tokens |\n| `CUSTOM_TOKEN_ADDRESSES` | (Optional) Adds a predefined list of tokens to finalize. May be useful in case of custom bridge setups when the regular technique of finding token deployments does not work. |\n| `ENABLE_WITHDRAWAL_METERING` | (Optional, default: `\"true\"`) By default Finalizer collects metrics about withdrawn token volumens. Users may optionally switch off this metering. |\n| `ETH_FINALIZATION_THRESHOLD`| (Optional, default: \"0\") Finalizer will only finalize ETH withdrawals that are greater or equal to this value |\n\nThe configuration structure describing the service config can be found in [`config.rs`](https://github.com/matter-labs/zksync-withdrawal-finalizer/blob/main/bin/withdrawal-finalizer/src/config.rs)\n\n** more about zkSync contracts can be found [here](https://github.com/matter-labs/era-contracts/blob/main/docs/Overview.md)\n\n## Configuring Tokens to finalize.\n\nIt may be handy to limit a set of tokens the Finalizer is finalizing. This\nconfiguration may be specified by setting a rule in the `TOKENS_TO_FINALIZE` value.\nIf this environment variable is not set then by default Finalizer will only finalize\nETH token (`0x000...0800a`).\n\nYou may specify `All`, `None`, `BlackList` or `WhiteList` as json documents:\n\n1. `TOKENS_TO_FINALIZE = '\"All\"'` - Finalize everything\n1. `TOKENS_TO_FINALIZE = '\"None\"'` - Finalize nothing\n1. `TOKENS_TO_FINALIZE = '{ \"WhiteList\":[ \"0x3355df6D4c9C3035724Fd0e3914dE96A5a83aaf4\" ] }'` - Finalize only these tokens\n1. `TOKENS_TO_FINALIZE = '{ \"BlackList\":[ \"0x3355df6D4c9C3035724Fd0e3914dE96A5a83aaf4\" ] }'` - Finalize all tokens but these\n\n## Deploying the finalizer smart contract\n\nThe finalizer smart contract needs to reference the addresses of the diamond proxy contract and l1 erc20 proxy contract.\nYou also need to know the key of the account you want to use to deploy the finalizer contract.\n\nWhen you know those to deploy the contract you need to run (assume you are running `anvil` in a separate terminal):\n\n```\n$ yarn\n$ env CONTRACTS_DIAMOND_PROXY_ADDR=\"0x9A6DE0f62Aa270A8bCB1e2610078650D539B1Ef9\" CONTRACTS_L1_ERC20_BRIDGE_PROXY_ADDR=\"0x2Ae09702F77a4940621572fBcDAe2382D44a2cbA\" MNEMONIC=\"test test test test test test test test test test test junk\" ETH_CLIENT_WEB3_URL=\"http://localhost:8545\" npx hardhat run ./scripts/deploy.ts\n```\n\nIf all goes well the the result would be\n\n```\n...\nCompiled 18 Solidity files successfully (evm target: paris).\nCONTRACTS_WITHDRAWAL_FINALIZER_ADDRESS=0x712516e61C8B383dF4A63CFe83d7701Bce54B03e\n```\n\nAnd so you know the address of the deployed contract.\n\n\n## License\n\nzkSync Withdrawal Finalizer is distributed under the terms of either\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n\nat your option.\n\n## Official Links\n\n- [Website](https://zksync.io/)\n- [GitHub](https://github.com/matter-labs)\n- [Twitter](https://twitter.com/zksync)\n- [Twitter for Devs](https://twitter.com/zkSyncDevs)\n- [Discord](https://discord.gg/nMaPGrDDwk)\n\n## Disclaimer\n\nzkSync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go\nthrough more audits and bug bounties programs. We would love to hear our community's thoughts and suggestions about it!\nIt is important to state that forking it now can potentially lead to missing important security updates, critical\nfeatures, and performance improvements.\n", "release_dates": ["2024-02-21T10:42:40Z", "2024-02-12T17:36:54Z", "2024-01-30T20:57:04Z", "2024-01-19T17:49:27Z", "2024-01-18T14:11:22Z", "2024-01-18T11:28:15Z", "2024-01-17T16:07:44Z", "2024-01-16T18:17:25Z", "2023-11-14T16:49:25Z", "2023-11-14T15:41:52Z", "2023-11-14T13:15:20Z", "2023-11-13T22:11:03Z", "2023-11-13T20:09:38Z", "2023-11-09T18:29:40Z", "2023-11-06T14:05:54Z", "2023-11-06T12:52:15Z", "2023-11-03T15:51:20Z", "2023-11-03T15:14:05Z", "2023-10-30T13:14:53Z", "2023-10-30T13:14:47Z", "2023-10-30T13:14:51Z", "2023-10-30T13:14:50Z", "2023-10-30T13:14:45Z", "2023-10-30T13:14:48Z", "2023-10-30T13:14:44Z", "2023-10-30T13:14:43Z", "2023-10-20T09:51:30Z", "2023-10-20T08:33:56Z", "2023-10-20T07:58:18Z", "2023-10-20T06:29:49Z"]}, {"name": "zksync2-js-evm-equiv", "description": null, "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# \ud83d\ude80 zksync2-js JavaScript SDK \ud83d\ude80\n\nIn order to provide easy access to all the features of zkSync Era, the `zksync2-js` JavaScript SDK was created,\nwhich is made in a way that has an interface very similar to those of [ethers](https://docs.ethers.io/v6/). In\nfact, `ethers` is a peer dependency of our library and most of the objects exported by `zksync2-js` (\ne.g. `Wallet`, `Provider` etc.) inherit from the corresponding `ethers` objects and override only the fields that need\nto be changed.\n\nWhile most of the existing SDKs should work out of the box, deploying smart contracts or using unique zkSync features,\nlike account abstraction, requires providing additional fields to those that Ethereum transactions have by default.\n\nThe library is made in such a way that after replacing `ethers` with `zksync2-js` most client apps will work out of\nbox.\n\n\ud83d\udd17 For a detailed walkthrough, refer to the [official documentation](https://era.zksync.io/docs/api/js/zksync2-js).\n\n## \ud83d\udccc Overview\n\nTo begin, it is useful to have a basic understanding of the types of objects available and what they are responsible for, at a high level:\n\n-   `Provider` provides connection to the zkSync Era blockchain, which allows querying the blockchain state, such as account, block or transaction details,\n    querying event logs or evaluating read-only code using call. Additionally, the client facilitates writing to the blockchain by sending\n    transactions.\n-   `Wallet` wraps all operations that interact with an account. An account generally has a private key, which can be used to sign a variety of\n    types of payloads. It provides easy usage of the most common features.\n\n## \ud83d\udee0 Prerequisites\n\n-   `node: >= 18` ([installation guide](https://nodejs.org/en/download/package-manager))\n-   `ethers: ^6.7.1`\n\n## \ud83d\udce5 Installation & Setup\n\n```bash\nyarn add zksync2-js\nyarn add ethers@6 # ethers is a peer dependency of zksync2-js\n```\n\n## \ud83d\udcdd Examples\n\nThe complete examples with various use cases are available [here](https://github.com/zksync-sdk/zksync2-examples/tree/main/js).\n\n### Connect to the zkSync Era network:\n\n```ts\nimport { Provider, utils, types } from \"zksync2-js\";\nimport { ethers } from \"ethers\";\n\nconst provider = Provider.getDefaultProvider(types.Network.Goerli); // zkSync Era testnet (L2)\nconst ethProvider = ethers.getDefaultProvider(\"goerli\"); // goerli testnet (L1)\n```\n\n### Get the latest block number\n\n```ts\nconst blockNumber = await provider.getBlockNumber();\n```\n\n### Get the latest block\n\n```ts\nconst block = await provider.getBlock(\"latest\");\n```\n\n### Create a wallet\n\n```ts\nconst PRIVATE_KEY = process.env.PRIVATE_KEY;\nconst wallet = new Wallet(PRIVATE_KEY, provider, ethProvider);\n```\n\n### Check account balances\n\n```ts\nconst ethBalance = await wallet.getBalance(); // balance on zkSync Era network\n\nconst ethBalanceL1 = await wallet.getBalanceL1(); // balance on goerli network\n```\n\n### Transfer funds\n\nTransfer funds among accounts on L2 network.\n\n```ts\nconst receiver = Wallet.createRandom();\n\nconst transfer = await wallet.transfer({\n    to: receiver,\n    token: utils.ETH_ADDRESS,\n    amount: ethers.parseEther(\"1.0\"),\n});\n```\n\n### Deposit funds\n\nTransfer funds from L1 to L2 network.\n\n```ts\nconst deposit = await wallet.deposit({\n    token: utils.ETH_ADDRESS,\n    amount: ethers.parseEther(\"1.0\"),\n});\n```\n\n### Withdraw funds\n\nTransfer funds from L2 to L1 network.\n\n```ts\nconst withdrawal = await wallet.withdraw({\n    token: utils.ETH_ADDRESS,\n    amount: ethers.parseEther(\"1.0\"),\n});\n```\n\n## \ud83e\udd1d Contributing\n\nWe welcome contributions from the community! If you're interested in contributing to the zksync2-js JavaScript SDK,\nplease take a look at our [CONTRIBUTING.md](./.github/CONTRIBUTING.md) for guidelines and details on the process.\n\nThank you for making zksync2-js JavaScript SDK better! \ud83d\ude4c\n", "release_dates": []}, {"name": "zkvyper-bin", "description": "This repository contains current and historical builds of the zkEVM Vyper Compiler.", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# zkvyper-bin\n\nThis repository contains current and historical builds of the zkEVM Vyper Compiler. \n\n[Compiler changelog](https://github.com/matter-labs/era-compiler-vyper/blob/-/CHANGELOG.md)\n\n## Troubleshooting \n- The binary may need to have its executable bit set:\n \n```chmod a+x <path to file>```\n\n- On macOS, the binary may need to have its quarantine attribute cleared: \n\n```xattr -d com.apple.quarantine <path to file>```\n", "release_dates": ["2024-02-21T14:29:10Z", "2024-02-14T19:40:33Z", "2024-01-12T21:57:34Z", "2024-01-05T14:03:25Z", "2023-12-19T13:54:22Z", "2023-10-30T20:49:51Z", "2023-09-14T11:38:47Z", "2023-09-06T12:37:53Z", "2023-09-06T12:35:28Z", "2023-09-06T12:34:23Z", "2023-09-06T12:27:21Z", "2023-09-06T12:26:43Z", "2023-09-06T12:25:52Z", "2023-09-06T12:25:38Z", "2023-09-06T12:25:01Z", "2023-09-06T12:24:15Z"]}, {"name": "zk_os", "description": "OS for next iteration of the world computer", "language": "Rust", "license": null, "readme": "## Zk OS\n\nIdeally: Operation system for the next \"world computer\", that allows to run untrusted user programs expressed in native code (RISC-V ISA in our case, 32/64 bit, I + M set). We assume strictly serial execution model, with blocking IPC, and each program would pass resources from itself to the callee (mainly time ticks).\n\nIn practice for now: example repo to work together with our `risc_v_simulator` and used to implement more restricted version of isolation.\n\n## Grand vision\n\nOnce upon a time there was an Idea for Ethereum shards to have different interpreters, but so far it didn't happen. Let's try to fix this. Assume (via `risc_v_simulator` repo) that one has an access to ZK provable simulator of RISC-V 32 (now in the simulator) or 64 (that it most likely will be in practice) bit instruction set with I+M extensions (no usermode/MMU for now). It was oracle access to non-deterministic data via quasi-UART (read word/write word). And let's try to build an execution environment of smart-contracts that live in the common 32-byte address space, follow the same binary interface (e.g. Solidity's ABI), but their code can be either\n- bytecode of our zkVM\n- EVM bytecode\n- WASM\n\nand all of them can call each other! For a moment (because simulator has no interrup functionality) we can ignore resource metering, but it can actually be implemented without interrupts in our model.\n\nSo we can write a system that looks like:\n- small system layer that implement IO: storage, transient storage, events, memory allocation (note - no translation, so it'll require some creativity down the road). Note that we can implement all the nice tricks that were demonstrated by zkSync Era, for example lazy storage application, provable(!) pubdata discounts, and whatever we imagine, and all of the can be implemented by one(!) copy of Rust (read - normal language) code, and still be provable(!!!)\n- three interpreters listed above. Those may require to be butchered to don't abuse allocations (or use proper `Allocator` trait implementation controlled by out system layer), or even extended (more on it below). But for example for storage access they still would go and ask the system layer like \"give me storage slot X for contract Y\"\n- One can make any assumption about the \"origin\" of the interaction, but it should resemble a standard smart-contract call transaction, and in general few transactions make a block.\n- when one sees a \"FAR CALL\" (zkVM) / \"CALL\" (EVM) / some special host function call to other contract (WASM) it should pass the execution to another contract along with some resources\n\nSo the task we give you with this repo, example and description - try to make such a system. Be creative - because ALL the code that you write is provable, one can do interesting things. For example - when EVM bytecode is deployed, it's possible to preprocess is and e.g. create metadata of all jumpdests, or merklize, or check bytecode for some patterns, or one-pass JIT it even. Same for example for WASM - create a lookup table of block indexes -> offsets, or even JIT to native(!) RISC-V code, and if such JIT is not overly complex and somewhat \"safe\" - it will be huge efficiency boost. And remember - this action is just Rust code (no circuit), and done once, and proven - so it makes sense to sometimes to O(1) preprocessing on deployments for manifold saving in runtime later one\n\n## Another side\nWith this repo we also start more engaged work with community and final application developers in a form of RFPs that should say \"what do you want to see in the ideal blockchain execution environment\".\n\nFor example, we named \"transient storage\" above - it's super easy to implement (and zkSync Era has it actually for free with minimal modification of the current circuits), but was drowning in the proposals for a period of years.\n\nOr may be it would be nice to have immutable-like variables, but not mixed in the \"code\" and rather just stored alongside the code itself - in special constants area. So ALL contracts that have the same CODE (that is LOGIC and LAW) would literally have same bytecode hash (for ease of comparison), regardless of what constants were chosen by the deploying party.\n\nBe creative here and leave such proposals or feature requests for the \"system layer\" in issues of this repo.\n\n## What's in the repo\n\nThe repo itself is just a small example of how one can bootstrap the system, inspired by the [blog](https://osblog.stephenmarz.com/index.html) about OS development in Rust. It's not intended to be 100% correct or pretend to be anywhere like a good OS because our execution enviroment is different, for example we do not require threads/scheduling, or memory isolation (by translation) yet (but eventually we will need it!). It's a good starting/demo point to start desining an implementation of the vision above.\n", "release_dates": []}]