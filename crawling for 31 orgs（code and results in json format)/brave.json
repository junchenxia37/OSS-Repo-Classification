[{"name": "ab2cb", "description": "Convert AdBlock Plus filter lists to Safari iOS9 Content Blocker JSON", "language": "Python", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# ab2cb: convert AdBlock Plus content filters to Safari Content Blockers\n\nThere are a handful of [known issues](https://github.com/brave/ab2cb/pull/5#issuecomment-672247647) with this script. It's recommended to use [`adblock-rust`](https://github.com/brave/adblock-rust)'s content blocking conversion support instead.\n\nThe `ab2cb` script reads filter lists as used by AdBlock Plus and produces a JSON Content Blocker file.\n\nDocumentation on Content Blockers is a bit sparse. The best source seems to be reading the Safari test source code.\n\n\n## Examples\n\n### Convert  A File\n\n```shell\n$ ab2cb -o blockList.json easylist.txt\n```\n\n### Read From stdin and Write To stdout\n\n```shell\n$ curl -s https://easylist-downloads.adblockplus.org/easylist.txt | ab2cb > blockList.json\n```\n\n## Usage\n\n```shell\n$ ab2cb -h\nusage: ab2cb [options] [File ...]\n\nab2cb: convert AdBlock content filters to Safari Content Blockers\n\npositional arguments:\n  File                  Files to extract from. If not given read from stdin.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --version             show program's version number and exit\n  --debug               Turn on debug logging.\n  --debug-log FILE      Save debug logging to FILE.\n  -o FILE, --output FILE\n                        Save converted text to FILE. If not given, output to\n                        stdout.\n  --no-white            Do not produce white list rules.\n```\n\n\n##  To Run\n\n1. Clone this repo\n2. cd to the repo\n3. Setup virtualenv with Python 3 (if needed)\n    ```shell\n    python3 -m venv venv\n    source ./venv/bin/activate\n    pip install tox pep8\n    ```\n4. Activate with the command: `. bin/activate.sh`\n5. Make the dev environment with the command: `make dev`\n6. Run `ab2cb -h` to verify executable works\n\nWhen done, you can close things out\n1. Deactivate with `. bin/deactivate.sh`\n2. `deactivate` virtualenv\n\n## Testing\n\n1. Setup virtualenv with Python 3 (if needed)\n\t```shell\n\tpython3 -m venv venv\n\tsource ./venv/bin/activate\n\tpip install tox pep8\n\t```\n2. Run the tests\n\t```shell\n\tmake test\n\t```\n\n\n### Testing filters\n\nCurrently this is manual: you have to load the content blocker json into Safari, navigate to a test page and check the blocking using the web inspector. I'm working on automating this.\n\nThere is a small JavaScript file in the test directory called `check.js` that will load a json file and check the regex compiles.\n\n\n## References\n\nSafari Extensibility: Content Blocking and Shared Links\nWWDC 2015 Video\nhttps://developer.apple.com/videos/wwdc/2015/?id=511\n\nEasyList\nhttps://easylist.adblockplus.org/en/\n\nWriting Adblock Plus filters\nhttps://adblockplus.org/en/filters\n\nIntroduction to WebKit Content Blockers\nSurfin' Safari Blog\nhttps://www.webkit.org/blog/3476/content-blockers-first-look/\n\nAdBlock Plus\nfilterClasses.js\nhttps://github.com/adblockplus/adblockplus/blob/master/lib/filterClasses.js\n\nWebKit Tests\nContentExtensions.cpp\nhttp://trac.webkit.org/browser/trunk/Tools/TestWebKitAPI/Tests/WebCore/ContentExtensions.cpp\n\n", "release_dates": []}, {"name": "ad-block-visualize", "description": "Tools to help visualize ad-block list data.", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Ad Block Visualization\n\nTools to help visualize ad-block list data.\n\n## Types of charts\n\n- Filter types   \n  https://plot.ly/~bbondy/2.embed\n- Filters by domain list   \n \u00a0https://plot.ly/~bbondy/4.embed\n\n## Development\n\nAdd the following content at this location: `~/.plotly/.credentials`\n\n```\n{\n    \"username\": \"username-here\",\n    \"api_key\": \"api-key-here\"\n}\n```\n\n```\nyarn install\nyarn start\n```\n\nYou will see output for the URL to use to view the generated charts.\n", "release_dates": []}, {"name": "adblock-lists", "description": "Maintains adblock lists that Brave uses", "language": "Adblock Filter List", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Lists\n\nIf you modify any of these lists, follow [these instructions](https://github.com/brave/ad-block/wiki/Testing-ad-block-rule-changes-in-Brave) to test your changes locally.\n\n## brave-unbreak.txt\n\nCombined with all lists, including regional.\n\n## coin-miners.txt\n\nTracks URLs that do coin mining.\n", "release_dates": []}, {"name": "adblock-resources", "description": "Custom resources and scriptlets used for Brave's adblocker", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# adblock-resources\n\nContains resources and scriptlets designed for use with Brave's [adblock-rust](https://github.com/brave/adblock-rust) library.\n\nCustom resources should be added to the `resources` directory, and a corresponding entry should be added to the `metadata.json` file.\n\n## Using\n\nThis package can be imported as a library, exposing the function `readResources` which will produce the correctly formatted list of resources for use with [adblock-rust](https://github.com/brave/adblock-rust).\n\nAlternatively, `npm run build` will write all resources to `dist/resources.json` for future use.\n\nTo generate `metadata.json` automatically from files in `resources/`, run `npm run generateMetadata`.\n\nUse `npm run test` after modifying the resources or metadata file to ensure the format can be accepted by `adblock-rust`.\n\n## Metadata format\n\n`metadata.json` is a list of elements of the following format:\n\n```json\n{\n    \"name\": \"name-of-my-resource\",\n    \"aliases\": [\"an-alias-for-my-resource\"],\n    \"kind\": {\"mime\":\"application/javascript\"},\n    \"resourcePath\": \"pathRelativeToResources.js\"\n}\n```\n\n- `name` is the name of the resource as it would be used in a filter rule.\n\n- `aliases` is a list containing optional additional (usually shorter) identifiers that could be used instead of the `name`. Usually this is empty or contains a single entry that is an abbreviation of the `name`.\n\n- `kind` is either a MIME type as shown above, or simply the string `\"template\"` to specify that the resource is a scriptlet with optional template parameters (i.e., `{{1}}`, `{{2}}`, ...).\n\n- `resourcePath` specifies the path to the content of the resource. It should be relative to the `resources` directory in the root of this repository.\n\nIn general, this format corresponds to the `Resource` struct from [adblock-rust](https://github.com/brave/adblock-rust), but the base64-encoded `content` field is replaced by a path to a file for better maintainability. This library will translate the `resourcePath` field back to a base64-encoded `content` field when ready for use.\n\n## Filter list description format\n\nThe `filter_lists/*.json` files are lists of elements, each describing a filter list. The format for each element is:\n\n```json\n{\n    \"title\": \"New Filter Rules\",\n    \"desc\": \"Removes new elements\"\n    \"langs\": [],\n    \"component_id\": \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\",\n    \"base64_public_key\": \"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs...IDAQAB\",\n    \"list_text_component\": {\n        \"component_id\": \"bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\",\n        \"base64_public_key\": \"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs...IDAQAB\",\n    },\n    \"sources\": [\n        {\n            \"url\": \"https://raw.githubusercontent.com/brave/adblock-lists/master/brave-lists/new-list.txt\",\n            \"title\": \"Brave New List\",\n            \"format\": \"Standard\",\n            \"support_url\": \"https://github.com/brave/adblock-lists\",\n        }\n    ]\n}\n```\n\n- `uuid` is a UUID generated with, for example, the CLI tool `uuidgen`.\n\n- `title` is a human-readable title for the filter list component. Each source also has a title, which is a human-readable title for each individual list making up the full component.\n\n- `desc` is a short human-readable description of what the filter list is designed to block.\n\n- `langs` is a list of _locale codes_ for the given component, allowing it to be preselected in-browser by users in the corresponding regions. Note that despite the name, it should not list _language codes_.\n\n- `component_id` and `base64_public_key` are unique constants generated per-list such that the lists can be served in CRX components created by [brave-core-crx-packager](https://github.com/brave/brave-core-crx-packager). Note that the ones inside `list_text_component` should not have the same values.\n\n- `sources` is a list of individual filter lists that are concatenated together in order to create the full list for a component.\n\n- `url` is the URL where a filter list source can be downloaded from. It should be a list of rules in the format specified in `format` in a plaintext file.\n\n- `format` is either ABP/uBO-style format (\"Standard\", most common) or IP address and hostname (\"Hosts\").\n\n- `support_url` is somewhere a user can ask for help with the filter list.\n\n### Optional fields\n\nThe following 4 fields are all optional and default to `false` or `0` if omitted.\n\n- `hidden` (`boolean`) should the component be displayed in brave://settings/shields/filters as an additional list option?\n- `default_enabled` (`boolean`) should the component be enabled by default?\n- `first_party_protections` (`boolean`) should first-party heuristics be applied to rules from the list?\n- `permission_mask` (`number`) what scriptlet permissions should be granted to rules from the list?\n  The bits of the bitmask are currently assigned as follows:\n    - Bit `0`: \"trusted\" resources from the uBlock Origin project\n    - Bit `1`: resources only intended for use by Brave-authored lists\n    - Bits `2`-`7`: reserved\n\n## Adding a new list\n\nThe `generate_component.sh` script can be used to help create a new filter list component.\nIt will generate:\n- A UUID (for the top-level `uuid` field)\n- A public key (corresponding to the `list_text_component.base64_public_key` field)\n- A component ID (corresponding to the `list_text_component.component_id` field)\n- The component's private key (in a new PEM file)\n\nThe script should be run with no arguments.\nThe resulting PEM file will be named `ad-block-updater-<component_id>.pem`. This new PEM file has to be uploaded to 1Password. See instructions [here](https://github.com/brave/internal/wiki/Uploading-new-adblock-list-PEM-file-to-1Password).\n\nWe will need to run this script a second time to get values for the top-level `base64_public_key` and `component_id` fields. These will be different from the values for `list_text_component.base64_public_key` and `list_text_component.component_id` fields. This is necessary for iOS, see [tracking issue](https://github.com/brave/brave-ios/issues/5974).\n", "release_dates": []}, {"name": "adblock-rust", "description": "Brave's Rust-based adblock engine", "language": "Rust", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# adblock-rust\n\n[![crates.io](https://img.shields.io/crates/v/adblock.svg)](https://crates.io/crates/adblock)\n[![npmjs.com](https://img.shields.io/npm/v/adblock-rs.svg)](https://www.npmjs.com/package/adblock-rs)\n[![docs.rs](https://docs.rs/adblock/badge.svg)](https://docs.rs/adblock)\n![Build Status](https://github.com/brave/adblock-rust/actions/workflows/ci.yml/badge.svg)\n[![License](https://img.shields.io/badge/License-MPL--2.0-blue)](LICENSE.txt)\n\n### _Putting you back in control of your browsing experience._\n\n`adblock-rust` is the engine powering [Brave](https://brave.com)'s native adblocker, available as a library for anyone to use. It features:\n\n- Network blocking\n- Cosmetic filtering\n- Resource replacements\n- Hosts syntax\n- uBlock Origin syntax extensions\n- iOS content-blocking syntax conversion\n- Compiling to native code or WASM\n- Rust bindings ([crates](https://crates.io/crates/adblock))\n- JS bindings ([npm](https://npmjs.com/adblock-rs))\n- Community-maintained Python bindings ([pypi](https://pypi.org/project/adblock/))\n- High performance!\n\n## Getting started\n\n`adblock-rust` is used in several projects, including browsers, research tools, and proxies.\nIt may be a good fit for yours, too!\n\nSee [docs.rs](https://docs.rs/adblock) for detailed API documentation.\n\nAlso check the [Rust example](./examples/example.rs) or the [NodeJS example](./js/example.js).\n\n### Optional features\n\nThe following `cargo` [features](https://doc.rust-lang.org/cargo/reference/features.html) can be used to tweak `adblock-rust` to best fit your use-case.\n\n#### CSS validation during rule parsing (`css-validation`)\n\nWhen parsing cosmetic filter rules, it's possible to include a built-in implementation of CSS validation (through the [selectors](https://crates.io/crates/selectors) and [cssparser](https://crates.io/crates/cssparser) crates) by enabling the `css-validation` feature. This will cause `adblock-rust` to reject cosmetic filter rules with invalid CSS syntax.\n\n#### Content blocking format translation (`content-blocking`)\n\nEnabling the `content-blocking` feature gives `adblock-rust` support for conversion of standard ABP-style rules into Apple's [content-blocking format](https://developer.apple.com/documentation/safariservices/creating_a_content_blocker), which can be exported for use on iOS and macOS platforms.\n\n#### External domain resolution (`embedded-domain-resolver`)\n\nBy default, `adblock-rust` ships with a built-in domain resolution implementation (through the [addr](https://crates.io/crates/addr) crate) that will generally suffice for standalone use-cases. For more advanced use-cases, disabling the `embedded-domain-resolver` feature will allow `adblock-rust` to use an external domain resolution implementation instead. This is extremely useful to reduce binary bloat and improve consistency when embedding `adblock-rust` within a browser.\n\n#### Parsing resources from uBlock Origin's formats (`resource-assembler`)\n\n`adblock-rust` uses uBlock Origin-compatible resources for scriptlet injection and redirect rules.\nThe `resource-assembler` feature allows `adblock-rust` to parse these resources directly from the file formats used by the uBlock Origin repository.\n\n#### Thread safety (`object-pooling`, `unsync-regex-caching`)\n\nThe `object-pooling` and `unsync-regex-caching` features enable optimizations for rule matching speed and the amount of memory used by the engine.\nThese features can be disabled to make the engine `Send + Sync`, although it is recommended to only access the engine on a single thread to maintain optimal performance.\n", "release_dates": []}, {"name": "adblock-rust-ffi", "description": "An FFI crate to expose functionality from brave/adblock-rust", "language": "Rust", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# adblock-rust-ffi [![Build Status](https://travis-ci.org/brave/adblock-rust-ffi.svg?branch=master)](https://travis-ci.org/brave/adblock-rust-ffi)\n\n**A FFI crate C++ wrapper to expose functionality from [adblock-rust](https://github.com/brave/adblock-rust)**\n\nThe `adblock-rust` crate implements an Adblock Plus (ABP) filter parser and matcher. This\ncrate exposes C FFI functions and is configured to produce a static library so that the functionality\ncan be used in other languages.\n\nCurrently there are only bindings for C++.\n\n# Development\n\nWorking on this repository requires having Rust, g++, and valgrind installed.\n\n## Testing\n\nThere are end to end test binaries for C++ bindings, when run under\nvalgrind we can ensure memory is being properly freed.\n\n## C++\n\n### Running tests\n\n```\nmake sample\n```\n\n## Regenerating the C header\n\n```\ncbindgen -o src/lib.h\n```\n", "release_dates": []}, {"name": "ads-manager-landing-page", "description": null, "language": "HTML", "license": null, "readme": "# Brave Ads\n\nLanding page and supporting webpages for Brave Ads and the Brave Ads advertiser dashboard at https://ads.brave.com. \n", "release_dates": []}, {"name": "ads-ui", "description": "Self-service ads UI", "language": "TypeScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "<p align=\"center\">\n<img height=\"50\" src=\"./Subdomains_Rewards_Ads_Default.png\"/>\n</p>\n<br>\n\nBrave Ads Manager is a key component of the ads infrastructure. From the ads manager, advertisers are able to define unique ad campaigns and creatives. Additionally, advertisers can review delivery and engagement metrics on their ad campaigns.\n\n## Tech Stack & Philosophy\n\n`ads-manager` is built with [TypeScript](https://www.typescriptlang.org/) and [React.js](https://reactjs.org/).\n\nOur API requests are constructed as [GraphQL](https://graphql.org/) queries and are then handled by the [Apollo Client](https://www.apollographql.com/docs/react/).\n\n`ads-manager` routing is instrumented by the [React Router](https://github.com/ReactTraining/react-router), and testing is done using the [Jest](https://jestjs.io/) framework.\n\nOur application bundle is created with [webpack](https://webpack.js.org/) and stored on [AWS S3](https://aws.amazon.com/s3/).\n\nThis bundle is then served to users as a static asset by [AWS CloudFront CDN](https://aws.amazon.com/cloudfront/).\n\n## Local Development\n\n- Create a `.env.local` file, or update `.env` file provided\n- Set `BACKEND_URL=<>` to the endpoint you wish to pull data from.\n\n**Note:**\nWe are using HTTPS in developer mode so that cookie based authentication works properly.\nYou may need to proceed through a certificate warning in order to develop locally.\n\n### Generating GraphQL Types:\n\n```\n> npm run codegen\n```\n\n## Localization\nAfter changing text, o adding new translated text you need to run:\n```\n\u276f npm run extract\n```\n\nTHe output should look something like:\n```\n> ads-ui@0.1.0 extract\n> lingui extract\n\n\u2714\nCatalog statistics for src/locales/{locale}:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Language \u2502 Total count \u2502 Missing \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 en       \u2502     488     \u2502    0    \u2502\n\u2502 es       \u2502     491     \u2502   491   \u2502\n\u2502 pt       \u2502     491     \u2502   491   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n(use \"npm run extract\" to update catalogs with new messages)\n```\n\nThis extracts all new messages, and gives a brief glimpse of what you have translated so far.\nOnce translations are complete, they should be added to the `msgstr` portion of their respective language.\n\nTo add more locales, edit the `locales` array in `lingui.config.js` and run `npm run extract` again.\nMake sure you also update `i18n.ts` with the new locale.\n\n\n", "release_dates": []}, {"name": "audit-config", "description": "Additional audit configuration for Brave browser", "language": null, "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "This repository contains [a list](config.json) of audit findings to be\nsuppressed/ignored across [brave-core](https://github.com/brave/brave-core)\nbranches.\n\nThe identifier of a finding is a url for npm findings and an id for rust\nfindings, e.g.:\n* `https://github.com/advisories/GHSA-36jr-mh4h-2g58`\n* `RUSTSEC-2021-0139`\n", "release_dates": []}, {"name": "autoplay-whitelist", "description": null, "language": "C++", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# autoplay-whitelist\n\nC++ autoplay whitelist parser for Brave\n\n## Installation\n\n1. Clone the git repository from GitHub:\n\n        git clone https://github.com/brave/autoplay-whitelist\n\n2. Open the working directory:\n\n        cd autoplay-whitelist\n\n3. Install the Node (v5+) dependencies:\n\n        npm install\n\n## Build the node addon\n\n```\nnpm run install\n```\n\n## Generate the DAT file\n\n```\nnpm run data-files\n```\n\n## Running tests\n\n```\nnpm run test\n```\n", "release_dates": []}, {"name": "badge-matrix", "description": "More advanced badges for projects using Travis or Sauce Labs", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# badge-matrix\n\nMore advanced badges for your projects using Travis or Sauce Labs.\n\n[See it in action over at the `script-atomic-onload` project.](https://github.com/exogen/script-atomic-onload)\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n## Contents\n\n- [Badges](#badges)\n- [Web Service](#web-service)\n  - [Endpoints](#endpoints)\n    - [`/browsers`](#browsers)\n    - [`/sauce/:user`](#sauceuser)\n    - [`/size/:source/:path`](#sizesourcepath)\n    - [`/travis/:user/:repo`](#travisuserrepo)\n    - [`/travis/:user/:repo/sauce/:sauceUser`](#travisuserreposaucesauceuser)\n- [Deployment](#deployment)\n  - [Heroku](#heroku)\n  - [Anywhere else](#anywhere-else)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n## Badges\n\n**File size for any file on GitHub or npm**\n\n[![Builder package.json size](https://badges.herokuapp.com/size/github/FormidableLabs/builder/master/package.json)](https://github.com/FormidableLabs/builder)\n\n[![Victory size](https://badges.herokuapp.com/size/npm/victory/dist/victory.min.js?gzip=true)](https://www.npmjs.com/package/victory)\n\n**Slice your Travis build matrix by environment**\n\n![TEST_LOADER=jquery](https://badges.herokuapp.com/travis/exogen/script-atomic-onload?branch=master&env=TEST_LOADER=little-loader&label=TEST_LOADER=little-loader)\n\n![TEST_LOADER=little-loader](https://badges.herokuapp.com/travis/exogen/script-atomic-onload?branch=master&env=TEST_LOADER=jquery&label=TEST_LOADER=jquery)\n\n**Browser support matrix from Sauce Labs**\n\n[![Browser Status](https://badges.herokuapp.com/sauce/wml-little-loader)](https://saucelabs.com/u/wml-little-loader)\n\nBeautiful *and* customizable!\n\n* `?labels=none`\n\n  [![Browser Status](https://badges.herokuapp.com/sauce/wml-little-loader?labels=none)](https://saucelabs.com/u/wml-little-loader)\n* `?logos=none`\n\n  [![Browser Status](https://badges.herokuapp.com/sauce/wml-little-loader?logos=none)](https://saucelabs.com/u/wml-little-loader)\n* `?logos=none&labels=longName`\n\n  [![Browser Status](https://badges.herokuapp.com/sauce/wml-little-loader?logos=none&labels=longName)](https://saucelabs.com/u/wml-little-loader)\n\nUsing something other than Sauce Labs? Just construct a URL with results from\nyour browser tests.\n\n* `browsers?firefox=20,26&iexplore=!8,-9,10`\n\n  ![Browser Status](https://badges.herokuapp.com/browsers?firefox=20,26&iexplore=!8,-9,10)\n\n## Web Service\n\nDeployed at: `https://badges.herokuapp.com/`\n\nYou may also run your own instance using this package. See the **Deployment** section.\n\n### Endpoints\n\n#### `/browsers`\n\n  Render browser matrix badge based on support specified in the query\n  parameters, for cases where your testing is done with a service other than\n  Sauce Labs (otherwise use the `/sauce` endpoint), or you don\u2019t have CI and\n  just want to show your intended support.\n\n  **Query parameters**\n\n  * `android`,\n    `firefox`,\n    `googlechrome`,\n    `iexplore`,\n    `ipad`,\n    `iphone`,\n    `microsoftedge`,\n    `opera`,\n    `safari`\n\n    A comma-separated list of version numbers that were tested for the given\n    browser, e.g. `firefox=20,26`.\n\n    Prefix a version number to indicate status:\n\n    * **`+`** or no prefix: Passed.\n    * **`-`**: Failed.\n    * **`!`**: Error.\n  * `logos`,\n    `labels`,\n    `versionDivider`,\n    `style`\n\n    Same as the `/sauce/:user` endpoint below.\n\n#### `/sauce/:user`\n\n  Render browser support matrix badge for the Sauce Labs account at `:user`.\n\n  **Query parameters**\n\n  * `build`\n\n    Build number, it should match the `build` string of one or more jobs. By\n    default, try to find the most recent build. The build can be from any CI\n    service, not just Travis.\n\n    Sauce Labs\u2019 API doesn\u2019t allow filtering by build, so finding the jobs for a\n    build can be a bit of a hassle:\n\n    * If the requested build is not in the first 500 results returned by the\n      API, then you should specify `from` and `to` to limit the query window\n      to the time span of the build.\n    * If no `from` is given, then stop fetching more jobs from the API when a\n      different build number is encountered.\n\n    Jobs with a `null` value for `build` are never included.\n  * `name`\n\n    Name filter, it should match a whitespace separated substring in the `name`\n    of one or more jobs. Only jobs matching the filter will be included in the\n    result.\n  * `tag`\n\n    Tag filter, it should match a string in the `tags` array of one or more\n    jobs. Only jobs matching the filter will be included in the result.\n  * `from`\n\n    Start time (Unix epoch) of the window in which to find jobs. Passed along\n    to the Sauce Labs API.\n  * `to`\n\n    End time (Unix epoch) of the window in which to find jobs. Passed along to\n    the Sauce Labs API.\n  * `skip`\n\n    Number of initial jobs to skip. Passed along to the Sauce Labs API.\n  * `source`\n\n    Data source from which to render results, defaults to `svg`.\n\n    * **api**: Fetch results from the Sauce Labs API. This allows you to specify\n      any of the above query parameters for filtering jobs.\n    * **svg**: Fetch Sauce Labs\u2019 own browser matrix SVG widget and transform it\n      into our slimmer, beautified version. If you aren\u2019t using any of the\n      options above, and just want the same results as their own widget would\n      render, use this. If you try specifying any of the options above, the\n      server will automatically change `source` to `api`. This is probably much\n      faster than talking to the API, but it\u2019s a bit more fragile since their\n      SVG output could change.\n  * `logos`\n\n    How to render browser logos, defaults to **inside**.\n\n    * **inside** or **true**: Show logos in the label part of the badge.\n    * **none** or **false**: Don\u2019t show logos.\n  * `labels`\n\n    How to render browser labels, defaults to **shortName**.\n\n    * **shortName** or **true**: Short names, e.g. \"Chrome\", \"FF\", \"IE\".\n    * **name**: Medium names, e.g. \"Chrome\", \"Firefox\", \"Internet Explorer\".\n    * **longName**: Long names, e.g. \"Google Chrome\", \"Mozilla Firefox\",\n      \"Microsoft Internet Explorer\".\n    * **sauceName**: Browser identifiers used by Sauce Labs, e.g.\n      \"googlechrome\", \"firefox\", \"iexplore\".\n    * **none** or **false**: Don\u2019t show labels.\n  * `versionDivider`\n\n    How to render the divider between browser version numbers, defaults to\n    **none**.\n\n    * **none** or **false**: Don\u2019t show a divider.\n    * **line** or **true**: Show a subtle beveled line between version numbers.\n  * `style`\n\n    Badge style, defaults to **flat**. Styles match\n    [shields.io](http://shields.io/).\n\n    * **flat**: Round and smooth.\n    * **flat-square**: Square and flat.\n\n#### `/size/:source/:path`\n\n  Render a file size badge for any file on GitHub or npm.\n\n  * `:source` can be `github` or `npm`.\n  * `:path` can be any valid `raw.githubusercontent.com` or `unpkg.com` path\n    (when `:source` is `github` or `npm`, respectively).\n\n  **Query parameters**\n\n  * `gzip`\n\n    Whether to show the gzip-compressed size, defaults to **false**.\n\n    * **true**: Show compressed size.\n    * **false**: Show uncompressed size.\n  * `label`\n\n    Custom badge label, by default it will be \"size\" or \"size (gzip)\".\n  * `color`\n\n    Color name or value to pass along to [shields.io](http://shields.io/),\n    defaults to **brightgreen**. Note that the default may change to **blue** in\n    the future, as is somewhat conventional for purely informational,\n    non-qualitative badges like this one.\n  * `style`\n\n    Style to pass along to [shields.io](http://shields.io/).\n\n#### `/travis/:user/:repo`\n\n  Render build status badge for the Travis project at `:user/:repo`, counting\n  only build jobs that match the given `env` filter.\n\n  **Query parameters**\n\n  * `branch`\n\n    Git branch, defaults to **master**.\n  * `env`\n\n    Environment filter, it should match a `VAR=value` line in the `env`\n    section of your build matrix. All jobs in the build matching the filter\n    will be aggregated into one final status, similar to how Travis determines\n    an overall build status. If no filter is given, all jobs in the build are\n    included (even if they are Allowed Failures).\n  * `label`\n\n    Text label to render on the left side of the badge, defaults to the repo\n    name.\n  * `style`\n\n    Style to pass along to [shields.io](http://shields.io/).\n\n#### `/travis/:user/:repo/sauce/:sauceUser`\n\nRender browser support matrix badge for the Travis project at `:user/:repo`,\ngetting Sauce Labs results from `:sauceUser` (defaults to `:user`).\n\nYou can also use the `/sauce/:user` endpoint, but this way ensures that we\nonly consider Sauce Labs jobs that match up with the latest Travis build\nnumber for the given `branch`, and also makes the correct jobs easier to find\nsince Travis provides the time span of the build.\n\n**Query parameters**\n\n* `branch`\n\n  Git branch of the Travis build, defaults to **master**.\n* `name`,\n  `tag`,\n  `logos`,\n  `labels`,\n  `versionDivider`,\n  `style`\n\n  Same as the `/sauce/:user` endpoint above.\n\n## Deployment\n\nIf you want to run your own instance of `badge-matrix`, clone this repo.\n\n### Heroku\n\n1. Create a Heroku app.\n2. `npm run add-font` will copy `Verdana.ttf` from wherever it is on your system.\n3. `npm run deploy` will build the sources and deploy to Heroku.\n\n### Anywhere else\n\n1. `npm run build` will build the sources.\n2. `npm run add-font` will copy `Verdana.ttf` from wherever it is on your system.\n3. `npm start` will start the server.\n", "release_dates": []}, {"name": "bat-community-website", "description": "Official BAT Community website.", "language": "HTML", "license": null, "readme": "# BAT Commmunity Website\n\nOfficial website and portal for the Basic Attention Token community.\n\nhttps://batcommunity.org\n", "release_dates": []}, {"name": "bin-build", "description": "Easily build binaries", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# bin-build [![Build Status](https://travis-ci.org/kevva/bin-build.svg?branch=master)](https://travis-ci.org/kevva/bin-build)\n\n> Easily build binaries\n\n\n## Install\n\n```\n$ npm install --save bin-build\n```\n\n\n## Usage\n\n```js\nconst binBuild = require('bin-build');\n\nbinBuild.url('http://www.lcdf.org/gifsicle/gifsicle-1.80.tar.gz', [\n\t'./configure --disable-gifview --disable-gifdiff',\n\t'make install'\n]).then(() => {\n\tconsole.log('gifsicle built successfully');\n});\n\nbinBuild.file('gifsicle-1.80.tar.gz', [\n\t'./configure --disable-gifview --disable-gifdiff',\n\t'make install'\n]).then(() => {\n\tconsole.log('gifsicle built successfully');\n});\n```\n\n\n## API\n\n### binBuild.directory(directory, commands)\n\n#### directory\n\nType: `string`\n\nPath to a directory containing the source code.\n\n#### commands\n\nType: `Array`\n\nCommands to run when building.\n\n### binBuild.file(file, commands, [options])\n\n#### file\n\nType: `string`\n\nPath to a archive file containing the source code.\n\n#### commands\n\nType: `Array`\n\nCommands to run when building.\n\n#### options\n\nType: `Object`\n\n##### strip\n\nType: `number`<br>\nDefault: `1`\n\nStrip a number of leading paths from file names on extraction.\n\n### binBuild.url(url, commands, [options])\n\n#### url\n\nType: `string`\n\nURL to a archive file containing the source code.\n\n#### commands\n\nType: `Array`\n\nCommands to run when building.\n\n#### options\n\nType: `Object`\n\n##### strip\n\nType: `number`<br>\nDefault: `1`\n\nStrip a number of leading paths from file names on extraction.\n\n\n## License\n\nMIT \u00a9 [Kevin M\u00e5rtensson](https://github.com/kevva)\n", "release_dates": []}, {"name": "bin-wrapper", "description": "Binary wrapper that makes your programs seamlessly available as local dependencies", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# bin-wrapper [![CI](https://github.com/kevva/bin-wrapper/actions/workflows/ci.yml/badge.svg)](https://github.com/kevva/bin-wrapper/actions/workflows/ci.yml)\n\n> Binary wrapper that makes your programs seamlessly available as local dependencies\n\n\n## Install\n\n```sh\nnpm install bin-wrapper\n```\n\n\n## Usage\n\n```js\nimport path from 'node:path';\nimport BinWrapper from 'bin-wrapper';\n\nconst base = 'https://github.com/imagemin/gifsicle-bin/raw/main/vendor';\nconst bin = new BinWrapper()\n\t.src(`${base}/macos/gifsicle`, 'darwin')\n\t.src(`${base}/linux/x64/gifsicle`, 'linux', 'x64')\n\t.src(`${base}/win/x64/gifsicle.exe`, 'win32', 'x64')\n\t.dest(path.join('vendor'))\n\t.use(process.platform === 'win32' ? 'gifsicle.exe' : 'gifsicle')\n\t.version('>=1.71');\n\n(async () => {\n\tawait bin.run(['--version']);\n\tconsole.log('gifsicle is working');\n})();\n```\n\nGet the path to your binary with `bin.path()`:\n\n```js\nconsole.log(bin.path());\n//=> 'path/to/vendor/gifsicle'\n```\n\n\n## API\n\n### `new BinWrapper(options)`\n\nCreates a new `BinWrapper` instance.\n\n#### options\n\nType: `Object`\n\n##### skipCheck\n\n* Type: `boolean`\n* Default: `false`\n\nWhether to skip the binary check or not.\n\n##### strip\n\n* Type: `number`\n* Default: `1`\n\nStrip a number of leading paths from file names on extraction.\n\n### .src(url, [os], [arch])\n\nAdds a source to download.\n\n#### url\n\nType: `string`\n\nAccepts a URL pointing to a file to download.\n\n#### os\n\nType: `string`\n\nTie the source to a specific OS.\n\n#### arch\n\nType: `string`\n\nTie the source to a specific arch.\n\n### .dest(destination)\n\n#### destination\n\nType: `string`\n\nAccepts a path which the files will be downloaded to.\n\n### .use(binary)\n\n#### binary\n\nType: `string`\n\nDefine which file to use as the binary.\n\n### .path()\n\nReturns the full path to your binary.\n\n### .version(range)\n\n#### range\n\nType: `string`\n\nDefine a [semver range](https://github.com/npm/node-semver#ranges) to check\nthe binary against.\n\n### .run([arguments])\n\nRuns the search for the binary. If no binary is found it will download the file\nusing the URL provided in `.src()`.\n\n#### arguments\n\n* Type: `Array`\n* Default: `['--version']`\n\nCommand to run the binary with. If it exits with code `0` it means that the\nbinary is working.\n\n\n## License\n\nMIT \u00a9 [Kevin M\u00e5rtensson](http://kevinmartensson.com)\n", "release_dates": []}, {"name": "bitgo-client", "description": null, "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# bitgo-client\n\nclient utils for https://github.com/brave/bitgo-proxy. tests are run in that\nrepo.\n\n# setup\n\nBitGo does not yet support Node 12+, so run `nvm use lts/dubnium` to use\na compatible version. Then run `yarn` to install deps.\n", "release_dates": []}, {"name": "bittorrent-tracker", "description": "\ud83c\udf0a Simple, robust, BitTorrent tracker (client & server) implementation", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# bittorrent-tracker [![travis][travis-image]][travis-url] [![npm][npm-image]][npm-url] [![downloads][downloads-image]][downloads-url] [![javascript style guide][standard-image]][standard-url]\n\n[travis-image]: https://img.shields.io/travis/webtorrent/bittorrent-tracker/master.svg\n[travis-url]: https://travis-ci.org/webtorrent/bittorrent-tracker\n[npm-image]: https://img.shields.io/npm/v/bittorrent-tracker.svg\n[npm-url]: https://npmjs.org/package/bittorrent-tracker\n[downloads-image]: https://img.shields.io/npm/dm/bittorrent-tracker.svg\n[downloads-url]: https://npmjs.org/package/bittorrent-tracker\n[standard-image]: https://img.shields.io/badge/code_style-standard-brightgreen.svg\n[standard-url]: https://standardjs.com\n\n#### Simple, robust, BitTorrent tracker (client & server) implementation\n\n![tracker visualization](img/img.png)\n\nNode.js implementation of a [BitTorrent tracker](https://wiki.theory.org/BitTorrentSpecification#Tracker_HTTP.2FHTTPS_Protocol), client and server.\n\nA **BitTorrent tracker** is a web service which responds to requests from BitTorrent\nclients. The requests include metrics from clients that help the tracker keep overall\nstatistics about the torrent. The response includes a peer list that helps the client\nparticipate in the torrent swarm.\n\nThis module is used by [WebTorrent](http://webtorrent.io).\n\n## features\n\n- Includes client & server implementations\n- Supports all mainstream tracker types:\n  - HTTP trackers\n  - UDP trackers ([BEP 15](http://www.bittorrent.org/beps/bep_0015.html))\n  - WebTorrent trackers ([BEP forthcoming](http://webtorrent.io))\n- Supports ipv4 & ipv6\n- Supports tracker \"scrape\" extension\n- Robust and well-tested\n  - Comprehensive test suite (runs entirely offline, so it's reliable)\n  - Used by popular clients: [WebTorrent](http://webtorrent.io), [peerflix](https://www.npmjs.com/package/peerflix), and [playback](https://mafintosh.github.io/playback/)\n- Tracker statistics available via web interface at `/stats` or JSON data at `/stats.json`\n\nAlso see [bittorrent-dht](https://www.npmjs.com/package/bittorrent-dht).\n\n### Tracker stats\n\n![Screenshot](img/trackerStats.png)\n\n## install\n\n```\nnpm install bittorrent-tracker\n```\n\n## usage\n\n### client\n\nTo connect to a tracker, just do this:\n\n```js\nvar Client = require('bittorrent-tracker')\n\nvar requiredOpts = {\n  infoHash: new Buffer('012345678901234567890'), // hex string or Buffer\n  peerId: new Buffer('01234567890123456789'), // hex string or Buffer\n  announce: [], // list of tracker server urls\n  port: 6881 // torrent client port, (in browser, optional)\n}\n\nvar optionalOpts = {\n  getAnnounceOpts: function () {\n    // Provide a callback that will be called whenever announce() is called\n    // internally (on timer), or by the user\n    return {\n      uploaded: 0,\n      downloaded: 0,\n      left: 0,\n      customParam: 'blah' // custom parameters supported\n    }\n  },\n  // RTCPeerConnection config object (only used in browser)\n  rtcConfig: {},\n  // User-Agent header for http requests\n  userAgent: '',\n  // Custom webrtc impl, useful in node to specify [wrtc](https://npmjs.com/package/wrtc)\n  wrtc: {},\n}\n\nvar client = new Client(requiredOpts)\n\nclient.on('error', function (err) {\n  // fatal client error!\n  console.log(err.message)\n})\n\nclient.on('warning', function (err) {\n  // a tracker was unavailable or sent bad data to the client. you can probably ignore it\n  console.log(err.message)\n})\n\n// start getting peers from the tracker\nclient.start()\n\nclient.on('update', function (data) {\n  console.log('got an announce response from tracker: ' + data.announce)\n  console.log('number of seeders in the swarm: ' + data.complete)\n  console.log('number of leechers in the swarm: ' + data.incomplete)\n})\n\nclient.once('peer', function (addr) {\n  console.log('found a peer: ' + addr) // 85.10.239.191:48623\n})\n\n// announce that download has completed (and you are now a seeder)\nclient.complete()\n\n// force a tracker announce. will trigger more 'update' events and maybe more 'peer' events\nclient.update()\n\n// provide parameters to the tracker\nclient.update({\n  uploaded: 0,\n  downloaded: 0,\n  left: 0,\n  customParam: 'blah' // custom parameters supported\n})\n\n// stop getting peers from the tracker, gracefully leave the swarm\nclient.stop()\n\n// ungracefully leave the swarm (without sending final 'stop' message)\nclient.destroy()\n\n// scrape\nclient.scrape()\n\nclient.on('scrape', function (data) {\n  console.log('got a scrape response from tracker: ' + data.announce)\n  console.log('number of seeders in the swarm: ' + data.complete)\n  console.log('number of leechers in the swarm: ' + data.incomplete)\n  console.log('number of total downloads of this torrent: ' + data.downloaded)\n})\n```\n\n### server\n\nTo start a BitTorrent tracker server to track swarms of peers:\n\n```js\nvar Server = require('bittorrent-tracker').Server\n\nvar server = new Server({\n  udp: true, // enable udp server? [default=true]\n  http: true, // enable http server? [default=true]\n  ws: true, // enable websocket server? [default=true]\n  stats: true, // enable web-based statistics? [default=true]\n  filter: function (infoHash, params, cb) {\n    // Blacklist/whitelist function for allowing/disallowing torrents. If this option is\n    // omitted, all torrents are allowed. It is possible to interface with a database or\n    // external system before deciding to allow/deny, because this function is async.\n\n    // It is possible to block by peer id (whitelisting torrent clients) or by secret\n    // key (private trackers). Full access to the original HTTP/UDP request parameters\n    // are available in `params`.\n\n    // This example only allows one torrent.\n\n    var allowed = (infoHash === 'aaa67059ed6bd08362da625b3ae77f6f4a075aaa')\n    if (allowed) {\n      // If the callback is passed `null`, the torrent will be allowed.\n      cb(null)\n    } else {\n      // If the callback is passed an `Error` object, the torrent will be disallowed\n      // and the error's `message` property will be given as the reason.\n      cb(new Error('disallowed torrent'))\n    }\n  }\n})\n\n// Internal http, udp, and websocket servers exposed as public properties.\nserver.http\nserver.udp\nserver.ws\n\nserver.on('error', function (err) {\n  // fatal server error!\n  console.log(err.message)\n})\n\nserver.on('warning', function (err) {\n  // client sent bad data. probably not a problem, just a buggy client.\n  console.log(err.message)\n})\n\nserver.on('listening', function () {\n  // fired when all requested servers are listening\n  console.log('listening on http port:' + server.http.address().port)\n  console.log('listening on udp port:' + server.udp.address().port)\n})\n\n// start tracker server listening! Use 0 to listen on a random free port.\nserver.listen(port, hostname, onlistening)\n\n// listen for individual tracker messages from peers:\n\nserver.on('start', function (addr) {\n  console.log('got start message from ' + addr)\n})\n\nserver.on('complete', function (addr) {})\nserver.on('update', function (addr) {})\nserver.on('stop', function (addr) {})\n\n// get info hashes for all torrents in the tracker server\nObject.keys(server.torrents)\n\n// get the number of seeders for a particular torrent\nserver.torrents[infoHash].complete\n\n// get the number of leechers for a particular torrent\nserver.torrents[infoHash].incomplete\n\n// get the peers who are in a particular torrent swarm\nserver.torrents[infoHash].peers\n```\n\nThe http server will handle requests for the following paths: `/announce`, `/scrape`. Requests for other paths will not be handled.\n\n## multi scrape\n\nScraping multiple torrent info is possible with a static `Client.scrape` method:\n\n```js\nvar Client = require('bittorrent-tracker')\nClient.scrape({ announce: announceUrl, infoHash: [ infoHash1, infoHash2 ]}, function (err, results) {\n  results[infoHash1].announce\n  results[infoHash1].infoHash\n  results[infoHash1].complete\n  results[infoHash1].incomplete\n  results[infoHash1].downloaded\n\n  // ...\n})\n````\n\n## command line\n\nInstall `bittorrent-tracker` globally:\n\n```sh\n$ npm install -g bittorrent-tracker\n```\n\nEasily start a tracker server:\n\n```sh\n$ bittorrent-tracker\nhttp server listening on 8000\nudp server listening on 8000\nws server listening on 8000\n```\n\nLots of options:\n\n```sh\n$ bittorrent-tracker --help\n  bittorrent-tracker - Start a bittorrent tracker server\n\n  Usage:\n    bittorrent-tracker [OPTIONS]\n\n  If no --http, --udp, or --ws option is supplied, all tracker types will be started.\n\n  Options:\n    -p, --port [number]  change the port [default: 8000]\n        --trust-proxy    trust 'x-forwarded-for' header from reverse proxy\n        --interval       client announce interval (ms) [default: 600000]\n        --http           enable http server\n        --udp            enable udp server\n        --ws             enable websocket server\n    -q, --quiet          only show error output\n    -s, --silent         show no output\n    -v, --version        print the current version\n```\n\n## license\n\nMIT. Copyright (c) [Feross Aboukhadijeh](https://feross.org) and [WebTorrent, LLC](https://webtorrent.io).\n", "release_dates": []}, {"name": "blockies", "description": "<1k library that generates blocky identicons", "language": "JavaScript", "license": null, "readme": "Blockies\n========\n\nA tiny library for generating identicons for Ethereum addresses. These are not meant to replace user profiles, but as security icons, to allow the user to more easily check if an address he wants to interact with is the correct one. The symmetrical aspect of the icons allow our brain see [faces or objects](https://en.wikipedia.org/wiki/Pareidolia), making the icon more recognizable. This also contains the HQX library, for optionally creating not-so-blocky icons (see sample below).\n\n![Sample blockies image](sample.png \"Blockies\")\n\n[**Demo page**](http://download13.github.io/blockies/)\n\nUse\n---\n\n```javascript\nvar icon = blockies.create({ // All options are optional\n    seed: 'randstring', // seed used to generate icon data, default: random\n    color: '#dfe', // to manually specify the icon color, default: random\n    bgcolor: '#aaa', // choose a different background color, default: random\n    size: 15, // width/height of the icon in blocks, default: 8\n    scale: 3, // width/height of each block in pixels, default: 4\n    spotcolor: '#000' // each pixel has a 13% chance of being of a third color,\n    // default: random. Set to -1 to disable it. These \"spots\" create structures\n    // that look like eyes, mouths and noses.\n});\n\ndocument.body.appendChild(icon); // icon is a canvas element\n```\n\nIn the above example the icon will be 15x15 blocks, and each block will be 3x3 pixels. The icon canvas will be 45x45 pixels.\n\n\nNotes\n-----\n\nThe defaults of size 8 and scale 4 generate 32x32 pixel icons. Below are some standard sizes that work well. A size larger than 10 will start generating more noisy icons that don't ressemble much.\n\n * 24x24 `{size: 8, scale: 3}`\n * 50x50 `{size: 5, scale: 10}`\n\n\nBuild\n-----\n\n    node build\nAll this does is minify `blockies.js` to `blockies.min.js`.\n\n\nLicense\n-------\n\n[WTFPL](http://www.wtfpl.net/)\n", "release_dates": []}, {"name": "bloodhound", "description": "bloodhound.js for node and browser", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# bloodhound-js\n[bloodhound.js](https://github.com/twitter/typeahead.js/blob/master/doc/bloodhound.md) for node and browser\n\n> Bloodhound is the typeahead.js suggestion engine. Bloodhound is robust, flexible, and offers advanced functionalities such as prefetching, intelligent caching, fast lookups, and backfilling with remote data.\n\n### Installtion\n``` sh\nnpm install bloodhound-js --save\n```\n### Changes\n+ no jquery deps\n+ works with both browser and node\n+ jquery deferred with [es6-promise](https://www.npmjs.com/package/es6-promise)\n+ storage polyfill with [storage2](https://www.npmjs.com/package/storage2)\n+ ajax with [superagent](https://www.npmjs.com/package/superagent)\n\n### Usage\n``` javascript\nvar Bloodhound = require('bloodhound-js');\nvar engine = new Bloodhound({\n  local: ['dog', 'pig', 'moose'],\n  queryTokenizer: Bloodhound.tokenizers.whitespace,\n  datumTokenizer: Bloodhound.tokenizers.whitespace\n});\n\nvar promise = engine.initialize();\n\npromise.then(function() {\n  console.log('engine init done');\n\n  engine.search('d', function(d) {\n    console.log(d);\n  }, function(d) {\n    console.log(d);\n  });\n});\n```\n\n### License\nMIT\n", "release_dates": []}, {"name": "bloom-filter-cpp", "description": null, "language": "C++", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "[![Build Status](https://travis-ci.org/bbondy/bloom-filter-cpp.svg?branch=master)](https://travis-ci.org/bbondy/bloom-filter-cpp)\n\n# BloomFilter.cpp\nC++ Native node module Bloom filter written in C++ for use in node or any other C++ project.\n\nThe Bloom filter tests whether an element belongs to a set. False positive matches are possible but not common, false negatives are not possible.\nThe Bloom filter library also implements Rabin\u2013Karp algorithm with Rabin fingerprint hashes for multiple substring searches.\n\nThis is a port of a [similar lib](https://github.com/bbondy/bloom-filter-js) I prototyped in JS.\n\n## To include bloom-filter-cpp in your project:\n\n```\nnpm install --save bloom-filter-cpp\n```\n\n\n## JS Usage\n\n```javascript\nvar BloomFilter = require('bloom-filter-cpp').BloomFilter\n\nvar b1 = new BloomFilter()\n\nconsole.log('b1 ading hello')\nb1.add('hello')\n\nconsole.log('b1 exists hello? ', b1.exists('hello'))\nconsole.log('b1 exists hello2? ', b1.exists('hello2'))\n\nvar b2 = new BloomFilter()\nconsole.log('b2 exists hello? ', b2.exists('hello'))\nconsole.log('b2 exists hello2? ', b2.exists('hello2'))\n```\n\n\n## C++ Usage\n\n```c++\n#include \"BloomFilter.h\"\n#include <iostream>\n\nusing namespace std;\n\nint main(int argc, char**argv) {\n  BloomFilter b;\n  b.add(\"Brian\");\n  b.add(\"Ronald\");\n  b.add(\"Bondy\");\n\n  // Prints true\n  cout << (b.exists(\"Brian\") ? \"true\" : \"false\") << endl;\n\n  // Prints false\n  cout << (b.exists(\"Brian Ronald\") ? \"true\" : \"false\") << endl;\n\n  // Create a new BloomerFilter form a previous serialization\n  BloomFilter b2(b.getBuffer(), b.getByteBufferSize());\n\n  // Prints the same as above\n  cout << (b2.exists(\"Brian\") ? \"true\" : \"false\") << endl;\n  cout << (b2.exists(\"Brian Ronald\") ? \"true\" : \"false\") << endl;\n\n  // And you can check if any substring of a passed string exists\n  // Prints true\n  cout << (b.substringExists(\"Hello my name is Brian\", 5) ? \"true\" : \"false\") << endl;\n  // Prints false\n  cout << (b.substringExists(\"Hello my name is Bri\", 3) ? \"true\" : \"false\") << endl;\n\n  return 0;\n}\n```\n\n\n## Developing bloom-filter-cpp\n\n````\ngit clone bloom-filter-cpp\nnpm install\n```\n\n## Build everything in release\n\n```\nmake\n```\n\n## Running sample\n\n```\nmake sample\n```\n\n## Running tests\n\n```\nmake test\n```\n\n## Clearing build files\n```\nmake clean\n```\n", "release_dates": []}, {"name": "brave-ad-service", "description": "Documentation and Specs related to the Brave Ad Service", "language": null, "license": null, "readme": "This repository contains documents and specifications related to the Brave Ad Service\n", "release_dates": []}, {"name": "brave-ads-docs", "description": null, "language": "TypeScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Website\n\nThis website is built using [Docusaurus 3](https://docusaurus.io/), a modern static website generator.\n\n### Installation\n\n```\n$ npm i\n```\n\n### Local Development\n\n```\n$ npm run start\n```\n\nThis command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.\n\n### Build\n\n```\n$ npm run build\n```\n\nThis command generates static content into the `build` directory and can be served using any static contents hosting service.\n\n# Contribution\nAll files added to this repository should be written in markdown. <br />\nAll markdown features supported in Docusaurus can be found: https://docusaurus.io/docs/markdown-features\n\n## Creating Docs\nDocs provides users with a way to organize Markdown files in a hierarchical format\n\nA simple structure would be:\n```markdown\nbrave-ads-docs\n\u251c\u2500\u2500 docs\n\u2502   \u2514\u2500\u2500 my-new-markdown.md\n\u251c\u2500\u2500 ...\n```\n\nWith an example document:\n```markdown\n---\nsidebar_position: 1\n---\n\n# My Page\n\nThis will be the \"title\" of your document\n\n## Headers\n\nThis will show up on the table of contents on the upper right\n\n### Only h2 and h3 will be in the table of contents by default.\n- lists will help you\n- present the key points\n- that you want your users to remember\n  - and you may nest them\n    - multiple times\n```\n\n- `sidebar_position` is used to determine what order the content will show up in.\n\n## Folder Structure\n\nHow the Markdown files are arranged under the docs folder can have multiple impacts on Docusaurus content generation\n\n### Doc URL\nA document's URL location is its file path relative to the docs folder\n\n```markdown\nbrave-ads-docs\n\u2514\u2500\u2500 docs\n    \u2514\u2500\u2500 ad-placements\n        \u2514\u2500\u2500 brave-browser\n            \u2514\u2500\u2500 brave-search\n                \u2514\u2500\u2500 keyword.md\n```\n\n- Results in: http://localhost:3000/ad-placements/brave-browser/brave-search/keyword\n\nEach document folder location should have a file `_category_.json` which contains:\n```json\n{\n  \"label\": \"My Human Readable Name\",\n  \"position\": 1\n}\n```\n- **label**: will be what the directory is displayed as to the end user\n- **position**: where you want that directory in the navigation bar\n\n\n\n", "release_dates": []}, {"name": "brave-browser", "description": "Next generation Brave browser for Android, Linux, macOS, Windows.", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "![Brave Browser](./docs/source/_static/Brave.svg)\n\n## Overview\n\nThis repository holds the build tools needed to build the Brave desktop browser for macOS, Windows, and Linux.  In particular, it fetches and syncs code from the projects defined in `package.json` and `src/brave/DEPS`:\n\n  - [Chromium](https://chromium.googlesource.com/chromium/src.git)\n    - Fetches code via `depot_tools`.\n    - Sets the branch for Chromium (ex: 65.0.3325.181).\n  - [brave-core](https://github.com/brave/brave-core)\n    - Mounted at `src/brave`.\n    - Maintains patches for 3rd party Chromium code.\n  - [adblock-rust](https://github.com/brave/adblock-rust)\n    - Implements Brave's ad-block engine.\n    - Linked through [brave/adblock-rust-ffi](https://github.com/brave/brave-core/tree/master/components/adblock_rust_ffi).\n\n## Downloads\n\nYou can [visit our website](https://brave.com/download) to get the latest stable release.\n\n## Contributing\n\nPlease see the [contributing guidelines](./CONTRIBUTING.md).\n\nOur [Wiki](https://github.com/brave/brave-browser/wiki) also has some useful technical information.\n\n## Community\n\n[Join the Q&A community](https://community.brave.com/) if you'd like to get more involved with Brave. You can [ask for help](https://community.brave.com/c/support-and-troubleshooting),\n[discuss features you'd like to see](https://community.brave.com/c/brave-feature-requests), and a lot more. We'd love to have your help so that we can continue improving Brave.\n\nHelp us translate Brave to your language by submitting translations at https://explore.transifex.com/brave/brave_en/.\n\nFollow [@brave](https://twitter.com/brave) on Twitter for important news and announcements.\n\n## Install prerequisites\n\nFollow the instructions for your platform:\n\n- [macOS](https://github.com/brave/brave-browser/wiki/macOS-Development-Environment)\n- [iOS](https://github.com/brave/brave-browser/wiki/iOS-Development-Environment)\n- [Windows](https://github.com/brave/brave-browser/wiki/Windows-Development-Environment)\n- [Linux/Android](https://github.com/brave/brave-browser/wiki/Linux-Development-Environment)\n\n## Clone and initialize the repo\n\nOnce you have the prerequisites installed, you can get the code and initialize the build environment.\n\n```bash\ngit clone git@github.com:brave/brave-core.git path-to-your-project-folder/src/brave\ncd path-to-your-project-folder/src/brave\nnpm install\n\n# the Chromium source is downloaded, which has a large history (gigabytes of data)\n# this might take really long to finish depending on internet speed\n\nnpm run init\n```\nbrave-core based android builds should use `npm run init -- --target_os=android --target_arch=arm` (or whichever CPU type you want to build for)\nbrave-core based iOS builds should use `npm run init -- --target_os=ios`\n\nYou can also set the target_os and target_arch for init and build using:\n\n```\nnpm config set target_os android\nnpm config set target_arch arm\n```\n\nAdditional parameters needed to build are documented at https://github.com/brave/brave-browser/wiki/Build-configuration\n\nInternal developers can find more information at https://github.com/brave/devops/wiki/%60.env%60-config-for-Brave-Developers\n\n## Build Brave\nThe default build type is component.\n\n```\n# start the component build compile\nnpm run build\n```\n\nTo do a release build:\n\n```\n# start the release compile\nnpm run build Release\n```\n\nbrave-core based android builds should use `npm run build -- --target_os=android --target_arch=arm` or set the npm config variables as specified above for `init`\n\nbrave-core based iOS builds should use the Xcode project found in `ios/brave-ios/App`. You can open this project directly or run `npm run ios_bootstrap -- --open_xcodeproj` to have it opened in Xcode. See the [iOS Developer Environment](https://github.com/brave/brave-browser/wiki/iOS-Development-Environment#Building) for more information on iOS builds.\n\n### Build Configurations\n\nRunning a release build with `npm run build Release` can be very slow and use a lot of RAM, especially on Linux with the Gold LLVM plugin.\n\nTo run a statically linked build (takes longer to build, but starts faster):\n\n```bash\nnpm run build -- Static\n```\n\nTo run a debug build (Component build with is_debug=true):\n\n```bash\nnpm run build -- Debug\n```\nNOTE: the build will take a while to complete. Depending on your processor and memory, it could potentially take a few hours.\n\n## Run Brave\nTo start the build:\n\n`npm start [Release|Component|Static|Debug]`\n\n# Update Brave\n\n`npm run sync -- [--force] [--init] [--create] [brave_core_ref]`\n\n**This will attempt to stash your local changes in brave-core, but it's safer to commit local changes before running this**\n\n`npm run sync` will (depending on the below flags):\n\n1. \ud83d\udce5 Update sub-projects (chromium, brave-core) to latest commit of a git ref (e.g. tag or branch)\n2. \ud83e\udd15 Apply patches\n3. \ud83d\udd04 Update gclient DEPS dependencies\n4. \u23e9 Run hooks (e.g. to perform `npm install` on child projects)\n\n| flag | Description |\n|---|---|\n|`[no flags]`|updates chromium if needed and re-applies patches. If the chromium version did not change, it will only re-apply patches that have changed. Will update child dependencies **only if any project needed updating during this script run**. <br> **Use this if you want the script to manage keeping you up to date instead of pulling or switching branches manually. **|\n|`--force`|updates both _Chromium_ and _brave-core_ to the latest remote commit for the current brave-core branch and the _Chromium_ ref specified in brave-browser/package.json (e.g. `master` or `74.0.0.103`). Will re-apply all patches. Will force update all child dependencies. <br> **Use this if you're having trouble and want to force the branches back to a known state. **|\n|`--init`|force update both _Chromium_ and _brave-core_ to the versions specified in brave-browser/package.json and force updates all dependent repos - same as `npm run init`|\n|`--sync_chromium (true/false)`|Will force or skip the chromium version update when applicable. Useful if you want to avoid a minor update when not ready for the larger build time a chromium update may result in. A warning will be output about the current code state expecting a different chromium version. Your build may fail as a result.|\n|`-D, --delete_unused_deps`|Will delete from the working copy any dependencies that have been removed since the last sync. Mimics `gclient sync -D`.|\n\nRun `npm run sync brave_core_ref` to checkout the specified _brave-core_ ref and update all dependent repos including chromium if needed.\n\n## Scenarios\n\n#### Create a new branch:\n```bash\nbrave-browser> cd src/brave\nbrave-browser/src/brave> git checkout -b branch_name\n```\n\n#### Checkout an existing branch or tag:\n```bash\nbrave-browser/src/brave> git fetch origin\nbrave-browser/src/brave> git checkout [-b] branch_name\nbrave-browser/src/brave> npm run sync\n...Updating 2 patches...\n...Updating child dependencies...\n...Running hooks...\n```\n\n#### Update the current branch to the latest remote:\n```bash\nbrave-browser/src/brave> git pull\nbrave-browser/src/brave> npm run sync\n...Updating 2 patches...\n...Updating child dependencies...\n...Running hooks...\n```\n\n#### Reset to latest brave-browser master and brave-core master (via `init`, will always result in a longer build and will remove any pending changes in your brave-core working directory):\n```bash\nbrave-browser> git checkout master\nbrave-browser> git pull\nbrave-browser> npm run sync -- --init\n```\n\n#### When you know that DEPS didn't change, but .patch files did (quickest attempt to perform a mini-sync before a build):\n```bash\nbrave-browser/src/brave> git checkout featureB\nbrave-browser/src/brave> git pull\nbrave-browser/src/brave> cd ../..\nbrave-browser> npm run apply_patches\n...Applying 2 patches...\n```\n\n# Enabling third-party APIs:\n\n1. **Google Safe Browsing**: Get an API key with SafeBrowsing API enabled from https://console.developers.google.com/. Update the `GOOGLE_API_KEY` environment variable with your key as per https://www.chromium.org/developers/how-tos/api-keys to enable Google SafeBrowsing.\n\n# Development\n\n- [Security rules from Chromium](https://chromium.googlesource.com/chromium/src/+/refs/heads/main/docs/security/rules.md)\n- [IPC review guidelines](https://chromium.googlesource.com/chromium/src/+/HEAD/docs/security/ipc-reviews.md) (in particular [this reference](https://docs.google.com/document/d/1Kw4aTuISF7csHnjOpDJGc7JYIjlvOAKRprCTBVWw_E4/edit#heading=h.84bpc1e9z1bg))\n- [Brave's internal security guidelines](https://github.com/brave/internal/wiki/Pull-request-security-audit-checklist) (for employees only)\n- [Rust usage](https://github.com/brave/brave-core/blob/master/docs/rust.md)\n\n# Troubleshooting\n\nSee [Troubleshooting](https://github.com/brave/brave-browser/wiki/Troubleshooting) for solutions to common problems.\n", "release_dates": ["2024-03-01T18:25:41Z", "2024-03-01T14:18:13Z", "2024-03-01T02:18:58Z", "2024-03-01T07:01:25Z", "2024-02-29T18:18:49Z", "2024-02-29T14:09:49Z", "2024-02-29T02:15:42Z", "2024-02-29T06:13:10Z", "2024-02-28T18:22:17Z", "2024-02-28T14:13:33Z", "2024-02-28T02:30:12Z", "2024-02-28T06:49:26Z", "2024-02-28T03:53:44Z", "2024-02-27T22:31:01Z", "2024-02-27T18:37:35Z", "2024-02-27T14:14:59Z", "2024-02-27T02:15:59Z", "2024-02-27T08:01:08Z", "2024-02-27T03:24:28Z", "2024-02-26T18:13:58Z", "2024-02-26T13:34:08Z", "2024-02-26T04:09:46Z", "2024-02-27T01:13:39Z", "2024-02-26T06:39:01Z", "2024-02-23T18:18:32Z", "2024-02-23T14:06:27Z", "2024-02-23T02:16:05Z", "2024-02-23T06:21:28Z", "2024-02-22T20:06:24Z", "2024-02-22T18:19:47Z"]}, {"name": "brave-browser-snap", "description": null, "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "[![brave](https://snapcraft.io/brave/badge.svg)](https://snapcraft.io/brave)\n\nThis is the snap package for Brave browser. More details at [brave.com/linux](https://brave.com/linux)\n\nFor issues please visit [github.com/brave/brave-browser/issues](https://github.com/brave/brave-browser/issues)\n\nInstall using `sudo snap install brave`\n\n[![Get it from the Snap Store](https://snapcraft.io/static/images/badges/en/snap-store-white.svg)](https://snapcraft.io/brave)\n", "release_dates": []}, {"name": "brave-chromium-themes", "description": "Brave Themes", "language": null, "license": null, "readme": "# brave-chromium-themes\n", "release_dates": []}, {"name": "brave-core", "description": "Core engine for the Brave browser for Android, Linux, macOS, Windows. For issues https://github.com/brave/brave-browser/issues", "language": "HTML", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave Core\n\nBrave Core is a set of changes, APIs, and scripts used for customizing Chromium to make the Brave browser. Please also check https://github.com/brave/brave-browser\n\nFollow [@brave](https://twitter.com/brave) on Twitter for important announcements.\n\n## Resources\n\n- [Issues](https://github.com/brave/brave-browser/issues)\n- [Releases](https://github.com/brave/brave-browser/releases)\n- [Documentation wiki](https://github.com/brave/brave-browser/wiki)\n\n## Community\n\nYou can ask questions and interact with the community in the following\nlocations:\n- [Brave Community](https://community.brave.com/)\n- [`community`](https://bravesoftware.slack.com) channel on Brave Software's Slack\n", "release_dates": []}, {"name": "brave-core-crx-packager", "description": null, "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave Core CRX Packager\n\nThe CRX Packager creates and packages CRX files for the components and extensions included with the Brave browser.\n\n## Development\n\nWhen developing a new component extension, you must generate a new unique extension ID and public/private key pair. You can do that by\n\n1. Generating a new keypair with `openssl genrsa 2048 | openssl pkcs8 -topk8 -nocrypt -out key.pem`\n2. Storing the new PEM in 1Password for Teams\n3. Generating the public key for the `manifest.json` with `openssl rsa -in key.pem -pubout -outform DER | openssl base64 -A`\n4. Generating the component ID with `openssl rsa -in key.pem -pubout -outform DER | shasum -a 256 | head -c32 | tr 0-9a-f a-p`\n5. Updating https://github.com/brave/adblock-resources/blob/master/filter_lists/regional.json with the right component_id and base64_public_key (if this is for AdBlock)\n5. Updating the CRX packager to use the new PEM\n\n## Cloning and Installation\n\nClone the repository and install Node dependencies:\n\n```bash\ngit clone git@github.com:brave/brave-core-crx-packager.git\ncd brave-core-crx-packager\ngit submodule init\ngit submodule update\n# If you use NVM to switch between Node versions\nnvm use\nCXXFLAGS=\"--std=c++17\" npm install\n```\n\nCurrently\n* Node 20.x is required.\n* Python is required.\n* Rust is required. (for ad-block)\n\n## Packaging\n\n### Component Extensions\n\nTo package a component extension, first generate the appropriate DAT file(s) if any. For example, to generate all of the DAT files used by the Ad Block component extension use the following command:\n\n```bash\nnpm run data-files-ad-block-rust\n```\n\nThen package the component extension(s) into one or more CRX files. For example, to package all of the Ad Block component extensions use the following command:\n\n```bash\nnpm run package-ad-block -- --keys-directory <keys-dir> --binary <binary> --endpoint <endpoint>\n```\n\nwhere:\n\n* `keys-dir` is the directory containing the associated private keys used to sign the CRX files\n* `binary` is the full path to the Chrome web browser binary, used for packing the CRX files\n* `endpoint` is the DynamoDB endpoint (use http://localhost:8000 if setup locally)\n\nThe currently supported component extension types are:\n\n* `ad-block`\n* `tor-client`\n* `local-data-files` (formerly `tracking-protection`)\n\n#### Testing locally without signing\n\n```bash\nnpm run <target-name> -- --local-run\n```\n\nFor example, if you added a new list to `local-data-files` and want to make sure it will show up correctly:\n```bash\nnpm run package-local-data-files -- --local-run\n```\nThis will create the lists in `build/local-data-files-updater/default/1`.\n\nNote: not all targets might be supported with `--local-run`.\n\n### NTP Sponsored Images(SI) component\n\nTo pacakge NTP SI components, download assets from passed url at first. It will download assets to `./build/ntp-sponsored-images/resources/`\n\n```bash\nnpm run generate-ntp-sponsored-images -- --data-url <s3 buckets url>\n```\n\nThen, package assets to crx files per region. It will generate component crx files for each region at `./build/ntp-sponsored-images/output`. Passed args to `--keys-directory` should include all PEM files that has private key for supported regions.\n\n```bash\nnpm run package-ntp-sponsored-images -- --binary \"/Applications/Google\\\\ Chrome.app/Contents/MacOS/Google\\\\ Chrome\" --keys-directory keys/\n```\n\n### NTP Super Referrer(SR) component\n\nGenerate private key file as ntp-super-referrer-{super-referrer-code}.pem and add it as secret file to Builder. See above instruction how to generate private key file.\n\nTo pacakge NTP SR components, download assets from passed url at first. It will download assets to `./build/ntp-super-referrer/resources/{super-referrer-code}`\n\n```bash\nnpm run generate-ntp-super-referrer -- --data-url <s3 buckets url> --super-referrer-name <super-referrer-code>\n```\n\nThen, package assets to crx file for specific super referrer. It will generate component crx file at `./build/ntp-super-referrer/output`.\n\n```bash\nnpm run package-ntp-super-referrer -- --binary \"/Applications/Google\\\\ Chrome.app/Contents/MacOS/Google\\\\ Chrome\" --key-file ntp-super-referrer-{super-referrer-code}.pem --super-referrer-name <super-referrer-code>\n```\n\n## Generating differential updates\n\nTo generate differential updates using [puffin](https://chromium.googlesource.com/chromium/src/+/main/third_party/puffin/) use the following command to fetch the last 10 versions and generate the patch files:\n\n```bash\naws-vault exec extensions-dev-role --  npm run generate-puffpatches -- --crx-directory ./build/ntp-sponsored-images/output -p 10\n```\n\n*Note: `puffin` binary is required*\n\n## Uploading\n\nAfter packaging a CRX file, you can upload it to Brave's S3 extensions bucket (`brave-extensions`).\n\n### Component Extensions\n\nTo upload a component extension, use the appropriate upload command. For example, to upload all of the Ad Block component extensions use the following command:\n\n```bash\naws-vault exec extensions-dev-role -- npm run upload-ad-block -- --crx-directory <crx-dir> --endpoint <endpoint>\n```\n\nwhere:\n\n* `crx-dir` is the directory containing the CRX files to upload (as produced by running `package-ad-block`, for example)\n* `endpoint` is the DynamoDB endpoint (use http://localhost:8000 if setup locally)\n\n### NTP SI component\nTo upload NTP SI components, pass crx directory that has all generated crx files and endpoint as arguments.\n```bash\naws-vault exec extensions-dev-role -- npm run upload-ntp-sponsored-images-components -- --crx-directory ./build/ntp-sponsored-images/output\n```\n\n### NTP SR component\nTo upload NTP SR components, pass crx directory that has generated crx file and endpoint as arguments.\n```bash\naws-vault exec extensions-dev-role -- npm run upload-ntp-super-referrer-component -- --crx-directory ./build/ntp-super-referrer/output\n```\n\n### User Model Installer component\nUpload data file to bucket brave-user-model-installer-input(-dev) using AWS console or setting up AWS credential in [`aws-vault`](https://github.com/brave/devops/wiki/Developing-With-AWS-Access-Keys#aws-access-key-management) and use AWS CLI directly:\n\n```\n[profile dev]\nregion = us-west-2\n\n[profile extensions-dev-role]\nsource_profile = dev\nrole_arn = arn:aws:iam::XXXXXXXXXXXX:role/extensions-dev-developer-role\nmfa_serial = arn:aws:iam::XXXXXXXXXXXX:mfa/dev\n```\n```\naws-vault exec extensions-dev-role -- aws s3 cp --recursive iso_3166_1_gb s3://brave-user-model-installer-input-dev/iso_3166_1_gb/ \n```\nor update the AWS CLI config file to use [`credential_process`](https://docs.aws.amazon.com/cli/latest/topic/config-vars.html#sourcing-credentials-from-external-processes) attribute to reference [`aws-vault` profile](https://github.com/99designs/aws-vault/blob/master/USAGE.md#using-credential_process):\n```\n[profile dev]\nregion = us-west-2\ncredential_process = aws-vault exec --no-session --json dev\n\n[profile extensions-dev-role]\nsource_profile = dev\nrole_arn = arn:aws:iam::XXXXXXXXXXXX:role/extensions-dev-developer-role\nmfa_serial = arn:aws:iam::XXXXXXXXXXXX:mfa/dev\n```\n```\naws s3 cp --recursive iso_3166_1_gb s3://brave-user-model-installer-input-dev/iso_3166_1_gb/ --profile extensions-dev-role\n```\n\nTo upload the component, pass crx directory that has generated crx file and endpoint as arguments.\n```bash\naws exec extensions-dev-role -- npm run upload-user-model-installer-updates -- --crx-directory ./build/user-model-installer/output\n```\n\n## Versioning\n\nVersioning occurs automatically. The first time an extension is packaged, it receives the version number `1.0.0`. When uploaded, that version number along with other metadata is stored in DynamoDB. Subsequent packagings increment the last component of the version number by one.\n\n## S3 Credentials\n\nUploading to S3 requires that you create appropriately provisioned AWS credentials. Once provisioned, you can make your credentials accessible to this script via [`aws-vault`](https://github.com/brave/devops/wiki/Developing-With-AWS-Access-Keys#aws-access-key-management).\n\n\n## Troubleshooting\n\nSince the packager uses Chrome to pack the extensions, make sure you're not currently running Chrome when you perform the packaging step. If you don't quit Chrome before running the packaging scripts, you may see errors like the following (which are harmless, but may obscure actual problems):\n\n```\n[2400:12692:1019/161515.198:ERROR:cache_util_win.cc(19)] Unable to move the cache: 5\n[2400:12692:1019/161515.198:ERROR:cache_util.cc(140)] Unable to move cache folder C:\\Users\\emerick\\AppData\\Local\\Google\\Chrome\\User Data\\ShaderCache\\GPUCache to C:\\Users\\emerick\\AppData\\Local\\Google\\Chrome\\User Data\\ShaderCache\\old_GPUCache_000\n[2400:12692:1019/161515.198:ERROR:disk_cache.cc(168)] Unable to create cache\n[2400:12692:1019/161515.198:ERROR:shader_disk_cache.cc(620)] Shader Cache Creation failed: -2\n```\n\nWhen specifying the path for the `--binary` option on Windows, it can be tricky to get the quoting just right without confusing your shell. This syntax works correctly:\n\n```\n--binary \\\"\"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\\\"\"\n```\n", "release_dates": []}, {"name": "brave-donation-extensions", "description": "Implements brave donation tipping for brave-core", "language": "TypeScript", "license": null, "readme": "# brave-donation-extensions\n", "release_dates": []}, {"name": "brave-extension", "description": "Shields panel browser action extension for the Brave browser", "language": "TypeScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "> # \u26a0\ufe0f This project is going to be archived.\n> ## If you're looking to contribute to brave-extension, check out its new home at https://github.com/brave/brave-core. Pull requests against this repository are going to be ignored.\n\n# Brave Only Extension\n\n[![Build Status](https://travis-ci.org/brave/brave-extension.svg?branch=master)](https://travis-ci.org/brave/brave-extension)\n\n> Experiment moving part of the Brave UI into an extension for use in Brave only (Not Chrome, it will use APIs not available in Chrome)\n\n## Installation\n\n```bash\n# clone brave-extension\n$ git clone git@github.com:brave/brave-extension.git\n\n# Install dependencies\n$ cd brave-extension\n$ npm install\n```\n\n## Development\n\n```bash\n# Build files will appear in './dev'\n# Start webpack development server\n$ npm run dev\n```\n\n## Release\n\n### Build\n\n```bash\n# build files to './build'\n$ npm run build\n```\n\n### Packaging\n\n\n```bash\n# compress release into a brave.zip and brave.crx.\n$ npm run build\n$ npm run compress -- [options]\n```\n\n## Test\n\n* `test/app`: React components, Redux actions & reducers tests\n* `test/e2e`: E2E tests (use [chromedriver](https://www.npmjs.com/package/chromedriver), [selenium-webdriver](https://www.npmjs.com/package/selenium-webdriver))\n\n```bash\n# lint\n$ npm run test-unit\n\n# test/e2e\n$ npm run-script build\n$ npm run test-e2e\n```\n\n## LICENSE\n\n[MPL-2](LICENSE)\n", "release_dates": []}, {"name": "brave-ios", "description": "Brave iOS Browser", "language": "Swift", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "Brave for iOS \ud83e\udd81\n===============\n\nDownload on the [App Store](https://apps.apple.com/app/brave-web-browser/id1052879175).\n\nThe iOS codebase has moved to https://github.com/brave/brave-core\n\nThis respository will be archived in the future.\n", "release_dates": ["2024-03-01T20:02:40Z", "2023-12-20T20:14:32Z", "2023-12-20T19:13:03Z", "2023-12-06T21:44:20Z", "2023-11-20T17:37:19Z", "2023-11-20T17:34:20Z", "2023-11-20T17:31:07Z", "2023-11-20T17:02:02Z", "2023-11-14T20:52:49Z", "2023-11-14T20:46:39Z", "2023-11-14T17:12:08Z", "2023-11-14T19:29:47Z", "2023-11-14T19:23:06Z", "2023-11-14T19:03:56Z", "2023-05-10T15:25:26Z", "2023-04-15T06:07:27Z", "2023-04-14T19:59:01Z", "2022-02-14T03:31:51Z", "2022-02-14T03:29:31Z", "2022-02-11T22:26:06Z", "2021-11-19T07:18:35Z", "2021-11-15T22:10:55Z", "2021-11-10T05:58:36Z", "2021-11-10T05:56:21Z", "2021-10-07T06:33:28Z", "2021-10-07T06:30:46Z", "2021-08-26T14:20:49Z", "2021-08-17T07:23:15Z", "2021-08-10T20:26:04Z", "2021-07-28T20:50:26Z"]}, {"name": "brave-manager", "description": null, "language": "Python", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave Manager\n\nA tool for quickly uninstalling all copies of Brave from a Windows system.\n\n## Installation\n\nDownload [this repository's Zip file](https://github.com/brave/brave-manager/archive/refs/heads/main.zip)\nand unpack it.\n\n## Usage\n\nRight-click on `Uninstall Brave.bat` and pick \"Run as Administrator.\nIf you encounter any issues, try first right-clicking `Stop BraveUpdate.bat`.\n", "release_dates": []}, {"name": "brave-release", "description": "Project to build packages that install repos and keyrings", "language": "Shell", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave-release\n\nThis repository contains files that will build the packages that we use to\nenable our distribution on Linux platforms.\n\n### Dependencies\n\n1. To build RPMs you'll need the 'mock' package installed, as well as 'rpm-sign' if you plan on signing packages: `dnf install mock rpm-sign` on fedora, `mock rpmsign` on debian/ubuntu\n\n2. To build debs you'll need the 'debhelper' and 'build-essential' packages installed: `apt install debhelper build-essential` on ubuntu/debian, `dpkg` on fedora.\n\n### Instructions\n\n##### RPM\nBuild the RPM. Note this will take a while the first time as it needs to create each dist's chroot:\n```\n$ cd rpm\n$ make\n```\n\nResulting packages will be placed in `brave-release/rpm/output`\n\n##### deb\n\n```\n$ cd deb\n$ make\n```\n\nResulting packages will be placed in `brave-release/deb/output`\n\n### Things likely to need updates\n\n* Certificates. These change, and when these change we'll need to update this package to include new certificates and to revoke old ones.\n\n* New dists. When a new EL, Fedora, Ubuntu, or Debian come about we'll need to build packages for them.\n\n### Usage and testing\n\n##### RPM\n\n```\n$ sudo rpm --import file.asc\n$ sudo dnf install rpm/output/brave-release-1.0-1.fc29.x86_64.rpm\n$ sudo dnf config-manager --set-enabled brave-release # (or brave-beta or brave-nightly)\n$ sudo dnf install brave-browser\n```\n\n##### deb\n\n```\n$ cat deb/brave.asc | sudo apt-key add - # TODO: put real key here\n$ sudo dpkg -i deb/output/brave-release-xenial.deb\n$ sudo sed -i 's/Enabled: false/Enabled: true/' /etc/apt/sources.list.d/brave-release.sources\n$ sudo apt-get update && sudo apt-get install brave-browser\n```\n\n\n### Improvements\n\n* We should decide how we'll handle certificates. Should local copies live in here, or should we fetch them from somewhere known beforehand?\n", "release_dates": []}, {"name": "brave-rewards-ios", "description": "Brave Rewards UI & Implementation on iOS", "language": "Swift", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# brave-rewards-ios\n\n**Note: The code in this repo has been relocated to [brave-ios](https://github.com/brave/brave-ios)**\n\n---\n\n\nA UI framework for consuming Brave Rewards on [brave-ios](https://github.com/brave/brave-ios). The core logic around BraveRewards resides in brave-core\n\nBuilding the code\n-----------------\n\n1. Install the latest [Xcode developer tools](https://developer.apple.com/xcode/downloads/) from Apple. (Xcode 10 and up required)\n1. Install Carthage:\n    ```shell\n    brew update\n    brew install carthage\n    ```\n1. Install SwiftLint:\n    ```shell\n    brew install swiftlint\n    ```\n1. Clone the repository:\n    ```shell\n    git clone https://github.com/brave/brave-rewards-ios.git\n    ```\n1. Pull in the project dependencies:\n    ```shell\n    cd brave-rewards-ios\n    carthage bootstrap --platform ios --cache-builds --no-use-binaries\n    ```\n1. Open `BraveRewards.xcodeproj` in Xcode.\n1. Build the `BraveRewardsExample` scheme in Xcode\n", "release_dates": []}, {"name": "brave-site-specific-scripts", "description": "a.k.a. Greaselion", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# brave-site-specific-scripts\na.k.a. Greaselion\n\nSite-specific scripts for Brave\n\nThis repository provides content scripts that\u2014depending on your browser settings\u2014may be injected into specific sites while you browse the web with Brave.\n\nYou can view the [`Greaselion.json`](https://github.com/brave/brave-site-specific-scripts/blob/master/Greaselion.json) master configuration file or view the individual scripts elsewhere in this repository.\n\nThe rest of this README is primarily for Brave developers who need to work with this code.\n\n---\n\nTable of contents:\n\n - [Developing new Greaselion scripts](#developing-new-greaselion-scripts)\n - [Script capabilities](#script-capabilities)\n - [Configuration file format](#configuration-file-format)\n   - [`preconditions` key](#preconditions-key)\n   - [`urls` key](#urls-key)\n   - [`scripts` key](#scripts-key)\n - [Before submitting a PR](#before-submitting-a-pr)\n - [Pushing to production](#pushing-to-production)\n - [Troubleshooting](#troubleshooting)\n\n## Developing new Greaselion scripts\n\nGreaselion supports an arbitrary number of rules. All rules are listed in the `Greaselion.json` file, which is parsed once at startup. (In release builds, it is re-parsed if the Local Data Files Updater component is updated while Brave is running, but that should not affect you during development.)\n\nIf you are developing a new Greaselion rule, you can directly edit your local `Greaselion.json` file, which is in a platform-specific location. On a Mac, it should be somewhere like\n\n`~/Library/Application Support/BraveSoftware/Brave-Browser-Development/afalakplffnnnlkncjhbmahjfjhmlkal/VERSION/1/Greaselion.json`\n\nwhere `VERSION` varies.\n\nAdd your new rule in the `Greaselion.json` file, then create your script file inside the `scripts/` subdirectory. Most Greaselion rules will only need one script file, but if you need more than one, you can list multiple files in a single Greaselion rule. They will be injected in the order listed in the `Greaselion.json` file.\n\n## Script capabilities\n\nYou can think of Greaselion scripts as single-file Chromium extensions. In fact, they are treated internally as component extensions, although this is an implementation detail that should not affect you during development. All of the [Chromium APIs](https://developer.chrome.com/extensions/content_scripts#capabilities) are available to Greaselion scripts, including [`chrome.runtime`](https://developer.chrome.com/extensions/runtime).\n\nGreaselion scripts are executed as soon as the page DOM is available, but before images have loaded. This is equivalent to an extension that specifies `\"run_at\": \"document_end\"` in its manifest.\n\n## Configuration file format\n\nThe `Greaselion.json` file controls which scripts are injected on which sites, under which conditions. It is in `JSON` format. The root element is a `JSON` array whose elements are `JSON` objects. Each object is a \"Greaselion rule.\" Greaselion rules are self-contained and independent of each other; no rule affects any other rule. All Greaselion rules are considered on all URL requests. Multiple rules may end up \"matching\" a single URL request, and depending on browser settings, injecting one or more scripts into the web page that the end user is navigating.\n\nEvery Greaselion rule must contain 2 required keys and may contain 1 optional key (listed below). Keys must not be duplicated within a single Greaselion rule. Keys may appear in any order. All keys are case-sensitive.\n\n### `preconditions` key\n\n`preconditions` is an optional key whose value is a `JSON` object. Its role is to specify the environment in which this Greaselion rule applies. These roughly correspond to per-profile browser settings.\n\nThere can be multiple preconditions in this object. **All preconditions must be fulfilled** in order for a Greaselion rule to \"match.\" If any precondition is not fulfilled, the entire rule is ignored and none of its scripts will be injected.\n\nThese `preconditions` keys are supported:\n\n - `rewards-enabled` may be `true` or `false`. Corresponds to whether \"Brave Rewards\" is enabled in this profile.\n\nThis list is exhaustive. No other preconditions are supported.\n\n### `urls` key\n\n`urls` is a required key whose value is a `JSON` array. Its role is to specify the URLs for which this Greaselion rule applies.\n\nEach item in the array is a [URL match pattern](https://developer.chrome.com/extensions/match_patterns), which is a datatype defined by Chromium that allows you to specify URLs with wildcards in certain places. It intelligently handles variations that can occur in URLs and strange edge cases that you probably would never have considered.\n\nEach match pattern must be use either the `http:` or `https:` scheme. There is no support for `file:` URLs.\n\nThere can be multiple URL match patterns in this array. If all preconditions are fulfilled and **if any URL pattern matches**, all scripts in the Greaselion rule will be injected.\n\n### `scripts` key\n\n`scripts` is a required key whose value is a `JSON` array. Its role is to specify the actual script files to be injected into the page.\n\nEach item in this array is a partial pathname and filename. The path is relative to the directory where the `Greaselion.json` configuration file resides.\n\n## Before submitting a PR\nRun this command to ensure that it will all compile properly:\n\n        rm -rf dist\n        npm run build && npm run lint && npm run test\n        \nAll tests must PASS!\n\nWhen you are satisfied that everything is working as expected,  [create a pull request](https://github.com/brave/brave-site-specific-scripts/pull/new/master) in this repository with your new Greaselion script files and an updated `Greaselion.json` file.\n\n## QA\n\nAlways have QA test your changes before pushing them to production. Since Greaselion scripts are managed via the [Local Data Files Updater component](https://github.com/brave/brave-core-crx-packager), you should create a branch in that repo and update the `package-lock.json` file to use the appropriate commit of `brave-site-specific-scripts` containing your Greaselion changes. Upon creating that branch, run the [dev deployment job](https://ci.brave.com/view/All/job/brave-core-ext-local-data-files-update-publish-dev/) to create a test build for QA using that branch.\n\nNote: the deployment job automatically runs against master a few times a day, so QA must only test with the specific version run against your branch; if the deployment job kicks off again before QA finishes, you must run it against your branch again.\n\nQA can test with your dev component by running brave with the `--use-dev-goupdater-url` flag and checking for the correct version number in brave://components. It sometimes takes up to 10 minutes or more for the new component to appear here.\n\nOnce QA signs off on your changes, you may merge your branch into `master`.\n\n## Pushing to production\n\nQA tested your changes first, right? See above.\n\nLike tracking lists or adblocking lists, Greaselion scripts can be updated and pushed to users outside of a full application update. On the client side, this is managed by the [Local Data Files service](https://github.com/brave/brave-core/blob/master/components/brave_component_updater/browser/local_data_files_service.cc). On the server side, it is managed by uploading a new version of the [Local Data Files Updater component](https://github.com/brave/brave-core-crx-packager). In between is this repository.\n\n### Via Jenkins (you usually want to use this method)\n\n1. Update `package-lock.json` in the `brave-core-crx-packager` repo to use your new version.\n1. Run the [production deployment job](https://ci.brave.com/view/All/job/brave-core-ext-local-data-files-update-publish/) to push your change to production.\n\n### Manually (you almost always will want to use Jenkins, see above)\n\n 1. Once your pull request has been approved and merged and QA has tested your changes in a dev environment, run the [`brave-core-crx-packager`](https://github.com/brave/brave-core-crx-packager) `package-local-data-files` script to create a new version of the Local Data Files Updater component. The new version will include all the Greaselion scripts from this repository.\n 2. Run the `brave-core-crx-packager` `upload-local-data-files` script to upload the newly packaged Local Data Files Updater component to the Brave extension server.\n 3. To test that the process worked, open a release build of Brave and navigate to `brave://components/`. Under `Brave Local Data Updater`, click the `Check for update` button. It should find and download the newly uploaded component.\n\nBrave automatically checks for updates to its components, so most Brave users should receive your updated Greaselion script within 24 hours. The client-side Greaselion service is designed to refresh itself without relaunching Brave, so changes will go live even if a user is already running Brave at the time. Open tabs will not be refreshed, but the new Greaselion scripts will be active once the user manually refreshes the tab, or when they open a new tab.\n\n## Troubleshooting\n\nRunning a debug build, if something goes catastrophically wrong, there may be error messages printed in the debug log. Search for `greaselion_` to find them.\n\n - `Malformed pattern in Greaselion configuration`: one of the URL patterns is not valid URL match pattern syntax, or it uses some URL scheme other than `http:` or `https:`.\n - `Malformed filename in Greaselion configuration`: one of the script paths is not valid, perhaps because it points to an absolute pathname or tries to use `../..` notation to point to a file outside the root directory where `Greaselion.json` resides.\n - `Could not load Greaselion script`: the script path itself is valid but the file was not found.\n - `Could not obtain Greaselion configuration`: the `Greaselion.json` file was not found.\n - `Failed to parse Greaselion configuration`: the `Greaselion.json` file was found but could not be parsed as `JSON`. You probably have a stray comma at the end of a list. Chromium's `JSON` parser is strict and will not allow this. The last Greaselion rule must not have a comma after it. The last script in the `scripts` list must not have a comma after it. The last URL pattern in the `urls` list must not have a comma after it. The last precondition in the `preconditions` object must not have a comma after it. Ask me how I know so much about commas.\n - Any other log message from a `greaselion_*` source file indicates a bug in Greaselion itself, for which you should file a bug. Examples include, but are not limited to, `Could not create Greaselion temp directory`, `Could not write Greaselion manifest`, `Could not copy Greaselion script`, `Could not load Greaselion extension`, and similar messages.\n", "release_dates": []}, {"name": "brave-talk", "description": "Unlimited private video calls with your friends and colleagues", "language": "TypeScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave Talk\n\n## Working with the code\n\nThe website is built using [webpack 5](https://webpack.js.org).\n\nTo work with it locally:\n\n    $ npm install\n    $ npm start\n\nSource code is all in [`src`](./src). Contents of [`public`](./public) are deployed to target without further modification.\n\nCurrently the page uses a html template [`index.html`](./src/index.html) styled using global class names in [`css/welcome.css`](./src/css/welcome/css). Logic is contained within [`index.ts`](./src/index.ts).\n\nBy convention, the javsascript this interacts with elements in the html template by id and the css relies solely on class names.\n\nBefore you commit, you most likely want to ensure the continuous integration build will not\nfail. To run the most likely-to-fail checks, use:\n\n    $ npm run check\n\nTo build for production:\n\n    $ npm ci\n    $ npm run build\n\nwhich creates a `./html` directory containing compiled assets.\n\n# Branching Strategy\n\n- `prod` => releases to [talk.brave.com](http://talk.brave.com) (production)\n- `main` => releases to staging\n- `dev` => releases to development\n\n1. production releases should only be made after we have been able to test exactly what we're going to release on stage. So these should always be a PR from `main` to `prod` that's basically \"make production === stage\". These are the only PRs that should go to `prod`.\n2. therefore a merge to `main` should only happen when we think the feature is ready to release.\n3. when starting a piece of work, create a branch off `main` and keep adding commits there until it's ready to release.\n4. to test the code in a real environment, either:\n   a. merge that branch to `dev` - but don't delete the feature branch. Repeatedly merge the feature that feature branch to `dev` as work progresses. Merges to `dev` do not require PRs.\n   OR\n   b. manually initiate the \"Deploy to Development\" github action selecting that branch - this will deploy just those changes to development.\n5. In-development QA of this feature should happen on the development environment.\n6. when it's good to go merge the feature branch to `main` - with a PR and security review if required. Do not merge until all reviews are completed.\n7. then, after checking on the staging environment (including QA regression testing if needed) PR a production release as per step 1.\n8. now and again we will reset `dev` to match `main` just to keep the history tidy.\n\n# `index.html` Updating Strategy\n\nJapanese language support is available for brave-talk. So whenever we are adding new content in `index.html`, we have to make the following changes:\n\n1. add `i18n-element-text` class to the new tag\n2. add appropriate `id` to the new tag which is used as a key for translation\n3. add the appropriate content translation in the `src > locales`. The format is {key: `tag id`, value: `transated version`}\n\n# Prettier\n\nThis codebase uses [prettier](https://prettier.io/) to keep the code formatted nicely and avoid needless changes in diff. It's recommended\nthat you [configure your editor](https://prettier.io/docs/en/editors.html) to reformat as you go. There's also a pre-commit hook configured that should\nreformat on commit, or you can run `npm run format`.\n", "release_dates": []}, {"name": "brave-talk-gcalendar-extension", "description": "A Chrome extension for Calendar integrations for Brave Talk", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Brave Talk for Calendars\n\nThis is the code for the [_Brave Talk for Calendars_](http://chrome.google.com/webstore/detail/nimfmkdcckklbkhjjkmbjfcpaiifgamg) browser extension,\noriginally based on https://github.com/jitsi/jidesha.\n\nLearn more about Brave Talk at https://brave.com/talk/.\n\n# For Developers\n\n### Building the Extension\n\n```bash\nnpm install\nnpm run build\n```\n\nAfter building, the extension files are located in the `/dist` directory.\n\n## Manual Testing\n\n1. Navigate to brave://extensions.\n2. Enable Developer Mode.\n3. Click on _Load unpacked_ and choose the `/dist` directory.\n4. Visit a supported calendar like [Google Calendar](https://calendar.google.com/), [Proton Calendar](https://calendar.proton.me/), or [Skiff Calendar](https://app.skiff.com/calendar/).\n5. When creating a new event, look for the option to add a Brave Talk meeting.\n\n### Manual Testing Checklist\n\n- Validate the calendar recognition.\n- Ensure the Brave Talk button's position and status are correct.\n- Check if the scheduled Brave Talk meeting's URL is present in the event details.\n- Confirm the URL's persistence in event details post-refresh.\n- Evaluate the Brave Talk button's functions:\n  - It should schedule a meeting when none exists.\n  - If a meeting exists, it should provide access to the meeting URL.\n- Monitor the Brave Talk button's status changes:\n  - It should show \"Join the meeting\" upon adding a meeting.\n  - It should revert to \"create a meeting\" once a meeting is removed.\n\n## Automated Testing\n\nTests run against live calendars. Therefore, create a `.env` file at the project's root, populating it with the credentials of the calendar you're testing. Here's a template:\n\n```bash\n# Google Details\nGOOGLE_AUTH_URL=\"https://accounts.google.com\"\nGOOGLE_USERNAME=\"\u2026\"\nGOOGLE_PASSWORD=\"\u2026\"\nGOOGLE_RECOVERY_PHONE_NUMBER=\"\u2026\"\nGOOGLE_STAY_SIGNED_IN=\"false\"\n\n# Proton Details\nPROTON_AUTH_URL=\"https://calendar.proton.me\"\nPROTON_USERNAME=\"\u2026\"\nPROTON_PASSWORD=\"\u2026\"\nPROTON_STAY_SIGNED_IN=\"false\"\n\n# Skiff Details\nSKIFF_AUTH_URL=\"https://app.skiff.com/calendar/\"\nSKIFF_USERNAME=\"\u2026\"\nSKIFF_PASSWORD=\"\u2026\"\nSKIFF_STAY_SIGNED_IN=\"false\"\n```\n\n> Note: You may use the `.env.example` template provided. Rename it to `.env` and modify as needed.\n\nRun the tests using Puppeteer:\n\n```bash\nnpm install\nnpm run build\nnpm run test # For all calendars\n# Or specify a calendar:\nnpm run test skiff\nnpm run test proton\n```\n", "release_dates": ["2023-08-15T12:09:29Z", "2023-08-08T14:13:49Z"]}, {"name": "brave-tipping-extension", "description": null, "language": null, "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# brave-tipping-extension", "release_dates": []}, {"name": "brave-ui", "description": "List of reusable React components to empower your brave UI", "language": "TypeScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# WARNING! This project is deprecated. Consider switching to https://github.com/brave/leo\n\n<p align=\"center\"><img src=\"./ui-logo.svg\" width=\"130px\" height=\"170px\"/></p>\n\n<p align=\"center\">\n<a href=\"https://www.npmjs.com/package/@brave/brave-ui\" alt=\"NPM\"><img src=\"https://img.shields.io/npm/v/@brave/brave-ui.svg\" /></a>\n<a href=\"https://standardjs.com\" alt=\"JavaScript Style Guide\"><img src=\"https://img.shields.io/badge/code_style-standard-brightgreen.svg\" /></a>\n</p>\n\n---\n\n## :wave: Welcome to Brave UI\n\nHere you will find a list of reusable React components used in most of Brave products. Brave UI's [component library](https://brave.github.io/brave-ui) can be found on Storybook.\n\n:exclamation:**Important:** We are still hacking a lot on this project, and therefore don't recommend that anyone use it yet. It's free to try and use at your own risk but bear in mind that components and APIs are very likely to change without notice.\n\n### Installation\n\n```\n$ npm install\n```\n\n### Using Brave UI\n\n```\nnpm run storybook-start\n```\n\n### Tests\n\nWe use Jest for testing. Playground is available under the `stories/` folder.\n\n```\nnpm run test-unit\n```\n\n### License\n\nThis project is licensed under the MPL-2.0.\n", "release_dates": ["2018-05-04T20:03:54Z", "2018-04-26T20:51:33Z", "2018-04-26T20:24:17Z", "2018-04-20T01:59:51Z", "2018-04-05T15:06:20Z", "2018-04-05T15:02:58Z", "2018-02-21T08:10:08Z", "2018-02-21T08:08:34Z", "2017-12-13T23:05:39Z", "2017-12-06T13:36:32Z", "2017-11-30T05:08:37Z", "2017-11-29T00:36:45Z", "2017-11-24T05:20:20Z", "2017-11-24T05:08:01Z"]}, {"name": "brave-variations", "description": "Resources to compile, publish and inspect the variations seed file", "language": "TypeScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave Variations (Griffin)\nGriffin is Brave's version of Google's Finch - A backend for Chromium's variation service. This repository contains resources to compile, publish and inspect the so called *seed* file, which contains definitions for all variations.\n\nSee the [Wiki](https://github.com/brave/brave-browser/wiki/Brave-Variations-(Griffin)) to learn more about what variations are and how to use them for (1) staged rollouts, (2) parameter updates and (3) experiments.\n\n## Overview\nA continuous integration server (CI) serializes and signs the updated seed file before publishing it to a CDN endpoint at https://variations.brave.com/seed. To browse the contents of the seed file a dashboard is hosted at https://griffin.brave.com. The repo is organized as follows:\n- `/crypto` contains a util to create key pairs and sign the seed file.\n- `/seed` contains the JSON seed definition and serialisation code.\n- `/src` contains the web dashboard to browse the seed contents and tracker code the track changes. See https://github.com/brave/brave-variations/blob/main/src/README.md for details.\n\n## Git flow\n1. Work in feature branch and when done create a PR to `main` branch (which will be picked up by CI for staging).\n2. Verify that everything works as intended via the staging endpoint `--variations-server-url=https://variations.bravesoftware.com/seed`.\n3. Cherry-pick the commit to production by creating another PR to `production` branch (which will be picked up by CI again).\n\n## Key Generation and Exchange\nOn initial deployment and subsequent key rotations a new key pair has to be generated. The public key is exchanged by patching the hard-coded public key bytes in [variations_seed_store.cc#L37](https://source.chromium.org/chromium/chromium/src/+/master:components/variations/variations_seed_store.cc;l=37):\n\n1. Generate a key pair with `$ go run ./crypto/crypto_util.go keygen`.\n2. Update the [patched public key](https://github.com/brave/brave-core/blob/master/chromium_src/components/variations/variations_seed_store.cc#L6) in brave-core.\n3. Store the private key in a secure vault and ensure it is accessible by CI.\n\n## Seed Serialization, Signing and Serving\nThe following steps are performed by CI to publish the updated seed file:\n\n1. Run `$ python seed/serialize.py seed/seed.json` to compile the protobuf.\n2. Sign the seed file with `$ go run /crypto/crypto_util.go sign`.\n3. Update the `X-Seed-Signature` response header.\n4. Update the ETAG header with the contents of `serialnumber`.\n\nConstraints:\n\n- All studies are [one time randomized](https://source.chromium.org/chromium/chromium/src/+/main:base/metrics/field_trial.h;l=99).\n- Platform and channel filters must be applied. See `PLATFORMS` and `CHANNELS` constants in `serialize.py`.\n- Brave Ads studies must contain the stubstring \"BraveAds\" in their study name. Only one ads study with page visible side effects is allowed to run. Multiple studies without visible side effects can run simultanesouly.\n\n## Some Notes on using variations in the Browser\n- Studies only take effect after restarting the browser.\n- Pull from staging endpoint with `--variations-server-url=https://variations.bravesoftware.com/seed`.\n- Precedence rules for feature overrides (starting with highest precedence):\n  - Flags via `brave://flags`\n  - CLI overrides with `--disable-features=\"...\" --enable-features=\"...\"`, e.g. enable feature `FooBar` with parameters `param1=2` and `param3=4` via `--enable-features=FooBar:param1/2/param3/4`\n  - Variations overrides as defined in the `seed`\n  - hard-coded `base::feature` defaults\n- Filter rules might include\n  - Countries: The ISO country code is set in the `X-Country` response header and is inferred from the source IP by the CDN but can be faked with e.g. `--variations-override-country=US`\n  - Channels: Use e.g. `--fake-variations-channel=beta` to override the channel of your build.\n- To verify if the browser signed up for any studies eight augment logs with `--vmodule=\"*/variations/*\"=1` or inspect `brave://version/?show-variations-cmd` under the \"Variations\" section.\n- for logging add `--vmodule=\"*/variations/*\"=1` or higher\n\n## Dashboard\nTo build the dashboard:\n1. Install dependencies `$ npm install`\n2. Bundle resources `$ npm run build`\n", "release_dates": []}, {"name": "brave-versions", "description": "Generate an easily queryable metadata set about Brave releases", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "brave-versions\n===\n\nGenerate an easily queryable JSON dataset about Brave public releases\n\nThis script stitches together data about public\n[Brave releases](https://github.com/brave/brave-browser/releases) from Github and the\n`package.json` data from [brave-browser](https://github.com/brave/brave-browser) to produce\na central dataset about Brave versions.\n\n# Getting started\n\n**Dependencies**\n\n- [nvm](https://github.com/nvm-sh/nvm)\n\n**Clone and install dependencies**\n\n```bash\ngit clone https://github.com/marshall/brave-versions\ncd brave-versions\n\nnvm use\nnpm install\n```\n\n**Run brave-versions**\n\n```bash\nnpm run brave-versions\n```\n\nBy default generated json is written to `brave-versions.json`\n\n# Configuration\n\nConfiguration is currently done through command line switches and environment variables / dotenv.\n\n**Command line**\n\n```bash\n$ brave-versions --help\nUsage: brave-versions [options]\n\nOptions:\n  -V, --version            output the version number\n  --brave-browser <dir>    existing brave-browser git repo (default: \"/Users/marshall/.brave-versions/brave-browser\")\n  --cache-dir <dir>        cache in dir (default: \"/Users/marshall/.brave-versions\")\n  --cache-github-releases  enable cached github releases (default: false)\n  --no-git-pull            skip git pull in brave-browser (default: git pull to update)\n  -o, --output <file>      path to output json manifest (default: brave-versions.json)\n  -h, --help               display help for command\n\n```\n\n**Environment Variables**\n\n| Name | Description |\n| -------------------- | ------------|\n| `BRAVE_VERSIONS_DIR` | path where data is cached, by default this is `$HOME/.brave-versions` |\n| `GITHUB_TOKEN` | optional authorization token for Github API (use to raise the Github API rate limit) |\n\n# Data format\n\nThe manifest generated by `brave-versions` is a JSON file with the following general structure:\n```javascript\n{\n  \"<git tag>\": {\n    \"tag\": \"<git tag>\",\n    \"name\": \"<version name>\",\n    \"channel\": \"stable|beta|nightly|dev\",\n    \"commit\": \"<git sha>\",\n    \"published\": \"<release publish date/time>\",\n    \"dependencies\": {\n      \"chrome\": \"<chrome version>\"\n    },\n    \"github\": {\n      \"release_id\": \"<github release id>\",\n      \"assets\": [\n        {\n          \"id\": \"<github asset id>\",\n          \"name\": \"<filename>\",\n          \"download_url\": \"<github download url>\"\n        },\n        //...\n      ]\n    }\n  },\n  //...\n}\n```\n", "release_dates": []}, {"name": "brave-wallet-docs", "description": "Documentation for the Brave Wallet docs site", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Website\n\nView the live Brave Wallet documentation site at https://wallet-docs.brave.com/\n\nThe Brave Wallet documentation website is built using [Docusaurus 2](https://docusaurus.io/), a modern static website generator.\n\n### Installation\n\n```\n$ yarn\n```\n\n### Local Development\n\n```\n$ yarn start\n```\n\nThis command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.\n\n### Build\n\n```\n$ yarn build\n```\n\nThis command generates static content into the `build` directory and can be served using any static contents hosting service.\n\n### Deployment\n\n```\n$ GIT_USER=<Your GitHub username> USE_SSH=true yarn deploy\n```\n\nIf you are using GitHub pages for hosting, this command is a convenient way to build the website and push to the `gh-pages` branch.\n", "release_dates": []}, {"name": "brightray", "description": "A thin shim over Chromium\u2019s Content module", "language": "C++", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Brightray\n\nBrightray is a static library that makes\n[libchromiumcontent](https://github.com/electron/libchromiumcontent) easier to\nuse in applications.\n\n## Using it in your app\n\nSee [brightray_example](https://github.com/electron/brightray_example) for a\nsample application written using Brightray.\n\n## Development\n\n### Prerequisites\n\n* Python 2.7\n* Linux:\n    * Clang 3.0\n* Mac:\n    * Xcode\n* Windows:\n    * Visual Studio 2010 SP1\n\n### One-time setup\n\nYou must previously have built and uploaded libchromiumcontent using its\n`script/upload` script.\n\n    $ script/bootstrap http://base.url.com/used/by/script/upload\n\n### Building\n\n    $ script/build\n\nBuilding Brightray on its own isn\u2019t all that interesting, since it\u2019s just a\nstatic library. Building it into an application (like\n[brightray_example](https://github.com/electron/brightray_example)) is the only\nway to test it.\n\n## License\n\nIn general, everything is covered by the [`LICENSE`](LICENSE) file. Some files\nspecify at the top that they are covered by the\n[`LICENSE-CHROMIUM`](LICENSE-CHROMIUM) file instead.\n", "release_dates": []}, {"name": "browser-benchmarking", "description": "A basic suite for benchmarking across browsers", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": null, "release_dates": []}, {"name": "browser-laptop", "description": "[DEPRECATED] Please see https://github.com/brave/brave-browser for the current version of Brave", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "[![Lint](https://badges.herokuapp.com/travis/brave/browser-laptop?env=TEST_DIR=lint&label=lint)](https://travis-ci.org/brave/browser-laptop)\n[![Unit Tests](https://badges.herokuapp.com/travis/brave/browser-laptop?env=TEST_DIR=unit&label=unit-tests)](https://travis-ci.org/brave/browser-laptop)\n[![codecov.io](https://codecov.io/github/brave/browser-laptop/coverage.svg?branch=master)](https://codecov.io/gh/brave/browser-laptop?branch=master)\n[![JavaScript Style Guide](https://img.shields.io/badge/code_style-standard-brightgreen.svg)](https://standardjs.com)\n[![Open Source Helpers](https://www.codetriage.com/brave/browser-laptop/badges/users.svg)](https://www.codetriage.com/brave/browser-laptop)\n\n# Brave Browser\n\nDesktop browser for macOS, Windows, and Linux.\n\n_**Deprecation notice: this repository is for the older Muon (our fork of Electron) version of Brave.**_<br>\n_**The newer version of the browser (`brave-core`) [can be found here](https://github.com/brave/brave-browser).**_<br>\n_**Development is being wound down on this version as issues are migrated to the new code-base**_\n\nIf you're experiencing issues with Brave or would like to contribute, [please check out the new code-base instead](https://github.com/brave/brave-browser)\n\nFor other versions of our browser, please see:\n* iPhone - [brave/browser-ios](https://github.com/brave/browser-ios)\n* Android - [brave/browser-android-tabs](https://github.com/brave/browser-android-tabs)\n\n## Downloads\n\nTo download the latest release, [see our releases page](https://github.com/brave/browser-laptop/releases).\n\nYou can also [visit our website](https://brave.com/downloads.html) to get the latest stable release (along with a more user-friendly download page).\n\nThe Muon version of Brave has only one active [release channel](https://github.com/brave/browser-laptop/wiki/Release-channels): Release. This will be deprecated as we move to `brave-core`. Both the [Beta channel](https://brave.com/download-beta) and [Developer channel](https://brave.com/download-dev) are already using the [`brave-core`](https://github.com/brave/brave-browser) code-base.\n\n## Community\n\n[Join the Q&A community](https://community.brave.com/) if you'd like to get more involved with Brave. You can [ask for help](https://community.brave.com/c/help-me),\n[discuss features you'd like to see](https://community.brave.com/c/feature-requests), and a lot more. We'd love to have your help so that we can continue improving Brave.\n\n## Useful documentation\n\n* See [CONTRIBUTING.md](CONTRIBUTING.md) for tips and guidelines about contributing.\n* See [docs/style.md](docs/style.md) for information on styling.\n* See [docs/tests.md](docs/tests.md) for information on testing, including how to run a subset of the tests.\n* See [docs/debugging.md](docs/debugging.md) for information on debugging.\n* See [docs/translations.md](docs/translations.md) to learn how you can help us with translations (localization).\n* See [docs/linuxInstall.md](docs/linuxInstall.md) for information on installing the browser on Linux distributions.\n\n## Running from source\n\nIf you're setting up using Windows, please see the [Building on Windows wiki entry](https://github.com/brave/browser-laptop/wiki/(setup)-Windows-build-guide) for a full walkthrough.\n\nFor other platforms (macOS, Linux) You'll need certain packages installed before you can build and run Brave locally.\n\n### Prerequisites\n\n1. the current LTS version of `nodejs`\n\n    Install from your package manager, [nvm](https://github.com/creationix/nvm), or download from https://nodejs.org\n\n2. [npm](https://github.com/npm/npm) version 5 or greater (to make use of the `package-lock.json`)\n\n#### On Debian / Ubuntu /Mint\n\n````\napt-get install build-essential rpm ninja-build\n````\n\n#### On Fedora\n\n````\ndnf install rpm-build\ndnf group install \"Development Tools\" \"C Development Tools and Libraries\"\n````\n\n### Installation\n\nAfter installing the prerequisites:\n\n1. Clone the git repository from GitHub:\n\n        # For beta testers:\n        git clone --depth 1 https://github.com/brave/browser-laptop\n\n        # For devs over HTTPS:\n        git clone https://github.com/brave/browser-laptop\n\n        # For devs over SSH:\n        git clone git@github.com:brave/browser-laptop.git\n\n2. Open the working directory:\n\n        cd browser-laptop\n\n3. Install the Node dependencies:\n\n        npm install\n\nInstead of `npm install` you may also install with [yarn](https://github.com/yarnpkg/yarn) running `yarn install`.\n\n### Troubleshooting\n\nAdditional notes on troubleshooting installation issues are in the [Troubleshooting](https://github.com/brave/browser-laptop/wiki/Troubleshooting) page in the Wiki.\n\n### Preconfigured VMs\n\nSome platforms are available as pre-configured VMs. See the [readme](https://github.com/brave/browser-laptop/blob/master/test/vms/vagrant/README.md) for details.\n\n### Running Brave\n\nTo run a development version of the browser requires a few steps. The easiest way is just to use two\nterminals. One terminal can be used just to watch for changes to the code\n\n    npm run watch\n\nNow actually run Brave in another terminal\n\n    npm start\n\nSome errors related to [brave/electron](https://github.com/brave/electron) update can be fixed by doing a clean install:\n\n    rm -rf node_modules/\n    npm install\n\nIf this does not work, please clear out your ~/.electron first and try again.\n\n### Running webdriver tests\n\nTo run the webdriver tests\n\n    npm run watch-test  or  npm run watch-all\n\nNow run tests in another terminal\n\n    npm test\n\nSee [docs/tests.md](docs/tests.md) for more information.\n\n### Port\n\nBrave uses port 8080 to communicate between its client and server sides by default. If you are using port 8080 for something else (e.g. a web proxy) then you can set the node config to make it use a different one.\n\ne.g.\nnpm config set brave:port 9001\n\nAdditional notes on troubleshooting development issues are in the [Troubleshooting](https://github.com/brave/browser-laptop/wiki/Troubleshooting) page in the Wiki.\n\n## Running inside of a development version of [Muon](https://github.com/brave/muon)\n\nBy default, we provide pre-built binaries when you `npm install` with our own fork of [electron-prebuilt](https://github.com/brave/electron-prebuilt).\n\nIf you want to modify the code to [Muon](https://github.com/brave/muon) (Brave's Electron fork), then you'll need to build it. An example of why you might do that would be exposing a new event to the webview (from Muon).\n\nTo start this process, you'll want to check out our [browser-laptop-bootstrap](https://github.com/brave/browser-laptop-bootstrap) repo. From there, [you can follow the steps in our wiki](https://github.com/brave/browser-laptop-bootstrap/wiki) to get up and running.\n\n## Packaging for bundles, installers, and updates\n\nPlease [see our wiki entry](https://github.com/brave/browser-laptop/wiki/Packaging-for-bundles,-installers,-and-updates) for more information about packaging.\n", "release_dates": ["2019-04-11T05:59:09Z", "2019-04-09T06:41:03Z", "2018-12-20T16:05:11Z", "2018-12-17T23:42:00Z", "2018-12-14T23:45:06Z", "2018-12-14T04:28:04Z", "2018-12-07T19:43:37Z", "2018-12-07T18:15:28Z", "2018-10-15T06:40:52Z", "2018-10-08T08:50:40Z", "2018-10-05T21:39:57Z", "2018-10-05T06:15:50Z", "2018-09-18T18:20:04Z", "2018-09-18T06:18:51Z", "2018-09-14T06:20:15Z", "2018-09-12T07:08:07Z", "2018-09-11T20:44:52Z", "2018-09-10T17:30:54Z", "2018-09-05T06:36:37Z", "2018-09-02T23:17:51Z", "2018-08-31T23:23:49Z", "2018-08-29T16:32:50Z", "2018-08-28T18:25:27Z", "2018-08-23T17:45:51Z", "2018-08-21T19:45:45Z", "2018-08-19T04:56:57Z", "2018-08-14T07:15:42Z", "2018-08-14T06:16:04Z", "2018-08-09T07:31:52Z", "2018-08-07T06:08:01Z"]}, {"name": "browser-laptop-releases", "description": "Published releases for brave/browser-electron used by brave/electron-prebuilt", "language": "HTML", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# browser-laptop-releases\n\nPublished releases for brave/browser-electron used by brave/electron-prebuilt through github pages at http://brave.github.io/browser-laptop-releases\n\n\n## Downloading Brave laptop / desktop releases\n\nThis repo is only for Brave's electron pre-built binaries.  It should not to be confused with Brave releases.\nBrave releases can be found [here](https://github.com/brave/browser-laptop/releases).\n", "release_dates": []}, {"name": "calendar-duration-rs", "description": "Rust library containing a calendar respecting duration.", "language": "Rust", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# calendar-duration\n\n[![Crates.io](https://img.shields.io/crates/v/calendar-duration?style=for-the-badge)](https://crates.io/crates/calendar-duration)\n[![docs.rs](https://img.shields.io/docsrs/calendar-duration?style=for-the-badge)](https://docs.rs/calendar-duration)\n[![GitHub](https://img.shields.io/github/license/brave-experiments/calendar-duration?style=for-the-badge)](https://github.com/brave-experiments/calendar-duration/blob/master/LICENSE)\n\nA Rust library containing a calendar respecting duration that is compatible with the `time` crate.\nSupports parsing and displaying to/from strings. Also supports addition and subtraction with `OffsetDateTime`.\n\n## Usage\n\nAdd the following dependency:\n\n```\ncalendar-duration = \"<latest version>\"\n```\n\nSee [documentation](https://docs.rs/calendar-duration) for details.\n\n## Time string syntax\n\n- `y` for years\n- `mon` for months\n- `w` for weeks\n- `d` for days\n- `h` for hours\n- `m` for minutes\n- `s` for seconds\n\nThe string can be prefixed with `-` for negative durations.\n\n## Examples\n\n- `1y3mon4d`\n- `-3w4m5s`\n", "release_dates": ["2023-09-19T01:49:26Z"]}, {"name": "catapult", "description": "Deprecated Catapult GitHub. Please instead use http://crbug.com \"Speed>Benchmarks\" component for bugs and https://chromium.googlesource.com/catapult for downloading and editing source code..", "language": "HTML", "license": {"key": "bsd-3-clause", "name": "BSD 3-Clause \"New\" or \"Revised\" License", "spdx_id": "BSD-3-Clause", "url": "https://api.github.com/licenses/bsd-3-clause", "node_id": "MDc6TGljZW5zZTU="}, "readme": "\n<!-- Copyright 2015 The Chromium Authors. All rights reserved.\n     Use of this source code is governed by a BSD-style license that can be\n     found in the LICENSE file.\n-->\n[Brave README](./README-BRAVE.md)\n========\n\nCatapult\n========\n\nCatapult is the home for several performance tools that span from gathering,\ndisplaying and analyzing performance data. This includes:\n\n * [Trace-viewer](tracing/README.md)\n * [Telemetry](telemetry/README.md)\n * [Performance Dashboard](dashboard/README.md)\n * [Systrace](systrace/README.md)\n * [Web Page Replay](web_page_replay_go/README.md)\n\nThese tools were created by Chromium developers for performance analysis,\ntesting, and monitoring of Chrome, but they can also be used for analyzing and\nmonitoring websites, and eventually Android apps.\n\nContributing\n============\nPlease see [our contributor's guide](CONTRIBUTING.md)\n\n<!-- **[Current build status](https://build.chromium.org/p/client.catapult/waterfall)** -->\n", "release_dates": []}, {"name": "chromium", "description": "The official GitHub mirror of the Chromium source", "language": null, "license": {"key": "bsd-3-clause", "name": "BSD 3-Clause \"New\" or \"Revised\" License", "spdx_id": "BSD-3-Clause", "url": "https://api.github.com/licenses/bsd-3-clause", "node_id": "MDc6TGljZW5zZTU="}, "readme": "# ![Logo](chrome/app/theme/chromium/product_logo_64.png) Chromium\n\nChromium is an open-source browser project that aims to build a safer, faster,\nand more stable way for all users to experience the web.\n\nThe project's web site is https://www.chromium.org.\n\nTo check out the source code locally, don't use `git clone`! Instead,\nfollow [the instructions on how to get the code](docs/get_the_code.md).\n\nDocumentation in the source is rooted in [docs/README.md](docs/README.md).\n\nLearn how to [Get Around the Chromium Source Code Directory Structure\n](https://www.chromium.org/developers/how-tos/getting-around-the-chrome-source-code).\n\nFor historical reasons, there are some small top level directories. Now the\nguidance is that new top level directories are for product (e.g. Chrome,\nAndroid WebView, Ash). Even if these products have multiple executables, the\ncode should be in subdirectories of the product.\n\nIf you found a bug, please file it at https://crbug.com/new.\n", "release_dates": []}, {"name": "chromium-releases", "description": null, "language": null, "license": null, "readme": "# chromium-releases\n\nThis repository contains shallow clones of the chromium tags used in Brave\n", "release_dates": []}, {"name": "chromium-source-tarball", "description": "Generate source tarball of Chromium automatically", "language": "HTML", "license": null, "readme": "# Chromium source tarball\n\nAutomatically generate source tarballs for Chromium releases channel, and upload\nthem to the\n[releases](https://github.com/brave/chromium-source-tarball/releases) page.\n\nUnlike the offical source tarballs which only contains dependencies for Linux\nthat specified for Linux packagers, source tarballs in this repo includes the\ndependencies of all platforms.\n\n## Dependencies\n\n  * `brew install xz`\n  * `pip install requests`\n  \n## Usage\n\n### 1. Bootstrap\n\n```bash\n$ ./script/bootstrap\n```\n\n### 2. Generate the source tarball\n\n```bash\n$ ./script/sync 38.0.2125.101\n```\n\n### 3. Upload generated source tarball to GitHub Release\n\n```bash\n$ ./script/upload\n```\n\n## Keep updated with Chrome Releases blog\n\nThe source tarballs in this repo are kept updated with the\n[Chrome Releases](http://googlechromereleases.blogspot.com) blog, you can find\nthe script under `script/chrome_releases_monitor/`.\n", "release_dates": ["2016-09-16T17:18:59Z", "2016-07-21T13:14:04Z", "2016-07-21T14:59:00Z", "2016-08-04T23:12:24Z", "2016-06-07T14:30:05Z", "2016-06-04T23:26:40Z", "2016-05-26T18:27:59Z", "2016-05-21T21:24:03Z", "2016-06-28T15:38:40Z", "2016-06-18T02:05:37Z", "2016-05-12T15:46:51Z", "2016-04-29T19:12:44Z", "2016-04-23T22:59:52Z"]}, {"name": "cloudwatch-alarm-exporter", "description": "Metrics exporter for Cloudwatch Alarms that is also able to directly push alerts to prometheus/alertmanger", "language": "Go", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# CloudWatch Alarm Exporter\nThis exporter exposes the state of the CloudWatch alarms. It is also possible to utilize it to directly send alerts to prometheus/alertmanager however it is recommended to use metrics instead. The biggest reason for this is that it's possible to make queries on alarms and also get a bit of historic data.\n\n## Building\nBuilding the project is straight forward by using `go get`\n\n go get github.com/brave/cloudwatch-alarm-exporter\n", "release_dates": []}, {"name": "cmake-js", "description": "CMake.js - a Node.js native addon build tool", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# CMake.js (MIT)\n\n## Announcement - Works without Visual Studio!\n\nJust install [Visual C++ Build Tools TP](https://www.microsoft.com/en-us/download/details.aspx?id=49983) and CMake.js will use that if there\nis no Visual C++ available.\n\n## About\nCMake.js is a Node.js/io.js native addon build tool which works *exactly* like [node-gyp](https://github.com/TooTallNate/node-gyp), but instead of [gyp](http://en.wikipedia.org/wiki/GYP_%28software%29), it is based on [CMake](http://cmake.org) build system. It's compatible with the following runtimes:\n\n- Node.js 0.10+\n- io.js\n- [NW.js](https://github.com/nwjs/nw.js): all CMake.js based native modules are compatible with NW.js out-of-the-box, there is no [nw-gyp like magic](https://github.com/nwjs/nw.js/wiki/Using-Node-modules#3rd-party-modules-with-cc-addons) required\n- [Electron](https://github.com/atom/electron) (formerly known as atom-shell): out-of-the-box build support, [no post build steps required](https://github.com/atom/electron/blob/master/docs/tutorial/using-native-node-modules.md)\n\n### Supported native libraries\n\n- **Boost**: it's supported by a separate module called boost-lib, that manages Boost dependencies, downloads and installs appropriate Boost versions from Github, and compiles its required libraries automatically. See the [readme](https://github.com/unbornchikken/boost-lib) and the [tutorial](https://github.com/unbornchikken/cmake-js/wiki/TUTORIAL-04-Creating-CMake.js-based-native-modules-with-Boost-dependency).\n\n## Why CMake?\nNearly every native addon is using node-gyp today, so what's wrong with it?\n\n1. First of all, Google, the creator of the gyp platform is moving\ntowards its new build system called [gn](https://code.google.com/p/chromium/wiki/gn),\nwhich means gyp's days of support are counted. (Just for the record, despite the announced gn switch,\nthere is [Bazel](https://github.com/google/bazel) in the works, so sooner or later gn will be dropped in favor of it - IMHO.)\n\n2. It uses Python 2 which is a huge PITA in the current century, and because of the above, there is no hope for upgrade,\nsee: [node-gyp Issue #193](https://github.com/TooTallNate/node-gyp/issues/193).\n\n3. While gyp is very good in dependency management and project generation,\nit still lacks features of essential build customization  \n(see: [gyp wiki - Custom_build_steps](https://code.google.com/p/gyp/wiki/GypUserDocumentation#Custom_build_steps)).\n\n4. [Its wiki](http://code.google.com/p/gyp/w/list) might be enough for an inhouse project,\nbut far from what can be called for a good product documentation.\n\n5. If you wanna port a native library to node as an addon,\nthere is a (very-very) good chance that it doesn't use gyp for its build system,\nyou have to make gyp binding by hand, which is really hard or nearly impossible considering the previous bulletpoint.\nAlso you have to be an expert of the given build system **and** gyp to do it right.\n\n6. There is no IDE that supports gyp as a native project format. Gyp can be used to generate IDE projects,\nbut this is not a two way operation, if you tune your settings or setup in the IDE,\nyou have to propagate changes back to gyp files by hand.\n\n7. Gyp itself isn't capable to build node modules,\nthere is fair amount custom JS code in node-gyp module to make it capable to doing so\n(that's why it named as Generate Your Project not Build Your Project).\nSo supporting advanced build features like Ninja generators is impossible without extra development effort added to node-gyp\n(see [node-gyp PR #429](https://github.com/TooTallNate/node-gyp/pull/429)).\nIt looks like [node-gyp support itself eats up development resources](https://github.com/TooTallNate/node-gyp/issues),\nso there won't be new features like this added or merged in the near future.\nSo with node-gyp you are stuck to good old Make which makes build times very long while working on large modules.\n\nSo, let's take a look at CMake compared to the above bullet points.\n\n1. Cmake is quite mature and very widely used, making it quite stable and convenient. It's used by projects like\n[Blender](http://wiki.blender.org/index.php/Dev:Doc/Building_Blender/Linux/Ubuntu/CMake),\n[LLVM](http://llvm.org/docs/CMake.html), [MySQL or Netflix](http://www.cmake.org/success/),\nand it isn't likely to be abandoned in the near future.\n\n2. It's native software, having no dependencies to any runtime.\n\n3. Right now CMake has all of the features that\n[were missing when development of gyp started](https://code.google.com/p/gyp/wiki/GypVsCMake), and on top of that\nit still has those features that gyp didn't have since then.\nIt has an own module ecosystem with [internal modules](http://www.cmake.org/cmake/help/v3.2/manual/cmake-modules.7.html),\nand with 3rd party gems like [Compile Time Reducer (Cotire)](https://github.com/sakra/cotire).\n\n4. CMake has [excellent documentation](http://www.cmake.org/documentation/),\nlots of [tutorials](https://www.google.hu/webhp?sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8#q=cmake%20tutorial),\nand [examples](https://www.google.hu/webhp?sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8#q=cmake+example).\n\n5. If you pick a native cross platform library, there is a very good chance that is uses CMake as of its build system,\nor it has CMake build files somewhere,\nfor example: [Shark](http://image.diku.dk/shark/sphinx_pages/build/html/rest_sources/getting_started/installation.html),\n[Lua](https://github.com/LuaDist/lua), [SDL](http://wiki.libsdl.org/Installation).\nIf not, [there are converters](http://www.cmake.org/Wiki/CMake#Converters_from_other_buildsystems_to_CMake)\nthat helps you to create CMake files from other project formats.\n\n6. CMake is widely supported by major cross platform C++ IDEs\nlike: [QtCreator](http://doc.qt.io/qtcreator/creator-project-cmake.html), [KDevelop](https://www.kdevelop.org/)\nand the upcoming [CLion](https://www.jetbrains.com/clion/#cmake-support) from JetBrains.\nWith CMake.js you are gonna be able to develop Node.js addons by using those,\neven you have the ability to use features like integrated debugging.\n\n7. CMake.js module doesn't build your project, CMake does.\nAll of its commands (configure, build, clean, etc.) are simple CMake invocations without involving JS magic anywhere.\nEven you can print CMake command line with CMake.js module for each command (eg.: cmake-js print-configure, cmake-js print-build, cmake-js print-clean).\nThis means supporting new features of a given native build system (like new version of Ninja or Visual Studio)\nwon't involve developer efforts from CMake.js side, installing new versions of CMake will be enough.\n\n## Installation\n\n```bash\nnpm install -g cmake-js\n```\n\n**Help:**\n\n```bash\ncmake-js --help\n```\n\n```\nUsage: cmake-js [<command>] [options]\n\nCommands:\n  install          Install Node.js/io.js distribution files if needed\n  configure        Configure CMake project\n  print-configure  Print the configuration command\n  build            Build the project (will configure first if required)\n  print-build      Print the build command\n  clean            Clean the project directory\n  print-clean      Print the clean command\n  reconfigure      Clean the project directory then configure the project\n  rebuild          Clean the project directory then build the project\n  compile          Build the project, and if build fails, try a full rebuild\n\nOptions:\n  --version              Show version number                           [boolean]\n  -h, --help             show this screen                              [boolean]\n  -l, --log-level        set log level (silly, verbose, info, http, warn,\n                         error), default is info                        [string]\n  -d, --directory        specify CMake project's directory (where CMakeLists.txt\n                         located)                                       [string]\n  -D, --debug            build debug configuration                     [boolean]\n  -c, --cmake-path       path of CMake executable                       [string]\n  -m, --prefer-make      use Unix Makefiles even if Ninja is available (Posix)\n                                                                       [boolean]\n  -x, --prefer-xcode     use Xcode instead of Unix Makefiles           [boolean]\n  -g, --prefer-gnu       use GNU compiler instead of default CMake compiler, if\n                         available (Posix)                             [boolean]\n  -C, --prefer-clang     use Clang compiler instead of default CMake compiler,\n                         if available (Posix)                          [boolean]\n  -s, --std              C++ standard, eg.: c++98, c++11, c++14, etc., default\n                         is c++11 (Posix)                               [string]\n  -r, --runtime          the runtime to use                             [string]\n  -v, --runtime-version  the runtime version to use                     [string]\n  -a, --arch             the architecture to build in                   [string]\n  -o, --prec11           use C++98 standard (obsolete: use -s=c++98 instead)\n                                                                       [boolean]\n  --CD                   Custom argument passed to CMake in format:\n                         -D<your-arg-here>                              [string]\n  -i, --silent           Prevents CMake.js to print to the stdio        [boolean]\n  -O, --out              Specify the output directory to compile to, default is\n                         projectRoot/build                              [string]\n```\n\n**Requirements:**\n\n- [CMake](http://www.cmake.org/download/)\n- A proper C/C++ compiler toolchain of the given platform\n    - **Windows**:\n        - Visual C++ Build Tools ([Technical Preview works](https://www.microsoft.com/en-us/download/details.aspx?id=48159))\n        or a recent version of Visual C++ will do ([the free Community](https://www.visualstudio.com/en-us/news/vs2013-community-vs.aspx) version works well)             \n    - **Unix/Posix**:\n        - Clang or GCC\n        - Ninja or Make (Ninja will be picked if both present)\n\n## Usage\n\n### General\n\nIn a nutshell. *(For more complete documentation please see [the first tutorial](https://github.com/unbornchikken/cmake-js/wiki/TUTORIAL-01-Creating-a-native-module-by-using-CMake.js-and-NAN).)*\n\n- Install cmake-js for your module `npm install --save cmake-js`\n- Put a CMakeLists.txt file into you module root with this minimal required content:\n\n```cmake\nproject (your-addon-name-here)\ninclude_directories(${CMAKE_JS_INC})\nfile(GLOB SOURCE_FILES \"your-source files-location-here\")\nadd_library(${PROJECT_NAME} SHARED ${SOURCE_FILES})\nset_target_properties(${PROJECT_NAME} PROPERTIES PREFIX \"\" SUFFIX \".node\")\ntarget_link_libraries(${PROJECT_NAME} ${CMAKE_JS_LIB})\n```\n\n- Add the following into your package.json scripts section:\n\n```json\n\"scripts\": {\n    \"install\": \"cmake-js compile\"\n  }\n```\n\n#### Commandline\n\nIn your module folder you can access cmake-js commands if you install cmake-js globally:\n\n```\nnpm install -g cmake-js\n```\n\nPlease refer to the `--help` for the lists of available commands (they are like commands in `node-gyp`).\n\nYou can override the project default runtimes via `--runtime` and `--runtime-version`, such as: `--runtime=electron --runtime-version=0.26.0`. See below for more info on runtimes.\n\n### CMake Specific\n\n`CMAKE_JS_VERSION` variable will reflect the actual CMake.js version. So CMake.js based builds could be detected, eg.:\n\n```cmake\nif (CMAKE_JS_VERSION)\n    add_subdirectory(node_addon)\nelse()\n    add_subdirectory(other_subproject)\nendif()\n```\n\n### NPM Config Integration\n\nYou can set npm configuration options for CMake.js.\n\nFor all users (global):\n\n```\nnpm config set cmake_<key> <value> --global\n```\n\nFor current user:\n\n```\nnpm config set cmake_<key> <value>\n```\n\nCMake.js will set a variable named uppercase `\"<key>\"` to `<value>` (by using `-D<key>=\"<value>\"` option). User's settings will **overwrite** globals.\n\n#### Example:\n\nEnter at command prompt:\n\n```\nnpm config set cmake_bubu=\"kittyfck\"\n```\n\nThen write to your CMakeLists.txt the following:\n\n```cmake\nmessage (STATUS ${BUBU})\n```\n\nThis will print during configure:\n\n```\n--- kittyfck\n```\n\n### Custom CMake options\n\nYou can add custom CMake options by beginning option name with `CD`.\n\n#### Example\n\nIn command prompt:\n```\ncmake-js compile --CDBUBU=\"kittyfck\"\n```\n\nThen in your CMakeLists.txt:\n\n```cmake\nmessage (STATUS ${BUBU})\n```\n\nThis will print during configure:\n\n```\n--- kittyfck\n```\n\n### Runtimes\n\nYou can configure runtimes for compiling target for all depending CMake.js modules in an application. Define a `cmake-js` key in the application's root `package.json` file, eg.:\n\n```json\n{\n  \"name\": \"ta-taram-taram\",\n  \"description\": \"pa-param-pam-pam\",\n  \"version\": \"1.0.0\",\n  \"main\": \"app.js\",\n  \"cmake-js\": {\n    \"runtime\": \"node\",\n    \"runtimeVersion\": \"0.12.0\",\n    \"arch\": \"ia32\"\n  }\n}\n```\n\nAvailable settings:\n\n- **runtime**: application's target runtime, possible values are:\n\t- `node`: Node.js\n\t- `iojs`: io.js\n\t- `nw`: nw.js\n\t- `electron`: Electron\n- **runtimeVersion**: version of the application's target runtime, for example: `0.12.1`\n- **arch**: architecutre of application's target runtime (eg: `x64`, `ia32`, `arm`). *Notice: on non-Windows systems the C++ toolset's architecture's gonna be used despite of this setting. If you don't specify this on Windows, then architecture of the main node/io.js runtime is gonna be used, so you have to choose a matching nw.js runtime.*\n\n#### Runtime options in CMakeLists.txt\n\nThe actual node runtime parameters are detectable in CMakeLists.txt files, the following variables are set:\n\n- **NODE_RUNTIME**: `\"node\"`, `\"iojs\"`, `\"nw\"`, `\"electron\"`\n- **NODE_RUNTIMEVERSION**: for example: `\"0.12.1\"`\n- **NODE_ARCH**: `\"x64\"`, `\"ia32\"`, `\"arm\"`\n\n#### NW.js\n\nTo make compatible your NW.js application with any CMake.js based modules, write the following to your application's package.json file:\n\n```json\n{\n  \"cmake-js\": {\n    \"runtime\": \"nw\",\n    \"runtimeVersion\": \"nw.js-version-here\",\n    \"arch\": \"whatever-setting-is-appropriate-for-your-application's-windows-build\"\n  }\n}\n```\n\nThat's it. There is nothing else to do either on the application's or on the module's side, CMake.js modules are compatible with NW.js out-of-the-box. For more complete documentation please see [the third tutorial](https://github.com/unbornchikken/cmake-js/wiki/TUTORIAL-03-Using-CMake.js-based-native-modules-with-nw.js).\n\n#### Electron\n\nTo make compatible your Electron application with any CMake.js based modules, write the following to your application's package.json file:\n\n```json\n{\n  \"cmake-js\": {\n    \"runtime\": \"electron\",\n    \"runtimeVersion\": \"electron-runtime-version-here\",\n    \"arch\": \"whatever-setting-is-appropriate-for-your-application's-windows-build\"\n  }\n}\n```\n\nThat's it. There is nothing else to do either on the application's or on the module's side, CMake.js modules are compatible with Electron out-of-the-box.\n\n#### Important\n\nIt is important to understand that this setting is to be configured in the **application's root package.json file**. If you're creating a native module targeting nw.js for example, then **do not specify anything** in your module's package.json. It's the actual application's decision to specify its runtime, your module's just compatible anything that was mentioned in the [About chapter](#about). Actually defining `cmake-js` key in your module's package.json file may lead to an error. Why? If you set it up to use nw.js 0.12.1 for example, then when it gets compiled during development time (to run its unit tests for example) it's gonna be compiled against io.js 1.2 runtime. But if you're having io.js 34.0.1 at the commandline then, which is binary incompatible with 1.2, then your unit tests will fail for sure. So it is advised to not use cmake-js target settings in your module's package.json, because that way CMake.js will use that you have, and your tests will pass.\n\n#### Heroku\n[Heroku](https://heroku.com) uses the concept of a [buildpack](https://devcenter.heroku.com/articles/buildpacks) to define\nhow an application should be prepared to run in a [dyno](https://devcenter.heroku.com/articles/dynos).\nThe typical buildpack for note-based applications,\n[heroku/nodejs](https://github.com/heroku/heroku-buildpack-nodejs),\nprovides an environment capable of running [node-gyp](https://github.com/TooTallNate/node-gyp),\nbut not [CMake](http://cmake.org).\n\nThe least \"painful\" way of addressing this is to use heroku's multipack facility:\n\n- Set the applications' buildpack to\n[https://github.com/heroku/heroku-buildpack-multi.git](https://github.com/heroku/heroku-buildpack-multi.git)\n\n- In the root directory of the application,\ncreate a file called `.buildpacks` with these two lines:\n\n        https://github.com/brave/heroku-cmake-buildpack.git\n        https://github.com/heroku/heroku-buildpack-nodejs.git\n\n- Deploy the application to have the changes take effect\n\nThe `heroku-buildpack-multi` will run each buildpack in order allowing the node application to reference CMake in the Heroku\nbuild environment.\n\n## Tutorials\n\n- [TUTORIAL 01 Creating a native module by using CMake.js and NAN](https://github.com/unbornchikken/cmake-js/wiki/TUTORIAL-01-Creating-a-native-module-by-using-CMake.js-and-NAN)\n- [TUTORIAL 02 Creating CMake.js based native addons with Qt Creator](https://github.com/unbornchikken/cmake-js/wiki/TUTORIAL-02-Creating-CMake.js-based-native-addons-with-QT-Creator)\n- [TUTORIAL 03 Using CMake.js based native modules with NW.js](https://github.com/unbornchikken/cmake-js/wiki/TUTORIAL-03-Using-CMake.js-based-native-modules-with-nw.js)\n- [TUTORIAL 04 Creating CMake.js based native modules with Boost dependency](https://github.com/unbornchikken/cmake-js/wiki/TUTORIAL-04-Creating-CMake.js-based-native-modules-with-Boost-dependency)\n\n## Use case in the works - ArrayFire.js\n\nI'm working on the Node.js port of the awesome [ArrayFire](http://arrayfire.com/) CPU/GPU computing library, please follow its status in its repo: [ArrayFire.js](https://github.com/arrayfire/arrayfire_js).\n\n## Changelog\n\nView [changelog.md](changelog.md)\n\n## Credits\n\n- [Ivshti (Ivo Georgiev)](https://github.com/Ivshti) - Electron support\n- [Johan (JohanvdWest)](https://github.com/JohanvdWest) - option for supporting pre C++11 compilers\n- [javedulu](https://github.com/javedulu) option to generate Xcode project (-x, --prefer-xcode)\n- [Gerhard Berger](https://github.com/gerhardberger) - Custom CMake parameter support, silent and out parameters\n", "release_dates": []}, {"name": "coinbase-node", "description": "The official Node.js library for the Coinbase API.", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Coinbase\n\nThe official Node.js library for the [Coinbase API](https://developers.coinbase.com/api/v2).\n\n## Features\n\n* Full Test coverage.\n* Support for both [API Key + Secret](https://developers.coinbase.com/api/v2#api-key) and [OAuth 2](https://developers.coinbase.com/api/v2#oauth2-coinbase-connect) authentication.\n* Convenient methods for making calls to the API.\n* Automatic parsing of API responses into relevant Javascript objects.\n* Adheres to the nodejs error-first callback protocol.\n* Continuous Integration testing against node 0.10, 0.11, and 0.12.\n\n## Installation\n\n`npm install coinbase`\n\n## Version Compatibility\n\nVersion | GitHub repository\n--------|------------------\n`2.0.x` | This repository\n`0.1.x` | [mateodelnorte/coinbase](https://github.com/mateodelnorte/coinbase)\n\nNpm `coinbase` package name used to refer to the unofficial [coinbase](https://github.com/mateodelnorte/coinbase) library maintained by [Matt Walters](https://github.com/mateodelnorte). Matt graciously allowed us to use the name for this package instead. You can still find that package on [Github](https://github.com/mateodelnorte/coinbase). Thanks, Matt.\n\n## Quick Start\n\nThe first thing you'll need to do is [sign up for coinbase](https://coinbase.com).\n\n## API Key\n\nIf you're writing code for your own Coinbase account, [enable an API key](https://coinbase.com/settings/api). Next, create a ``Client`` object for interacting with the API:\n\n\n```javascript\nvar Client = require('coinbase').Client;\nvar client = new Client({'apiKey': mykey, 'apiSecret': mysecret});\n```\n\n## OAuth2\n\nIf you're writing code that will act on behalf of another user, start by\n[creating a new OAuth 2 application](https://coinbase.com/oauth/applications). You will need to do some work to obtain OAuth credentials for your users; while outside the scope of this document, please refer to our [OAuth 2 tutorial](https://developers.coinbase.com/docs/wallet/coinbase-connect/integrating) and [documentation](https://developers.coinbase.com/docs/wallet/coinbase-connect/reference). Once you have these credentials, create a client:\n\n```javascript\nvar Client = require('coinbase').Client;\nvar client = new Client({'accessToken': accessToken, 'refreshToken': refreshToken});\n```\n\n## Making API Calls\n\nWith a `client instance`, you can now make API calls. We've included some examples below, but in general the library has Javascript prototypes for each of the objects described in our [REST API documentation](https://developers.coinbase.com/api/v2).  These classes each have methods for making the relevant API calls; for instance, ``coinbase.model.Transaction.complete`` maps to the [complete bitcoin request](https://developers.coinbase.com/api/v2#complete-request-money) API endpoint. The comments of each method in the code references the endpoint it implements. Each API method returns an ``object`` representing the JSON response from the API.\n\n**Listing available accounts**\n\n```javascript\nvar coinbase = require('coinbase');\nvar client   = new coinbase.Client({'apiKey': mykey, 'apiSecret': mysecret});\n\nclient.getAccounts({}, function(err, accounts) {\n  accounts.forEach(function(acct) {\n    console.log('my bal: ' + acct.balance.amount + ' for ' + acct.name);\n  });\n});\n```\n\n**Get Balance from an Account Id**\n\n```javascript\nvar coinbase = require('coinbase');\nvar client   = new coinbase.Client({'apiKey': mykey, 'apiSecret': mysecret});\n\nclient.getAccount('<ACCOUNT ID>', function(err, account) {\n  console.log('bal: ' + account.balance.amount + ' currency: ' + account.balance.currency);\n});\n```\n\n**Selling bitcoin**\n\n```javascript\nvar args = {\n  \"amount\": \"12\",\n  \"currency\": \"BTC\"\n};\naccount.sell(args, function(err, xfer) {\n  console.log('my xfer id is: ' + xfer.id);\n});\n```\n\n**Sending bitcoin**\n\n```javascript\nvar args = {\n  \"to\": \"user1@example.com\",\n  \"amount\": \"1.234\",\n  \"currency\": \"BTC\",\n  \"description\": \"Sample transaction for you\"\n};\naccount.sendMoney(args, function(err, txn) {\n  console.log('my txn id is: ' + txn.id);\n});\n```\n\n**Requesting bitcoin**\n\n```javascript\nvar args = {\n  \"to\": \"user1@example.com\",\n  \"amount\": \"1.234\",\n  \"currency\": \"BTC\",\n  \"description\": \"Sample transaction for you\"\n};\naccount.requestMoney(args, function(err, txn) {\n  console.log('my txn id is: ' + txn.id);\n});\n```\n\n**Listing current transactions**\n\n```javascript\naccount.getTransactions(null, function(err, txns) {\n  txns.forEach(function(txn) {\n    console.log('my txn status: ' + txn.status);\n  });\n});\n```\n\n**Using pagination**\n\n```javascript\naccount.getTransactions(null, function(err, txns, pagination) {\n  txns.forEach(function(txn) {\n    console.log('my txn: ' + txn.id);\n  });\n  console.log(pagination.next_uri);\n  account.getTransactions(pagination, function(err, txns) {\n    txns.forEach(function(txn) {\n      console.log('my txn: ' + txn.id);\n    });\n  });\n});\n```\n\n**Checking bitcoin prices**\n\n```javascript\nclient.getBuyPrice({'currencyPair': 'BTC-USD'}, function(err, obj) {\n  console.log('total amount: ' + obj.data.amount);\n});\n```\n\n**Verifying merchant callback authenticity**\n```javascript\nif (client.verifyCallback(req.raw_body, req.headers['CB-SIGNATURE'])) {\n  // Process callback\n}\n```\n\n## Error Handling\n\nErrors are thrown for invalid arguments but are otherwise returned as the\nfirst argument to callback functions using [http-errors](https://github.com/jshttp/http-errors) module.\n\nErrors contain `name`, `status`, and `message` fields for error handling. You can find\nmore information about error types [here](https://developers.coinbase.com/api/v2#errors)\n\n## Testing / Contributing\n\nAny and all contributions are welcome! The process is simple:\n\n1. Fork this repo\n2. Make your changes and add tests\n3. Run the test suite\n4. Submit a pull request.\n\nTests are run via [mocha](http://mochajs.org) and [nock](https://github.com/pgte/nock). To run the tests, clone the repository and then:\n\n`npm install`\n\n`npm test`\n\nPlease also scan the packages for known vulnerabilities.\n\n```bash\nnpm install -g nsp\nnsp check --output summary\n```\n\nYou can also run the tests against various node environments using the Dockerfile.example file.\n\n1. `cp Dockerfile.example Dockerfile`\n2. edit Dockerfile and uncomment the node version that interests you\n3. `[sudo] docker build -t coinbase-node .`\n4. `[sudo] docker run -it coinbase-node`\n", "release_dates": []}, {"name": "config-attestation", "description": null, "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Current service configurations\n\n[![config](https://github.com/brave/config-attestation/actions/workflows/config.yml/badge.svg)](https://github.com/brave/config-attestation/actions/workflows/config.yml)\n\nAt Brave we care about privacy. That means we work to minimize tracking\non the internet for our users, and that includes interaction\nwith services run by Brave itself.\n\nWe also don't expect you to take our word for it; we try to make our\nprivacy features something you can verify.\n\nThis repository is a mechanism for that. Many of our features\ndepend on complex configuration data with various service\nproviders. That configuration protects your privacy, so you deserve\na chance to verify it.\n\nWe've granted this repository special, read-only access to some of\nthat configuration data. You can follow the steps below to review\nour work.\n\n## Verification\n\nTo check the current configuration of the service, click on the\n*config* badge above, or on the `Actions` tab for this repository\nand select a recent workflow run. You'll need to be logged in\nto GitHub to access data on this page.\n\nExamine the logs for the `fetch and display config` step. You should\nsee something like\n\n```json\n{\n  \"protocol\": \"tcp/443\",\n  \"domain\": \"pcdn.bravesoftware.com\",\n  \"proxy_protocol\": \"off\",\n  \"traffic_type\": \"direct\",\n  \"modified_on\": \"2020-06-25T23:16:38.918708Z\"\n}\n```\n\nThis displays key values that control our configuration of Cloudflare's\n[Spectrum proxy](https://www.cloudflare.com/en-gb/products/cloudflare-spectrum/)\nfor a particular website.\n\n- **protocol**\n  A value of `tcp/443` indicates the proxy accepts normal https traffic.\n- **domain**\n  This describes the website the proxy is forwarding for.\n  Match this up with the brave service endpoint you're auditing.\n  Cloudflare is accepting traffic for this domain name and routing\n  the traffic to their own internal servers first so they can strip\n  the IP address.\n- **proxy_protocol**\n  This should be `off`, meaning the proxy **does not** forward the IP\n  address of the connecting client.\n  This means Brave can't use it to track you!\n- **traffic_type**\n  A value of `direct` here means https traffic is forwarded directly\n  to Brave's server without decrypting it.\n  Although Cloudflare sees the client IP address, this means\n  they don't learn anything about the content of the request or\n  our server's response to it.\n- **modified_on**\n  The date the configuration was last updated.\n\nBy publishing these values, we offer some assurance that we're not\nable to track clients connecting to these services.\nSince the configuration data comes\n[directly from Cloudflare](https://api.cloudflare.com/#spectrum-applications-get-spectrum-application-configuration),\nit accurately represents the real proxy parameters.\nBecause the query is processed by GitHub,\nwe can't have changed the values before reporting them.\n\n## Threat Model\n\nSince this report is about auditing Brave's service configuration,\nthe primary attacker we consider is Brave itself. The various service\nproviders are generally trusted to implement what they claim to.\nWe consider various attacks below.\n\n*Brave could post a fake report.*\nThe main audit report webpage generated by this code repository\nis published through the Github Pages mechanism. While hosted\nby Github, the content is under Brave's control, and so Brave\ncould publish a report page which wasn't actually generated\nby running this code. The web page is thus not trustworthy in\nitself, but intended as a reader-friendly summary. This attack\nmay be guarded against by review of the Github Action workflow\nlog, linked at the bottom of the page. That content is controlled\nby Github and would not match a different report page published\nthrough another channel.\n\n*Brave could try to subvert report generation.*\nThe configuration data is fetched and the report generated as part\nof a Github Actions script. To insert incorrect information in\nthis process, Brave would require Github's collusion. We consider\nthis unlikely.\n\nNote, however that this is only true while the script is using a\nGithub-provided runner. If Brave configured the action to execute\non a self-hosted runner under their own control, they could likely\nsubvert the process, inserting inauthentic report data while\npretending to execute the code as specified.\n\n*Brave could change the configuration while the report is running.*\nBrave ultimately controls the Cloudflare configuration for each\nservice and the audit report timing. They could use a less secure\nconfig most of the time and only set secure options for a short\ninterval around the time a query is made to publish a new audit\nreport. This is, however, detectable by looking at the `modified_on`\nfield of each domain's report. This data comes from the Cloudflare\nAPI, and so is trusted to be correct. Any recent modification\nis suspicious, and one that is habitually more recent than the\nreport generation interval could indicate this attack.\n\n*Brave could try to get inaccurate data from Cloudflare.*\nThe report is ultimately generated from configuration data retrieved\nfrom Cloudflare's API endpoint and refers to specific domains.\nBrave would require Cloudflare's collusion, similar to the Github\ncase. We consider this unlikely as well.\n\n*Brave could omit compromising channels.*\nWhile this audit publishes certain service configuration settings,\nthe information that config is designed to protect may be available\nin other ways. To the extent that services have public documentation\nand/or offer the same services to other subscribers, anyone evaluating\nthe audit report can independently look for any such overlapping\naccess methods.\n\nOne example is the Cloudflare [Spectrum event log](https://developers.cloudflare.com/logs/reference/log-fields/zone/spectrum_events/)\nwhich can contain both a timestamp and the original client IP addresses.\nIf Brave accessed that log they could subvert some of the anonymity\nprotection the proxy is intended to create. There is an audit log\nwhich would reveal whether the Spectrum event log had been accessed.\nBrave has this log disabled for their account and enabling it\nis [forbidden in their contract](https://brave.com/brave-private-cdn/)\nwith Cloudflare.\nUnfortunately, unlike the Spectrum configuration itself, which\ncan be accessed through a read-only interface, the audit log can\nonly be accessed with a token which grants edit permissions.\nWe considered the risk of granting modification rights to a\nGithub Actions script too high, and so that audit log isn't\nincluded in the report.\n\nHappy checking!\n", "release_dates": []}, {"name": "constellation", "description": null, "language": "Rust", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Constellation\n\nRust library implementing the *Constellation* threshold aggregation\nmechanism. It allows clients to submit ordered, granular data at\nthe highest that is possible whilst maintaining crowd-based\nanonymity. The receiving server can only decode messages whose\ncontents were also submitted by some threshold number of other\nclients, blocking identification of unique behaviour.\n\nConstellation is a _nested_ version of the [STAR](https://arxiv.org/abs/2109.10074)\nprotocol and this library makes use of the [sta-rs](https://github.com/brave/sta-rs)\nRust implementation.\n\n## Disclaimer\n\nWARNING this library has not been audited, use at your own risk! This\ncode is under active development and may change substantially in future\nversions.\n\n## Quickstart\n\nBuild & test:\n```\ncargo build\ncargo test\n```\n", "release_dates": []}, {"name": "constellation-processors", "description": "Server-side collector and aggregator for recovering data protected by the Constellation/nested STAR protocol.", "language": "Rust", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Constellation Processors\n\nServer-side collector, aggregator and data lake sink for recovering data protected by the nested version of the [STAR](https://arxiv.org/abs/2109.10074) protocol.\n\nIncludes:\n\n- Server: for collecting messages protected by Constellation/STAR\n- Aggregator: for decrypting message data deemed recoverable\n- Data lake sink: for storage of decrypted message data\n\n## Data flow\n\n![Data flow](misc/flow.drawio.png)\n\n## Usage\n\nOne or more modes must be selected: server (`-s` flag), aggregator (`-a` flag) and/or data lake sink (`-l` flag).\n\nRun `cargo run -- -h` to see options.\n\n### Development environment setup\n\nCopy `.env.example` to `.env`. Run `docker-compose up -d`.\n\nRun `cargo run` with the desired arguments. If the aggregator is run, database migrations will be automatically applied.\n\n#### Collecting measurements/sending test measurements\n\n1. Run a collector/server to collect measurements: `cargo run -- -s`\n2. Run the test client in the `misc/test-client` directory. This command will send `k * 10` messages (10 unique measurements) with epoch 1: `cargo run -- -e 1 -u 10`\n\n#### Running aggregation/sinking/viewing results\n\n1. Run data lake sink: `cargo run -- -l`\n2. Run the aggregator, with a test current epoch value (usually the current epoch is fetched from the randomness server directly): `cargo run -- -a --test-epoch 1`\n3. Use [awscli-local](https://github.com/localstack/awscli-local) to list and copy the jsonl files from the `p3a-star-recovered` bucket.\n\n#### Outputting measurements to stdout\n\nThe `--output-measurements-to-stdout` switch can be used to output measurements to the console from the data lake sink or aggregator. If this mode is enabled in the aggregator, measurements will not be sent to the \"decrypted\" Kafka stream/data lake sink.\n\n### Environment variables\n\n| Name | Default value | Required? | Description |\n| -- | -- | -- | -- |\n| K_THRESHOLD | `50` | No | The selected _k_ threshold for the Constellation application. |\n| KAFKA_BROKERS | | Yes | List of Kafka brokers to connect to. |\n| DATABASE_URL | | Yes | Postgres database URL. Used to store recovered keys, unrecovered messages and measurement counts. **The database name must not be included in the URL, it must be provided in the `DATABASE_NAMES` variable.** |\n| TEST_DATABASE_URL | | Only if tests are run | Database URL to use for integration tests. **The database name must be included in the URL.** |\n| S3_ENDPOINT | | No | Endpoint for connecting to S3. Optional, but useful for development purposes (i.e. connecting to LocalStack). |\n| S3_OUTPUT_BUCKET | `p3a-star-recovered` | No | Name of S3 bucket for storing recovered measurements. |\n| DATABASE_MAX_CONN | `100` | No | Max connections for Postgres connection pool. |\n| DATABASE_MAX_WRITE_CONN | `8` | No | Max connections to use for updates/inserts. A transaction will be created for each connection. |\n| LAKE_SINK_BATCH_SIZE | `1000` | No | Number of recovered measurements to store per data lake file. |\n| MIN_RECV_RATE_PER_SEC | `100` | No | The minimum consumption rate for encrypted messages. If the consumption rate is below this value, it is assumed that the consumer is near the end of the stream. Consumption will stop if the rate is below this value. |\n| MAX_INIT_RECV_TIMEOUT_MS | `30000` | No | The maximum amount of time to wait for an encrypted message to be received, at the beginning of consumption. |\n| MIN_MSGS_TO_PROCESS | `1000` | No | The minimum amount of consumed messages to process/aggregate. If the amount consumed is below this value, the process will exit. |\n| KAFKA_ENABLE_PLAINTEXT | | No | If set to `true`, TLS will not be used for Kafka connections. |\n| KAFKA_TLS_CA_CERT_PATH | | No | CA certificate path to use for Kafka TLS connections. |\n| KAFKA_TLS_CERT_PATH | | No | Certificate path to use for Kafka TLS connections. |\n| KAFKA_TLS_KEY_PATH | | No | Key path to use for Kafka TLS connections. |\n| KAFKA_PRODUCE_QUEUE_TASK_COUNT | `64` | No | Amount of tasks to use for producing Kafka records. |\n\n#### Data channel settings\n\nEach environment variable below can contain multiple data channels, with one value associated with each channel.\n\nThe format for an individual data channel setting is `<data channel name>=<value for data channel>`. Multiple channel settings can be configured for each environment variable by using a comma as a delimiter.\n\n| Name | Default value | Required? | Description |\n| -- | -- | -- | -- |\n| KAFKA_ENCRYPTED_TOPICS | `typical=p3a-star-enc` | No | Topics for storing protected messages. |\n| KAFKA_OUTPUT_TOPICS | `typical=p3a-star-out` | No | Topics for storing recovered measurements. |\n| DATABASE_NAMES | `typical=postgres` | No | Postgres database names for the aggregator. |\n| EPOCH_LENGTHS | `typical=1w` | No | Time periods of the epochs. |\n| EPOCH_LIFETIMES | `typical=3` | No | The amount of current & recent previous epochs considered to be 'active'. Epochs older than this lifetime will be consider 'expired', and all partial measurements will be reported at the end of aggregation, if any.  |\n| EPOCH_DATE_FIELD_NAMES | `typical=wos` | No | The name of the date fields to inject into the aggregated measurements. The injected field will include the survey date, inferred via the measurement epoch. |\n| RANDOMNESS_INSTANCE_NAMES | `typical=typical` | No | Randomness server instance names, for retrieving relevant server info. |\n| MIN_CHANNEL_REVISIONS | | No | The minimum `Brave-P3A-Version` header value for measurements submitted to the server. |\n\nThe main channel name can be selected by using the `--main-channel-name` switch. Using this switch will have the following effects:\n\n- If the server is utilized, measurements sent to the `/` path will be sent to the Kafka topic associated with this channel.\n- If the aggregator is utilized, the Kafka topics and database name associated with this channel will be used in processing.\n- This setting has no effect on the lake sink.\n\n## Test client\n\nA test client can be found in `misc/test-client`.\n\nIt can be used to generate random encrypted measurements, create encrypted messages from existing measurements in a CSV and sending the messages to the server.\n\nTo generate random measurements and send them to the server, run `cargo run -- -u 10`. This will send 10 random measurements that meet _k_ to the server (1000 messages total, assuming _k_ is set to 100).\n\nTo generate messages from existing measurements in a CSV, ensure the CSV is prepared correctly. Columns will be converted to STAR layers in the order defined in the CSV. Ensure the total number of occurences for the measurement is in last column.\n\nExample:\n```\nquestion_hash,answer_index,channel,platform,country_code,woi,total\n00469a48c5ec8932,0,release,winia32-bc,  ,2022-01-10,1\n00469a48c5ec8932,0,release,winia32-bc,  ,2022-01-10,1\n00469a48c5ec8932,0,release,winx64-bc,  ,2020-12-21,1\n00469a48c5ec8932,0,release,winx64-bc,  ,2022-02-21,2\n```\n\nRun `cargo run -- --gen-data-file data.csv`. A file containing encrypted messages will be created.\n\nRun `cargo run -- --messages-file data.b64l` to send the encrypted messages to the server.\n\nSee `cargo run -- -h` for all options.\n", "release_dates": ["2022-11-28T20:32:58Z"]}, {"name": "country-reverse-geocoding", "description": "Static Country Reverse Geocoding", "language": "JavaScript", "license": null, "readme": "country-reverse-geocoding\n=========================\n\nNodeJS module to reverse geocoding of countries.\n\n## Installation\n\n`npm install country-reverse-geocoding`\n\n## How it works\n\nThe only method of this module is `get_country`:\n\n`get_country(lat, lng)`\n\nWhere `lat` and `lng` are the latitude and longitude of the point to be\nreverse-geocoded.\n`get_country` returns:\n* an `Error` if something went wrong\n* `null` if the point is not in any country\n* an object with two attributes: `code`, the country code, and `name`, the English name of this country\n\n```javascript\nvar crg = require('country-reverse-geocoding').country_reverse_geocoding();\n\nvar country = crg.get_country(47.3, 0.7);\n\nconsole.log(country.name); // France\n```\n\n## Tests\n\nInstall jasmine-node:\n\n`npm install jasmine-node -g`\n\nThen run\n\n`jasmine-node spec/`\n\n## More information\n\nThe GeoJSON specification: http://www.geojson.org/\nThe GeoJSON file used in this module comes from https://github.com/johan/world.geo.json\n\n## License\n\nDistributed under the MIT License.\n", "release_dates": []}, {"name": "CppUnitLite", "description": "Lightweight C++ unit testing framework", "language": "C++", "license": {"key": "zlib", "name": "zlib License", "spdx_id": "Zlib", "url": "https://api.github.com/licenses/zlib", "node_id": "MDc6TGljZW5zZTI3"}, "readme": "# CppUnitLite - lite c++ testing framework\n\nThis is a modified version of CppUnitLite\n\n## Usage\n\nUse CppUnitLite to add unit tests to the c++ side of a node addon.\n\n### Installing\n\nInstall cppunitlite with npm.  It has no package dependencies, but\nrequires node-gyp to be installed and working.\n\n    $ npm i --save-dev cppunitlite\n    npm http GET https://registry.npmjs.org/cppunitlite\n    npm http 304 https://registry.npmjs.org/cppunitlite\n\n    > cppunitlite@0.0.3 install Z:\\code\\node_modules\\cppunitlite\n    > node-gyp rebuild\n\n    ... platform dependent stuff ...\n    cppunitlite@0.0.3 node_modules\\cppunitlite\n\n### Changes to your binding.gyp\n\nAdd a test target to your binding.gyp:\n\n```\n    {\n      \"target_name\": \"test\",\n      \"type\": \"executable\",\n      \"sources\": [\n          # test filenames\n      ],\n      \"include_dirs\": [\n        \".\",\n        \"src\",\n        \"<!(node -e \\\"require('cppunitlite')\\\")\",\n        \"<!(node -e \\\"require('nan')\\\")\"\n      ],\n      \"dependencies\": [\n        \"node_modules/cppunitlite/binding.gyp:CppUnitLite\",\n      ],\n      \"conditions\": [\n        ['OS==\"win\"', {\n          }, {\n            'cflags_cc': [ '-fexceptions' ]\n          }\n        ]\n      ],\n      # sample unit test\n    }\n```\n\n### A test main\n\nCppUnitLite does not provide a main() function, but it's easy to write\na minimal one; for example:\n\n    #include \"CppUnitLite/TestHarness.h\"\n\n    int main()\n    {\n        TestResult tr;\n        TestRegistry::runAllTests(tr);\n\n        return 0;\n    }\n\n### Write Unit Tests\n\nThe include directories are set up so that the CppUnitLite headers\nshould be included with a path.\n\n    #include \"CppUnitLite/TestHarness.h\"\n\n    #include <string>\n\n    static inline SimpleString StringFrom(const std::string& value)\n    {\n    \treturn SimpleString(value.c_str());\n    }\n\n    TEST( Hello, world )\n    {\n      std::string s1(\"Hello\"), s2(\"Hello\"), s3(\"world\");\n\n      CHECK_EQUAL(s1, s2);\n      CHECK_EQUAL(s2, s1);\n\n      CHECK(s1 != s3);\n    }\n\n## Version history\n\nOriginal version from Michael Feathers\nhttp://www.objectmentor.com/resources/downloads.html\nhttp://www.objectmentor.com/resources/bin/CppUnitLite.zip\n\nSome documentation here:\nhttp://c2.com/cgi/wiki?CppUnitLite\n\nModified version by Keith Bauer, published as an SVN repository\nhttp://www.onesadcookie.com/svn/CppUnitLite\n\nImported to git 2014-01-19 and pushed to github\n", "release_dates": []}, {"name": "crashpad", "description": "Electron fork of crashpad", "language": "C++", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": null, "release_dates": []}, {"name": "crypto", "description": "shared crypto utils for Brave Browser", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave crypto utils\n\n[![Build Status](https://travis-ci.org/brave/crypto.svg?branch=master)](https://travis-ci.org/brave/crypto)\n\nShared crypto utils for Brave browser.\n\n## Install\n\n`npm install brave-crypto`\n\n## Docs\n\nSee [docs/api.md](docs/api.md).\n\nUsage note: In Node.js v4 and later `Buffer` objects are backed by `Uint8Array`s,\nso you can freely substitute `Buffer`s where the input specified in the docs is\n`Uint8Array`. However note that the returned object will still be a `Uint8Array` unless otherwise specified in the docs.\n", "release_dates": ["2021-05-07T17:48:52Z", "2021-01-07T23:27:07Z", "2020-09-01T22:32:13Z", "2020-07-16T17:16:39Z"]}, {"name": "debug-symbol-fetcher", "description": "This repository fetches debug symbols for brave browser builds", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# debug-symbol-fetcher\nnpm module to install a fetcher for brave debug symbols\n\n# usage\n```javascript\nvar minidump = require(\"minidump\")\nminidump.addSymbolPath.apply(minidump, require(\"debug-symbol-fetcher\").pathsForVersion('x.x.x'))\n\n// now when using minidump.walkStack, it would give a more understandable report due to having debug symbols\n```\n\nYou can use MUON_VERSIONS and CORE_VERSIONS environment variables to make the module install custom versions, for example when deploying to Heroku.\n```\nheroku config:set MUON_VERSIONS=\"0.29.2 0.27.1\" CORE_VERSIONS=\"0.50.8\"\n```\n", "release_dates": []}, {"name": "devops-github-workflows", "description": null, "language": null, "license": null, "readme": "# devops-github-workflows", "release_dates": []}, {"name": "dnode", "description": "turtles all the way down rpc", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": null, "release_dates": []}, {"name": "docker-jitsi-meet", "description": "Jitsi Meet on Docker", "language": "Lua", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Jitsi Meet on Docker\n\n![](resources/jitsi-docker.png)\n\n[Jitsi](https://jitsi.org/) is a set of Open Source projects that allows you to easily build and deploy secure videoconferencing solutions.\n\n[Jitsi Meet](https://jitsi.org/jitsi-meet/) is a fully encrypted, 100% Open Source video conferencing solution that you can use all day, every day, for free \u2014 with no account needed.\n\nThis repository contains the necessary tools to run a Jitsi Meet stack on [Docker](https://www.docker.com) using [Docker Compose](https://docs.docker.com/compose/).\n\n## Installation\n\nThe installation manual is available [here](https://jitsi.github.io/handbook/docs/devops-guide/devops-guide-docker).\n\n## TODO\n\n* Support container replicas (where applicable).\n* TURN server.\n\n", "release_dates": []}, {"name": "docusign_rest", "description": "A wrapper gem for the DocuSign REST API", "language": "Ruby", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# DocusignRest\n\nThis 'wrapper gem' hooks a Ruby app (currently only tested with Rails) up to the [DocuSign](http://www.docusign.com/) [REST API](http://www.docusign.com/developer-center) to allow for embedded signing.\n\n## !!USAGE NOTE!!\n\nI haven't taken the time to do a proper RubyGems release in a while. However, several PRs have been merged to master that fix issues and/or add functionality. So please bundle to the master branch here on github for the best experience. Hopefully I can pick up more active maintenance of this in the months to come. Alternatively, if you'd like to be a maintainer please let me know! Thanks.\n\n## Installation\n\nAdd this line to your application's Gemfile:\n\n    gem 'docusign_rest'\n\nAnd then execute:\n\n    $ bundle\n\nOr install it yourself as:\n\n    $ gem install docusign_rest\n\n## Configuration\n\nThere is a bundled rake task that will prompt you for your DocuSign credentials including:\n\n  * Username\n  * Password\n  * Integrator Key\n\nand create the `config/initializers/docusign_rest.rb` file in your Rails app for you. If the file was unable to be created, the rake task will output the config block for you to manually add to an initializer.\n\n**Note** please run the below task and ensure your initializer is in place before attempting to use any of the methods in this gem. Without the initializer this gem will not be able to properly authenticate you to the DocuSign REST API.\n\n    $ bundle exec rake docusign_rest:generate_config\n\noutputs:\n\n    Please do the following:\n    ------------------------\n    1) Login or register for an account at demo.docusign.net\n        ...or their production url if applicable\n    2) Click 'Preferences' in the upper right corner of the page\n    3) Click 'API' in far lower left corner of the menu\n    4) Request a new 'Integrator Key' via the web interface\n        * You will use this key in one of the next steps to retrieve your 'accountId'\n\n    Please enter your DocuSign username: someone@gmail.com\n    Please enter your DocuSign password: p@ssw0rd1\n    Please enter your DocuSign integrator_key: KEYS-19ddd1cc-cb56-4ca6-87ec-38db47d14b32\n\n    The following block of code was added to config/initializers/docusign_rest.rb\n\n    require 'docusign_rest'\n\n    DocusignRest.configure do |config|\n      config.username       = 'someone@gmail.com'\n      config.password       = 'p@ssw0rd1'\n      config.integrator_key = 'KEYS-19ddd1cc-cb56-4ca6-87ec-38db47d14b32'\n      config.account_id     = '123456'\n      #config.endpoint       = 'https://www.docusign.net/restapi'\n      #config.api_version    = 'v2'\n    end\n\n\n### Config Options\n\nThere are several other configuration options available but the two most likely to be needed are:\n\n```ruby\nconfig.endpoint       = 'https://docusign.net/restapi'\nconfig.api_version    = 'v1'\n```\n\nThe above options allow you to change the endpoint (to be able to hit the production DocuSign API, for instance) and to modify the API version you wish to use. If there is a big change in the API it's likely that this gem will need to be updated to leverage changes on the DocuSign side. However, it doesn't hurt to provide the option in case there are several minor updates that do not break functionality but would otherwise require a new gem release. These config options have existed since the gem was created, but in v0.0.3 and above, the options are auto-generated in the config file as comments to make them easier to discover.\n\n\n## Usage\n\nThe docusign\\_rest gem makes creating multipart POST (aka file upload) requests to the DocuSign REST API dead simple. It's built on top of Net:HTTP and utilizes the [multipart-post](https://github.com/nicksieger/multipart-post) gem to assist with formatting the multipart requests. The DocuSign REST API requires that all files be embedded as JSON directly in the request body (not the body\\_stream like multipart-post does by default) so the docusign\\_rest gem takes care of [setting that up for you](https://github.com/j2fly/docusign_rest/blob/master/lib/docusign_rest/client.rb#L397). \n\nThis gem also monkey patches one small part of multipart-post to inject some header values and formatting that DocuSign requires. If you would like to see the monkey patched code please take a look at [lib/multipart-post/parts.rb](https://github.com/j2fly/docusign_rest/blob/master/lib/multipart_post/parts.rb). It's only re-opening one method, but feel free to make sure you understand that code if it concerns you. \n\n### Examples\n\n* These examples assume you have already run the `docusign_rest:generate_config` rake task and have the configure block properly setup in an initializer with your username, password, integrator\\_key, and account\\_id. \n* Unless noted otherwise, these requests return the JSON parsed body of the response so you can index the returned hash directly. For example: `template_response[\"templateId\"]`.\n\n**Getting account_id:**\n\n```ruby\nclient = DocusignRest::Client.new\nputs client.get_account_id\n```\n\n\n**Creating an envelope from a document:**\n\nNote: In the example below there are two sign here tabs for the user with a role of 'Attorney'. There are also two documents attached to the envelope, however, this exact configuration would only allow for signature on the first document. If you need signature for a second document, you'll need to add further options, namely: `document_id: 2` in one of the sign_here_tabs so that DocuSign knows where to embed that signature tab.\n\n```ruby\nclient = DocusignRest::Client.new\ndocument_envelope_response = client.create_envelope_from_document(\n  email: {\n    subject: \"test email subject\",\n    body: \"this is the email body and it's large!\"\n  },\n  # If embedded is set to true  in the signers array below, emails\n  # don't go out to the signers and you can embed the signature page in an \n  # iFrame by using the client.get_recipient_view method\n  signers: [\n    {\n      embedded: true,\n      name: 'Test Guy',\n      email: 'someone@gmail.com',\n      role_name: 'Issuer',\n      sign_here_tabs: [\n        {\n          anchor_string: 'sign_here_1',\n          anchor_x_offset: '140',\n          anchor_y_offset: '8'\n        }\n      ]\n    },\n    {\n      embedded: true,\n      name: 'Test Girl',\n      email: 'someone+else@gmail.com',\n      role_name: 'Attorney',\n      sign_here_tabs: [\n        {\n          anchor_string: 'sign_here_2',\n          anchor_x_offset: '140',\n          anchor_y_offset: '8'\n        },\n        {\n          anchor_string: 'sign_here_3',\n          anchor_x_offset: '140',\n          anchor_y_offset: '8'\n        }\n      ]\n    }\n  ],\n  files: [\n    {path: '/Absolute/path/to/test.pdf', name: 'test.pdf'},\n    {path: '/Absolute/path/to/test2.pdf', name: 'test2.pdf'}\n  ],\n  status: 'sent'\n)\n```\n\n\n**Creating a template:**\n\n```ruby\nclient = DocusignRest::Client.new\n@template_response = client.create_template(\n  description: 'Template Description',\n  name: \"Template Name\",\n  signers: [\n    {\n      embedded: true,\n      name: 'jon',\n      email: 'someone@gmail.com',\n      role_name: 'Issuer',\n      sign_here_tabs: [\n        {\n          anchor_string: 'issuer_sig',\n          anchor_x_offset: '140',\n          anchor_y_offset: '8'\n        }\n      ]\n    },\n    {\n      embedded: true,\n      name: 'tim',\n      email: 'someone+else@gmail.com',\n      role_name: 'Attorney',\n      sign_here_tabs: [\n        {\n          anchor_string: 'attorney_sig',\n          anchor_x_offset: '140',\n          anchor_y_offset: '8'\n        }\n      ]\n    }\n  ],\n  files: [\n    {path: '/Absolute/path/to/test.pdf', name: 'test.pdf'}\n  ]\n)\n```\n\n\n**Creating an envelope from a template:**\n\n```ruby\nclient = DocusignRest::Client.new\n@envelope_response = client.create_envelope_from_template(\n  status: 'sent',\n  email: {\n    subject: \"The test email subject envelope\",\n    body: \"Envelope body content here\"\n  },\n  template_id: @template_response[\"templateId\"],\n  signers: [\n    {\n      embedded: true,\n      name: 'jon',\n      email: 'someone@gmail.com',\n      role_name: 'Issuer'\n    },\n    {\n      embedded: true,\n      name: 'tim',\n      email: 'someone+else@gmail.com',\n      role_name: 'Attorney'\n    }\n  ]\n)\n```\n\n**Creating an envelope from a template using custom tabs:**\n\nNote: This feature is not supported in 'v1' of the REST API\n\n```ruby\nclient = DocusignRest::Client.new\n@envelope_response = client.create_envelope_from_template(\n  status: 'sent',\n  email: {\n    subject: \"The test email subject envelope\",\n    body: \"Envelope body content here\"\n  },\n  template_id: @template_response[\"templateId\"],\n  signers: [\n    {\n      embedded: true,\n      name: 'jon',\n      email: 'someone@gmail.com',\n      role_name: 'Issuer',\n      text_tabs: [\n        { \n          label: 'Seller Full Name', \n          name: 'Seller Full Name', \n          value: 'Jon Doe'\n        }\n      ]\n    },\n    {\n      embedded: true,\n      name: 'tim',\n      email: 'someone+else@gmail.com',\n      role_name: 'Attorney',\n      text_tabs: [\n        { \n          label: 'Attorney Full Name', \n          name: 'Attorney Full Name', \n          value: 'Tim Smith'\n        }\n      ]\n    }\n  ]\n)\n```\n\n\n**Retrieving the url for embedded signing. (Returns a string, not a hash)**\n\n```ruby\nclient = DocusignRest::Client.new\n@url = client.get_recipient_view(\n  envelope_id: @envelope_response[\"envelopeId\"],\n  name: current_user.full_name,\n  email: current_user.email,\n  return_url: 'http://google.com'\n)\n```\n\n\n**Check status of an envelope including the signers hash w/ the status of each signer**\n\n```ruby\nclient = DocusignRest::Client.new\nresponse = client.get_envelope_recipients(\n  envelope_id: @envelope_response[\"envelopeId\"],\n  include_tabs: true,\n  include_extended: true\n)\n```\n\n**Retrieve a document from an envelope and store it at a local file path**\n\n```ruby\nclient = DocusignRest::Client.new\nclient.get_document_from_envelope(\n  envelope_id: @envelope_response[\"envelopeId\"],\n  document_id: 1,\n  local_save_path: \"#{Rails.root.join('docusign_docs/file_name.pdf')}\"\n)\n```\n\n## Breaking out of the iFrame after signing\n\nIn order to return to your application after the signing process is complete it's important to have a way to evaluate whether or not the signing was successful and then do something about each case. The way I set this up was to render the embedded signing iframe for a controller action called 'embedded_signing' and specify the return_url of the `client.get_recipient_view` API call to be something like: http://myapp.com/docusign_response. Then in the same controller as the embedded_signing method, define the docusign_response method. This is where the signing process will redirect to after the user is done interacting with the DocuSign iframe. DocuSign passes a query string parameter in the return_url named 'event' and you can check like so: `if params[:event] == \"signing_complete\"` then you'll want to redirect to another spot in your app, not in the iframe. To do so, we need to use JavaScript to access the iframe's parent and set it's location to the path of our choosing. To do this, instanciate the DocusignRest::Utility class and call the breakout_path method like this:\n\n```ruby    \nclass SomeController < ApplicationController\n\n  # the view corresponding to this action has the iFrame in it with the\n  # @url as it's src. @envelope_response is populated from either:\n  # @envelope_response = client.create_envelope_from_document\n  # or\n  # @envelope_response = client.create_envelope_from_template\n  def embedded_signing\n    client = DocusignRest::Client.new\n    @url = client.get_recipient_view(\n      envelope_id: @envelope_response[\"envelopeId\"],\n      name: current_user.display_name,\n      email: current_user.email,\n      return_url: \"http://localhost:3000/docusign_response\"\n    )\n  end\n\n  def docusign_response\n    utility = DocusignRest::Utility.new\n\n    if params[:event] == \"signing_complete\"\n      flash[:notice] = \"Thanks! Successfully signed\"\n      render :text => utility.breakout_path(some_path), content_type: 'text/html'\n    else\n      flash[:notice] = \"You chose not to sign the document.\"\n      render :text => utility.breakout_path(some_other_path), content_type: 'text/html'\n    end\n  end\n\nend\n```\n\n## Contributing\n\n1. Fork it\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Added some feature'`) making sure to write tests to ensure nothing breaks\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create new Pull Request\n\n### Running the tests\n\nIn order to run the tests you'll need to register for a (free) DocuSign developer account. After doing so you'll have a username, password, and integrator key. Armed with that information execute the following ruby file:\n\n    $ bundle exec ruby lib/tasks/docusign_task.rb\n\nThis calls a rake task which adds a non-version controlled file in the test folder called `docusign_login_config.rb` which holds your account specific credentials and is required in order to hit the test API through the test suite.\n\n**Guard**\n\nSimply run 'guard' from the root directory of the repository to have the test suite executed automatically as you make changes.\n\n**VCR**\n\nThe test suite uses VCR and is configured to record all requests by using the 'all' configuration option surrounding each API request. If you want to speed up the test suite locally for new feature development, you may want to change the VCR config record setting to 'once' temporarily which will not write a new YAML file for each request each time you hit the API and significantly speed up the tests. However, this can lead to false passing tests as the gem changes so it's recommended that you ensure all tests pass by actually hitting the API before submitting a pull request.\n\n**SSL Issue**\n\nIn the event that you have an SSL error running the tests, such as;\n\n    SSL_connect returned=1 errno=0 state=SSLv3 read server certificate B: certificate verify failed\n\nthere is a sample cert 'cacert.pem' you can use when executing the\ntest suite.\n\n    SSL_CERT_FILE=cacert.pem guard\n    SSL_CERT_FILE=cacert.pem ruby lib/tasks/docusign_task.rb\n", "release_dates": []}, {"name": "download", "description": "Download and extract files", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# download [![CI](https://github.com/kevva/download/actions/workflows/ci.yml/badge.svg)](https://github.com/kevva/download/actions/workflows/ci.yml)\n\n> Download and extract files\n\n*See [download-cli](https://github.com/kevva/download-cli) for the command-line version.*\n\n\n## Install\n\n```sh\nnpm install download\n```\n\n\n## Usage\n\n```js\nimport fs from 'node:fs';\nimport download from 'download';\n\n(async () => {\n\tawait download('http://unicorn.com/foo.jpg', 'dist');\n\n\tfs.writeFileSync('dist/foo.jpg', await download('http://unicorn.com/foo.jpg'));\n\n\tdownload('unicorn.com/foo.jpg').pipe(fs.createWriteStream('dist/foo.jpg'));\n\n\tawait Promise.all([\n\t\t'unicorn.com/foo.jpg',\n\t\t'cats.com/dancing.gif'\n\t].map(url => download(url, 'dist')));\n})();\n```\n\n### Proxies\n\nTo work with proxies, read the [`got documentation`](https://github.com/sindresorhus/got#proxies).\n\n\n## API\n\n### download(url, destination?, options?)\n\nReturns both a `Promise<Buffer>` and a [Duplex stream](https://nodejs.org/api/stream.html#stream_class_stream_duplex) with [additional events](https://github.com/sindresorhus/got#streams-1).\n\n#### url\n\nType: `string`\n\nURL to download.\n\n#### destination\n\nType: `string`\n\nPath to where your file will be written.\n\n#### options\n\nType: `Object`\n\nSame options as [`got`](https://github.com/sindresorhus/got#options) and [`decompress`](https://github.com/kevva/decompress#options) in addition to the ones below.\n\n##### extract\n\n* Type: `boolean`\n* Default: `false`\n\nIf set to `true`, try extracting the file using [`decompress`](https://github.com/kevva/decompress).\n\n##### filename\n\nType: `string`\n\nName of the saved file.\n", "release_dates": []}, {"name": "electron-builder", "description": "Complete solution to package and deploy Electron apps", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# electron-builder [![npm version](https://img.shields.io/npm/v/electron-builder.svg)](https://npmjs.org/package/electron-builder) [![donate](https://img.shields.io/badge/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=W6V79R2RGCCHL)\nComplete solution to package and build ready for distribution and \"auto update\" Electron app for MacOS, Windows and Linux.\n\n* NPM packages management:\n  * [Native application dependencies](http://electron.atom.io/docs/latest/tutorial/using-native-node-modules/) compilation (only if [two-package.json project structure](#two-packagejson-structure) used).\n  * Development dependencies are never included. You don't need to ignore it explicitly.\n* [Code Signing](https://github.com/electron-userland/electron-builder/wiki/Code-Signing) on a CI server or development machine.\n* [Auto Update](#auto-update) ready application packaging.\n* [Build version management](https://github.com/electron-userland/electron-builder/wiki/Options#build-version-management).\n* Numerous target formats:\n  * All platforms: `7z`, `zip`, `tar.xz`, `tar.lz`, `tar.gz`, `tar.bz2`.\n  * [MacOS](https://github.com/electron-userland/electron-builder/wiki/Options#MacOptions-target): `dmg`, `mas`.\n  * [Linux](https://github.com/electron-userland/electron-builder/wiki/Options#LinuxBuildOptions-target): `AppImage`, `deb`, `rpm`, `freebsd`, `pacman`, `p5p`, `apk`.\n  * [Windows](https://github.com/electron-userland/electron-builder/wiki/Options#WinBuildOptions-target): NSIS, Squirrel.Windows.\n* [Publishing artifacts to GitHub Releases](https://github.com/electron-userland/electron-builder/wiki/Publishing-Artifacts).\n\n[appdmg](https://github.com/LinusU/node-appdmg) are used under the hood.\n\n_Note: `appdmg` (and the platform specific `7zip-bin-*` packages) are `optionalDependencies`, which may require manual install if you have npm configured to [not install optional deps by default](https://docs.npmjs.com/misc/config#optional)._\n\nReal project example \u2014 [onshape-desktop-shell](https://github.com/develar/onshape-desktop-shell).\n\n# Two package.json structure\n\nWe recommend to use two package.json files (it is not required, you can build project with any structure).\n\n1. For development\n\n   In the root of the project. Here you declare dependencies for your development environment and build scripts.\n\n2. For your application\n\n   In the `app` directory. *Only this directory is distributed with real application.*\n\nWhy?\n\n1. Native npm modules (those written in C, not JavaScript) need to be compiled, and here we have two different compilation targets for them. Those used in application need to be compiled against electron runtime, and all `devDependencies` need to be compiled against your locally installed node.js. Thanks to having two files this is trivial (see [#39](https://github.com/electron-userland/electron-builder/issues/39)).\n2. No need to specify which [files](https://github.com/electron-userland/electron-builder/wiki/Options#BuildMetadata-files) to include in the app (because development files reside outside the `app` directory).\n\nPlease see [Loading App Dependencies Manually](https://github.com/electron-userland/electron-builder/wiki/Loading-App-Dependencies-Manually) and [#379](https://github.com/electron-userland/electron-builder/issues/379#issuecomment-218503881).\n\n# Configuration\n\nSee [options](https://github.com/electron-userland/electron-builder/wiki/Options), but consider to follow simple guide outlined below at first.\n\nFor a production app you need to sign your application, see [Where to buy code signing certificate](https://github.com/electron-userland/electron-builder/wiki/Code-Signing#where-to-buy-code-signing-certificate).\n\n## In short\n1. Specify standard fields in the application `package.json` \u2014 [name](https://github.com/electron-userland/electron-builder/wiki/Options#AppMetadata-name), `description`, `version` and [author](https://docs.npmjs.com/files/package.json#people-fields-author-contributors) (for Linux [homepage](https://github.com/electron-userland/electron-builder/wiki/Options#AppMetadata-homepage) and [license](https://github.com/electron-userland/electron-builder/wiki/Options#AppMetadata-license) are also required).\n\n2. Specify [build](https://github.com/electron-userland/electron-builder/wiki/Options#build) field in the development `package.json`:\n    ```json\n    \"build\": {\n      \"appId\": \"your.id\",\n      \"app-category-type\": \"your.app.category.type\",\n      \"win\": {\n        \"iconUrl\": \"(windows-only) https link to icon\"\n      }\n    }\n    ```\n   See [options](https://github.com/electron-userland/electron-builder/wiki/Options). This object will be used as a source of [electron-packager](https://www.npmjs.com/package/electron-packager#packageropts-callback) options. You can specify any other options here.\n\n3. Create directory `build` in the root of the project and put your `background.png` (MacOS DMG background), `icon.icns` (MacOS app icon) and `icon.ico` (Windows app icon).\n\n   <a id=\"user-content-linuxIcon\" class=\"anchor\" href=\"#linuxIcon\" aria-hidden=\"true\"></a>Linux icon set will be generated automatically on the fly from the MacOS `icns` file (or you can put them into the `build/icons` directory \u2014 filename must contains size (e.g. `32x32.png`)).\n\n4. Add [scripts](https://docs.npmjs.com/cli/run-script) to the development `package.json`:\n    ```json\n    \"scripts\": {\n      \"postinstall\": \"install-app-deps\",\n      \"pack\": \"build --dir\",\n      \"dist\": \"build\"\n    }\n    ```\n    And then you can run `npm run dist` (to package in a distributable format (e.g. dmg, windows installer, deb package)) or `npm run pack` (useful to test).\n\n5. Install [required system packages](https://github.com/electron-userland/electron-builder/wiki/Multi-Platform-Build).\n\nPlease note \u2014 packaged into an asar archive [by default](https://github.com/electron-userland/electron-builder/wiki/Options#BuildMetadata-asar).\n\n# Auto Update\n`electron-builder` produces all required artifacts:\n\n* `.dmg`: MacOS installer, required for MacOS user to initial install.\n* `-mac.zip`: required for Squirrel.Mac.\n* `.exe` and `-ia32.exe`: Windows installer, required for Windows user to initial install. Please note \u2014 [your app must handle Squirrel.Windows events](https://github.com/electronjs/windows-installer#handling-squirrel-events). See [real example](https://github.com/develar/onshape-desktop-shell/blob/master/src/WinSquirrelStartupEventHandler.ts).\n* `.full-nupkg`: required for Squirrel.Windows.\n\nFor auto updating to work, you must implement and configure Electron's [`autoUpdater`](http://electron.atom.io/docs/latest/api/auto-updater/) module ([example](https://github.com/develar/onshape-desktop-shell/blob/master/src/AppUpdater.ts)).\nYou also need to deploy your releases to a server.\nConsider using [Nuts](https://github.com/GitbookIO/nuts) (GitHub as a backend to store assets), [Electron Release Server](https://github.com/ArekSredzki/electron-release-server) or [Squirrel Updates Server](https://github.com/Aluxian/squirrel-updates-server).\nSee the [Publishing Artifacts](https://github.com/electron-userland/electron-builder/wiki/Publishing-Artifacts) section of the [Wiki](https://github.com/electron-userland/electron-builder/wiki) for information on configuring your CI environment for automatic deployment.\n\nFor windows consider only [distributing 64-bit versions](https://github.com/electron-userland/electron-builder/issues/359#issuecomment-214851130).\n\n# CLI Usage\nExecute `node_modules/.bin/build --help` to get actual CLI usage guide.\n```\nBuilding:\n  --mac, -m, -o, --osx  Build for MacOS, accepts target list (see\n                        https://goo.gl/HAnnq8).                          [array]\n  --linux, -l           Build for Linux, accepts target list (see\n                        https://goo.gl/O80IL2)                           [array]\n  --win, -w, --windows  Build for Windows, accepts target list (see\n                        https://goo.gl/dL4i8i)                           [array]\n  --x64                 Build for x64                                  [boolean]\n  --ia32                Build for ia32                                 [boolean]\n  --dir                 Build unpacked dir. Useful to test.            [boolean]\n\nPublishing:\n  --publish, -p  Publish artifacts (to GitHub Releases), see\n                 https://goo.gl/WMlr4n\n                           [choices: \"onTag\", \"onTagOrDraft\", \"always\", \"never\"]\n  --draft        Create a draft (unpublished) release                  [boolean]\n  --prerelease   Identify the release as a prerelease                  [boolean]\n\nDeprecated:\n  --platform  The target platform (preferred to use --mac, --win or --linux)\n               [choices: \"mac\", \"osx\", \"win\", \"linux\", \"darwin\", \"win32\", \"all\"]\n  --arch      The target arch (preferred to use --x64 or --ia32)\n                                                 [choices: \"ia32\", \"x64\", \"all\"]\n\nOther:\n  --help     Show help                                                 [boolean]\n  --version  Show version number                                       [boolean]\n\nExamples:\n  build -mwl                build for MacOS, Windows and Linux\n  build --linux deb tar.xz  build deb and tar.xz for Linux\n  build --win --ia32        build for Windows ia32\n```\n\n# Programmatic Usage\nSee `node_modules/electron-builder/out/electron-builder.d.ts`. [Typings](https://github.com/Microsoft/TypeScript/wiki/Typings-for-npm-packages) is supported.\n\n```js\n\"use strict\"\n\nconst builder = require(\"electron-builder\")\nconst Platform = builder.Platform\n\n// Promise is returned\nbuilder.build({\n  targets: Platform.MAC.createTarget(),\n  devMetadata: {\n    \"//\": \"build and other properties, see https://goo.gl/5jVxoO\"\n  }\n})\n  .then(() => {\n    // handle result\n  })\n  .catch((error) => {\n    // handle error\n  })\n```\n\n# Donations\n\n[Donate with PayPal.](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=W6V79R2RGCCHL)\n\n# Further Reading\nSee the [Wiki](https://github.com/electron-userland/electron-builder/wiki) for more documentation.\n\n\n", "release_dates": []}, {"name": "electron-chromedriver", "description": "Download ChromeDriver for Electron", "language": "JavaScript", "license": null, "readme": "# Electron ChromeDriver\n\n[![Linux Build Status](https://travis-ci.org/electron/chromedriver.svg?branch=master)](https://travis-ci.org/electron/chromedriver)\n[![Windows Build Status](https://ci.appveyor.com/api/projects/status/cjfs6uem441l52m5/branch/master?svg=true)](https://ci.appveyor.com/project/Atom/chromedriver/branch/master)\n<br>\n[![js-standard-style](https://img.shields.io/badge/code%20style-standard-brightgreen.svg?style=flat)](http://standardjs.com/)\n[![devDependencies:?](https://img.shields.io/david/electron/chromedriver.svg)](https://david-dm.org/electron/chromedriver)\n<br>\n[![license:mit](https://img.shields.io/badge/license-mit-blue.svg)](https://opensource.org/licenses/MIT)\n[![npm:](https://img.shields.io/npm/v/electron-chromedriver.svg)](https://www.npmjs.com/packages/electron-chromedriver)\n[![dependencies:?](https://img.shields.io/npm/dm/electron-chromedriver.svg)](https://www.npmjs.com/packages/electron-chromedriver)\n\nSimple node module to download the [ChromeDriver](https://sites.google.com/a/chromium.org/chromedriver)\nversion for [Electron](http://electron.atom.io).\n\nThis minor version of this library tracks the minor version of the Electron\nversions released. So if you are using Electron `1.0.x` you would want to use\nan `electron-chromedriver` dependency of `~1.0.0` in your `package.json` file.\n\nThis library is used by [spectron](https://github.com/electron/spectron).\n\n## Using\n\n```sh\nnpm install --save-dev electron-chromedriver\nchromedriver -h\n```\n\n## Custom Mirror\n\nYou can set the `ELECTRON_MIRROR` or [`NPM_CONFIG_ELECTRON_MIRROR`](https://docs.npmjs.com/misc/config#environment-variables)\nenvironment variables to use a custom base URL for downloading ChromeDriver zips.\n\n```sh\n# Electron mirror for China\nELECTRON_MIRROR=\"https://npm.taobao.org/mirrors/electron/\"\n\n# Local mirror\n# Example of requested URL: http://localhost:8080/1.2.0/chromedriver-v2.21-darwin-x64.zip\nELECTRON_MIRROR=\"http://localhost:8080/\"\n```\n", "release_dates": []}, {"name": "electron-debug-symbols", "description": "npm module to install electron debug symbols", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# electron-debug-symbols\nnpm module to install brave/electron debug symbols\n\n# usage\n```javascript\nvar minidump = require(\"minidump\")\nminidump.addSymbolPath.apply(minidump, require(\"electron-debug-symbols\").pathsForVersion('x.x.x'))\n\n// now when using minidump.walkStack, it would give a more understandable report due to having debug symbols\n```\n\nYou can use BRAVE_VERSIONS environment variables to make the module install custom versions, for example when deploying to Heroku.\n```\nheroku config:set BRAVE_VERSIONS=\"0.29.2 0.27.1\"\n```", "release_dates": []}, {"name": "electron-download", "description": "downloads a electron release zip from github", "language": "JavaScript", "license": null, "readme": "# electron-download\n\n[![Build Status](https://travis-ci.org/electron-userland/electron-download.svg?branch=master)](https://travis-ci.org/electron-userland/electron-download)\n\n[![NPM](https://nodei.co/npm/electron-download.png)](https://nodei.co/npm/electron-download/)\n\ndownloads a electron release zip from github\n\nused by [electron-prebuilt](https://npmjs.org/electron-prebuilt) and [electron-packager](https://npmjs.org/electron-packager)\n\n### usage\n\n```plain\n$ npm install --global electron-download\n$ electron-download --version=0.31.1\n```\n\n```\nvar download = require('electron-download')\n\ndownload({\n  version: '0.25.1',\n  arch: 'ia32',\n  platform: 'win32',\n  cache: './zips' // defaults to <users home directory>/.electron\n}, function (err, zipPath) {\n  // zipPath will be the path of the zip that it downloaded.\n  // if the zip was already cached it will skip\n  // downloading and call the cb with the cached zip path\n  // if it wasn't cached it will download the zip and save\n  // it in the cache path\n})\n```\n\nif you don't specify `arch` or `platform` args it will use `require('os')` to get them from the current OS. specifying `version` is mandatory.\n\nIf you would like to override the mirror location, three options are available. The mirror URL is composed as `url = ELECTRON_MIRROR + ELECTRON_CUSTOM_DIR + '/' + ELECTRON_CUSTOM_FILENAME`.\n\nYou can set the `ELECTRON_MIRROR` or [`NPM_CONFIG_ELECTRON_MIRROR`](https://docs.npmjs.com/misc/config#environment-variables) env or `mirror` opt variable to use a custom base URL for grabbing electron zips. The same pattern applies to `ELECTRON_CUSTOM_DIR` and `ELECTRON_CUSTOM_FILENAME`\n\n```plain\n## Electron Mirror of China\nELECTRON_MIRROR=\"https://npm.taobao.org/mirrors/electron/\"\n\n## or for a local mirror\nELECTRON_MIRROR=\"https://10.1.2.105/\"\nELECTRON_CUSTOM_DIR=\"our/internal/filePath\"\n```\n\n", "release_dates": []}, {"name": "electron-installer-debian", "description": "Create a Debian package for your Electron app.", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "![Electron Installer for Debian](resources/logo.png)\n\n# electron-installer-debian [![Version](https://img.shields.io/npm/v/electron-installer-debian.svg)](https://www.npmjs.com/package/electron-installer-debian) [![Build Status](https://img.shields.io/travis/unindented/electron-installer-debian.svg)](http://travis-ci.org/unindented/electron-installer-debian) [![Dependency Status](https://img.shields.io/gemnasium/unindented/electron-installer-debian.svg)](https://gemnasium.com/unindented/electron-installer-debian)\n\n> Create a Debian package for your Electron app.\n\n\n## Requirements\n\nThis tool requires `fakeroot` and `dpkg` to build the `.deb` package.\n\nI'd recommend building your packages on your target platform, but if you insist on using Mac OS X, you can install these tools through [Homebrew](http://brew.sh/):\n\n```\n$ brew install fakeroot dpkg\n```\n\n\n## Installation\n\nFor use from command-line:\n\n```\n$ npm install -g electron-installer-debian\n```\n\nFor use in npm scripts or programmatically:\n\n```\n$ npm install --save-dev electron-installer-debian\n```\n\n\n## Usage\n\nSay your Electron app lives in `path/to/app`, and has a structure like this:\n\n```\n.\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 node_modules\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 electron-packager\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 electron-prebuilt\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 resources\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Icon.png\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 IconTemplate.png\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 IconTemplate@2x.png\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 index.js\n    \u251c\u2500\u2500 main\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 index.js\n    \u2514\u2500\u2500 renderer\n        \u251c\u2500\u2500 index.html\n        \u2514\u2500\u2500 index.js\n```\n\nYou now run `electron-packager` to build the app for Debian:\n\n```\n$ electron-packager . app --platform linux --arch x64 --out dist/\n```\n\nAnd you end up with something like this in your `dist` folder:\n\n```\n.\n\u2514\u2500\u2500 dist\n \u00a0\u00a0 \u2514\u2500\u2500 app-linux-x64\n \u00a0\u00a0     \u251c\u2500\u2500 LICENSE\n \u00a0\u00a0     \u251c\u2500\u2500 LICENSES.chromium.html\n \u00a0\u00a0     \u251c\u2500\u2500 content_shell.pak\n \u00a0\u00a0     \u251c\u2500\u2500 app\n \u00a0\u00a0     \u251c\u2500\u2500 icudtl.dat\n \u00a0\u00a0     \u251c\u2500\u2500 libgcrypt.so.11\n \u00a0\u00a0     \u251c\u2500\u2500 libnode.so\n \u00a0\u00a0     \u251c\u2500\u2500 locales\n \u00a0\u00a0     \u251c\u2500\u2500 natives_blob.bin\n \u00a0\u00a0     \u251c\u2500\u2500 resources\n \u00a0\u00a0     \u251c\u2500\u2500 snapshot_blob.bin\n \u00a0\u00a0     \u2514\u2500\u2500 version\n```\n\nHow do you turn that into a Debian package that your users can install?\n\n### Command-Line\n\nIf you want to run `electron-installer-debian` straight from the command-line, install the package globally:\n\n```\n$ npm install -g electron-installer-debian\n```\n\nAnd point it to your built app:\n\n```\n$ electron-installer-debian --src dist/app-linux-x64/ --dest dist/installers/ --arch amd64\n```\n\nYou'll end up with the package at `dist/installers/app_0.0.1_amd64.deb`.\n\n### Scripts\n\nIf you want to run `electron-installer-debian` through npm, install the package locally:\n\n```\n$ npm install --save-dev electron-installer-debian\n```\n\nEdit the `scripts` section of your `package.json`:\n\n```js\n{\n  \"name\": \"app\",\n  \"description\": \"An awesome app!\",\n  \"version\": \"0.0.1\",\n  \"scripts\": {\n    \"start\": \"electron .\",\n    \"build\": \"electron-packager . app --platform linux --arch x64 --out dist/\",\n    \"deb64\": \"electron-installer-debian --src dist/app-linux-x64/ --dest dist/installers/ --arch amd64\"\n  },\n  \"devDependencies\": {\n    \"electron-installer-debian\": \"*\",\n    \"electron-packager\": \"*\",\n    \"electron-prebuilt\": \"*\"\n  }\n}\n```\n\nAnd run the script:\n\n```\n$ npm run deb64\n```\n\nYou'll end up with the package at `dist/installers/app_0.0.1_amd64.deb`.\n\n### Programmatically\n\nInstall the package locally:\n\n```\n$ npm install --save-dev electron-installer-debian\n```\n\nAnd write something like this:\n\n```js\nvar installer = require('electron-installer-debian')\n\nvar options = {\n  src: 'dist/app-linux-x64/',\n  dest: 'dist/installers/',\n  arch: 'amd64'\n}\n\nconsole.log('Creating package (this may take a while)')\n\ninstaller(options, function (err) {\n  if (err) {\n    console.error(err, err.stack)\n    process.exit(1)\n  }\n\n  console.log('Successfully created package at ' + options.dest)\n})\n```\n\nYou'll end up with the package at `dist/installers/app_0.0.1_amd64.deb`.\n\n### Options\n\nEven though you can pass most of these options through the command-line interface, it may be easier to create a configuration file:\n\n```js\n{\n  \"dest\": \"dist/installers/\",\n  \"icon\": \"resources/Icon.png\",\n  \"categories\": [\n    \"Utility\"\n  ],\n  \"lintianOverrides\": [\n    \"changelog-file-missing-in-native-package\"\n  ]\n}\n```\n\nAnd pass that instead with the `config` option:\n\n```\n$ electron-installer-debian --src dist/app-linux-x64/ --arch amd64 --config config.json\n```\n\nAnyways, here's the full list of options:\n\n#### src\nType: `String`\nDefault: `undefined`\n\nPath to the folder that contains your built Electron application.\n\n#### dest\nType: `String`\nDefault: `undefined`\n\nPath to the folder that will contain your Debian installer.\n\n#### rename\nType: `Function`\nDefault: `function (dest, src) { return path.join(dest, src); }`\n\nFunction that renames all files generated by the task just before putting them in your `dest` folder.\n\n#### options.name\nType: `String`\nDefault: `package.name`\n\nName of the package (e.g. `atom`), used in the [`Package` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Package).\n\nAccording to the *Debian Policy Manual*:\n\n> Package names [...] must consist only of lower case letters (a-z), digits (0-9), plus (+) and minus (-) signs, and periods (.). They must be at least two characters long and must start with an alphanumeric character.\n\n#### options.productName\nType: `String`\nDefault: `package.productName || package.name`\n\nName of the application (e.g. `Atom`), used in the [`Name` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\n#### options.genericName\nType: `String`\nDefault: `package.genericName || package.productName || package.name`\n\nGeneric name of the application (e.g. `Text Editor`), used in the [`GenericName` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\n#### options.description\nType: `String`\nDefault: `package.description`\n\nShort description of the application, used in the [`Description` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Description).\n\n#### options.productDescription\nType: `String`\nDefault: `package.productDescription || package.description`\n\nLong description of the application, used in the [`Description` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Description).\n\n#### options.version\nType: `String`\nDefault: `package.version`\n\nVersion number of the package, used in the [`Version` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Version).\n\n#### options.revision\nType: `String`\nDefault: `package.revision`\n\nRevision number of the package, used in the [`Version` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Version).\n\n#### options.section\nType: `String`\nDefault: `\"utils\"`\n\nApplication area into which the package has been classified, used in the [`Section` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Section).\n\nYou can read more about [sections](https://www.debian.org/doc/debian-policy/ch-archive.html#s-subsections), and also check out the [list of existing sections in Debian unstable](https://packages.debian.org/unstable/).\n\n#### options.priority\nType: `String`\nDefault: `\"optional\"`\n\nHow important it is that the user have the package installed., used in the [`Priority` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Priority).\n\nYou can read more about [priorities](https://www.debian.org/doc/debian-policy/ch-archive.html#s-priorities).\n\n#### options.arch\nType: `String`\nDefault: `undefined`\n\nMachine architecture the package is targeted to, used in the [`Architecture` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Architecture).\n\nFor possible values see the output of `dpkg-architecture -L`.\n\n#### options.size\nType: `Integer`\nDefault: `size of the folder`\n\nEstimate of the total amount of disk space required to install the named package, used in the [`Installed-Size` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Installed-Size).\n\n#### options.depends et al\nType: `Array[String]`\nDefault: `[]`\n\nRelationships to other packages, used in the [`Depends`, `Recommends`, `Suggests`, `Enhances` and `Pre-Depends` fields of the `control` specification](https://www.debian.org/doc/debian-policy/ch-relationships.html#s-binarydeps).\n\n#### options.maintainer\nType: `String`\nDefault: `package.author.name <package.author.email>`\n\nMaintainer of the package, used in the [`Maintainer` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Maintainer).\n\n#### options.homepage\nType: `String`\nDefault: `package.homepage || package.author.url`\n\nURL of the homepage for the package, used in the [`Homepage` field of the `control` specification](https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Homepage).\n\n#### options.bin\nType: `String`\nDefault: `package.name`\n\nRelative path to the executable that will act as binary for the application, used in the [`Exec` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\nThe generated package will contain a symlink `/usr/bin/<%= options.name %>` pointing to the path provided here.\n\nFor example, providing this configuration:\n\n```js\n{\n  src: '...',\n  dest: '...',\n  name: 'foo',\n  bin: 'resources/cli/launcher.sh'\n}\n```\n\nWill create a package with the following symlink:\n\n```\nusr/bin/foo@ -> ../lib/foo/resources/cli/launcher.sh\n```\n\nAnd a desktop specification with the following `Exec` key:\n\n```\nExec=foo %U\n```\n\n#### options.icon\nType: `String` or `Object[String:String]`\nDefault: `undefined`\n\nPath to a single image that will act as icon for the application:\n\n```js\n{\n  icon: 'resources/Icon.png'\n}\n```\n\nOr multiple images with their corresponding resolutions:\n\n```js\n{\n  icon: {\n    '48x48': 'resources/Icon48.png',\n    '64x64': 'resources/Icon64.png',\n    '128x128': 'resources/Icon128.png',\n    '256x256': 'resources/Icon256.png'\n  }\n}\n```\n\n#### options.categories\nType: `Array[String]`\nDefault: `[]`\n\nCategories in which the application should be shown in a menu, used in the [`Categories` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\nFor possible values check out the [Desktop Menu Specification](http://standards.freedesktop.org/menu-spec/latest/apa.html).\n\n#### options.mimeType\nType: `Array[String]`\nDefault: `[]`\n\nMIME types the application is able to open, used in the [`MimeType` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\n#### options.lintianOverrides\nType: `Array[String]`\nDefault: `[]`\n\nYou can use these to quieten [`lintian`](https://lintian.debian.org/manual/).\n\n\n## Meta\n\n* Code: `git clone git://github.com/unindented/electron-installer-debian.git`\n* Home: <https://github.com/unindented/electron-installer-debian/>\n\n\n## Contributors\n\n* Daniel Perez Alvarez ([unindented@gmail.com](mailto:unindented@gmail.com))\n\n\n## License\n\nCopyright (c) 2016 Daniel Perez Alvarez ([unindented.org](https://unindented.org/)). This is free software, and may be redistributed under the terms specified in the LICENSE file.\n", "release_dates": []}, {"name": "electron-installer-redhat", "description": "Create a Red Hat package for your Electron app.", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "![Electron Installer for Red Hat](resources/logo.png)\n\n# electron-installer-redhat [![Version](https://img.shields.io/npm/v/electron-installer-redhat.svg)](https://www.npmjs.com/package/electron-installer-redhat) [![Build Status](https://img.shields.io/travis/unindented/electron-installer-redhat.svg)](http://travis-ci.org/unindented/electron-installer-redhat) [![Dependency Status](https://img.shields.io/gemnasium/unindented/electron-installer-redhat.svg)](https://gemnasium.com/unindented/electron-installer-redhat)\n\n> Create a Red Hat package for your Electron app.\n\n\n## Requirements\n\nThis tool requires `rpmbuild` to build the `.rpm` package. On Fedora you can do something like this:\n\n```\n$ sudo dnf install rpm-build\n```\n\nWhile on Ubuntu you'll need to do this instead:\n\n```\n$ sudo apt-get install rpm\n```\n\n\n## Installation\n\nFor use from command-line:\n\n```\n$ npm install -g electron-installer-redhat\n```\n\nFor use in npm scripts or programmatically:\n\n```\n$ npm install --save-dev electron-installer-redhat\n```\n\n\n## Usage\n\nSay your Electron app lives in `path/to/app`, and has a structure like this:\n\n```\n.\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 node_modules\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 electron-packager\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 electron-prebuilt\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 resources\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Icon.png\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 IconTemplate.png\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 IconTemplate@2x.png\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 index.js\n    \u251c\u2500\u2500 main\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 index.js\n    \u2514\u2500\u2500 renderer\n        \u251c\u2500\u2500 index.html\n        \u2514\u2500\u2500 index.js\n```\n\nYou now run `electron-packager` to build the app for Red Hat:\n\n```\n$ electron-packager . app --platform linux --arch x64 --out dist/\n```\n\nAnd you end up with something like this in your `dist` folder:\n\n```\n.\n\u2514\u2500\u2500 dist\n \u00a0\u00a0 \u2514\u2500\u2500 app-linux-x64\n \u00a0\u00a0     \u251c\u2500\u2500 LICENSE\n \u00a0\u00a0     \u251c\u2500\u2500 LICENSES.chromium.html\n \u00a0\u00a0     \u251c\u2500\u2500 content_shell.pak\n \u00a0\u00a0     \u251c\u2500\u2500 app\n \u00a0\u00a0     \u251c\u2500\u2500 icudtl.dat\n \u00a0\u00a0     \u251c\u2500\u2500 libgcrypt.so.11\n \u00a0\u00a0     \u251c\u2500\u2500 libnode.so\n \u00a0\u00a0     \u251c\u2500\u2500 locales\n \u00a0\u00a0     \u251c\u2500\u2500 natives_blob.bin\n \u00a0\u00a0     \u251c\u2500\u2500 resources\n \u00a0\u00a0     \u251c\u2500\u2500 snapshot_blob.bin\n \u00a0\u00a0     \u2514\u2500\u2500 version\n```\n\nHow do you turn that into a Red Hat package that your users can install?\n\n### Command-Line\n\nIf you want to run `electron-installer-redhat` straight from the command-line, install the package globally:\n\n```\n$ npm install -g electron-installer-redhat\n```\n\nAnd point it to your built app:\n\n```\n$ electron-installer-redhat --src dist/app-linux-x64/ --dest dist/installers/ --arch x86_64\n```\n\nYou'll end up with the package at `dist/installers/app-0.0.1.x86_64.rpm`.\n\n### Scripts\n\nIf you want to run `electron-installer-redhat` through npm, install the package locally:\n\n```\n$ npm install --save-dev electron-installer-redhat\n```\n\nEdit the `scripts` section of your `package.json`:\n\n```js\n{\n  \"name\": \"app\",\n  \"description\": \"An awesome app!\",\n  \"version\": \"0.0.1\",\n  \"scripts\": {\n    \"start\": \"electron .\",\n    \"build\": \"electron-packager . app --platform linux --arch x64 --out dist/\",\n    \"rpm64\": \"electron-installer-redhat --src dist/app-linux-x64/ --dest dist/installers/ --arch x86_64\"\n  },\n  \"devDependencies\": {\n    \"electron-installer-redhat\": \"*\",\n    \"electron-packager\": \"*\",\n    \"electron-prebuilt\": \"*\"\n  }\n}\n```\n\nAnd run the script:\n\n```\n$ npm run rpm64\n```\n\nYou'll end up with the package at `dist/installers/app-0.0.1.x86_64.rpm`.\n\n### Programmatically\n\nInstall the package locally:\n\n```\n$ npm install --save-dev electron-installer-redhat\n```\n\nAnd write something like this:\n\n```js\nvar installer = require('electron-installer-redhat')\n\nvar options = {\n  src: 'dist/app-linux-x64/',\n  dest: 'dist/installers/',\n  arch: 'x86_64'\n}\n\nconsole.log('Creating package (this may take a while)')\n\ninstaller(options, function (err) {\n  if (err) {\n    console.error(err, err.stack)\n    process.exit(1)\n  }\n\n  console.log('Successfully created package at ' + options.dest)\n})\n```\n\nYou'll end up with the package at `dist/installers/app-0.0.1.x86_64.rpm`.\n\n### Options\n\nEven though you can pass most of these options through the command-line interface, it may be easier to create a configuration file:\n\n```js\n{\n  \"dest\": \"dist/installers/\",\n  \"icon\": \"resources/Icon.png\",\n  \"categories\": [\n    \"Utility\"\n  ]\n}\n```\n\nAnd pass that instead with the `config` option:\n\n```\n$ electron-installer-redhat --src dist/app-linux-x64/ --arch x86_64 --config config.json\n```\n\nAnyways, here's the full list of options:\n\n#### src\nType: `String`\nDefault: `undefined`\n\nPath to the folder that contains your built Electron application.\n\n#### dest\nType: `String`\nDefault: `undefined`\n\nPath to the folder that will contain your Red Hat installer.\n\n#### rename\nType: `Function`\nDefault: `function (dest, src) { return path.join(dest, src); }`\n\nFunction that renames all files generated by the task just before putting them in your `dest` folder.\n\n#### options.name\nType: `String`\nDefault: `package.name`\n\nName of the package (e.g. `atom`), used in the [`Name` field of the `spec` file](https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Creating_a_SPEC_file).\n\nCheck out the [Fedora Naming Guidelines](https://fedoraproject.org/wiki/Packaging:NamingGuidelines#Common_Character_Set_for_Package_Naming).\n\n#### options.productName\nType: `String`\nDefault: `package.productName || package.name`\n\nName of the application (e.g. `Atom`), used in the [`Name` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\n#### options.genericName\nType: `String`\nDefault: `package.genericName || package.productName || package.name`\n\nGeneric name of the application (e.g. `Text Editor`), used in the [`GenericName` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\n#### options.description\nType: `String`\nDefault: `package.description`\n\nShort description of the application, used in the [`Summary` field of the `spec` file](https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Creating_a_SPEC_file).\n\n#### options.productDescription\nType: `String`\nDefault: `package.productDescription || package.description`\n\nLong description of the application, used in the [`%description` tag of the `spec` file](https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Creating_a_SPEC_file).\n\n#### options.version\nType: `String`\nDefault: `package.version`\n\nVersion number of the package, used in the [`Version` field of the `spec` file](https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Creating_a_SPEC_file).\n\n#### options.revision\nType: `String`\nDefault: `package.revision`\n\nRevision number of the package, used in the [`Release` field of the `spec` file](https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Creating_a_SPEC_file).\n\n#### options.license\nType: `String`\nDefault: `package.license`\n\nLicense of the package, used in the [`License` field of the `spec` file](https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Creating_a_SPEC_file).\n\n#### options.group\nType: `String`\nDefault: `undefined`\n\nGroup of the package, used in the [`Group` field of the `spec` file](https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Creating_a_SPEC_file).\n\n#### options.arch\nType: `String`\nDefault: `undefined`\n\nMachine architecture the package is targeted to, used to set the `--target` option.\n\n#### options.requires\nType: `Array[String]`\nDefault: `[\"lsb\", \"libXScrnSaver\"]`\n\nPackages that are required when the program starts, used in the [`Requires` field of the `spec` file](https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Creating_a_SPEC_file).\n\n#### options.homepage\nType: `String`\nDefault: `package.homepage || package.author.url`\n\nURL of the homepage for the package, used in the [`Homepage` field of the `control` specification](https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Creating_a_SPEC_file).\n\n#### options.compressionLevel\nType: `Number`\nDefault: `2`\n\nPackage compression level, from `0` to `9`.\n\n#### options.bin\nType: `String`\nDefault: `package.name`\n\nRelative path to the executable that will act as binary for the application, used in the [`Exec` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\nThe generated package will contain a symlink `/usr/bin/<%= options.name %>` pointing to the path provided here.\n\nFor example, providing this configuration:\n\n```js\n{\n  src: '...',\n  dest: '...',\n  name: 'foo',\n  bin: 'resources/cli/launcher.sh'\n}\n```\n\nWill create a package with the following symlink:\n\n```\nusr/bin/foo@ -> ../share/foo/resources/cli/launcher/sh\n```\n\nAnd a desktop specification with the following `Exec` key:\n\n```\nExec=foo %U\n```\n\n#### options.execArguments\nType: `Array[String]`\nDefault: `[]`\n\nCommand-line arguments to pass to the executable. Will be added to the [`Exec` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\n#### options.icon\nType: `String` or `Object[String:String]`\nDefault: `undefined`\n\nPath to a single image that will act as icon for the application:\n\n```js\n{\n  icon: 'resources/Icon.png'\n}\n```\n\nOr multiple images with their corresponding resolutions:\n\n```js\n{\n  icon: {\n    '48x48': 'resources/Icon48.png',\n    '64x64': 'resources/Icon64.png',\n    '128x128': 'resources/Icon128.png',\n    '256x256': 'resources/Icon256.png'\n  }\n}\n```\n\n#### options.categories\nType: `Array[String]`\nDefault: `[]`\n\nCategories in which the application should be shown in a menu, used in the [`Categories` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\nFor possible values check out the [Desktop Menu Specification](http://standards.freedesktop.org/menu-spec/latest/apa.html).\n\n#### options.mimeType\nType: `Array[String]`\nDefault: `[]`\n\nMIME types the application is able to open, used in the [`MimeType` field of the `desktop` specification](http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-latest.html).\n\n## Meta\n\n* Code: `git clone git://github.com/unindented/electron-installer-redhat.git`\n* Home: <https://github.com/unindented/electron-installer-redhat/>\n\n\n## Contributors\n\n* Daniel Perez Alvarez ([unindented@gmail.com](mailto:unindented@gmail.com))\n\n\n## License\n\nCopyright (c) 2016 Daniel Perez Alvarez ([unindented.org](https://unindented.org/)). This is free software, and may be redistributed under the terms specified in the LICENSE file.\n", "release_dates": []}, {"name": "electron-installer-squirrel-windows", "description": "Generate Windows installers for Electron apps using Squirrel.", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# electron-installer-squirrel-windows [![][appveyor_img]][appveyor_url]\n\nGenerate Windows installers for [Electron][electron] apps using [Squirrel][squirrel].\n\n## Todo\n\n- Pull `AppModel` into it's own module\n\n## Installation\n\n```\n# For use in npm scripts\nnpm i electron-installer-squirrel-windows --save-dev\n\n# For use from cli\nnpm i electron-installer-squirrel-windows -g\n```\n\n## Usage\n\n```\nUsage: electron-installer-squirrel-windows <path/to/.app>\n\nGenerate Windows installers for Electron apps.\n\nUsage:\n  electron-installer-squirrel-windows ./dist/FooBar-win32-ia32\n  # Creates a `.nupkg`, a `RELEASES` file, and a `.exe` installer file in `./`\n\nOptions:\n  --out=<path>         The directory to place artifacts [Default: `process.cwd()`].\n  --debug              Enable debug messages.\n  --overwrite          Overwrite any existing `Setup.exe` [Default: `false`].\n  -h --help            Show this screen.\n  --version            Show version.\n```\n\n## Integration\n\nSquirrel will spawn your app with command line flags on first run,\nupdates, and uninstalls. It is **very** important that your app handle\nthese events as _early_ as possible, and quit **immediately** after\nhandling them. Squirrel will give your app a short amount of time\n(~15sec) to apply these operations and quit.\n\nThe [electron-squirrel-startup][electron-squirrel-startup] module will handle\nthe most common events for you, such as managing desktop shortcuts.  Just\nadd the following to the top of your `main.js` and you're good to go:\n\n```js\nif(require('electron-squirrel-startup')) return;\n```\n\n### API\n\n```javascript\nvar createInstaller = require('electron-installer-squirrel-windows')\ncreateInstaller(opts, function done (err) { })\n```\n#### createInstaller(opts, callback)\n\n##### opts\n\n**Required**\n\n`path` - *String*\nThe directory generated by [electron-packager][electron-packager].\n\n**Optional**\n\n> **Note** All optional keys will be read from your `package.json` by default.\n\n`name` - *String*\nThe application name (usually all lowercase with dashes for spaces).\n\n`product_name` - *String*\nThe marketing name (usually `name` with spaces and titlecased).\n\n`out` - *String*\nThe folder path to create the `.exe` installer in. [Default: `process.cwd()`]\n\n`loading_gif` - *String*\nThe local path to a `.gif` file to display during install. [Default: `__dirname/resources/install-spinner.gif`]\n\n`authors` - *String*\nThe authors value for the nuget package metadata.\n\n`owners` - *String*\nThe owners value for the nuget package metadata. [Default: `#{authors}`]\n\n`exe` - *String*\nThe name of your app's main `.exe` file. [Default: `#{product_name}Setup.exe`]\n\n`description` - *String*\nThe description value for the nuget package metadata. [Default: ``]\n\n`version` - *String*\nThe version value for the nuget package metadata.\n\n`title` - *String*\nThe title value for the nuget package metadata. [Default: `#{product_name || name}`]\n\n`cert_path` - *String*\nThe path to an Authenticode Code Signing Certificate. [Default: `null`]\n\n`cert_password` - *String*\nThe password to decrypt the certificate given in `cert_path`. [Default: `null`]\n\n`sign_with_params` - *String*\nParams to pass to signtool which overrides `cert_path` and `cert_password`.  [Default: `null`]\n\n`setup_icon` - *String*\nURL to the `.ico` file to use as the icon for the generated `Setup.exe`. [Default: `http://git.io/vqdOX` (atom.ico)]\n\n`remote_releases` - *String*\nURL to your existing updates. If given, these will be downloaded to create delta updates. [Default: `null`]\n\n`overwrite` - *Boolean*\nOverwrite existing installers if they already exist. [Default: `false`]\n\n`debug` - *Boolean*\nEnable debug message output. [Default: `false`]\n\n##### callback\n\n`err` - *Error*\nContains errors if any.\n\n## License\n\nRelicensed under Apache 2.0 Copyright (c) 2015 MongoDB Inc.\n\nBased on [atom/grunt-electron-installer][original] Copyright (c) 2015 GitHub Inc.\n\n[appveyor_img]: https://ci.appveyor.com/api/projects/status/157smy0vsosp72bu/branch/master?svg=true\n[appveyor_url]: https://ci.appveyor.com/project/mongodb-js/electron-installer-squirrel-windows/branch/master\n[electron]: https://github.com/atom/electron\n[squirrel]: https://github.com/Squirrel/Squirrel.Windows\n[original]: https://github.com/atom/grunt-electron-installer\n[electron-squirrel-startup]: https://github.com/mongodb-js/electron-squirrel-startup\n", "release_dates": []}, {"name": "electron-packager", "description": "Package and distribute your Electron app in OS executables (.app, .exe etc) via JS or CLI. Maintained by the community", "language": "JavaScript", "license": {"key": "bsd-2-clause", "name": "BSD 2-Clause \"Simplified\" License", "spdx_id": "BSD-2-Clause", "url": "https://api.github.com/licenses/bsd-2-clause", "node_id": "MDc6TGljZW5zZTQ="}, "readme": "# electron-packager\n\nPackage your [Electron](http://electron.atom.io) app into OS-specific bundles (`.app`, `.exe`, etc.) via JavaScript or the command line.\n\n[![Travis CI Build Status](https://travis-ci.org/electron-userland/electron-packager.svg?branch=master)](https://travis-ci.org/electron-userland/electron-packager)\n[![AppVeyor Build status](https://ci.appveyor.com/api/projects/status/m51mlf6ntd138555?svg=true)](https://ci.appveyor.com/project/electron-userland/electron-packager)\n[![Coverage Status](https://coveralls.io/repos/github/electron-userland/electron-packager/badge.svg?branch=master)](https://coveralls.io/github/electron-userland/electron-packager?branch=master)\n\n## About\n\nElectron Packager is a command line tool that packages electron app source code into executables like `.app` or `.exe` along with a copy of Electron.\n\nNote that packaged Electron applications can be relatively large. A zipped barebones OS X Electron application is around 40MB.\n\n### Electron Packager is an [OPEN Open Source Project](http://openopensource.org/)\n\nIndividuals making significant and valuable contributions are given commit-access to the project to contribute as they see fit. This project is more like an open wiki than a standard guarded open source project.\n\nSee [CONTRIBUTING.md](https://github.com/electron-userland/electron-packager/blob/master/CONTRIBUTING.md) and [openopensource.org](http://openopensource.org/) for more details.\n\n### [Release Notes](https://github.com/electron-userland/electron-packager/blob/master/NEWS.md)\n\n## Supported Platforms\n\nElectron Packager is known to run on the following **host** platforms:\n\n* Windows (32/64 bit)\n* OS X\n* Linux (x86/x86_64)\n\nIt generates executables/bundles for the following **target** platforms:\n\n* Windows (also known as `win32`, for both 32/64 bit)\n* OS X (also known as `darwin`) / [Mac App Store](http://electron.atom.io/docs/v0.36.0/tutorial/mac-app-store-submission-guide/) (also known as `mas`)<sup>*</sup>\n* Linux (for both x86/x86_64)\n\n<sup>*</sup> *Note for OS X / MAS target bundles: the `.app` bundle can only be signed when building on a host OS X platform.*\n\n## Installation\n\nThis module requires Node.js 4.0 or higher to run.\n\n```sh\n# for use in npm scripts\nnpm install electron-packager --save-dev\n\n# for use from cli\nnpm install electron-packager -g\n```\n\n## Usage\n\n### From the Command Line\n\nRunning electron-packager from the command line has this basic form:\n\n```\nelectron-packager <sourcedir> <appname> --platform=<platform> --arch=<arch> [optional flags...]\n```\n\nThis will:\n\n- Find or download the correct release of Electron\n- Use that version of Electron to create a app in `<out>/<appname>-<platform>-<arch>` *(this can be customized via an optional flag)*\n\nFor details on the optional flags, run `electron-packager --help` or see [usage.txt](https://github.com/electron-userland/electron-packager/blob/master/usage.txt).\n\nIf `appname` is omitted, this will use the name specified by \"productName\" or \"name\" in the nearest package.json.\n\nYou should be able to launch the app on the platform you built for. If not, check your settings and try again.\n\n**Be careful** not to include `node_modules` you don't want into your final app. `electron-packager`, `electron-prebuilt` and `.git` will be ignored by default. You can use `--ignore` to ignore files and folders via a regular expression. For example, `--ignore=node_modules/package-to-ignore` or `--ignore=\"node_modules/(some-package[0-9]*|dev-dependency)\"`.\n\n#### Example\n\nLet's assume that you have made an app based on the [electron-quick-start](https://github.com/electron/electron-quick-start) repository on a OS X or Linux host platform with the following file structure:\n\n```\nfoobar\n\u251c\u2500package.json\n\u251c\u2500index.html\n\u251c[\u2026other files, like LICENSE\u2026]\n\u2514\u2500script.js\n```\n\n\u2026and that the following is true:\n\n* `electron-packager` is installed globally\n* `productName` in `package.json` has been set to `Foo Bar`\n* `npm install` for the `Foo Bar` app has been run at least once\n\nWhen one runs the following command for the first time in the `foobar` directory:\n\n```\nelectron-packager . --all\n```\n\n`electron-packager` will do the following:\n\n* Use the current directory for the `sourcedir`\n* Infer the `appname` from the `productName` in `package.json`\n* Download [all supported target platforms and arches](#supported-platforms) of Electron using the installed `electron-prebuilt` version (and cache the downloads in `~/.electron`)\n* For the `darwin` build, as an example:\n  * build the OS X `Foo Bar.app`\n  * place `Foo Bar.app` in `foobar/Foo Bar-darwin-x64/` (since an `out` directory was not specified, it used the current working directory)\n\nThe file structure now looks like:\n\n```\nfoobar\n\u251c\u252cFoo Bar-darwin-x64\n\u2502\u251c\u252cFoo Bar.app\n\u2502\u2502\u2514[\u2026Mac app contents\u2026]\n\u2502\u251c\u2500LICENSE\n\u2502\u2514\u2500version\n\u251c[\u2026other application bundles, like \"Foo Bar-win32-x64\" (sans quotes)\u2026]\n\u251c\u2500package.json\n\u251c\u2500index.html\n\u251c[\u2026other files, like LICENSE\u2026]\n\u2514\u2500script.js\n```\n\nThe `Foo Bar.app` folder generated can be executed by a system running OS X, which will start the packaged Electron app. This is also true of the Windows x64 build on a system running a new enough version of Windows for a 64-bit system (via `Foo Bar-win32-x64/Foo Bar.exe`), and so on.\n\n### [Programmatic API](https://github.com/electron-userland/electron-packager/blob/master/docs/api.md)\n\n## Building Windows apps from non-Windows platforms\n\nBuilding an Electron app for the Windows platform with a custom icon requires editing the `Electron.exe` file. Currently, electron-packager uses [node-rcedit](https://github.com/atom/node-rcedit) to accomplish this. A Windows executable is bundled in that node package and needs to be run in order for this functionality to work, so on non-Windows host platforms, [Wine](https://www.winehq.org/) needs to be installed. On OS X, it is installable via [Homebrew](http://brew.sh/).\n\n## Related\n\n- [electron-builder](https://www.npmjs.com/package/electron-builder) - for creating installer wizards\n- [grunt-electron](https://github.com/sindresorhus/grunt-electron) - grunt plugin for electron-packager\n- [electron-packager-interactive](https://github.com/Urucas/electron-packager-interactive) - an interactive CLI for electron-packager\n", "release_dates": []}, {"name": "electron-prebuilt", "description": "Install atom-shell prebuilts using npm", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# electron-prebuilt\n\n[![build status](http://img.shields.io/travis/mafintosh/electron-prebuilt.svg?style=flat)](http://travis-ci.org/mafintosh/electron-prebuilt)\n[![dat](http://img.shields.io/badge/Development%20sponsored%20by-dat-green.svg?style=flat)](http://dat-data.com/)\n\n![badge](https://nodei.co/npm/electron-prebuilt.png?downloads=true)\n\nInstall [electron](https://github.com/atom/electron) prebuilt binaries for command-line use using npm. This module helps you easily install the `electron` command for use on the command line without having to compile anything.\n\nElectron is a JavaScript runtime that bundles Node.js and Chromium. You use it similar to the `node` command on the command line for executing JavaScript programs. For more info you can read [this intro blog post](http://maxogden.com/electron-fundamentals.html) or dive into the [Electron documentation](https://github.com/atom/electron/tree/master/docs)\n\n## Installation\n\nDownload and install the latest build of electron for your OS and add it to your projects `package.json` as a `devDependency`:\n\n```\nnpm install electron-prebuilt --save-dev\n```\n\nThis is the preferred way to use electron, as it doesn't require users to install electron globally.\n\nYou can also use the `-g` flag (global) to symlink it into your PATH:\n\n```\nnpm install -g electron-prebuilt\n```\n\nIf that command fails with an `EACCESS` error you may have to run it again with `sudo`:\n\n```\nsudo npm install -g electron-prebuilt\n```\n\nNow you can just run `electron` to run electron:\n\n```\nelectron\n```\n\nIf you need to use an HTTP proxy you can [set these environment variables](https://github.com/request/request/tree/f0c4ec061141051988d1216c24936ad2e7d5c45d#controlling-proxy-behaviour-using-environment-variables)\n\nIf you want to change the architecture that is downloaded (e.g., `ia32` on an `x64` machine), you can use the `--arch` flag with npm install or set the `npm_config_arch` environment variable:\n```\nnpm install --arch=ia32 electron-prebuilt\n```\n\n## About\n\nWorks on Mac, Windows and Linux OSes that Electron supports (e.g. Electron [does not support Windows XP](https://github.com/atom/electron/issues/691)).\n\nThe version numbers of this module match the version number of the [offical Electron releases](https://github.com/atom/electron/releases), which do not follow [semantic versioning](http://semver.org/).\n\nThis module is automatically released whenever a new version of Electron is released thanks to [electron-prebuilt-updater](https://github.com/johnmuhl/electron-prebuilt-updater) written by [John Muhl](https://github.com/johnmuhl/).\n\n## Usage\n\nFirst you have to [write an electron application](https://github.com/atom/electron/blob/master/docs/tutorial/quick-start.md)\n\nThen you can run your app using:\n\n```\nelectron your-app/\n```\n\n## Related modules\n\n- [electron-packager](https://github.com/maxogden/electron-packager) - package and distribute your electron app in OS executables (.app, .exe etc)\n- [electron-builder](https://github.com/loopline-systems/electron-builder) - create installers for Windows and OS X. It's built to work together with electron-packager\n- [menubar](https://github.com/maxogden/menubar) - high level way to create menubar desktop applications with electron\n\nFind more at the [awesome-electron](https://github.com/sindresorhus/awesome-electron) list\n\n## Programmatic usage\n\nMost people use this from the command line, but if you require `electron-prebuilt` inside your node app it will return the file path to the binary.\nUse this to spawn electron from node scripts.\n\n``` js\nvar electron = require('electron-prebuilt')\nvar proc = require('child_process')\n\n// will something similar to print /Users/maf/.../Electron\nconsole.log(electron)\n\n// spawn electron\nvar child = proc.spawn(electron)\n```\n", "release_dates": ["2016-09-03T06:53:56Z"]}, {"name": "electron-squirrel-startup", "description": "Default Squirrel.Windows event handler for your Electron apps.", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# electron-squirrel-startup [![travis][travis_img]][travis_url] [![npm][npm_img]][npm_url] [![appveyor][appveyor_img]][appveyor_url]\n\n> Default [Squirrel.Windows][squirrel] event handler for your [Electron][electron] apps.\n\n## Installation\n\n```\nnpm i electron-squirrel-startup\n```\n\n## Usage\n\nTo handle the most common commands, such as managing desktop shortcuts, just\nadd the following to the top of your `main.js` and you're good to go:\n\n```js\nif(require('electron-squirrel-startup')) return;\n```\n\n## Read More\n\n### [Handling Squirrel Events][squirrel-events]\n### [Squirrel.Windows Commands][squirrel-commands]\n\n## License\n\nApache 2.0\n\n[squirrel]: https://github.com/Squirrel/Squirrel.Windows\n[electron]: https://github.com/atom/electron\n[squirrel-commands]: https://github.com/Squirrel/Squirrel.Windows/blob/master/src/Update/Program.cs#L98\n[squirrel-events]: https://github.com/atom/grunt-electron-installer#handling-squirrel-events\n[appveyor_img]: https://ci.appveyor.com/api/projects/status/jljyvooqy91gbo7y?svg=true\n[appveyor_url]: https://ci.appveyor.com/project/imlucas/electron-squirrel-startup\n[travis_img]: https://img.shields.io/travis/mongodb-js/electron-squirrel-startup.svg\n[travis_url]: https://travis-ci.org/mongodb-js/electron-squirrel-startup\n[npm_img]: https://img.shields.io/npm/v/electron-squirrel-startup.svg\n[npm_url]: https://npmjs.org/package/electron-squirrel-startup\n", "release_dates": []}, {"name": "eotk", "description": "Enterprise Onion Toolkit", "language": "Awk", "license": {"key": "gpl-3.0", "name": "GNU General Public License v3.0", "spdx_id": "GPL-3.0", "url": "https://api.github.com/licenses/gpl-3.0", "node_id": "MDc6TGljZW5zZTk="}, "readme": "Fork notes:  \n* Prebuilt releases need to be run from /opt/eotk\n\n---\n\n# The Enterprise Onion Toolkit\n![banner image](docs.d/hello-onion-text.png)\n\n## :warning: Important HTTPS-related Annoucement: March 2022 :warning:\n\nI've landed a small breaking change in order to better-support HARICA as a certificate provider,\nbut also for better usability; this change impacts any project with a multi-onion\nEV certificate from Digicert.\n\n* v3 onion addresses used in pathnames are now truncated at 20 chars\n  of onion, rather than 30 overall, to make shorter pathnames for unix\n  domain sockets\n* onion scratch-directory name changes:\n  * was: `projects.d/tweep.d/abcdefghijklmnopqrstuvwxyza-v3.d/port-80.sock`\n  * now: `projects.d/tweep.d/abcdefghijklmnopqrst-v3.d/port-80.sock`\n  * :warning: this means that some scratch directories may be are remade, \n    so a full restart is advisable after updating\n* https certificate path-name changes\n  * was: HTTPS certificate files used the full onion address\n  * now: onion HTTPS certificates are now expected to be installed in\n    per-onion-truncated-at-20 pathnames: e.g. for each ONIONADDRESS in\n    PROJECTNAME:\n    * `/projects.d/PROJECTNAME.d/ssl.d/ONIONADDRFIRST20CHAR-v3.onion.cert`\n    * `/projects.d/PROJECTNAME.d/ssl.d/ONIONADDRFIRST20CHAR-v3.onion.pem`\n  * :warning: this means that you will need to rename pre-existing certificate \n    `cert` and `pem` files after you update and reconfigure; \n  * :warning: **if you fail to do this you will experience \"self-signed certificate\" warnings**\n* if you are using 'multi' certificates (such as some Digicert EV) where a\n  single certificate contains all SubjectAltNames for 2+ onion\n  addresses that are part of a single project:\n  * :warning: do `set ssl_cert_each_onion 0` in the configuration, to re-enable\n    multi cert handling\n  * :warning: the names of the certificate files must be changed:\n    * was: filenames used to be\n      `projects.d/PROJECTNAME.d/ssl.d/PRIMARYONIONADDRESSWASHERE.{pem,cert}`\n    * now: multi-certificates now must be named with the more meaningful\n      `projects.d/PROJECTNAME.d/ssl.d/PROJECTNAME.{pem,cert}`\n\nIf you have any issues, please reach out to @alecmuffett on Twitter, or log an issue above.\n\n## Primary Supported Platforms\n\n* Ubuntu 20.04LTS, Latest Updates\n* OSX Mojave with Homebrew, Latest Updates\n* Raspbian Stretch/Stretch-Lite, Latest Updates\n\n## Maillist / Group\n\nGeneral discussion mailllist: deployment, tweaks and tuning:\n\n* mailto:eotk-users+subscribe@googlegroups.com (via email)\n* https://groups.google.com/group/eotk-users/subscribe (via web)\n\nNB: bugs should be reported through `Issues`, above.\n\n### EOTK In the News\n\n* Apr 2021 [The Intercept launches onionsite using EOTK](https://theintercept.com/2021/04/28/tor-browser-onion/)\n* Oct 2020 [Brave browser launches onionsite using EOTK](https://brave.com/new-onion-service/)\n* Oct 2019 [BBC News launches 'dark web' Tor mirror](https://www.bbc.co.uk/news/technology-50150981)\n* Oct 2019 [BBC launches dark web news site in bid to dodge censors](https://www.cityam.com/bbc-launches-dark-web-news-site-in-bid-to-dodge-censors/)\n* Oct 2019 [Tor blimey, Auntie! BBC launches dedicated dark web mirror site](https://www.theregister.co.uk/2019/10/24/beeb_launches_dedicated_dark_web_site/)\n* Oct 2019 [BBC News heads to the dark web with new Tor mirror\n](https://www.theverge.com/2019/10/24/20930085/bbc-news-dark-web-tor-the-onion-browser-secure-censorship)\n* Jan 2018 [Volunteer Spotlight: Alec Helps Companies Activate Onion Services\n](https://blog.torproject.org/volunteer-spotlight-alec-helps-companies-activate-onion-services)\n* Nov 2017 [Un service Wikipedia pour le Dark Web a \u00e9t\u00e9 lanc\u00e9 par un ing\u00e9nieur en s\u00e9curit\u00e9](https://www.developpez.com/actu/175523/Un-service-Wikipedia-pour-le-Dark-Web-a-ete-lance-par-un-ingenieur-en-securite-afin-de-contourner-la-censure-dans-certains-pays/)\n* Nov 2017 [\u0394\u03b7\u03bc\u03b9\u03bf\u03c5\u03c1\u03b3\u03ae\u03b8\u03b7\u03ba\u03b5 \u03c3\u03ba\u03bf\u03c4\u03b5\u03b9\u03bd\u03ae \u03ad\u03ba\u03b4\u03bf\u03c3\u03b7 \u03c4\u03b7\u03c2 \u0392\u03b9\u03ba\u03b9\u03c0\u03b1\u03af\u03b4\u03b5\u03b9\u03b1\u03c2 \u03b3\u03b9\u03b1 \u03b1\u03bd\u03b8\u03c1\u03ce\u03c0\u03bf\u03c5\u03c2 \u03c3\u03b5 \u03bb\u03bf\u03b3\u03bf\u03ba\u03c1\u03b9\u03bc\u03ad\u03bd\u03b1 \u03ba\u03b1\u03b8\u03b5\u03c3\u03c4\u03ce\u03c4\u03b1](https://texnologia.net/dhmiourgithike-skoteinh-ekdosh-ths-wikipedia-gia-anthropous-se-logokrimena-kathestota/2017/11)\n* Nov 2017 [A security expert built an unofficial Wikipedia for the dark web](https://www.engadget.com/2017/11/25/a-security-expert-built-an-unofficial-wikipedia-for-the-dark-web/)\n* Nov 2017 [There\u2019s Now a Dark Web Version of Wikipedia](https://motherboard.vice.com/en_us/article/7x4g4b/theres-now-a-dark-web-version-of-wikipedia-tor-alec-muffett)\n* Oct 2017 [The New York Times is Now Available as a Tor Onion Service](https://open.nytimes.com/https-open-nytimes-com-the-new-york-times-as-a-tor-onion-service-e0d0b67b7482)\n* Apr 2017 [This Company Will Create Your Own Tor Hidden Service](https://motherboard.vice.com/en_us/article/this-company-will-create-your-own-tor-hidden-service)\n* Feb 2017 [New Tool Takes Mere Minutes to Create Dark Web Version of Any Site](https://motherboard.vice.com/en_us/article/new-tool-takes-mere-minutes-to-create-dark-web-version-of-any-site)\n\n## Introduction\n\nEOTK provides a tool for deploying HTTP and HTTPS onion sites to\nprovide official onion-networking presences for popular websites.\n\nThe result is essentially a \"man in the middle\" proxy; you should set\nthem up only for your own sites, or for sites which do not require\nlogin credentials of any kind.\n\n## Installation\n\nPlease refer to the [How To Install](docs.d/HOW-TO-INSTALL.md) guide,\nand the other documents in [that folder](docs.d/).\n\n## Help I'm Stuck!\n\nPing @alecmuffett on Twitter, or log an `Issue`, above.\n\n## Important Note About Anonymity\n\nThe presumed use-case of EOTK is that you have an already-public\nwebsite and you wish to give it a corresponding Onion address.\n\nA lot of people mistakenly believe that Tor Onion Networking is \"all\nabout anonymity\" - which is incorrect, since it also includes:\n\n* extra privacy\n* identity/surety of to whom you are connected\n* freedom from oversight/network surveillance\n* anti-blocking, and...\n* enhanced integrity/tamperproofing\n\n...none of which are the same as \"anonymity\", but all of which are\nvaluable qualities to add to communications.\n\nFurther: setting up an Onion address can provide less contention, more\nspeed & more bandwidth to people accessing your site than they would\nget by using Tor \"Exit Nodes\".\n\nIf you set up EOTK in its intended mode then your resulting site is\nalmost certainly not going to be anonymous; for one thing your brand\nname (etc) will likely be plastered all over it.\n\nIf you want to set up a server which includes anonymity **as well as**\nall of the aforementioned qualities, you [want to be reading an\nentirely different document,\ninstead](https://github.com/alecmuffett/the-onion-diaries/blob/master/basic-production-onion-server.md).\n\n## Acknowledgements\n\nEOTK stands largely on the experience of work I led at Facebook to\ncreate `www.facebookcorewwwi.onion`, but it owes a *huge* debt to\n[Mike Tigas](https://github.com/mtigas)'s work at ProPublica to put\ntheir site into Onionspace through using NGINX as a rewriting proxy --\nand that [he wrote the whole experience up in great\ndetail](https://www.propublica.org/nerds/item/a-more-secure-and-anonymous-propublica-using-tor-hidden-services)\nincluding [sample config\nfiles](https://gist.github.com/mtigas/9a7425dfdacda15790b2).\n\nReading this prodded me to learn about NGINX and then aim to shrink &\ngenericise the solution; so thanks, Mike!\n\nAlso, thanks go to Christopher Weatherhead for acting as a local NGINX\n*sounding board* :-)\n\nAnd back in history: Michal N\u00e1n\u00e1si, Matt Jones, Trevor Pottinger and\nthe rest of the FB-over-Tor team.  Hugs.\n", "release_dates": ["2024-02-21T16:22:55Z", "2024-02-21T02:05:31Z", "2023-11-10T13:02:45Z", "2023-07-06T14:19:55Z"]}, {"name": "eth-hd-keyring", "description": "A simple standard interface for an HD ethereum wallet.", "language": "JavaScript", "license": null, "readme": "# HD Keyring [![Build and test](https://github.com/brave/eth-hd-keyring/actions/workflows/action.yml/badge.svg)](https://github.com/brave/eth-hd-keyring/actions/workflows/action.yml)\n\nA simple JS class wrapped around [ethereumjs-wallet](https://github.com/ethereumjs/ethereumjs-wallet) designed to expose an interface common to many different signing strategies, to be used in a `KeyringController`, like is being used in [MetaMask](https://metamask.io/)\n\n## The Keyring Class Protocol\n\nOne of the goals of this class is to allow developers to easily add new signing strategies to MetaMask. We call these signing strategies Keyrings, because they can manage multiple keys.\n\n### Keyring.type\n\nA class property that returns a unique string describing the Keyring.\nThis is the only class property or method, the remaining methods are instance methods.\n\n### constructor( options )\n\nAs a Javascript class, your Keyring object will be used to instantiate new Keyring instances using the new keyword.  For example:\n\n```\nconst keyring = new YourKeyringClass(options);\n```\n\nThe constructor currently receives an options object that will be defined by your keyring-building UI, once the user has gone through the steps required for you to fully instantiate a new keyring.  For example, choosing a pattern for a vanity account, or entering a seed phrase.\n\nWe haven't defined the protocol for this account-generating UI yet, so for now please ensure your Keyring behaves nicely when not passed any options object.\n\n## Keyring Instance Methods\n\nAll below instance methods must return Promises to allow asynchronous resolution.\n\n### serialize()\n\nIn this method, you must return any JSON-serializable JavaScript object that you like. It will be encoded to a string, encrypted with the user's password, and stored to disk. This is the same object you will receive in the deserialize() method, so it should capture all the information you need to restore the Keyring's state.\n\n### deserialize( object )\n\nAs discussed above, the deserialize() method will be passed the JavaScript object that you returned when the serialize() method was called.\n\n### addAccounts( n = 1 )\n\nThe addAccounts(n) method is used to inform your keyring that the user wishes to create a new account. You should perform whatever internal steps are needed so that a call to serialize() will persist the new account, and then return an array of the new account addresses.\n\nThe method may be called with or without an argument, specifying the number of accounts to create. You should generally default to 1 per call.\n\n### getAccounts()\n\nWhen this method is called, you must return an array of hex-string addresses for the accounts that your Keyring is able to sign for.\n\n### signTransaction(address, transaction)\n\nThis method will receive a hex-prefixed, all-lowercase address string for the account you should sign the incoming transaction with.\n\nFor your convenience, the transaction is an instance of ethereumjs-tx, (https://github.com/ethereumjs/ethereumjs-tx) so signing can be as simple as:\n\n```\ntransaction.sign(privateKey)\n```\n\nYou must return a valid signed ethereumjs-tx (https://github.com/ethereumjs/ethereumjs-tx) object when complete, it can be the same transaction you received.\n\n### signMessage(address, data)\n\nThe `eth_sign` method will receive the incoming data, alread hashed, and must sign that hash, and then return the raw signed hash.\n\n### exportAccount(address)\n\nExports the specified account as a private key hex string.\n\n", "release_dates": []}, {"name": "eth-json-rpc-infura", "description": null, "language": "JavaScript", "license": null, "readme": "# eth-json-rpc-infura\n\n`json-rpc-engine` middleware for infura's REST endpoints.\n\n### usage as provider\n\n```js\nconst createInfuraProvider = require('eth-json-rpc-infura/src/createProvider')\nconst Ethjs = require('ethjs')\n\nconst provider = createInfuraProvider({ network: 'mainnet' })\nconst eth = new Ethjs(provider)\n```\n\n### usage as middleware\n\n```js\nconst createInfuraMiddleware = require('eth-json-rpc-infura')\nconst RpcEngine = require('json-rpc-engine')\n\nconst engine = new RpcEngine()\nengine.push(createInfuraMiddleware({ network: 'ropsten' }))\n```\n", "release_dates": []}, {"name": "eth-ledger-bridge-keyring", "description": "A wrapper around LedgerJS libraries, to support the KeyringController protocol used by MetaMask", "language": "JavaScript", "license": {"key": "isc", "name": "ISC License", "spdx_id": "ISC", "url": "https://api.github.com/licenses/isc", "node_id": "MDc6TGljZW5zZTEw"}, "readme": "eth-ledger-bridge-keyring [![CircleCI](https://circleci.com/gh/MetaMask/eth-ledger-bridge-keyring.svg?style=svg)](https://circleci.com/gh/MetaMask/eth-ledger-bridge-keyring)\n==================\n\nAn implementation of MetaMask's [Keyring interface](https://github.com/MetaMask/eth-simple-keyring#the-keyring-class-protocol), that uses a Ledger hardware wallet for all cryptographic operations.\n\nIn most regards, it works in the same way as\n[eth-hd-keyring](https://github.com/MetaMask/eth-hd-keyring), but using a Ledger\ndevice. However there are a number of differences:\n\n- Because the keys are stored in the device, operations that rely on the device\n  will fail if there is no Ledger device attached, or a different Ledger device\n  is attached.\n\n- It does not support the `signMessage`, `signTypedData` or `exportAccount`\n  methods, because Ledger devices do not support these operations.\n\n- Because extensions have limited access to browser features, there's no easy way to interact wth the Ledger Hardware wallet from the MetaMask extension. This library implements a workaround to those restrictions by injecting (on demand) an iframe to the background page of the extension, (which is hosted [here](https://metamask.github.io/eth-ledger-bridge-keyring/index.html).\n\nThe iframe is allowed to interact with the Ledger device (since U2F requires SSL and the iframe is hosted under https) using the libraries from [LedgerJS](https://github.com/LedgerHQ/ledgerjs) *hw-app-eth* and *hw-transport-u2f* and establishes a two-way communication channel with the extension via postMessage.\n\nThe iframe code it's hosted in the same repo under the branch [gh-pages](https://github.com/MetaMask/eth-ledger-bridge-keyring/tree/gh-pages) and it's being served via github pages. In the future we might move it under the metamask.io domain.\n\nUsage\n-----\n\nIn addition to all the known methods from the [Keyring class protocol](https://github.com/MetaMask/eth-simple-keyring#the-keyring-class-protocol),\nthere are a few others:\n\n\n- **isUnlocked** : Returns true if we have the public key in memory, which allows to generate the list of accounts at any time\n\n- **unlock** : Connects to the Ledger device and exports the extended public key, which is later used to read the available ethereum addresses inside the Ledger account.\n\n- **setAccountToUnlock** : the index of the account that you want to unlock in order to use with the signTransaction and signPersonalMessage methods\n\n- **getFirstPage** : returns the first ordered set of accounts from the Ledger account\n\n- **getNextPage** : returns the next ordered set of accounts from the Ledger account based on the current page\n\n- **getPreviousPage** : returns the previous ordered set of accounts from the Ledger account based on the current page\n\n- **forgetDevice** : removes all the device info from memory so the next interaction with the keyring will prompt the user to connect the Ledger device and export the account information\n\nTesting\n-------\nRun the following command:\n\n```bash\nyarn test\n```\n\n\n\nAttributions\n-------\nThis code was inspired by [eth-ledger-keyring](https://github.com/jamespic/eth-ledger-keyring) and [eth-hd-keyring](https://github.com/MetaMask/eth-hd-keyring)\n", "release_dates": []}, {"name": "eth-token-tracker", "description": "A JS module for tracking Ethereum token balances over block changes", "language": "JavaScript", "license": {"key": "isc", "name": "ISC License", "spdx_id": "ISC", "url": "https://api.github.com/licenses/isc", "node_id": "MDc6TGljZW5zZTEw"}, "readme": "# Eth Token Tracker [![CircleCI](https://circleci.com/gh/MetaMask/eth-token-tracker/tree/master.svg?style=svg)](https://circleci.com/gh/MetaMask/eth-token-tracker/tree/master)\n\nA JS module for tracking Ethereum tokens and their values over time.\n\n## Installation\n\n`npm install '@metamask/eth-token-tracker'`\n\n## Usage\n\n```javascript\nconst TokenTracker = require('@metamask/eth-token-tracker')\n\nvar tokenTracker = new TokenTracker({\n\n  userAddress: addresses[0], // whose balance to track\n  provider,                  // a web3-style provider\n  pollingInterval: 4000,     // block polling interval (optional)\n\n  // Tell it about the tokens to track:\n  tokens: [\n    {\n      address: tokenAddress,\n    }\n  ],\n})\n\n// You can use this method to check the state of the tokens\nvar balances = tokenTracker.serialize()\n\n// You can also subscribe to updates\ntokenTracker.on('update', function (balances) {\n  console.log(`Your balance of ${balances[0].symbol} is ${balances[0].string}`)\n})\n\n// You can add additional tokens after initialization:\ntokenTracker.add({ address: otherTokenAddress })\n\n// Make sure to clean up, or it will hold a reference:\ntokenTracker.stop()\n```\n\n", "release_dates": []}, {"name": "ethereum-remote-client", "description": "Integrated customization of MetaMask for use in Brave", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Brave Ethereum Remote Client Extension\n\nEthereum Remote Client is the extension which powers Brave's Crypto Wallets.  It was originally a fork of MetaMask but will be diverging significantly over time.\n\nBrave's Ethereum Remote Client is a Chromium extension for interacting with the Ethereum blockchain. It supports transfering ether, working with assets (ERC20 & ERC223, ERC721, ERC1155), and running Dapps. This extension is only meant to be used within Brave.\n\n## Building locally\n\n- Install [Node.js](https://nodejs.org) version 12\n    - If you are using [nvm](https://github.com/creationix/nvm#installation) (recommended) running `nvm use` will automatically choose the right node version for you.\n- Install [Yarn](https://yarnpkg.com/en/docs/install)\n- Install dependencies: `yarn`\n- Build the project to the `./dist/` folder with `yarn dist`.\n- Optionally, to start a development build (e.g. with logging and file watching) run `yarn start` instead.\n    - To start the [React DevTools](https://github.com/facebook/react-devtools) and [Redux DevTools Extension](http://extension.remotedev.io)\n      alongside the app, use `yarn start:dev`.\n      - React DevTools will open in a separate window; no browser extension is required\n      - Redux DevTools will need to be installed as a browser extension. Open the Redux Remote Devtools to access Redux state logs. This can be done by either right clicking within the web browser to bring up the context menu, expanding the Redux DevTools panel and clicking Open Remote DevTools OR clicking the Redux DevTools extension icon and clicking Open Remote DevTools.\n        - You will also need to check the \"Use custom (local) server\" checkbox in the Remote DevTools Settings, using the default server configuration (host `localhost`, port `8000`, secure connection checkbox unchecked)\n\nUncompressed builds can be found in `/dist`, compressed builds can be found in `/builds` once they're built.\n\n## Contributing\n\n### Running Tests\n\nRun tests with `yarn test`.\n\nYou can also test with a continuously watching process, via `yarn watch`.\n\nYou can run the linter by itself with `yarn lint`.\n\n## Architecture\n\n[![Architecture Diagram](./docs/architecture.png)][1]\n\n## Development\n\n```bash\nyarn install\nyarn dev:brave\n```\n\n## Build for Publishing\n\n```bash\nyarn install\nyarn run dist:brave\n```\n\n## Publish to npm\n```bash\nnpm install\nnpm run publish:brave\n```\n\n## Other Docs\n\n- [How to add custom build to Chrome](./docs/add-to-chrome.md)\n- [How to add custom build to Firefox](./docs/add-to-firefox.md)\n- [How to add a new translation](./docs/translating-guide.md)\n- [Publishing Guide](./docs/publishing.md)\n- [How to use the TREZOR emulator](./docs/trezor-emulator.md)\n- [How to generate a visualization of this repository's development](./development/gource-viz.sh)\n\n[1]: http://www.nomnoml.com/#view/%5B%3Cactor%3Euser%5D%0A%0A%5Bmetamask-ui%7C%0A%20%20%20%5Btools%7C%0A%20%20%20%20%20react%0A%20%20%20%20%20redux%0A%20%20%20%20%20thunk%0A%20%20%20%20%20ethUtils%0A%20%20%20%20%20jazzicon%0A%20%20%20%5D%0A%20%20%20%5Bcomponents%7C%0A%20%20%20%20%20app%0A%20%20%20%20%20account-detail%0A%20%20%20%20%20accounts%0A%20%20%20%20%20locked-screen%0A%20%20%20%20%20restore-vault%0A%20%20%20%20%20identicon%0A%20%20%20%20%20config%0A%20%20%20%20%20info%0A%20%20%20%5D%0A%20%20%20%5Breducers%7C%0A%20%20%20%20%20app%0A%20%20%20%20%20metamask%0A%20%20%20%20%20identities%0A%20%20%20%5D%0A%20%20%20%5Bactions%7C%0A%20%20%20%20%20%5BbackgroundConnection%5D%0A%20%20%20%5D%0A%20%20%20%5Bcomponents%5D%3A-%3E%5Bactions%5D%0A%20%20%20%5Bactions%5D%3A-%3E%5Breducers%5D%0A%20%20%20%5Breducers%5D%3A-%3E%5Bcomponents%5D%0A%5D%0A%0A%5Bweb%20dapp%7C%0A%20%20%5Bui%20code%5D%0A%20%20%5Bweb3%5D%0A%20%20%5Bmetamask-inpage%5D%0A%20%20%0A%20%20%5B%3Cactor%3Eui%20developer%5D%0A%20%20%5Bui%20developer%5D-%3E%5Bui%20code%5D%0A%20%20%5Bui%20code%5D%3C-%3E%5Bweb3%5D%0A%20%20%5Bweb3%5D%3C-%3E%5Bmetamask-inpage%5D%0A%5D%0A%0A%5Bmetamask-background%7C%0A%20%20%5Bprovider-engine%5D%0A%20%20%5Bhooked%20wallet%20subprovider%5D%0A%20%20%5Bid%20store%5D%0A%20%20%0A%20%20%5Bprovider-engine%5D%3C-%3E%5Bhooked%20wallet%20subprovider%5D%0A%20%20%5Bhooked%20wallet%20subprovider%5D%3C-%3E%5Bid%20store%5D%0A%20%20%5Bconfig%20manager%7C%0A%20%20%20%20%5Brpc%20configuration%5D%0A%20%20%20%20%5Bencrypted%20keys%5D%0A%20%20%20%20%5Bwallet%20nicknames%5D%0A%20%20%5D%0A%20%20%0A%20%20%5Bprovider-engine%5D%3C-%5Bconfig%20manager%5D%0A%20%20%5Bid%20store%5D%3C-%3E%5Bconfig%20manager%5D%0A%5D%0A%0A%5Buser%5D%3C-%3E%5Bmetamask-ui%5D%0A%0A%5Buser%5D%3C%3A--%3A%3E%5Bweb%20dapp%5D%0A%0A%5Bmetamask-contentscript%7C%0A%20%20%5Bplugin%20restart%20detector%5D%0A%20%20%5Brpc%20passthrough%5D%0A%5D%0A%0A%5Brpc%20%7C%0A%20%20%5Bethereum%20blockchain%20%7C%0A%20%20%20%20%5Bcontracts%5D%0A%20%20%20%20%5Baccounts%5D%0A%20%20%5D%0A%5D%0A%0A%5Bweb%20dapp%5D%3C%3A--%3A%3E%5Bmetamask-contentscript%5D%0A%5Bmetamask-contentscript%5D%3C-%3E%5Bmetamask-background%5D%0A%5Bmetamask-background%5D%3C-%3E%5Bmetamask-ui%5D%0A%5Bmetamask-background%5D%3C-%3E%5Brpc%5D%0A\n", "release_dates": ["2021-10-13T17:35:48Z", "2021-09-16T17:44:49Z", "2021-09-13T14:27:17Z", "2021-09-09T15:28:29Z", "2021-09-03T00:45:43Z", "2021-08-30T15:55:33Z", "2021-08-10T20:27:49Z", "2021-07-15T22:43:19Z", "2021-07-08T15:42:53Z", "2021-07-07T01:44:33Z", "2021-07-01T18:57:31Z", "2021-06-25T14:13:54Z", "2021-06-10T20:14:22Z", "2021-03-18T18:51:12Z", "2021-03-05T04:33:51Z", "2021-02-10T18:28:46Z", "2021-02-08T23:03:20Z", "2021-01-24T20:05:06Z", "2020-12-28T04:17:53Z", "2020-12-16T22:22:39Z", "2020-11-24T00:57:59Z", "2020-10-23T18:11:46Z", "2020-10-13T18:37:51Z", "2020-09-24T20:11:20Z", "2020-09-14T18:07:21Z", "2020-09-11T03:33:30Z", "2020-08-24T20:37:13Z", "2020-08-24T17:46:02Z", "2020-08-24T01:11:11Z", "2020-08-23T01:46:35Z"]}, {"name": "extension-whitelist", "description": null, "language": "C++", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# extension-whitelist\n\nC++ extension whitelist and blacklist parser for Brave\n\nExtensions on the blacklist can not be installed by the user. Extensions on the whitelist may be installed normally. All other extensions may also be installed normally, but Brave will warn that \"Brave has not reviewed this extension yet\" (or similar wording).\n\nYou can view both lists in the [`whitelist.json`](https://github.com/brave/extension-whitelist/blob/master/data/whitelist.json) file.\n\nThe rest of this README is for Brave developers who need to work with this code, or any developer who wants to use it in their own project.\n\n## Installation\n\n1. Clone the git repository from GitHub:\n\n        git clone https://github.com/brave/extension-whitelist\n\n2. Open the working directory:\n\n        cd extension-whitelist\n\n3. Install the Node (v5+) dependencies:\n\n        npm install\n\n## Build the node addon\n\n```\nnpm run install\n```\n\n## Generate the DAT file\n\n```\nnpm run data-files\n```\n\n## Running tests\n\n```\nnpm run test\n```\n\n## Trigger a CI build\n\nThe `brave-core-ext-local-data-files-update-publish` in CI polls the [`brave/brave-core-crx-packager` repository](https://github.com/brave/brave-core-crx-packager) once a day and makes a new build of the *Brave Local Data Updater* component if there are any new commits on `master`. A build can also be started manually there.\n\nRenovate is supposed to be watching all dependent repositories (such as `brave/extension-whitelist`) for changes and to propose a PR on `brave/brave-core-crx-packager` to update `package-lock.json` (and `package.json` as needed) when one of the dependencies needs to be updated. If that doesn't happen for some reason, a manual PR can be created and merged. See https://github.com/brave/brave-core-crx-packager/pull/316 for an example.\n", "release_dates": []}, {"name": "eyeshade", "description": "Deprecated, please see", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# NOTE: This repo is deprecated, please see [bat-ledger](https://github.com/brave-intl/bat-ledger)\n# Brave Eyeshade\n** NB: this repository is still undergoing active functional development.**\n\nThe Brave Eyeshade is the back-end accountant for the\n[Brave Ledger](https://github.com/brave/ledger/tree/master/documentation/Ledger-Principles.md).\n\nNote that [travis-ci](https://travis-ci.org/brave/eyeshade) is not yet operational for this repository.\n\n# Initialization\nTake a look at the files in the `config/` directory.\nWhen the server starts,\nit will look file a file called `config/config.{PROFILE}.js` where `{PROFILE}` is `$NODE_ENV` (defaulting to `\"development\"`).\n\nAuthentication is achieved via a GitHub [OAuth application](https://github.com/settings/developers).\nCreate a developer application with an authorization callback of the form `https://{DOMAIN:PORT}/v1/login` and update the\n`login.clientId` and `login.clientSecret` properties.\n\nAuthorization is achieved by verifying that the user is a member of a GitHub organization, i.e.,\n`https://github.com/orgs/{ORGANIZATION}/teams`.\nSet the `login.organization` property to the name of the organization.\n\nNow start the server with `npm start` and `https://{DOMAIN:PORT}/v1/login` which will start the authentication/authorization\nprocess.\nOn success,\nyou will be redirected to `https://{DOMAIN:PORT}/documentation`.\n\n# Setup\nClone the repo: `git clone git@github.com:brave/eyeshade.git`\n\nInstall dependencies with `npm install`\n\nInstall MongoDB: `brew update && brew install mongodb`\n\nStart MongoDB. There are a variety of ways to do this, one option on a mac: `brew tap homebrew/services && brew services start mongodb`\n\nInstall Redis: `brew update && brew install redis`\n\nStart Redis. There are a variety of ways to do this, one option on a mac: `brew tap homebrew/services && brew services start redis`\n\n## StandardJS\n\nFor linting we use [StandardJS](https://github.com/feross/standard). It's recommended that you install the necessary IDE plugin. Since this repo uses ES7 features, you'll need a global install of both the standard and babel-eslint packages.\n\n## Configuration\n\nFor staging or production environments configuration variables are stored as environment preferences. See config/config.production.js for a list of these variables.\n\nFor local development you can copy config/config.development.js.tpl to config/config.development.js and define the local config variables.\n\n## Running the server\n\nUse `gulp` to run the server in development. This also sets up watchers and will restart the server on a file change.\n\n## Proximo\n\nProximo is currently used as a proxy so we can make outbound BitGo requests using a static IP. \nPlease define `process.env.BITGO_USE_PROXY` as appropriate.\n", "release_dates": []}, {"name": "FFmpeg", "description": "mirror of git://source.ffmpeg.org/ffmpeg.git", "language": "C", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "FFmpeg README\n=============\n\nFFmpeg is a collection of libraries and tools to process multimedia content\nsuch as audio, video, subtitles and related metadata.\n\n## Libraries\n\n* `libavcodec` provides implementation of a wider range of codecs.\n* `libavformat` implements streaming protocols, container formats and basic I/O access.\n* `libavutil` includes hashers, decompressors and miscellaneous utility functions.\n* `libavfilter` provides a mean to alter decoded Audio and Video through chain of filters.\n* `libavdevice` provides an abstraction to access capture and playback devices.\n* `libswresample` implements audio mixing and resampling routines.\n* `libswscale` implements color conversion and scaling routines.\n\n## Tools\n\n* [ffmpeg](https://ffmpeg.org/ffmpeg.html) is a command line toolbox to\n  manipulate, convert and stream multimedia content.\n* [ffplay](https://ffmpeg.org/ffplay.html) is a minimalistic multimedia player.\n* [ffprobe](https://ffmpeg.org/ffprobe.html) is a simple analysis tool to inspect\n  multimedia content.\n* [ffserver](https://ffmpeg.org/ffserver.html) is a multimedia streaming server\n  for live broadcasts.\n* Additional small tools such as `aviocat`, `ismindex` and `qt-faststart`.\n\n## Documentation\n\nThe offline documentation is available in the **doc/** directory.\n\nThe online documentation is available in the main [website](https://ffmpeg.org)\nand in the [wiki](https://trac.ffmpeg.org).\n\n### Examples\n\nCoding examples are available in the **doc/examples** directory.\n\n## License\n\nFFmpeg codebase is mainly LGPL-licensed with optional components licensed under\nGPL. Please refer to the LICENSE file for detailed information.\n\n## Contributing\n\nPatches should be submitted to the ffmpeg-devel mailing list using\n`git format-patch` or `git send-email`. Github pull requests should be\navoided because they are not part of our review process. Few developers\nfollow pull requests so they will likely be ignored.\n", "release_dates": []}, {"name": "figma-api-exporter", "description": "Export assets from Figma API, sync your SVG files.", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Figma API Exporter\n\nAllows you to export assets from Figma files automatically and use it in your project.\n\n## Features:\n- download all components as SVGs from Figma file or Frame\n\n## Examples\n\n```js\nconst figmaApiExporter = require('figma-api-exporter').default;\n\nconst exporter = figmaApiExporter(YOUR_FIGMA_API_TOKEN);\n\nexporter\n  .getSvgs({\n    fileId: YOUR_FIGMA_FILE_ID,\n    canvas: 'Icons',\n  })\n  .then(svgsData =>\n    exporter.downloadSvgs({\n      saveDirectory: './svgsFiles',\n      svgsData: svgsData.svgs,\n      lastModified: svgsData.lastModified,\n    })\n  );\n```\n\n## API\n### getSvgs\nFunction which fetches urls of component exports as svgs.\n\nArguments:\n- fileId (required) (string) - id of figma files you want to extract svgs from\n- canvas (optional) (string|function) - filter exported components by Page name, you can use a custom filter function with additional information about page\n- component (optional) (string|function) - filter by exported components by Component name, you can use a custom filter function with additional information about component\n\n### downloadSvgs\nFunction which downloads svg files to your directory. It checks Figma File modification date and component ids to find out if your local copy is up to date before downloading everything. You can replace this function with your own script.\n\nArguments:\n- saveDirectory (required) (string) - path to save svg files\n- svgsData (required) (array) - '.svgs' values returned from `.getSvgs()`\n- lastModified (required) (string) - `.lastModified` value returned from `.getSvgs()`, used to check if Figma file was modified and it should continue downloading\n- clearDirectory (optional) (boolean) (defaults to: `false`) - change to `true` if you want to clear the `saveDirectory` before downloading files, it comes handy when you want to delete old icons, which don't exist in Figma anymore\n", "release_dates": []}, {"name": "format-chromium-histogram", "description": "NodeJS re-implementation of Chromium's C++ about://histograms rendering", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# format-chromium-histogram\n\nChromium-based browsers expose ASCII histogram visualizations through `about://histograms`, rendered by internal C++ code.\n\nThese histograms can also be [accessed](https://chromedevtools.github.io/devtools-protocol/tot/Browser/#method-getHistogram) through the Chrome DevTools Protocol, but only as a raw JSON structure.\nIt's difficult to visualize these, especially when compared to the graphs available on `about://histograms`.\n\nThis repository contains a simple NodeJS re-implementation of Chromium's C++ histogram rendering so that collected histogram data can be used for analysis outside of the browser.\n\n## Usage\n\nSee [`print-histogram.js`](/print-histogram.js) for sample usage.\n", "release_dates": []}, {"name": "git-secrets-unittest", "description": null, "language": "Python", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Testing git-secrets\n\nThis `unittest-git-secrets.py` script can easily validate both git-secrets and git pre-commit\nhook functions correctly.\n\nThis is intended to be cross platform, so it should work on Mac and Linux\nwithout any modification.\n\nNOTE: On Windows, this script works in WSL, but not on Powershell. This is\nbecause `git-secrets` is a bash script, and bash cannot run in Powershell. In\norder to use this script and `git-secrets` it must be run in WSL.\n\n## Prereqs\n\nYou must have the following prereqs configured:\n\n* Python 3.4 or above\n* The tool [git-secrets](https://github.com/awslabs/git-secrets) must be\n  installed and configured to recognize AWS patterns\n* You must setup a Git pre-commit hook to run during every commit operation\n  * To setup the pre-commit hook, add it to your local Git config variable\n    'init.templateDir' [with these\n    commands](https://github.com/awslabs/git-secrets#advanced-configuration),\n    which will add the hook to all future Git repositories. Read the `git init`\n    ([manpage](https://git-scm.com/docs/git-init#_template_directory)).\n    (PREFERRED METHOD)\n  * You can also use the Git config variable\n    ['core.hooksPath'](https://git-scm.com/docs/git-config#Documentation/git-config.txt-corehooksPath).\n\n## Running the Test\n\nTo execute the test script, run the command:\n\n```python3 unittest-git-secrets.py```\n\n### Successful output\n\n```\n$\u00a0python3 unittest-git-secrets.py\nCommand 'git commit -m 'test pre-commit hook'' return code: 1\nCommand output:\n test.txt:1:aws_secret_access_key = NOTAVALIDSECRETACCESSKEY\n\n[ERROR] Matched one or more prohibited patterns\n\nPossible mitigations:\n- Mark false positives as allowed using: git config --add secrets.allowed ...\n- Mark false positives as allowed by adding regular expressions to .gitallowed at repository's root directory\n- List your configured patterns: git config --get-all secrets.patterns\n- List your configured allowed patterns: git config --get-all secrets.allowed\n- List your configured allowed patterns in .gitallowed at repository's root directory\n- Use --no-verify if this is a one-time false positive\n\n.\n----------------------------------------------------------------------\nRan 1 test in 0.116s\n\nOK\n```\n\nWe use the Python Unittest framework, so the output will look like a unit test.\nIt should show `OK` on the last line, as above. It will have the string `[ERROR]\nMatched one or more prohibited patterns`, which means that `git-secrets`\nsuccesfully found a prohibited pattern, a scenario that we intentionally create\nwithin the script by creating a temporary Git repository. This output means that\n`git-secrets` worked as expected and you are ready to safely commit to GitHub\nrepositories.\n\n### Unsuccessful output\n\nIf the script does not work correctly, it will show output similar to below. It\nwill say that the test failed. This could mean that your git hook is not setup\nproperly, or `git-secrets` is not installed properly, or the script itself had\nan error.\n\n```\nF\n======================================================================\nFAIL: test_git_pre_commit_hook (__main__.Test_01_GitPreCommitHook)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"unittest-git-secrets.py\", line 175, in test_git_pre_commit_hook\n    self.assertTrue(self.g1.trigger_hook(self.outfile))\nAssertionError: False is not true\n\n----------------------------------------------------------------------\nRan 1 test in 0.146s\n\nFAILED (failures=1)\n```\n\nIf this occurs, please re-read the steps for installing both `git-secrets`, and\nyour git hooks in the [prereqs](#prereqs) section above to verify you have\nconfigured your environment properly.\n\n## Meta\n\nAuthor: [Matt Bacchi](mailto:mbacchi@brave.com)\n\nDistributed under the Mozilla Public License, v. 2.0. See ``LICENSE`` or\nhttp://mozilla.org/MPL/2.0/ for more information.\n\n## Contributing\n\n1. Create your branch (`git checkout -b fooBar`)\n2. Commit your changes (`git commit -am 'Add some fooBar'`)\n3. Push to the branch (`git push origin fooBar`)\n4. Create a new Pull Request\n", "release_dates": []}, {"name": "gn-project-generators", "description": null, "language": "Python", "license": {"key": "bsd-3-clause", "name": "BSD 3-Clause \"New\" or \"Revised\" License", "spdx_id": "BSD-3-Clause", "url": "https://api.github.com/licenses/bsd-3-clause", "node_id": "MDc6TGljZW5zZTU="}, "readme": "This repository contains experimental project generators for GN\n\n### xcode.py\n\nGenerates Xcode project from JSON file. Unlike original GN Xcode generator this one generates separate indexing target for each GN target, which means include directories, defines and precompiled headers should be set properly for every indexed source file.\n\nIt also uses Custom build tool for Product targets, so that Clean action from IDE should work as expected.\n\nUsage: `gn gen --ide=json --json-ide-script=<path-to>xcode.py out-dir`\n\n### msvc2015.py\n\nGenerates MSVC solution from JSON file. Uses CLCompile items for C/C++ files so that C files are properly indexed as C (they are indexed as C++ when being a custom build tool type resulting in false errors). Supports building single files (ctrl + F7), and PCH for intellisense.\n\nAlso synchronizes ninja invocations from MSVC on build folder, so that when visual studio tries building projects in parallel only one ninja instance is active at a time. \n\nShould work with both python 2.7 and 3.\n\nUsage: `gn gen --ide=json --json-ide-script=<path-to>msvc2015.py out-dir`\n\n### Remarks\n\nBoth MSVC and Xcode generator expose `.gn` and `.gni` files as well as relevant parts of the `/build` directory. For MSVC a textmate bundle is provided in `misc` directory to get syntax highlighting, for Xcode the project forces file type to perl, which seems to be good enough approximation for gn syntax\n", "release_dates": []}, {"name": "go-sync", "description": "Brave sync server v2", "language": "Go", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave Sync Server v2\n\nA sync server implemented in go to communicate with Brave sync clients using\n[components/sync/protocol/sync.proto](https://cs.chromium.org/chromium/src/components/sync/protocol/sync.proto).\nCurrent Chromium version for sync protocol buffer files used in this repo is Chromium 116.0.5845.183.\n\nThis server supports endpoints as bellow.\n- The `POST /v2/command/` endpoint handles Commit and GetUpdates requests from sync clients and return corresponding responses both in protobuf format. Detailed of requests and their corresponding responses are defined in `schema/protobuf/sync_pb/sync.proto`. Sync clients are responsible for generating valid access tokens and present them to the server in the Authorization header of requests.\n\nCurrently we use dynamoDB as the datastore, the schema could be found in `schema/dynamodb/table.json`.\n\n## Developer Setup\n1. [Install Go 1.18](https://golang.org/doc/install)\n2. [Install GolangCI-Lint](https://github.com/golangci/golangci-lint#install)\n3. [Install gowrap](https://github.com/hexdigest/gowrap#installation)\n4. Clone this repo\n5. [Install protobuf protocol compiler](https://github.com/protocolbuffers/protobuf#protocol-compiler-installation) if you need to compile protobuf files, which could be built using `make protobuf`.\n6. Build via `make`\n\n## Local development using Docker and DynamoDB Local\n1. Clone this repo\n2. Run `make docker`\n3. Run `make docker-up`\n4. For running unit tests, run `make docker-test`\n\n# Updating protocol definitions\n1. Copy the `.proto` files from `components/sync/protocol` in `chromium` to `schema/protobuf/sync_pb` in `go-sync`.\n2. Copy the `.proto` files from `components/sync/protocol` in `brave-core` to `schema/protobuf/sync_pb` in `go-sync`.\n3. Run `make repath-proto` to set correct import paths in `.proto` files.\n4. Run `make proto-go-module` to add the `go_module` option to `.proto` files.\n5. Run `make protobuf` to generate the Go code from `.proto` definitions.\n\n## Prometheus Instrumentation\nThe instrumented datastore and redis interfaces are generated, providing integration with Prometheus.  The following will re-generate the instrumented code, required when updating protocl definitions:\n\n```\nmake instrumented\n```\n\nChanges to `datastore/datastore.go` or `cache/cache.go` should be followed with the above command.\n", "release_dates": ["2023-09-18T15:07:56Z", "2023-09-07T22:17:42Z", "2022-01-11T00:07:52Z", "2022-01-05T23:17:10Z", "2021-12-02T23:12:45Z", "2021-11-02T23:29:51Z", "2021-06-22T02:22:47Z", "2021-06-14T20:47:52Z", "2021-05-25T18:02:27Z", "2021-03-03T21:17:10Z", "2021-02-03T05:58:38Z", "2021-01-15T23:32:40Z", "2020-10-08T21:10:54Z", "2020-09-02T20:37:55Z", "2020-09-01T22:51:19Z", "2020-07-17T00:30:25Z", "2020-06-29T21:02:43Z", "2020-06-16T15:27:52Z", "2020-06-11T19:49:32Z", "2020-06-10T17:28:45Z", "2020-06-05T22:17:48Z", "2020-06-05T21:46:52Z"]}, {"name": "go-sync-adm-tools", "description": null, "language": "Go", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "## Brave Sync Administration Tools\n\nThis repository contains a set of Brave Sync Administration tools for maintaining sync data in DynamoDB (currently).\n\n### Installation\n\nTo install the tools, check out the repo, and run the following:\n\n```\n   $ make all\n```\n\n### List of Tools\n\n`main`:  This tool sets an hour TTL on DynamoDB data that needs to be deleted.\n\n##### Usage\n\nIn order to use `main`, the user needs to have permissions to the DynamoDB in the given Sync account.  Typically this is ran by a member of the DevOps team.\nUsing the `devops-admin-rw-role`, a DevOps team member can set the TTL for a given client ID by running the following:\n```\n   $ export AWS_ENDPOINT=https://dynamodb.us-west-2.amazonaws.com\n   $ aws-vault exec sync-prod-devops-rw -- ./main delete 8XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX2\n     Deleting user data for clientID 8XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX2\n     Successfully set ttl for 1741 records\n```\n", "release_dates": []}, {"name": "go-translate", "description": "Translation adapter / relay server for Brave", "language": "Go", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Translation server for brave\n\n`go-translate` implements a translation server for use in brave-core written in Go.\nIt works on top of brave-hosted [Lingvanex On-premise Translation Server](https://lingvanex.com/translationserver/). It gets the requests from browsers in Chromium format,\nrewrites them to Lingvanex format, processes the requests and returns the result back in Chromium format.\n\nThe audience for this server is all desktop/android brave users.\n\nThe translation server supports 2 endpoints\n\n1) The `POST /translate_a/t` endpoint processes translate requests in Chromium format, sends corresponding requests to Lingvanex docker container, then returns responses in Chromium format back to the brave-core client.\n\n2) The `GET /translate_a/l` returns the languages supported by Lingvanex in Chromium format.\n\ngo-translate also hosts a few static resources needed for in-page translation.\n\n## Dependencies\n\n- Install Go 1.12 or later.\n- Dependencies are managed by go modules.\n- `go get -u github.com/golangci/golangci-lint/cmd/golangci-lint`\n\n## Setup\n\n```\ngit clone git@github.com:brave/go-translate.git\ncd ~/path-to/go-translate\nmake build\n```\n\n## Run lint:\n\n`make lint`\n\n## Run tests:\n\n`make test`\n\n## Build and run go-translate:\n\n`make build`\n\n## Local debugging\n\n- Generate TLS credentials:\n`openssl genrsa -out server.key 2048`\n`openssl ecparam -genkey -name secp384r1 -out server.key`\n`openssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650`\n\n- Replace `err := srv.ListenAndServe()` with `err := srv.ListenAndServeTLS(\"server.crt\", \"server.key\")` in `server/server.go`;\n\n- Set LNX_HOST (company VPN should be enabled):\n  `export LNX_HOST=http://translate-lnx-dev-a4b82554457afe1c.elb.us-west-2.amazonaws.com:8080/api`\n\n- Launch the local server: `make build`;\n\n- Launch the browser with switches:\n`--ignore-certificate-errors --translate-security-origin=https://127.0.0.1:8195/ --translate-script-url=https://127.0.0.1:8195/static/v1/element.js`.\n\n- Other switches can be added if necessary (for example `--enable-features=UseBraveTranslateGo:update-languages/true` );\n\n- Disable Shield on the tested sites (or globally), it cuts requests to localhost. `405 OPTIONS` errors also can be ignored;\n\n- If you have troubles check if you can reach https://127.0.0.1:8195/static/v1/element.js in the tested browser.\n", "release_dates": []}, {"name": "go-update", "description": "Component update server for brave-core written in Go", "language": "Go", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave component update server written in Go\n\n`go-update` implements a [component update server](https://developer.chrome.com/apps/autoupdate) for use in brave-core written in Go.\n\nThe intended audience for this server is all users of brave-core.\n\nThe server is only intended to support a small number of extensions that Brave handles ourselves.\n\nThe component update server supports 2 types of requests both at the same endpoint `/extensions`\n\n1) The `POST /extensions` endpoint uses an XML schema for the request and the response.  Samples can be found in the tests.\n2) The `GET /extensions` endpoint uses URL query parameters and responds with a similar XML schema. Samples can also be found in the tests.\n\nThis server is compatible with Google's component update server, so it is a drop-in replacement to handle the requests coming from Chromium.\n\nWhen there is only a single extension requested, and if we do not support the extension ourselves, we will redirect the request to Google's component updater to handle the request.\n\nThis server also serves as a filter so Brave can blacklist any extension before it has a chance to redirect to Google's component updater.\n\n## Runbook\nhttps://github.com/brave/devops/tree/master/docs/runbooks/go-updater\n\n## Dependencies\n\nGo 1.21.\n\n## Run lint:\n\nInstall `golangci-lint` if you don't already have it:\n\n`go get github.com/golangci/golangci-lint/cmd/golangci-lint`\n\nThen:\n\n`make lint`\n\n## Run tests:\n\n`make test`\n\n## Build go-update:\n\n`make build`\n\n## Run go-update:\n\n`./main`\n", "release_dates": []}, {"name": "goggles-quickstart", "description": "Educational material to learn about Goggles and how to create your own. ", "language": null, "license": null, "readme": "<h1 align=\"center\">Brave Search Goggles</h2>\n\n<p align=\"center\">\n  <em>\n    Search\n    \u00b7 Open Ranking\n    \u00b7 Algorithmic Transparency\n  </em>\n  <br />\n  <em>\n    <a href=\"https://search.brave.com/goggles\">Try it</a>\n    \u00b7 <a href=\"https://search.brave.com/goggles/discover\">Discover</a>\n    \u00b7 <a href=\"https://brave.com/goggles\">Whitepaper</a>\n  </em>\n</p>\n<br/>\n\nGoggles enable anyone, be it individuals or a community, to alter the ranking\nof Brave search by using a set of instructions (rules and filters). Anyone can\ncreate, apply, or extend a Goggle. Essentially Goggles act as a custom\nre-ranking on top of Brave\u2019s search index.\n\nThis means that, instead of a single ranking, Brave Search can offer an almost\nlimitless number of ranking options. While Brave Search doesn't have editorial\nbiases, all search engines have some level of intrinsic bias due to underlying\ndata (the Web) and some algorithmic choices of features to select. Goggles\nallows for users to counter such intrinsic biases in the ranking, and also to\ncreate custom search experiences that couldn\u2019t be covered by an all-purpose\nsearch engine such as Brave Search.\n\nGoggles are owned solely by their creators and, if public, can be used by\nanyone on top of Brave Search index.\n\nWant to start building your own goggles, or fork or extend existing ones? Check\nout our Goggles [quickstart guide](./goggles/quickstart.goggle).\n\nWant to learn more about the motivation for Goggles? Check out the [Goggles whitepaper](https://brave.com/goggles).\n\n## [Getting Started](https://github.com/brave/goggles-quickstart/blob/main/getting-started.md#getting-started)\n\n* [Goggles syntax](https://github.com/brave/goggles-quickstart/blob/main/getting-started.md#goggles-syntax)\n* [Creating a Goggle](https://github.com/brave/goggles-quickstart/blob/main/getting-started.md#creating-a-goggle)\n* [Updating a Goggle](https://github.com/brave/goggles-quickstart/blob/main/getting-started.md#updating-a-goggle)\n* [Deleting a Goggle](https://github.com/brave/goggles-quickstart/blob/main/getting-started.md#deleting-a-goggle)\n* [Learn by example](https://github.com/brave/goggles-quickstart/blob/main/getting-started.md#learn-by-example)\n* [Fine-tuning a Goggle](https://github.com/brave/goggles-quickstart/blob/main/getting-started.md#fine-tuning-a-goggle)\n* [Sharing a Goggle with the world](https://github.com/brave/goggles-quickstart/blob/main/getting-started.md#sharing-a-goggle-with-the-world)\n* [What happens when two instructions are conflicting?](https://github.com/brave/goggles-quickstart/blob/main/getting-started.md#what-happens-when-two-instructions-are-conflicting)\n* [How can I exclude any result not matched by my Goggle?](https://github.com/brave/goggles-quickstart/blob/main/getting-started.md#what-happens-when-two-instructions-are-conflicting)\n\n## [FAQ](https://github.com/brave/goggles-quickstart/blob/main/faq.md#faq)\n\n* [Who owns a Goggle?](https://github.com/brave/goggles-quickstart/blob/main/faq.md#who-owns-a-goggle)\n* [Why can\u2019t I apply multiple Goggles at the same time?](https://github.com/brave/goggles-quickstart/blob/main/faq.md#why-cant-i-apply-multiple-goggles-at-the-same-time)\n* [Can Goggles ownership be transferred?](https://github.com/brave/goggles-quickstart/blob/main/faq.md#can-goggles-ownership-be-transferred)\n* [Do Goggles contribute to polarization?](https://github.com/brave/goggles-quickstart/blob/main/faq.md#do-goggles-contribute-to-polarization)\n* [What\u2019s next for Goggles?](https://github.com/brave/goggles-quickstart/blob/main/faq.md#do-goggles-contribute-to-polarization)\n* [Why is Goggles in Beta?](https://github.com/brave/goggles-quickstart/blob/main/faq.md#why-is-goggles-in-beta)\n* [Why is a particular page not recoverable with Goggles?](https://github.com/brave/goggles-quickstart/blob/main/faq.md#why-is-a-particular-page-not-recoverable-with-goggles)\n* [Can anyone create a Goggle or is it only for developers?](https://github.com/brave/goggles-quickstart/blob/main/faq.md#can-anyone-create-a-goggle-or-is-it-only-for-developers)\n* [How can I discover new Goggles?](https://github.com/brave/goggles-quickstart/blob/main/faq.md#how-can-i-discover-new-goggles)\n\n\n## Privacy considerations\n\nTo apply a Goggle, a user needs to pass the Goggle URL together with a query.\nWe treat Goggle URLs with the same strict provisions we use to handle other\ndata elements (like IP or geo-coordinates) that could serve as identifiers.\nBrave does not track the queries of any of its users, and searching with\nGoggles is no exception. However, note that if a Goggle is used only by one, or\na very small number of people, the Goggle URL could serve as an identifier, and\nenable the creation of a profile of the user\u2019s queries while using that\nparticular Goggle.\n\nLearn more about our [privacy policy](https://search.brave.com/help/privacy-policy).\n", "release_dates": []}, {"name": "googleads-referral", "description": "Resolve Google Ads issue with installer domain", "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "GuardianConnect", "description": "API / VPN Framework for Guardian Firewall iOS application", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# GuardianConnect\nAPI / VPN Framework for Guardian Firewall iOS application\n\nTo build an xcframework for iOS or mac change into the root folder and run OR change to the target XCFramework and build straight from Xcode\n\n./build_framework.sh\n\nif all goes well you should have GuardianConnect.xcframework in that folder upon completion.\n\nThere is an iOS sample project in Swift to show how easy it is to integrate.\n\n", "release_dates": []}, {"name": "hapi-rate-limiter", "description": null, "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# hapi-rate-limiter\nA [Hapi](http://hapijs.com/) plugin that enables rate-limiting for GET, POST, and DELETE requests. This plugin can be configured with custom\nrates on a route-by-route basis.\n\n## Register the plugin\n```\nconst Bluebird = require('bluebird');\nconst Hapi     = require('hapi');\nconst Redis    = require('redis');\n\nBluebird.promisifyAll(Redis.RedisClient.prototype);\nBluebird.promisifyAll(Redis.Multi.prototype);\n\nconst Server = new Hapi.Server();\n\nconst RedisClient = Redis.createClient({\n  port: '6379',\n  host: 'localhost'\n});\n\nconst defaultRate = {\n  limit: 10,\n  window: 60\n};\n\nserver.register([\n  register: require('hapi-rate-limiter'),\n  options: {\n    defaultRate: (request) => defaultRate,\n    redisClient: RedisClient,\n    overLimitError: (rate) => new Error(`Rate Limit Exceeded - try again in ${rate.window} seconds`)\n  }\n], (err) => {\n\n});\n```\n\n#### Options\nThe first four options `(defaultRate, rateLimitKey, redisClient, overLimitError)` are required for the plugin to work properly.\n\nRate-limiting is by default disabled on all routes, unless `enabled=true` in the route plugin [settings](#custom-rate).\n\n##### `defaultRate`\nFunction that accepts a `Request` object and returns:\n```\n{\n  limit: # of max requests allows within window (integer)\n  window: # of seconds before count resets (integer)\n}\n```\n\nThis is used if there is no `rate` function defined in the route plugin [settings](#custom-rate).\n\n##### `rateLimitKey`\nA function that returns a key for an given request. This can be any differentiating value in each request, such as an API Key, IP Address, etc.\n\n##### `redisClient`\nA promisified redis client.\n\n##### `overLimitError`\nA function that is called when the rate limit is exceeded. It must return an error. It is called with an object `rate` that contains information about the current state of the request rate.\n\n##### `methods`\nThe default list of HTTP methods that are examined. The default is:\n```\n[ 'get', 'post', 'delete' ]\n```\nYou might prefer:\n```\n[ 'get', 'post', 'delete', 'put', 'patch' ]\n```\n\n##### `enabled`\nIf set to `true` in the options, then all routes are subject to rate-limiting.\n\n## Managing Routes\nSettings for individual routes can be set while registering a route.\n\n#### Custom Rate\nA custom `limit` and `window` can be registered for each route. The `rate` key\naccepts a `Request` object and returns a [rate](#defaultRate).\n\n```\nconst customRate = {\n  limit: 20,\n  window: 30\n};\n\nserver.route([{\n  method: 'POST',\n  path: '/custom_rate_route',\n  config: {\n    plugins: {\n      rateLimit: {\n        enabled: true\n        rate: (request) => customRate\n      }\n    },\n    handler: (request, reply) => {\n      reply({ rate: request.plugins['hapi-rate-limiter'].rate });\n    }\n  }\n}]);\n```\n\nTo enable rate-limiting for a route, `enabled` must be `true` in the route plugin settings.\n\n`rate` can also be defined in these settings to set a custom rate. If this is not defined, `defaultRate` will be used.\n\n#### Disable Rate-Limiting for route\n\nIf `plugins.rateLimit` is not defined, rate-limiting is disabled for that route\n(unless `options.enabled` is `true` when the plugin is registered).\n\n```\nserver.route([{\n  method: 'POST',\n  path: '/disabled_route',\n  config: {\n    handler: (request, reply) => {\n      reply({ rate: request.plugins['hapi-rate-limiter'].rate });\n    }\n  }\n}]);\n```\n\n## Headers\nRate-limiting information for each request is attached to the response header with the following keys:\n\n`x-rate-limit-limit:` total number of requests allowed within the window\n\n`x-rate-limit-remaining:` remaining number of requests allows within current window\n\n`x-rate-limit-reset:` time when rate-limiter will reset (UTC seconds-since-epoch)\n", "release_dates": []}, {"name": "hapi-swagger", "description": "A Swagger interface for HAPI", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# hapi-swagger\n\nThis is a [OpenAPI (aka Swagger)](https://openapis.org/) plug-in for [HAPI](http://hapijs.com/) When installed it will self document the API interface\nin a project.\n\n[![build status](https://img.shields.io/travis/glennjones/hapi-swagger.svg?style=flat-square)](http://travis-ci.org/glennjones/hapi-swagger)\n[![Coverage Status](https://img.shields.io/coveralls/glennjones/hapi-swagger/dev.svg?style=flat-square)](https://coveralls.io/r/glennjones/hapi-swagger)\n[![npm downloads](https://img.shields.io/npm/dm/hapi-swagger.svg?style=flat-square)](https://www.npmjs.com/package/hapi-swagger)\n[![MIT license](http://img.shields.io/badge/license-MIT-blue.svg?style=flat-square)](https://raw.github.com/glennjones/microformat-shic/master/license.txt)\n\n\n# Install\n\nYou can add the module to your HAPI using npm:\n\n    $ npm install hapi-swagger --save\n\nIf you want to view the documentation from your API you will also need to install the `inert` and `vision` plugs-ins which support templates and static\ncontent serving.\n\n    $ npm install inert --save\n    $ npm install vision --save\n\n# Documentation\n\n* [Options Reference](optionsreference.md)\n* [Usage Guide](usageguide.md)\n\n\n# Quick start\n\nIn your HAPI apps main JavaScript file add the following code to created a HAPI `server` object. You will also add the routes for you API as describe on hapijs.com site.\n\n\n```Javascript\nconst Hapi = require('hapi');\nconst Inert = require('inert');\nconst Vision = require('vision');\nconst HapiSwagger = require('hapi-swagger');\nconst Pack = require('./package');\n\nconst server = new Hapi.Server();\nserver.connection({\n        host: 'localhost',\n        port: 3000\n    });\n\nconst options = {\n    info: {\n            'title': 'Test API Documentation',\n            'version': Pack.version,\n        }\n    };\n\nserver.register([\n    Inert,\n    Vision,\n    {\n        'register': HapiSwagger,\n        'options': options\n    }], (err) => {\n        server.start( (err) => {\n           if (err) {\n                console.log(err);\n            } else {\n                console.log('Server running at:', server.info.uri);\n            }\n        });\n    });\n\nserver.route(Routes);\n```\n\n# Tagging your API routes\nAs a project may be a mixture of web pages and API endpoints you need to tag the routes you wish Swagger to\ndocument. Simply add the `tags: ['api']` property to the route object for any endpoint you want documenting.\n\nYou can even specify more tags and then later generate tag-specific documentation. If you specify\n`tags: ['api', 'foo']`, you can later use `/documentation?tags=foo` to load the documentation on the\nHTML page (see next section).\n\n```Javascript\n{\n    method: 'GET',\n    path: '/todo/{id}/',\n    config: {\n        handler: handlers.getToDo,\n        description: 'Get todo',\n        notes: 'Returns a todo item by the id passed in the path',\n        tags: ['api'], // ADD THIS TAG\n        validate: {\n            params: {\n                id : Joi.number()\n                        .required()\n                        .description('the id for the todo item'),\n            }\n        }\n    },\n}\n```\n\nOnce you have tagged your routes start the application. __The plugin adds a page into your site with the route `/documentation`__,\nso the the full URL for the above options would be `http://localhost:3000/documentation`.\n\n\n\n# Contributing\n\nRead the [contributing guidelines](https://github.com/glennjones/hapi-swagger/blob/master/.github/CONTRIBUTING.md) for details.\n\n\n\n\n# Thanks\nI would like to thank all that have contributed to the project over the last couple of years. This is a hard project to maintain, getting HAPI to work with Swagger\nis like putting a round plug in a square hole. Without the help of others it would not be possible.\n\n\n", "release_dates": []}, {"name": "hashset-cpp", "description": "Simple hashtable implementation with easy serialization and deserialization", "language": "C++", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Hash Set\n\n[![Build Status](https://travis-ci.org/bbondy/hashset-cpp.svg?branch=master)](https://travis-ci.org/bbondy/hashset-cpp)\n\nImplements a simple HashSet for strings in environments where you don't have the std lib available.\nYou should probably not be using this. Instead consider using `hash_set` which is a more generic implementation with templates.\nThis is only useful for very specific use cases having specific memory layout requirements.\n\n## Setup\n\n```\nnpm install --save hashset-cpp\n```\n\n## Sample\n\n```c++\n#include <iostream>\n#include \"hash_set.h\"\n#include \"test/example_data.h\"\n\nusing std::cout;\nusing std::endl;\n\nint main(int argc, char **argv) {\n  // Bucket size is 256 and don't allow multiple items per item hash.\n  HashSet<ExampleData> set(256, false);\n  set.Add(ExampleData(\"test\"));\n\n  // Prints true\n  cout << \"test exists: \" << (set.Exists(ExampleData(\"test\"))\n      ? \"true\" : \"false\") << endl;\n  // Prints false\n  cout << \"test2 exists: \" << (set.Exists(ExampleData(\"test2\"))\n      ? \"true\" : \"false\") << endl;\n\n  uint32_t len;\n  char * buffer = set.Serialize(&len);\n  HashSet<ExampleData> set2(0, false);\n  set2.Deserialize(buffer, len);\n  // Prints true\n  cout << \"test exists: \" << (set2.Exists(ExampleData(\"test\"))\n      ? \"true\" : \"false\") << endl;\n  // Prints false\n  cout << \"test2 exists: \" << (set2.Exists(ExampleData(\"test2\"))\n      ? \"true\" : \"false\") << endl;\n\n  delete[] buffer;\n  return 0;\n}\n```\n\n## Build everything in release\n\n```\nmake\n```\n\n## Running sample\n\n```\nmake sample\n```\n\n## Running tests\n\n```\nmake test\n```\n\n## Clearing build files\n```\nmake clean\n```\n\n## Linting\n```\nnpm run lint\n```\n", "release_dates": []}, {"name": "heroku-cmake-buildpack", "description": "Heroku Cedar14 CMake Buildpack", "language": "Shell", "license": null, "readme": "# Heroku Cedar 14 cmake buildpack\n\nUse buildpack multi and use this buildpack before your buildpack.\n", "release_dates": ["2017-08-31T03:38:33Z"]}, {"name": "heroku-cmake-buildpack-bin", "description": "A pre-compiled version of https://github.com/brave/heroku-cmake-buildpack", "language": "Shell", "license": null, "readme": "# heroku-cmake-buildpack-bin\n\nA pre-compiled version of https://github.com/brave/heroku-cmake-buildpack\n", "release_dates": []}, {"name": "heroku-cmake-buildpack-bin-18", "description": "a bin build of the cmake buildpack for heroku os 18", "language": "Shell", "license": null, "readme": "# heroku-cmake-buildpack-bin\n\nA pre-compiled version of https://github.com/brave/heroku-cmake-buildpack\n\nlogin to the heroku server\n```bash\nheroku run sh -a brave-cmake-buildpack-builder\n```\n\non the heroku server\n```bash\n./package.sh\n```\n\non the original computer\n```bash\nwormhole receive KEY-FROM-PACKAGE-SH\n```\n", "release_dates": ["2019-08-20T19:52:53Z"]}, {"name": "https-everywhere-builder", "description": "Build HTTPS Everywhere ruleset files for Brave", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# HTTPS Everywhere Builder\n\nBuilds HTTPS Everywhere ruleset files for Brave.\n\n## Configuring\n\nIf there are rulesets that are broken and need to be disabled, add them to the `exclusions` list.\n\n## Building locally\n\n    npm install\n    npm run build\n\n## Testing locally\n\n1. Copy `out/httpse.leveldb.zip` into `~/.config/BraveSoftware/Brave-Browser-Beta/oofiananboodjbbmdelgdommihjbkfag/*/*/` overwriting the existing file.\n2. Delete the `httpse.leveldb` directory.\n3. Unzip `httpse.leveldb.zip`.\n4. Start the browser and ensure that <http://https-everywhere.badssl.com/> works.\n5. Find a site that was added in the last release and check that it gets upgraded. Check it first with `curl --head` to make sure it doesn't redirect to HTTPS server-side.\n\n## Releasing a new version\n\n1. Connect to the Brave VPN.\n2. On Jenkins, look for the `brave-core-ext-https-everywhere-update-publish` job.\n3. Click \"Build Now\".\n\nOnce that's done, the new extension should be available within a few minutes.\n", "release_dates": []}, {"name": "https-everywhere-lib-cpp", "description": "C++ FFI bindings to the EFF HTTPS Everywhere library", "language": "Rust", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# https-everywhere-lib-cpp\n\n**A FFI crate C++ wrapper to expose functionality from [https-everywhere-lib-core](https://github.com/EFForg/https-everywhere-lib-core)**\n\nThe `https-everywhere-lib-core` crate implements an HTTPS Everywhere rule\nmatcher. This crate uses a C FFI to expose its functionality as a static C++\nlibrary.\n", "release_dates": []}, {"name": "https-everywhere-ruleset", "description": "Fork of the last freely-licensed copy of the EFF HTTPS Everywhere ruleset", "language": null, "license": {"key": "gpl-2.0", "name": "GNU General Public License v2.0", "spdx_id": "GPL-2.0", "url": "https://api.github.com/licenses/gpl-2.0", "node_id": "MDc6TGljZW5zZTg="}, "readme": null, "release_dates": []}, {"name": "httpse2ios", "description": "Converts HTTPSE xml rules to iOS Content Blocking API format", "language": "JavaScript", "license": null, "readme": null, "release_dates": []}, {"name": "imagemin-pngquant", "description": "Imagemin plugin for `pngquant`", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# imagemin-pngquant ![GitHub Actions Status](https://github.com/imagemin/imagemin-pngquant/workflows/test/badge.svg?branch=master)\n\n> [Imagemin](https://github.com/imagemin/imagemin) plugin for [`pngquant`](https://github.com/kornelski/pngquant)\n\n\n## Install\n\n```\n$ npm install imagemin-pngquant\n```\n\n\n## Usage\n\n```js\nconst imagemin = require('imagemin');\nconst imageminPngquant = require('imagemin-pngquant');\n\n(async () => {\n\tawait imagemin(['images/*.png'], {\n\t\tdestination: 'build/images',\n\t\tplugins: [\n\t\t\timageminPngquant()\n\t\t]\n\t});\n\n\tconsole.log('Images optimized');\n})();\n```\n\n\n## API\n\n### imageminPngquant(options?)(input)\n\nReturns `Promise<Buffer>`.\n\n#### options\n\nType: `object`\n\n##### speed\n\nType: `number`<br>\nDefault: `4`<br>\nValues: `1` (brute-force) to `11` (fastest)\n\nSpeed `10` has 5% lower quality, but is about 8 times faster than the default. Speed `11` disables dithering and lowers compression level.\n\n##### strip\n\nType: `boolean`<br>\nDefault: `false`\n\nRemove optional metadata.\n\n##### quality\n\nType: `Array<min: number, max: number>`<br>\nValues: `Array<0...1, 0...1>`<br>\nExample: `[0.3, 0.5]`\n\nInstructs pngquant to use the least amount of colors required to meet or exceed\nthe max quality. If conversion results in quality below the min quality the\nimage won't be saved.\n\nMin and max are numbers in range 0 (worst) to 1 (perfect), similar to JPEG.\n\n##### dithering\n\nType: `number | boolean`<br>\nDefault: `1` (full)<br>\nValues: `0...1`\n\nSet the dithering level using a fractional number between 0 (none) and 1 (full).\n\nPass in `false` to disable dithering.\n\n##### posterize\n\nType: `number`\n\nTruncate number of least significant bits of color (per channel). Use this when image will be output on low-depth displays (e.g. 16-bit RGB). pngquant will make almost-opaque pixels fully opaque and will reduce amount of semi-transparent colors.\n\n##### verbose\n\nType: `boolean`<br>\nDefault: `false`\n\nPrint verbose status messages.\n\n#### input\n\nType: `Buffer | Stream`\n\nBuffer or stream to optimize.\n", "release_dates": []}, {"name": "immutable-js-patch", "description": null, "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "Immutable Patch\n====\n\nApply RFC 6902 style patches to Immutable.JS data structures, such as `Maps`, `Lists`, and `Sets`.\n\n### Getting Started\n\nYou may get the module via npm:\n\n```\nnpm install immutablepatch\n```\n\nAnd apply JSON patches to an immutable JSON object:\n\n```js\nvar Immutable = require('immutable');\nvar patch = require('immutablepatch');\n\nvar list = Immutable.fromJS([1, 2, [3, 4]]);\nvar ops = Immutable.fromJS([\n  {op: 'replace', path: '/2/1', value: 10}\n]);\n\nvar result = patch(list, ops);\n// var expected = Immutable.fromJS([1, 2, [3, 10]]);\n```\n\nYou will probably need [`immutablediff`](https://github.com/intelie/immutable-js-diff) to generate diff operations.\n", "release_dates": []}, {"name": "infra-ci", "description": "CI pipeline for terraform using terraform", "language": "HCL", "license": null, "readme": "## Infra CI (WIP)\n\nTerraform CI with no external dependencies to AWS. This does not actually apply the changes currently.\n\n### Bootstrap\n\nCurrently this expects `cloudflare_parameter_name` and `fastly_parameter_name` to be references to SSM parameter store\nitems containing `CLOUDFLARE_TOKEN` and `FASTLY_API_KEY`. Later this would likely be referenced cross account. You can\nuse the following to set these in AWS.\n\n```bash\naws ssm put-parameter --type SecureString --name '/CodeBuild/FASTLY_API_KEY' --value \"$(echo -n 'enter secret: ' 1>&2; read s; echo -n $s)\"\naws ssm put-parameter --type SecureString --name '/CodeBuild/CLOUDFLARE_TOKEN' --value \"$(echo -n 'enter secret: ' 1>&2; read s; echo -n $s)\"\n```\n\nWith docker installed run the following \n```\n# <profile> is the profile to load from ~/.aws/credentials\n\n./scripts/tf.sh <profile> init\n./scripts/tf.sh <profile> apply\n```\n\n\nWorth noting `./scripts/tf.sh` passes arguments to terraform so can run any other tf commands as well.\n", "release_dates": []}, {"name": "inpage-provider", "description": "An Ethereum Provider that connects over a stream, as injected into websites by MetaMask", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# MetaMask Inpage Provider\n\nThe inpage Ethereum provider object injected by MetaMask into web pages.\nContains a lot of implementation details specific to MetaMask, and is probably\nnot suitable for out-of-the-box use with other wallets.\n\n## Installation\n\n`yarn add @metamask/inpage-provider`\n\n## Usage\n\n```javascript\nimport { initProvider } from '@metamask/inpage-provider'\n\n// Create a stream to a remote provider:\nconst metamaskStream = new LocalMessageDuplexStream({\n  name: 'inpage',\n  target: 'contentscript',\n})\n\n// this will initialize the provider and set it as window.ethereum\ninitProvider({\n  connectionStream: metamaskStream,\n})\n\nconst { ethereum } = window\n```\n\n### Do Not Modify the Provider\n\nThe Provider object should not be mutated by consumers under any circumstances.\nThe maintainers of this package will neither fix nor take responsbility for bugs caused by third parties mutating the provider object.\n", "release_dates": []}, {"name": "install-cmake", "description": "Download and compile CMake for subsequent use by npm installations", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# install-cmake\nDownload and compile [CMake](https://cmake.org/) for subsequent use by `npm --global install`.\nThis package installs CMake 3.5.2.\nNote that because `cmake` takes such a long time to download and compile,\nit is recommended that you install this package in global mode.\n\nBased on Stanley Gu's [cmake](https://github.com/stanleygu/cmake) for npm.\n\n## Installing on Windows\nWhen Windows is detected (via `process.platform === 'win32'`), CMake will be installed via MSI.\n\nThis package:\n- will add cmake to the system PATH\n- requires a single interactive input: allowing escalation to administrator\n- can be debugged by setting `captureLogs` to true, enabling verbose logs\n- is safe to run if already installed\n", "release_dates": []}, {"name": "ios-open-thirdparty-browser", "description": "Reference client for opening links in Firefox and Brave iOS", "language": "Swift", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Opening links in Firefox and Brave for iOS #\nThis open-source project provides support for opening links in third party browsers for iOS. There are classes (for Objective-C and Swift), along with a sample project that uses them, available for reference and use. \n\n### Using OpenInThirdPartyBrowserControllerSwift or OpenInThirdPartyBrowserControllerObjC to open links ###\nThes classes provide methods that handle the making of custom URI schemes, checking if Firefox or Brave (or others if we want to add more) is installed on the device and opening the URL in the browser. Swift and Objective-C implementations of these classes are provided to accommodate your language of choice.\n\n### Methods ###\n* `isInstalled`: returns true if  installed\n* `openInBrowser`: opens the specified URL; used with or without the following:\n\n### The Custom URL ###\nThe URI schemes are  `firefox://` and `brave://`. The scheme accepts the following query parameter:\n* `url`: (required) the URL to open.\n\nFor Example: \n```\nfirefox://open-url?url=https%253A%252F%252Fwww.mozilla.org%252Fen-US%252Fnewsletter%252Fios%252F\n```\n### Walkthrough ###\n1. Download the class file in the language of your choice:\n  * Swift: OpenInThirdPartyBrowserControllerSwift.swift\n  * Objective-C: OpenInThirdPartyBrowserControllerObjC.m and OpenInThirdPartyBrowserControllerSwiftObjC.h\n2. Whitelist the Firefox and Brave URL scheme in Info.plist, under the LSApplicationQueriesSchemes key:\n  * Add `firefox` and `brave` to LSApplicationQueriesSchemes\n  * If LSApplicationQueriesSchemes isn't already in your app's Info.plist, you can just manually add it\n  * In depth example on how to do that [here](http://useyourloaf.com/blog/querying-url-schemes-with-canopenurl.html)\n3. Call method `openInBrowser(url)` on OpenInThirdPartyBrowserController(Swift/ObjC)\n", "release_dates": []}, {"name": "jitsi-slack", "description": null, "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Jitsi Slack - Jitsi Meet Integration for Slack\n\nThis project provides a Slack integration to enable starting video conferences\nfrom Slack and easily inviting Slack members to conferences.\n\nEnables starting and joining [Jitsi Meet](https://meet.jit.si) meetings from within [Slack](https://slack.com/)\n\n## Getting Started\n\nThese instructions will get you started with the ability to run the project\non your local machine for development purposes.\n\n### Prerequisites\n\n#### Go\nA working setup for the Go Programming Language is needed. Here is a [getting started](https://golang.org/doc/install) guide. The project\nis currently using go version 1.11 along with module support.\n\n#### Slack\n\nA slack account needs to be created as well as an [app](https://api.slack.com/apps). The app created is intended for development\npurposes. The following functionality must be enabled in the `Add features and functionality` section of the slack app configuration:\n\n* Slash Commands\n* Bots\n\nThe slash command setup is `/jitsi` and the bot mention name is `@jitsi_meet`.\n\n## Configuration\n\n```\nSLACK_SIGNING_SECRET=<signing secret of slack app>\nSLACK_CLIENT_ID=<client id of slack app>\nSLACK_CLIENT_SECRET=<client secret of slack app>\nSLACK_APP_ID=<slack app id>\nSLACK_APP_SHARABLE_URL=<slack app url for sharing install>\nDYNAMO_TABLE=<dynamodb table name for storing oauth tokens>\nDYNAMO_REGION=<dynamodb region used>\nJITSI_TOKEN_SIGNING_KEY=<key used to sign conference asap jwts>\nJITSI_TOKEN_KID=<key identifier for conference asap jwts>\nJITSI_TOKEN_ISS=<issuer for conference asap jwts>\nJITSI_TOKEN_AUD=<audience for conference asap jwts>\nJITSI_CONFERENCE_HOST=<conference hosting service i.e. https://meet.jit.si>\n```\n\n## Development\nFeatures are being worked on that assist with local development that remove the need for dynamodb and support a developer's Slack workspace.\n\n## Running\n\nClone this project and build with `go build cmd/api/main.go` or build and run with `go run cmd/api/main.go`\n\n## Dependency Management\n\nDependency management for this project uses go module as of go version 1.11. More information can be found at [go command documentation](https://golang.org/cmd/go/#hdr-Modules__module_versions__and_more).\n\n## Versioning\n\nThis project uses [Semantic Versioning](https://semver.org) for the code and associated\ndocker containers. Versions are tracked as [tags](https://github.com/jitsi/jitsi-slack/tags) on this repository.\n\n## License\n\nThis project is licensed under the Apache 2.0 License [LICENSE](LICENSE)\n", "release_dates": []}, {"name": "jitsi-videobridge", "description": "Jitsi Videobridge is a WebRTC compatible video router or SFU that lets build highly scalable video conferencing infrastructure (i.e., up to hundreds of conferences per server).", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Intro\n\nJitsi Videobridge is an XMPP server component that allows for multiuser video\ncommunication. Unlike the expensive dedicated hardware videobridges, Jitsi\nVideobridge does not mix the video channels into a composite video stream, but\nonly relays the received video channels to all call participants. Therefore,\nwhile it does need to run on a server with good network bandwidth, CPU\nhorsepower is not that critical for performance.\n\nYou can find documentation in the doc/ directory in the source tree.\n\n# Running it\n\nYou can download binary packages for Debian/Ubuntu:\n* [stable](https://download.jitsi.org/stable/) ([instructions](https://jitsi.org/downloads/ubuntu-debian-installations-instructions/))\n* [testing](https://download.jitsi.org/testing/) ([instructions](https://jitsi.org/downloads/ubuntu-debian-installations-instructions-for-testing/))\n* [nightly](https://download.jitsi.org/unstable/) ([instructions](https://jitsi.org/downloads/ubuntu-debian-installations-instructions-nightly/))\n\nMaven assembly binaries:\n* [assemblies](https://download.jitsi.org/jitsi-videobridge/)\n\nOr you can clone the Git repo and run the JVB from source using maven.\n\n```sh\nHOST=\"Your XMPP server hostname/IP address goes here.\"\nDOMAIN=\"The JVB component name goes here.\"\nPORT=\"the component port of your XMPP server goes here.\"\nSECRET=\"The secret or password for the JVB component.\"\nJVB_HOME=\"The path to your JVB clone.\"\n\nmvn compile exec:exec -Dexec.executable=java -Dexec.args=\"-cp %classpath org.jitsi.videobridge.Main --domain=\\\"${DOMAIN}\\\" --host=\\\"${HOST}\\\" --port=\\\"${PORT}\\\" --secret=\\\"${SECRET}\\\" -Djava.library.path=$JVB_HOME/lib/native/linux-64 -Djava.util.logging.config.file=$JVB_HOME/lib/logging.properties -Dnet.java.sip.communicator.SC_HOME_DIR_NAME=.jitsi-videobridge \"\n```\n", "release_dates": []}, {"name": "joi", "description": "Object schema validation", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "![joi Logo](https://raw.github.com/hapijs/joi/master/images/joi.png)\n\nObject schema description language and validator for JavaScript objects.\n\n[![npm version](https://badge.fury.io/js/joi.svg)](http://badge.fury.io/js/joi)\n[![Build Status](https://secure.travis-ci.org/hapijs/joi.svg)](http://travis-ci.org/hapijs/joi)\n[![Dependencies Status](https://david-dm.org/hapijs/joi.svg)](https://david-dm.org/hapijs/joi)\n[![DevDependencies Status](https://david-dm.org/hapijs/joi/dev-status.svg)](https://david-dm.org/hapijs/joi#info=devDependencies)\n\n[![Join the chat at https://gitter.im/hapijs/joi](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/hapijs/joi?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nLead Maintainer: [Nicolas Morel](https://github.com/marsup)\n\n# Example\n\n```javascript\nvar Joi = require('joi');\n\nvar schema = Joi.object().keys({\n    username: Joi.string().alphanum().min(3).max(30).required(),\n    password: Joi.string().regex(/^[a-zA-Z0-9]{3,30}$/),\n    access_token: [Joi.string(), Joi.number()],\n    birthyear: Joi.number().integer().min(1900).max(2013),\n    email: Joi.string().email()\n}).with('username', 'birthyear').without('password', 'access_token');\n\nJoi.validate({ username: 'abc', birthyear: 1994 }, schema, function (err, value) { });  // err === null -> valid\n```\n\nThe above schema defines the following constraints:\n* `username`\n    * a required string\n    * must contain only alphanumeric characters\n    * at least 3 characters long but no more than 30\n    * must be accompanied by `birthyear`\n* `password`\n    * an optional string\n    * must satisfy the custom regex\n    * cannot appear together with `access_token`\n* `access_token`\n    * an optional, unconstrained string or number\n* `birthyear`\n    * an integer between 1900 and 2013\n* `email`\n    * a valid email address string\n\n# Usage\n\nUsage is a two steps process. First, a schema is constructed using the provided types and constraints:\n\n```javascript\nvar schema = {\n    a: Joi.string()\n};\n```\n\nNote that **joi** schema objects are immutable which means every additional rule added (e.g. `.min(5)`) will return a\nnew schema object.\n\nThen the value is validated against the schema:\n\n```javascript\nJoi.validate({ a: 'a string' }, schema, function (err, value) { });\n```\n\nIf the value is valid, `null` is returned, otherwise an `Error` object.\n\nThe schema can be a plain JavaScript object where every key is assigned a **joi** type, or it can be a **joi** type directly:\n\n```javascript\nvar schema = Joi.string().min(10);\n```\n\nIf the schema is a **joi** type, the `schema.validate(value, callback)` can be called directly on the type. When passing a non-type schema object,\nthe module converts it internally to an object() type equivalent to:\n\n```javascript\nvar schema = Joi.object().keys({\n    a: Joi.string()\n});\n```\n\nWhen validating a schema:\n\n* Keys are optional by default.\n* Strings are utf-8 encoded by default.\n* Rules are defined in an additive fashion and evaluated in order after whitelist and blacklist checks.\n\n# API\nSee the [API Reference](API.md).", "release_dates": []}, {"name": "KeyringController", "description": "A module for managing groups of Ethereum accounts and using them.", "language": "JavaScript", "license": null, "readme": "# Eth Keyring Controller [![Build and test](https://github.com/brave/KeyringController/actions/workflows/action.yml/badge.svg)](https://github.com/brave/KeyringController/actions/workflows/action.yml)\n\nA module for managing groups of Ethereum accounts called \"Keyrings\", defined originally for MetaMask's multiple-account-type feature.\n\nTo add new account types to a `KeyringController`, just make sure it follows [The Keyring Class Protocol](./docs/keyring.md).\n\nThe KeyringController has three main responsibilities:\n- Initializing & using (signing with) groups of Ethereum accounts (\"keyrings\").\n- Keeping track of local nicknames for those individual accounts.\n- Providing password-encryption persisting & restoring of secret information.\n\n## Installation\n\n`npm install eth-keyring-controller --save`\n\n## Usage\n\n```javascript\nconst KeyringController = require('eth-keyring-controller')\nconst SimpleKeyring = require('eth-simple-keyring')\n\nconst keyringController = new KeyringController({\n  keyringTypes: [SimpleKeyring], // optional array of types to support.\n  initState: initState.KeyringController, // Last emitted persisted state.\n  encryptor: { // An optional object for defining encryption schemes:\n               // Defaults to Browser-native SubtleCrypto.\n    encrypt (password, object) {\n      return new Promise('encrypted!')\n    },\n    decrypt (password, encryptedString) {\n      return new Promise({ foo: 'bar' })\n    },\n  },\n})\n\n// The KeyringController is also an event emitter:\nthis.keyringController.on('newAccount', (address) => {\n  console.log(`New account created: ${address}`)\n})\nthis.keyringController.on('removedAccount', handleThat)\n```\n\n## Methods\n\nCurrently the methods are heavily commented in [the source code](./index.js), so it's the best place to look until we aggregate it here as well.\n\n", "release_dates": ["2021-01-20T00:24:27Z", "2021-01-08T00:49:14Z"]}, {"name": "kuchikiki", "description": "(\u53e3\u5229\u304d) HTML tree-manipulation library for Rust", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Kuchikiki (\u53e3\u5229\u304d)\n\nHTML tree-manipulation library for Rust.\n\n[Documentation](https://docs.rs/kuchikiki)\n\nThis is a fork of the Kuchiki (\u673d\u6728) library, which in now unmaintained.\nThe Brave project is still using a branch, and so will continue to\nsupport this repository. You can use this version by updating the name\nin your `Cargo.toml` (add an extra `ki`!) and then remap code references\nto the new name, e.g. with\n\n```rust\nuse kuchikiki as kuchiki\n```\n\nSee the [Security Policy](SECURITY.md) for information on reporting vulnerabilities.\n", "release_dates": ["2023-05-15T19:18:32Z"]}, {"name": "LavaMoat", "description": "tools for sandboxing your dependency graph", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# LavaMoat\n\n![LavaMoat](./assets/lavamoat-logo.png \"Introduction to LavaMoat\")\n\n**LavaMoat** is a set of tools for securing JavaScript projects against a category of attacks called **software supply chain attacks.**\n\nThis genre of attack occurs when a malicious dependency makes it way into a developer's application. An attacker could use the vulerable dependency to then steal important secrets like credit card numbers, private keys, or personal data.\n\nThese attacks have already hit the cryptocurrency ecosystem and present a significant risk for the developers and users of wallets and apps.\n\nIn order to help mitigate the risk of such an attack we are building a suite of tools that range from a node-based runtime, to plugins for common app bundlers (eg webpack, browserify), to dependecy analysis and visualization tools.\n\n**The goal of LavaMoat** is to bring added protections to modern JavaScript apps without having to rewrite them from scratch and automate a good first-start security configuration.\n\n\n## [Watch the introduction video](https://www.youtube.com/watch?v=iaqe6F4S2tA&feature=emb_title&ab_channel=Feross)\n\n\n### How to secure your app against supplychain attacks\n\n1. disable/whitelist dependency lifecycle scripts (eg. \"postinstall\") via [@lavamoat/allow-scripts][LavamoatAllowScripts]\n2. run your server or build process in [lavamoat-node][LavamoatNode]\n3. build your ui with LavaMoat for [Webpack][LavamoatWebpack] or [Browserify][LavamoatBrowserify]\n\n### How LavaMoat works\n\nThe LavaMoat runtime reduces the supplychain risk in **three** primary ways:\n  1. Prevent modifying JavaScript's primordials (Object, String, Number, Array, ...)\n  2. Limit access to the platform API (window, document, XHR, etc) per-package\n\nBoth are provided by [SES][SesGithub] containers. Platform API access is passed in via a LavaMoat configuration file.\n\n### SecureEcmaScript (SES)\n\n[SES][SesGithub] is the sandbox used in LavaMoat. See SES's [secure computing guide][SesComputingGuide] to learn more about the risks of untrusted javascript.\n\n\n### LavaMoat in Node.js\n\nRun your server or app building code with protections via [LavaMoat Node][LavamoatNode]\n\n\n### LavaMoat in the browser\n\nWhen using LavaMoat in the browser, you can just use your favorite bundler if there is an available plugin.\n\nApp bundles have **two** major components:\n\n1. Runtime (aka kernel / loader / prelude / trusted computing base)\nThis is the code that initializes and runs the bundle. For example, the implementation of the `require` function.\n\n2. Module sources\nThis includes the js content of the module sources, and sometimes some config information like module name alaises.\n\nLavaMoat modifies the bundle's runtime to enforce the configured constraints.\n\n\n### Bundler Plugins:\n  - [LavaMoat Webpack][LavamoatWebpack]\n  - [LavaMoat Browserify][LavamoatBrowserify]\n\n\n### Additional tools\n\nIn addition to the LavaMoat runtime bundler plugins, there are some tools to help analyze your dependecy graph and configuration.\n\nSee [lavamoat-viz][LavamoatViz] for a demo of the tool.\n\n### Further reading on software supplychain security\n\n#### Articles:\n- [HackerNoon - I\u2019m harvesting credit card numbers and passwords from your site. Here\u2019s how](https://medium.com/hackernoon/im-harvesting-credit-card-numbers-and-passwords-from-your-site-here-s-how-9a8cb347c5b5)\n- [Agoric - POLA Would Have Prevented the Event-Stream Incident](https://medium.com/agoric/pola-would-have-prevented-the-event-stream-incident-45653ecbda99)\n- [Snyk - Why npm lockfiles can be a security blindspot for injecting malicious modules](https://snyk.io/blog/why-npm-lockfiles-can-be-a-security-blindspot-for-injecting-malicious-modules/)\n- [Bytecode Alliance - Building a secure by default, composable future for WebAssembly](https://bytecodealliance.org/articles/announcing-the-bytecode-alliance)\n\n\n#### Videos:\n- [Making 'npm install' Safe - Kate Sills - QCon 2020 ~40min](https://www.infoq.com/presentations/npm-install/)\n- [JavaScript Supply Chain Security - Adam Baldwin - LocoMocoSec 2019 ~25min](https://www.youtube.com/watch?v=HDo2iOlkbyc)\n- [Analysis of an exploited npm package \u2013 Jarrod Overson - Amsterdam JSNation Conference 2019  ~25min](https://www.youtube.com/watch?v=cvtt8TexqbU)\n\n### Supporters\n\nMade with love by [MetaMask](https://github.com/metamask/)\n\nFunded by [ConsenSys](https://github.com/consensys)\n\nRuns on [Agoric](https://github.com/agoric/)\n\n\n[SesGithub]: https://github.com/Agoric/ses-shim\n[SesComputingGuide]: https://github.com/Agoric/SES-shim/blob/master/packages/ses/docs/secure-coding-guide.md\n\n[CytoplasmGithub]: https://github.com/lavamoat/cytoplasm\n\n[LavamoatNode]: ./packages/node\n[LavamoatWebpack]: ./packages/webpack\n[LavamoatBrowserify]: ./packages/browserify\n[LavamoatViz]: ./packages//viz\n[LavamoatAllowScripts]: ./packages/allow-scripts\n", "release_dates": []}, {"name": "ledger", "description": "Deprecated, please see", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# NOTE: This repo is deprecated, please see [bat-ledger](https://github.com/brave-intl/bat-ledger)\n# Brave Ledger\nThe Brave Ledger is a BTC-based micropayments system for users and publishers.\n\nNote that [travis-ci](https://travis-ci.org/brave/ledger) is not yet operational for this repository.\n\n# Initialization\nTake a look at the files in the `config/` directory.\nWhen the server starts,\nit will look file a file called `config/config.{PROFILE}.js` where `{PROFILE}` is `$NODE_ENV` (defaulting to `\"development\"`).\n\nAuthentication is achieved via a GitHub [OAuth application](https://github.com/settings/developers).\nCreate a developer application with an authorization callback of the form `https://{DOMAIN:PORT}/v1/login` and update the\n`login.clientId` and `login.clientSecret` properties.\n\nAuthorization is achieved by verifying that the user is a member of a GitHub organization, i.e.,\n`https://github.com/orgs/{ORGANIZATION}/teams`.\nSet the `login.organization` property to the name of the organization.\n\nNow start the server with `npm start` and `https://{DOMAIN:PORT}/v1/login` which will start the authentication/authorization\nprocess.\nOn success,\nyou will be redirected to `https://{DOMAIN:PORT}/documentation`.\n\nWhen the server starts,\nit will create (if necessary) a `persona` and a `wallet` registrar.\nYou will need to create a 'contribution' surveyor,\ngo to `https://{DOMAIN:PORT}/documentation#!/v1/postV1SurveyorSurveyortype`,\nset`surveyorType` to 'contribution',\nand enter a body like this:\n\n    { \"adFree\": { \"fee\": { \"USD\": 5.00 }, \"votes\": 30 } }\n\n# Setup\nClone the repo: `git clone git@github.com:brave/ledger.git`\n\nInstall dependencies with `npm install`\n\nInstall MongoDB: `brew update && brew install mongodb`\n\nStart MongoDB. There are a variety of ways to do this, one option on a mac: `brew tap homebrew/services && brew services start mongodb`\n\nInstall Redis: `brew update && brew install redis`\n\nStart Redis. There are a variety of ways to do this, one option on a mac: `brew tap homebrew/services && brew services start redis`\n\n## StandardJS\n\nFor linting we use [StandardJS](https://github.com/feross/standard). It's recommended that you install the necessary IDE plugin. Since this repo uses ES7 features, you'll need a global install of both the standard and babel-eslint packages.\n\n## Configuration\n\nFor staging or production environments configuration variables are stored as environment preferences. See config/config.production.js for a list of these variables.\n\nFor local development you can copy config/config.development.js.tpl to config/config.development.js and define the local config variables.\n\n## Running the server\n\nUse `gulp` to run the server in development. This also sets up watchers and will restart the server on a file change.\n\n## Proximo\n\nProximo is currently used as a proxy so we can make outbound BitGo requests using a static IP. \nPlease define `process.env.BITGO_USE_PROXY` as appropriate.\n", "release_dates": []}, {"name": "ledger-balance", "description": "Deprecated, please see", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# NOTE: This repo is deprecated, please see [bat-balance](https://github.com/brave-intl/bat-balance)\n# ledger-balance\nFind the balance associated with a Bitcoin wallet.\nDo so using a list of blockchain reporters (providers) that is weighted over time.\n\n## API\n\n### Get the Balance of a Bitcoin wallet\n\n        var getBalance = require('ledger-balance').getBalance\n\n        var address = '3...'\n        getBalance(address, function (err, provider, result) {\n          if (err) return console.log((provider ? (provider.name + ': ') : '') + err.toString())\n\n          console.log('address=' + address + ' provider=' + provider.name + ' satoshis=' + result)\n        })\n\nThis method works by using a modified [round-robin](https://en.wikipedia.org/wiki/Round-robin_DNS) algorithm with a simple\nscoring system:\n\n- each time that `getBalance` is called, it shuffles the list of providers and then orders them according to each provider's score\n\n- each provider is tried in order and the first (successful) result is returned\n\n- if  the attempt is successful,\nthen the provider's score is set to a number between `-250` and `5000` that corresponds to the number of milli-seconds it to took to round-trip and process the request\n\n- if the attempt fails, then the provider score is set to one of:\n\n    - on DNS (or other network) error: -350;\n\n    - on timeout: -500;\n\n    - HTTP error: -750; or,\n\n    - on internal error: -1001 (thereby disqualifying the provider from further consideration)\n\n### Add to the list of Providers\n\nEach of these properties is mandatory:\n\n        require('ledger-balance').providers.push({ name      : 'commonly-known name of provider'\n                                                 , site      : 'https://example.com/'\n                                                 , server    : 'https://api.example.com'\n                                                 , path      : '\"/v1/address\" + address'\n                                                 , confirmed : 'body.confirmed_satoshis'\n                                                 })\n\nThe default value for the `method` is `\"GET\"`;\n(or `\"POST\"` if the value for the `payload` property is present).\n\nBoth the mandatory `path` property and the optional `payload` property are evaluated with this context:\n\n        { address: '3...' }\n\nThe mandatory `confirmed` property is evaluated with this context:\n\n        { body: JSON.parse(HTTP_response_body) }\n\nThere is also an optional `unconfirmed` property that is evaluated in the same context.\n\n## Finally...\n\nAll of the blockchain reporters in this package are available using public APIs without any API key.\n\nIf you want to have your blockchain reporter added to the package,\nplease send an email to [Brave Software](mailto:devops@brave.com?subject=ledger-balance).\n\nIf you want to have your blockchain reporter removed from the package,\nalso send an [email](mailto:devops@brave.com?subject=ledger-balance).\n\nEnjoy!\n", "release_dates": []}, {"name": "ledger-client", "description": "Deprecated, please see", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# NOTE: This repo is deprecated, please see [bat-client](https://github.com/brave-intl/bat-client)\n# ledger-client\nAn example of client code for the [Brave ledger](https://github.com/brave/ledger).\n\n## API\n\nTo begin:\n\n- The client must maintain a secure, persistent storage in which it can store a JSON object.\n\n- Some calls require a callback of the form:\n\n        var callback = function (err, result, delayTime) { ... }\n\n    When the callback is invoked,\nif `err` is `null`, and `result` is not `null`, then `result` must be put into persistent storage.\n(If `err` is `null`,\nthen the operation has succeeded,\nregardless of whether `result` is defined or not.)\n\n- The [Ledger protocol](https://github.com/brave/ledger/tree/master/documentation/Ledger-Principles.md)\nrequires that the client uses a pseudo-random delay be introduced at certain points during operations.\nAccordingly,\nif the `delayTime` parameter is defined,\nthen the client should wait at least `delayTime` milliseconds before making a call to\n\n        client.sync(callback)\n\n    There is no harm in retrying earlier,\nbut,\nfrom the network's perspective,\nit will be a no-op.\n\n### Creating an Endpoint\n\n        var Client = require('ledger-client')\n        this.client = new Client(personaId, options, state)\n        this.client.sync(callback)\n\nwhere the value for `personaId` (if not `null`) is a\n[UUID v4](https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_.28random.29) value and `options` is:\n\n        // all properties are optional...\n        { server            : 'https://ledger.brave.com'\n        , debugP            : false\n        , loggingP          : false\n        , verboseP          : false\n        }\n\nand `state` is either: whatever was previously stored in persistent storage, or `{}`.\n\nThe client endpoint should not be referenced until the callback is invoked.\n\n### Bravery Properties\nTo retrieve the Bravery properties for the Ledger,\nthe client calls:\n\n        var properties = this.client.getBraveryProperties()\n\nwhere `properties` is a list of configuration options:\n\n| Property    | Meaning                     | Examples                     |\n|------------:|-----------------------------|------------------------------|\n| `setting`   | \"adFree\" or \"adReplacement\" | adFree                       |\n| `days`      | the reconcilation period    | 30                           |\n| `fee`       | for \"adFree\"                | { currency: USD, amount: 5 } |\n\nTo update the Bravery properties for the Ledger,\nthe client calls:\n\n        this.client.setBraveryProperties(properties, function (err, result) {\n          if (err) return console.log(err)\n\n          if (result) result must be put into persistent storage as the client's new state\n        })\n\nNote that this will likely result in the `callback` being invoked with a `result` parameter,\nindicating that persistent storage be updated.\n\n### Wallet Properties\n\n        var address = this.client.getWalletAddress()\n\n        this.client.getWalletProperties(function (err, properties) {\n          if (err) return console.log(err)\n\n          console.log('wallet balance=' + properties.balance + 'BTC')\n        })\n\n### Wallet Recovery\n\n        this.client.recoverWallet(recoveryId, passPhrase, function (err, result) {\n          if (err) return console.log(err)\n\n          console.log('recovered amount=' + result.satoshis + ' satoshis')\n        })\n\n### Reconcilation, Part One\nThe client should periodically call:\n\n        var nowP = client.isReadyToReconcile()\n\nIf `true` is returned,\nthen it is time for the periodic reconcilation to occur.\n\nAlternatively,\n\n        var msec = client.timeUntilReconcile()\n\nwill return `false` if reconcilation is already underway,\nor the number of milliseconds before reconcilation should occur\n(a negative number indicates that reconcilation is overdue).\n\nIt may be necessary to reset the reconcilation timestamp,\n\n        var timestamp = new Date().getTime()  // reconcile now (for some reason)\n\n        this.client.setTimeUntilReconcile(timestamp, function (err, result) {\n          if (err) return console.log(err)\n\n          if (result) result must be put into persistent storage as the client's new state\n        })\n\nThe more likely invocation is\n\n        this.client.setTimeUntilReconcile(null, function (err, result) { ... })\n\nwhich resets the reconcilation timestamp.\n\n### Reconcilation, Part Deux\nWhen it is time to reconcile,\nthe client calls:\n\n        client.reconcile(viewingId, callback)\n\nThe `viewingId` parameter (if not `null) is a UUID v4 value,\nthat may be used for subequent calls to `vote()`.\n\n## Statistical Voting\nAfter a successful reconciliation,\nthe client is authorized to cast one or more ballots,\nas indicated by the `ballots` method.\nEach vote is cast using the `vote` method:\n\n    if (client.ballots() > 0) {\n      // select publisher identity\n      client.vote(publisher, viewingId)\n    }\n\nThe `viewingId` parameter is optional,\notherwise it should correspond to a value used in a previous call to the `reconcile` method.\n\n## Logging\nIf `options.loggingP` is true,\nthen the client may call\n\n    var entries = client.report()\n\nwhich returns either an array of (zero or more) logging entries.\nEach entry contains three fields:\n\n        { who  : function that made entry\n          what : { parameters }\n          when : timestamp (as milliseconds since epoch)\n        }\n\n## Examples\nThe file `blastoff.js` is a (non-sensical) example of how to use the API --\nit blasts through the various API calls,\ndoing a sanity check.\nInvoke using:\n\n    % npm run blastoff\n    ...\n    please click here for payment: bitcoin:...?amount=0.0083\n    ^C\n\n    // transfer funds to user wallet, wait as long (or as little) as you want\n\n    % npm run touchdown\n\nWhen reconciliation completes (but before voting occurs), the process will exit.\nExamine `config.json` to see the entry in the `transactions` array.\n", "release_dates": []}, {"name": "ledger-geoip", "description": "Find the geoip information for an IP address, do so using a list of geoip reporters that is weighted over time.", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# ledger-geoip\nFind the geoip information for an IP address, do so using a list of geoip reporters that is weighted over time.\n\n## API\n\n### Get the Country Code for your IP address\n\n        var getGeoIP = require('ledger-geoip').getGeoIP\n\n        getGeoIP(function (err, provider, result) {\n          if (err) return console.log((provider ? (provider.name + ': ') : '') + err.toString())\n\n          console.log('provider=' + provider.name + ' satoshis=' + result)\n        })\n\nThis method works by using a modified [round-robin](https://en.wikipedia.org/wiki/Round-robin_DNS) algorithm with a simple\nscoring system:\n\n- each time that `getGeoIP` is called, it shuffles the list of providers and then orders them according to each provider's score\n\n- each provider is tried in order and the first (successful) result is returned\n\n- if  the attempt is successful,\nthen the provider's score is set to a number between `-250` and `5000` that corresponds to the number of milli-seconds it to took to round-trip and process the request\n\n- if the attempt fails, then the provider score is set to one of:\n\n    - on DNS (or other network) error: -350;\n\n    - on timeout: -500;\n\n    - HTTP error: -750; or,\n\n    - on internal error: -1001 (thereby disqualifying the provider from further consideration)\n\n### Add to the list of Providers\n\nEach of these properties is mandatory:\n\n        require('ledger-geoip').providers.push({ name     : 'commonly-known name of provider'\n                                               , site     : 'https://example.com/'\n                                               , server   : 'https://api.example.com'\n                                               , path     : '\"/v1/address\" + address'\n                                               , addressP : true\n                                               , textP    : false\n                                               , iso3166  : 'body.country_code'\n                                               })\n\nThe default value for the `method` is `\"GET\"`;\n(or `\"POST\"` if the value for the `payload` property is present).\n\nBoth the mandatory `path` property and the optional `payload` property are evaluated with this context:\n\n        { address: '...' }\n\nwhere `address` is either the first argument to the `getGeoIP` function,\nor is determined by calling `whatIsMyIP`.\nThe context is initialize _only_ if the optional `addressP` property is set to `true`.\n\nThe mandatory `iso3166` property is evaluated with this context:\n\n        { body: JSON.parse(HTTP_response_body) }\n\nor\n\n        { lines: HTTP_response_body.split('\\n') }\n\ndepending on whether the optional `textP` property is present and set to `true`.\n\n## Finally...\n\nAll of the GeoIP reporters in this package are available using public APIs without any API key.\n\nIf you want to have your GeoIP reporter added to the package,\nplease send an email to [Brave Software](mailto:devops@brave.com?subject=ledger-geoip).\n\nIf you want to have your GeoIP reporter removed from the package,\nalso send an [email](mailto:devops@brave.com?subject=ledger-geoip).\n\nEnjoy!\n", "release_dates": []}, {"name": "ledger-publisher", "description": "Deprecated, please see", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# NOTE: This repo is deprecated, please see [bat-publisher](https://github.com/brave-intl/bat-publisher)\n# ledger-publisher\nRoutines to identify publishers for the [Brave ledger](https://github.com/brave/ledger):\n\n* [Mapping a URL to a Publisher Identity](#publisher-identities)\n* [Adding a Page Visit to a Browsing Synopsis](#page-visits)\n\n## Publisher Identities\nA _publisher identity_ is derived from a URL and is intended to correspond to the publisher associated with the URL.\n\n    var getPublisher = require('ledger-publisher').getPublisher\n\n    var publisher = getPublisher('URL')\n\nNote that because some domains host multiple publishers,\na publisher identity may contain both a _domain_ and a _path_ separated by a solidus(`/`).\n\nAlso note that certain URLs aren't really appropriate for a publisher mapping.\nFor example,\nif a URL returns a 302,\ndon't bother mapping that URL.\n\n### Terminology\nConsider this URL:\n\n    https://foo.bar.example.com/component1/...?query\n\nThe label `com` from the URL's domain is a [top-level domain](https://en.wikipedia.org/wiki/Top-level_domain) (TLD),\nand the string `example.com` is a [second-level domain](https://en.wikipedia.org/wiki/Second-level_domain) (SLD).\nBy convention,\nthe _relative domain_ (RLD) is the string to the left of the SLD (e.g., `foo.bar`),\nand the _qualifying label_ (QLD) is the right-most label of the RLD (e.g., `bar`).\n\nThere are two popular types of TLDs:\n[infrastructure](https://en.wikipedia.org/wiki/Top-level_domain#Infrastructure_domain)\nand [international country code](https://en.wikipedia.org/wiki/Internationalized_country_code_top-level_domain) (ccTLD).\n\nAlthough an SLD is normally thought of being the next-to-last right-most label (e.g., `example`),\nfor domains with a ccTLD,\nthe convention differs.\nConsider this URL:\n\n    http://search.yahoo.co.jp/search?query\n\nThe string `co.jp` corresponds to the TLD, the string `yahoo.co.jp` corresponds to the SLD,\nand the QLD and RLD are both the string `search`.\n\n### Syntax\nThe ABNF syntax for a publisher identity is:\n\n    publisher-identity = domain [ \"/\" segment ]\n\n                domain = [ RLD \".\" ] SLD\n                   RLD = *[ label \".\" ] QLD\n                   QLD = label\n                   SLD = label \".\" TLD\n                   TLD = infraTLD / ccTLD\n                 ccTLD = label \".\" 2ALPHA                ; a two-letter country code, cf. ISO 3166\n              infraTLD = label                           ; \".com\", \".gov\", etc.\n\n                 label = alphanum *62(alphanum / \"-\")    ; any octet encoded according to RFC 2181\n              alphanum = ALPHA / DIGIT\n\n               segment = *pchar                          ; as defined in Section 3.3 of RFC 3986\n\nNote that a publisher identity must not include either a fragment (`#...`) or a query (`?...`).\n\n    var isPublisher = require('ledger-publisher').isPublisher\n\n    if (isPublisher('...')) ...\n\n### Mapping\nThe package uses a rule set expressed as a [JavaScript](https://en.wikipedia.org/wiki/JavaScript) array.\n\nEach rule in the array consists of an object with one mandatory property,\n`condition`,\na JavaScript boolean expression.\nIn addition,\nthere is usually either a `consequent` property\n(a JavaScript expression returning either a string, `null`, or `undefined`),\nor a `dom` property.\n\nTo detetermine the publisher identity associated with a URL:\n\n1. If the TLD associated with the URL's domain does not correspond to an infrastructure or ccTLD,\nthen the publisher identity is `undefined`.\n\n2. The URL is parsed into an object using the [URL module](https://nodejs.org/api/url.html).\n\n3. The parsed object is extended with the `URL`, `TLD`, `SLD`, `RLD`, and `QLD` objects.\nIf there is no `RLD`, the empty string (`\"\"`) is used for both the `RLD` and `QLD`.\n\n4. If the `dom.publisher` property of the rule is present,\nthen the HTML associated with the URL must be present,\nand one additional object is present during evaluation,\n`node`, which is the result of `jsdom(markup).body.querySelector(dom.publisher.nodeSelector)`,\nand the `dom.publisher.consequent` property is used instead of the `consequent` property for the rule in Step 5.2.\n\n5. Each rule is examined, in order, starting from the first element:\n\n    5.1. If the `condition` evaluates to `false`,\nthen execution continues with the next rule.\n\n    5.2. Otherwise,\nthe `consequent` is evaluated.\n\n    5.3. If the resulting value is the empty string (`\"\"`),\nthen execution continues with the next rule.\n\n    5.4. If the resulting value is `false`, `null` or `undefined`,\nthen the publisher identity is `undefined`.\n\n    5.5. Otherwise,\nthe resulting value is used as the publisher identity.\n\n6. If Step 5.5 is never executed,\nthen the publisher identity is `undefined`.\n\nThe initial rule set is built by a NPM script:\n\n    npm run build-rules\n\nAn initial rule set is available as:\n\n    require('ledger-publisher').ruleset\n\n**NB: THAT IN PREVIOUS VERSIONS OF THIS PACKAGE, THE PROPERTY WAS CALLED** `rules` **NOT** `ruleset`\n\n### Your Help is Needed!\nPlease submit a [pull request](https://github.com/brave/ledger-publisher/pulls) with updates to the rule set.\n\nIf you are running the [Brave Browser](https://brave.com/downloads.html) on your desktop,\nyou can run\n\n    % node dump.js\n\nin order to examine all the URLs you have visited in your current session (from the file `session-store-1`)\nand see the resulting publisher identities.\n\n## Page Visits\nA _page visit_ is just what you'd expect,\nbut it requires both a URL and the duration of the focus (in milliseconds).\nA synopsis is a collection of page visits that have been reduced to a a publisher and a score.\nThe synopsis includes a rolling window so that older visits are removed.\n\n    var synopsis = new (require('ledger-publisher').Synopsis)()\n\n    // each time a page is unloaded, record the focus duration\n    // markup is an optional third-parameter, cf., getPublisher above\n        synopsis.addVisit('URL', duration)\n\n    // addVisit is a wrapper around addPublisher\n        synopsis.addPublisher(publisher, props)\n\nAt present,\nthese properties are examined:\n\n* `duration` - the number of milli-seconds (mandatory)\n\n* `markup` - the HTML markup (optional)\n\nIn order to calculate the score,\noptions can be provided when creating the object.\nThe defaults are:\n\n    { minPublisherDuration    : 8 * 1000\n    , numFrames      : 30\n    , frameSize      : 24 * 60 * 60 * 1000\n    }\n\nWhen `addVisit` is invoked,\nthe duration must be at least `minPublisherDuration` milliseconds in length.\nIf so,\nthen one or more \"scorekeepers\" are run to calculate the score for the visit,\nusing both the `options` and `props`.\nAt present,\nthere are two scorekeepers:\n\n* `concave` - courtesy of [@dimitry-xyz](https://github.com/brave/ledger/issues/2#issuecomment-221752002)\n\n* `visits` - the total number of visits\n\n### The Concave Scorekeeper\nThe concave scorekeeper rewards the publisher of a page according to:\n\n1. a fixed bonus for the page hit\n2. how much time the user spends on the page\n\nThe reward increases as the user spends more time on the page, but the model uses a\nconcave quadratic (utility) function to provide diminishing returns as the time spent\non the page increases. If we set the `durationWeight` parameter to zero, the model \nonly takes into account the page hit and ignores the time spent on the page when \ncalculating the reward.\n\n### Tuning\nScorekeepers may be \"tuned\" using options,\nat present,\nonly the `concave` scorekeeper makes use of these.\nThe defaults are:\n\n    { _d : 1 / (30 * 1000)              //    0.0000333...\n    , _a : (1 / (_d * 2)) - minPublisherDuration // 5000\n    , _b : minPublisherDuration - _a             // 5000\n    }\n\nThe sliding window consist of `numFrames` frames,\neach having a timeframe of `frameSize` milliseconds.\nSo, for the default values,\nthe sliding window will be `30` days long.\n\n### Top Publishers\nOnce a synopsis is underway,\nthe \"top N\" publishers can be determined.\nEach publisher will has an associated weighted score,\nso that the sum of the scores \"should approximate\" `1.0`:\n\n    // get the top \"N\" publishers\n\n       console.log(JSON.stringify(synopsis.topN(20), null, 2))\n\n    // e.g., [ { publisher: \"example.com\", weight 0.0123456789 } ... ]\n\nThe parameter to the `topN` method is optional.\n\nSimilarly,\nto pseudo-randomly select a single publisher,\nusing the weighted score:\n\n    // select a single publisher\n\n       console.log(synopsis.winner())\n\n    // e.g., \"brave.com\"\n\n    // or multiple winners\n\n       console.log(synopsis.winners(n))\n\n## Acknowledgements\nMany thanks to [Elijah Insua](https://github.com/tmpvar) for the excellent [jsdom](https://github.com/tmpvar/jsdom) package,\nand to [Thomas Parisot](https://github.com/oncletom) for the excellent [tldjs](https://github.com/oncletom/tld.js) package.\n", "release_dates": []}, {"name": "leo", "description": "Design tokens for the Brave's design system known as Leo", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Leo - Brave's Design System\n\n## Tokens\n\nThe tokens part of this package is supposed to be used together with the [Design Tokens plugin for Figma](https://github.com/lukasoppermann/design-tokens).\nIt transforms the exported design tokens using [Amazon style dictionary](https://amzn.github.io/style-dictionary/#/).\nDestination formats for these tokens include CSS variables, Tailwind configuration, C++ (skia variables), Java and Swift.\nThe output files will be created at `/build` by running `npm run transform-tokens` which will also run upon install - regularly or when this package is used as a dependency.\n\n## Components\n\nFor component creation see [components](src/components/README.md).\n\n**Note:** components depend on the [css variables](#css) so make sure they're available on your page somewhere.\n\n### Web Components\n\nWeb Component wrappers are generated at build time and are available in the top\nlevel `web-components` folder.\n\n### React\n\nReact wrappers are generated at build time and are available in the top level\n`react` folder.\n\n## CSS\n\nTo get started with the CSS variables exported, you must have the contents of `build/css/variables.css` included in your html page. Perhaps directly through a `<link rel=\"stylesheet\">` element, or indirectly through webpack's css-loader and `import '@brave/leo/build/css/variables.css'`.\n\n### Typography\n\nIndividual typography variables are available but so are convenient combined font declarations:\n\n```css\n--typography-text-default-regular-font-size: 14px;\n--typography-text-default-regular-letter-spacing: 0;\n--typography-text-default-regular-line-height: 20px;\n--typography-text-default-regular-paragraph-indent: 0;\n--typography-text-default-regular-paragraph-spacing: 0;\n\n--font-text-default-regular: 400 14px/20px Poppins;\n```\n\n### Colors\n\nAny color in Brave's standard or extended palettes is available in a dark and light versions:\n\n```css\n--color-light-text-primary: rgb(29, 31, 37);\n--color-dark-text-primary: rgb(236, 239, 242);\n```\n\nHowever, there are color variables which will select the light or dark version automatically:\n\n```css\n/* sometimes this */\n--color-text-primary: rgb(29, 31, 37);\n\n/* or this */\n--color-text-primary: rgb(236, 239, 242);\n```\n\nThe relevant light or dark version is selected by:\n\n- The current global `@media (prefers-color-scheme: [value])` value\n- The closest HTML ancestor with a `data-theme` attribute, e.g.\n\n```html\n<div class=\"footer\" data-theme=\"dark\">\n  <p style=\"color: var(--color-text-primary);\">I am always in dark mode</p>\n</div>\n```\n\nAll Web Components and css variables aim to use the color theme according to the nearest ancestor which defines an override using a `data-theme=\"[dark|light]\" attribute\n\n## Tailwind\n\nA tailwind config, complete with plugin, is available at `@brave/leo/build/tailwind/index.js`. Once you configure this, all variables should be available using the `theme()` function.\n", "release_dates": []}, {"name": "leo-sf-symbols", "description": "Automatically generate SF Symbols from Leo Icons", "language": null, "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Leo SF Symbols\n\nThis collection of SF Symbols is automatically generated from the icons in [Leo](https://github.com/brave/leo/tree/main/icons)\n\n## Automatic Updates\n\nStart the https://github.com/brave/leo-sf-symbols/actions/workflows/update.yml\nand the symbols will automatically be updated to what's in the latest version\nof [Leo](https://github.com/brave/leo).\n\nWhen https://github.com/brave/leo/pull/259 lands, this action will be run\nautomatically when branches are merged.\n\n## Manually Updating\n\n1. Run `npm update-leo` to upgrade to latest Leo (which may have new icons)\n2. Run `npm run gen-sf-symbols` to regenerate symbols\n\nOnce the `sf-icons` branch in Leo lands we can automatically update Leo.\n", "release_dates": []}, {"name": "level", "description": "Fast & simple storage - a Node.js-style LevelDB wrapper", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# level\n\n> Fast & simple storage. A Node.js-style `LevelDB` wrapper.\n\n[![level badge][level-badge]](https://github.com/level/awesome)\n[![npm](https://img.shields.io/npm/v/level.svg)](https://www.npmjs.com/package/level)\n![Node version](https://img.shields.io/node/v/level.svg)\n[![Build Status](https://secure.travis-ci.org/Level/level.png)](http://travis-ci.org/Level/level)\n[![dependencies](https://david-dm.org/Level/level.svg)](https://david-dm.org/level/level)\n[![JavaScript Style Guide](https://img.shields.io/badge/code_style-standard-brightgreen.svg)](https://standardjs.com)\n[![npm](https://img.shields.io/npm/dm/level.svg)](https://www.npmjs.com/package/level)\n\nA convenience package that:\n\n* exports a function that returns a [`levelup instance`](https://github.com/level/levelup#ctor) when invoked\n* bundles the current release of [`levelup`][levelup] and [`leveldown`][leveldown]\n* leverages encodings using [`encoding-down`][encoding-down]\n\nUse this package to avoid having to explicitly install `leveldown` when you just want plain old `LevelDB` from `levelup`.\n\n```js\nvar level = require('level')\n\n// 1) Create our database, supply location and options.\n//    This will create or open the underlying LevelDB store.\nvar db = level('./mydb')\n\n// 2) Put a key & value\ndb.put('name', 'Level', function (err) {\n  if (err) return console.log('Ooops!', err) // some kind of I/O error\n\n  // 3) Fetch by key\n  db.get('name', function (err, value) {\n    if (err) return console.log('Ooops!', err) // likely the key was not found\n\n    // Ta da!\n    console.log('name=' + value)\n  })\n})\n```\n\n<a name=\"api\"></a>\n## API\n\n  * <a href=\"#ctor\"><code><b>level()</b></code></a>\n  * <a href=\"#open\"><code>db.<b>open()</b></code></a>\n  * <a href=\"#close\"><code>db.<b>close()</b></code></a>\n  * <a href=\"#put\"><code>db.<b>put()</b></code></a>\n  * <a href=\"#get\"><code>db.<b>get()</b></code></a>\n  * <a href=\"#del\"><code>db.<b>del()</b></code></a>\n  * <a href=\"#batch\"><code>db.<b>batch()</b></code> *(array form)*</a>\n  * <a href=\"#batch_chained\"><code>db.<b>batch()</b></code> *(chained form)*</a>\n  * <a href=\"#isOpen\"><code>db.<b>isOpen()</b></code></a>\n  * <a href=\"#isClosed\"><code>db.<b>isClosed()</b></code></a>\n  * <a href=\"#createReadStream\"><code>db.<b>createReadStream()</b></code></a>\n  * <a href=\"#createKeyStream\"><code>db.<b>createKeyStream()</b></code></a>\n  * <a href=\"#createValueStream\"><code>db.<b>createValueStream()</b></code></a>\n\nSee [`levelup`][levelup] and [`leveldown`][leveldown] for more details.\n\n<a name=\"ctor\"></a>\n### `const db = level(location[, options[, callback]])`\nThe main entry point for creating a new `levelup` instance.\n\n- `location` path to the underlying `LevelDB`.\n- `options` is passed on to the underlying store.\n- `options.keyEncoding` and `options.valueEncoding` are passed to [`encoding-down`][encoding-down], default encoding is `'utf8'`\n\nCalling `level('./db')` will also open the underlying store. This is an asynchronous operation which will trigger your callback if you provide one. The callback should take the form `function (err, db) {}` where `db` is the `levelup` instance. If you don't provide a callback, any read & write operations are simply queued internally until the store is fully opened.\n\nThis leads to two alternative ways of managing a `levelup` instance:\n\n```js\nlevel(location, options, function (err, db) {\n  if (err) throw err\n\n  db.get('foo', function (err, value) {\n    if (err) return console.log('foo does not exist')\n    console.log('got foo =', value)\n  })\n})\n```\n\nVersus the equivalent:\n\n```js\n// Will throw if an error occurs\nconst db = level(location, options)\n\ndb.get('foo', function (err, value) {\n  if (err) return console.log('foo does not exist')\n  console.log('got foo =', value)\n})\n```\n\n<a name=\"open\"></a>\n### `db.open([callback])`\nOpens the underlying store. In general you should never need to call this method directly as it's automatically called by <a href=\"#ctor\"><code>levelup()</code></a>.\n\nHowever, it is possible to *reopen* the store after it has been closed with <a href=\"#close\"><code>close()</code></a>, although this is not generally advised.\n\nIf no callback is passed, a promise is returned.\n\n<a name=\"close\"></a>\n### `db.close([callback])`\n<code>close()</code> closes the underlying store. The callback will receive any error encountered during closing as the first argument.\n\nYou should always clean up your `levelup` instance by calling `close()` when you no longer need it to free up resources. A store cannot be opened by multiple instances of `levelup` simultaneously.\n\nIf no callback is passed, a promise is returned.\n\n<a name=\"put\"></a>\n### `db.put(key, value[, options][, callback])`\n<code>put()</code> is the primary method for inserting data into the store. Both `key` and `value` can be of any type as far as `levelup` is concerned.\n\n`options` is passed on to the underlying store.\n\nIf no callback is passed, a promise is returned.\n\n<a name=\"get\"></a>\n### `db.get(key[, options][, callback])`\n<code>get()</code> is the primary method for fetching data from the store. The `key` can be of any type. If it doesn't exist in the store then the callback or promise will receive an error. A not-found err object will be of type `'NotFoundError'` so you can `err.type == 'NotFoundError'` or you can perform a truthy test on the property `err.notFound`.\n\n```js\ndb.get('foo', function (err, value) {\n  if (err) {\n    if (err.notFound) {\n      // handle a 'NotFoundError' here\n      return\n    }\n    // I/O or other error, pass it up the callback chain\n    return callback(err)\n  }\n\n  // .. handle `value` here\n})\n```\n\n`options` is passed on to the underlying store.\n\nIf no callback is passed, a promise is returned.\n\n<a name=\"del\"></a>\n### `db.del(key[, options][, callback])`\n<code>del()</code> is the primary method for removing data from the store.\n```js\ndb.del('foo', function (err) {\n  if (err)\n    // handle I/O or other error\n});\n```\n\n`options` is passed on to the underlying store.\n\nIf no callback is passed, a promise is returned.\n\n<a name=\"batch\"></a>\n### `db.batch(array[, options][, callback])` *(array form)*\n<code>batch()</code> can be used for very fast bulk-write operations (both *put* and *delete*). The `array` argument should contain a list of operations to be executed sequentially, although as a whole they are performed as an atomic operation inside the underlying store.\n\nEach operation is contained in an object having the following properties: `type`, `key`, `value`, where the *type* is either `'put'` or `'del'`. In the case of `'del'` the `value` property is ignored. Any entries with a `key` of `null` or `undefined` will cause an error to be returned on the `callback` and any `type: 'put'` entry with a `value` of `null` or `undefined` will return an error.\n\nIf `key` and `value` are defined but `type` is not, it will default to `'put'`.\n\n```js\nconst ops = [\n  { type: 'del', key: 'father' },\n  { type: 'put', key: 'name', value: 'Yuri Irsenovich Kim' },\n  { type: 'put', key: 'dob', value: '16 February 1941' },\n  { type: 'put', key: 'spouse', value: 'Kim Young-sook' },\n  { type: 'put', key: 'occupation', value: 'Clown' }\n]\n\ndb.batch(ops, function (err) {\n  if (err) return console.log('Ooops!', err)\n  console.log('Great success dear leader!')\n})\n```\n\n`options` is passed on to the underlying store.\n\nIf no callback is passed, a promise is returned.\n\n<a name=\"batch_chained\"></a>\n### `db.batch()` *(chained form)*\n<code>batch()</code>, when called with no arguments will return a `Batch` object which can be used to build, and eventually commit, an atomic batch operation. Depending on how it's used, it is possible to obtain greater performance when using the chained form of `batch()` over the array form.\n\n```js\ndb.batch()\n  .del('father')\n  .put('name', 'Yuri Irsenovich Kim')\n  .put('dob', '16 February 1941')\n  .put('spouse', 'Kim Young-sook')\n  .put('occupation', 'Clown')\n  .write(function () { console.log('Done!') })\n```\n\n<b><code>batch.put(key, value)</code></b>\n\nQueue a *put* operation on the current batch, not committed until a `write()` is called on the batch.\n\nThis method may `throw` a `WriteError` if there is a problem with your put (such as the `value` being `null` or `undefined`).\n\n<b><code>batch.del(key)</code></b>\n\nQueue a *del* operation on the current batch, not committed until a `write()` is called on the batch.\n\nThis method may `throw` a `WriteError` if there is a problem with your delete.\n\n<b><code>batch.clear()</code></b>\n\nClear all queued operations on the current batch, any previous operations will be discarded.\n\n<b><code>batch.length</code></b>\n\nThe number of queued operations on the current batch.\n\n<b><code>batch.write([callback])</code></b>\n\nCommit the queued operations for this batch. All operations not *cleared* will be written to the underlying store atomically, that is, they will either all succeed or fail with no partial commits.\n\nIf no callback is passed, a promise is returned.\n\n<a name=\"isOpen\"></a>\n### `db.isOpen()`\n\nA `levelup` instance can be in one of the following states:\n\n  * *\"new\"*     - newly created, not opened or closed\n  * *\"opening\"* - waiting for the underlying store to be opened\n  * *\"open\"*    - successfully opened the store, available for use\n  * *\"closing\"* - waiting for the store to be closed\n  * *\"closed\"*  - store has been successfully closed, should not be used\n\n`isOpen()` will return `true` only when the state is \"open\".\n\n<a name=\"isClosed\"></a>\n### `db.isClosed()`\n\n*See <a href=\"#put\"><code>isOpen()</code></a>*\n\n`isClosed()` will return `true` only when the state is \"closing\" *or* \"closed\", it can be useful for determining if read and write operations are permissible.\n\n<a name=\"createReadStream\"></a>\n### `db.createReadStream([options])`\n\nReturns a [Readable Stream](https://nodejs.org/docs/latest/api/stream.html#stream_readable_streams) of key-value pairs. A pair is an object with `key` and `value` properties. By default it will stream all entries in the underlying store from start to end. Use the options described below to control the range, direction and results.\n\n```js\ndb.createReadStream()\n  .on('data', function (data) {\n    console.log(data.key, '=', data.value)\n  })\n  .on('error', function (err) {\n    console.log('Oh my!', err)\n  })\n  .on('close', function () {\n    console.log('Stream closed')\n  })\n  .on('end', function () {\n    console.log('Stream ended')\n  })\n```\n\nYou can supply an options object as the first parameter to `createReadStream()` with the following properties:\n\n* `gt` (greater than), `gte` (greater than or equal) define the lower bound of the range to be streamed. Only entries where the key is greater than (or equal to) this option will be included in the range. When `reverse=true` the order will be reversed, but the entries streamed will be the same.\n\n* `lt` (less than), `lte` (less than or equal) define the higher bound of the range to be streamed. Only entries where the key is less than (or equal to) this option will be included in the range. When `reverse=true` the order will be reversed, but the entries streamed will be the same.\n\n* `reverse` *(boolean, default: `false`)*: stream entries in reverse order. Beware that due to the way that stores like LevelDB work, a reverse seek can be slower than a forward seek.\n\n* `limit` *(number, default: `-1`)*: limit the number of entries collected by this stream. This number represents a *maximum* number of entries and may not be reached if you get to the end of the range first. A value of `-1` means there is no limit. When `reverse=true` the entries with the highest keys will be returned instead of the lowest keys.\n\n* `keys` *(boolean, default: `true`)*: whether the results should contain keys. If set to `true` and `values` set to `false` then results will simply be keys, rather than objects with a `key` property. Used internally by the `createKeyStream()` method.\n\n* `values` *(boolean, default: `true`)*: whether the results should contain values. If set to `true` and `keys` set to `false` then results will simply be values, rather than objects with a `value` property. Used internally by the `createValueStream()` method.\n\nLegacy options:\n\n* `start`: instead use `gte`\n\n* `end`: instead use `lte`\n\n<a name=\"createKeyStream\"></a>\n### `db.createKeyStream([options])`\n\nReturns a [Readable Stream](https://nodejs.org/docs/latest/api/stream.html#stream_readable_streams) of keys rather than key-value pairs. Use the same options as described for [`createReadStream`](#createReadStream) to control the range and direction.\n\nYou can also obtain this stream by passing an options object to `createReadStream()` with `keys` set to `true` and `values` set to `false`. The result is equivalent; both streams operate in [object mode](https://nodejs.org/docs/latest/api/stream.html#stream_object_mode).\n\n```js\ndb.createKeyStream()\n  .on('data', function (data) {\n    console.log('key=', data)\n  })\n\n// same as:\ndb.createReadStream({ keys: true, values: false })\n  .on('data', function (data) {\n    console.log('key=', data)\n  })\n```\n\n<a name=\"createValueStream\"></a>\n### `db.createValueStream([options])`\n\nReturns a [Readable Stream](https://nodejs.org/docs/latest/api/stream.html#stream_readable_streams) of values rather than key-value pairs. Use the same options as described for [`createReadStream`](#createReadStream) to control the range and direction.\n\nYou can also obtain this stream by passing an options object to `createReadStream()` with `values` set to `true` and `keys` set to `false`. The result is equivalent; both streams operate in [object mode](https://nodejs.org/docs/latest/api/stream.html#stream_object_mode).\n\n```js\ndb.createValueStream()\n  .on('data', function (data) {\n    console.log('value=', data)\n  })\n\n// same as:\ndb.createReadStream({ keys: false, values: true })\n  .on('data', function (data) {\n    console.log('value=', data)\n  })\n```\n\n<a name=\"promises\"></a>\n## Promise Support\n\n`level` ships with native `Promise` support out of the box.\n\nEach function taking a callback also can be used as a promise, if the callback is omitted. This applies for:\n\n- `db.get(key[, options])`\n- `db.put(key, value[, options])`\n- `db.del(key[, options])`\n- `db.batch(ops[, options])`\n- `db.batch().write()`\n\nThe only exception is the `level` constructor itself, which if no callback is passed will lazily open the underlying store in the background.\n\nExample:\n\n```js\nconst db = level('./my-db')\n\ndb.put('foo', 'bar')\n  .then(function () { return db.get('foo') })\n  .then(function (value) { console.log(value) })\n  .catch(function (err) { console.error(err) })\n```\n\nOr using `async/await`:\n\n```js\nconst main = async () => {\n  const db = level('./my-db')\n\n  await db.put('foo', 'bar')\n  console.log(await db.get('foo'))\n}\n```\n\n<a name=\"events\"></a>\n## Events\n\n`levelup` is an [`EventEmitter`](https://nodejs.org/api/events.html) and emits the following events.\n\n| Event     | Description                 | Arguments            |\n|:----------|:----------------------------|:---------------------|\n| `put`     | Key has been updated        | `key, value` (any)   |\n| `del`     | Key has been deleted        | `key` (any)          |\n| `batch`   | Batch has executed          | `operations` (array) |\n| `opening` | Underlying store is opening | -                    |\n| `open`    | Store has opened            | -                    |\n| `ready`   | Alias of `open`             | -                    |\n| `closing` | Store is closing            | -                    |\n| `closed`  | Store has closed.           | -                    |\n\nFor example you can do:\n\n```js\ndb.on('put', function (key, value) {\n  console.log('inserted', { key, value })\n})\n```\n\n<a name=\"contributing\"></a>\n## Contributing\n\n`level` is an **OPEN Open Source Project**. This means that:\n\n> Individuals making significant and valuable contributions are given commit-access to the project to contribute as they see fit. This project is more like an open wiki than a standard guarded open source project.\n\nSee the [`CONTRIBUTING.md`](https://github.com/Level/community/blob/master/CONTRIBUTING.md) file for more details.\n\n<a name=\"license\"></a>\n## License &amp; Copyright\n\nCopyright (c) 2012-2017 `level` [contributors](https://github.com/level/community#contributors).\n\n`level` is licensed under the MIT license. All rights not explicitly granted in the MIT license are reserved. See the included `LICENSE.md` file for more details.\n\n[level-badge]: http://leveldb.org/img/badge.svg\n[levelup]: https://github.com/level/levelup\n[leveldown]: https://github.com/level/leveldown\n[encoding-down]: https://github.com/level/encoding-down\n", "release_dates": []}, {"name": "leveldown", "description": "Pure C++ Node.js LevelDB binding serving as the back-end to LevelUP", "language": "C++", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "leveldown\n=========\n\n[![level badge][level-badge]](https://github.com/level/awesome)\n[![npm](https://img.shields.io/npm/v/leveldown.svg)](https://www.npmjs.com/package/leveldown)\n![Node version](https://img.shields.io/node/v/leveldown.svg)\n[![Travis](https://img.shields.io/travis/Level/leveldown.svg?label=travis)](http://travis-ci.org/Level/leveldown)\n[![AppVeyor](https://img.shields.io/appveyor/ci/Level/leveldown.svg?label=appveyor)](https://ci.appveyor.com/project/Level/leveldown)\n[![dependencies](https://david-dm.org/Level/leveldown.svg)](https://david-dm.org/level/leveldown)\n[![npm](https://img.shields.io/npm/dm/leveldown.svg)](https://www.npmjs.com/package/leveldown)\n\n  * <a href=\"#intro\">Introduction</a>\n  * <a href=\"#platforms\">Supported platforms</a>\n  * <a href=\"#api\">API</a>\n  * <a href=\"#safety\">Safety</a>\n  * <a href=\"#snapshots\">Snapshots</a>\n  * <a href=\"#support\">Getting support</a>\n  * <a href=\"#contributing\">Contributing</a>\n  * <a href=\"#license\">Licence &amp; copyright</a>\n\n<a name=\"intro\"></a>\nIntroduction\n----------------------------\n\nThis module was originally part of [`levelup`](https://github.com/level/levelup) but was later extracted and now serves as a stand-alone binding for LevelDB.\n\nIt is **strongly recommended** that you use `levelup` in preference to `leveldown` unless you have measurable performance reasons to do so. `levelup` is optimised for usability and safety. Although we are working to improve the safety of the `leveldown` interface it is still easy to crash your Node process if you don't do things in just the right way.\n\nSee the section on <a href=\"#safety\">safety</a> below for details of known unsafe operations with `leveldown`.\n\n<a name=\"platforms\"></a>\nSupported platforms\n----------------------------\n\nWe aim to support *at least* Active LTS and Current Node.js releases. `leveldown` ships with prebuilt binaries for [many platforms](https://github.com/Level/leveldown/releases) and is known to work on:\n\n* **Linux** (including ARM platforms such as Raspberry Pi *and Kindle!*)\n* **Mac OS**\n* **Solaris** (SmartOS & Nodejitsu)\n* **FreeBSD**\n* **Windows**\n\nWhen installing `leveldown`, [`prebuild-install`](https://github.com/prebuild/prebuild-install) will install prebuilt binaries from GitHub if they exist and fallback to a compile step if they don't. In that case you'll need a [valid `node-gyp` installation](https://github.com/nodejs/node-gyp#installation).\n\nIf you don't want to use the prebuilt binary for the platform you are installing on, specify the `--build-from-source` flag when you install. If you are working on `leveldown` itself and want to re-compile the C++ code it's enough to do `npm install`.\n\n<a name=\"api\"></a>\n## API\n\n  * <a href=\"#ctor\"><code><b>leveldown()</b></code></a>\n  * <a href=\"#leveldown_open\"><code><b>leveldown#open()</b></code></a>\n  * <a href=\"#leveldown_close\"><code><b>leveldown#close()</b></code></a>\n  * <a href=\"#leveldown_put\"><code><b>leveldown#put()</b></code></a>\n  * <a href=\"#leveldown_get\"><code><b>leveldown#get()</b></code></a>\n  * <a href=\"#leveldown_del\"><code><b>leveldown#del()</b></code></a>\n  * <a href=\"#leveldown_batch\"><code><b>leveldown#batch()</b></code></a>\n  * <a href=\"#leveldown_approximateSize\"><code><b>leveldown#approximateSize()</b></code></a>\n  * <a href=\"#leveldown_compactRange\"><code><b>leveldown#compactRange()</b></code></a>\n  * <a href=\"#leveldown_getProperty\"><code><b>leveldown#getProperty()</b></code></a>\n  * <a href=\"#leveldown_iterator\"><code><b>leveldown#iterator()</b></code></a>\n  * <a href=\"#iterator_next\"><code><b>iterator#next()</b></code></a>\n  * <a href=\"#iterator_seek\"><code><b>iterator#seek()</b></code></a>\n  * <a href=\"#iterator_end\"><code><b>iterator#end()</b></code></a>\n  * <a href=\"#leveldown_destroy\"><code><b>leveldown.destroy()</b></code></a>\n  * <a href=\"#leveldown_repair\"><code><b>leveldown.repair()</b></code></a>\n\n\n--------------------------------------------------------\n<a name=\"ctor\"></a>\n### leveldown(location)\n<code>leveldown()</code> returns a new `leveldown` instance. `location` is a String pointing to the LevelDB location to be opened.\n\n\n--------------------------------------------------------\n<a name=\"leveldown_open\"></a>\n### leveldown#open([options, ]callback)\n<code>open()</code> is an instance method on an existing database object.\n\nThe `callback` function will be called with no arguments when the database has been successfully opened, or with a single `error` argument if the open operation failed for any reason.\n\n#### `options`\n\nThe optional `options` argument may contain:\n\n* `createIfMissing` *(boolean, default: `true`)*: If `true`, will initialise an empty database at the specified location if one doesn't already exist. If `false` and a database doesn't exist you will receive an error in your `open()` callback and your database won't open.\n\n* `errorIfExists` *(boolean, default: `false`)*: If `true`, you will receive an error in your `open()` callback if the database exists at the specified location.\n\n* `compression` *(boolean, default: `true`)*: If `true`, all *compressible* data will be run through the Snappy compression algorithm before being stored. Snappy is very fast and shouldn't gain much speed by disabling so leave this on unless you have good reason to turn it off.\n\n* `cacheSize` *(number, default: `8 * 1024 * 1024` = 8MB)*: The size (in bytes) of the in-memory [LRU](http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used) cache with frequently used uncompressed block contents.\n\n**Advanced options**\n\nThe following options are for advanced performance tuning. Modify them only if you can prove actual benefit for your particular application.\n\n* `writeBufferSize` *(number, default: `4 * 1024 * 1024` = 4MB)*: The maximum size (in bytes) of the log (in memory and stored in the .log file on disk). Beyond this size, LevelDB will convert the log data to the first level of sorted table files. From the LevelDB documentation:\n\n> Larger values increase performance, especially during bulk loads. Up to two write buffers may be held in memory at the same time, so you may wish to adjust this parameter to control memory usage. Also, a larger write buffer will result in a longer recovery time the next time the database is opened.\n\n* `blockSize` *(number, default `4096` = 4K)*: The *approximate* size of the blocks that make up the table files. The size related to uncompressed data (hence \"approximate\"). Blocks are indexed in the table file and entry-lookups involve reading an entire block and parsing to discover the required entry.\n\n* `maxOpenFiles` *(number, default: `1000`)*: The maximum number of files that LevelDB is allowed to have open at a time. If your data store is likely to have a large working set, you may increase this value to prevent file descriptor churn. To calculate the number of files required for your working set, divide your total data by `'maxFileSize'`.\n\n* `blockRestartInterval` *(number, default: `16`)*: The number of entries before restarting the \"delta encoding\" of keys within blocks. Each \"restart\" point stores the full key for the entry, between restarts, the common prefix of the keys for those entries is omitted. Restarts are similar to the concept of keyframes in video encoding and are used to minimise the amount of space required to store keys. This is particularly helpful when using deep namespacing / prefixing in your keys.\n\n* `maxFileSize` *(number, default: `2* 1024 * 1024` = 2MB)*: The maximum amount of bytes to write to a file before switching to a new one. From the LevelDB documentation:\n\n> ... if your filesystem is more efficient with larger files, you could consider increasing the value. The downside will be longer compactions and hence longer latency/performance hiccups. Another reason to increase this parameter might be when you are initially populating a large database.\n\n--------------------------------------------------------\n<a name=\"leveldown_close\"></a>\n### leveldown#close(callback)\n<code>close()</code> is an instance method on an existing database object. The underlying LevelDB database will be closed and the `callback` function will be called with no arguments if the operation is successful or with a single `error` argument if the operation failed for any reason.\n\n\n--------------------------------------------------------\n<a name=\"leveldown_put\"></a>\n### leveldown#put(key, value[, options], callback)\n<code>put()</code> is an instance method on an existing database object, used to store new entries, or overwrite existing entries in the LevelDB store.\n\nThe `key` and `value` objects may either be strings or Buffers. Other object types are converted to strings with the `toString()` method. Keys may not be `null` or `undefined` and objects converted with `toString()` should not result in an empty-string. Values of `null`, `undefined`, `''`, `[]` and `new Buffer(0)` (and any object resulting in a `toString()` of one of these) will be stored as a zero-length character array and will therefore be retrieved as either `''` or `new Buffer(0)` depending on the type requested.\n\nA richer set of data-types is catered for in `levelup`.\n\n#### `options`\n\nThe only property currently available on the `options` object is `sync` *(boolean, default: `false`)*. If you provide a `sync` value of `true` in your `options` object, LevelDB will perform a synchronous write of the data; although the operation will be asynchronous as far as Node is concerned. Normally, LevelDB passes the data to the operating system for writing and returns immediately, however a synchronous write will use `fsync()` or equivalent so your callback won't be triggered until the data is actually on disk. Synchronous filesystem writes are **significantly** slower than asynchronous writes but if you want to be absolutely sure that the data is flushed then you can use `{ sync: true }`.\n\nThe `callback` function will be called with no arguments if the operation is successful or with a single `error` argument if the operation failed for any reason.\n\n\n--------------------------------------------------------\n<a name=\"leveldown_get\"></a>\n### leveldown#get(key[, options], callback)\n<code>get()</code> is an instance method on an existing database object, used to fetch individual entries from the LevelDB store.\n\nThe `key` object may either be a string or a Buffer and cannot be `undefined` or `null`. Other object types are converted to strings with the `toString()` method and the resulting string *may not* be a zero-length. A richer set of data-types is catered for in `levelup`.\n\nValues fetched via `get()` that are stored as zero-length character arrays (`null`, `undefined`, `''`, `[]`, `new Buffer(0)`) will return as empty-`String` (`''`) or `new Buffer(0)` when fetched with `asBuffer: true` (see below).\n\n#### `options`\n\nThe optional `options` object may contain:\n\n* `fillCache` *(boolean, default: `true`)*: LevelDB will by default fill the in-memory LRU Cache with data from a call to get. Disabling this is done by setting `fillCache` to `false`.\n\n* `asBuffer` *(boolean, default: `true`)*: Used to determine whether to return the `value` of the entry as a string or a Buffer. Note that converting from a Buffer to a string incurs a cost so if you need a string (and the `value` can legitimately become a UTF8 string) then you should fetch it as one with `{ asBuffer: true }` and you'll avoid this conversion cost.\n\nThe `callback` function will be called with a single `error` if the operation failed for any reason. If successful the first argument will be `null` and the second argument will be the `value` as a string or Buffer depending on the `asBuffer` option.\n\n\n--------------------------------------------------------\n<a name=\"leveldown_del\"></a>\n### leveldown#del(key[, options], callback)\n<code>del()</code> is an instance method on an existing database object, used to delete entries from the LevelDB store.\n\nThe `key` object may either be a string or a Buffer and cannot be `undefined` or `null`. Other object types are converted to strings with the `toString()` method and the resulting string *may not* be a zero-length. A richer set of data-types is catered for in `levelup`.\n\n#### `options`\n\nThe only property currently available on the `options` object is `sync` *(boolean, default: `false`)*. See <a href=\"#leveldown_put\">leveldown#put()</a> for details about this option.\n\nThe `callback` function will be called with no arguments if the operation is successful or with a single `error` argument if the operation failed for any reason.\n\n\n--------------------------------------------------------\n<a name=\"leveldown_batch\"></a>\n### leveldown#batch(operations[, options], callback)\n<code>batch()</code> is an instance method on an existing database object. Used for very fast bulk-write operations (both *put* and *delete*). The `operations` argument should be an `Array` containing a list of operations to be executed sequentially, although as a whole they are performed as an atomic operation inside LevelDB.\n\nEach operation is contained in an object having the following properties: `type`, `key`, `value`, where the *type* is either `'put'` or `'del'`. In the case of `'del'` the `'value'` property is ignored. Any entries with a `'key'` of `null` or `undefined` will cause an error to be returned on the `callback`. Any entries where the *type* is `'put'` that have a `'value'` of `undefined`, `null`, `[]`, `''` or `new Buffer(0)` will be stored as a zero-length character array and therefore be fetched during reads as either `''` or `new Buffer(0)` depending on how they are requested.\n\nSee [`levelup`](https://github.com/level/levelup#batch) for full documentation on how this works in practice.\n\n#### `options`\n\nThe only property currently available on the `options` object is `sync` *(boolean, default: `false`)*. See <a href=\"#leveldown_put\">leveldown#put()</a> for details about this option.\n\nThe `callback` function will be called with no arguments if the operation is successful or with a single `error` argument if the operation failed for any reason.\n\n\n--------------------------------------------------------\n<a name=\"leveldown_approximateSize\"></a>\n### leveldown#approximateSize(start, end, callback)\n<code>approximateSize()</code> is an instance method on an existing database object. Used to get the approximate number of bytes of file system space used by the range `[start..end)`. The result may not include recently written data.\n\nThe `start` and `end` parameters may be strings or Buffers representing keys in the LevelDB store.\n\nThe `callback` function will be called with no arguments if the operation is successful or with a single `error` argument if the operation failed for any reason.\n\n\n--------------------------------------------------------\n<a name=\"leveldown_compactRange\"></a>\n### leveldown#compactRange(start, end, callback)\n<code>compactRange()</code> is an instance method on an existing database object. Used to manually trigger a database compaction in the range `[start..end)`.\n\nThe `start` and `end` parameters may be strings or Buffers representing keys in the LevelDB store.\n\nThe `callback` function will be called with no arguments if the operation is successful or with a single `error` argument if the operation failed for any reason.\n\n\n--------------------------------------------------------\n<a name=\"leveldown_getProperty\"></a>\n### leveldown#getProperty(property)\n<code>getProperty</code> can be used to get internal details from LevelDB. When issued with a valid property string, a readable string will be returned (this method is synchronous).\n\nCurrently, the only valid properties are:\n\n* <b><code>'leveldb.num-files-at-levelN'</code></b>: return the number of files at level *N*, where N is an integer representing a valid level (e.g. \"0\").\n\n* <b><code>'leveldb.stats'</code></b>: returns a multi-line string describing statistics about LevelDB's internal operation.\n\n* <b><code>'leveldb.sstables'</code></b>: returns a multi-line string describing all of the *sstables* that make up contents of the current database.\n\n\n--------------------------------------------------------\n<a name=\"leveldown_iterator\"></a>\n### leveldown#iterator([options])\n<code>iterator()</code> is an instance method on an existing database object. It returns a new **Iterator** instance.\n\n#### `options`\n\nThe optional `options` object may contain:\n\n* `gt` (greater than), `gte` (greater than or equal) define the lower bound of the values to be fetched and will determine the starting point where `reverse` is *not* `true`. Only records where the key is greater than (or equal to) this option will be included in the range. When `reverse` is `true` the order will be reversed, but the records returned will be the same.\n\n* `lt` (less than), `lte` (less than or equal) define the higher bound of the range to be fetched and will determine the starting point where `reverse` is *not* `true`. Only records where the key is less than (or equal to) this option will be included in the range. When `reverse` is `true` the order will be reversed, but the records returned will be the same.\n\n* `start, end` legacy ranges - instead use `gte, lte`\n\n* `reverse` *(boolean, default: `false`)*: a boolean, set to `true` if you want the stream to go in reverse order. Beware that due to the way LevelDB works, a reverse seek will be slower than a forward seek.\n\n* `keys` *(boolean, default: `true`)*: whether the callback to the `next()` method should receive a non-null `key`. There is a small efficiency gain if you ultimately don't care what the keys are as they don't need to be converted and copied into JavaScript.\n\n* `values` *(boolean, default: `true`)*: whether the callback to the `next()` method should receive a non-null `value`. There is a small efficiency gain if you ultimately don't care what the values are as they don't need to be converted and copied into JavaScript.\n\n* `limit` *(number, default: `-1`)*: limit the number of results collected by this iterator. This number represents a *maximum* number of results and may not be reached if you get to the end of the store or your `end` value first. A value of `-1` means there is no limit.\n\n* `fillCache` *(boolean, default: `false`)*: whether LevelDB's LRU-cache should be filled with data read.\n\n* `keyAsBuffer` *(boolean, default: `true`)*: Used to determine whether to return the `key` of each entry as a string or a Buffer. Note that converting from a Buffer to a string incurs a cost so if you need a string (and the `value` can legitimately become a UTF8 string) then you should fetch it as one.\n\n* `valueAsBuffer` *(boolean, default: `true`)*: Used to determine whether to return the `value` of each entry as a string or a Buffer.\n\n\n--------------------------------------------------------\n<a name=\"iterator_next\"></a>\n### iterator#next(callback)\n<code>next()</code> is an instance method on an existing iterator object, used to increment the underlying LevelDB iterator and return the entry at that location.\n\nthe `callback` function will be called with no arguments in any of the following situations:\n\n* the iterator comes to the end of the store\n* the `end` key has been reached; or\n* the `limit` has been reached; or\n* the last `seek()` was out of range\n\nOtherwise, the `callback` function will be called with the following 3 arguments:\n\n* `error` - any error that occurs while incrementing the iterator.\n* `key` - either a string or a Buffer depending on the `keyAsBuffer` argument when the `iterator()` was called.\n* `value` - either a string or a Buffer depending on the `valueAsBuffer` argument when the `iterator()` was called.\n\n\n--------------------------------------------------------\n<a name=\"iterator_seek\"></a>\n### iterator#seek(key)\n<code>seek()</code> is an instance method on an existing iterator object, used to seek the underlying LevelDB iterator to a given key.\n\nBy calling <code>seek(key)</code>, subsequent calls to <code>next(cb)</code> will return key/values larger or smaller than `key`, based on your <code>reverse</code> setting in the iterator constructor.\n\n--------------------------------------------------------\n<a name=\"iterator_end\"></a>\n### iterator#end(callback)\n<code>end()</code> is an instance method on an existing iterator object. The underlying LevelDB iterator will be deleted and the `callback` function will be called with no arguments if the operation is successful or with a single `error` argument if the operation failed for any reason.\n\n\n--------------------------------------------------------\n<a name=\"leveldown_destroy\"></a>\n### leveldown.destroy(location, callback)\n<code>destroy()</code> is used to completely remove an existing LevelDB database directory. You can use this function in place of a full directory *rm* if you want to be sure to only remove LevelDB-related files. If the directory only contains LevelDB files, the directory itself will be removed as well. If there are additional, non-LevelDB files in the directory, those files, and the directory, will be left alone.\n\nThe callback will be called when the destroy operation is complete, with a possible `error` argument.\n\n--------------------------------------------------------\n<a name=\"leveldown_repair\"></a>\n### leveldown.repair(location, callback)\n<code>repair()</code> can be used to attempt a restoration of a damaged LevelDB store. From the LevelDB documentation:\n\n> If a DB cannot be opened, you may attempt to call this method to resurrect as much of the contents of the database as possible. Some data may be lost, so be careful when calling this function on a database that contains important information.\n\nYou will find information on the *repair* operation in the *LOG* file inside the store directory.\n\nA `repair()` can also be used to perform a compaction of the LevelDB log into table files.\n\nThe callback will be called when the repair operation is complete, with a possible `error` argument.\n\n\n<a name=\"safety\"></a>\nSafety\n------\n\n### Database state\n\nCurrently `leveldown` does not track the state of the underlying LevelDB instance. This means that calling `open()` on an already open database may result in an error. Likewise, calling any other operation on a non-open database may result in an error.\n\n`levelup` currently tracks and manages state and will prevent out-of-state operations from being send to `leveldown`. If you use `leveldown` directly then you must track and manage state for yourself.\n\n<a name=\"snapshots\"></a>\nSnapshots\n---------------\n\n`leveldown` exposes a feature of LevelDB called [snapshots](https://github.com/google/leveldb/blob/master/doc/index.md#snapshots). This means that when you do e.g. `createReadStream` and `createWriteStream` at the same time, any data modified by the write stream will not affect data emitted from the read stream. In other words, a LevelDB Snapshot captures the latest state at the time the snapshot was created, enabling the snapshot to iterate or read the data without seeing any subsequent writes. Any read not performed on a snapshot will implicitly use the latest state.\n\n<a name=\"support\"></a>\nGetting support\n---------------\n\nThere are multiple ways you can find help in using LevelDB in Node.js:\n\n * **IRC:** you'll find an active group of `levelup` users in the **##leveldb** channel on Freenode, including most of the contributors to this project.\n * **Mailing list:** there is an active [Node.js LevelDB](https://groups.google.com/forum/#!forum/node-levelup) Google Group.\n * **GitHub:** you're welcome to open an issue here on this GitHub repository if you have a question.\n\n<a name=\"contributing\"></a>\nContributing\n------------\n\n`leveldown` is an **OPEN Open Source Project**. This means that:\n\n> Individuals making significant and valuable contributions are given commit-access to the project to contribute as they see fit. This project is more like an open wiki than a standard guarded open source project.\n\nSee the [contribution guide](https://github.com/Level/community/blob/master/CONTRIBUTING.md) for more details.\n\n### Windows\n\nA large portion of the Windows support comes from code by [Krzysztof Kowalczyk](http://blog.kowalczyk.info/) [@kjk](https://twitter.com/kjk), see his Windows LevelDB port [here](http://code.google.com/r/kkowalczyk-leveldb/). If you're using `leveldown` on Windows, you should give him your thanks!\n\n<a name=\"license\"></a>\nLicense &amp; copyright\n-------------------\n\nCopyright &copy; 2012-2017 `leveldown` [contributors](https://github.com/level/community#contributors).\n\n`leveldown` is licensed under the MIT license. All rights not explicitly granted in the MIT license are reserved. See the included `LICENSE.md` file for more details.\n\n*`leveldown` builds on the excellent work of the LevelDB and Snappy teams from Google and additional contributors. LevelDB and Snappy are both issued under the [New BSD Licence](http://opensource.org/licenses/BSD-3-Clause).*\n\n[level-badge]: http://leveldb.org/img/badge.svg\n", "release_dates": []}, {"name": "lib-jitsi-meet", "description": "A low-level JS video API that allows adding a completely custom video experience to web apps.", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Jitsi Meet API library\n\nYou can use Jitsi Meet API to create Jitsi Meet video conferences with a custom GUI.\n\n## Installation\n\n[Checkout the examples.](doc/API.md#installation)\n\n## Building the sources\n\nTo build the library, just type:\n```\nnpm install\n```\nTo lint:\n```\nnpm run lint\n```\nand to run unit tests:\n```\nnpm test\n```\nBoth linting and units will also be done by a pre-commit hook.\n", "release_dates": []}, {"name": "libchromiumcontent", "description": "Shared library build of Chromium\u2019s Content module", "language": "Python", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# libchromiumcontent\n\nA single, shared library that includes the [Chromium Content\nmodule](http://www.chromium.org/developers/content-module) and all its\ndependencies (e.g., Blink, V8, etc.).\n\n## Using it in your app\n\nTODO\n\n## Development\n\n### Prerequisites\n\n* [Linux](https://chromium.googlesource.com/chromium/src/+/master/docs/linux_build_instructions_prerequisites.md)\n* [Mac](https://chromium.googlesource.com/chromium/src/+/master/docs/mac_build_instructions.md#Prerequisites)\n* [Windows](http://dev.chromium.org/developers/how-tos/build-instructions-windows)\n\n### One-time setup\n\n    $ script/bootstrap\n\n### Building\n\n    $ script/update -t x64\n    $ script/build -t x64\n\n### Updating project files\n\nIf you change `VERSION` to point to a different Chromium release, or modify\n`chromiumcontent.gyp{,i}`, you should run:\n\n    $ script/update\n\nThis will regenerate all the project files. Then you can build again.\n\n### Building for ARM target\n\n```bash\n$ ./script/bootstrap\n$ ./script/update -t arm\n$ cd vendor/chromium/src\n$ ./build/install-build-deps.sh --arm\n$ ./chrome/installer/linux/sysroot_scripts/install-debian.wheezy.sysroot.py --arch=arm\n$ cd -\n$ ./script/build -t arm\n```\n", "release_dates": []}, {"name": "link-bubble", "description": "Brave Link Bubble Browser", "language": "Java", "license": null, "readme": "# Brave for Android (formerly Link Bubble)\n\n##Install instructions and setup\n\n`git clone git@github.com:brave/browser-android.git`\n\nEither install the [Crashlytics/Fabric Android Studio plugin](http://try.crashlytics.com/sdk-android/) or copy `Application/LinkBubble/fabric.properties.template` to `Application/LinkBubble/fabric.properties` and fill in the apiSecret.\n\nCopy `Application/LinkBubble/src/main/java/com/linkbubble/ConfigAPIs.java.template` to `Application/LinkBubble/src/main/java/com/linkbubble/ConfigAPIs.java` and fill in the youtube apiSecret.\n\nCopy `Application/LinkBubble/src/main/AndroidManifest.xml.template` to `Application/LinkBubble/src/main/AndroidManifest.xml` and fill in `com.crashlytics.ApiKey` and\n`io.fabric.ApiKey` with your Crashlytics API key. You can obtain it from logging into your Fabric account and going to: `Settings -> Organizations -> Brave (or your organization)` then click on `API Key` at the top.\n\nnpm install\n\n##Building\n\nOpen `./Application/` in Android Studio and build.  You'll need the NDK installed if you don't already have it, instructions below.\n\n##Building release build\n\nCopy `build-release.sh.template` to `build-release.sh`.\n\nModify each of these exported environment variables: `LINK_BUBBLE_KEYSTORE_LOCATION`, `LINK_BUBBLE_KEYSTORE_PASSWORD`, and `LINK_BUBBLE_KEY_PASSWORD`.\n\nIf you get an error about similar to:\n\n> Failure [INSTALL_PARSE_FAILED_INCONSISTENT_CERTIFICATES]\n\nTry uninstalling the application which already exists on your plugged in device.\n\n##Installing the NDK\n\nAndroid Studio has an easy way to download and link to the NDK.\n\nIn the menu navigate to File, Project Structure. Click the 'Download Android NDK' link. This should download and unzip the NDK, as well as link it inside of local.properties.\n\nIf you are not using Android Studio, reference this commit: https://github.com/brave/browser-android/commit/0fa9f58286e0679ec5772e19b995d6a508907691\n\n##Telling getlocalization.com about new strings\n\n1. Periodically upload the file `./Application/LinkBubble/src/main/res/values/strings.xml` to [getlocalization.com](https://www.getlocalization.com/LinkBubble/files/).  getlocalization.com will determine which strings are new\n2. When prompted on getlocalization.com, press the mark for retranslation (or keep existing) for changed strings.\n\n##Getting new translated strings from getlocalization.com\n\n1. Install npm dependencies with `npm install`.\n2. Run `npm run translate <username> <password>` to pull down the translated xml files.\n3. Commit and push your change.\n\nRemember to uncomment `checkStrings` from `MainApplication` and call it in `onCreate` to make sure the pulled files don't cause crashes with format specifiers.\n\n##ADB\n\nIf you don't have `adb` in your path add it to your `~/.bash_profile` or similar file:\n\n`export PATH=/Users/<your-username>/Library/Android/sdk/platform-tools:$PATH`\n\n- **Installing an apk onto your device:**  \n  `adb install -r ./LinkBubble/build/outputs/apk/LinkBubble-playstore-release.apk`\n- **Getting a list of devices:**\n  `adb devices`\n", "release_dates": ["2016-11-02T19:57:51Z", "2016-09-12T15:46:05Z", "2016-09-09T02:40:52Z", "2016-05-25T23:55:01Z", "2016-05-19T16:07:11Z", "2016-05-19T12:44:25Z", "2016-04-13T23:49:15Z", "2016-04-07T02:35:57Z", "2016-03-30T22:31:10Z", "2016-03-28T14:03:28Z", "2016-03-23T19:36:22Z", "2016-03-20T21:31:18Z", "2016-03-19T16:07:35Z", "2016-03-18T16:19:03Z", "2016-03-02T02:35:41Z", "2016-02-25T00:53:25Z", "2016-02-05T15:56:16Z", "2015-12-11T15:15:28Z", "2015-12-09T15:27:58Z", "2015-12-08T17:34:38Z", "2015-12-04T05:19:26Z", "2015-12-04T01:18:20Z", "2015-11-06T19:17:41Z", "2015-10-29T17:19:49Z", "2015-10-20T15:13:06Z", "2015-10-18T17:18:59Z", "2015-09-29T17:51:50Z", "2015-09-22T00:18:11Z", "2015-09-21T20:59:18Z", "2015-08-25T18:16:15Z"]}, {"name": "link-bubble-website", "description": "http://linkbubble.com", "language": "HTML", "license": null, "readme": "# linkbubble.com\n\nThe linkbubble.com website is hosted on github pages.\n\n## Setup\n\nClone the repo:\n\n    git clone git@github.com:brave/linkbubble-website.git\n\nInstall staticjinja\n\n    pip install staticjinja\n\n## Building & deploying:\n\n    ./deploy.sh\n\n## Testing locally:\n\nGenerate the templates:\n\n    staticjinja build --srcpath=$(pwd)/src/templates\n\nStart a python server:\n\n    python -m SimpleHTTPServer 9595\n", "release_dates": []}, {"name": "metric-proxy", "description": "anonymizing mixpanel gateway \ud83c\udf32\ud83c\udf32\ud83c\udf32\ud83e\udd81\ud83c\udf32", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# metric-proxy\n\nanonymizing mixpanel gateway\n\n## features\n\n- Supports Mixpanel HTTP API /track endpoint, via GET (single) and POST (batch events)\n- Persist campaign params as cookies (e.g. for funnel tracking)\n- Hides user IP addresses from Mixpanel\n\n## usage\n\n1. `npm install`\n2. Set env vars:\n```\nMIXPANEL_API_HOST=\"https://api.mixpanel.com\"\nMIXPANEL_TOKEN_WHITELIST=\"{token1},{token2},...\"\n```\n3. `npm start`\n4. Set Mixpanel API endpoint to http://localhost:4000 and send some data.\n", "release_dates": []}, {"name": "mini-breakpad-server", "description": "Minimum breakpad crash reports collecting server", "language": "CoffeeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# mini-breakpad-server\n\nMinimum collecting server for crash reports sent by\n[google-breakpad](https://code.google.com/p/google-breakpad/).\n\n\n## Features\n\n* No requirement for setting up databases or web servers.\n* Collecting crash reports with minidump files.\n* Simple web interface for viewing translated crash reports.\n\n## Run\n\n* `npm install .`\n* `grunt`\n* Put your breakpad symbols under `pool/symbols/PRODUCT_NAME`\n* `node lib/app.js`\n", "release_dates": []}, {"name": "mixpanel-android", "description": null, "language": "Java", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "<p align=\"center\">\n  <img src=\"https://github.com/mixpanel/mixpanel-android/blob/assets/mixpanel.png?raw=true\" alt=\"Mixpanel Android Library\" height=\"150\"/>\n</p>\n\n# Latest Version [![Build Status](https://travis-ci.org/mixpanel/mixpanel-android.svg)](https://travis-ci.org/mixpanel/mixpanel-android)\n\n##### _June 23, 2017_ - [v5.1.4](https://github.com/mixpanel/mixpanel-android/releases/tag/v5.1.4)\n\n# Table of Contents\n\n<!-- MarkdownTOC -->\n\n- [Quick Start Guide](#quick-start-guide)\n    - [Installation](#installation)\n    - [Integration](#integration)\n- [I want to know more!](#i-want-to-know-more)\n- [Want to Contribute?](#want-to-contribute)\n- [Changelog](#changelog)\n- [License](#license)\n\n<!-- /MarkdownTOC -->\n\n<a name=\"quick-start-guide\"></a>\n# Quick Start Guide\n\nCheck out our **[official documentation](https://mixpanel.com/help/reference/android)** for more in depth information on installing and using Mixpanel on Android.\n\n<a name=\"installation\"></a>\n## Installation\n\n### Dependencies in *app/build.gradle*\n\nAdd Mixpanel and Google Play Services to the `dependencies` section in *app/build.gradle*\n\n```gradle\ncompile \"com.mixpanel.android:mixpanel-android:5.+\"\ncompile \"com.google.android.gms:play-services:7.5.0+\"\n```\n\n### Permissions in *app/src/main/AndroidManifest.xml*\n\n```xml\n<uses-permission android:name=\"android.permission.INTERNET\" />\n<uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" />\n<uses-permission android:name=\"android.permission.BLUETOOTH\" />\n```\n\n<a name=\"integration\"></a>\n## Integration\n\n### Initialization\n\nInitialize Mixpanel in your main activity *app/src/main/java/com/mixpanel/example/myapplication/MainActivity.java*. Usually this should be done in [onCreate](https://developer.android.com/reference/android/app/Activity.html#onCreate(android.os.Bundle)).\n\n```java\nString projectToken = YOUR_PROJECT_TOKEN; // e.g.: \"1ef7e30d2a58d27f4b90c42e31d6d7ad\" \nMixpanelAPI mixpanel = MixpanelAPI.getInstance(this, projectToken);\n```\nRemember to replace `YOUR_PROJECT_TOKEN` with the token provided to you on mixpanel.com.\n\n### Tracking\n\nAfter installing the library into your Android app, Mixpanel will <a href=\"https://mixpanel.com/help/questions/articles/which-common-mobile-events-can-mixpanel-collect-on-my-behalf-automatically\" target=\"_blank\">automatically collect common mobile events</a>. You can enable/ disable automatic collection through your <a href=\"https://mixpanel.com/help/questions/articles/how-do-i-enable-common-mobile-events-if-i-have-already-implemented-mixpanel\" target=\"_blank\">project settings</a>.\n\nWith the `mixpanel` object created in [the last step](#integration) a call to `track` is all you need to send additional events to Mixpanel.\n\n```java\nmixpanel.track(\"Event name no props\")\n\nJSONObject props = new JSONObject();\nprops.put(\"Prop name\", \"Prop value\");\nprops.put(\"Prop 2\", \"Value 2\");\nmixpanel.track(\"Event name\", props);\n```\n\n<a name=\"i-want-to-know-more\"></a>\n# I want to know more!\n\nNo worries, here are some links that you will find useful:\n* **[Sample app](https://github.com/mixpanel/sample-android-mixpanel-integration)**\n* **[Android integration video tutorial](https://www.youtube.com/watch?v=KcpOa93eSVs)**\n* **[Full API Reference](http://mixpanel.github.io/mixpanel-android/index.html)**\n\nHave any questions? Reach out to [support@mixpanel.com](mailto:support@mixpanel.com) to speak to someone smart, quickly.\n\n<a name=\"want-to-contribute\"></a>\n# Want to Contribute?\n\nThe Mixpanel library for Android is an open source project, and we'd love to see your contributions!\nWe'd also love for you to come and work with us! Check out our **[opening positions](https://mixpanel.com/jobs/#openings)** for details.\n\n<a name=\"changelog\"></a>\n# Changelog\n\nSee [wiki page](https://github.com/mixpanel/mixpanel-android/wiki/Changelog).\n\n<a name=\"license\"></a>\n# License\n\n```\nSee LICENSE File for details. The Base64Coder,\nConfigurationChecker, and StackBlurManager classes, and the entirety of the\n com.mixpanel.android.java_websocket package used by this\nsoftware have been licensed from non-Mixpanel sources and modified\nfor use in the library. Please see the relevant source files, and the\nLICENSE file in the com.mixpanel.android.java_websocket package for details.\n\nThe StackBlurManager class uses an algorithm by Mario Klingemann <mario@quansimondo.com>\nYou can learn more about the algorithm at\nhttp://www.quasimondo.com/StackBlurForCanvas/StackBlurDemo.html.\n```\n", "release_dates": []}, {"name": "mixpanel-iphone", "description": "iPhone tracking library for Mixpanel Analytics", "language": "Objective-C", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "[![Build Status](https://travis-ci.org/mixpanel/mixpanel-iphone.svg?branch=yolo-travis-ci)](https://travis-ci.org/mixpanel/mixpanel-iphone)\n[![Average time to resolve an issue](http://isitmaintained.com/badge/resolution/mixpanel/mixpanel-iphone.svg)](http://isitmaintained.com/project/mixpanel/mixpanel-iphone \"Average time to resolve an issue\")\n[![Percentage of issues still open](http://isitmaintained.com/badge/open/mixpanel/mixpanel-iphone.svg)](http://isitmaintained.com/project/mixpanel/mixpanel-iphone \"Percentage of issues still open\")\n[![CocoaPods Version](http://img.shields.io/cocoapods/v/Mixpanel.svg?style=flat)](https://mixpanel.com)\n[![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage)\n[![Apache License](http://img.shields.io/cocoapods/l/Mixpanel.svg?style=flat)](https://mixpanel.com)\n\n# Table of Contents\n\n<!-- MarkdownTOC -->\n\n- [Introduction](#introduction)\n- [Installation](#installation)\n    - [CocoaPods](#cocoapods)\n    - [Carthage](#carthage)\n    - [Manual Installation](#manual-installation)\n- [Integrate](#integrate)\n- [Start tracking](#start-tracking)\n\n<!-- /MarkdownTOC -->\n\n<a name=\"introduction\"></a>\n# Introduction\n\nThe Mixpanel library for iOS is an open source project, and we'd love to see your contributions! We'd also love for you to come and work with us! Check out https://mixpanel.com/jobs/#openings for details.\n\nIf you are using Swift, we recommend our **[Swift Library](https://github.com/mixpanel/mixpanel-swift)**.\n\n<a name=\"installation\"></a>\n# Installation\n\n<a name=\"cocoapods\"></a>\n## CocoaPods\n\nMixpanel supports `CocoaPods` for easy installation.\nTo Install, see our **[full documentation \u00bb](https://mixpanel.com/help/reference/ios)**\n\n#### iOS, tvOS, watchOS, macOS: \n`pod 'Mixpanel'`\n#### App Extension:\n`pod 'Mixpanel-AppExtension'`\n\n<a name=\"carthage\"></a>\n## Carthage\n\nMixpanel also supports `Carthage` to package your dependencies as a framework.\nCheck out the **[Carthage docs \u00bb](https://github.com/Carthage/Carthage)** for more info.\n\nTo integrate Mixpanel into your Xcode project using Carthage, specify it in your `Cartfile`:\n\n```ogdl\ngithub \"mixpanel/mixpanel-iphone\"\n```\n\nRun `carthage update` to build the framework and drag the built `Mixpanel.framework` into your Xcode project.\n\n<a name=\"manual-installation\"></a>\n## Manual Installation\n\nTo help users stay up to date with the latests version of our iOS SDK, we always recommend integrating our SDK via CocoaPods, which simplifies version updates and dependency management. However, there are cases where users can't use CocoaPods. Not to worry, just follow these manual installation steps and you'll be all set.\n\n### Step 1: Add as a submodule\n\nAdd Mixpanel as a submodule to your local git repo like so:\n\n```\ngit submodule add git@github.com:mixpanel/mixpanel-iphone.git\n```\n\nNow the Mixpanel project and its files should be in your project folder!\n\n### Step 2: Add the SDK to your app!\n\nDrag and drop Mixpanel.xcodeproj from the mixpanel-iphone folder into your Xcode Project Workspace:\n\n![alt text](http://i.imgur.com/6qgxEBY.png)\n\n### Step 3: Import the Mixpanel framework\n\nAdd Mixpanel.framework under \"Linked Frameworks and Libaries\" to your app.\n\n![alt text](http://i.imgur.com/aJx6R8S.png)\n\n<a name=\"integrate\"></a>\n# Integrate\n\nImport <Mixpanel/Mixpanel.h> into AppDelegate.m, and initialize Mixpanel within `application:didFinishLaunchingWithOptions:`\n\n```objective-c\n#import \"AppDelegate.h\"\n#import <Mixpanel/Mixpanel.h>\n\n@implementation AppDelegate\n\n- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions {\n    [Mixpanel sharedInstanceWithToken:MIXPANEL_TOKEN];\n}\n```\n\nYou initialize your Mixpanel instance with the token provided to you on mixpanel.com.\n\n<a name=\"start-tracking\"></a>\n# Start tracking\n\nAfter installing the library into your iOS app, Mixpanel will <a href=\"https://mixpanel.com/help/questions/articles/which-common-mobile-events-can-mixpanel-collect-on-my-behalf-automatically\" target=\"_blank\">automatically collect common mobile events</a>. You can enable/ disable automatic collection through your <a href=\"https://mixpanel.com/help/questions/articles/how-do-i-enable-common-mobile-events-if-i-have-already-implemented-mixpanel\" target=\"_blank\">project settings</a>.\n\nTracking additional events is as easy as adding `track:` or `track:properties:` anywhere after initializing Mixpanel.\n\n```objective-c\n[[Mixpanel sharedInstance] track:@\"Event name\"];\n[[Mixpanel sharedInstance] track:@\"Event name\" properties:@{@\"Prop name\": @\"Prop value\"}];\n```\n\nYou're done! You've successfully integrated the Mixpanel SDK into your app. To stay up to speed on important SDK releases and updates watch our iPhone repository on [Github](https://github.com/mixpanel/mixpanel-iphone).\n\nHave any questions? Reach out to [support@mixpanel.com](mailto:support@mixpanel.com) to speak to someone smart, quickly.\n", "release_dates": []}, {"name": "mixpanel-swift", "description": "Mixpanel tracking library for iOS (Swift)", "language": "Swift", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "<p align=\"center\">\n  <img src=\"https://github.com/mixpanel/mixpanel-swift/blob/assets/mixpanelswift.png?raw=true\" alt=\"Mixpanel Swift Library\" height=\"200\"/>\n</p>\n\n\n[![Build Status](https://travis-ci.org/mixpanel/mixpanel-swift.svg)](https://travis-ci.org/mixpanel/mixpanel-swift)\n[![Average time to resolve an issue](http://isitmaintained.com/badge/resolution/mixpanel/mixpanel-swift.svg)](http://isitmaintained.com/project/mixpanel/mixpanel-swift \"Average time to resolve an issue\")\n[![Percentage of issues still open](http://isitmaintained.com/badge/open/mixpanel/mixpanel-swift.svg)](http://isitmaintained.com/project/mixpanel/mixpanel-swift \"Percentage of issues still open\")\n[![CocoaPods Compatible](http://img.shields.io/cocoapods/v/Mixpanel-swift.svg)](https://mixpanel.com)\n[![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg)](https://github.com/Carthage/Carthage)\n[![Apache License](http://img.shields.io/cocoapods/l/Mixpanel-swift.svg)](https://mixpanel.com)\n[![Documentation](https://mixpanel.github.io/mixpanel-swift/badge.svg)](https://mixpanel.github.io/mixpanel-swift)\n# Table of Contents\n\n<!-- MarkdownTOC -->\n\n- [Introduction](#introduction)\n    - [Current supported features](#current-supported-features)\n- [Installation](#installation)\n    - [CocoaPods](#cocoapods)\n    - [Carthage](#carthage)\n    - [Manual Installation](#manual-installation)\n- [Initializing and Usage](#initializing-and-usage)\n    - [Integrate](#integrate)\n    - [Start tracking](#start-tracking)\n\n<!-- /MarkdownTOC -->\n\n<a name=\"introduction\"></a>\n# Introduction\n\nWelcome to the official Mixpanel Swift Library\n\nThe Mixpanel Swift library for iOS is an open source project, and we'd love to see your contributions! \nWe'd also love for you to come and work with us! Check out **[Jobs](https://mixpanel.com/jobs/#openings)** for details.\n\nIf you are using Objective-C, we recommend using our **[Objective-C Library](https://github.com/mixpanel/mixpanel-iphone)**.\n\n<a name=\"current-supported-features\"></a>\n## Current supported features\n\n**Our library now also has Swift 4 support. If you wish to use our Swift 4 implementation, please point to our 'swift4' branch (https://github.com/mixpanel/mixpanel-swift/tree/swift4)**\n\n**Our master branch and our releases are in Swift 3. If you wish to use our Swift 2.3 implementation, please point to our v1.0.1 release.**\n\nOur Swift library fully supports all of the Mixpanel features, and has full parity with the [Objective-C Library](https://github.com/mixpanel/mixpanel-iphone).\n\n<a name=\"installation\"></a>\n# Installation\n\n<a name=\"cocoapods\"></a>\n## CocoaPods\n\n**Our current release only supports CocoaPods version 1.1.0+**\n\nMixpanel supports `CocoaPods` for easy installation.\nTo Install, see our **[swift integration guide \u00bb](https://mixpanel.com/help/reference/swift)**\n\nFor iOS, tvOS, macOS, and App Extension integrations:\n\n`pod 'Mixpanel-swift'`\n\n<a name=\"carthage\"></a>\n## Carthage\n\nMixpanel also supports `Carthage` to package your dependencies as a framework. Include the following dependency in your Cartfile:\n\n`github \"mixpanel/mixpanel-swift\"`\n\nCheck out the **[Carthage docs \u00bb](https://github.com/Carthage/Carthage#if-youre-building-for-ios-tvos-or-watchos)** for more info. \n\n<a name=\"manual-installation\"></a>\n## Manual Installation\n\nTo help users stay up to date with the latests version of our Swift SDK, we always recommend integrating our SDK via CocoaPods, which simplifies version updates and dependency management. However, there are cases where users can't use CocoaPods. Not to worry, just follow these manual installation steps and you'll be all set.\n\n### Step 1: Add as a Submodule\n\nAdd Mixpanel as a submodule to your local git repo like so:\n\n```\ngit submodule add git@github.com:mixpanel/mixpanel-swift.git\n```\n\nNow the Mixpanel project and its files should be in your project folder! \n\n### Step 2: Drag Mixpanel to your project\n\nDrag the Mixpanel.xcodeproj inside your sample project under the main sample project file:\n\n![alt text](http://images.mxpnl.com/docs/2016-07-19%2023:34:02.724663-Screen%20Shot%202016-07-19%20at%204.33.34%20PM.png)\n\n### Step 3: Embed the framework\n\nSelect your app .xcodeproj file. Under \"General\", add the Mixpanel framework as an embedded binary:\n\n![alt text](http://images.mxpnl.com/docs/2016-07-19%2023:31:29.237158-add_framework.png)\n\n<a name=\"initializing-and-usage\"></a>\n# Initializing and Usage\n\n<a name=\"integrate\"></a>\n## Integrate\n\nImport Mixpanel into AppDelegate.swift, and initialize Mixpanel within `application:didFinishLaunchingWithOptions:`\n![alt text](http://images.mxpnl.com/docs/2016-07-19%2023:27:03.724972-Screen%20Shot%202016-07-18%20at%207.16.51%20PM.png)\n\n```swift\nfunc application(_ application: UIApplication,\n                 didFinishLaunchingWithOptions launchOptions: [NSObject: AnyObject]?) -> Bool {\n    Mixpanel.initialize(token: \"MIXPANEL_TOKEN\")\n}\n```\n\nYou initialize your Mixpanel instance with the token provided to you on mixpanel.com.\n\n<a name=\"start-tracking\"></a>\n## Start tracking\n\nAfter installing the library into your iOS app, Mixpanel will <a href=\"https://mixpanel.com/help/questions/articles/which-common-mobile-events-can-mixpanel-collect-on-my-behalf-automatically\" target=\"_blank\">automatically collect common mobile events</a>. You can enable/ disable automatic collection through your <a href=\"https://mixpanel.com/help/questions/articles/how-do-i-enable-common-mobile-events-if-i-have-already-implemented-mixpanel\" target=\"_blank\">project settings</a>.\n\nTo interact with the instance and track additional events, you can either use the mixpanel instance given when initializing:\n```swift\nmixpanel.track(event: \"Tracked Event!\")\n```\nor you can directly fetch the instance and use it from the Mixpanel object:\n```swift\nMixpanel.mainInstance().track(event: \"Tracked Event!\")\n```\n\nYou're done! You've successfully integrated the Mixpanel Swift SDK into your app. To stay up to speed on important SDK releases and updates, star or watch our repository on [Github](https://github.com/mixpanel/mixpanel-swift).\n\nHave any questions? Reach out to [support@mixpanel.com](mailto:support@mixpanel.com) to speak to someone smart, quickly.\n", "release_dates": []}, {"name": "monk", "description": "The wise MongoDB API", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# monk\n\n[![build status](https://secure.travis-ci.org/Automattic/monk.svg?branch=master)](https://secure.travis-ci.org/Automattic/monk)\n[![codecov](https://codecov.io/gh/Automattic/monk/branch/master/graph/badge.svg)](https://codecov.io/gh/Automattic/monk)\n[![Join the chat at https://gitter.im/Automattic/monk](https://badges.gitter.im/Automattic/monk.svg)](https://gitter.im/Automattic/monk?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nMonk is a tiny layer that provides simple yet substantial usability\nimprovements for MongoDB usage within Node.JS.\n\n*note*: monk 2.x drop the support for node < 0.12. If you are still using an earlier version, stick to monk 1.x\n\n```js\nconst db = require('monk')('localhost/mydb')\nconst users = db.get('users')\n\nusers.index('name last')\nusers.insert({ name: 'Tobi', bigdata: {} })\nusers.find({ name: 'Loki' }, '-bigdata').then(function () {\n  // exclude bigdata field\n})\nusers.find({}, {sort: {name: 1}}).then(function () {\n  // sorted by name field\n})\nusers.remove({ name: 'Loki' })\n\ndb.close()\n```\n\n## Features\n\n- Command buffering. You can start querying right away.\n- Promises built-in for all queries. Easy interoperability with modules.\n- Easy connections / configuration\n- Well-designed signatures\n- Improvements to the MongoDB APIs (eg: `findAndModify` supports the\n  `update` signature style)\n- Auto-casting of `_id` in queries\n- Allows to set global options or collection-level options for queries. (eg:\n  `safe` is `true` by default for all queries)\n\n## How to use\n\n[Documentation](https://Automattic.github.io/monk)\n\n## License\n\n(The MIT License)\n\nCopyright (c) 2012 Guillermo Rauch &lt;guillermo@learnboost.com&gt;\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n'Software'), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n", "release_dates": []}, {"name": "muon", "description": "[DEPRECATED] Build browsers and browser like applications with HTML, CSS, and JavaScript", "language": "C++", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "Muon is a framework that leverages the full power of [Chromium](https://www.chromium.org/Home) including extensions\nsupport, and allows you to build browsers and browser like applications with HTML, CSS, and JavaScript.  Node is added\ninto the browser process only for security reasons.\n\nIt may be a better fit than [Electron](https://github.com/electron/electron) for your application, if your application\nneeds to leverage the full support of Chromium, needs tighter security, or needs support for things like autofill and\nextensions. See the [Moving from Electron to Muon](docs/tutorial/moving-from-electron.md) guide to help make the transition.\n\nSome of Muons goals include:\n- use the Chromium source directly (eliminating electron's copy of `chrome_src`) with minor patches\n  - make integrating chrome components less painful\n  - faster and more streamlined end-to-end build process (see [browser-laptop-bootstrap](https://github.com/brave/browser-laptop-bootstrap))\n- add support for Chrome extensions\n- add security focused features for the renderer:\n  - remove node completely (from the renderer process)\n  - full sandbox\n  - scriptable window.opener support\n\nMuon is a fork of the [Electron](https://github.com/electron/electron/) framework\nwhich is currently used in the [Brave](https://brave.com) web browser.\n\nFollow [@brave](https://twitter.com/brave) on Twitter for important\nannouncements.\n\n## Downloads\n\nPrebuilt binaries and debug symbols of Muon for Linux, Windows and macOS can\nbe found on the [releases](https://github.com/brave/muon/releases) page.\n\n## Documentation\n\nGuides and the API reference are located in the\n[docs](https://github.com/brave/muon/tree/master/docs) directory.\n\nYou can also [see our wiki](https://github.com/brave/browser-laptop-bootstrap/wiki) for tips on building Muon.\n\n## Quick Start\n\nClone and run the [`muon-quick`](https://github.com/brave/muon-quick)\nrepository to see a minimal Muon app in action.\n\n## Versions\n\nThe version numbers for Muon will be major.minor.patch\nMajor version changes are for breaking api changes\nMinor version changes are for chromium major version changes\nPatch version changes are for everything else\n\n## Community\n\nYou can ask questions and interact with the community in the muon community chat room:\n- [The Muon Community](https://discord.gg/TcT5tX2)\n", "release_dates": ["2018-10-04T19:53:19Z", "2018-09-28T16:08:25Z", "2018-09-18T02:30:01Z", "2018-09-14T01:21:28Z", "2018-09-12T05:50:15Z", "2018-09-07T06:50:21Z", "2018-09-05T05:55:06Z", "2018-09-02T17:23:17Z", "2018-08-31T21:36:38Z", "2018-08-29T15:12:30Z", "2018-08-28T13:48:39Z", "2018-08-14T02:41:29Z", "2018-08-08T23:56:54Z", "2018-08-03T05:50:27Z", "2018-08-03T00:29:59Z", "2018-08-02T02:43:20Z", "2018-07-27T15:17:29Z", "2018-07-25T16:42:27Z", "2018-07-20T16:17:44Z", "2018-07-13T19:23:09Z", "2018-07-13T00:31:01Z", "2018-07-06T16:47:07Z", "2018-06-30T06:28:44Z", "2018-06-26T19:42:03Z", "2018-06-25T14:25:23Z", "2018-06-21T14:17:07Z", "2018-06-19T14:32:12Z", "2018-06-13T14:18:46Z", "2018-06-12T04:34:58Z", "2018-06-12T21:05:06Z"]}, {"name": "muon-pyramid-uploader", "description": "upload muon debug builds to s3", "language": "Shell", "license": null, "readme": "Usage:\n```\ndocker run -it --rm -e AWS_ACCESS_KEY_ID=\"ABC1234\" -e AWS_SECRET_ACCESS_KEY=\"xxxxx\" -v /home/core/browser-laptop/node_modules/electron-prebuilt/dist:/opt/target build-uploader s3://brave-test-builds/muon/brave-debug-v4.4.20-linux-x64.zip\n```\n", "release_dates": []}, {"name": "muon-quick", "description": null, "language": "JavaScript", "license": {"key": "cc0-1.0", "name": "Creative Commons Zero v1.0 Universal", "spdx_id": "CC0-1.0", "url": "https://api.github.com/licenses/cc0-1.0", "node_id": "MDc6TGljZW5zZTY="}, "readme": "# Muon Quick Start\n\n1. git clone https://github.com/brave/muon-quick.git\n2. cd muon-quick\n3. npm install\n4. npm start\n", "release_dates": []}, {"name": "muon-winstaller", "description": "Creates windows installers for Brave (forked originally from electron-winstaller", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Electron Installer\n\n[![AppVeyor Build status](https://ci.appveyor.com/api/projects/status/kqvkqdv0feks9d2a/branch/master?svg=true)](https://ci.appveyor.com/project/Atom/windows-installer/branch/master)\n[![Travis CI Build Status](https://travis-ci.org/electron/windows-installer.svg?branch=master)](https://travis-ci.org/electronjs/windows-installer)\n\nNPM module that builds Windows installers for\n[Electron](https://github.com/atom/electron) apps using\n[Squirrel](https://github.com/Squirrel/Squirrel.Windows).\n\n## Installing\n\n```sh\nnpm install --save-dev electron-winstaller\n```\n\n## Usage\n\nRequire the package:\n\n```js\nvar electronInstaller = require('electron-winstaller');\n```\n\nThen do a build like so..\n\n```js\nresultPromise = electronInstaller.createWindowsInstaller({\n    appDirectory: '/tmp/build/my-app-64',\n    outputDirectory: '/tmp/build/installer64',\n    authors: 'My App Inc.',\n    exe: 'myapp.exe'\n  });\n\nresultPromise.then(() => console.log(\"It worked!\"), (e) => console.log(`No dice: ${e.message}`));\n```\n\nAfter running you will have an `.nupkg`, a\n`RELEASES` file, and a `.exe` installer file in the `outputDirectory` folder\nfor each multi task target given under the config entry.\n\nThere are several configuration settings supported:\n\n| Config Name           | Required | Description |\n| --------------------- | -------- | ----------- |\n| `appDirectory`        | Yes      | The folder path of your Electron app |\n| `outputDirectory`     | No       | The folder path to create the `.exe` installer in. Defaults to the `installer` folder at the project root. |\n| `loadingGif`          | No       | The local path to a `.gif` file to display during install. |\n| `authors`             | Yes      | The authors value for the nuget package metadata. Defaults to the `author` field from your app's package.json file when unspecified. |\n| `owners`              | No       | The owners value for the nuget package metadata. Defaults to the `authors` field when unspecified. |\n| `exe`                 | No       | The name of your app's main `.exe` file. This uses the `name` field in your app's package.json file with an added `.exe` extension when unspecified. |\n| `description`         | No       | The description value for the nuget package metadata. Defaults to the `description` field from your app's package.json file when unspecified. |\n| `version`             | No       | The version value for the nuget package metadata. Defaults to the `version` field from your app's package.json file when unspecified. |\n| `title`               | No       | The title value for the nuget package metadata. Defaults to the `productName` field and then the `name` field from your app's package.json file when unspecified. |\n| `name`                | No      | Windows Application Model ID (appId). Defaults to the `name` field in your app's package.json file. |\n| `certificateFile`     | No       | The path to an Authenticode Code Signing Certificate |\n| `certificatePassword` | No       | The password to decrypt the certificate given in `certificateFile` |\n| `signWithParams`      | No       | Params to pass to signtool.  Overrides `certificateFile` and `certificatePassword`. |\n| `iconUrl`             | No       | A URL to an ICO file to use as the application icon (displayed in Control Panel > Programs and Features). Defaults to the Atom icon. |\n| `setupIcon`           | No       | The ICO file to use as the icon for the generated Setup.exe |\n| `setupExe`            | No       | The name to use for the generated Setup.exe file |\n| `setupMsi`            | No       | The name to use for the generated Setup.msi file |\n| `noMsi`               | No       | Should Squirrel.Windows create an MSI installer? |\n| `remoteReleases`      | No       | A URL to your existing updates. If given, these will be downloaded to create delta updates |\n| `remoteToken`         | No       | Authentication token for remote updates |\n\n## Sign your installer or else bad things will happen\n\nFor development / internal use, creating installers without a signature is okay, but for a production app you need to sign your application. Internet Explorer's SmartScreen filter will block your app from being downloaded, and many anti-virus vendors will consider your app as malware unless you obtain a valid cert.\n\nAny certificate valid for \"Authenticode Code Signing\" will work here, but if you get the right kind of code certificate, you can also opt-in to [Windows Error Reporting](http://en.wikipedia.org/wiki/Windows_Error_Reporting). [This MSDN page](http://msdn.microsoft.com/en-us/library/windows/hardware/hh801887.aspx) has the latest links on where to get a WER-compatible certificate. The \"Standard Code Signing\" certificate is sufficient for this purpose.\n\n## Handling Squirrel Events\n\nSquirrel will spawn your app with command line flags on first run, updates,\nand uninstalls. it is **very** important that your app handle these events as _early_\nas possible, and quit **immediately** after handling them. Squirrel will give your\napp a short amount of time (~15sec) to apply these operations and quit.\n\nThe [electron-squirrel-startup](https://github.com/mongodb-js/electron-squirrel-startup) module will handle\nthe most common events for you, such as managing desktop shortcuts.  Just\nadd the following to the top of your `main.js` and you're good to go:\n\n```js\nif (require('electron-squirrel-startup')) return;\n```\n\nYou should handle these events in your app's `main` entry point with something\nsuch as:\n\n```js\nconst app = require('app');\n\n// this should be placed at top of main.js to handle setup events quickly\nif (handleSquirrelEvent()) {\n  // squirrel event handled and app will exit in 1000ms, so don't do anything else\n  return;\n}\n\nfunction handleSquirrelEvent() {\n  if (process.argv.length === 1) {\n    return false;\n  }\n\n  const ChildProcess = require('child_process');\n  const path = require('path');\n\n  const appFolder = path.resolve(process.execPath, '..');\n  const rootAtomFolder = path.resolve(appFolder, '..');\n  const updateDotExe = path.resolve(path.join(rootAtomFolder, 'Update.exe'));\n  const exeName = path.basename(process.execPath);\n\n  const spawn = function(command, args) {\n    let spawnedProcess, error;\n\n    try {\n      spawnedProcess = ChildProcess.spawn(command, args, {detached: true});\n    } catch (error) {}\n\n    return spawnedProcess;\n  };\n\n  const spawnUpdate = function(args) {\n    return spawn(updateDotExe, args);\n  };\n\n  const squirrelEvent = process.argv[1];\n  switch (squirrelEvent) {\n    case '--squirrel-install':\n    case '--squirrel-updated':\n      // Optionally do things such as:\n      // - Add your .exe to the PATH\n      // - Write to the registry for things like file associations and\n      //   explorer context menus\n\n      // Install desktop and start menu shortcuts\n      spawnUpdate(['--createShortcut', exeName]);\n\n      setTimeout(app.quit, 1000);\n      return true;\n\n    case '--squirrel-uninstall':\n      // Undo anything you did in the --squirrel-install and\n      // --squirrel-updated handlers\n\n      // Remove desktop and start menu shortcuts\n      spawnUpdate(['--removeShortcut', exeName]);\n\n      setTimeout(app.quit, 1000);\n      return true;\n\n    case '--squirrel-obsolete':\n      // This is called on the outgoing version of your app before\n      // we update to the new version - it's the opposite of\n      // --squirrel-updated\n\n      app.quit();\n      return true;\n  }\n};\n```\n\nNotice that the first time the installer launches your app, your app will see a ```--squirrel-firstrun``` flag. This allows you to do things like showing up a splash screen or presenting a settings UI. Another thing to be aware of is that, since the app is spawned by squirrel and squirrel acquires a file lock during installation, you won't be able to successfully check for app updates till a few seconds later when squirrel releases the lock.\n\n## Debugging this package\n\nYou can get debug messages from this package by running with the environment variable `DEBUG=electron-windows-installer:main` e.g.\n\n```\nDEBUG=electron-windows-installer:main node tasks/electron-winstaller.js\n```\n", "release_dates": []}, {"name": "news-aggregator", "description": null, "language": "Python", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# News Aggregator\nThis project is the backend side of Brave News, and it fetches the articles from the Brave-defined publishers and\nshows their feeds/News in the Browser.\n\nFor more details: https://brave.com/brave-news-updates/\n\n## Setup\n\n### Dependencies\nPython Version (Required):\n\n    Python 3.9\n\nRequired setup:\n\n    virtualenv -p /usr/bin/python3.9 .venv\n    . .venv/bin/activate\n    pip install -r requirements.dev.txt\n\n\n### Running locally\n\nTo generate sources and list of feeds:\n\n    export PYTHONPATH=$PWD:$PWD/src\n    NO_UPLOAD=1 NO_DOWNLOAD=1 python src/csv_to_json.py\n\nTo generate browser feed and images:\n\n    export PYTHONPATH=$PWD:$PWD/src\n    NO_UPLOAD=1 python src/feed_processor_multi.py feed\n\nTo update the favicon urls:\n\n    export PYTHONPATH=$PWD:$PWD/src\n    NO_UPLOAD=1 NO_DOWNLOAD=1 python src/favicons_covers/update_favicon_urls.py\n\n### Organization\n\nThis service organizes as follows:\n```\nnews_aggregator/\n\u251c\u2500\u2500 bin/                # This dir contains the helping shell scripts for Dockerfile.\n\u251c\u2500\u2500 lib/                # This dir contains the utility modules.\n\u251c\u2500\u2500 models/             # This dir contains the dataclasses.\n\u251c\u2500\u2500 sources/            # This dir contains the sources files.\n\u251c\u2500\u2500 src/                # This dir contains all the python script to run the new aggregator.\n\u251c\u2500\u2500 tests/              # This dir contains the tests.\n```\n\n### Contribution\n\nWe configured the pre-commit hooks to ensure the quality of the code. To set-up the pre-commit hooks run the following\ncommands:\n\n    pre-commit install\n    pre-commit run --all-files\n\n\n# wasm_thumbnail\n\nThe `wasm_thumbnail.wasm` binary comes from <https://github.com/brave-intl/wasm-thumbnail>.\n", "release_dates": []}, {"name": "nitriding", "description": "Tool kit for building networked services on top of AWS Nitro Enclaves.", "language": "Go", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# This repository is unmaintained\n\nDevelopment on this project is continuing under\n[nitriding-daemon](https://github.com/brave/nitriding-daemon).\n", "release_dates": []}, {"name": "nitriding-daemon", "description": "Tool kit for building secure, scalable, and networked services on top of AWS Nitro Enclaves.", "language": "Go", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "<div align=\"center\">\n  <img src=\"./doc/nitriding-logo.svg\" alt=\"Nitriding logo\" width=\"250\">\n</div>\n\n---\n\n[![GoDoc](https://pkg.go.dev/badge/github.com/brave/nitriding-daemon?utm_source=godoc)](https://pkg.go.dev/github.com/brave/nitriding-daemon)\n\nThis Go tool kit makes it possible to run your application inside an\n[AWS Nitro Enclave](https://aws.amazon.com/ec2/nitro/nitro-enclaves/).\nLet's assume that you built a Web service in Rust.  You can now use nitriding to\nmove your Rust code into a secure enclave, making it possible for your users to\nremotely verify that you are in fact running the code that you claim to run.\nNitriding provides the following features:\n\n* Automatically obtains an HTTPS certificate (either self-signed or via\n  [Let's Encrypt](https://letsencrypt.org))\n  for clients to securely connect to your enclave over the Internet.  Nitriding\n  can act as a TLS-terminating reverse HTTP proxy for your application, so your\n  application does not have to deal with obtaining certificates.\n\n* Automatically exposes an HTTPS endpoint for remote attestation.  After having\n  audited your enclave's source code, your users can conveniently verify the\n  enclave's image by using a tool like\n  [verify-enclave](https://github.com/brave-experiments/verify-enclave)\n  and running:\n\n   ```\n   make verify CODE=/path/to/code/ ENCLAVE=https://enclave.com/enclave/attestation\n   ```\n\n* Are you building an application that uses a protocol other than HTTP?  If so,\n  nitriding makes it possible to register a hash over your application's public\n  key material which is subsequently included in the\n  [attestation document](https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-concepts.html#term-attestdoc).\n  This allows your users to verify that their connection is securely terminated\n  inside the enclave, regardless of the protocol that you are using.\n\n* Provides an API to scale enclave applications horizontally while synchronizing\n  state between enclaves.\n\n* AWS Nitro Enclaves only provide a highly constrained\n  [VSOCK channel](https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-concepts.html#term-socket)\n  between the enclave and its host.  Nitriding creates TAP interface inside the\n  enclave, allowing your application to transparently access the Internet\n  without having to worry about VSOCK, port forwarding, or tunneling.\n\n* Automatically initializes the enclave's entropy pool using the Nitro\n  hypervisor.\n\nTo learn more about nitriding's trust assumptions, architecture, and build\nsystem, take a look at our [research paper](https://arxiv.org/abs/2206.04123).\n\n## More documentation\n\n* [How to use nitriding](doc/usage.md)\n* [System architecture](doc/architecture.md)\n* [HTTP API](doc/http-api.md)\n* [Horizontal scaling](doc/key-synchronization.md)\n* [Example application](example/)\n* [Setup enclave EC2 host](doc/setup.md)\n", "release_dates": []}, {"name": "nlp-pipelines", "description": "NLP pipelines for in-browser functionality", "language": "Jupyter Notebook", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# nlp-pipelines\n\nNLP pipelines & models for in-browser functionality\n\n## installation \n\n```\npip install .\n```\n\n#testing \nto test the example japanese model: \n```\npython scripts/test_predictions.py -m models/jp_modelv1.json.gz -u https://www.rakuteneagles.jp/\n```\nsimilarly usage for the english model: \n\n```\npython scripts/test_predictions.py -m models/english_hashed.json.gz -u https://brave.com\n```\n\n## Background \n\nThis repo contains simple nlp pipelines which can then be packaged for use within the browser\nA simple nlp pipeline in this context looks like the following: \n\n(text)-->(preprocessing)-->(representation)-->(classifier)-->(inferred class)\n\nBriefly, an nlp pipeline defines a series of text transformations to be applied as a preprocessing \nstep, eventually producing a numerical representation of the text data. These representations are \nthen fed to a classifier which produces a classification rule for the input text data. Some examples \nof text classification pipelines follow:\n\n(japanese text)-->(hashing)-->(naive-bayes)-->result\n(english text)-->(lowercase)-->(hashing)-->(linear classifier)-->result\n\n## WHY? \n\nThe major reasons for the existence of this repo are Standardization and reproducibility. \nMore precisely:\n- standardize on input/output pipelines on nlp along with preprocessing steps\n- standardize the way these pipelines are represented, serialized and persisted\n- add further metadata to stored models such as language, date produced, processing steps\n- make sure the behavior of the python code closely matches the c++ code in the browser\n- make it trivial to add new language models both in terms of producing a model and of browser integration\n\n## How does a resulting model look like? \nCurrently like the following json object (subject to change to protobuf or other binary serialization):\n```\n{'time': '2019-03-13 13:24:37.197630',\n 'language': 'EN',\n 'representation': '{\"transforms\": [\"{\"transformation_type\": \"TO_LOWER\", \"params\": null}\", \n                                    \"{\"transformation_type\": \"HASHED_NGRAMS\", \"params\": {\"n_range\": [1, 2, 3, 4, 5], \"num_buckets\": 500}}\"]}',\n 'classifier': '{\"classifier_type\": \"NB\", \n                \"classes\": [\"ham\", \"junk\", \"spam\"], \n                \"class_weights\": {\"ham\": [-6.779,...., -6.32],\n                                  \"junk\": [...]\n                                  \"spam\":[...]\n                    }\n                }\n}\n```\n\n## Testing: \nJust run `pytest`\n\n## TODO:\n\n- Big question about the serialization format currently using json as that was the existing choice for ml models.\n  However protobufs or messagepack might result in much shorter models and also substantially simpler to load/serialize/deserialize \n  and cross-function with other languages. \n- Json substantially bigger unless one cuts off a few decimal points <-> accuracy vs stirage concerns\n- Add more classifiers and more preprocessing steps\n\n- Downstream book-keeping infrastructure (answer which models work best for which contexts and have those handy)\n\n- Organize into a proper python package and namespace\n\n", "release_dates": []}, {"name": "node", "description": "Node fork to make it suitable for embedding", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "Node.js\n=======\n\n[![Gitter](https://badges.gitter.im/Join Chat.svg)](https://gitter.im/nodejs/node?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nNode.js is a JavaScript runtime built on Chrome's V8 JavaScript engine. Node.js\nuses an event-driven, non-blocking I/O model that makes it lightweight and\nefficient. The Node.js package ecosystem, npm, is the largest ecosystem of open\nsource libraries in the world.\n\nThe Node.js project is supported by the\n[Node.js Foundation](https://nodejs.org/en/foundation/). Contributions,\npolicies and releases are managed under an\n[open governance model](./GOVERNANCE.md). We are also bound by a\n[Code of Conduct](./CODE_OF_CONDUCT.md).\n\nIf you need help using or installing Node.js, please use the\n[nodejs/help](https://github.com/nodejs/help) issue tracker.\n\n## Release Types\n\nThe Node.js project maintains multiple types of releases:\n\n* **Stable**: Released from active development branches of this repository,\n  versioned by [SemVer](http://semver.org/) and signed by a member of the\n  [Release Team](#release-team).\n  Code for Stable releases is organized in this repository by major version\n  number, For example: [v4.x](https://github.com/nodejs/node/tree/v4.x).\n  The major version number of Stable releases will increment every 6 months\n  allowing for breaking changes to be introduced. This happens in April and\n  October every year. Stable release lines beginning in October each year have\n  a maximum support life of 8 months. Stable release lines beginning in April\n  each year will convert to LTS (see below) after 6 months and receive further\n  support for 30 months.\n* **LTS**: Releases that receive Long-term Support, with a focus on stability\n  and security. Every second Stable release line (major version) will become an\n  LTS line and receive 18 months of _Active LTS_ support and a further 12\n  months of _Maintenance_. LTS release lines are given alphabetically\n  ordered codenames, beginning with v4 Argon. LTS releases are less frequent\n  and will attempt to maintain consistent major and minor version numbers,\n  only incrementing patch version numbers. There are no breaking changes or\n  feature additions, except in some special circumstances. More information\n  can be found in the [LTS README](https://github.com/nodejs/LTS/).\n* **Nightly**: Versions of code in this repository on the current Stable\n  branch, automatically built every 24-hours where changes exist. Use with\n  caution.\n\n## Download\n\nBinaries, installers, and source tarballs are available at\n<https://nodejs.org>.\n\n**Stable** and **LTS** releases are available at\n<https://nodejs.org/download/release/>, listed under their version strings.\nThe [latest](https://nodejs.org/download/release/latest/) directory is an\nalias for the latest Stable release. The latest LTS release from an LTS\nline is available in the form: latest-_codename_. For example:\n<https://nodejs.org/download/release/latest-argon>\n\n**Nightly** builds are available at\n<https://nodejs.org/download/nightly/>, listed under their version\nstring which includes their date (in UTC time) and the commit SHA at\nthe HEAD of the release.\n\n**API documentation** is available in each release and nightly\ndirectory under _docs_. <https://nodejs.org/api/> points to the API\ndocumentation of the latest stable version.\n\n### Verifying Binaries\n\nStable, LTS and Nightly download directories all contain a *SHASUM256.txt*\nfile that lists the SHA checksums for each file available for\ndownload. To check that a downloaded file matches the checksum, run\nit through `sha256sum` with a command such as:\n\n```\n$ grep node-vx.y.z.tar.gz SHASUMS256.txt | sha256sum -c -\n```\n\n_(Where \"node-vx.y.z.tar.gz\" is the name of the file you have\ndownloaded)_\n\nAdditionally, Stable and LTS releases (not Nightlies) have GPG signed\ncopies of SHASUM256.txt files available as SHASUM256.txt.asc. You can use\n`gpg` to verify that the file has not been tampered with.\n\nTo verify a SHASUM256.txt.asc, you will first need to import all of\nthe GPG keys of individuals authorized to create releases. They are\nlisted at the bottom of this README under [Release Team](#release-team).\nUse a command such as this to import the keys:\n\n```\n$ gpg --keyserver pool.sks-keyservers.net \\\n  --recv-keys DD8F2338BAE7501E3DD5AC78C273792F7D83545D\n```\n\n_(See the bottom of this README for a full script to import active\nrelease keys)_\n\nYou can then use `gpg --verify SHASUMS256.txt.asc` to verify that the\nfile has been signed by an authorized member of the Node.js team.\n\nOnce verified, use the SHASUMS256.txt.asc file to get the checksum for\nthe binary verification command above.\n\n## Building Node.js\n\nSee [BUILDING.md](BUILDING.md) for instructions on how to build\nNode.js from source.\n\n\n## Resources for Newcomers\n\n* [CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md)\n* [CONTRIBUTING.md](./CONTRIBUTING.md)\n* [GOVERNANCE.md](./GOVERNANCE.md)\n* IRC (general questions): [#node.js on Freenode.net](http://webchat.freenode.net?channels=node.js&uio=d4)\n* IRC (node core development): [#node-dev on Freenode.net](http://webchat.freenode.net?channels=node-dev&uio=d4)\n* [nodejs/node on Gitter](https://gitter.im/nodejs/node)\n\n## Security\n\nAll security bugs in Node.js are taken seriously and should be reported by\nemailing security@nodejs.org. This will be delivered to a subset of the project\nteam who handle security issues. Please don't disclose security bugs\npublicly until they have been handled by the security team.\n\nYour email will be acknowledged within 24 hours, and you\u2019ll receive a more\ndetailed response to your email within 48 hours indicating the next steps in\nhandling your report.\n\n## Current Project Team Members\n\nThe Node.js project team comprises a group of core collaborators and a sub-group\nthat forms the _Core Technical Committee_ (CTC) which governs the project. For more\ninformation about the governance of the Node.js project, see\n[GOVERNANCE.md](./GOVERNANCE.md).\n\n### CTC (Core Technical Committee)\n\n* [bnoordhuis](https://github.com/bnoordhuis) - **Ben Noordhuis** &lt;info@bnoordhuis.nl&gt;\n* [ChALkeR](https://github.com/ChALkeR) - **\u0421\u043a\u043e\u0432\u043e\u0440\u043e\u0434\u0430 \u041d\u0438\u043a\u0438\u0442\u0430 \u0410\u043d\u0434\u0440\u0435\u0435\u0432\u0438\u0447** &lt;chalkerx@gmail.com&gt;\n* [chrisdickinson](https://github.com/chrisdickinson) - **Chris Dickinson** &lt;christopher.s.dickinson@gmail.com&gt;\n* [cjihrig](https://github.com/cjihrig) - **Colin Ihrig** &lt;cjihrig@gmail.com&gt;\n* [evanlucas](https://github.com/evanlucas) - **Evan Lucas** &lt;evanlucas@me.com&gt;\n* [fishrock123](https://github.com/fishrock123) - **Jeremiah Senkpiel** &lt;fishrock123@rocketmail.com&gt;\n* [indutny](https://github.com/indutny) - **Fedor Indutny** &lt;fedor.indutny@gmail.com&gt;\n* [jasnell](https://github.com/jasnell) - **James M Snell** &lt;jasnell@gmail.com&gt;\n* [mhdawson](https://github.com/mhdawson) - **Michael Dawson** &lt;michael_dawson@ca.ibm.com&gt;\n* [misterdjules](https://github.com/misterdjules) - **Julien Gilli** &lt;jgilli@nodejs.org&gt;\n* [mscdex](https://github.com/mscdex) - **Brian White** &lt;mscdex@mscdex.net&gt;\n* [ofrobots](https://github.com/ofrobots) - **Ali Ijaz Sheikh** &lt;ofrobots@google.com&gt;\n* [orangemocha](https://github.com/orangemocha) - **Alexis Campailla** &lt;orangemocha@nodejs.org&gt;\n* [piscisaureus](https://github.com/piscisaureus) - **Bert Belder** &lt;bertbelder@gmail.com&gt;\n* [rvagg](https://github.com/rvagg) - **Rod Vagg** &lt;rod@vagg.org&gt;\n* [shigeki](https://github.com/shigeki) - **Shigeki Ohtsu** &lt;ohtsu@iij.ad.jp&gt;\n* [trevnorris](https://github.com/trevnorris) - **Trevor Norris** &lt;trev.norris@gmail.com&gt;\n* [Trott](https://github.com/Trott) - **Rich Trott** &lt;rtrott@gmail.com&gt;\n\n### Collaborators\n\n* [AndreasMadsen](https://github.com/AndreasMadsen) - **Andreas Madsen** &lt;amwebdk@gmail.com&gt;\n* [benjamingr](https://github.com/benjamingr) - **Benjamin Gruenbaum** &lt;benjamingr@gmail.com&gt;\n* [brendanashworth](https://github.com/brendanashworth) - **Brendan Ashworth** &lt;brendan.ashworth@me.com&gt;\n* [calvinmetcalf](https://github.com/calvinmetcalf) - **Calvin Metcalf** &lt;calvin.metcalf@gmail.com&gt;\n* [claudiorodriguez](https://github.com/claudiorodriguez) - **Claudio Rodriguez** &lt;cjrodr@yahoo.com&gt;\n* [domenic](https://github.com/domenic) - **Domenic Denicola** &lt;d@domenic.me&gt;\n* [geek](https://github.com/geek) - **Wyatt Preul** &lt;wpreul@gmail.com&gt;\n* [iarna](https://github.com/iarna) - **Rebecca Turner** &lt;me@re-becca.org&gt;\n* [isaacs](https://github.com/isaacs) - **Isaac Z. Schlueter** &lt;i@izs.me&gt;\n* [jbergstroem](https://github.com/jbergstroem) - **Johan Bergstr\u00f6m** &lt;bugs@bergstroem.nu&gt;\n* [joaocgreis](https://github.com/joaocgreis) - **Jo\u00e3o Reis** &lt;reis@janeasystems.com&gt;\n* [julianduque](https://github.com/julianduque) - **Julian Duque** &lt;julianduquej@gmail.com&gt;\n* [JungMinu](https://github.com/JungMinu) - **Minwoo Jung** &lt;jmwsoft@gmail.com&gt;\n* [lxe](https://github.com/lxe) - **Aleksey Smolenchuk** &lt;lxe@lxe.co&gt;\n* [matthewloring](https://github.com/matthewloring) - **Matthew Loring** &lt;mattloring@google.com&gt;\n* [mcollina](https://github.com/mcollina) - **Matteo Collina** &lt;matteo.collina@gmail.com&gt;\n* [micnic](https://github.com/micnic) - **Nicu Micleu\u0219anu** &lt;micnic90@gmail.com&gt;\n* [mikeal](https://github.com/mikeal) - **Mikeal Rogers** &lt;mikeal.rogers@gmail.com&gt;\n* [monsanto](https://github.com/monsanto) - **Christopher Monsanto** &lt;chris@monsan.to&gt;\n* [Olegas](https://github.com/Olegas) - **Oleg Elifantiev** &lt;oleg@elifantiev.ru&gt;\n* [petkaantonov](https://github.com/petkaantonov) - **Petka Antonov** &lt;petka_antonov@hotmail.com&gt;\n* [phillipj](https://github.com/phillipj) - **Phillip Johnsen** &lt;johphi@gmail.com&gt;\n* [qard](https://github.com/qard) - **Stephen Belanger** &lt;admin@stephenbelanger.com&gt;\n* [rlidwka](https://github.com/rlidwka) - **Alex Kocharin** &lt;alex@kocharin.ru&gt;\n* [rmg](https://github.com/rmg) - **Ryan Graham** &lt;r.m.graham@gmail.com&gt;\n* [robertkowalski](https://github.com/robertkowalski) - **Robert Kowalski** &lt;rok@kowalski.gd&gt;\n* [romankl](https://github.com/romankl) - **Roman Klauke** &lt;romaaan.git@gmail.com&gt;\n* [saghul](https://github.com/saghul) - **Sa\u00fal Ibarra Corretg\u00e9** &lt;saghul@gmail.com&gt;\n* [sam-github](https://github.com/sam-github) - **Sam Roberts** &lt;vieuxtech@gmail.com&gt;\n* [seishun](https://github.com/seishun) - **Nikolai Vavilov** &lt;vvnicholas@gmail.com&gt;\n* [silverwind](https://github.com/silverwind) - **Roman Reiss** &lt;me@silverwind.io&gt;\n* [srl295](https://github.com/srl295) - **Steven R Loomis** &lt;srloomis@us.ibm.com&gt;\n* [targos](https://github.com/targos) - **Micha\u00ebl Zasso** &lt;mic.besace@gmail.com&gt;\n* [tellnes](https://github.com/tellnes) - **Christian Tellnes** &lt;christian@tellnes.no&gt;\n* [thealphanerd](https://github.com/thealphanerd) - **Myles Borins** &lt;myles.borins@gmail.com&gt;\n* [thefourtheye](https://github.com/thefourtheye) - **Sakthipriyan Vairamani** &lt;thechargingvolcano@gmail.com&gt;\n* [thekemkid](https://github.com/thekemkid) - **Glen Keane** &lt;glenkeane.94@gmail.com&gt;\n* [thlorenz](https://github.com/thlorenz) - **Thorsten Lorenz** &lt;thlorenz@gmx.de&gt;\n* [tunniclm](https://github.com/tunniclm) - **Mike Tunnicliffe** &lt;m.j.tunnicliffe@gmail.com&gt;\n* [vkurchatkin](https://github.com/vkurchatkin) - **Vladimir Kurchatkin** &lt;vladimir.kurchatkin@gmail.com&gt;\n* [whitlockjc](https://github.com/whitlockjc) - **Jeremy Whitlock** &lt;jwhitlock@apache.org&gt;\n* [yosuke-furukawa](https://github.com/yosuke-furukawa) - **Yosuke Furukawa** &lt;yosuke.furukawa@gmail.com&gt;\n* [zkat](https://github.com/zkat) - **Kat March\u00e1n** &lt;kzm@sykosomatic.org&gt;\n\nCollaborators & CTC members follow the [COLLABORATOR_GUIDE.md](./COLLABORATOR_GUIDE.md) in\nmaintaining the Node.js project.\n\n### Release Team\n\nReleases of Node.js and io.js will be signed with one of the following GPG keys:\n\n* **Chris Dickinson** &lt;christopher.s.dickinson@gmail.com&gt; `9554F04D7259F04124DE6B476D5A82AC7E37093B`\n* **Colin Ihrig** &lt;cjihrig@gmail.com&gt; `94AE36675C464D64BAFA68DD7434390BDBE9B9C5`\n* **Evan Lucas** &lt;evanlucas@me.com&gt; `B9AE9905FFD7803F25714661B63B535A4C206CA9`\n* **James M Snell** &lt;jasnell@keybase.io&gt; `71DCFD284A79C3B38668286BC97EC7A07EDE3FC1`\n* **Jeremiah Senkpiel** &lt;fishrock@keybase.io&gt; `FD3A5288F042B6850C66B31F09FE44734EB7990E`\n* **Myles Borins** &lt;myles.borins@gmail.com&gt; `C4F0DFFF4E8C1A8236409D08E73BC641CC11F4C8`\n* **Rod Vagg** &lt;rod@vagg.org&gt; `DD8F2338BAE7501E3DD5AC78C273792F7D83545D`\n* **Sam Roberts** &lt;octetcloud@keybase.io&gt; `0034A06D9D9B0064CE8ADF6BF1747F4AD2306D93`\n\nThe full set of trusted release keys can be imported by running:\n\n```\ngpg --keyserver pool.sks-keyservers.net --recv-keys 9554F04D7259F04124DE6B476D5A82AC7E37093B\ngpg --keyserver pool.sks-keyservers.net --recv-keys 94AE36675C464D64BAFA68DD7434390BDBE9B9C5\ngpg --keyserver pool.sks-keyservers.net --recv-keys 0034A06D9D9B0064CE8ADF6BF1747F4AD2306D93\ngpg --keyserver pool.sks-keyservers.net --recv-keys FD3A5288F042B6850C66B31F09FE44734EB7990E\ngpg --keyserver pool.sks-keyservers.net --recv-keys 71DCFD284A79C3B38668286BC97EC7A07EDE3FC1\ngpg --keyserver pool.sks-keyservers.net --recv-keys DD8F2338BAE7501E3DD5AC78C273792F7D83545D\ngpg --keyserver pool.sks-keyservers.net --recv-keys C4F0DFFF4E8C1A8236409D08E73BC641CC11F4C8\ngpg --keyserver pool.sks-keyservers.net --recv-keys B9AE9905FFD7803F25714661B63B535A4C206CA9\n```\n\nSee the section above on [Verifying Binaries](#verifying-binaries) for\ndetails on what to do with these keys to verify that a downloaded file is official.\n\nPrevious releases of Node.js have been signed with one of the following GPG\nkeys:\n\n* **Isaac Z. Schlueter** &lt;i@izs.me&gt; `93C7E9E91B49E432C2F75674B0A78B0A6C481CF6`\n* **Julien Gilli** &lt;jgilli@fastmail.fm&gt; `114F43EE0176B71C7BC219DD50A3051F888C628D`\n* **Timothy J Fontaine** &lt;tjfontaine@gmail.com&gt; `7937DFD2AB06298B2293C3187D33FF9D0246406D`\n", "release_dates": []}, {"name": "node-alias", "description": "Mac OS aliases creation and reading from node.js", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# node-alias\n\nMac OS aliases creation and reading from node.js\n\n## Attention\n\nThis library does currently not handle the `book\\0\\0\\0\\0mark\\0\\0\\0\\0`-header. It only does manipulation on the raw alias data.\n\nI intend to add something like `alias.write(buf, path)` and `alias.read(path)`.\n\n## Installation\n\n```sh\nnpm install macos-alias\n```\n\n## Usage\n\n```javascript\nvar alias = require('macos-alias');\n```\n\n## API\n\n### alias.create(target)\n\nCreate a new alias pointing to `target`, returns a buffer.\n\n(This function performs blocking fs interaction)\n\n### alias.decode(buf)\n\nDecodes buffer `buf` and returns an object with info about the alias.\n\n### alias.encode(info)\n\nEncodes the `info`-object into an alias, returns a buffer.\n\n### alias.isAlias(path)\n\nCheck if the file at `path` is an alias, returns a boolean.\n\n(This function performs blocking fs interaction)\n\n## Hacking\n\nClone the repo and start making changes, run `node-gyp` to build the project.\n\n```sh\nnode-gyp rebuild\n```\n\n## Tests\n\n```sh\nmocha\n```\n", "release_dates": []}, {"name": "node-anonize2-relic", "description": "Node bindings to the anonize2 library, using the RELIC toolkit.", "language": "C", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# node-anonize2-relic\nNode bindings to the [anonize2](https://gitlab.com/abhvious/anonize2) library,\nusing the [RELIC toolkit](https://github.com/relic-toolkit/relic).\n\n## Licensing\nThis repository contains the [anonize2](https://gitlab.com/abhvious/anonize2) library,\nwhich is licensed under [Apache v2.0 License](https://gitlab.com/abhvious/anonize2/blob/master/LICENSE.txt).\nThis repository also contains code derived from the [RELIC toolkit](https://github.com/relic-toolkit/relic),\nwhich is available under a [modified LGPL](https://github.com/relic-toolkit/relic/blob/master/COPYING) license.\nAll other files are licensed under the [MPL-2.0](./LICENSE).\n\nThe RELIC toolkit license is LGPLv2.1 with these overriding provisions:\n\n   1. Making modifications to RELIC configuration files, build scripts and\n      configuration headers such as \"relic_conf.h\" in order to create a\n      customized build setup of RELIC with the otherwise unmodified source code,\n      does not constitute a derived work.\n\n   2. Statically linking the RELIC library into a user application does not\n      make the user application a derived work, and therefore does not require\n      the user to distribute the source code or object code of their own\n      application. The RELIC source code with all modifications must still be\n      passed on in the same way as using RELIC as a shared library.\n\n   3. Using source code obfuscation on the RELIC source code when distributing\n      it is not permitted.\n\nIt is the intent of this package to produce a `librelic_s.a`,\nwhich is then used by as an add-on for node.js,\nit is believed that this package fully complies with the RELIC toolkit's licensing requirements.\n\n## You must have CMake installed\nThe easiest way to do this is:\n\n        npm install -g install-cmake\n", "release_dates": []}, {"name": "node-anonize2-relic-emscripten", "description": "Node bindings to the anonize2 library, using the RELIC toolkit and Emscripten.", "language": "C", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# node-anonize2-relic-emscripten\nJavascript bindings to the [anonize2](https://gitlab.com/abhvious/anonize2) library,\nusing the [RELIC toolkit](https://github.com/relic-toolkit/relic)\nand [Emscripten](https://github.com/kripken/emscripten)\n\nThe package will look for `anonize2.js.mem` in `__dirname` unless `__dirname` contains `\"app.asar\"`,\nin which case the directory \n\n    \".../Contents/Resources/app.asar.unpacked/node_modules/node-anonize2-relic-emscripten/anonize2.js.mem\"\n\nis consulted instead.\n\n## Licensing\nThis repository contains the [anonize2](https://gitlab.com/abhvious/anonize2) library,\nwhich is licensed under [Apache v2.0 License](https://gitlab.com/abhvious/anonize2/blob/master/LICENSE.txt).\nThis repository also contains code derived from the [RELIC toolkit](https://github.com/relic-toolkit/relic),\nwhich is available under a [modified LGPL](https://github.com/relic-toolkit/relic/blob/master/COPYING) license.\nAll other files are licensed under the [MPL-2.0](./LICENSE).\n\nThe RELIC toolkit license is LGPLv2.1 with these overriding provisions:\n\n   1. Making modifications to RELIC configuration files, build scripts and\n      configuration headers such as \"relic_conf.h\" in order to create a\n      customized build setup of RELIC with the otherwise unmodified source code,\n      does not constitute a derived work.\n\n   2. Statically linking the RELIC library into a user application does not\n      make the user application a derived work, and therefore does not require\n      the user to distribute the source code or object code of their own\n      application. The RELIC source code with all modifications must still be\n      passed on in the same way as using RELIC as a shared library.\n\n   3. Using source code obfuscation on the RELIC source code when distributing\n      it is not permitted.\n\nThis package uses the `anonize2.js` and `anonize2.js.mem` files produced by the\n[anonize2 build area](https://gitlab.com/abhvious/anonize2/builds),\nwhich is then used by as an add-on for node.js,\nit is believed that this package fully complies with the RELIC toolkit's licensing requirements.\n\n## Making the emscripten version\n\n* On the Mac:\n\n  * `brew install emscripten cmake`\n\n  * Edit `~/.emscripten` to set\n\n        LLVM_ROOT = '/Users/mrose/homebrew/Cellar/emscripten/1.37.1/libexec/llvm/bin'\n\n  * Install a JDK\n\n* Run `cmake.sh`\n", "release_dates": []}, {"name": "node-dtrace-provider", "description": "Native DTrace probes for node.js apps", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# dtrace-provider - Native DTrace providers for Node.js apps.\n\nThis extension allows you to create native DTrace providers for your\nNode.js applications. That is, to create providers and probes which\nexpose information specific to your application, rather than\ninformation about the node runtime.\n\nYou could use this to expose high-level information about the inner\nworkings of your application, or to create a specific context in which\nto look at information from other runtime or system-level providers. \n\nThe provider is not created in the usual way, by declaring it and then\nchanging the build process to include it, but instead dynamically at\nruntime. This is done entirely in-process, and there is no background\ncompiler or [dtrace(1M)](https://illumos.org/man/1M/dtrace) invocation.\nThe process creating the provider need not run as root.\n\n## INSTALL\n\n    $ npm install dtrace-provider\n\n## EXAMPLE\n\nHere's a simple example of creating a provider:\n\n```javascript\nvar d = require('dtrace-provider');\n\nvar dtp = d.createDTraceProvider(\"nodeapp\");\nvar p1 = dtp.addProbe(\"probe1\", \"int\", \"int\");\nvar p2 = dtp.addProbe(\"probe2\", \"char *\");\ndtp.enable();\n```\n\nProbes may be fired via the provider object:\n\n```javascript\ndtp.fire(\"probe1\", function() {\n    return [1, 2];\n});\ndtp.fire(\"probe2\", function() {\n    return [\"hello, dtrace via provider\", \"foo\"];\n});\n```\n\nor via the probe objects themselves:\n\n```javascript\np1.fire(function() {\n  return [1, 2, 3, 4, 5, 6];\n});\np2.fire(function() {\n  return [\"hello, dtrace via probe\", \"foo\"];\n});\n```\n\nNote that `.fire()` takes a callback that returns the arguments to be\nprovided when the DTrace probe actually fires. This allows you to call\n`.fire()` unconditionally when you want to fire the probe, but the\ncallback will be invoked only when the DTrace probe is actually\nenabled. This allows you to create probes whose arguments might be\nexpensive to construct, and only do any work when the probe is\nactually enabled. (Examples might include converting a large object to\na string representation or gathering large amounts of information.)\n\nIn some cases, creating a new closure to pass to `.fire()` each time\nit's called may introduce unwanted overhead. For extremely\nCPU-intensive or memory-conscious workloads, you can avoid this by\nlifting the closures for your hot probes into an outer scope. You can\nthen supply arguments to that function as additional arguments to\n`.fire()`. As an example, you can convert the following program:\n\n```javascript\nfunction manipulateObj(largeObj) {\n    var count = 0;\n    var name = null;\n    ...\n    p1.fire(function () {\n        return [count, keyToValue(name), JSON.stringify(largeObj)];\n    });\n}\n```\n\nInto this one:\n\n```javascript\nfunction f(a, b, c) {\n    return [a, keyToValue(b), JSON.stringify(c)];\n}\n\nfunction manipulateObj(largeObj) {\n    var count = 0;\n    var name = null;\n    ...\n    p1.fire(f, count, name, largeObj);\n}\n```\n\nBe careful to avoid passing `.fire()` additional arguments that are\nthemselves expensive to construct, as that undermines the design goal\nhere: minimizing the effect of disabled probes.\n\nThis example creates a provider called \"nodeapp\", and adds two\nprobes. It then enables the provider, at which point the provider\nbecomes visible to DTrace.\n\nThe probes are then fired, which produces this output:\n\n    $ sudo dtrace -Z -n 'nodeapp*:::probe1{ trace(arg0); trace(arg1) }'  \\\n                     -n 'nodeapp*:::probe2{ trace(copyinstr(arg0));  }'\n    dtrace: description 'nodeapp*:::probe1' matched 0 probes\n    dtrace: description 'nodeapp*:::probe2' matched 0 probes\n    CPU     ID                    FUNCTION:NAME\n      1 123562                      func:probe1                 1                2\n      1 123563                      func:probe2   hello, dtrace                    \n\nArguments are captured by a callback only executed when the probe is\nenabled. This means you can do more expensive work to gather arguments.\n\nThe maximum number of arguments supported is 32. \n\nAvailable argument types are \"int\", for integer numeric values,\n\"char *\" for strings, and \"json\" for objects rendered into JSON strings.\n\nArguments typed as \"json\" will be created as \"char *\" probes in\nDTrace, but objects passed to these probe arguments will be\nautomatically serialized to JSON before being passed to DTrace. This\nfeature is best used in conjunction with the json() D subroutine, but\nis available whether or not the platform supports it.\n\n    # create a json probe:\n\n    var dtp = d.createDTraceProvider(\"nodeapp\");\n    var p1 = dtp.addProbe(\"j1\", \"json\");\n    dtp.enable();\n    p1.fire(function() { return { \"foo\": \"bar\" }; });\n\n    # on a platform supporting json():\n\n    $ sudo dtrace -Z -n 'nodeapp*:::j1{ this->j = copyinstr(arg0); \\\n                                        trace(json(this->j, \"foo\")) }'\n    dtrace: description 'nodeapp$target:::j1' matched 0 probes\n    CPU     ID                    FUNCTION:NAME\n      0  68712                            j1:j1   bar\n\n## PLATFORM SUPPORT\n\nThis libusdt-based Node.JS module supports 64 and 32 bit processes on\nMac OS X and Solaris-like systems such as illumos or SmartOS. As more\nplatform support is added to libusdt, those platforms will be\nsupported by this module. See libusdt's status at:\n\n  https://github.com/chrisa/libusdt#readme\n\nWhen using Mac OS X, be aware that as of 10.11 (El Capitan), DTrace use\nis restricted, and you'll probably want to\n[disable SIP](http://internals.exposed/blog/dtrace-vs-sip.html) to\neffectively use DTrace.\n\nFreeBSD 10 and 11 are also supported, but you'll need to make sure that\nyou have the DTrace headers installed in `/usr/src` otherwise libusdt\nwon't be able to compile. You can\n[clone them using SVN](https://www.freebsd.org/doc/handbook/svn.html),\nor find the correct `src.txz`\n[here](http://ftp.freebsd.org/pub/FreeBSD/releases/) and extract that.\nAlso note that FreeBSD 10 is restricted to only 4 working arguments per\nprobe.\n\nPlatforms not supporting DTrace (notably, Linux and Windows) may\ninstall this module without building libusdt, with a stub no-op\nimplementation provided for compatibility. This allows cross-platform\nnpm modules to embed probes and include a dependency on this module.\n\nGNU Make is required to build libusdt; the build scripts will look for\ngmake in `PATH` first, and then for make.\n\n### TROUBLESHOOTING BUILD ISSUES\n\nIf compilation fails during installation on platforms with DTrace, then\nthe library will fall back to the stub implementation that does nothing.\nTo force an installation failure when compiling fails, set the environment\nvariable `NODE_DTRACE_PROVIDER_REQUIRE` to `hard`:\n\n```shell\n$ NODE_DTRACE_PROVIDER_REQUIRE=hard npm install\n```\n\nThis will then show you the output of the build process so you can see at\nwhich point it's having an issue. Common issues are:\n\n- Missing a C/C++ compiler toolchain for your platform.\n- `python` is Python 3 instead of Python 2; run `npm config set python python2.7`\n  (or similar) to set the Python binary npm uses.\n- On OS X you may need to agree to the XCode license if that's the compiler\n  toolchain you're using. This will usually manifest with an error like\n  `Agreeing to the Xcode/iOS license requires admin privileges, please re-run as root via sudo.`\n  To accept the license, you can run `sudo xcodebuild -license`.\n\nOnce you've found and fixed the issue, you can run `npm rebuild` to rerun\nthe lifecycle scripts.\n\n## CAVEATS\n\nThere is some overhead to probes, even when disabled. Probes are\nalready using the \"is-enabled\" feature of DTrace to control execution\nof the arguments-gathering callback, but some work still needs to be\ndone before that's checked. This overhead should not be a problem\nunless probes are placed in particularly hot code paths.\n\n## CONTRIBUTING\n\nTo clone the project's source code:\n\n    $ git clone --recursive https://github.com/chrisa/node-dtrace-provider.git\n\nFor issues, please use the [GitHub issue tracker](https://github.com/chrisa/node-dtrace-provider/issues)\nlinked to the repository. GitHub pull requests are very welcome.\n\n## RUNNING THE TESTS\n\n```shell\n$ npm install\n$ sudo ./node_modules/.bin/tap --tap test/*.test.js\n```\n\n## OTHER IMPLEMENTATIONS\n\nThis node extension is derived from the ruby-dtrace gem, via the Perl\nmodule Devel::DTrace::Provider, both of which provide the same\nfunctionality to those languages.\n", "release_dates": []}, {"name": "node-gyp", "description": "Node.js native addon build tool", "language": "Python", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# `node-gyp` - Node.js native addon build tool\n\n`node-gyp` is a cross-platform command-line tool written in Node.js for compiling\nnative addon modules for Node.js. It bundles the [gyp](https://gyp.gsrc.io)\nproject used by the Chromium team and takes away the pain of dealing with the\nvarious differences in build platforms.\n\nMultiple target versions of Node.js are supported (i.e. `0.8`, ..., `4`, `5`, `6`,\netc.), regardless of what version of Node.js is actually installed on your system\n(`node-gyp` downloads the necessary development files or headers for the target version).\n\n## Features\n\n * Easy to use, consistent interface\n * Same commands to build your module on every platform\n * Supports multiple target versions of Node.js\n\n## Installation\n\nYou can install with `npm`:\n\n``` bash\n$ npm install -g node-gyp\n```\n\nYou will also need to install:\n\n### On Unix\n\n   * `python` (`v2.7` recommended, `v3.x.x` is __*not*__ supported)\n   * `make`\n   * A proper C/C++ compiler toolchain, like [GCC](https://gcc.gnu.org)\n\n### On macOS\n\n   * `python` (`v2.7` recommended, `v3.x.x` is __*not*__ supported) (already installed on macOS)\n   * [Xcode](https://developer.apple.com/xcode/download/)\n     * You also need to install the `Command Line Tools` via Xcode. You can find this under the menu `Xcode -> Preferences -> Locations` (or by running `xcode-select --install` in your Terminal)\n       * This step will install `gcc` and the related toolchain containing `make`\n\n### On Windows\n\n#### Option 1\n\nInstall all the required tools and configurations using Microsoft's [windows-build-tools](https://github.com/felixrieseberg/windows-build-tools) using `npm install --global --production windows-build-tools` from an elevated PowerShell or CMD.exe (run as Administrator).\n\n#### Option 2\n\nInstall tools and configuration manually:\n   * Install Visual C++ Build Environment: [Visual Studio Build Tools](https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools)\n   (using \"Visual C++ build tools\" workload) or [Visual Studio 2017 Community](https://visualstudio.microsoft.com/pl/thank-you-downloading-visual-studio/?sku=Community)\n   (using the \"Desktop development with C++\" workload)\n   * Install [Python 2.7](https://www.python.org/downloads/) (`v3.x.x` is not supported), and run `npm config set python python2.7` (or see below for further instructions on specifying the proper Python version and path.)\n   * Launch cmd, `npm config set msvs_version 2017`\n\n   If the above steps didn't work for you, please visit [Microsoft's Node.js Guidelines for Windows](https://github.com/Microsoft/nodejs-guidelines/blob/master/windows-environment.md#compiling-native-addon-modules) for additional tips.\n\n   To target native ARM64 Node.js on Windows 10 on ARM, add the components \"Visual C++ compilers and libraries for ARM64\" and \"Visual C++ ATL for ARM64\".\n\n### Configuring Python Dependency\n\nIf you have multiple Python versions installed, you can identify which Python\nversion `node-gyp` uses by setting the `--python` variable:\n\n``` bash\n$ node-gyp --python /path/to/python2.7\n```\n\nIf `node-gyp` is called by way of `npm`, *and* you have multiple versions of\nPython installed, then you can set `npm`'s 'python' config key to the appropriate\nvalue:\n\n``` bash\n$ npm config set python /path/to/executable/python2.7\n```\n\n## How to Use\n\nTo compile your native addon, first go to its root directory:\n\n``` bash\n$ cd my_node_addon\n```\n\nThe next step is to generate the appropriate project build files for the current\nplatform. Use `configure` for that:\n\n``` bash\n$ node-gyp configure\n```\n\nAuto-detection fails for Visual C++ Build Tools 2015, so `--msvs_version=2015`\nneeds to be added (not needed when run by npm as configured above):\n``` bash\n$ node-gyp configure --msvs_version=2015\n```\n\n__Note__: The `configure` step looks for a `binding.gyp` file in the current\ndirectory to process. See below for instructions on creating a `binding.gyp` file.\n\nNow you will have either a `Makefile` (on Unix platforms) or a `vcxproj` file\n(on Windows) in the `build/` directory. Next, invoke the `build` command:\n\n``` bash\n$ node-gyp build\n```\n\nNow you have your compiled `.node` bindings file! The compiled bindings end up\nin `build/Debug/` or `build/Release/`, depending on the build mode. At this point,\nyou can require the `.node` file with Node.js and run your tests!\n\n__Note:__ To create a _Debug_ build of the bindings file, pass the `--debug` (or\n`-d`) switch when running either the `configure`, `build` or `rebuild` commands.\n\n## The `binding.gyp` file\n\nA `binding.gyp` file describes the configuration to build your module, in a\nJSON-like format. This file gets placed in the root of your package, alongside\n`package.json`.\n\nA barebones `gyp` file appropriate for building a Node.js addon could look like:\n\n``` python\n{\n  \"targets\": [\n    {\n      \"target_name\": \"binding\",\n      \"sources\": [ \"src/binding.cc\" ]\n    }\n  ]\n}\n```\n\nSome additional resources for addons and writing `gyp` files:\n\n * [\"Going Native\" a nodeschool.io tutorial](http://nodeschool.io/#goingnative)\n * [\"Hello World\" node addon example](https://github.com/nodejs/node/tree/master/test/addons/hello-world)\n * [gyp user documentation](https://gyp.gsrc.io/docs/UserDocumentation.md)\n * [gyp input format reference](https://gyp.gsrc.io/docs/InputFormatReference.md)\n * [*\"binding.gyp\" files out in the wild* wiki page](https://github.com/nodejs/node-gyp/wiki/%22binding.gyp%22-files-out-in-the-wild)\n\n\n## Commands\n\n`node-gyp` responds to the following commands:\n\n| **Command**   | **Description**\n|:--------------|:---------------------------------------------------------------\n| `help`        | Shows the help dialog\n| `build`       | Invokes `make`/`msbuild.exe` and builds the native addon\n| `clean`       | Removes the `build` directory if it exists\n| `configure`   | Generates project build files for the current platform\n| `rebuild`     | Runs `clean`, `configure` and `build` all in a row\n| `install`     | Installs Node.js header files for the given version\n| `list`        | Lists the currently installed Node.js header versions\n| `remove`      | Removes the Node.js header files for the given version\n\n\n## Command Options\n\n`node-gyp` accepts the following command options:\n\n| **Command**                       | **Description**\n|:----------------------------------|:------------------------------------------\n| `-j n`, `--jobs n`                | Run `make` in parallel\n| `--target=v6.2.1`                 | Node.js version to build for (default is `process.version`)\n| `--silly`, `--loglevel=silly`     | Log all progress to console\n| `--verbose`, `--loglevel=verbose` | Log most progress to console\n| `--silent`, `--loglevel=silent`   | Don't log anything to console\n| `debug`, `--debug`                | Make Debug build (default is `Release`)\n| `--release`, `--no-debug`         | Make Release build\n| `-C $dir`, `--directory=$dir`     | Run command in different directory\n| `--make=$make`                    | Override `make` command (e.g. `gmake`)\n| `--thin=yes`                      | Enable thin static libraries\n| `--arch=$arch`                    | Set target architecture (e.g. ia32)\n| `--tarball=$path`                 | Get headers from a local tarball\n| `--devdir=$path`                  | SDK download directory (default is OS cache directory)\n| `--ensure`                        | Don't reinstall headers if already present\n| `--dist-url=$url`                 | Download header tarball from custom URL\n| `--proxy=$url`                    | Set HTTP proxy for downloading header tarball\n| `--cafile=$cafile`                | Override default CA chain (to download tarball)\n| `--nodedir=$path`                 | Set the path to the node source code\n| `--python=$path`                  | Set path to the Python 2 binary\n| `--msvs_version=$version`         | Set Visual Studio version (Windows only)\n| `--solution=$solution`            | Set Visual Studio Solution version (Windows only)\n\n## Configuration\n\n### Environment variables\n\nUse the form `npm_config_OPTION_NAME` for any of the command options listed\nabove (dashes in option names should be replaced by underscores).\n\nFor example, to set `devdir` equal to `/tmp/.gyp`, you would:\n\nRun this on Unix:\n\n```bash\n$ export npm_config_devdir=/tmp/.gyp\n```\n\nOr this on Windows:\n\n```console\n> set npm_config_devdir=c:\\temp\\.gyp\n```\n\n### `npm` configuration\n\nUse the form `OPTION_NAME` for any of the command options listed above.\n\nFor example, to set `devdir` equal to `/tmp/.gyp`, you would run:\n\n```bash\n$ npm config set [--global] devdir /tmp/.gyp\n```\n\n**Note:** Configuration set via `npm` will only be used when `node-gyp`\nis run via `npm`, not when `node-gyp` is run directly.\n\n## License\n\n`node-gyp` is available under the MIT license. See the [LICENSE\nfile](LICENSE) for details.\n", "release_dates": []}, {"name": "node-minidump", "description": "Node module to process minidump files", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# minidump - Process minidump files [![Build Status](https://travis-ci.org/atom/node-minidump.svg?branch=master)](https://travis-ci.org/atom/node-minidump)\n\n## Installing\n\n```sh\nnpm install minidump\n```\n\n## Building\n  * Clone the repository recursively\n  * Run `npm install`\n\n## Docs\n\n```javascript\nvar minidump = require('minidump');\n```\n\n### minidump.addSymbolPath(path1, ..., pathN)\n\nAdd search paths for looking up symbol files.\n\n### minidump.walkStack(minidumpFilePath, symbolPaths, callback, options)\n\noptions {object}:\n\n  machine: [false] - should output be in parseable format\n\nGet the stack trace from `minidumpFilePath`, the `callback` would be called\nwith `callback(error, report)` upon completion.\n\n### minidump.dumpSymbol(binaryPath, callback)\n\nDump debug symbols in minidump format from `binaryPath`, the `callback` would\nbe called with `callback(error, minidump)` upon completion.\n", "release_dates": []}, {"name": "node-sha3", "description": "A Node.js C++ extension for SHA-3 (Keccak)", "language": "C++", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# A Node.js C++ extension for SHA-3 (Keccak)\n\nThis Node.js extension implements the SHA-3 ([Keccak](http://keccak.noekeon.org/)) cryptographic hashing algorithm. It is based on the reference C implementation, version 3.2. The exposed interface is almost identical to that of the `crypto` standard library.\n\n[![Build Status](https://travis-ci.org/phusion/node-sha3.svg?branch=master)](https://travis-ci.org/phusion/node-sha3)\n\n[<img src=\"http://www.phusion.nl/assets/logo.png\">](http://www.phusion.nl/)\n\n## Installation\n\n    npm install sha3\n\n## Usage\n\nKeccak supports 5 hash lengths: 224-bit, 256-bit, 384-bit, 512-bit and variable length. Variable length is not supported by this Node.js extension. Unless the user specifies otherwise, this Node.js extension assumes 512-bit.\n\n    var SHA3 = require('sha3');\n\n    // Generate 512-bit digest.\n    var d = new SHA3.SHA3Hash();\n    d.update('foo');\n    d.digest('hex');   // => \"1597842a...\"\n\n    // Generate 224-bit digest.\n    var d = new SHA3.SHA3Hash(224);\n    d.update('foo');\n    d.digest('hex');   // => \"daa94da7...\"\n\n### new SHA3Hash([hashlen])\n\nThis is the hash object. `hashlen` is 512 by default.\n\n### hash.update(data, [input_encoding])\n\nUpdates the hash content with the given data, the encoding of which is given in `input_encoding` and can be `'utf8'`, `'ascii'` or `'binary'`. Defaults to `'binary'`. This can be called many times with new data as it is streamed.\n\n### hash.digest([encoding])\n\nCalculates the digest of all of the passed data to be hashed. The encoding can be `'hex'` or `'binary'`. Defaults to `'binary'`.\n\nNote: unlike `crypto.Hash`, a `SHA3Hash` object _can_ still be used after the `digest()` method been called.\n\n## Running the test suite\n\nRun the test suite as follows:\n\n    npm test\n\nThe test suite is automatically generated from Keccak's reference test suite.\nIt requires that you have Python 2.7 installed and available via the\n`python` executable.\n\n## Warning\n\nDo not use SHA-3 for hashing passwords. Do not even use SHA-3 + salt for hashing passowords. Use a [slow hash](http://codahale.com/how-to-safely-store-a-password/) instead.\n\n## See also\n\n[Digest::SHA3 for Ruby](https://github.com/phusion/digest-sha3-ruby)\n", "release_dates": []}, {"name": "node-spellchecker", "description": "SpellChecker Node Module", "language": "C++", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# SpellChecker Node Module [![Build Status](https://travis-ci.org/atom/node-spellchecker.svg?branch=master)](https://travis-ci.org/atom/node-spellchecker) [![Build status](https://ci.appveyor.com/api/projects/status/up294b734wagwlaw/branch/master?svg=true)](https://ci.appveyor.com/project/kevinsawicki/node-spellchecker/branch/master)\n\nNative bindings to [NSSpellChecker](https://developer.apple.com/library/mac/#documentation/cocoa/reference/ApplicationKit/Classes/NSSpellChecker_Class/Reference/Reference.html), [Hunspell](http://hunspell.sourceforge.net/), or the [Windows 8 Spell Check API](https://msdn.microsoft.com/en-us/library/windows/desktop/hh869853(v=vs.85).aspx), depending on your platform. Windows 7 and below as well as Linux will rely on Hunspell.\n\n## Installing\n\n```bash\nnpm install spellchecker\n```\n\n## Using\n\n```coffeescript\nSpellChecker = require 'spellchecker'\n```\n\n### SpellChecker.isMisspelled(word)\n\nCheck if a word is misspelled.\n\n`word` - String word to check.\n\nReturns `true` if the word is misspelled, `false` otherwise.\n\n### SpellChecker.getCorrectionsForMisspelling(word)\n\nGet the corrections for a misspelled word.\n\n`word` - String word to get corrections for.\n\nReturns a non-null but possibly empty array of string corrections.\n\n### SpellChecker.add(word)\n\nAdds a word to the dictionary.\nWhen using Hunspell, this will not modify the .dic file; new words must be added each time the spellchecker is created. Use a custom dictionary file.\n\n`word` - String word to add.\n\nReturns nothing.\n", "release_dates": []}, {"name": "omaha", "description": "Omaha for brave-browser", "language": "C++", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Omaha\n\n## This is not an official Google product.\n## How to build ##\nSee https://github.com/brave/brave-browser/wiki/Brave-omaha\n\nOmaha is the open-source version of Google Update, a program to install requested software and keep it up to date.  The Google-branded version of Omaha is used to support software patching (both background updating, and on-demand update checks) for Google Chrome, Earth, and a variety of other Google products on Windows 7, 8, and 10.\n\nFor a quick overview of how Omaha works, you can see [this unofficial tutorial](https://fman.io/blog/google-omaha-tutorial/). Please note that it was written by a third party so we cannot guarantee its availability, accuracy or safety.\n\nWe know that keeping software updated is both important and hard, and so by open-sourcing this project, our hope is that perhaps we can help others solve this problem. So, if you'd like to get involved, or even use Omaha to support your own software projects, then just follow the instructions in the [Developer Setup Guide](https://github.com/google/omaha/blob/master/doc/DeveloperSetupGuide.md), and you'll be good to go!\n", "release_dates": []}, {"name": "omaha-build", "description": "[WIP] Windows omaha client", "language": "PowerShell", "license": null, "readme": "### This will be archived soon, see https://github.com/brave/omaha-build/issues/5\n\nNote: You will need packer >= 1.2.3 to avoid an issue where imported vagrant box's are empty\n\n### Build vs2015community box\npacker build --only=virtualbox-iso packer.json\n\n### Bring up vagrant box\n```\nvagrant box add -n vs2015community ./<path to packer output>\nvagrant up\nvagrant reload\n```\n\n### Manual steps\n* Install C:\\tmp\\pywin32.exe\n* Install C:\\tmp\\scons.exe\n* In cmd prompt:\n  * `cd C:\\omaha\\omaha`\n  * `C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat`\n  * `hammer`\n", "release_dates": []}, {"name": "omaha-server", "description": "Google Omaha server (as known as Google Update)", "language": "Python", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# omaha-server\n\n[![Build Status](https://travis-ci.org/brave/omaha-server.svg?branch=master)](https://travis-ci.org/brave/omaha-server)\n[![Coverage Status](https://coveralls.io/repos/brave/omaha-server/badge.png?branch=master)](https://coveralls.io/r/brave/omaha-server?branch=master)\n[![Code Health](https://landscape.io/github/brave/omaha-server/master/landscape.svg?style=flat)](https://landscape.io/github/brave/omaha-server/master)\n[![Scrutinizer Code Quality](https://scrutinizer-ci.com/g/brave/omaha-server/badges/quality-score.png?b=master)](https://scrutinizer-ci.com/g/brave/omaha-server/?branch=master)\n[![Apache License, Version 2.0](https://img.shields.io/badge/license-Apache%202.0-red.svg)](https://github.com/brave/omaha-server/blob/master/LICENSE)\n[![](https://badge.imagelayers.io/brave/omaha-server:master.svg)](https://imagelayers.io/?images=brave/omaha-server:master 'Get your own badge on imagelayers.io')\n\nGoogle Omaha server implementation and Sparkle (mac) feed management.\n\nCurrently, our implementation is integrated into the updating processes of several organisations for products that require sophisticated update logic and advanced usage statistics. We provide additional support and further enhancement on a contract basis. For a case study and enquiries please refer [our website](https://www.crystalnix.com/case-study/google-omaha)\n\n## Setting up a development server\n\n**Requirements:**\n\n- Ubuntu Trusty 14.04 (LTS) (64-bit)\n- [pipenv](https://pipenv.readthedocs.io/en/latest/)\n- [docker](docker.com) or [boot2docker](https://github.com/boot2docker/boot2docker) for OS X & Windows\n- [docker-compose](https://docs.docker.com/compose/install/)\n\n```shell\n$ sudo apt-get update\n$ sudo apt-get install docker.io\n$ sudo apt-get install python python-pip\n$ sudo pip install -U pipenv\n$ sudo pip install -U docker-compose\n$ git clone https://github.com/brave/omaha-server.git\n$ cd omaha-server\n# Up local environment\n$ make up\n\n# Stop server\n$ make stop\n```\n\nOpen `http://{DOCKER_HOST}:9090/admin/`\n\n- username: `admin`\n- password: `admin`\n\n## Setting up a development environment\n\n**Requirements:**\n\n- python 3.7\n- [pipenv](https://pipenv.readthedocs.io/en/latest/)\n- PostgreSQL\n- Redis\n\n```shell\n$ sudo pip install -U pipenv\n$ make install-dev\n```\n\n## Activate virtual environment\n\n```shell\n$ pipenv shell\n```\n\n### Tests\n\n```shell\n$ make test\n```\n\n## Statistics\n\nAll statistics are stored in Redis. In order not to lose all data, we recommend to set up the backing up process. The proposed solution uses ElastiCache which supports [automatic backups](https://aws.amazon.com/en/blogs/aws/backup-and-restore-elasticache-redis-nodes/). In the case of a self-hosted solution do not forget to set up backups.\n\nRequired `userid`. [Including user id into request](https://github.com/Crystalnix/omaha/wiki/Omaha-Client-working-with-protocol#including-user-id-into-request)\n\n## Utils\n\nA command for generating fake data such as requests, events and statistics:\n\n```shell\n# Usage: ./manage.py generate_fake_data [options] <app_id>\n# Options:\n#     --count=COUNT         Total number of data values (default: 100)\n$ ./manage.py generate_fake_data {F07B3878-CD6F-4B96-B52F-95C4D2} --count=20\n```\n\nA command for generating fake statistics:\n\n```shell\n# Usage: ./manage.py generate_fake_statistics [options]\n# Options:\n#     --count=COUNT         Total number of data values (default: 100)\n$ ./manage.py generate_fake_statistics --count=3000\n```\n\nA command for generating fake live data:\n\n```shell\n# Usage: ./manage.py generate_fake_live_data <app_id>\n#\n$ ./manage.py generate_fake_live_data {c00b6344-038f-4e51-bcb1-33ffdd812d81}\n```\n\nA command for generating fake live data for Mac:\n\n```shell\n# Usage: ./manage.py generate_fake_mac_live_data <app_name> <channel>\n#\n$ ./manage.py generate_fake_mac_live_data Application alpha\n```\n\n## Deploying Omaha-Server to AWS\n\n**Requirements:**\n\n- [Sentry](https://github.com/getsentry/sentry)\n\t\t+ [SetUp Sentry as self-hosted solution](https://docs.sentry.io/server/installation/)\n\t\t+ [Sentry as SaaS solution](https://www.getsentry.com/)\n- AWS RDS: [Creating a DB Instance Running the PostgreSQL Database Engine](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreatePostgreSQLInstance.html)\n- Redis instance in AWS ElasticCache: [Documentation](http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/GettingStarted.CreateCluster.Redis.html)\n- AWS S3: [Create a Bucket](http://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html)\n- [AWS Access Key ID and Secret Access Key](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSGettingStartedGuide/AWSCredentials.html)\n\n#### Environment variables\n\n| Environment variable name |    Description       |       Default value        |\n|---------------------------|----------------------|----------------------------|\n| APP_VERSION               | App version          | DEV                        |\n| DJANGO_SETTINGS_MODULE    |                      | omaha_server.settings      |\n| SECRET_KEY                | Django SECRET_KEY    |                            |\n| HOST_NAME                 | App host name        |                            |\n| DB_HOST                   | DB Host              | 127.0.0.1                  |\n| DB_USER                   | DB User              | postgres                   |\n| DB_NAME                   | DB Name              | postgres                   |\n| DB_PASSWORD               | DB Password          | ''                         |\n| DB_PORT                   | DB port              | 5432                       |\n| AWS_ACCESS_KEY_ID         | AWS Access Key       |                            |\n| AWS_SECRET_ACCESS_KEY     | AWS Secret Key       |                            |\n| AWS_STORAGE_BUCKET_NAME   | S3 storage bucket    |                            |\n| RAVEN_DSN                 | Sentry url           |                            |\n| RAVEN_DSN_STACKTRACE      | Sentry url           | RAVEN_DSN                  |\n| REDIS_HOST                | Redis host           | 127.0.0.1                  |\n| REDIS_PORT                | Redis port           | 6379                       |\n| REDIS_DB                  | Redis db             | 1                          |\n| REDIS_STAT_PORT           | For statistics       | REDIS_PORT                 |\n| REDIS_STAT_HOST           |                      | REDIS_HOST                 |\n| REDIS_STAT_DB             |                      | 15                         |\n| UWSGI_PROCESSES           |                      |                            |\n| UWSGI_THREADS             |                      |                            |\n| OMAHA_SERVER_PRIVATE      | Is private server    | False                      |\n| DB_PUBLIC_USER            |                      |                            |\n| DB_PUBLIC_PASSWORD        |                      |                            |\n| AWS_ROLE                  |                      |                            |\n| OMAHA_URL_PREFIX          | no trailing slash!   |                            |\n| SENTRY_STACKTRACE_API_KEY | Auth API token       |                            |\n| OMAHA_ONLY_HTTPS          | HTTPS-only           | False                      |\n| CUP_REQUEST_VALIDATION    |                      | False                      |\n| CRASH_TRACKER             | Sentry, ELK          | Sentry                     |\n| LOGSTASH_HOST             | Logstash host        |                            |\n| LOGSTASH_PORT             | Logstash TCP port    |                            |\n| FILEBEAT_HOST             | Filebeat host        | 127.0.0.1                  |\n| FILEBEAT_PORT             | Filebeat UDP port    | 9021                       |\n| ELK_HOST                  | Logstash host        | ''                         |\n| ELK_PORT                  | Logstash TCP port    | ''                         |\n| FILEBEAT_DESTINATION      | filebeat output type | ''                         |\n| LOG_NGINX_TO_FILEBEAT     | Send logs to filebeat| 'True'                     |\n| EMAIL_SENDER              | Verified SES email   |                            |\n| EMAIL_RECIPIENTS          | Feedback recepients  |                            |\n| RSYSLOG_ENABLE            | Send logs to rsyslog | ''                         |\n\n\n\n- [uWSGI Options](http://uwsgi-docs.readthedocs.org/en/latest/Options.html) & [Environment variables](http://uwsgi-docs.readthedocs.org/en/latest/Configuration.html#environment-variables)\n- [Sentry](https://github.com/getsentry/sentry)\n- Sentry API key is stored on the way Sentry Organization page -> API Keys\n\n#### Enable Client Update Protocol v2\n\n1. Use [Omaha eckeytool](https://github.com/google/omaha/tree/master/omaha/tools/eckeytool) to generate private.pem key and cup_ecdsa_pubkey.{KEYID}.h files.\n2. Add cup_ecdsa_pubkey.{KEYID}.h to Omaha source directory /path/to/omaha/omaha/net/, set CupEcdsaRequestImpl::kCupProductionPublicKey in /path/to/omaha/omaha/net/cup_ecdsa_request.cc to new key and build Omaha client.\n3. Add private.pem keyid and path to omaha CUP_PEM_KEYS dictionary.\n\n## Links\n\n- Presentation: [omaha-server High Fidelity, High Velocity Deployments in the Cloud](http://slides.com/andreylisin/omaha-server/#/)\n\n## Contributors\n\nThanks to [Abiral Shrestha](https://twitter.com/proabiral) for the security reports and suggestions.\n\n## Copyright and license\n\nThis software is licensed under the Apache 2 license, quoted below.\n\nCopyright 2014 [Crystalnix Limited](http://crystalnix.com)\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not\nuse this file except in compliance with the License. You may obtain a copy of\nthe License at\n\n[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\nWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\nLicense for the specific language governing permissions and limitations under\nthe License.\n", "release_dates": []}, {"name": "optional-dev-dependency", "description": ":sunglasses: try to install an optional development dependency, YOLO if you can't.", "language": "JavaScript", "license": {"key": "isc", "name": "ISC License", "spdx_id": "ISC", "url": "https://api.github.com/licenses/isc", "node_id": "MDc6TGljZW5zZTEw"}, "readme": "# optional-dev-dependency\n\n[![Build Status][travis-image]][travis-url]\n[![Coverage Status][coveralls-image]][coveralls-url]\n[![NPM version][npm-image]][npm-url]\n[![js-standard-style][standard-image]][standard-url]\n\nFor when you want to try to install a module, but want to keep on truckin'\nif you are unable to. I found this useful for simulating optional-dev-dependencies.\n\n```shell\noptional-dev-dependency lodash redis@2.2.3 fffffffgggggg\n```\n\nAll different [npm install styles](https://docs.npmjs.com/cli/install) are supported besides the git remote url\n\n## Command Line\n\n```\noptional-dev-dependency package [options]\n\nOptions:\n  -s, --silent   should the `npm install` output be shown?\n                                                      [boolean] [default: false]\n  -S, --save     try to install the specified packages, and save them to\n                 optionalDevDependencies in package.json\n                                                      [boolean] [default: false]\n  -t, --tag      only try to load dependencies with this tag\n  -V, --verbose  output NPM commands before running them\n                                                      [boolean] [default: false]\n  -h, --help     Show help                                             [boolean]\n  -v, --version  Show version number                                   [boolean]\n\nExamples:\n  ../bin/odd.js lodash hiredis  try to install 'lodash' and 'hiredis', it's okay\n                                if an install fails.\n  ../bin/odd.js -t travis       try to install optionalDevDependencies for the\n                                'travis' tag from package.json, it's okay if an\n                                install fails.\n```\n\n## Examples\n\nHere's an example from `node_redis`:\n\n```json\n{\n  \"name\": \"redis\",\n  \"scripts\": {\n    \"pretest\": \"optional-dev-dependency hiredis\"\n  }\n}\n```\n\nYou can also save optionalDevDependencies in your `package.json` file for ease\nof installation later.  For example, let's say you want most developers who\ndownload your package and play with it to run basic tests, but when you run your\ncode on your continuous integration server, you need a few extra dependencies.\nYou can use a `package.json` file like this:\n\n```json\n{\n  \"name\": \"sample\",\n  \"scripts\": {\n    \"test\": \"mocha\",\n    \"precoverage\": \"optional-dev-dependency\",\n    \"coverage\": \"nyc npm test\",\n    \"preci\": \"optional-dev-dependency -t ci\",\n    \"ci\": \"nyc report --reporter=text-lcov | coveralls\"\n  },\n  \"optionalDevDependencies\": {\n    \"nyc\": \"^8.3.1\",\n    \"coveralls\": [\n      \"^2.11.14\",\n      \"ci\"\n    ]\n  }\n}\n```\n\nWhen you do `npm run coverage`, the `precoverage` script will ensure that all\noptionalDevDependencies without a tag are installed (in this case, `nyc`).\n\nWhen you do `npm run ci` on your CI server, the `preci` script will ensure that\nall optionalDevDependencies with the `ci` tag are installed (in this case,\n`coveralls`).\n\nYou can load optionalDevDependencies into your `package.json` with the\n--save/-S flag.  This will install the latest lodash, save that version\nin your `package.json`, and will only install it later if the `foo` or `bar`\ntag is specified:\n\n```shell\noptional-dev-dependency --save lodash -t foo -t bar\n```\n\n## License\n\nISC\n\n[travis-url]: https://travis-ci.org/bcoe/optional-dev-dependency\n[travis-image]: https://img.shields.io/travis/bcoe/optional-dev-dependency.svg\n[coveralls-url]: https://coveralls.io/github/bcoe/optional-dev-dependency\n[coveralls-image]: https://img.shields.io/coveralls/bcoe/optional-dev-dependency.svg\n[npm-url]: https://npmjs.org/package/optional-dev-dependency\n[npm-image]: https://img.shields.io/npm/v/optional-dev-dependency.svg\n[standard-image]: https://img.shields.io/badge/code%20style-standard-brightgreen.svg\n[standard-url]: https://github.com/feross/standard\n", "release_dates": []}, {"name": "page-links-to", "description": "#WordPressPlugin: Lets you make a WordPress page (or other content type) link to an external URL of your choosing, instead of its WordPress URL.", "language": "PHP", "license": null, "readme": "# Page Links To #\n\n[![Build Status](https://travis-ci.org/markjaquith/page-links-to.svg?branch=master)](https://travis-ci.org/markjaquith/page-links-to)  \n\nContributors: markjaquith  \nDonate link: https://txfx.net/wordpress-plugins/donate  \nTags: page, redirect, link, external link, repoint  \nRequires at least: 4.8  \nTested up to: 5.4  \nStable tag: 3.3.3  \n\nLets you make a WordPress page (or port or other content type) link to a URL of your choosing (on your site, or on another site), instead of its normal WordPress URL.\n\n## Description ##\n\nThis plugin allows you to make a WordPress page (or post or custom post type) link to a URL of your choosing, instead of its WordPress URL. It also will redirect people who go to the old (or \"normal\") URL to the new one you've chosen.\n\n**Common uses:**\n\n* Set up navigational links to non-WordPress sections of your site or to off-site resources.\n* Publish content on other blogs (or other services, like Medium) but have them show up in your WordPress posts stream. All you have to supply is a title and a URL. The post title will link to the content on the other site.\n* For store operators, you can link to products on other retailer's sites (maybe with an affiliate code) but have them show up like they're products in your store.\n* Create a \"pretty URL\" for something complicated. Say you have https://example.com/crazy-store-url.cgi?search=productId&sourceJunk=cruft ... just create a WordPress page called \"My Store\" and use Page Links To to point it to the ugly URL. Give people the new URL: https://example.com/my-store/ and it will redirect them!\n\n## Installation ##\n\n1. Upload the `page-links-to` folder to your `/wp-content/plugins/` directory.\n\n2. Activate the \"Page Links To\" plugin.\n\n**Existing Content Usage:**\n\n1. Edit a page (or post or custom post type).\n\n2. Below, find the Page Links To widget, select \"A custom URL\", and add a URL of your choosing.\n\n3. Optionally check the box to enable link opening in a new browser tab.\n\n4. Save the page (or post or custom post type).\n\n5. Done! Now that content will point to the URL that you chose. Also, if anyone had the old WordPress URL for that content, they will be redirected to the custom URL if they visit.\n\n**Creating New Page Links:**\n\n1. Click Pages > Add New Page Link.\n\n2. Provide a title and a destination URL.\n\n3. Optionally provide a custom slug, which will be used in creating a local redirect URL.\n\n4. Click Publish.\n\n## Screenshots ##\n\n1. The Page Links To meta box in action\n2. The quick Add Page Link dialog.\n\n## Frequently Asked Questions ##\n\n### How do I make it so that a page doesn't link to anything? I'd like to use it as a dummy container. ###\n\nJust use \"#\" as the link. That won't go anywhere.\n\n### Can this be used to repoint categories to an arbitrary URL? ###\n\nNot currently. Please contact me if you're interested in that functionality.\n\n### My links are sending me to http://myblog.com/site-i-wanted-to-link-to.com ... why? ###\n\nIf you want to link to a full URL, you *must* include the `http://` portion.\n\n### Can I link to relative URLs for URLs on the same domain? ###\n\nYes. Linking to `/my-photos.php` is a good idea, as it'll still work if you move your site to a different domain.\n\n## Contribute ##\n\nYou can contribute (or report bugs) on [Github](https://github.com/markjaquith/page-links-to/).\n\n## Changelog ##\n\n### 3.3.3 ###\n* Add a SlotFill in the Block Editor, for extension.\n* Fix New Tab support in Internet Explorer.\n\n### 3.3.2 ###\n* Fix a small new tab JS error.\n\n### 3.3.1 ###\n* Fix WordPress 5.2 Block Editor (plugin will NOT be in its own panel if you're using WordPress 5.2).\n\n### 3.3.0 ###\n* Move Block Editor UI into its own panel.\n* Compatibility with Elementor.\n* Allow posts to load in the customizer (used by some front-end editing plugins).\n* Allow the \"open in new tab\" functionality to be completely disabled with a filter.\n* Make \"open in new tab\" more reliable.\n\n### 3.2.2 ###\n* Bug fixes\n* Better compat with custom post types in the Block Editor\n\n### 3.2.1 ###\n* Bug fixes\n\n### 3.2.0 ###\n* Block Editor improvements\n* Smaller build\n\n### 3.1.2 ###\n* Customizer bug fix\n\n### 3.1.1 ###\n* Block Editor bugfixes\n\n### 3.1.0 ###\n* Support for the Block Editor (Gutenberg)\n\n### 3.0.1 ###\n* Fixed a PHP warning caused by some themes\n\n### 3.0.0 ###\n* Quick page link adding UI\n* External link indicator\n* Short URL copying\n* Short URL display on edit screen\n\n### 2.11.2 ###\n* Newsletter\n\n### 2.11.1 ###\n* Restore PHP 5.3 compatibility, broken in 2.11.0\n\n### 2.11.0 ###\n* Code cleanup\n\n### 2.10.4 ###\n* New screenshot and assets\n\n### 2.10.3 ###\n* Fix readme.txt\n\n### 2.10.2 ###\n* Fix bug in Internet Explorer\n\n### 2.10.1 ###\n* Version bump\n\n### 2.10.0 ###\n* Switch to ES6 and Babel from CoffeeScript\n* Remove jQuery as front-end requirement\n* Bump supported version\n\n### 2.9.10 ###\n* Bump supported version\n\n### 2.9.9 ###\n* Back out jQuery protection code that causes issues on some sites\n\n### 2.9.8 ###\n* Added a Russian translation\n* Maintain a reference to WordPress' jQuery version\n* Modernize build tools\n\n### 2.9.6 ###\n* Fixed an issue with redirects that have `@` in the URL\n* Fixed issues with setting and displaying custom URLs for attachments\n\n### 2.9.5 ###\n* Made relative URLs absolute in redirects\n* Fixed a potential PHP warning\n* Registered the metadata fields for better XML-RPC integration\n\n### 2.9.4 ###\n* Add Hungarian translation.\n\n### 2.9.3 ###\n* Only rely on an internal cache for `wp_list_pages()` processing, and time-limit the cache.\n* Work around some weird edge cases\n\n### 2.9.2 ###\n* Restore WordPress 3.4.x functionality.\n\n### 2.9.1 ###\n* Fix a redirection bug in 2.9\n\n### 2.9 ###\n* Respect \"open in new tab\" setting in more custom situations, like custom loops and widgets.\n* Add unit tests\n* Massive code refactoring\n* Added translations for: Spanish, Catalan, French.\n\n### 2.8 ###\n* Added translations for: Swedish, Hebrew.\n\n### 2.7.1 ###\n* Fix an array bug\n\n### 2.7 ###\n* Fix a PHP notice\n* Use JS to open links in an external window, even outside of nav menus\n* Completely revamped UI\n* Several translations\n\n### 2.6 ###\n* Proper linking for custom post types (insead of just a 301).\n* Fixed a bug that prevented links from opening in a new window.\n* Notifies people when they are editing content that uses this plugin.\n* Removed the option to set redirection type. Always 301, now.\n* Removed some PHP4 and WP 2.8 back compat stuff.\n\n### 2.5 ###\n* Allow all show_ui post types to use the meta box.\n* Introduce a filter so a plugin can remove a post type from the list.\n* Target filtering for WordPress nav menus.\n* Silence some PHP notices. Props Ross McKay, Bill Erickson.\n\n### 2.4.1 ###\n* Fixed typo that was preventing 302 redirects from working. props Ryan Murphy.\n* Fixed a random PHP notice\n\n### 2.4 ###\n* Rewrote using Singleton best practices\n* Fixed a regex bug that could break current menu highlighting. props skarab\n\n### 2.3 ###\n* Fixed a bug with current menu item highlighting\n\n### 2.2 ###\n* Cleanup\n* compatibility tweaks to interoperate with a few other plugins\n* prompt http:// and auto-add it if a URL starts with \"www.\"\n\n### 2.1 ###\n* WordPress MU compatibility for when `switch_to_blog()` is used... it now uses `$blog_id` to keep their caches from stomping on each other\n\n### 2.0 ###\n* Allow one-character URLs so that things like \"#\" (dummy link) are possible\n\n### 1.9 ###\n* Fixed \"open in new window\" functionality\n", "release_dates": []}, {"name": "pagegraph-crawl", "description": "Gather pagegraph data from all over the internet", "language": "TypeScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "pagegraph-crawl\n===\n\nCommand line tool for crawling web pages with PageGraph.\n\nInstall\n---\nFor building/installing the tool, you need to have `tsc` (TypeScript Compiler) package installed.\n\n```bash\nnpm install\nnpm run build\n```\n\nTest\n---\n```bash\nnpm run test\n```\nThe tests are defined in `test/test.js`. Test parameters are defined in `test/config.js` and can be overriden via environment variables. You need to specify a PageGraph binary path.\n\nUsage\n---\nSince [PageGraph](https://github.com/brave/brave-browser/wiki/PageGraph) is built as part of Brave Nightly, you can simply point the binary path to be your local installation.\n\n```bash\nnpm run crawl -- -b /Applications/Brave\\ Browser\\ Nightly.app/Contents/MacOS/Brave\\ Browser\\ Nightly -u https://brave.com -t 5 -o output/ --debug debug\n```\n\nThe `-t` specifies how many seconds to crawl the URL provided in `-u` using the PageGraph binary in `-b`. \n\nYou can see all supported options:\n```bash\nnpm run crawl -- -h\n```\n", "release_dates": []}, {"name": "pagegraph-rust", "description": "Utilities for analyzing PageGraph outputs", "language": "Rust", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# pagegraph\n\nThis crate provides utilities for analyzing PageGraph outputs.\n\n## Workspace organization\n\n`pagegraph` provides a core library for interacting directly with pagegraph files and building custom extraction tools.\n\n`pagegraph-cli` provides a more convenient, no-code wrapper around common operations, supplying outputs in easily-parseable formats.\n\n## Example\n\nThe following example reads from a PageGraph file and produces all deleted\n`div` elements from the corresponding webpage.\n\n```rust\nuse pagegraph::from_xml::read_from_file;\nuse pagegraph::types::{ NodeType, EdgeType };\n\nfn main() {\n    let graph = read_from_file(\"/path/to/any/pagegraph.graphml\");\n\n    let deleted_divs = graph.filter_nodes(|node| {\n        match node {\n            NodeType::HtmlElement { is_deleted: true, tag_name, .. } if tag_name == \"div\" => true,\n            _ => false,\n        }\n    });\n}\n```\n", "release_dates": []}, {"name": "PanModal", "description": "An elegant and highly customizable presentation API for constructing bottom sheet modals on iOS.", "language": "Swift", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "\n### PanModal is an elegant and highly customizable presentation API for constructing bottom sheet modals on iOS.\n\n<p align=\"center\">\n    <img src=\"https://github.com/slackhq/PanModal/raw/master/Screenshots/panModal.gif\" width=\"30%\" height=\"30%\" alt=\"Screenshot Preview\" />\n</p>\n\n<p align=\"center\">\n    <img src=\"https://img.shields.io/badge/Platform-iOS_10+-green.svg\" alt=\"Platform: iOS 10.0+\" />\n    <a href=\"https://developer.apple.com/swift\" target=\"_blank\"><img src=\"https://img.shields.io/badge/Language-Swift_5-blueviolet.svg\" alt=\"Language: Swift 5\" /></a>\n    <a href=\"https://cocoapods.org/pods/PanModal\" target=\"_blank\"><img src=\"https://img.shields.io/badge/CocoaPods-v1.0-red.svg\" alt=\"CocoaPods compatible\" /></a>\n    <a href=\"https://github.com/Carthage/Carthage\" target=\"_blank\"><img src=\"https://img.shields.io/badge/Carthage-compatible-blue.svg\" alt=\"Carthage compatible\" /></a>\n    <img src=\"https://img.shields.io/badge/License-MIT-green.svg\" alt=\"License: MIT\" />\n</p>\n\n<p align=\"center\">\n    <a href=\"#features\">Features</a>\n  \u2022 <a href=\"#compatibility\">Compatibility</a>\n  \u2022 <a href=\"#installation\">Installation</a>\n  \u2022 <a href=\"#usage\">Usage</a>\n  \u2022 <a href=\"#documentation\">Documentation</a>\n  \u2022 <a href=\"#contributing\">Contributing</a>\n  \u2022 <a href=\"#authors\">Authors</a>\n  \u2022 <a href=\"#license\">License</a>\n</p>\n\n<p align=\"center\">\nRead our <a href=\"https://slack.engineering/panmodal-better-support-for-thumb-accessibility-on-slack-mobile-52b2a7596031\" target=\"_blank\">blog</a> on how Slack is getting more :thumbsup: with PanModal\n\nSwift 4.2 support can be found on the `Swift4.2` branch.\n</p>\n\n## Features\n\n* Supports any type of `UIViewController`\n* Seamless transition between modal and content\n* Maintains 60 fps performance\n\n## Compatibility\n\nPanModal requires **iOS 10+** and is compatible with **Swift 4.2** projects.\n\n## Installation\n\n* <a href=\"https://guides.cocoapods.org/using/using-cocoapods.html\" target=\"_blank\">CocoaPods</a>:\n\n```ruby\npod 'PanModal'\n```\n\n* <a href=\"https://github.com/Carthage/Carthage\" target=\"_blank\">Carthage</a>:\n\n```ruby\ngithub \"slackhq/PanModal\"\n```\n\n* <a href=\"https://swift.org/package-manager/\" target=\"_blank\">Swift Package Manager</a>:\n\n```swift\ndependencies: [\n  .package(url: \"https://github.com/slackhq/PanModal.git\", .exact(\"1.2.6\")),\n],\n```\n\n## Usage\n\nPanModal was designed to be used effortlessly. Simply call `presentPanModal` in the same way you would expect to present a `UIViewController`\n\n```swift\n.presentPanModal(yourViewController)\n```\n\nThe presented view controller must conform to `PanModalPresentable` to take advantage of the customizable options\n\n```swift\nextension YourViewController: PanModalPresentable {\n\n    var panScrollable: UIScrollView? {\n        return nil\n    }\n}\n```\n\n### PanScrollable\n\nIf the presented view controller has an embedded `UIScrollView` e.g. as is the case with `UITableViewController`, panModal will seamlessly transition pan gestures between the modal and the scroll view\n\n```swift\nclass TableViewController: UITableViewController, PanModalPresentable {\n\n    var panScrollable: UIScrollView? {\n        return tableView\n    }\n}\n```\n\n### Adjusting Heights\n\nHeight values of the panModal can be adjusted by overriding `shortFormHeight` or `longFormHeight`\n\n```swift\nvar shortFormHeight: PanModalHeight {\n    return .contentHeight(300)\n}\n\nvar longFormHeight: PanModalHeight {\n    return .maxHeightWithTopInset(40)\n}\n```\n\n### Updates at Runtime\n\nValues are stored during presentation, so when adjusting at runtime you should call `panModalSetNeedsLayoutUpdate()`\n\n```swift\nfunc viewDidLoad() {\n    hasLoaded = true\n\n    panModalSetNeedsLayoutUpdate()\n    panModalTransition(to: .shortForm)\n}\n\nvar shortFormHeight: PanModalHeight {\n    if hasLoaded {\n        return .contentHeight(200)\n    }\n    return .maxHeight\n}\n```\n\n### Sample App\n\nCheck out the [Sample App](https://github.com/slackhq/PanModal/tree/master/Sample) for more complex configurations of `PanModalPresentable`, including navigation controllers and stacked modals.\n\n## Documentation\nOption + click on any of PanModal's methods or notes for detailed documentation.\n\n<p align=\"left\">\n    <img src=\"https://github.com/slackhq/PanModal/blob/master/Screenshots/documentation.png\" width=\"50%\" height=\"50%\" alt=\"Screenshot Preview\" />\n</p>\n\n## Contributing\n\nWe're glad to be open sourcing this library. We use it in numerous places within the slack app and expect it to be easy to use as well as modify; we've added extensive documentation within the code to support that.\n\nWe will only be fixing critical bugs, thus, for any non-critical issues or feature requests we hope to be able to rely on the community using the library to add what they need. For more information, please read the [contributing guidelines](https://github.com/slackhq/PanModal/blob/master/CONTRIBUTING.md).\n\n## Authors\n\n[Stephen Sowole](https://github.com/ste57) \u2022 [Tosin Afolabi](https://github.com/tosinaf)\n\n## License\n\n<b>PanModal</b> is released under a MIT License. See LICENSE file for details.\n", "release_dates": []}, {"name": "pdf.js", "description": "PDF Reader in JavaScript", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# PDF.js\n\nPDF.js is a Portable Document Format (PDF) viewer that is built with HTML5.\n\nPDF.js is community-driven and supported by Mozilla Labs. Our goal is to\ncreate a general-purpose, web standards-based platform for parsing and\nrendering PDFs.\n\n## Contributing\n\nPDF.js is an open source project and always looking for more contributors. To\nget involved, visit:\n\n+ [Issue Reporting Guide](https://github.com/mozilla/pdf.js/blob/master/.github/CONTRIBUTING.md)\n+ [Code Contribution Guide](https://github.com/mozilla/pdf.js/wiki/Contributing)\n+ [Frequently Asked Questions](https://github.com/mozilla/pdf.js/wiki/Frequently-Asked-Questions)\n+ [Good Beginner Bugs](https://github.com/mozilla/pdf.js/issues?direction=desc&labels=5-good-beginner-bug&page=1&sort=created&state=open)\n+ [Projects](https://github.com/mozilla/pdf.js/projects)\n\nFeel free to stop by #pdfjs on irc.mozilla.org for questions or guidance.\n\n## Getting Started\n\n### Online demo\n\n+ https://mozilla.github.io/pdf.js/web/viewer.html\n\n### Browser Extensions\n\n#### Firefox (and Seamonkey)\n\nPDF.js is built into version 19+ of Firefox, however, one extension is still available:\n\n+ [Development Version](http://mozilla.github.io/pdf.js/extensions/firefox/pdf.js.xpi) - This extension is mainly intended for developers/testers, and it is updated every time new code is merged into the PDF.js codebase. It should be quite stable but might break from time to time.\n\n  + Please note that the extension is *not* guaranteed to be compatible with Firefox versions that are *older* than the current ESR version, see the [Release Calendar](https://wiki.mozilla.org/RapidRelease/Calendar#Past_branch_dates).\n\n  + The extension should also work in Seamonkey, provided that it is based on a Firefox version as above (see [Which version of Firefox does SeaMonkey 2.x correspond with?](https://wiki.mozilla.org/SeaMonkey/FAQ#General)), but we do *not* guarantee compatibility.\n\n#### Chrome\n\n+ The official extension for Chrome can be installed from the [Chrome Web Store](https://chrome.google.com/webstore/detail/pdf-viewer/oemmndcbldboiebfnladdacbdfmadadm).\n*This extension is maintained by [@Rob--W](https://github.com/Rob--W).*\n+ Build Your Own - Get the code as explained below and issue `gulp chromium`. Then open\nChrome, go to `Tools > Extension` and load the (unpackaged) extension from the\ndirectory `build/chromium`.\n\n## Getting the Code\n\nTo get a local copy of the current code, clone it using git:\n\n    $ git clone git://github.com/mozilla/pdf.js.git\n    $ cd pdf.js\n\nNext, install Node.js via the [official package](http://nodejs.org) or via\n[nvm](https://github.com/creationix/nvm). You need to install the gulp package\nglobally (see also [gulp's getting started](https://github.com/gulpjs/gulp/blob/master/docs/getting-started.md#getting-started)):\n\n    $ npm install -g gulp-cli\n\nIf everything worked out, install all dependencies for PDF.js:\n\n    $ npm install\n\nFinally, you need to start a local web server as some browsers do not allow opening\nPDF files using a `file://` URL. Run:\n\n    $ gulp server\n\nand then you can open:\n\n+ http://localhost:8888/web/viewer.html\n\nPlease keep in mind that this requires an ES6 compatible browser; refer to [Building PDF.js](https://github.com/mozilla/pdf.js/blob/master/README.md#building-pdfjs) for usage with older browsers.\n\nIt is also possible to view all test PDF files on the right side by opening:\n\n+ http://localhost:8888/test/pdfs/?frame\n\n## Building PDF.js\n\nIn order to bundle all `src/` files into two production scripts and build the generic\nviewer, run:\n\n    $ gulp generic\n\nThis will generate `pdf.js` and `pdf.worker.js` in the `build/generic/build/` directory.\nBoth scripts are needed but only `pdf.js` needs to be included since `pdf.worker.js` will\nbe loaded by `pdf.js`. The PDF.js files are large and should be minified for production.\n\n## Using PDF.js in a web application\n\nTo use PDF.js in a web application you can choose to use a pre-built version of the library\nor to build it from source. We supply pre-built versions for usage with NPM and Bower under\nthe `pdfjs-dist` name. For more information and examples please refer to the\n[wiki page](https://github.com/mozilla/pdf.js/wiki/Setup-pdf.js-in-a-website) on this subject.\n\n## Learning\n\nYou can play with the PDF.js API directly from your browser using the live demos below:\n\n+ [Interactive examples](http://mozilla.github.io/pdf.js/examples/index.html#interactive-examples)\n\nThe repository contains a hello world example that you can run locally:\n\n+ [examples/helloworld/](https://github.com/mozilla/pdf.js/blob/master/examples/helloworld/)\n\nMore examples can be found in the examples folder. Some of them are using the pdfjs-dist package, which can be built and installed in this repo directory via `gulp dist-install` command.\n\nFor an introduction to the PDF.js code, check out the presentation by our\ncontributor Julian Viereck:\n\n+ http://www.youtube.com/watch?v=Iv15UY-4Fg8\n\nMore learning resources can be found at:\n\n+ https://github.com/mozilla/pdf.js/wiki/Additional-Learning-Resources\n\n## Questions\n\nCheck out our FAQs and get answers to common questions:\n\n+ https://github.com/mozilla/pdf.js/wiki/Frequently-Asked-Questions\n\nTalk to us on IRC:\n\n+ #pdfjs on irc.mozilla.org\n\nFile an issue:\n\n+ https://github.com/mozilla/pdf.js/issues/new\n\nFollow us on twitter: @pdfjs\n\n+ http://twitter.com/#!/pdfjs\n", "release_dates": []}, {"name": "perfaderp", "description": "App to process webkit CPU profiles", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# perfaderp\n\nThis app processes CPU Profiles generated with the webkit CPU profiler. You can generate them in Chromium based browsers with Dev Tools -> Kabob Menu -> More Tools -> JavaScript profiler.\n\n## Sources\n\n### Listen for new S3 objects via SQS\n\nA bucket is setup so new objects send notifications to an SQS queue. This app listens on the SQS queue.\n\n### Manually download S3 bucket\n\n`S3_BUCKET={bucket} node tools/importS3.js` manually imports all CPU profiles from the bucket, up to 1000 (fixme).\n\n\n# Deployment\n\n- First setup an S3 bucket with the CPU profiles and have it notify to SQS.\n- Syntax: `https://bucket.s3.amazonaws.com/brave/browser-laptop/15234--a1b2c3d4e5d6/{category}--{test case}--{user profile}-2017-09-28T23%3A39%3A49.451Z.cpuprofile`\n- Runs in Docker on Linux or MacOS.\n- Clone the repo then create an `env.node` Docker env file. Minimally it should have `NODE_ENV` and `SQS_ENDPOINT_CPU_PROFILES`; it also needs `AWS_ACCESS_KEY_ID` and `AWS_ACCESS_KEY_ID` if not using an IAM instance role.\n- `docker-compose up -d` to start.\n- Go to http://{hostname}:3000 to view grafana, the influxdb interface. Default password is admin/admin. Data source is influxdb at `http://{hostname}:8086`, connect directly (no proxy). Then create a dashboards.\n", "release_dates": []}, {"name": "php-coding-standards", "description": "PHP Coding Standards for Brave.com", "language": null, "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "PHP_CodeSniffer ruleset for Brave.com\n=====================================\n\n# Installation\n\n1. Install [PHP_CodeSniffer](https://github.com/squizlabs/PHP_CodeSniffer).\n2. Clone the dependent coding standards:\n\n       git clone https://github.com/sirbrillig/phpcs-variable-analysis\n       git clone https://github.com/Automattic/VIP-Coding-Standards\n       git clone https://github.com/WordPress/WordPress-Coding-Standards\n2. Look for the latest release of the [WordPress](https://github.com/WordPress/WordPress-Coding-Standards/releases) and [VIP](https://github.com/Automattic/VIP-Coding-Standards/releases) coding standards and use it instead of the default branch:\n       cd WordPress-Coding-Standards ; git checkout 2.3.0\n       cd VIP-Coding-Standards ; git checkout 2.2.0\n\n3. Install the dependent coding standards, for example, by creating the\n   appropriate symlinks in `/usr/share/php/PHP/CodeSniffer/src/Standards/`:\n\n       cd /usr/share/php/PHP/CodeSniffer/src/Standards/\n       sudo ln -s /home/username/phpcs-variable-analysis/VariableAnalysis/ .\n       sudo ln -s /home/username/VIP-Coding-Standards/WordPress-VIP-Go/ .\n       sudo ln -s /home/username/devel/VIP-Coding-Standards/WordPressVIPMinimum/ .\n       sudo ln -s /home/username/devel/WordPress-Coding-Standards/WordPress .\n       sudo ln -s /home/username/devel/WordPress-Coding-Standards/WordPress-Core/ .\n       sudo ln -s /home/username/devel/WordPress-Coding-Standards/WordPress-Extra .\n       sudo ln -s /home/username/devel/WordPress-Coding-Standards/WordPress-Docs .\n4. Install the `brave.com` coding standards:\n\n       cd /usr/share/php/PHP/CodeSniffer/src/Standards/\n       sudo ln -s /home/username/php-coding-standards/BraveMinimum/ .\n\n# Usage\n\nCreate a `phpcs.xml` file in the root of your PHP plugin, similar to this\none:\n\n```\n<?xml version=\"1.0\"?>\n<ruleset name=\"PluginName\">\n\t<description>Coding standard for the Plugin-Name plugin</description>\n\n\t<rule ref=\"BraveMinimum\">\n\t</rule>\n</ruleset>\n```\n\nand then run `phpcs .`.\n", "release_dates": []}, {"name": "playlist-component", "description": null, "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# playlist-component", "release_dates": []}, {"name": "pre-commit", "description": "Automatically installs a git pre-commit script in your git repository which runs your `npm test` on pre-commit", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# pre-commit\n\n[![Version npm][version]](http://browsenpm.org/package/pre-commit)[![Build Status][build]](https://travis-ci.org/observing/pre-commit)[![Dependencies][david]](https://david-dm.org/observing/pre-commit)[![Coverage Status][cover]](https://coveralls.io/r/observing/pre-commit?branch=master)\n\n[version]: http://img.shields.io/npm/v/pre-commit.svg?style=flat-square\n[build]: http://img.shields.io/travis/observing/pre-commit/master.svg?style=flat-square\n[david]: https://img.shields.io/david/observing/pre-commit.svg?style=flat-square\n[cover]: http://img.shields.io/coveralls/observing/pre-commit/master.svg?style=flat-square\n\n**pre-commit** is a pre-commit hook installer for `git`. It will ensure that\nyour `npm test` (or other specified scripts) passes before you can commit your\nchanges. This all conveniently configured in your `package.json`.\n\nBut don't worry, you can still force a commit by telling `git` to skip the\n`pre-commit` hooks by simply committing using `--no-verify`.\n\n### Installation\n\nIt's advised to install the **pre-commit** module as a `devDependencies` in your\n`package.json` as you only need this for development purposes. To install the\nmodule simply run:\n\n```\nnpm install --save-dev pre-commit\n```\n\nTo install it as `devDependency`. When this module is installed it will override\nthe existing `pre-commit` file in your `.git/hooks` folder. Existing\n`pre-commit` hooks will be backed up as `pre-commit.old` in the same repository.\n\n### Configuration\n\n`pre-commit` will try to run your `npm test` command in the root of the git\nrepository by default unless it's the default value that is set by the `npm\ninit` script. \n\nBut `pre-commit` is not limited to just running your `npm test`'s during the\ncommit hook. It's also capable of running every other script that you've\nspecified in your `package.json` \"scripts\" field. So before people commit you\ncould ensure that:\n\n- You have 100% coverage\n- All styling passes.\n- JSHint passes.\n- Contribution licenses signed etc.\n\nThe only thing you need to do is add a `pre-commit` array to your `package.json`\nthat specifies which scripts you want to have ran and in which order:\n\n```js\n{\n  \"name\": \"437464d0899504fb6b7b\",\n  \"version\": \"0.0.0\",\n  \"description\": \"ERROR: No README.md file found!\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: I SHOULD FAIL LOLOLOLOLOL \\\" && exit 1\",\n    \"foo\": \"echo \\\"fooo\\\" && exit 0\",\n    \"bar\": \"echo \\\"bar\\\" && exit 0\"\n  },\n  \"pre-commit\": [\n    \"foo\",\n    \"bar\",\n    \"test\"\n  ]\n}\n```\n\nIn the example above, it will first run: `npm run foo` then `npm run bar` and\nfinally `npm run test` which will make the commit fail as it returns the error\ncode `1`.  If you prefer strings over arrays or `precommit` without a middle\ndash, that also works:\n\n```js\n{\n  \"precommit\": \"foo, bar, test\"\n  \"pre-commit\": \"foo, bar, test\"\n  \"pre-commit\": [\"foo\", \"bar\", \"test\"]\n  \"precommit\": [\"foo\", \"bar\", \"test\"],\n  \"precommit\": {\n    \"run\": \"foo, bar, test\",\n  },\n  \"pre-commit\": {\n    \"run\": [\"foo\", \"bar\", \"test\"],\n  },\n  \"precommit\": {\n    \"run\": [\"foo\", \"bar\", \"test\"],\n  },\n  \"pre-commit\": {\n    \"run\": \"foo, bar, test\",\n  }\n}\n```\n\nThe examples above are all the same. In addition to configuring which scripts\nshould be ran you can also configure the following options:\n\n- **silent** Don't output the prefixed `pre-commit:` messages when things fail\n  or when we have nothing to run. Should be a boolean.\n- **colors** Don't output colors when we write messages. Should be a boolean.\n- **template** Path to a file who's content should be used as template for the\n  git commit body.\n\nThese options can either be added in the `pre-commit`/`precommit` object as keys\nor as `\"pre-commit.{key}` key properties in the `package.json`:\n\n```js\n{\n  \"precommit.silent\": true,\n  \"pre-commit\": {\n    \"silent\": true\n  }\n}\n```\n\nIt's all the same. Different styles so use what matches your project. To learn\nmore about the scripts, please read the official `npm` documentation:\n\nhttps://npmjs.org/doc/scripts.html\n\nAnd to learn more about git hooks read:\n\nhttp://githooks.com\n\n### License\n\nMIT\n", "release_dates": []}, {"name": "prochlo", "description": null, "language": "C++", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": null, "release_dates": []}, {"name": "public-suffix-list", "description": "The Public Suffix List - Brave Fork", "language": null, "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "The Public Suffix List\n======================\n\nA \"public suffix\" is one under which Internet users can (or historically could)\ndirectly register names. Some examples of public suffixes are .com, .co.uk and\npvt.k12.ma.us. The Public Suffix List is a list of all known public suffixes.\n\nSee https://publicsuffix.org/ and the [Wiki](https://github.com/publicsuffix/list/wiki) link above for more information.\n\n**Are you here to add or update something?**\n\nAll submissions must conform to the [validation and acceptance factors](https://github.com/publicsuffix/list/wiki/Guidelines#validation-and-non-acceptance-factors) and provide sufficient rationale or basically be as complete as possible, and follow the [Guidelines](https://github.com/publicsuffix/list/wiki/Guidelines), especially as they relate to format and [sorting](https://github.com/publicsuffix/list/wiki/Guidelines#sort-your-submission-correctly-important).\n\nThe list is currently maintained by people who are volunteering their time towards universal acceptance and ensuring there is a bridge between the ICANN world of domain names and the crucial last mile - the world of developers and human users.  \n\nIteration back and forth will delay PR review or inclusion.  Be extremely thorough, and patient.\n\nImportant Notice:\n\n2023-09-01 : **We are not sending _PSL txt record email notices to anyone**.    \n\nWe are getting reports that some parties are receiving email notices about ensuring they have (and maintain/keep) _PSL TXT records tied to the relevant pull request URL in order to maintain their listing on the PSL.   This is not from the maintainers, we're not sending those.  That said, please do leave those in place for domains that you want to keep listed, as their inclusion served two roles.  1: a means to publicly validate a connection between the submitting party and the administration in DNS of submitted name(s). 2: future use for culling the list via automation.  We have never had the resourcing to perform the latter, but at some point will do this, and due to the nature of most submitters having a 'set and forget' attitude about their entries, we felt it best to leverage the only likely time we'd have their attention to preserve their record.\n\n2023-02-20 : Did [guidance from Google related to the changes that they are making to adsense subdomains](https://support.google.com/adsense/answer/12170421) bring you here?  Work with Google Adsense [Help Link](https://support.google.com/adsense/gethelp) with any support questions you have.  The PSL is thinly resourced, and the volunteer maintainers are unable to answer questions about Adsense changes or support Adsense.\n\nThe PSL is volunteer-resourced and is absolutely not resourced to answer questions or support changes.  Guidance is in the form of self-help (READ THE [WIKI](https://github.com/publicsuffix/list/wiki)), THERE IS NO PSL CUSTOMER SERVICE RESOURCE TO ASSIST YOU.   *Please work directly with Google to ensure your domain does in fact need an entry, and they should help you know what the benefits and consequences are.  _IT POSSIBLE TO HARM YOUR WEBSITE COOKIES BY REQUESTING A MAL-FORMED PSL ENTRY_.  Also, understand what propagation delays and rollback processing entail before making requests.*\n\n2021-04-23 : Did guidance related to an issue with Facebook or Apple bring you here?  [Read this before submitting requests](https://github.com/publicsuffix/list/issues/1245)  We are not approving workaround requests per the validation and acceptance standards, but do have open discussion with Facebook on the matter.  \n", "release_dates": []}, {"name": "pull-merge", "description": "LLM Capabilities for your pull-requests", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# ![pull-merge](/logo/svg/logo-no-background.svg)\n\npuLL-Merge is a `github-action` to add LLM capabilities to pull-requests in `github`\n\n## Usage\n\nAdd an action under `.github/workflow/security-action.yml` with the following content:\n\n```yaml\nname: puLL-Merge\non:\n  pull_request:\n    types: [opened, synchronize, reopened, ready_for_review]\n    branches: [main]\n\njobs:\n  pull-merge:\n    name: security\n    runs-on: ubuntu-latest\n    steps:\n      - uses: brave/pull-merge@main\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          openai_api_key: ${{ secrets.OPENAI_API_KEY }}\n\n```\n\n## Testing LLM integrations (local)\n\n```bash\n$ ./run.js ./src/openaiExplainPatch.js --githubKey=<GITHUB_KEY> --openaiKey=<OPENAI_KEY> --owner=brave --repo=security-action --prnum=406\n```\n", "release_dates": []}, {"name": "python-patch", "description": "Library to parse and apply unified diffs", "language": "Python", "license": null, "readme": "Library to parse and apply unified diffs.\n\n[![Build Status](https://travis-ci.com/brave/python-patch.svg?branch=master)](https://travis-ci.com/brave/python-patch)\n\n### Features\n\n * Python 2 and 3 compatible\n * Automatic correction of\n   * Linefeeds according to patched file\n   * Diffs broken by stripping trailing whitespace\n   * a/ and b/ prefixes\n * Single file, which is a command line tool and a library\n * No dependencies outside Python stdlib\n * Patch format detection (SVN, HG, GIT)\n * Nice diffstat histogram\n * Linux / Windows / OS X\n * Test coverage\n\nThings that don't work out of the box:\n\n * File renaming, creation and removal\n * Directory tree operations\n * Version control specific properties\n * Non-unified diff formats\n\n\n### Usage\n\nDownload **patch.py** and run it with Python. It is a self-contained\nmodule without external dependencies.\n\n    patch.py diff.patch\n\nYou can also run the .zip file.\n    \n    python patch-1.16.zip diff.patch\n\n### Installation\n\n**patch.py** is self sufficient. You can copy it into your repository\nand use it from here. This setup will always be repeatable. But if\nyou need to add `patch` module as a dependency, make sure to use strict\nspecifiers to avoid hitting an API break when version 2 is released:\n\n    pip install \"patch==1.*\"\n\n\n### Other stuff\n\n* [CHANGES](doc/CHANGES.md)\n* [LICENSE](doc/LICENSE)\n* [CREDITS](doc/CREDITS)\n\n* [test coverage](http://techtonik.github.io/python-patch/tests/coverage/)\n", "release_dates": []}, {"name": "qa-resources", "description": null, "language": "HTML", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "<h2>Running Changelog Generator allows you to </h2>\n<ul>\n  <li>Create test runs </li>\n  <li>Generate release notes</li>\n  <li>Generate the exclusion list</li>\n</ul>\n\n<h2>Before you begin</h2>\n<ol>\n  <li><p>Download and install Python3 : <code>https://www.python.org/downloads/ </code> </p></li>\n  <li><p>If you haven\u2019t already set up a \u2018Development\u2019 directory for github so you can clone repositories, \n    \n   - Create a Development directory \n   - Open terminal, type <code>mkdir Development</code></p></li>\n   _**This document assumes this is where you create this directory. You will need to adjust accordingly if you create this directory elsewhere.**_\n</ol>\n\n\n<h2>First time stuff - getting set up</h2>\n<ol>\n  <li><p>Open Terminal and navigate to your <code>Development</code> directory.</p></li>\n  <li><p>Type: <code>git clone git@github.com:brave/qa-resources.git</code></p></li>\n  <li><p>Press Enter/Return. You have now cloned the qa-resources repo onto your machine.</p></li>\n  <li><p>Next, you\u2019ll need to install the <code>pygithub</code> package. This gives you the shared code needed to use GitHub\u2019s public api. \n    \n   - Open a Terminal and type: <code>pip3 install PyGithub</code> Then select Enter/Return.</p>\n   - FYI - You can get information on this pygithub package here: <code>http://pygithub.readthedocs.io/en/latest/introduction.html</code> <br />and the main library of packages can be found here: <code>https://pypi.python.org/pypi</code> </p></li>\n  <li><p>In the qa-resources folder, create a file called <code>github.secret</code>. To do this in your Terminal session change directory to qa-resources if you are not already inside the directory. Then type <code>touch github.secret</code> and select Enter/Return.</p></li>\n  <li><p>Next, you have to create a github key. \n  \n   - Login to your github account and navigate to <code>https://github.com/settings/profile</code></p>\n   - Open new tab and navigate to <code>https://github.com/settings/tokens </code></p>\n   - Click on **Generate new token** button. Give the token a meaningful name and select the checkboxes below for your token.</p>\n   - Select \u2018Generate token\u2019 button. Your token is now generated, it looks similar to an SHA. Copy the token. Do not exit this page yet.</p>\n<li><p>Add this token to your github.secret file. \n  \n   - To do this, in your Terminal session change directory to qa-resources if you are not already inside the directory. </p>\n   - Then type <code>vi github.secret</code> and select Enter/Return.</p>\n   - Since you\u2019ve already copied your token, type <code>i</code>  and paste your token. Then hit the Esc key.</p>\n   - Now type <code>:wq</code> to save and exit the file.\n   - If you want to verify that the token was saved correctly, you can type <code>cat github.secret</code> and your token will display.</p></li>\n  </ol>\n\n<h2>Running the Changelog Generator</h2>\n<ol>\n  <li><p>Open a Terminal session.</p></li>\n  <li><p>Change directory to where you have qa-resources.</p></li>\n  <li><p>Determine what product you want to run the changelog-generator for (browser-laptop, Android, iOS) and if you want to create issues in github or just see the output in the terminal.\n    \n   - For simulating creation of test runs\n\n     - In the terminal type <code>python3 brave_testrun_generator.py --test true</code> and select Enter/Return.\n     - Follow options on screen to simulate generating test runs. It will just displays the output in the terminal and does NOT create GitHub issues. \n\n  - For Tor/IPFS:\n\n     - Ensure milestones are created before running the test run generator.\n     - Selecting the number option won't generate test runs for Tor/IPFS, need to type in `Tor/IPFS` respectively. \n     \n</p></li>\n</ol>\n\n<h2> Format of terminal output</h2>\n<p>General format of the output in the terminal is as follows. Enter the number for which you want to generate test runs </p>\n\n```\n\nRate Limit: 5000\nRate Remaining: some number\n\n##########################################################################################################################\n\nFor Desktop or Android minor CR bump only use the basic checks selection to generate testruns\n\nCurrent open milestones for Desktop/Android\n1. X.XX.x - Release\n2. X.XX.x - Beta\n3. X.XX.x - Nightly\n\nCurrent open milestones for iOS\n1. X.XX\n2. X.XX\n3. X.XX\n4. icebox\n\nNOTE:\n\nFor Tor Release make sure you type \"Tor\" or \"tor\" instead of the number\n\nFor IPFS Release make sure you type \"IPFS/KUBO \" or \"ipfs/kubo\" instead of the number\n##########################################################################################################################\n\nCreate test runs for:\n\n1. Desktop Release (Full manual pass)\n2. Desktop Release (Basic checks for hotfix/minor Chromium bump)\n3. Android Release (Full manual pass)\n4. Android Release (Basic checks for hotfix/minor Chromium bump)\n5. iOS Release\n6. Crypto Wallet - Desktop\n7. Crypto Wallet - Android\n8. Crypto Wallet - iOS\n9. Tor Release\n10. IPFS Release\n\nChoose the platform for which you want to generate the test run:\n```\n\n<h2> Misc Notes</h2>\n\n  - To get updates to the changelog-generator you can open a terminal and navigate to the <Code>/Development/qa-resources</code> folder and type: <code>git pull</code>\n  - Be sure you never add your <code>github.secret</code> file to any git commits you do.\n  - If you uninstall Python3 for any reason, any packages you install (like PyGithub) will also be uninstalled, so you will need to install them again.\n\n", "release_dates": []}, {"name": "qr-image", "description": "Yet another QR code generator", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "qr-image\n========\n\n[![npm version](https://badge.fury.io/js/qr-image.svg)](https://badge.fury.io/js/qr-image)\n\nThis is yet another QR Code generator.\n\nOverview\n--------\n\n  * No dependecies;\n  * generate image in `png`, `svg`, `eps` and `pdf` formats;\n  * numeric and alphanumeric modes;\n  * support UTF-8.\n\n[Releases](https://github.com/alexeyten/qr-image/releases/)\n\n\nInstalling\n-----\n\n```shell\nnpm install qr-image\n```\n\nUsage\n-----\n\nExample:\n```javascript\nvar qr = require('qr-image');\n\nvar qr_svg = qr.image('I love QR!', { type: 'svg' });\nqr_svg.pipe(require('fs').createWriteStream('i_love_qr.svg'));\n\nvar svg_string = qr.imageSync('I love QR!', { type: 'svg' });\n```\n\n[More examples](./examples)\n\n`qr = require('qr-image')`\n\n### Methods\n\n  * `qr.image(text, [ec_level | options])` \u2014 Readable stream with image data;\n  * `qr.imageSync(text, [ec_level | options])` \u2014 string with image data. (Buffer for `png`);\n  * `qr.svgObject(text, [ec_level | options])` \u2014 object with SVG path and size;\n  * `qr.matrix(text, [ec_level])` \u2014 2D array.\n\n\n### Options\n\n  * `text` \u2014 text to encode;\n  * `ec_level` \u2014 error correction level. One of `L`, `M`, `Q`, `H`. Default `M`.\n  * `options` \u2014 image options object:\n    * `ec_level` \u2014 default `M`.\n    * `type` \u2014 image type. Possible values `png` (default), `svg`, `pdf` and `eps`.\n    * `size` (png and svg only) \u2014 size of one module in pixels. Default `5` for png and `undefined` for svg.\n    * `margin` \u2014 white space around QR image in modules. Default `4` for `png` and `1` for others.\n    * `customize` (only png) \u2014 function to customize qr bitmap before encoding to PNG.\n    * `parse_url` (experimental, default `false`) \u2014 try to optimize QR-code for URLs.\n\nChanges\n-------\n\n  * Implement `imageSync` for `png`.\n\n\nTODO\n----\n\n  * Tests;\n  * mixing modes;\n  * Kanji (???).\n", "release_dates": []}, {"name": "rappor", "description": "RAPPOR: Privacy-Preserving Reporting Algorithms", "language": "R", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "RAPPOR\n======\n\nRAPPOR is a novel privacy technology that allows inferring statistics about\npopulations while preserving the privacy of individual users.\n\nThis repository contains simulation and analysis code in Python and R.\n\nFor a detailed description of the algorithms, see the\n[paper](http://arxiv.org/abs/1407.6981) and links below.\n\nFeel free to send feedback to\n[rappor-discuss@googlegroups.com][group].\n\nRunning the Demo\n----------------\n\nAlthough the Python and R libraries should be portable to any platform, our\nend-to-end demo has only been tested on Linux.\n\nIf you don't have a Linux box handy, you can [view the generated\noutput](http://google.github.io/rappor/examples/report.html).\n\nTo setup your enviroment there are some packages and R dependencies. There is a setup script to install them:\n    $ ./setup.sh\nThen to build the native components run:\n    $ ./build.sh \nThis compiles and tests the `fastrand` C extension module for Python, which\nspeeds up the simulation.\n\nFinally to run the demo run:\n    $ ./demo.sh\n\nThe demo strings together the Python and R code.  It:\n\n1. Generates simulated input data with different distributions\n2. Runs it through the RAPPOR privacy-preserving reporting mechanisms\n3. Analyzes and plots the aggregated reports against the true input\n\nThe output is written to `_tmp/regtest/results.html`, and can be opened with a\nbrowser.\n\nDependencies\n------------\n\n[R](http://r-project.org) analysis (`analysis/R`):\n\n- [glmnet](http://cran.r-project.org/web/packages/glmnet/index.html)\n- [limSolve](https://cran.r-project.org/web/packages/limSolve/index.html)\n\nDemo dependencies (`demo.sh`):\n\nThese are necessary if you want to test changes to the code.\n\n- R libraries\n  - [ggplot2](http://cran.r-project.org/web/packages/ggplot2/index.html)\n  - [optparse](http://cran.r-project.org/web/packages/optparse/index.html)\n- bash shell / coreutils: to run tests\n\nPython client (`client/python`):\n\n- None.  You should be able to just import the `rappor.py` file.\n\nPlatform:\n\n- R: tested on R 3.0.\n- Python: tested on Python 2.7.\n- OS: the shell script tests have been tested on Linux, but may work on\n  Mac/Cygwin.  The R and Python code should work on any OS.\n\nDevelopment\n-----------\n\nTo run tests:\n\n    $ ./test.sh\n\nThis currently runs Python unit tests, lints Python source files, and runs R\nunit tests.\n\nAPI\n---\n\n`rappor.py` is a tiny standalone Python file, and you can easily copy it into a\nPython program.\n\nNOTE: Its interface is subject to change.  We are in the demo stage now, but if\nthere's demand, we will document and publish the interface.\n\nThe R interface is also subject to change.\n\n<!-- TODO: Add links to interface docs when available. -->\n\nThe `fastrand` C module is optional.  It's likely only useful for simulation of\nthousands of clients.  It doesn't use cryptographically strong randomness, and\nthus should **not** be used in production.\n\nDirectory Structure\n-------------------\n\n    analysis/\n      R/                 # R code for analysis\n      cpp/               # Fast reimplementations of certain analysis\n                         #   algorithms\n    apps/                # Web apps to help you use RAPPOR (using Shiny)\n    bin/                 # Command line tools for analysis.\n    client/              # Client libraries\n      python/            # Python client library\n        rappor.py\n        ...\n      cpp/               # C++ client library\n        encoder.cc\n        ...\n    doc/                 # Documentation\n    tests/               # Tools for regression tests\n      compare_dist.R     # Test helper for single variable analysis\n      gen_true_values.R  # Generate test input\n      make_summary.py    # Generate an HTML report for the regtest\n      rappor_sim.py      # RAPPOR client simulation\n      regtest_spec.py    # Specification of test cases\n      ...\n    build.sh             # Build scripts (docs, C extension, etc.)\n    demo.sh              # Quick demonstration\n    docs.sh              # Generate docs form the markdown in doc/\n    gh-pages/            # Where generated docs go. (A subtree of the branch gh-pages)\n    pipeline/            # Analysis pipeline code.\n    regtest.sh           # End-to-end regression tests, including client\n                         #  libraries and analysis\n    setup.sh             # Install dependencies (for Linux)\n    test.sh              # Test runner\n\nDocumentation\n-------------\n\n- [RAPPOR Data Flow](http://google.github.io/rappor/doc/data-flow.html)\n\nPublications\n------------\n\n- [RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response](http://arxiv.org/abs/1407.6981)\n- [Building a RAPPOR with the Unknown: Privacy-Preserving Learning of Associations and Data Dictionaries](http://arxiv.org/abs/1503.01214)\n\nLinks\n-----\n\n- [Google Blog Post about RAPPOR](http://googleresearch.blogspot.com/2014/10/learning-statistics-with-privacy-aided.html)\n- [RAPPOR implementation in Chrome](http://www.chromium.org/developers/design-documents/rappor)\n  - This is a production quality C++ implementation, but it's somewhat tied to\n    Chrome, and doesn't support all privacy parameters (e.g. only a few values\n    of p and q).  On the other hand, the code in this repo is not yet\n    production quality, but supports experimentation with different parameters\n    and data sets.  Of course, anyone is free to implement RAPPOR independently\n    as well.\n- Mailing list: [rappor-discuss@googlegroups.com][group]\n\n[group]: https://groups.google.com/forum/#!forum/rappor-discuss\n", "release_dates": []}, {"name": "ref-fvm", "description": "Reference implementation of the Filecoin Virtual Machine", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Reference Filecoin VM implementation (v3; dev)\n\n[![Continuous integration](https://github.com/filecoin-project/ref-fvm/actions/workflows/ci.yml/badge.svg)](https://github.com/filecoin-project/ref-fvm/actions/workflows/ci.yml)\n\nThis repository contains the reference implementation of the Filecoin VM ([specs](https://github.com/filecoin-project/fvm-project)). It is written in Rust, and intended to be integrated via FFI into non-Rust clients (e.g. Lotus, Fuhon), or directly into Rust clients (e.g. Forest). FFI bindings for Go are provided in-repo, and developers are encouraged to contribute bindings for other languages.\n\n\nSee the [Project Website](https://fvm.filecoin.io/) for details.\n\n## Build requirements\n\n* Install [rustup](https://rustup.rs/).\n\n## Build instructions\n\n```sh\n$ git clone https://github.com/filecoin-project/ref-fvm.git\n$ cd fvm\n$ rustup target add wasm32-unknown-unknown\n$ make\n```\n\n## Code structure\n\nHere's what you'll find in each directory:\n\n- `/fvm`\n  - The core of the Filecoin Virtual Machine. The key concepts are:\n    - `Machine`: an instantiation of the machine, anchored at a specific state root and epoch, ready to intake messages to be applied.\n    - `Executor`: an object to execute messages on a `Machine`.\n    - `CallManager`: tracks and manages the call stack for a given message.\n    - Invocation container (conceptual layer, not explicitly appearing in code): the WASM instance + sandbox under which a given actor in the call stack runs.\n    - `Kernel`: the environment attached to an invocation container for external interactions.\n  - There are two API boundaries in the system:\n    1. the boundary between the actor code and the Kernel, which is traversed by invoking `Syscalls`.\n    2. the boundary between the FVM and the host node, represented by `Externs`.\n  - Some parts of the FVM are based on the [Forest](https://github.com/ChainSafe/forest) implementation.\n- `/sdk`\n  - Reference SDK implementation to write Filecoin native actors, used by the canonical built-in actors through the Actors FVM Runtime shim.\n  - User-defined FVM actors written in Rust can also use this SDK, although it is currently quite rough around the edges. In the next weeks, we expect to sweeten it for improved developer experience.\n  - Alternative SDKs will emerge in the community. We also expect community teams to develop SDKs in other WASM-compilable languages such as Swift, Kotlin (using Kotlin Native), and even Go (via the TinyGo compiler).\n- `/shared`\n  - A crate of core types and primitives shared between the FVM and the SDK.\n- `/ipld`\n  - IPLD libraries. Some of which are based on, and adapted from, the [Forest](https://github.com/ChainSafe/forest) implementation.\n- `/testing/conformance`\n  - Contains the test vector runner, as well as benchmarking utilities on top of it.\n  - The conformance test runner feeds the test vector corpus located at https://github.com/filecoin-project/fvm-test-vectors into ref-fvm, in order to validate spec conformance.\n  - The benchmarking utilities use the `criterion` Rust library to measure the performance and overhead of ref-fvm across various facets.\n  - See the [instructions](./testing/conformance/README.md#instructions) about how to run the tests and the benchmarks.\n  - Disclaimers\n    - Benchmarks are currently very slow to run, setup and teardown. This is due to using default WASM cache, and will be fixed soon.\n\n## License\n\nDual-licensed: [MIT](./LICENSE-MIT), [Apache Software License v2](./LICENSE-APACHE), by way of the\n[Permissive License Stack](https://protocol.ai/blog/announcing-the-permissive-license-stack/).\n\n---\n\nactors and vm forked from [ChainSafe/forest](https://github.com/ChainSafe/forest)\ncommit: [`73e8f95a108902c6bef44ee359a8478663844e5b`](https://github.com/ChainSafe/forest/commit/73e8f95a108902c6bef44ee359a8478663844e5b)\n", "release_dates": []}, {"name": "referrer-whitelist", "description": null, "language": null, "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": null, "release_dates": []}, {"name": "release-boss", "description": null, "language": "Python", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Release Boss\n\n![Build Status](https://github.com/brave/adblock-rust/actions/workflows/ci.yml/badge.svg)\n\nFeeling like you need another boss? We've got you covered. \nRelease boss is your all in one automated boss. It will nag you for triage things you should have done but didn't do.\n\n> It's just that we're putting new coversheets on all the TPS reports *before* they go out now. So if you could just remember to do that from now on, that'd be great ...\n\n## Setup\n\n`pipenv install`\n\n## Running tests\n\n`pipenv run pytest`\n\n## Environment\n\n```\nSLACK_ACCESS_TOKEN=<token-here>\nGITHUB_ACCESS_TOKEN=<token-here>\n```\n\n## Commands\n\n### Linting\n\n`pipenv run lint`\n\n### Find PR counts per release data\n\n`pipenv run main --action=pr-milestone`\n\n### Checks for missing labels and notifies people of those issues on Slack\n\n`pipenv run main --action=fix-missing-issue-labels`\n\n### Detect PRs that have a missing milestone\n\n`pipenv run main --action=pr-milestone`\n\n### Detect issues that have a missing milestone\n\n`pipenv run main --action=issues-milestone`\n\n### Other not fully supported commands without tweaking code\n\n- Plot PR counts per release data: `pipenv run plot`\n\n\n### Getting help\n\n`pipenv run main --help`\n", "release_dates": []}, {"name": "release-tools", "description": "Release tools for browser-laptop and extensions", "language": "JavaScript", "license": null, "readme": "# release-tools\n\nScripts and tools used for releasing browser-laptop and extensions\n", "release_dates": []}, {"name": "renovate-config", "description": null, "language": null, "license": null, "readme": null, "release_dates": []}, {"name": "scproxy", "description": "Multi tiered redis proxy hack for sccache (wip)", "language": "Go", "license": null, "readme": "# scproxy\n\nRedis backend for sccproxy that allows for read only with local caching and read write access over ssh forwarding.\n\nThis is somewhat of a hack since local caching would ideally be supported in sccache directly. It may make sense to use goma\nhere as well when the server side is open sourced (https://groups.google.com/a/chromium.org/forum/m/#!topic/chromium-dev/q7hSGr_JNzg).\n\n## Getting Started\n\n### Server\n\n```\n# Allow read/write and read only access for your public key\ncat ~/.ssh/id_rsa.pub > sshd/authorized_keys.rw\ncat ~/.ssh/id_rsa.pub > sshd/authorized_keys.ro\n\n# Build and start server\ndocker-compose -f docker-compose.proxy.yml up --build\n```\n\n### Read only client with local redis caching\n```\n./start.sh  <server ip>\n```\n\nCurrently this doesn't support encrypted ssh keys, and the above command assumes `~/.ssh/id_rsa`. Workaround for now is to create a second unencrypted ssh key that is only used for this service and pass it as an argument to `./start.sh`.\n```\nssh-keygen -f ~/.ssh/scproxy\n./start.sh <server ip> scproxy\n```\n\n### Read write client\n```\n./start_rw.sh  <server ip>\n```\n\n\n\n### Prerequisites\n\n* docker\n* docker-compose\n\n### Known issues\n\n", "release_dates": []}, {"name": "sdebug", "description": "a wrapper around debug() to add structured data logging", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# sdebug\nA wrapper around debug() to add structured data logging, viz., [RFC5424](https://tools.ietf.org/html/rfc5424#section-6.3).\n\nFirst,\ntake a look at the excellent [debug module](https://github.com/visionmedia/debug) to understand the basic concepts.\n\nNext,\nto add structure:\n\n\n    % DEBUG='*' node\n\n        // create a new debugging instance with the 'server' prefix\n        var debug = new (require('sdebug'))('server')\n\n        // add default properties for every log entry\n        debug.initialize({ 'server': { id: server.info.id } })\n\n        // create a log entry with unstructured text\n        debug('hello world.')\n\n        // outputs:\n        server [server@1104 id=\"zekariah.local:58165:iksjwi0d\"] hello world\n\n        // create a log entry with structured data\n        var params = { request: { id: '...', method: '...', pathname: '...', statusCode='...' },\n                       headers: ... }\n        debug('end', params)\n\n        // outputs (newlines added for readability):\n        server [request@1104 id=\"1455817135688:zekariah.local:58165:iksjwi0d:10000\" method=\"GET\" pathname=\"/\" statusCode=\"200\"]\n               [headers@1104 content_type=\"text/html; charset=utf-8\" cache_control=\"no-cache\" vary=\"accept-encoding\" content_encoding=\"gzip\"]\n               end\n", "release_dates": []}, {"name": "security-action", "description": "Composite GitHub CI Action containing the minimal viable security lint for brave repositories", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# security-action\n\nComposite GitHub CI Action[^1] containing the minimal viable security lint for brave repositories\n\n## Usage\n\nAdd an action under `.github/workflow/security-action.yml` with the following content:\n\n```yml\nname: security\non:\n  workflow_dispatch:\n  push:\n    branches: [main]\n  pull_request:\n    types: [opened, synchronize, reopened, ready_for_review]\n    branches: [main]\n\njobs:\n  security:\n    name: security\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      # CodeQL analyzed languages\n      matrix:\n        language: [ 'generic', 'javascript', 'python', 'ruby' ]\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 0\n      - uses: brave/security-action@main\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          slack_token: ${{ secrets.HOTSPOTS_SLACK_TOKEN }} # optional\n          # by default assignees will be thypon and bcaller, modify accordingly\n          assignees: |\n            yoursecuritycontact\n            yoursecondsecuritycontact\n          codeql_config: ./.github/codeql/codeql-config.yml # optional\n```\n\n## Branching Strategy\n\n- main branch, this should be tracked and included by all the repositories, without versioning. It should be always \"stable\" and contain the latest and greatest security checks\n- feature/*, feature branches including new security checkers\n- bugfix/*, fixes for specific bugs in the action\n\n## References\n\n[^1]: https://docs.github.com/en/actions/creating-actions/creating-a-composite-action\n", "release_dates": []}, {"name": "simplepadding", "description": null, "language": "Python", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# simplepadding\n\nModule used to add and remove simple padding to binary files up to 4GB.\n\n## Copyright notice\n\nCopyright 2020 Brave Software Inc.\n\nThis Source Code Form is subject to the terms of the Mozilla Public\nLicense, v. 2.0. If a copy of the MPL was not distributed with this file,\nYou can obtain one at https://mozilla.org/MPL/2.0/.\n", "release_dates": []}, {"name": "site-hacks-extension", "description": "Experiment moving the site hacks into an extension for use in Brave", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": null, "release_dates": []}, {"name": "slim-list-lambda", "description": "Lambda function for reducing EasyList + EasyPrivacy for use in iOS clients", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "Slim List System\n===\n\nSlim List is a AWS lambda based crawling system for evaluating which EasyList and EasyPrivacy rules are the most useful.  The main goal of the system is to shrink EasyList and EasyPrivacy so that they can be shipped in the iOS client.\n\nSlim list consists of many AWS parts: S3 for scratch and final resuls, SQS for job queing, and multiple lambdas included in this repo.\n\nHow the Lambdas in the system interact\n---\nThis lambda function is the entry point to the whole system.  While its implemented as a single lambda function, its performs five distinct tasks.  In order:\n   1. [brave/lambda_actions/crawl-dispatch.js](https://github.com/brave/slim-list-lambda/blob/master/brave/lambda_actions/crawl-dispatch.js) fetches a new Tracno 10k list and then queues up the sites to crawl in SQS.  This function is called once per crawl.\n   2. [brave/lambda_actions/crawl.js](https://github.com/brave/slim-list-lambda/blob/master/brave/lambda_actions/crawl.js) is called *per page* that needs to be crawled. It triggers a chrome instance to crawl a page, records everything thats fetched, writes a description of it to S3, and possibly kicks off more `brave/lambda_actions/crawl.js` instances to crawl child pages\n   3. [brave/lambda_actions/record.js](https://github.com/brave/slim-list-lambda/blob/master/brave/lambda_actions/record.js) is also called once for each page that is mesured.  This invocation reads all the seralized data from the `crawl.js` invocation, and writes it to postgres.  (This is a separate step to reduce the number of parallel jobs triggered in 1.iii, to avoid sinking the DB).\n   4. [brave/lambda_actions/build.js](https://github.com/brave/slim-list-lambda/blob/master/brave/lambda_actions/build.js) does the DB side analysis to determine which filter lists rules are popular enough to be included in \u201cslim list\u201d.  It is also called once per crawl.\n   5. [brave/lambda_actions/assemble.js](https://github.com/brave/slim-list-lambda/blob/master/brave/lambda_actions/assemble.js) combines the slim list data with brave owned/authored lists, and produces an iOS content blocking rule file, as well as a corresponding DAT file to be loaded by adblock-rust browser-side. It will do this for each regional list as well. All of the outputs are stored in S3.\n\nStructure of S3 Crawl Data\n---\n```\n    <batch>\n      domains.json\n      rules.dat\n      manifest.json\n      data\n        <domain>\n          <depth-breath>.json\n            {url: url crawled,\n            data: urls requested,\n            depth: depth of this report,\n            breath: breath of this report,\n            timestamp: ISO timestamp}\n```\n\nDeployment\n---\n\nSlim List lambdas are deployed into a staging and production account.  In order to deploy to the staging environment, perform merges/pushes on the `main` branch.  To deploy to production, perform merges/pushes on the `production` branch.  In order to gain access to these AWS environments, please ping DevOps team in #devops Brave Slack channel.\n", "release_dates": []}, {"name": "sniproxy", "description": "TLS proxy routing TCP connections to backends based on the TLS SNI in the TLS handshake", "language": "Go", "license": {"key": "gpl-3.0", "name": "GNU General Public License v3.0", "spdx_id": "GPL-3.0", "url": "https://api.github.com/licenses/gpl-3.0", "node_id": "MDc6TGljZW5zZTk="}, "readme": "# SNIProxy\n\n_SNIProxy_ is a TLS proxy which, based on the\n[TLS SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) contained in TLS\nhandshakes, routes TCP connections to backends. The proxy does not need the TLS\nencryption keys and can not decrypt the TLS traffic.\n\n_SNIProxy_ is meant to be simple to use and configure, with sane defaults and\nfew parameters.\n\n## Docker image\n\n```shell\n$ docker run --name sniproxy -p 443:443/tcp \\\n\t-v $(pwd)/sniproxy.conf:/sniproxy.conf \\\n\tatenart/sniproxy:latest -conf sniproxy.conf\n```\n\n_SNIProxy_ can be bound to a custom address or port using the `-bind` command\nline option.\n\n```shell\n$ docker run --name sniproxy -p 443:443/tcp \\\n\t-v $(pwd)/sniproxy.conf:/sniproxy.conf \\\n\tatenart/sniproxy:latest -bind 192.168.0.1:8080 -conf sniproxy.conf\n```\n\n## Configuration file\n\nThe configuration is made of a list of blocks. Each block represents a route. A\nroute is defined by a list of hostnames, a backend to route the connection to\nand optional parameters. Empty blocks (`{}`) can be omitted.\n\n```\nhostname0, hostname1, \u2026 {\n\tbackend <IP/hostname>:port {\n\t\toptional-parameter\n\t}\n\tparameter0\n\tparameter1 arg0, arg1, \u2026\n\t\u2026\n}\n```\n\nA route can be as simple as:\n\n```\nexample.net {\n\tbackend 1.2.3.4:8080\n}\n```\n\nHostnames can contain regexp:\n\n```\n# Matches example.net and all its subdomains.\nexample.net, *.example.net {\n\tbackend localhost:1234\n}\n```\n\nBy leaving hostname blank, passthrough mode is enabled:\n\n```\n# Uses example.com:443 as the backend\nexample.com {\n\tbackend :443\n}\n```\n\n### Optional parameters\n\n[HAProxy's PROXY protocol](https://www.haproxy.org/download/2.0/doc/proxy-protocol.txt)\nv1 and v2 are supported.\n\n```\nexample.net {\n\tbackend 1.2.3.4:443 {\n\t\t# Send a PROXY header using the PROXY protocol v1.\n\t\tsend-proxy\n\t}\n}\n\nblog.example.net {\n\tbackend 1.2.3.5:443 {\n\t\t# Send a PROXY header using the PROXY protocol v2.\n\t\tsend-proxy-v2\n\t}\n}\n```\n\n_SNIProxy_ also has the ability to block or allow connections based on the\nclient IP address. Single IPs or subnets (using a CIDR range) are supported.\n\n```\n# Deny a single client. All other connections will be routed to the backend.\nexample.net {\n\tbackend 1.2.3.4:443\n\tdeny 10.0.0.42\n}\n\n# Lists can be used as well, either using commas (,) or using multiple\n# statements.\nexample.net {\n\tbackend 1.2.3.4:443\n\tdeny 10.0.0.42, 10.0.0.43, 10.0.0.44\n\tdeny 10.0.0.45\n}\n\n# When at least one IP is allowed, all IPs are denied automatically (0.0.0.0/0\n# and ::/0).\nexample.net {\n\tbackend 1.2.3.4:443\n\t# 192.168.0.42 is allowed, all other IPs are denied.\n\tallow 192.168.0.42\n}\n\n# Example with ranges.\nexample.net {\n\tbackend 1.2.3.4:443\n\tdeny 192.168.0.0/24\n}\n\n# The most specific range wins (if the range is the same, deny wins).\nexample.net {\n\tbackend 1.2.3.4:443\n\t# Deny 192.168.0.0/22 except for 192.168.0.2 and 192.168.1.8/29.\n\tdeny 192.168.0.0/22\n\tallow 192.168.1.8/29, 192.168.0.2\n}\n```\n\n_SNIProxy_ can use a different dedicated backend for ACME TLS.\n\n```\nexample.net {\n\tbackend 1.2.3.4:443\n\tacme 1.2.3.5:443\n}\n```\n\nACLs can be bypassed for ACME:\n\n```\n# All IPs are denied except for 192.168.0.0/24 and ACME TLS.\nexample.net {\n\tbackend 1.2.3.4:443\n\tacme 1.2.3.5:443\n\tallow 192.168.0.0/24, acme\n}\n```\n", "release_dates": []}, {"name": "solana-token-list", "description": "The community maintained Solana token registry", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# @brave/spl-token-registry\n\n[![npm](https://img.shields.io/npm/v/@brave/spl-token-registry)](https://unpkg.com/@brave/spl-token-registry@latest/) [![GitHub license](https://img.shields.io/badge/license-APACHE-blue.svg)](https://github.com/brave/solana-token-list/blob/master/LICENSE)\n\nSolana Token Registry is a package that allows application to query for list of tokens.\nThe JSON schema for the tokens includes: chainId, address, name, decimals, symbol, logoURI (optional), tags (optional), and custom extensions metadata.\n\n## Installation\n\n```bash\nnpm install @brave/spl-token-registry\n```\n\n```bash\nyarn add @brave/spl-token-registry\n```\n\n## Examples\n\n### Query available tokens\n\n```typescript\nnew TokenListProvider().resolve().then((tokens) => {\n  const tokenList = tokens.filterByClusterSlug('mainnet-beta').getList();\n  console.log(tokenList);\n});\n```\n\n### Render icon for token in React\n\n```typescript jsx\nimport React, { useEffect, useState } from 'react';\nimport { TokenListProvider, TokenInfo } from '@brave/spl-token-registry';\n\n\nexport const Icon = (props: { mint: string }) => {\n  const [tokenMap, setTokenMap] = useState<Map<string, TokenInfo>>(new Map());\n\n  useEffect(() => {\n    new TokenListProvider().resolve().then(tokens => {\n      const tokenList = tokens.filterByChainId(ENV.MainnetBeta).getList();\n\n      setTokenMap(tokenList.reduce((map, item) => {\n        map.set(item.address, item);\n        return map;\n      },new Map()));\n    });\n  }, [setTokenMap]);\n\n  const token = tokenMap.get(props.mint);\n  if (!token || !token.logoURI) return null;\n\n  return (<img src={token.logoURI} />);\n\n```\n\n## Adding new token\n\nSubmit PR with changes to JSON file `src/tokens/solana.tokenlist.json`\n\nPlease follow the Uniswap Token List specification found here: https://github.com/Uniswap/token-lists\n\n# Disclaimer\n\nAll claims, content, designs, algorithms, estimates, roadmaps,\nspecifications, and performance measurements described in this project\nare done with the Solana Foundation's (\"SF\") best efforts. It is up to\nthe reader to check and validate their accuracy and truthfulness.\nFurthermore nothing in this project constitutes a solicitation for\ninvestment.\n\nAny content produced by SF or developer resources that SF provides, are\nfor educational and inspiration purposes only. SF does not encourage,\ninduce or sanction the deployment, integration or use of any such\napplications (including the code comprising the Solana blockchain\nprotocol) in violation of applicable laws or regulations and hereby\nprohibits any such deployment, integration or use. This includes use of\nany such applications by the reader (a) in violation of export control\nor sanctions laws of the United States or any other applicable\njurisdiction, (b) if the reader is located in or ordinarily resident in\na country or territory subject to comprehensive sanctions administered\nby the U.S. Office of Foreign Assets Control (OFAC), or (c) if the\nreader is or is working on behalf of a Specially Designated National\n(SDN) or a person subject to similar blocking or denied party\nprohibitions.\n\nThe reader should be aware that U.S. export control and sanctions laws\nprohibit U.S. persons (and other persons that are subject to such laws)\nfrom transacting with persons in certain countries and territories or\nthat are on the SDN list. As a project based primarily on open-source\nsoftware, it is possible that such sanctioned persons may nevertheless\nbypass prohibitions, obtain the code comprising the Solana blockchain\nprotocol (or other project code or applications) and deploy, integrate,\nor otherwise use it. Accordingly, there is a risk to individuals that\nother persons using the Solana blockchain protocol may be sanctioned\npersons and that transactions with such persons would be a violation of\nU.S. export controls and sanctions law. This risk applies to\nindividuals, organizations, and other ecosystem participants that\ndeploy, integrate, or use the Solana blockchain protocol code directly\n(e.g., as a node operator), and individuals that transact on the Solana\nblockchain through light clients, third party interfaces, and/or wallet\nsoftware.\n", "release_dates": ["2022-12-01T04:03:47Z", "2022-04-22T21:21:36Z", "2022-04-22T21:16:45Z"]}, {"name": "source-suggestions", "description": null, "language": "Python", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# brave-news-source-suggestion\n\nService for producing the source embedding representations and similarity matrix needed for source suggestion feature in Brave News.\n\n## Installation\n\n```\npip install -r requirements.txt\n```\n\n## Scripts\n**source-feed-accumulator.py**: parses Brave News feed periodically, collecting articles for each source in `articles_history.csv`. For each article, we store the `publisher_id` attribute.\n\n**sources-similarity-matrix.py**: takes as input the article history and produces a 384-dimensional embedding for each source, using the `sentence-transformer` package. More in particular:\n- `all-MiniLM-L6-v2` for english language sources.\n- `paraphrase-multilingual-MiniLM-L12-v2` for non-english language sources.\nOnce all source embeddings are generated, a pairwise source similarity matrix is produced.\n\n## Running locally\nTo collect and accumulate article history:\n```\nexport NO_UPLOAD=1\nexport NO_DOWNLOAD=1\npython source-feed-accumulator.py\n```\n\nTo computed source embeddings and produce the source similarity matrix:\n```\nexport NO_UPLOAD=1\nexport NO_DOWNLOAD=1\npython sources-similarity-matrix.py\n```\n", "release_dates": []}, {"name": "Sparkle", "description": "A software update framework for macOS", "language": "Objective-C", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": null, "release_dates": []}, {"name": "spectron", "description": "Test Electron apps using ChromeDriver", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# <img src=\"https://cloud.githubusercontent.com/assets/378023/15063284/cf544f2c-1383-11e6-9336-e13bd64b1694.png\" width=\"60px\" align=\"center\" alt=\"Spectron icon\"> Spectron\n\n[![Linux Build Status](https://travis-ci.org/electron/spectron.svg?branch=master)](https://travis-ci.org/electron/spectron)\n[![Windows Build Status](https://ci.appveyor.com/api/projects/status/iv8xd919q6b44pap/branch/master?svg=true)](https://ci.appveyor.com/project/kevinsawicki/spectron/branch/master)\n<br>\n[![js-standard-style](https://img.shields.io/badge/code%20style-standard-brightgreen.svg?style=flat)](http://standardjs.com/)\n[![devDependencies:?](https://img.shields.io/david/electron/spectron.svg)](https://david-dm.org/electron/spectron)\n<br>\n[![license:mit](https://img.shields.io/badge/license-mit-blue.svg)](https://opensource.org/licenses/MIT)\n[![npm:](https://img.shields.io/npm/v/spectron.svg)](https://www.npmjs.com/packages/spectron)\n[![dependencies:?](https://img.shields.io/npm/dm/spectron.svg)](https://www.npmjs.com/packages/spectron)\n\nEasily test your [Electron](http://electron.atom.io) apps using\n[ChromeDriver](https://sites.google.com/a/chromium.org/chromedriver) and\n[WebdriverIO](http://webdriver.io).\n\nThis minor version of this library tracks the minor version of the Electron\nversions released. So if you are using Electron `1.0.x` you would want to use\na `spectron` dependency of `~3.0.0` in your `package.json` file.\n\nLearn more from [this presentation](https://speakerdeck.com/kevinsawicki/testing-your-electron-apps-with-chromedriver).\n\n:rotating_light: Upgrading from `1.x` to `2.x`/`3.x`? Read the [changelog](https://github.com/electron/spectron/blob/master/CHANGELOG.md).\n\n## Using\n\n```sh\nnpm install --save-dev spectron\n```\n\nSpectron works with any testing framework but the following example uses\n[mocha](https://mochajs.org):\n\n```js\nvar Application = require('spectron').Application\nvar assert = require('assert')\n\ndescribe('application launch', function () {\n  this.timeout(10000)\n\n  beforeEach(function () {\n    this.app = new Application({\n      path: '/Applications/MyApp.app/Contents/MacOS/MyApp'\n    })\n    return this.app.start()\n  })\n\n  afterEach(function () {\n    if (this.app && this.app.isRunning()) {\n      return this.app.stop()\n    }\n  })\n\n  it('shows an initial window', function () {\n    return this.app.client.getWindowCount().then(function (count) {\n      assert.equal(count, 1)\n    })\n  })\n})\n```\n\n## Application API\n\nSpectron exports an `Application` class that when configured, can start and\nstop your Electron application.\n\n### new Application(options)\n\nCreate a new application with the following options:\n\n* `path` -  **Required.** String path to the Electron application executable to\n  launch.\n  **Note:** If you want to invoke `electron` directly with your app's main\n  script then you should specify `path` as  `electron` via `electron-prebuilt`\n  and specify your app's main script path as the first argument in the `args`\n  array.\n* `args` - Array of arguments to pass to the executable.\n  See [here](https://sites.google.com/a/chromium.org/chromedriver/capabilities)\n  for details on the Chrome arguments.\n* `cwd`- String path to the working directory to use for the launched\n  application. Defaults to `process.cwd()`.\n* `env` - Object of additional environment variables to set in the launched\n  application.\n* `host` - String host name of the launched `chromedriver` process.\n  Defaults to `'localhost'`.\n* `port` - Number port of the launched `chromedriver` process.\n  Defaults to `9515`.\n* `nodePath` - String path to a `node` executable to launch ChromeDriver with.\n  Defaults to `process.execPath`.\n* `connectionRetryCount` - Number of retry attempts to make when connecting\n  to ChromeDriver. Defaults to `10` attempts.\n* `connectionRetryTimeout` - Number in milliseconds to wait for connections\n  to ChromeDriver to be made. Defaults to `30000` milliseconds.\n* `quitTimeout` - Number in milliseconds to wait for application quitting.\n  Defaults to `1000` milliseconds.\n* `requireName` - Custom property name to use when requiring modules. Defaults\n  to `require`. This should only be used if your application deletes the main\n  `window.require` function and assigns it to another property name on `window`.\n* `startTimeout` - Number in milliseconds to wait for ChromeDriver to start.\n  Defaults to `5000` milliseconds.\n* `waitTimeout` - Number in milliseconds to wait for calls like\n  `waitUntilTextExists` and `waitUntilWindowLoaded` to complete.\n  Defaults to `5000` milliseconds.\n* `debuggerAddress` - String address of a Chrome debugger server to connect to.\n* `chromeDriverLogPath` - String path to file to store ChromeDriver logs in.\n  Setting this option enables `--verbose` logging when starting ChromeDriver.\n\n### Node Integration\n\nThe Electron helpers provided by Spectron require accessing the core Electron\nAPIs in the renderer processes of your application. So if your Electron\napplication has `nodeIntegration` set to `false` then you'll need to expose a\n`require` window global to Spectron so it can access the core Electron APIs.\n\nYou can do this by adding a [`preload`][preload] script that does the following:\n\n```js\nif (process.env.NODE_ENV === 'test') {\n  window.electronRequire = require\n}\n```\n\nThen create the Spectron `Application` with the `requireName` option set to\n`'electronRequire'` and then runs your tests via `NODE_ENV=test npm test`.\n\n**Note:** This is only required if you tests are accessing any Electron APIs.\nYou don't need to do this if you are only accessing the helpers on the `client`\nproperty which do not require Node integration.\n\n### Properties\n\n#### client\n\nSpectron uses [WebdriverIO](http://webdriver.io) and exposes the managed\n`client` property on the created `Application` instances.\n\nThe full `client` API provided by WebdriverIO can be found\n[here](http://webdriver.io/api.html).\n\nSeveral additional commands are provided specific to Electron.\n\nAll the commands return a `Promise`.\n\nSo if you wanted to get the text of an element you would do:\n\n```js\napp.client.getText('#error-alert').then(function (errorText) {\n  console.log('The #error-alert text content is ' + errorText)\n})\n```\n\n#### electron\n\nThe `electron` property is your gateway to accessing the full Electron API.\n\nEach Electron module is exposed as a property on the `electron` property\nso you can think of it as an alias for `require('electron')` from within your\napp.\n\nSo if you wanted to access the [clipboard](http://electron.atom.io/docs/latest/api/clipboard)\nAPI in your tests you would do:\n\n```js\napp.electron.clipboard.writeText('pasta')\n   .electron.clipboard.readText().then(function (clipboardText) {\n     console.log('The clipboard text is ' + clipboardText)\n   })\n```\n\n#### browserWindow\n\nThe `browserWindow` property is an alias for `require('electron').remote.getCurrentWindow()`.\n\nIt provides you access to the current [BrowserWindow](http://electron.atom.io/docs/latest/api/browser-window/)\nand contains all the APIs.\n\nSo if you wanted to check if the current window is visible in your tests you\nwould do:\n\n```js\napp.browserWindow.isVisible().then(function (visible) {\n  console.log('window is visible? ' + visible)\n})\n```\n\nIt is named `browserWindow` instead of `window` so that it doesn't collide\nwith the WebDriver command of that name.\n\n##### capturePage\n\nThe async `capturePage` API is supported but instead of taking a callback it\nreturns a `Promise` that resolves to a `Buffer` that is the image data of\nscreenshot.\n\n```js\napp.browserWindow.capturePage().then(function (imageBuffer) {\n  fs.writeFile('page.png', imageBuffer)\n})\n```\n\n#### webContents\n\nThe `webContents` property is an alias for `require('electron').remote.getCurrentWebContents()`.\n\nIt provides you access to the [WebContents](http://electron.atom.io/docs/latest/api/web-contents/)\nfor the current window and contains all the APIs.\n\nSo if you wanted to check if the current window is loading in your tests you\nwould do:\n\n```js\napp.webContents.isLoading().then(function (visible) {\n  console.log('window is loading? ' + visible)\n})\n```\n\n##### savePage\n\nThe async `savePage` API is supported but instead of taking a callback it\nreturns a `Promise` that will raise any errors and resolve to `undefined` when\ncomplete.\n\n```js\napp.webContents.savePage('/Users/kevin/page.html', 'HTMLComplete')\n  .then(function () {\n    console.log('page saved')\n  }).catch(function (error) {\n    console.error('saving page failed', error.message)\n  })\n```\n\n#### mainProcess\n\nThe `mainProcess` property is an alias for `require('electron').remote.process`.\n\nIt provides you access to the main process's [process](https://nodejs.org/api/process.html)\nglobal.\n\nSo if you wanted to get the `argv` for the main process in your tests you would\ndo:\n\n```js\napp.mainProcess.argv().then(function (argv) {\n  console.log('main process args: ' + argv)\n})\n```\n\nProperties on the `process` are exposed as functions that return promises so\nmake sure to call `mainProcess.env().then(...)` instead of\n`mainProcess.env.then(...)`.\n\n#### rendererProcess\n\nThe `rendererProcess` property is an alias for `global.process`.\n\nIt provides you access to the renderer process's [process](https://nodejs.org/api/process.html)\nglobal.\n\nSo if you wanted to get the environment variables for the renderer process in\nyour tests you would do:\n\n```js\napp.rendererProcess.env().then(function (env) {\n  console.log('renderer process env variables: ' + env)\n})\n```\n\n### Methods\n\n#### start()\n\nStarts the application. Returns a `Promise` that will be resolved when the\napplication is ready to use. You should always wait for start to complete\nbefore running any commands.\n\n#### stop()\n\nStops the application. Returns a `Promise` that will be resolved once the\napplication has stopped.\n\n#### restart()\n\nStops the application and then starts it. Returns a `Promise` that will be\nresolved once the application has started again.\n\n#### isRunning()\n\nChecks to determine if the application is running or not.\n\nReturns a `Boolean`.\n\n#### getSettings()\n\nGet all the configured options passed to the `new Application()` constructor.\nThis will include the default options values currently being used.\n\nReturns an `Object`.\n\n#### client.getMainProcessLogs()\n\nGets the `console` log output from the main process. The logs are cleared\nafter they are returned.\n\nReturns a `Promise` that resolves to an array of string log messages\n\n```js\napp.client.getMainProcessLogs().then(function (logs) {\n  logs.forEach(function (log) {\n    console.log(log)\n  })\n})\n```\n\n#### client.getRenderProcessLogs()\n\nGets the `console` log output from the render process. The logs are cleared\nafter they are returned.\n\nReturns a `Promise` that resolves to an array of log objects.\n\n```js\napp.client.getRenderProcessLogs().then(function (logs) {\n  logs.forEach(function (log) {\n    console.log(log.message)\n    console.log(log.source)\n    console.log(log.level)\n  })\n})\n```\n\n#### client.getSelectedText()\n\nGet the selected text in the current window.\n\n```js\napp.client.getSelectedText().then(function (selectedText) {\n  console.log(selectedText)\n})\n```\n\n#### client.getWindowCount()\n\nGets the number of open windows.\n`<webview>` tags are also counted as separate windows.\n\n```js\napp.client.getWindowCount().then(function (count) {\n  console.log(count)\n})\n```\n\n#### client.waitUntilTextExists(selector, text, [timeout])\n\nWaits until the element matching the given selector contains the given\ntext. Takes an optional timeout in milliseconds that defaults to `5000`.\n\n```js\napp.client.waitUntilTextExists('#message', 'Success', 10000)\n```\n\n#### client.waitUntilWindowLoaded([timeout])\n\nWait until the window is no longer loading. Takes an optional timeout\nin milliseconds that defaults to `5000`.\n\n```js\napp.client.waitUntilWindowLoaded(10000)\n```\n\n#### client.windowByIndex(index)\n\nFocus a window using its index from the `windowHandles()` array.\n`<webview>` tags can also be focused as a separate window.\n\n```js\napp.client.windowByIndex(1)\n```\n\n### Accessibility Testing\n\nSpectron bundles the [Accessibility Developer Tools](https://github.com/GoogleChrome/accessibility-developer-tools)\nprovided by Google and adds support for auditing each window and `<webview>`\ntag in your application.\n\n#### client.auditAccessibility(options)\n\nRun an accessibility audit in the focused window with the specified options.\n\n* `options` - An optional Object with the following keys:\n  * `ignoreWarnings` - `true` to ignore failures with a severity of `'Warning'`\n    and only include failures with a severity of `'Severe'`. Defaults to `false`.\n  * `ignoreRules` - Array of String rule code values such as `AX_COLOR_01` to\n    ignore failures for. The full list is available [here](https://github.com/GoogleChrome/accessibility-developer-tools/wiki/Audit-Rules).\n\nReturns an `audit` Object with the following properties:\n\n* `message` - A detailed String message about the results\n* `failed` - A Boolean, `false` when the audit has failures\n* `results` - An array of detail objects for each failed rule. Each object\n  in the array has the following properties:\n  * `code` - A unique String accessibility rule identifier\n  * `elements` - An Array of Strings representing the selector path of each\n    HTML element that failed the rule\n  * `message` - A String message about the failed rule\n  * `severity` - `'Warning'` or `'Severe'`\n  * `url` - A String URL providing more details about the failed rule\n\n```js\napp.client.auditAccessibility().then(function (audit) {\n  if (audit.failed) {\n    console.error(audit.message)\n  }\n})\n```\n\nSee https://github.com/GoogleChrome/accessibility-developer-tools/wiki/Audit-Rules\nfor more details about the audit rules.\n\nIf you are using a `<webview>` tag in your app and want to audit both the outer\npage and the `<webview>`'s page then you will need to do the following:\n\n```js\n// Focus main page and audit it\napp.client.windowByIndex(0).then(function() {\n  app.client.auditAccessibility().then(function (audit) {\n    if (audit.failed) {\n      console.error('Main page failed audit')\n      console.error(audit.message)\n    }\n\n    //Focus <webview> tag and audit it\n    app.client.windowByIndex(1).then(function() {\n      app.client.auditAccessibility().then(function () {\n        if (audit.failed) {\n          console.error('<webview> page failed audit')\n          console.error(audit.message)\n        }\n      })\n    })\n  })\n})\n```\n\n## Continuous Integration\n\n### On Travis CI\n\nYou will want to add the following to your `.travis.yml` file when building on\nLinux:\n\n```yml\nbefore_script:\n  - \"export DISPLAY=:99.0\"\n  - \"sh -e /etc/init.d/xvfb start\"\n  - sleep 3 # give xvfb some time to start\n```\n\nCheck out Spectron's [.travis.yml](https://github.com/electron/spectron/blob/master/.travis.yml)\nfile for a production example.\n\n### On AppVeyor\n\nYou will want to add the following to your `appveyor.yml` file:\n\n```yml\nos: unstable\n```\n\nCheck out Spectron's [appveyor.yml](https://github.com/electron/spectron/blob/master/appveyor.yml)\nfile for a production example.\n\n\n## Test Library Examples\n\n### With Chai As Promised\n\nWebdriverIO is promise-based and so it pairs really well with the\n[Chai as Promised](https://github.com/domenic/chai-as-promised) library that\nbuilds on top of [Chai](http://chaijs.com).\n\nUsing these together allows you to chain assertions together and have fewer\ncallback blocks. See below for a simple example:\n\n```sh\nnpm install --save-dev chai\nnpm install --save-dev chai-as-promised\n```\n\n```js\nvar Application = require('spectron').Application\nvar chai = require('chai')\nvar chaiAsPromised = require('chai-as-promised')\nvar path = require('path')\n\nchai.should()\nchai.use(chaiAsPromised)\n\ndescribe('application launch', function () {\n  beforeEach(function () {\n    this.app = new Application({\n      path: '/Applications/MyApp.app/Contents/MacOS/MyApp'\n    })\n    return this.app.start()\n  })\n\n  beforeEach(function () {\n    chaiAsPromised.transferPromiseness = this.app.transferPromiseness\n  })\n\n  afterEach(function () {\n    if (this.app && this.app.isRunning()) {\n      return this.app.stop()\n    }\n  })\n\n  it('opens a window', function () {\n    return this.app.client.waitUntilWindowLoaded()\n      .getWindowCount().should.eventually.equal(1)\n      .browserWindow.isMinimized().should.eventually.be.false\n      .browserWindow.isDevToolsOpened().should.eventually.be.false\n      .browserWindow.isVisible().should.eventually.be.true\n      .browserWindow.isFocused().should.eventually.be.true\n      .browserWindow.getBounds().should.eventually.have.property('width').and.be.above(0)\n      .browserWindow.getBounds().should.eventually.have.property('height').and.be.above(0)\n  })\n})\n```\n\n### With AVA\n\nSpectron works with [AVA](https://github.com/avajs/ava), which allows you\nto write your tests in ES2015+ without doing any extra work.\n\n```js\nimport test from 'ava';\nimport {Application} from 'spectron';\n\ntest.beforeEach(t => {\n  t.context.app = new Application({\n    path: '/Applications/MyApp.app/Contents/MacOS/MyApp'\n  });\n\n  return t.context.app.start();\n});\n\ntest.afterEach(t => {\n  return t.context.app.stop();\n});\n\ntest(t => {\n  return t.context.app.client.waitUntilWindowLoaded()\n    .getWindowCount().then(count => {\n      t.is(count, 1);\n    }).browserWindow.isMinimized().then(min => {\n      t.false(min);\n    }).browserWindow.isDevToolsOpened().then(opened => {\n      t.false(opened);\n    }).browserWindow.isVisible().then(visible => {\n      t.true(visible);\n    }).browserWindow.isFocused().then(focused => {\n      t.true(focused);\n    }).browserWindow.getBounds().then(bounds => {\n      t.true(bounds.width > 0);\n      t.true(bounds.height > 0);\n    });\n});\n```\n\nAVA has built-in support for [async functions](https://github.com/avajs/ava#async-function-support), which simplifies async operations:\n\n```js\nimport test from 'ava';\nimport {Application} from 'spectron';\n\ntest.beforeEach(async t => {\n  t.context.app = new Application({\n    path: '/Applications/MyApp.app/Contents/MacOS/MyApp'\n  });\n\n  await t.context.app.start();\n});\n\ntest.afterEach.always(async t => {\n  await t.context.app.stop();\n});\n\ntest(async t => {\n  const app = t.context.app;\n  await app.client.waitUntilWindowLoaded();\n\n  const win = app.browserWindow;\n  t.is(await app.client.getWindowCount(), 1);\n  t.false(await win.isMinimized());\n  t.false(await win.isDevToolsOpened());\n  t.true(await win.isVisible());\n  t.true(await win.isFocused());\n\n  const {width, height} = await win.getBounds();\n  t.true(width > 0);\n  t.true(height > 0);\n});\n```\n\n[preload]: http://electron.atom.io/docs/api/browser-window/#new-browserwindowoptions\n", "release_dates": []}, {"name": "Squirrel.Windows", "description": "An installation and update framework for Windows desktop apps", "language": "C++", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "| README.md |\n|:---|\n\n![](docs/artwork/Squirrel-Logo.png)\n\n# Squirrel: It's like ClickOnce but Works\u2122\n\nSquirrel is both a set of tools and a library, to completely manage both installation and updating your Desktop Windows application, written in either C# or any other language (i.e., Squirrel can manage native C++ applications).\n\nSquirrel uses NuGet packages to create installation and update packages, which means that you probably already know most of what you need to create an installer.\n\n## What Do We Want?\n\nWindows apps should be as fast and as easy to install and update as apps like Google Chrome. From an app developer's side, it should be really straightforward to create an installer for my app, and publish updates to it, without having to jump through insane hoops. \n\n* **Integrating** an app to use Squirrel should be extremely easy, provide a client API, and be developer friendly.\n* **Packaging** is really easy, can be automated, and supports delta update packages.\n* **Distributing** should be straightforward, use simple HTTP updates, and provide multiple \"channels\" (a-la Chrome Dev/Beta/Release).\n* **Installing** is Wizard-Free\u2122, with no UAC dialogs, does not require reboot, and is .NET Framework friendly.\n* **Updating** is in the background, doesn't interrupt the user, and does not require a reboot.\n\nRefer to our full list of goals for [integrating, packaging, distributing, installing, and updating](docs/goals.md).\n\n## Documentation\n\nSee the documentation [Table of Contents](docs/readme.md) for an overview of the available documentation for Squirrel.Windows. It includes a [Getting Started Guide](docs/getting-started/0-overview.md) as well as additional topics related to using Squirrel in your applications. \n\n## Building Squirrel\nFor the impatient:\n\n```sh\ngit clone --recursive https://github.com/squirrel/squirrel.windows\ncd squirrel.windows\n.\\.NuGet\\NuGet.exe restore\nmsbuild /p:Configuration=Release\n```\nSee [Contributing](docs/contributing/contributing.md) for additional information on building and contributing to Squirrel.\n\n\n## License and Usage\n\nSee [COPYING](COPYING) for details on copyright and usage of the Squirrel.Windows software.\n\n\n\n\n\n\n\n\n\n", "release_dates": []}, {"name": "sta-rs", "description": null, "language": "Rust", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# sta-rs\n\nRust workspace for implementing basic functionality of [STAR: Distributed\nSecret-Sharing for Threshold Aggregation\nReporting](https://arxiv.org/abs/2109.10074).\n\n## Disclaimer\n\nWARNING the libraries present in this workspace have not been audited,\nuse at your own risk! This code is under active development and may\nchange substantially in future versions.\n\n## Crates\n\n- [sta-rs](./star): A rust implementation of the [STAR\n  protocol](https://arxiv.org/abs/2109.10074).\n- [ppoprf](./ppoprf): A rust implementation of the PPOPRF protocol\n  detailed in the [STAR paper](https://arxiv.org/abs/2109.10074).\n- [sharks](./sharks): A fork of the existing [sharks\n  crate](https://crates.io/crates/sharks) for performing Shamir secret\n  sharing, using larger base fields of sizes 129 and 255 bits. The\n  fields were implemented using \n- [adss](./adss): A rust implementation of the [Adept Secret\n  Sharing scheme](https://eprint.iacr.org/2020/800) of Bellare et al,\n  based on the forked [star-sharks](./sharks) crate, using the underlying\n  finite field implementation made available in\n  [zkcrypto/ff](https://github.com/zkcrypto/ff).\n- [star-wasm](./star-wasm): WASM bindings for using [star](./star)\n  functionality.\n\n## Quickstart\n\nBuild & test:\n```\ncargo build\ncargo test\n```\n\nBenchmarks:\n```\ncargo bench\n```\n\nOpen local copy of documentation:\n```\ncargo doc --open --no-deps\n```\n## Example usage\n\n### WASM\n\nSee [star-wasm](./star-wasm/src/lib.rs) for public API functions exposed\nby libraries.\n\n- The `create_share` function should be called by clients, and creates\n  the `share` and `tag` sent in a STAR client message, as well as the\n  encryption `key` used to encrypt data to the server. Once this\n  function has been called, use `key` to encrypt the desired data into a\n  `ciphertext` object (using a valid AES encryption method). The client\n  should then send `(ciphertext, share, tag)` to the aggregation server.\n- The `group_shares` function takes in a collection of `share` objects\n  and recovers the `key` object that the client used for encrypting\n  `ciphertext`. This function only succeeds if the number of shares is\n  higher than the prescribed threshold.\n\n", "release_dates": []}, {"name": "star-randsrv", "description": "Go wrapper service for the STAR randomness server.", "language": "Rust", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "STAR Randomness Server\n======================\n\nThis repository implements the randomness server that's proposed\nin the paper [STAR: Distributed Secret Sharing\nfor Private Threshold Aggregation Reporting](https://arxiv.org/abs/2109.10074).\nThe actual oblivious pseudorandom function implementation can be found\nin the [sta-rs](https://github.com/brave/sta-rs) repository.\nThis repository implements webservice wrapper to make evaluation available\nover the network.\n\nIt also includes a reproducible container build that can be run inside an\nAWS Nitro Enclave, providing remote attestation of the implementation and\nadditional security for the private key.\n\nInstallation\n------------\n\nTo test, lint, and build the randomness server, simply run:\n\n```\nmake\n```\n\nTo execute just the randomness webapp with logging, run:\n\n```\nRUST_LOG=tower_http=trace,star_randsrv=debug cargo run\n```\n\nTo build a reproducible container image of the randomness server, run:\n\n```\nmake image\n```\n\nInput\n-----\n\nThe randomness server exposes an HTTP POST request handler at `/randomness`.\nThe handler expects a JSON-formatted request body.  Below is an example of a\nvalid request body.\n\n```\n{\n  \"points\": [\n    \"uqUmPbpGjpqaQcVnbn39PZGtL4DjfY+h9R+XqlKLuVc=\",\n    \"CCBnmLsPR8hFzuxhRz0a05TAh+p0jFhebMCDgOcfdWk=\",\n    \"bNQSygww5ykQpfsDMJXTiaX/MmpWW4qnfmuRpdR/1yY=\"\n  ]\n}\n```\n\nThe JSON array `points` contains a list of one or more Base64-encoded\n[Ristretto](https://github.com/bwesterb/go-ristretto) points.\n\nOutput\n------\n\nThe randomness server's response contains a similar JSON structure but its\npoints are punctured based on the client-provided input and the server's secret\nkey.  Refer to the [STAR paper](https://arxiv.org/abs/2109.10074) for details.\nBelow is an example of the server's response:\n\n```\n{\n  \"epoch\": 0,\n  \"points\": [\n    \"qC3vaUizBSrNZCCkzD3jBhHqMEWZIuNj5IdNk57GGHY=\",\n    \"rh7Tcr1LqwVQVtCEEIZqwUCPDvBOMM5bJPA8EfShnzI=\",\n    \"Bq8LJ0KpfwQHgh1tkr8OP+ogmxPQz7lWHfAPuyVxXU0=\"\n  ]\n}\n```\n\nNote that the array's ordering matters.  The point at index *n* of the server's\nresponse corresponds to the point at index *n* of the client's request.\n", "release_dates": []}, {"name": "store-brave-com", "description": null, "language": "TypeScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave Merch Store\n\n## Architecture\nThis repository is a monorepo with two services:\n\n### Storefront\nThe storefront is built using [SvelteKit](https://kit.svelte.dev/). All queries to the API are defined using GraphQL, but via an autogenerated SDK created by [`@graphql-codegen`](https://the-guild.dev/graphql/codegen). E.g.\n\n```graphql\nquery FeaturedProducts {\n  products(where: { isFeatured: { equals: true } }) {\n    ...ProductSummary\n  }\n}\n```\n\n```javascript\nconst { products } = await sdk.FeaturedProducts();\n```\n\n### API\nThe API is powered by [Keystone](https://keystonejs.com/), which is a CMS that provides a GraphQL API which the storefront consumes. Note that this API is not publicly available, and is restricted to requests coming from the `storefront` service.\n\nAll of the data comes from Printful via their [API](https://developers.printful.com/docs/).\n\n## Production deployment\n### Frontend\n\n#### Build\n\n```bash\nnpm install && npm run build\n```\n\n#### Start\n\n```bash\nnpm run start\n```\n\nYou'll need the following environment variables:\n\n```\nENVIRONMENT=/* staging | production */\nBASE_URL=/* environment specific domain for store frontend (IMPORTANT: no trailing slash) */\nPUBLIC_ASSETS_PATH=/* public URL to images S3 bucket e.g. https://cdn.store.brave.com */\nAPI_URL=/* url (not including the path) where GraphQL api can be found */\nPRINTFUL_API_TOKEN=/* api token from printful */\nPRINTFUL_BASE_URL=https://api.printful.com\nPRINTFUL_STORE_ID=/* store id from printful */\nSTRIPE_KEY=/* key for making requests to Stripe */\nSTRIPE_WEBHOOK_SECRET=/* key for making listening to Stripe webhooks */\nSENTRY_DSN=/* DSN for Sentry alerts */\n```\n\n### API\n\n#### Build\n\n```bash\ncd api && npm install && npm run build\n```\n\n#### Start\n\n```bash\nnpm run start\n```\n\nYou'll need the following environment variables:\n\n```\nENVIRONMENT=/* staging | production */\nSESSION_SECRET=/* 32 character code */\nDB_URL=/* db url, e.g. localhost:5432 */\nS3_IMAGES_BUCKET=/* bucket name from s3 */\nPUBLIC_ASSETS_PATH=/* public URL to images S3 bucket e.g. https://cdn.store.brave.com */\nPRINTFUL_API_TOKEN=/* api token from printful */\nPRINTFUL_BASE_URL=https://api.printful.com\nPRINTFUL_STORE_ID=/* store id from printful */\nSENTRY_DSN=/* DSN for Sentry alerts */\n```\n\n## Local development\n\n### Setup\n\n#### PostgreSQL\nIn order to develop locally, you must have [PostgreSQL](https://www.postgresql.org/download/) downloaded and running on your machine.\n\n#### Environment variables\nYou'll also need to create two `.env` files \u2013 one in the root of the repository, and the other in the `api/` folder:\n\n```bash\ntouch .env\ntouch api/.env\n```\n\nThe files should be populated with the respective sets of variables as described in [Production deployment](#production-deployment), using the appropriate values for your local environment.\n\n#### Dependencies\nEnsure dependencies are installed for both the root director and the `api/` directory.\n\n```bash\nnpm install\ncd api && npm install\ncd ../ # return to root for subsequent commands\n```\n\n### Start API (Keystone)\nIn order to start the API, open a new terminal window, `cd` into `api`, and start the service.\n\n```bash\nnpm run dev\n```\n\nRunning the above command will create the database if necessary and run the migrations to create the necessary tables.\n\nYou can populate the DB by going to `http://localhost:3000/sync-store` and clicking the `Sync now` button. **Note** that in our staging and production environments, images are synced to our own S3 bucket, and we do not request images directly from Printful's CDN on the storefront. However when running locally, these images _**will**_ be requested from Printful's CDN unless you've authenticated with AWS with the appropriate role.\n\n### Start storefront (SvelteKit)\nLeaving the terminal window open for the API, start the storefront from the root of the repository. In order to run this, you'll need to provide the `PUBLIC_ASSETS_PATH` environment variable in order for it to be available during the initial build phase. The value should use the staging URL for the image CDN: `https://cdn.store.bravesoftware.com`.\n\n```bash\nPUBLIC_ASSETS_PATH=https://cdn.store.bravesoftware.com npm run dev\n```\n\n### Start watch script for `codegen` (optional)\nThe storefront uses an SDK to interact with the API which is automatically generated by [`@graphql-codegen`](https://the-guild.dev/graphql/codegen) from GraphQL queries defined in `src/lib/graphql/queries.graphql`.\n\nIn order to watch for changes to `src/lib/graphql/queries.graphql` and trigger this generation process, you can run the following command **in a new terminal** (this would be the third necessary terminal).\n\n```bash\nnpm run gen -- --watch \"src/**/*.graphql\"\n```\n\n## Branch promotion\nUpon approval, PR branches are merged to `staging` via `Squash and merge` and the staging environment is rebuilt via CI/CD. Once functionality is confirmed on the staging site and the feature is ready to move to production, the `staging` branch is merged into `main` using the `--ff-only` flag on a local machine and then pushed to the remote `main` branch.\n\nE.g.\n\n```bash\ngit fetch\ngit merge --ff-only origin/staging\ngit push\n```\n\nPushing to `main`, like `staging`, triggers CI/CD to rebuild the production environment.\n\n### Diagram of branch flow\n\n```mermaid\nflowchart LR\n  subgraph STAGING\n    direction TB\n    s1{{on push}} --> s2[CI/CD] --> s3([store.bravesoftware.com])\n  end\n  subgraph MAIN\n    direction TB\n    m1{{on push}} --> m2[CI/CD] --> m3([store.brave.com])\n  end\nPR -->|Squash and merge| STAGING -->|merge --ff-only| MAIN\n```\n", "release_dates": []}, {"name": "sugarcoat", "description": "\ud83d\udcdc Autogenerate privacy-preserving versions of JavaScript scripts", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# SugarCoat\n\nThis is used in the [SugarCoat pipeline](https://github.com/brave-experiments/sugarcoat-pipeline) to generate privacy-preserving versions of tracking scripts.\n\n## Development\n\n[pnpm](https://pnpm.js.org/) is recommended for managing a JavaScript development environment for\nSugarCoat.\n\nTo initialize an isolated JavaScript development environment:\n\n```\npnpm install\n```\n\n### Code Formatting\n\nCode formatting for JavaScript is handled by [prettierx](https://github.com/brodybits/prettierx),\nwith a few [options](.prettierrc.toml) tweaked.\n\nTo check that the code is correctly formatted:\n\n```\npnpm run check\n```\n\nTo auto-format the code:\n\n```\npnpm run fmt\n```\n", "release_dates": []}, {"name": "sugarcoat-pipeline", "description": "CLI that implements the SugarCoat pipeline", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# SugarCoat Pipeline\n\nSugarCoat is a tool that allows filterlist authors to automatically patch JavaScript scripts to restrict their access to sensitive data according to a custom privacy policy. Check out the [blog post](https://brave.com/privacy-updates/12-sugarcoat/) and [paper](https://brave.com/wp-content/uploads/2021/06/sugarcoat-ccs-2021.pdf)!\n\nThis repo is an implementation of the SugarCoat pipeline. It uses [pagegraph-crawl](https://github.com/brave-experiments/pagegraph-crawl) to crawl a given website and generate PageGraph graphs, [pagegraph-rust-cli](https://github.com/brave-experiments/pagegraph-rust/tree/main/pagegraph-cli) to get JavaScript script sources that match adblock rules from the generated graphs, and [sugarcoat](https://github.com/brave-experiments/sugarcoat) for the actual patching of JavaScript scripts. \n\nYou can specify which sensitive Web APIs to block access to in `policy.json` ([example](https://github.com/brave-experiments/sugarcoat-pipeline/blob/main/policy.json)). All SugarCoat pipeline output is generated in `output/` by default (can be changed via CLI argument). Patched scripts go in `output/sugarcoated_scripts` and the generated EasyList-style filter rules in `output/sugarcoat_rules.txt`.\n\n## Setup\n\n1. Git clone this repo:\n\n```bash\ngit clone https://github.com/brave-experiments/sugarcoat-pipeline\ncd sugarcoat-pipeline\n```\n\n2. You need the [Rust and Cargo toolchain](https://doc.rust-lang.org/cargo/getting-started/installation.html) setup in order to use the SugarCoat pipeline. The `pagegraph-rust-cli` Rust binary is built using Cargo as part of the post-installation phase. \n\n3. To install the NPM dependencies:\n\n```bash\nnpm install\n```\n\nNote that the minimum Node version required is `14.18.1`.\n\n4. You will also need a working PageGraph binary (an instrumented version of the Brave browser) to crawl the website you want to sugarcoat and generate `.graphml` files that are then analyzed for scripts. You can [build a binary following the wiki instructions](https://github.com/brave/brave-browser/wiki/PageGraph), or you can download one for Intel Macs from the [Release page here](https://github.com/brave-experiments/sugarcoat-pipeline/releases/latest). Remember to unzip it! Alternatively, on the command line:\n\n#### For Mac\n```bash\n# Download the latest Mac Intel zip (and follow redirect)\ncurl -L https://github.com/brave-experiments/sugarcoat-pipeline/releases/latest/download/pagegraph-mac-intel.zip -o pagegraph-mac-intel.zip\nunzip pagegraph-mac-intel.zip\nrm pagegraph-mac-intel.zip\n```\n\n5. (optional) You will need a local copy of a filter list - you can get the latest copy of the easylist filterlist [here](https://easylist.to/easylist/easylist.txt), easyprivacy [here](https://easylist.to/easylist/easyprivacy.txt) or uBlockOrigin Unbreak [here](https://raw.githubusercontent.com/uBlockOrigin/uAssets/master/filters/unbreak.txt). Alternatively, there's copies in the repo. \n\n```bash\ncurl -s https://easylist.to/easylist/easylist.txt -o easylist.txt\ncurl -s https://raw.githubusercontent.com/uBlockOrigin/uAssets/master/filters/unbreak.txt -o unbreak.txt\ncurl -s https://easylist.to/easylist/easyprivacy.txt -o easyprivacy.txt\n```\n\n## Usage\n```bash\nnpm run sugarcoat-pipeline  -- -b <PATH_TO_PAGEGRAPH_BINARY> -u <URL> -t <SECS_TO_RUN_PAGEGRAPH> -l <FILTERLISTS>\n```\nThe filterlists can be space-separated i.e. `-l easylist.txt unbreak.txt`. \n\n### Example:\n\n#### For Mac\n```bash\nnpm run sugarcoat-pipeline  -- -b pagegraph-mac-intel.app/Contents/MacOS/Brave\\ Browser\\ Development   -t 10 -l easylist.txt unbreak.txt easyprivacy.txt -o output -u https://metacritic.com \n```\n(note that on macOS the binary has to be the executable under the `.app`).\n\nNow check `output/` (is auto-generated).\n\n### Help\n```bash\n$ npm run sugarcoat-pipeline  -- -h\n\n> sugarcoat-pipeline@0.1.0 sugarcoat-pipeline\n> node sugarcoat-pipeline.js \"-h\"\n\nusage: sugarcoat-pipeline.js [-h] [-b BINARY] [-u URL] [-t SECS] [-d] -l FILTER_LISTS [FILTER_LISTS ...] [-p POLICY] [-o OUTPUT] [-g GRAPHS_DIR_OVERRIDE] [-k] [-r RETRIES] [-m] [-s]\n\nSugarCoat pipeline CLI\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -b BINARY, --binary BINARY\n                        Path to the PageGraph-enabled build of Brave\n  -u URL, --url URL     The URL to record.\n  -t SECS, --secs SECS  The dwell time in seconds. Default: 30 seconds\n  -d, --debug           Print debugging information\n  -l FILTER_LISTS [FILTER_LISTS ...], --filter-lists FILTER_LISTS [FILTER_LISTS ...]\n                        Filter lists to use\n  -p POLICY, --policy POLICY\n                        Path to policy file. Default: policy.json\n  -o OUTPUT, --output OUTPUT\n                        Path to output directory. All generated files go here. Default: output\n  -g GRAPHS_DIR_OVERRIDE, --graphs-dir-override GRAPHS_DIR_OVERRIDE\n                        Path to graphs directory. If set, skips PageGraph generation\n  -k, --keep            Do not erase intermediary files generated in output for sugarcoat\n  -r RETRIES, --retries RETRIES\n                        Number of times a URL is attempted to be re-crawled on failure. Default: 5\n  -m, --no-minify       Do not minify generated SugarCoat script.\n  -s, --keep-original-script-name\n                        Keep original script name instead of setting it to be hash of contents.\n```\n\n## Feedback\n\nSomething not working? Please [raise an issue](https://github.com/brave-experiments/sugarcoat-pipeline/issues).\n\n## Testing\n\nThis project uses mocha for tests.\n```bash\nnpm run test\n```\n\nTo run in debug mode,\n```bash\nDEBUG=true npm run test\n```\n\nTo run a specific test,\n```bash\nnpm run test -- -g \"simple\"\n```\n\nTo run tests in debug mode:\n```bash\nDEBUG=true npm run test\n```\n", "release_dates": ["2021-06-24T05:47:08Z"]}, {"name": "sugarcoat-resources", "description": null, "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# sugarcoat-resources\n\nGenerated [SugarCoat](https://brave.com/wp-content/uploads/2021/06/sugarcoat-ccs-2021.pdf) resources to be used by the browser as privacy-preserving script replacements. For information on how they're produced, check the [pipeline implementation](https://github.com/brave-experiments/sugarcoat-pipeline/). Resources to include are controlled by [sugarcoat filter list rules](https://github.com/brave/adblock-lists/blob/master/brave-lists/brave-sugarcoat.txt). \n", "release_dates": []}, {"name": "svg-resizer", "description": null, "language": "JavaScript", "license": null, "readme": "# svg-resizer\n\nBasic cli utility to batch resize svg files\n\n# Requirements\n\nSvg-resizer requires `libsvg2` to resize SVG files.\n\nInstall it with `sudo apt-get install librsvg2-bin` on Linux or with `brew install librsvg` on OSX.\n\n# Usage\n\n    $ ./svg-resizer.js -f -x 20 -y 20 -o example/resized/ -i example/*.svg\n\n# Options\n\n- **width** `-x` `--width`\n\n  Output SVG width.\n\n- **height** `-y` `--height`\n\n  Output SVG height.\n\n- **fit** `-f` `--fit`\n\n  Fit to specified dimensions preserving aspect ratio.\n\n- **format** `-e` `--format`\n\n  Output format, but default is `svg` but can be `png`, `pdf`, `ps`, `svg` or `xml`.\n\n- **output** `-o` `--output`\n\n  Destination folder.\n\n- **i** `-i` `--input`\n\n  Input folder or file.\n\n", "release_dates": []}, {"name": "svg2jsx", "description": "\u269b Transform SVG to valid JSX", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# svg2jsx \ud83c\udf13\n> Tiny module for transforming SVG to valid JSX\n\n[![npm version](https://badge.fury.io/js/%40balajmarius%2Fsvg2jsx.svg)](https://badge.fury.io/js/%40balajmarius%2Fsvg-to-jsx)\n\n### Install \u2699\n\n```\nyarn add @balajmarius/svg2jsx --dev\n```\n\n### Test \u26f1\n\n```\nyarn test\n```\n\n### Use \ud83d\udee0\n\n```javascript\nconst fs = require('fs')\nconst path = require('path')\nconst svg2jsx = require('@balajmarius/svg2jsx')\n\nconst filepath = path.resolve(__dirname, 'test.svg')\n\nfs.readFile(filepath, 'utf8', (error, data) => {\n\n  if (error) throw new Error('\ud83d\ude1e Something went wrong')\n\n  return svg2jsx(data)\n    .then(transformedSVG => console.log(transformedSVG))\n    .catch(error => console.log(error))\n\n})\n```\n", "release_dates": []}, {"name": "swap", "description": "Brave Swap monorepo", "language": "TypeScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave Swap\n\n[![npm version](https://badge.fury.io/js/@brave%2Fswap-interface.svg)](https://badge.fury.io/js/@brave%2Fswap-interface)\n![build](https://github.com/brave/swap/actions/workflows/build.yml/badge.svg)\n\nAn open-source swap interface by Brave, focussed on usability and multi-chain\nsupport.\n\n## Project structure\n\n```\n\u251c\u2500\u2500 interface\n\u2502\n\u251c\u2500\u2500 sites\n\u2502   \u251c\u2500\u2500 mock\n\u2502   \u251c\u2500\u2500 bravedotcom\n```\n\nThe project consists of three top-level directories:\n1. `interface` \u2b95 library implementing the UI, and swap hooks.\n2. `sites` \u2b95 full-blown applications that use the `interface` library.\n\n# Development\n\nSince `interface` is a library, it cannot be run as a standalone application.\nWe have therefore created a `sites/mock` application that can be used for local\ndevelopment. Please follow these instructions to setup a development environment\nwith hot reloading. \n\n```shell\n$ cd swap/interface\n$ npm install\n$ npm run dev\n```\n\nIn another tab:\n```shell\n$ cd swap/sites/mock\n$ npm install\n$ npm start\n```\n", "release_dates": ["2023-05-12T17:50:58Z", "2023-05-12T04:46:05Z", "2023-02-26T07:26:08Z", "2023-02-21T15:41:08Z", "2023-02-21T12:00:27Z", "2023-02-15T17:36:24Z", "2023-02-07T06:30:25Z", "2023-01-13T17:08:01Z", "2022-11-30T16:50:34Z", "2022-11-30T06:52:08Z", "2022-11-25T16:58:56Z", "2022-11-22T03:04:04Z", "2022-11-21T17:05:27Z", "2022-11-17T18:21:17Z", "2022-11-09T08:47:15Z", "2022-11-03T18:59:42Z", "2022-11-03T11:46:52Z", "2022-11-02T10:34:27Z", "2022-10-27T09:08:51Z", "2022-10-20T15:53:57Z", "2022-10-19T19:16:12Z", "2022-10-18T16:11:51Z", "2022-10-14T13:52:34Z", "2022-10-13T20:39:53Z", "2022-10-13T17:47:33Z", "2022-10-12T16:21:51Z", "2022-10-12T15:15:05Z", "2022-10-11T17:41:20Z", "2022-10-10T17:32:14Z", "2022-10-07T09:37:16Z"]}, {"name": "sync", "description": "deprecated Brave sync server. (sync now uses a fork of the Chromium sync protocol.)", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave Sync\n\n[![Build\nStatus](https://travis-ci.org/brave/sync.svg?branch=master)](https://travis-ci.org/brave/sync)\n\nA client/server for Brave sync\n\n## Building\n\nInstall dependencies:\n\n```\nnpm install\n```\n\nBuild a bundled JS library for the client:\n\n```\nnpm run build\n```\n\nRun the server:\n\n```sh\nnpm run start\n```\n\n## Testing\n\nThe sync client uses Browserify to transform Node js into browser js. To unittest\nthe library in a browser (default: electron), run `npm run browsertest`.\nTo test in a different browser run `npm run browsertest -- --browser chrome`.\nResults appear in both the browser inspector and your terminal.\n\nTo run tests in Node, just do `npm test`.\n\nTo do a basic client/server integration test against the production server, run\n`npm run client` and navigate to `http://localhost:8000/`). The page\nshould not show any 'ERROR' messages and should end with 'success'.\n\n## Development\n\n### Server\n\n`server/config` contains settings; defaults in defaults.json and environment variable mappings in custom-environment-variables.json.\n\nTo configure locally you can create a file `config-dev.sh` and `source config-dev.sh` when needed:\n\n```sh\n#!/bin/bash\nexport AWS_ACCESS_KEY_ID=\"{stuff}\"\nexport AWS_SECRET_ACCESS_KEY=\"{secret stuff}\"\n```\n\nRun the server with file watching and autoreloading:\n```sh\nnpm run start-dev\n```\n\n### Client integration\n\nTo integrate Brave sync on a platform (iOS, Android, Laptop):\n\n1. Make a new branch.\n2. In the main browser process, implement an IPC message handler as specified\n   in `client/constants/messages.js`.\n3. If webviews on your platform do not support `chrome.ipcRenderer.{send, on}`,\n   edit `client/polyfill/chrome.js` as needed to polyfill this functionality.\n\n#### Building for browser-laptop\n\n1. Make sure this repo is checked out next to `browser-laptop/`\n2. Checkout the `feature/syncing` branch in browser-laptop\n3. `npm run dist`\n4. If developing, do `npm start` in browser-laptop. Console messages from the\n   sync client will be logged in `Library/Application\n   Support/brave-development/chrome-debug.log`.\n\n### Tests\n\nTo run tests you need to configure these environment variables:\n\n- AWS_REGION\n- AWS_S3_BUCKET\n- AWS_ACCESS_KEY_ID\n- AWS_SECRET_ACCESS_KEY\n", "release_dates": ["2017-10-09T04:02:05Z", "2017-10-06T00:56:43Z", "2017-10-06T00:41:27Z", "2017-07-18T18:05:08Z", "2017-07-11T06:18:37Z", "2017-07-06T16:42:17Z", "2017-06-29T23:53:51Z", "2017-06-08T00:19:42Z", "2017-06-02T23:10:13Z", "2017-05-12T00:54:28Z", "2017-04-27T07:39:16Z", "2017-04-19T21:59:30Z", "2017-04-10T23:52:22Z", "2017-04-06T00:28:51Z", "2017-04-04T02:19:51Z", "2017-03-15T00:27:03Z", "2017-03-07T23:00:42Z", "2017-02-22T00:20:34Z", "2017-02-18T02:54:29Z", "2017-02-14T23:02:36Z", "2017-02-14T23:19:50Z", "2017-02-13T23:54:44Z", "2017-02-09T06:02:47Z", "2017-02-02T07:20:46Z", "2017-01-27T02:09:12Z", "2017-01-24T21:32:44Z", "2017-01-19T23:34:19Z", "2017-01-19T00:13:34Z", "2017-01-17T18:51:41Z", "2017-01-15T07:41:52Z"]}, {"name": "token-lists", "description": "Manages custom token lists for Brave Wallet", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# token-lists\n\n[![Build](https://github.com/brave/token-lists/actions/workflows/build.yml/badge.svg)](https://github.com/brave/token-lists/actions/workflows/build.yml) [![npm version](https://badge.fury.io/js/brave-wallet-lists.svg)](https://badge.fury.io/js/brave-wallet-lists)\n\nManages custom token lists for Brave Wallet\n\n## Automated Publishing\n\nWe have setup a **weekly** cron job on [Jenkins](https://github.com/brave/devops/blob/master/jenkins/jobs/extensions/brave-core-ext-wallet-data-files-update-publish.yml) that publishes the latest NPM package to wallet data files.\n\n## Development\n\n### Ubuntu\n\n- Install system dependencies.\n\n  ```bash\n  sudo apt install librsvg2-bin libimagequant-dev pkg-config\n  ```\n\n- Ensure you have the required node version and `yarn` installed.\n\n- Install dependencies and run the build script.\n\n  ```bash\n  yarn\n  yarn start\n  ```\n\n### MacOS\n\n- Install system dependencies.\n\n  ```bash\n  brew install librsvg libimagequant pkg-config\n  ```\n\n- Ensure you have the required node version and `yarn` installed.\n\n- Install dependencies and run the build script.\n\n  ```bash\n  yarn\n  yarn start\n  ```\n\n### Docker\n\n- Install [docker](https://runnable.com/docker/)\n- Create a docker image `docker build -t token-lists .`\n- Launch the docker image `docker run -u \"$(id -u):$(id -g)\" -v \"$PWD/build:/token-lists/build\" -ti token-lists`\n- You will see an output in the `build` folder\n\n## Publishing token list to npm\n\n[brave/brave-core-crx-packager](https://github.com/brave/brave-core-crx-packager) uses the npm package published [here brave-wallet-lists](https://www.npmjs.com/package/brave-wallet-lists). It will be automatically published when your\nPR is merged and a new release is created.\n\nThis produces a zero-dependency package with output images and token lists.\n\n## Testing a deployment\n\nTo test wallet data files use the development component updater with a fresh profile.\n\nTo do this you can use the command line argument `--use-dev-goupdater-url`.\n\nYou can use a clean profile without clearing with this as well: `--user-data-dir=<tmp-dir>`.\n\nIf you're using a development build, you can set the dev server via this npmrc environment in `~/.npmrc`:\n\n`updater_dev_endpoint=https://go-updater-dev.bravesoftware.com/extensions`\n\nYou can test a deployment by running the Jenkins job named:\n`brave-core-ext-wallet-data-files-update-publish-dev`\nPlease check to make sure it succeeds.\n\nWait 5-10 minutes as the server will purge its cache during that timeframe and start serving the new component.\n\nThen startup Brave using:\n`open -a Brave\\ Browser\\ Beta.app --args --use-dev-goupdater-url --user-data-dir=$(mktemp -d)`\n\nAfter things are tested you can run the Jenkins job: `brave-core-ext-wallet-data-files-update-publish` and then after success, test on your normal Brave profile.\nThe change will be live within 5-10 minutes. Please also test on production.\n\nAfter testing on production, gives sign off in Slack on `#releases` and `#prod-changes`.\n\n## Troubleshooting deployment\n\nYou can see a list of the components that the component updater serves by going to these URLs:\n\n- Prod: https://go-updater.brave.com/extensions/test\n- Dev: https://go-updater-dev.bravesoftware.com/extensions/test\n\n", "release_dates": ["2024-02-07T13:57:35Z", "2024-02-01T09:55:56Z", "2024-01-10T14:13:22Z", "2023-12-22T13:54:59Z", "2023-12-14T08:28:41Z", "2023-12-13T19:57:59Z", "2023-11-02T19:55:38Z", "2023-10-19T15:41:40Z", "2023-10-12T11:30:53Z", "2023-09-19T08:33:44Z", "2023-08-14T17:22:05Z", "2023-08-07T11:30:43Z", "2023-08-04T15:48:59Z", "2023-07-26T13:57:49Z", "2023-07-25T19:16:38Z", "2023-06-20T19:14:31Z", "2023-06-16T16:53:07Z", "2023-06-15T18:58:56Z", "2023-05-17T05:18:44Z", "2023-05-10T16:10:05Z", "2023-04-21T08:44:00Z", "2023-03-23T12:51:22Z", "2023-03-20T06:38:38Z", "2023-03-17T14:48:03Z", "2023-02-17T15:46:53Z", "2023-02-10T15:40:30Z", "2023-02-08T18:07:33Z", "2022-12-05T15:55:25Z", "2022-12-05T13:56:53Z", "2022-11-16T17:10:27Z"]}, {"name": "tokenizer", "description": "A modular resource tokenization service.", "language": "Go", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Tokenizer\n\nTokenizer receives sensitive input from somewhere, tokenizes it, and sends the\noutput somewhere else.  This summary is deliberately vague because tokenizer's\ninput, output, and tokenization are pluggable: Input can come from an HTTP API\nor stdin.  Tokenization can be done by a\n[HMAC-SHA256](https://en.wikipedia.org/wiki/HMAC)\nor\n[CryptoPAn](https://en.wikipedia.org/wiki/Crypto-PAn).\nThe output can be a Kafka broker or stdout.  Tokenizer further supports\npluggable aggregation, which dictates how input is processed.\n\n# Development\n\nTo test, lint, and build `tkzr`, run:\n\n    make\n\nTo create a reproducible Docker image, run:\n\n    make docker\n\nTo understand tokenizer's architecture, begin by studying its\n[interfaces](interfaces.go).\n\n# Usage\n\nRun the following command to compile `tkzr`.\n\n    make tkzr\n\nUse the following command to run tokenizer with the given receiver, forwarder,\nand tokenizer:\n\n    tkzr -receiver stdin -tokenizer hmac -forwarder stdout\n", "release_dates": []}, {"name": "torrent-discovery", "description": "Discover BitTorrent and WebTorrent peers", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# torrent-discovery [![travis][travis-image]][travis-url] [![npm][npm-image]][npm-url] [![downloads][downloads-image]][downloads-url] [![javascript style guide][standard-image]][standard-url]\n\n[travis-image]: https://img.shields.io/travis/webtorrent/torrent-discovery/master.svg\n[travis-url]: https://travis-ci.org/webtorrent/torrent-discovery\n[npm-image]: https://img.shields.io/npm/v/torrent-discovery.svg\n[npm-url]: https://npmjs.org/package/torrent-discovery\n[downloads-image]: https://img.shields.io/npm/dm/torrent-discovery.svg\n[downloads-url]: https://npmjs.org/package/torrent-discovery\n[standard-image]: https://img.shields.io/badge/code_style-standard-brightgreen.svg\n[standard-url]: https://standardjs.com\n\n### Discover BitTorrent and WebTorrent peers\n\nThis module bundles [bittorrent-dht](https://www.npmjs.com/package/bittorrent-dht) and\n[bittorrent-tracker](https://www.npmjs.com/package/bittorrent-tracker) clients and exposes a\nsingle API for discovering BitTorrent peers via both discovery methods.\n\n## features\n\n- simple API\n- find peers from trackers and the DHT\n- automatically announces, so other peers can discover us\n- can start finding peers with just an info hash, before full metadata is available\n\nThis module also **works in the browser** with [browserify](http://browserify.org). In\nthat context, it discovers [WebTorrent](http://webtorrent.io) (WebRTC) peers.\n\n## install\n\n```\nnpm install torrent-discovery\n```\n\n## api\n\n### `discovery = new Discovery(opts)`\n\nCreate a new peer discovery instance. Required options are:\n\n```js\n{\n  infoHash: '', // as hex string or Buffer\n  peerId: '',   // as hex string or Buffer\n  port: 0       // torrent client port (only required in node)\n}\n```\n\nOptional options are:\n\n```js\n{\n  announce: [],  // force list of announce urls to use (from magnet uri)\n  dht: true,     // use dht? optionally, this can be an `opts` object, or a DHT instance to use (can be reused for multiple torrents)\n  dhtPort: 0,    // custom listen port for the DHT instance (not used if DHT instance is given via `opts.dht`)\n  userAgent: '', // User-Agent header for http requests\n  tracker: true, // use trackers? optionally, this can be an `opts` object\n}\n```\n\nSee the documentation for [bittorrent-dht](https://www.npmjs.com/package/bittorrent-dht) and\n[bittorrent-tracker](https://www.npmjs.com/package/bittorrent-tracker) for information on what\noptions are available via the `opts` object.\n\n**This module automatically handles announcing on intervals, for maximum peer discovery.**\n\n### `discovery.updatePort(port)`\n\nWhen the port that the torrent client is listening on changes, call this method to\nreannounce to the tracker and DHT with the new port.\n\n### `discovery.complete([opts])`\n\nAnnounce that download has completed (and the client is now a seeder). This is only\nused by trackers, for statistical purposes. If trackers are not in use, then\nthis method is a no-op.\n\nOptional `opts` object with the following options:\n\n```\n{number=} opts.uploaded\n{number=} opts.downloaded\n{number=} opts.numwant\n{number=} opts.left (if not set, calculated automatically)\n```\n\n### `discovery.destroy()`\n\nDestroy and cleanup the DHT and tracker instances.\n\n### events\n\n### `discovery.on('peer', (peer, source) => {})`\n\nEmitted whenever a new peer is discovered. Source is either 'tracker' or 'dht' based on peer source.\n\n**In node**, `peer` is a string in the form `ip:port`, e.g. `12.34.56.78:4000`.\n\n**In the browser**, `peer` is an instance of\n[`simple-peer`](https://www.npmjs.com/package/simple-peer), a small wrapper around a WebRTC\npeer connection.\n\n### `discovery.on('dhtAnnounce', () => {})`\n\nEmitted whenever an `announce` message has been sent to the DHT.\n\n### `discovery.on('warning', err => {})`\n\nEmitted when there is a non-fatal DHT or tracker error, like an inaccessible tracker\nserver. Useful for logging. This is non-fatal.\n\n### `discovery.on('error', err => {})`\n\nEmitted when there is a fatal, unrecoverable DHT or tracker error.\n\n## license\n\nMIT. Copyright (c) [Feross Aboukhadijeh](https://feross.org) and [WebTorrent, LLC](https://webtorrent.io).\n", "release_dates": []}, {"name": "tor_build_scripts", "description": "Build scripts for tor binary", "language": "Shell", "license": null, "readme": "# Build scripts for tor binary\n\n### GPG keys\n\nGPG keyservers are known to be flaky so we include the keys in the repo:\n\n1. Tor:\n\nGenerating `tor.gpg`:\n```\n$ rm -f gpg-keys/tor.gpg\n$ touch gpg-keys/tor.gpg\n$ gpg --no-default-keyring --keyring gpg-keys/tor.gpg --keyserver hkps://keys.openpgp.org --recv-keys 514102454D0A87DB0767A1EBBE6A0531C18A9179\n$ gpg --no-default-keyring --keyring gpg-keys/tor.gpg --keyserver hkps://keys.openpgp.org --recv-keys B74417EDDF22AC9F9E90F49142E86A2A11F48D36\n$ gpg --no-default-keyring --keyring gpg-keys/tor.gpg --keyserver hkps://keys.openpgp.org --recv-keys 2133BC600AB133E1D826D173FE43009C4607B1FB\n```\n\nThe fingerprints should match those listed on https://support.torproject.org/little-t-tor/verify-little-t-tor/.\n\n2. Libevent:\n\nGenerating `libevent.gpg`:\n```\n$ gpg --keyserver hkps://keyserver.ubuntu.com:443 --recv-keys 9E3AC83A27974B84D1B3401DB86086848EF8686D\n$ gpg --output gpg-keys/libevent.gpg --export 9E3AC83A27974B84D1B3401DB86086848EF8686D\n```\n\n```\n$ gpg --fingerprint 9E3AC83A27974B84D1B3401DB86086848EF8686D\npub   rsa2048 2010-06-10 [SC]\n      9E3A C83A 2797 4B84 D1B3  401D B860 8684 8EF8 686D\nuid           [ unknown] Azat Khuzhin <a3at.mail@gmail.com>\nuid           [ unknown] Azat Khuzhin <bin@azat.sh>\nuid           [ unknown] Azat Khuzhin <azat@libevent.org>\nsub   rsa2048 2010-06-10 [E]\n```\n\n3. OpenSSL\n\nGenerating `openssl.gpg`:\n```\n$ gpg --no-default-keyring --keyring gpg-keys/openssl.gpg --recv-key 8657ABB260F056B1E5190839D9C4D26D0E604491\n$ gpg --no-default-keyring --keyring gpg-keys/openssl.gpg --recv-key B7C1C14360F353A36862E4D5231C84CDDCC69C45\n$ gpg --keyserver hkps://keyserver.ubuntu.com --no-default-keyring --keyring gpg-keys/openssl.gpg --recv-key 5B2545DAB21995F4088CEFAA36CEE4DEB00CFE33\n$ gpg --keyserver hkps://keyserver.ubuntu.com --no-default-keyring --keyring gpg-keys/openssl.gpg --recv-key C1F33DD8CE1D4CC613AF14DA9195C48241FBF7DD\n$ gpg --keyserver hkps://keyserver.ubuntu.com --no-default-keyring --keyring gpg-keys/openssl.gpg --recv-key 7953AC1FBC3DC8B3B292393ED5E9E43F7DF9EE8C\n$ gpg --keyserver hkps://keyserver.ubuntu.com --no-default-keyring --keyring gpg-keys/openssl.gpg --recv-key E5E52560DD91C556DDBDA5D02064C53641C25E5D\n$ gpg --keyserver hkps://keyserver.ubuntu.com --no-default-keyring --keyring gpg-keys/openssl.gpg --recv-key DC7032662AF885E2F47F243F527466A21CA79E6D\n$ gpg --keyserver hkps://keys.openpgp.org --no-default-keyring --keyring gpg-keys/openssl.gpg --recv-key EFC0A467D613CB83C7ED6D30D894E2CE8B3D79F5\n```\n\nThe keys are listed on https://www.openssl.org/community/omc.html.\n\n### Generating binaries\n\n1. Increment the Brave version number for each published build.\n2. Run `source env.sh` to set the correct environment variables.\n3. Run `build_<os>.sh` to generate the binary. \n4. Confirm all signature and hash checks passed.\n\nThe generated binary is of the form `tor-<tor-version>-<os>-brave-<brave-version>`\n\n### Updates:\n\nIn case of updates for `tor` | `libevent` | `zlib` | `openssl`\n\n1. Increment the brave version number in env.sh if needed.\n2. Update the upstream distfile version in env.sh.\n3. Attempt a build.  It should fail.\n4. Confirm that the _signature_ passes and the _hash_ fails.\n5. Confirm the upstream distribution is plausible.\n   - Confirm a README or NEWS or ChangeLog says the right version.\n     (Otherwise we are subject to version rollback attacks.)\n6. Update the hash in env.sh.\n7. Attempt a build.  It should pass.\n8. Prepare a PR for your branch.\n9. To test building on other platforms, build the *brave-tor-client-build* project in Jenkins using your branch instead of `master` (the \"Upload\" build option must be ON). The build output will give you URLs on S3 of all of the generated binaries (one per platform).\n10. Download each binary and run `sha512sum` on them. Make sure you use the **post-signing** Windows binary since both signed and unsigned will be in the output.\n11. Merge your `brave/tor_build_scripts` PR once it's been reviewed.\n12. Prepare a PR for the `brave/brave-core-crx-packager` repo bumping the version numbers and hashes (e.g. brave/brave-core-crx-packager#390).\n13. Build a new version of the component on **dev** by building the *brave-core-ext-tor-client-update-publish-dev* project in Jenkins using your branch (in the `brave/brave-core-crx-packager` repo) instead of `master`.\n14. Once the build has finished, check that the correct version of the tor daemon is downloaded when running `brave-browser --use-dev-goupdater-url` (check the terminal log messages).\n15. Ask QA to create a milestone like https://github.com/brave/brave-browser/milestone/281 and do a manual test pass on each platform with the dev builds.\n16. Merge the `brave/brave-core-crx-packager` PR once it's been reviewed and QA has approved.\n17. Build a new version of the component on **prod** by building the *brave-core-ext-tor-client-update-publish* project in Jenkins using the `master` branch.\n18. Update to the latest version of the *Brave Tor Client Updater* component in your browser by triggering an update in `brave://components` and test that https://brave4u7jddbv7cyviptqjc7jusxh72uik7zt6adtckl5f4nwy2v72qd.onion/index.html loads fine.\n19. Ask QA to repeat this test on all platforms.\n", "release_dates": []}, {"name": "tracking-protection", "description": "Tracking protection engine used in the Brave browser for list like disconnectme.", "language": "C++", "license": null, "readme": "# tracking-protection\n\nC++ tracking protection filter parser for lists like\nhttps://github.com/disconnectme/disconnect-tracking-protection/blob/master/services.json\n\n## Setup\n\n```\nnpm install --save tracking-protection\n```\n\n## Installation\n\n1. Clone the git repository from GitHub:\n\n        git clone https://github.com/SergeyZhukovsky/tracking-protection\n\n2. Open the working directory:\n\n        cd tracking-protection\n\n3. Install the Node (v5+) dependencies:\n\n        npm install\n\n## Sample\n\n```c++\n#include <iostream>\n#include \"./TPParser.h\"\n\nusing std::cout;\nusing std::endl;\n\nint main(int argc, char **argv) {\n    CTPParser parser;\n    parser.addTracker(\"facebook.com\");\n    parser.addTracker(\"facebook.de\");\n\n    // Prints matches\n    if (parser.matchesTracker(\"facebook.com\")) {\n        cout << \"matches\" << endl;\n    }\n    else {\n        cout << \"does not match\" << endl;\n    }\n\n    // Prints does not match\n    if (parser.matchesTracker(\"facebook1.com\")) {\n        cout << \"matches\" << endl;\n    } else {\n        cout << \"does not match\" << endl;\n    }\n\n    // Prints does not match\n    if (parser.matchesTracker(\"subdomain.google-analytics.com.\")) {\n        cout << \"matches\" << endl;\n    } else {\n        cout << \"does not match\" << endl;\n    }\n\n    parser.addFirstPartyHosts(\"facebook.com\", \"facebook.fr,facebook.de\");\n    parser.addFirstPartyHosts(\"google.com\", \"2mdn.net,admeld.com\");\n    parser.addFirstPartyHosts(\"subdomain.google.com\", \"facebook.fr,facebook.de\");\n\n    // Returns combined result of third party hosts for \"google.com\" and for \"subdomain.google.com\"\n    // \"facebook.fr,facebook.de,2mdn.net,admeld.com\"\n    char* thirdPartyHosts = parser.findFirstPartyHosts(\"subdomain.google.com\");\n    if (nullptr != thirdPartyHosts) {\n        cout << thirdPartyHosts << endl;\n        delete []thirdPartyHosts;\n    }\n\n    unsigned int totalSize = 0;\n    // Serialize data\n    char* data = parser.serialize(&totalSize);\n\n    // Deserialize data\n    parser.deserialize(data);\n\n    // Prints matches\n    if (parser.matchesTracker(\"facebook.com\")) {\n        cout << \"matches\" << endl;\n    }\n    else {\n        cout << \"does not match\" << endl;\n    }\n    // Prints does not match\n    if (parser.matchesTracker(\"facebook1.com\")) {\n        cout << \"matches\" << endl;\n    } else {\n        cout << \"does not match\" << endl;\n    }\n\n    // Prints \"2mdn.net,admeld.com\"\n    thirdPartyHosts = parser.findFirstPartyHosts(\"google.com\");\n    if (nullptr != thirdPartyHosts) {\n        cout << thirdPartyHosts << endl;\n    }\n\n    if (data) {\n        delete []data;\n    }\n\n    return 0;\n}\n```\n\n## Build everything in release\n\n```\nmake\n```\n\n## Build everything in debug\n\n```\nmake build-debug\n```\n\n## Running sample\n\n```\nmake sample\n```\n\n## Running tests\n\n```\nmake test\n```\n\n## Clearing build files\n```\nmake clean\n```\n", "release_dates": []}, {"name": "transparency-report-generator", "description": null, "language": "TypeScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Generator Script for Transparency Report Data\n\nThis repository contains the scripts used to build Brave's *Transparency Report Data* which drives pages like [brave.com/transparency](https://brave.com/transparency/) and [basicattentiontoken.org/growth](https://basicattentiontoken.org/growth/).\n\n## Setup\n\nClone and `npm install` to get started.\n\nSeveral *environment variables* will be required for a successful run:\n\n- `COINBASE_API_KEY`\n- `COINBASE_API_SECRET`\n- `COINBASE_API_PASSPHRASE`\n- `GEMINI_API_KEY`\n- `GEMINI_API_SECRET`\n- `ADS_SERVER_STATS_CREDENTIAL`\n\n## Building and Testing\n\nWith the environment variables in place, and having already ran `npm install`, you can now run `npm run build` or `npm run test` to build and/or test, respectively. Running the *build* script will attempt to generate (or overwrite) a local `transparency.json` file. Running the *test* script will run the same script with *verbose logging* enabled, but will make no attempt to save the resulting file.\n\n## Data Sources and Services\n\nThis project pulls data from various services and providers:\n\nProvider | API Key Required | Explanation of Use\n-----------------|:---------------:|---------------\n[Coinbase](https://docs.cloud.coinbase.com/exchange/reference) | \u2714 | Querying for previous BAT purchases\n[Gemini](https://docs.gemini.com/rest-api/) | \u2714 | Querying for previous BAT purchases\n[Uphold](https://uphold.com/en/developer/api/documentation/#introduction) | \u2716 | Querying for previous BAT purchase details\n[bravebat.info](https://bravebat.info/docs/index.html) | \u2716 | Community growth metrics\n[Ethplorer](https://github.com/EverexIO/Ethplorer/wiki/Ethplorer-API) | \u2714* | Querying for BAT info and metrics\n[CryptoCompare](https://min-api.cryptocompare.com/documentation) | \u2716 | Querying for historical BAT value data\nBrave | \u2714 | Querying for Ads data and Rewards metrics\n\n<sup>\\* Ethplorer offers a [\"freekey\"](https://github.com/EverexIO/Ethplorer/wiki/Ethplorer-API#api-key-limits) API key for low-traffic, infrequent pings.</sup>\n\n", "release_dates": []}, {"name": "ua-parser-js", "description": "UAParser.js - JavaScript library to identify browser, engine, OS, CPU, and device type/model from userAgent string. Supports browser & node.js environment. Also available as jQuery/Zepto plugin, Bower/Meteor package, RequireJS/AMD module, & CLI tool.", "language": "JavaScript", "license": null, "readme": "# UAParser.js\n\n<img align=\"right\" src=\"https://raw.githubusercontent.com/faisalman/ua-parser-js/gh-pages/images/logo.png\"> A JavaScript-based User-Agent string parser. Can be used either in browser (client-side) or in node.js (server-side) environment. Also available as jQuery/Zepto plugin, Bower/Meteor package, & RequireJS/AMD module. This library aims to identify detailed type of web browser, layout engine, operating system, cpu architecture, and device type/model, entirely from user-agent string with a relatively small footprint (~17KB when minified / ~6KB gzipped). Written in vanilla JavaScript, which means it doesn't require any other library and can be used independently. However, it's not recommended to use this library as browser detection since the result may not be more accurate than using feature detection.\n\n[![Build Status](https://travis-ci.org/faisalman/ua-parser-js.svg?branch=master)](https://travis-ci.org/faisalman/ua-parser-js)\n[![NPM downloads](https://img.shields.io/npm/dw/ua-parser-js.svg)](https://www.npmjs.com/package/ua-parser-js)\n[![NPM](https://img.shields.io/npm/v/ua-parser-js.svg)](https://www.npmjs.com/package/ua-parser-js)\n[![Bower](https://img.shields.io/bower/v/ua-parser-js.svg)](https://bower.io/)\n[![CDNJS](https://img.shields.io/cdnjs/v/UAParser.js.svg)](https://cdnjs.com/libraries/UAParser.js)\n\n* Author    : Faisal Salman <<f@faisalman.com>>\n* Demo      : http://faisalman.github.io/ua-parser-js\n* Source    : https://github.com/faisalman/ua-parser-js\n\n# Constructor\n\n* `new UAParser([uastring][,extensions])`\n    * returns new instance\n\n* `UAParser([uastring][,extensions])`\n    * returns result object `{ ua: '', browser: {}, cpu: {}, device: {}, engine: {}, os: {} }`\n\n# Methods\n\n* `getBrowser()`\n    * returns `{ name: '', version: '' }`\n\n```\n# Possible 'browser.name':\n2345Explorer, Amaya, Android Browser, Arora, Avant, BIDUBrowser, Baidu,\nBasilisk, Blazer, Bolt, Bowser, Camino, Chimera, Chrome Headless,\nChrome WebView, Chrome, Chromium, Comodo Dragon, Dillo, Dolphin, Doris, Edge,\nEpiphany, Facebook, Fennec, Firebird, Firefox, Flock, GSA, GoBrowser,\nICE Browser, IE, IEMobile, IceApe, IceCat, IceDragon, Iceape, Iceweasel,\nIridium, Iron, Jasmine, K-Meleon, Kindle, Konqueror, LBBROWSER Line, Links,\nLunascape, Lynx, MIUI Browser, Maemo Browser, Maemo, Maxthon, MetaSr Midori,\nMinimo, Mobile Safari, Mosaic, Mozilla, NetFront, NetSurf, Netfront, Netscape,\nNokiaBrowser, Oculus Browser, OmniWeb, Opera Coast, Opera Mini, Opera Mobi,\nOpera Tablet, Opera, PaleMoon, PhantomJS, Phoenix, Polaris, Puffin, QQ,\nQQBrowser, QQBrowserLite, Quark, RockMelt, Safari, Samsung Browser, SeaMonkey,\nSilk, Skyfire, Sleipnir, Slim, SlimBrowser, Swiftfox, Tizen Browser, UCBrowser,\nVivaldi, Waterfox, WeChat, Yandex, baidu, iCab, w3m\n\n# 'browser.version' determined dynamically\n```\n\n* `getDevice()`\n    * returns `{ model: '', type: '', vendor: '' }` \n\n```\n# Possible 'device.type':\nconsole, mobile, tablet, smarttv, wearable, embedded\n\n# Possible 'device.vendor':\nAcer, Alcatel, Amazon, Apple, Archos, Asus, BenQ, BlackBerry, Dell, GeeksPhone, \nGoogle, HP, HTC, Huawei, Jolla, Lenovo, LG, Meizu, Microsoft, Motorola, Nexian, \nNintendo, Nokia, Nvidia, OnePlus, Ouya, Palm, Panasonic, Pebble, Polytron, RIM, \nSamsung, Sharp, Siemens, Sony[Ericsson], Sprint, Xbox, Xiaomi, ZTE\n\n# 'device.model' determined dynamically\n```\n\n* `getEngine()`\n    * returns `{ name: '', version: '' }`\n\n```\n# Possible 'engine.name'\nAmaya, EdgeHTML, Gecko, iCab, KHTML, Links, Lynx, NetFront, NetSurf, Presto, \nTasman, Trident, w3m, WebKit\n\n# 'engine.version' determined dynamically\n```\n\n* `getOS()`\n    * returns `{ name: '', version: '' }`\n\n```\n# Possible 'os.name'\nAIX, Amiga OS, Android, Arch, Bada, BeOS, BlackBerry, CentOS, Chromium OS, Contiki,\nFedora, Firefox OS, FreeBSD, Debian, DragonFly, Gentoo, GNU, Haiku, Hurd, iOS, \nJoli, Linpus, Linux, Mac OS, Mageia, Mandriva, MeeGo, Minix, Mint, Morph OS, NetBSD, \nNintendo, OpenBSD, OpenVMS, OS/2, Palm, PC-BSD, PCLinuxOS, Plan9, Playstation, QNX, RedHat, \nRIM Tablet OS, RISC OS, Sailfish, Series40, Slackware, Solaris, SUSE, Symbian, Tizen, \nUbuntu, Unix, VectorLinux, WebOS, Windows [Phone/Mobile], Zenwalk\n\n# 'os.version' determined dynamically\n```\n\n* `getCPU()`\n    * returns `{ architecture: '' }`\n\n```\n# Possible 'cpu.architecture'\n68k, amd64, arm[64], avr, ia[32/64], irix[64], mips[64], pa-risc, ppc, sparc[64]\n```\n\n* `getResult()`\n    * returns `{ ua: '', browser: {}, cpu: {}, device: {}, engine: {}, os: {} }`\n\n* `getUA()`\n    * returns UA string of current instance\n\n* `setUA(uastring)`\n    * set UA string to parse\n    * returns current instance\n\n\n# Example\n\n```html\n<!doctype html>\n<html>\n<head>\n<script type=\"text/javascript\" src=\"ua-parser.min.js\"></script>\n<script type=\"text/javascript\">\n\n\tvar parser = new UAParser();\n\n    // by default it takes ua string from current browser's window.navigator.userAgent\n    console.log(parser.getResult());\n    /*\n        /// this will print an object structured like this:\n        {\n            ua: \"\",\n            browser: {\n                name: \"\",\n                version: \"\"\n            },\n            engine: {\n                name: \"\",\n                version: \"\"\n            },\n            os: {\n                name: \"\",\n                version: \"\"\n            },\n            device: {\n                model: \"\",\n                type: \"\",\n                vendor: \"\"\n            },\n            cpu: {\n                architecture: \"\"\n            }\n        }\n    */\n\n    // let's test a custom user-agent string as an example\n    var uastring = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.2 (KHTML, like Gecko) Ubuntu/11.10 Chromium/15.0.874.106 Chrome/15.0.874.106 Safari/535.2\";\n    parser.setUA(uastring);\n\n    var result = parser.getResult();\n    // this will also produce the same result (without instantiation):\n    // var result = UAParser(uastring);\n\n    console.log(result.browser);        // {name: \"Chromium\", version: \"15.0.874.106\"}\n    console.log(result.device);         // {model: undefined, type: undefined, vendor: undefined}\n    console.log(result.os);             // {name: \"Ubuntu\", version: \"11.10\"}\n    console.log(result.os.version);     // \"11.10\"\n    console.log(result.engine.name);    // \"WebKit\"\n    console.log(result.cpu.architecture);   // \"amd64\"\n\n    // do some other tests\n    var uastring2 = \"Mozilla/5.0 (compatible; Konqueror/4.1; OpenBSD) KHTML/4.1.4 (like Gecko)\";\n    console.log(parser.setUA(uastring2).getBrowser().name); // \"Konqueror\"\n    console.log(parser.getOS());                            // {name: \"OpenBSD\", version: undefined}\n    console.log(parser.getEngine());                        // {name: \"KHTML\", version: \"4.1.4\"}\n\n    var uastring3 = 'Mozilla/5.0 (PlayBook; U; RIM Tablet OS 1.0.0; en-US) AppleWebKit/534.11 (KHTML, like Gecko) Version/7.1.0.7 Safari/534.11';\n    console.log(parser.setUA(uastring3).getDevice().model); // \"PlayBook\"\n    console.log(parser.getOS())                             // {name: \"RIM Tablet OS\", version: \"1.0.0\"}\n    console.log(parser.getBrowser().name);                  // \"Safari\"\n\n</script>\n</head>\n<body>\n</body>\n</html>\n```\n\n## Using node.js\n\n```sh\n$ npm install ua-parser-js\n```\n\n```js\nvar http = require('http');\nvar parser = require('ua-parser-js');\n\nhttp.createServer(function (req, res) {\n    // get user-agent header\n    var ua = parser(req.headers['user-agent']);\n    // write the result as response\n    res.end(JSON.stringify(ua, null, '  '));\n})\n.listen(1337, '127.0.0.1');\n\nconsole.log('Server running at http://127.0.0.1:1337/');\n```\n\n## Using requirejs\n\n```js\nrequirejs.config({\n    baseUrl : 'js/lib', // path to your script directory\n    paths   : {\n        'ua-parser-js' : 'ua-parser.min'\n    }\n});\n\nrequirejs(['ua-parser-js'], function(UAParser) {\n    var parser = new UAParser();\n    console.log(parser.getResult());\n});\n```\n\n## Using CDN\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/ua-parser-js@0/dist/ua-parser.min.js\"></script>\n```\n\n## Using bower\n\n```sh\n$ bower install ua-parser-js\n```\n\n## Using meteor\n\n```sh\n$ meteor add faisalman:ua-parser-js\n```\n\n## Using CLI\n\n```sh\n$ node ua-parser.min.js \"Mozilla/4.0 (compatible; MSIE 4.01; Windows 98)\"\n# multiple args\n$ node ua-parser.min.js \"Opera/1.2\" \"Opera/3.4\"\n# piped args\n$ echo \"Opera/1.2\" | node ua-parser.min.js\n# log file\n$ cat ua.log | node ua-parser.min.js\n```\n\n## Using jQuery/Zepto ($.ua)\n\nAlthough written in vanilla js (which means it doesn't depends on jQuery), this library will automatically detect if jQuery/Zepto is present and create `$.ua` object based on browser's user-agent (although in case you need, `window.UAParser` constructor is still present). To get/set user-agent you can use: `$.ua.get()` / `$.ua.set(uastring)`. \n\n```js\n// In browser with default user-agent: 'Mozilla/5.0 (Linux; U; Android 2.3.4; en-us; Sprint APA7373KT Build/GRJ22) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0':\n\n// Do some tests\nconsole.log($.ua.device);           // {vendor: \"HTC\", model: \"Evo Shift 4G\", type: \"mobile\"}\nconsole.log($.ua.os);               // {name: \"Android\", version: \"2.3.4\"}\nconsole.log($.ua.os.name);          // \"Android\"\nconsole.log($.ua.get());            // \"Mozilla/5.0 (Linux; U; Android 2.3.4; en-us; Sprint APA7373KT Build/GRJ22) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0\"\n\n// reset to custom user-agent\n$.ua.set('Mozilla/5.0 (Linux; U; Android 3.0.1; en-us; Xoom Build/HWI69) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13');\n\n// Test again\nconsole.log($.ua.browser.name);     // \"Safari\"\nconsole.log($.ua.engine.name);      // \"Webkit\"\nconsole.log($.ua.device);           // {vendor: \"Motorola\", model: \"Xoom\", type: \"tablet\"}\nconsole.log(parseInt($.ua.browser.version.split('.')[0], 10));  // 4\n\n// Add class to <body> tag\n// <body class=\"ua-browser-safari ua-devicetype-tablet\">\n$('body').addClass('ua-browser-' + $.ua.browser.name + ' ua-devicetype-' + $.ua.device.type);\n```\n\n## Extending regex patterns\n\n* `UAParser([uastring,] extensions)`\n\nPass your own regexes to extend the limited matching rules.\n\n```js\n// Example:\nvar myOwnRegex = [[/(myownbrowser)\\/([\\w\\.]+)/i], [UAParser.BROWSER.NAME, UAParser.BROWSER.VERSION]];\nvar myParser = new UAParser({ browser: myOwnRegex });\nvar uaString = 'Mozilla/5.0 MyOwnBrowser/1.3';\nconsole.log(myParser.setUA(uaString).getBrowser());   // {name: \"MyOwnBrowser\", version: \"1.3\"}\n```\n\n\n# Development\n\n## Contribute\n\n* Fork and clone this repository\n* Make some changes as required\n* Write a unit test to showcase your feature\n* Run the test suites to make sure the changes you made didn't break anything `$ npm run test`\n* Commit and push to your own repository\n* Submit a pull request to this repository under `develop` branch\n* Profit? $$$\n\n## Build\n\nBuild a minified & packed script\n\n```sh\n$ npm run build\n```\n\n\n# Donate\n\nDo you use & like UAParser.js but you don\u2019t find a way to show some love? If yes, please consider donating to support this project. Otherwise, no worries, regardless of whether there is support or not, I will keep maintaining this project. Still, if you buy me a cup of coffee I would be more than happy though :)\n\n[![Support via PayPal](https://cdn.rawgit.com/twolfson/paypal-github-button/1.0.0/dist/button.svg)](https://www.paypal.me/faisalman/)\n\n\n# License\n\nDual licensed under GPLv2 or MIT\n\nCopyright \u00a9 2012-2018 Faisal Salman <<f@faisalman.com>>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of \nthis software and associated documentation files (the \"Software\"), to deal in \nthe Software without restriction, including without limitation the rights to use, \ncopy, modify, merge, publish, distribute, sublicense, and/or sell copies of the \nSoftware, and to permit persons to whom the Software is furnished to do so, \nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all \ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n", "release_dates": []}, {"name": "uBlock", "description": "uBlock Origin - An efficient blocker for Chromium and Firefox. Fast and lean.", "language": "JavaScript", "license": {"key": "gpl-3.0", "name": "GNU General Public License v3.0", "spdx_id": "GPL-3.0", "url": "https://api.github.com/licenses/gpl-3.0", "node_id": "MDc6TGljZW5zZTk="}, "readme": "[![Badge Commits]][Commit Rate]\n[![Badge Issues]][Issues]\n[![Badge Localization]][Crowdin]\n[![Badge License]][License]\n[![Badge NPM]][NPM]\n[![Badge Mozilla]][Mozilla]\n[![Badge Chrome]][Chrome]\n[![Badge Edge]][Edge]\n\n***\n\n<h1 align=\"center\">\n<sub>\n<img src=\"https://github.com/gorhill/uBlock/blob/master/src/img/ublock.svg\" height=\"38\" width=\"38\">\n</sub>\nuBlock Origin (uBO)\n</h1>\n<p align=\"center\">\n<sub><a href=\"https://github.com/gorhill/uBlock/wiki/uBlock-Origin-is-completely-unrelated-to-the-web-site-ublock.org\"><b>BEWARE!</b> uBO is (and has always been) COMPLETELY UNRELATED to the website <code>ublock.org</code></a>.</sub>\n</p>\n\n***\n\n<p align=\"center\">\n<a href=\"https://addons.mozilla.org/addon/ublock-origin/\"><img src=\"https://user-images.githubusercontent.com/585534/107280546-7b9b2a00-6a26-11eb-8f9f-f95932f4bfec.png\" alt=\"Get uBlock Origin for Firefox\"></a>\n<a href=\"https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm\"><img src=\"https://user-images.githubusercontent.com/585534/107280622-91a8ea80-6a26-11eb-8d07-77c548b28665.png\" alt=\"Get uBlock Origin for Chromium\"></a>\n<a href=\"https://microsoftedge.microsoft.com/addons/detail/ublock-origin/odfafepnkmbhccpbejgmiehpchacaeak\"><img src=\"https://user-images.githubusercontent.com/585534/107280673-a5ece780-6a26-11eb-9cc7-9fa9f9f81180.png\" alt=\"Get uBlock Origin for Microsoft Edge\"></a>\n<a href=\"https://addons.opera.com/extensions/details/ublock/\"><img src=\"https://user-images.githubusercontent.com/585534/107280692-ac7b5f00-6a26-11eb-85c7-088926504452.png\" alt=\"Get uBlock Origin for Opera\"></a>\n<a href=\"https://addons.thunderbird.net/thunderbird/addon/ublock-origin/\"><img src=\"https://user-images.githubusercontent.com/124740436/235314672-73243149-3683-4407-a2d5-ad0f2b08bc17.png\" alt=\"Get uBlock Origin for Thunderbird\"></a>\n</p>\n\n***\n\nuBlock Origin (uBO) is a CPU and memory-efficient [wide-spectrum content blocker][Blocking] for Chromium and Firefox. It blocks ads, trackers, coin miners, popups, annoying anti-blockers, malware sites, etc., by default using [EasyList][EasyList], [EasyPrivacy][EasyPrivacy], [Peter Lowe's Blocklist][Peter Lowe's Blocklist], [Online Malicious URL Blocklist][Malicious Blocklist], and uBO [filter lists][uBO Filters]. There are many other lists available to block even more. Hosts files are also supported. uBO uses the EasyList filter syntax and [extends][Extended Syntax] the syntax to work with custom rules and filters.\n\nYou may easily unselect any preselected filter lists if you think uBO blocks too much. For reference, Adblock Plus installs with only EasyList, ABP filters, and Acceptable Ads enabled by default.\n\nIt is important to note that using a blocker is **NOT** [theft]. Do not fall for this creepy idea. The _ultimate_ logical consequence of `blocking = theft` is the criminalization of the inalienable right to privacy.\n\nAds, \"unintrusive\" or not, are just the visible portion of the privacy-invading means entering your browser when you visit most sites. **uBO's primary goal is to help users neutralize these privacy-invading methods** in a way that welcomes those users who do not wish to use more technical means.\n\n***\n\n* [Documentation](#documentation)\n* [Installation](#installation)\n  * [Firefox](#firefox)\n  * [Thunderbird](#thunderbird)\n  * [Chromium](#chromium)\n  * [All Programs](#all-programs)\n  * [Enterprise Deployment](#enterprise-deployment)\n* [Release History](#release-history)\n* [Translations](#translations)\n* [About](#about)\n\n## Documentation\n\n<table>\n    <thead>\n        <tr>\n            <th>Basic Mode</th>\n            <th>Advanced Mode</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>The <a href=\"https://github.com/gorhill/uBlock/wiki/Quick-guide:-popup-user-interface\">simple popup user interface</a> for an install-it-and-forget-it type of installation that is configured optimally by default.</td>\n            <td>The <a href=\"https://github.com/gorhill/uBlock/wiki/Dynamic-filtering:-quick-guide\">advanced popup user interface</a> includes a point-and-click firewall that is configurable on a per-site basis.</td>\n        </tr>\n        <tr>\n            <td align=\"center\" valign=\"top\"><a href=\"https://github.com/gorhill/uBlock/wiki/Quick-guide:-popup-user-interface\"><img src=\"https://user-images.githubusercontent.com/585534/232531044-c4ac4dd5-0b60-4c1e-aabb-914be04b846c.png\"/></a></td>\n            <td align=\"center\" valign=\"top\"><a href=\"https://github.com/gorhill/uBlock/wiki/Dynamic-filtering:-quick-guide\"><img src=\"https://user-images.githubusercontent.com/585534/232531439-a8f81cc3-6622-45c4-8b32-7348cecf6e98.png\"/></a></td>\n        </tr>\n    </tbody>\n</table>\n\nVisit the [Wiki][Wiki] for documentation.\n\nFor support, questions, or help, visit [/r/uBlockOrigin][Reddit].\n\n## Installation\n\n[Required Permissions][Permissions]\n\n#### Firefox\n\n[Firefox Add-ons][Mozilla]\n\n[Development Builds][Beta]\n\nuBO [works best][Works Best] on Firefox and is available for desktop and Android versions.\n\n#### Thunderbird\n\n[Thunderbird Add-ons][Thunderbird]\n\nIn Thunderbird, uBlock Origin does not affect emails, just feeds.\n\n#### Chromium\n\n[Chrome Web Store][Chrome]\n\n[Microsoft Edge Add-ons][Edge] (Published by: [Nicole Rolls][Nicole Rolls])\n\n[Opera Add-ons][Opera]\n\n[Development Builds][Chrome Dev]\n\nuBO should be compatible with any Chromium-based browser.\n\n#### All Programs\n\nDo **NOT** use uBO with any other content blocker. uBO [performs][Performance] as well as or better than most popular blockers. Other blockers can prevent uBO's privacy or anti-blocker-defusing features from working correctly.\n\n[Manual Installation][Manual Installation]\n\n#### Enterprise Deployment\n\n[Deploying uBO][Deployment]\n\n## Release History\n\n[Releases Page][Releases]\n\n## Translations\n\nHelp translate uBO via [Crowdin][Crowdin].\n\n## About\n\n[Manifesto][Manifesto]\n\n[Privacy Policy][Privacy Policy]\n\n[GPLv3 License][License]\n\nFree. Open-source. For users by users. No donations sought.\n\nIf you ever want to contribute something, think about the people working hard to maintain the filter lists you are using, which are available to use by all for free.\n\n\n<!----------------------------------------------------------------------------->\n\n[Peter Lowe's Blocklist]: https://pgl.yoyo.org/adservers/\n[Malicious Blocklist]: https://gitlab.com/malware-filter/urlhaus-filter#malicious-url-blocklist\n[Performance]: https://www.debugbear.com/blog/chrome-extension-performance-2021#how-do-ad-blockers-and-privacy-tools-affect-browser-performance\n[EasyPrivacy]: https://easylist.to/#easyprivacy\n[Thunderbird]: https://addons.thunderbird.net/thunderbird/addon/ublock-origin/\n[Chrome Dev]: https://chrome.google.com/webstore/detail/ublock-origin-development/cgbcahbpdhpcegmbfconppldiemgcoii\n[EasyList]: https://easylist.to/#easylist\n[Mozilla]: https://addons.mozilla.org/addon/ublock-origin/\n[Crowdin]: https://crowdin.com/project/ublock\n[Chrome]: https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm\n[Reddit]: https://www.reddit.com/r/uBlockOrigin/\n[Theft]: https://twitter.com/LeaVerou/status/518154828166725632\n[Opera]: https://addons.opera.com/extensions/details/ublock/\n[Edge]: https://microsoftedge.microsoft.com/addons/detail/ublock-origin/odfafepnkmbhccpbejgmiehpchacaeak\n[NPM]: https://www.npmjs.com/package/@gorhill/ubo-core\n\n[Manifesto]: MANIFESTO.md\n[License]: LICENSE.txt\n\n[Nicole Rolls]: https://github.com/nicole-ashley\n\n\n<!---------------------------------[ Internal ]-------------------------------->\n\n[Manual Installation]: https://github.com/gorhill/uBlock/tree/master/dist#install\n[Extended Syntax]: https://github.com/gorhill/uBlock/wiki/Static-filter-syntax#extended-syntax\n[Privacy Policy]: https://github.com/gorhill/uBlock/wiki/Privacy-policy\n[uBO Filters]: https://github.com/uBlockOrigin/uAssets/tree/master/filters\n[Permissions]: https://github.com/gorhill/uBlock/wiki/Permissions\n[Commit Rate]: https://github.com/gorhill/uBlock/commits/master\n[Works Best]: https://github.com/gorhill/uBlock/wiki/uBlock-Origin-works-best-on-Firefox\n[Deployment]: https://github.com/gorhill/uBlock/wiki/Deploying-uBlock-Origin\n[Blocking]: https://github.com/gorhill/uBlock/wiki/Blocking-mode\n[Releases]: https://github.com/gorhill/uBlock/releases\n[Issues]: https://github.com/uBlockOrigin/uBlock-issues/issues\n[Beta]: https://github.com/gorhill/uBlock/blob/master/dist/README.md#for-beta-version\n[Wiki]: https://github.com/gorhill/uBlock/wiki\n\n\n<!----------------------------------[ Badges ]--------------------------------->\n\n[Badge Localization]: https://d322cqt584bo4o.cloudfront.net/ublock/localized.svg\n[Badge Commits]: https://img.shields.io/github/commit-activity/m/gorhill/ublock?label=Commits\n[Badge Mozilla]: https://img.shields.io/amo/rating/ublock-origin?label=Firefox\n[Badge License]: https://img.shields.io/badge/License-GPLv3-blue.svg\n[Badge Chrome]: https://img.shields.io/chrome-web-store/rating/cjpalhdlnbpafiamejdnhcphjbkeiagm?label=Chrome\n[Badge Edge]: https://img.shields.io/badge/dynamic/json?label=Edge&color=brightgreen&query=%24.averageRating&suffix=%2F%35&url=https%3A%2F%2Fmicrosoftedge.microsoft.com%2Faddons%2Fgetproductdetailsbycrxid%2Fodfafepnkmbhccpbejgmiehpchacaeak\n[Badge Issues]: https://img.shields.io/github/issues/uBlockOrigin/uBlock-issues\n[Badge NPM]: https://img.shields.io/npm/v/@gorhill/ubo-core\n\n", "release_dates": []}, {"name": "unzip-crx", "description": "Unzip chrome extension files", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# unzip-crx\n\n__Unzip chrome extension files__\n\n[![Build Status](https://travis-ci.org/peerigon/unzip-crx.svg?branch=master)](https://travis-ci.org/peerigon/unzip-crx) [![Dependency Status](https://david-dm.org/peerigon/unzip-crx.svg)](https://david-dm.org/peerigon/unzip-crx) [![Coverage Status](https://coveralls.io/repos/github/peerigon/unzip-crx/badge.svg?branch=master)](https://coveralls.io/github/peerigon/unzip-crx?branch=master)\n\nIf you want to unzip [Chrome extension files](https://developer.chrome.com/extensions) (*.crx) you might have the problem that your unzip lib claims that the file header is malformed. This is due to that Chrome [adds some extra information](https://developer.chrome.com/extensions/crx) for identifying crx files. `unzip-crx` handles those additional headers and unzips as usual.\n\nThis lib is highly inspired by [crx2ff](https://github.com/abarreir/crx2ff) from [abarreir](https://github.com/abarreir), thanks!\n\n## Installation\n\n```\n$ npm install unzip-crx\n```\n\n## Example\n\n```js\nconst unzip = require(\"unzip-crx\");\n\nconst crxFile = \"./this-chrome-extension.crx\";\n\nunzip(crxFile).then(() => {\n  console.log(\"Successfully unzipped your crx file..\");\n});\n\n```\n\n## API\n\n### unzip(file[, destination])\n\nResolves with a Promise if the file was unzipped successfully, throws otherwise (use `.catch()`).\n\n\n\n## Contributing\n\nFrom opening a bug report to creating a pull request: **every contribution is appreciated and welcome**. If you're planing to implement a new feature or change the api please create an issue first. This way we can ensure that your precious work is not in vain.\n\nAll pull requests should have 100% test coverage (with notable exceptions) and need to pass all tests.\n\n- Call `npm test` to run the unit tests\n- Call `npm run coverage` to check the test coverage (using [istanbuljs/nyc](https://github.com/istanbuljs/nyc))\n\n## LICENSE\n\nMIT\n", "release_dates": []}, {"name": "user-studies-extension", "description": null, "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Brave User Studies Extension\n\n## About\nThis is a purely opt-in browser extension helping us to collect information about online user behaviour in a respectful and transparent way. The project contains the browser extension and the collection server. For instructions see the README files in the respective directory.\n\n\n**Note: We will not accept and immediately delete all data that is submitted by non-verified participants!**\n\n## Downloads\nDownloads are done via the Chrome Web Store. Brave Software team members will provide end-users with an official link to the extension (after an application process).\n\n## Contact us\nIf you have any questions feel free to reach out to us at user-studies@brave.com\n\nThanks!\n- The Brave Research Team\n", "release_dates": []}, {"name": "vault", "description": "Brave personal data store vault.", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "[![Build Status](https://travis-ci.org/brave/vault.svg)](https://travis-ci.org/brave/vault)\n\n# Brave Vault\n**NB: this repository is now deprecated. it is being replaced by something _wonderful!_**\n\nBrave personal data store vault.\n\n<img src='documentation/ecosystem.png' />\n\n# Initialization\nTake a look at the files in the `config/` directory.\nWhen the server starts,\nit will look file a file called `config/config.{PROFILE}.js` where `{PROFILE}` is `$NODE_ENV` (defaulting to `\"development\"`).\n\nAuthentication is achieved via a GitHub [OAuth application](https://github.com/settings/developers).\nCreate a developer application with an authorization callback of the form `https://{DOMAIN:PORT}/v1/login` and update the\n`login.clientId` and `login.clientSecret` properties.\n\nAuthorization is achieved by verifying that the user is a member of a GitHub organization, i.e.,\n`https://github.com/orgs/{ORGANIZATION}/teams`.\nSet the `login.organization` property to the name of the organization.\n\nNow start the server with `npm start` and `https://{DOMAIN:PORT}/v1/login` which will start the authentication/authorization\nprocess.\nOn success,\nyou will be redirected to `https://{DOMAIN:PORT}/documentation`.\n\n# Setup\nClone the repo: `git clone git@github.com:brave/vault.git`\n\nInstall dependencies with `npm install`\n\nInstall MongoDB: `brew update && brew install mongodb`\n\nStart MongoDB. There are a variety of ways to do this, one option on a mac: `brew tap homebrew/services && brew services start mongodb`\n\n## StandardJS\nFor linting we use [StandardJS](https://github.com/feross/standard). It's recommended that you install the necessary IDE plugin. Since this repo uses ES7 features, you'll need a global install of both the standard and babel-eslint packages.\n\n## Configuration\nFor staging or production environments configuration variables are stored as environment preferences. See config/config.production.js for a list of these variables.\n\nFor local development you can copy config/config.development.js.tpl to config/config.development.js and define the local config variables.\n\n## Running the server\nUse `gulp` to run the server in development. This also sets up watchers and will restart the server on a file change.\n\n## Theory of Operation\nAll operations are available via only HTTPS on public-facing systems.\nAt a minimum,\nall requests are logged with method, path, `Host` and `User-Agent` headers, client IP address,\nand `sessionId` parameter (if present);\nand all responses are logged with code and diagnostic(if any)\nAll HTTP content is `application/json`.\nCommonly used data types are:\n\n| data type     | syntax                                                                                                      |\n| -------------:|:----------------------------------------------------------------------------------------------------------- |\n| `diagnostic`  | localized string intended for logging and human consumption                                                 |\n| `sessionId`   | [UUID v4](https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_.28random.29) string        |\n| `timestamp`   | opaque string identifying a unique instance of time                                                         |\n| `userId`      | [UUID v4](https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_.28random.29) string        |\n\nErrors are \"boomlets\", e.g.,\n\n        {\n          \"statusCode\": 420,\n          \"error\": \"Enhance Your Calm\",\n          \"message\": \"Your repeated violations of the Verbal Morality Statute ...\"\n        }\n\nComplete <a href='http://vault-staging.brave.com/documentation'>documentation</a>.\n", "release_dates": []}, {"name": "vault-client", "description": "An example of client code for the Brave vault.", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "[![Build Status](https://travis-ci.org/brave/vault-client.svg)](https://travis-ci.com/brave/vault-client)\n\n# vault-client\n\nAn example of client code for the [Brave vault](https://github.com/brave/vault).\n\n## Please Read Carefully\nThis package includes the [MSR JavaScript Cryptography Library](http://research.microsoft.com/en-us/projects/msrjscrypto/),\nwhich is licensed under the [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0).\nThe entire library is 770MB, so rather than include it in this repository,\nonly the top-level directory is included,\nalong with the one file modified in order to allow the library to run under Node.\n(In the `minimized` branch, only a minified version of the modified file is present.)\nIt is hoped that the MSR authors will publish the library separately as a Node package,\nallowing the vault-client package to simply reference it.\n\n## API\n\nTo begin:\n\n- The client must maintain a secure, persistent storage in which it can store a JSON object.\n\n- There are two kinds of data: persona-global data and session-specific data:\n\n    - The api will manage a \"default\" `sessionId`; however, the client is free to supply any `sessionId` it wishes.\n\n    - To access (read/write/remove) session-specific data, both a `sessionId` and a `type` string must be specified\n    (by convention, a `sessionId` of `true` indicates the \"default\" `sessionId`).\n\n### Creating an Endpoint\n\n        var client = require('vault-client')\n        this.client = new client(options, state, function (err, result) { ... })\n\nwhere `options` is:\n\n        { server   : 'http://vault-staging.brave.com'\n        , verboseP : false\n        }\n\nand `state` is either: whatever was previously stored in persistent storage, or `{}`, or a URL string from a decoded QRcode.\n\nThe  client endpoint should not be referenced until the callback is invoked.\nWhen the callback is invoked, if `err` is `null`, and `result` is defined, then `result` must be put into persistent storage.\n(If `err` is `null`,\nthen the operation has succeeded,\nregardless of whether `result` is defined or not.)\n\n### Vault Properties\n\nTo retrieve the properties for the Ledger, the client calls:\n\n        var properties = this.client.get()\n\nwhere `properties` is a list of configuration options:\n\n| Property    | Possible Values                      |\n|------------:|--------------------------------------|\n| `personaId` | the identity of the persona          |\n| `sessionId` | the identify of the default session  |\n\n\n### Reading Persona Data\n\n        this.client.read(options, function (err, result) { ... })\n\nwhere `options` is:\n\n        { sessionId : true || string || undefined\n        , type      :         string || undefined\n        }\n\nIf `options.sessionId` is defined, then `options.type` must also be defined (and vice-versa) -- if either is defined, then\nsession-specific data is returned; otherwise persona-global data is returned.\n\nIf `err` is `null`, then result is:\n\n        { object1 : { ... }\n        , object2 : { ... }\n        }\n\nwhere `object1` contains those properties that are stored at the vault in plaintext,\nand `object2` contains those properties that are stored at the vault in ciphertext.\n\n### Writing Persona Data\n\n        this.client.write(options, object1, object2, function (err) { ... })\n\nwhere `options` is the same as with `this.client.read`,\n`object1` will be stored in the vault as plaintext,\nand `object2` will be encrypted and then stored in the vault as ciphertext.\n\n### Removing Persona Data\n\n        this.client.remove(options, function (err) { ... })\n\nwhere `options` is the same as with `this.client.read`.\nIf `options.sessionId` is not defined, then the entire persona is deleted, and the client object is now invalid.\n\n### Listing Session-Specific data for a Persona\n\n        this.client.list(options, function (err, result) { ... })\n\nwhere `options` is the same as with `this.client.read` _except_ that either (or both) `sessionId` or `type` may be `undefined`.\n\nIf `err` is `null`, then result is:\n\n        [ { sessionId : string\n          , type      : string\n          , object1   : { ... }\n          , object2   : { ... }\n          }\n        , ...\n        ]\n\n### Generating a URL string for QRcodes\n\n        this.client.qrcodeURL(options, function (err, result) { ... })\n\nwhere `options` is currently ignored.\n\nThe result given to the callback (a string) may be passed to a QRcode generation routine to be scanned by another client.\nThe second client should (after parsing the QRcode) use the resulting URL string as the `state` parameter to `new client()`.\n\n\n## Examples\n\n        var client = require('vault-client')\n        var state = /* retrieved from secure, persistent storage or {} */\n        var readyP = false\n        this.client = new client({}, state, function (err, result) {\n          if (err) return ...\n\n          readyP = true\n          if (result) /* store into secure, persistent storage */\n        })\n\n        ...\n\n        // save this client's history\n        this.client.write({ sessionId: true, type: 'history' }, null, { ... }, function(err) {\n            if (err) return ...\n        })\n\n        // get session-specific history for all clients\n        this.client.list({ type: 'history' }, null, { ... }, function(err) {\n            if (err) return ...\n        })\n\n        // get all session-specific data for the default sessionId\n        this.client.list({ sessionId: true }, null, { ... }, function(err) {\n            if (err) return ...\n        })\n\n        // get all session-specific data for a particular session\n        this.client.list({ sessionId: sessionId }, null, { ... }, function(err) {\n            if (err) return ...\n        })\n\nYou can also take a look at the file `example.js`.\n", "release_dates": []}, {"name": "vault-crash-parser", "description": "Version specific crash parsing", "language": "JavaScript", "license": null, "readme": null, "release_dates": []}, {"name": "vault-updater", "description": "Laptop browser update service", "language": "JavaScript", "license": null, "readme": "# Brave Auto Update Services\n\nAuto updater service managing update requests from locally installed updaters\n\n## Setup\n\nClone the repo\n\nInstall dependencies `npm install`\n\n## Start\n\n`npm start`\n\n## Environment variables\n\n```\nMLAB_URI:               URL to Mongo [required]\nCLOUDAMQP_URL:          URL to RabbitMQ [required]\n\nFIXIE_URL:              URL to fixie [optional]\nNEW_RELIC_APP_NAME:     Name or app [optional]\nNEW_RELIC_LICENSE_KEY:  New Relic key [optional]\nPAPERTRAIL_API_TOKEN:   Papertrail API token [optional]\n\nS3_CRASH_KEY:           S3 crash key [required]\nS3_CRASH_SECRET:        S3 crash secret [required]\nS3_CRASH_BUCKET:        S3 crash bucket name [default]\nS3_CRASH_REGION:        us-east-1 [default]\n\nFEATURE_REFERRAL_PROMO: If set request will be proxied to the referral promo for the download endpoints [optional]\nBEHIND_FASTLY:          If set the IP address sent to the referral promo will be in the second in the list rather than the first [optional]\nS3_DOWNLOAD_BUCKET:     S3 download bucket name [default]\nS3_DOWNLOAD_KEY:        S3 download key [required if FEATURE_REFERRAL_PROMO set]\nS3_DOWNLOAD_SECRET:     S3 download secret [required if FEATURE_REFERRAL_PROMO set]\n```\n", "release_dates": []}, {"name": "vibrant.js", "description": "Extract prominent colors from an image. JS port of Android's Palette.", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Vibrant.js\nExtract prominent colors from an image.\nVibrant.js is a javascript port of the [awesome Palette class](https://developer.android.com/reference/android/support/v7/graphics/Palette.html) in the Android support library.\n\n![](https://i.imgur.com/AxfT7hM.png)\n\n## Demo & usage docs\nSee the website: http://jariz.github.io/vibrant.js/\n\n##Installing\n####Bower\n`bower install vibrant`\n####Download\nSee our [releases](https://github.com/jariz/vibrant.js/releases/)\n####npm\n`npm install node-vibrant`  \nThis is a node compatible version made by [AKFish](https://github.com/akfish), [more info & docs](https://github.com/akfish/node-vibrant).\n\n##Building\n1. `npm install`\n1. `bower install`\n1. Compile gulpfile: `coffee -c gulpfile.coffee`\n2. `gulp`\n3. Done. Optionally run `gulp watch` for automatic compiling.\n\n##Other cool stuff\nCheck out [Tabbie](http://github.com/jariz/tabbie), the fully customisable material new tab page, with all your favorite websites and services!  \n\n[![](https://cloud.githubusercontent.com/assets/1415847/7971420/f3dec05a-0a44-11e5-8ecb-fcac49e91f50.png)](http://github.com/jariz/tabbie)\n", "release_dates": []}, {"name": "viproxy", "description": "Go TCP proxy library that translates between AF_INET and AF_VSOCK.", "language": "Go", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "VIProxy\n=======\n\nThe VIProxy package implements a TCP proxy that translates between AF\\_INET and\nAF\\_VSOCK connections.  The proxy takes as input two addresses, one being\nAF\\_INET and the other being AF\\_VSOCK.  The proxy then starts a TCP listener on\nthe in-address and once it receives an incoming connection to the in-address, it\nestablishes a TCP connection to the out-addresses.  Once both connections are\nestablished, the proxy copies data back and forth.\n\nThe [example](example) directory contains a simple example of how one would use\nviproxy.\n", "release_dates": []}, {"name": "vsock-relay", "description": "Relays TCP connections from IPv4/IPv6 to vsock.", "language": "Rust", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# vsock-relay\n\nRelays incoming IPv4/IPv6 TCP connections to vsock.\n\nRun with `-h` switch to see configuration options.\n\nThe `mock-vsock` feature will use IPv4/IPv6 for outgoing connections, which can be useful for local development/testing.\n", "release_dates": ["2023-07-20T23:47:51Z"]}, {"name": "wallet-standard-brave", "description": null, "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# wallet-standard-brave\n\nThis is modified from wallet-standard `ghost` example wallet following\nhttps://github.com/solana-labs/wallet-standard/blob/master/WALLET.md\n\n## Filing issues\n\nPlease file issues related to this repository in [Brave Browser repository](https://github.com/brave/brave-browser).\n", "release_dates": ["2023-04-01T18:24:13Z", "2023-04-01T18:23:49Z"]}, {"name": "web-discovery-project", "description": "Web Discovery Project", "language": "JavaScript", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# Web Discovery Project\n\nThis repository contains the client (extension) code for Web Discovery Project\nwhich runs in the Brave browser.\n\n# Setup\n\n## Linux\n\nIf you don't have Brave browser installed on your system: ``.\n\n```sh\n$ npm install\n$ ./update-brave.sh\n$ BRAVE_PATH=./brave/brave npm run start\n```\n\nYou can also set the `BRAVE_PATH` environment variable to your global Brave binary `$(which brave)`.\nThe last command will build the extension and start Brave with the extension loaded.\nEverything should work locally with this setup. By default it will rely on the `sandbox` environment deployed on AWS.\n\n## Mac\n\n```sh\n$ BRAVE_PATH=\"/Applications/Brave Browser.app/Contents/MacOS/Brave Browser\" npm run start\n```\n\n## Documentation\n\nFor more information about the Web Discovery methodology, privacy and security\nguarantees as well as examples of messages sent, visit [this README](./modules/web-discovery-project/sources/README.md).\n\n## Manual setup\n\n### Yarn\n\n```sh\n$ yarn install --frozen-lock\n$ yarn start:build # build extension\n$ yarn start:brave # start Brave with extension loaded\n```\n\n### Npm\n\n```sh\n$ npm ci\n$ npm run start:build # build extension\n$ npm run start:brave # start Brave with extension loaded\n```\n\n### Patterns\n\nThere are prod and test versions of the patterns file. Test patterns are used for tests only. Prod patterns are fetched from \nCDN (https://patterns.hpn.brave.com/patterns.gz). If you have to change patterns during development you need to:\n1. Serve a gzipped patterns file locally using an HTTP server.\n2. Update patterns URL for your environment in [the config file](./configs/common/urls.js) to point to your locally served file.\n3. Disable the signature verification of a patterns file by setting `WDP_PATTERNS_SIGNING` option to `true` in the config file for your environment. For `sandbox` environment such file is [/configs/sandbox.js](./configs/sandbox.js).\n\n## Useful commands\n\nOpen extension dev tools (burger menu > extensions > developer mode toggle > background page) then switch to console tab.\n\n### For `query` messages\n\nForce updating WebDiscoveryProject patterns:\n```javascript\nWDP.app.modules['web-discovery-project'].background.webDiscoveryProject.patternsLoader.resourceWatcher.forceUpdate()\n```\n\nAfter visiting a SERP page, force double-fetch to happen:\n```javascript\nWDP.app.modules['web-discovery-project'].background.webDiscoveryProject.strictQueries.map(x=>x.tDiff=0)\n```\n\n#### For `page` messages\n\nOpen a new tab and visit `https://www.marca.com/` (or another URL, and replace the occurrences in the following commands).\n\nForce an *active page* (tab is still open) to the database to be double-fetched...\n\n```javascript\nWDP.app.modules['web-discovery-project'].background.webDiscoveryProject._debugRemoveFromActivePages('https://www.marca.com/')\n```\n\nAfter forcing this, `https://www.marca.com/` will no longer be in dict at:\n\n```javascript\nWDP.app.modules['web-discovery-project'].background.webDiscoveryProject.state['v']\n```\n\nSee URLs on database waiting to be double-fetched:\n\n```javascript\nWDP.app.modules['web-discovery-project'].background.webDiscoveryProject.listOfUnchecked(1000000000000, 0, null, function(x) {console.log(x)})\n```\n\nForce a double-fetch of a single URL, (URL as appears in the table above, it might have been canonized)\n\n```javascript\nWDP.app.modules['web-discovery-project'].background.webDiscoveryProject.forceDoubleFetch(\"https://www.marca.com/\")\n```\n\n## Tests\n\nThere are two kinds of tests in WDP: `unit` and `integration`. All of them run\nin CI and you can run then on your computer too.\n\n### Unit tests\n\n```sh\n$ ./fern.js test configs/ci/unit-tests.js\n```\n\nYou should now get live feedback about the running tests. If you change the\ncode, a rebuild will be triggered and tests will restart.\n\n#### Fixtures\n\nSome unit tests rely on fixtures which are directories containing page HTML\nand expected extracted data. Fixture names contain a search query and a date\nit was created on. For example if you want to add a new google fixture for\nthe query `george washington` run the following commands:\n``` sh\ncd ./modules/web-discovery-project/tests/unit\nmkdir ./fixtures/content-extractor/go/george-washington-2023-10-04\n./generate-fixtures.sh\n```\n\n### Integration tests\n\nIntegration tests (in Brave):\n```sh\n./fern.js test configs/ci/integration-tests.js -l brave-web-ext --brave /opt/brave.com/brave/brave-browser\n```\n\n### Regression tests\n\nRegression tests (in Brave):\n```sh\n./fern.js test configs/ci/integration-tests.js -l brave-web-ext --grep UtilityRegression --brave /opt/brave.com/brave/brave-browser\n```\n\n**Note that you should replace the path to Brave in the command above**.\n\nYou can also use the `--keep-open` flag so that the test runner keeps watching\nfor code changes and will restart the tests whenever that happens.\n\nAnother useful flag is `--grep`, which allows you to select a subset of tests\nto run based on their names. For example:\n\n```sh\n./fern.js test configs/ci/integration-tests.js -l brave-web-ext --brave /opt/brave.com/brave/brave-browser --keep-open --grep registerContentScript\n```\n\nIntegration tests in **Docker**:\n```sh\n./run_tests_in_docker.sh \"configs/ci/integration-tests.js -l brave-web-ext --brave /opt/brave.com/brave/brave-browser\"\n```\n\n### Copyright\n\nCopyright \u00a9 2021 Brave Software. All rights reserved.\nCopyright \u00a9 2014 Cliqz GmbH. All rights reserved.\n\nThis Source Code Form is subject to the terms of the Mozilla Public\nLicense, v. 2.0. If a copy of the MPL was not distributed with this file,\nYou can obtain one at https://mozilla.org/MPL/2.0/.\n", "release_dates": ["2022-04-13T17:31:53Z", "2021-09-15T19:55:49Z", "2021-09-15T19:43:37Z", "2021-09-14T17:22:24Z"]}, {"name": "webkit-content-filter-validator", "description": "Compile JSON rules into a WebKit content filter store to check for syntax errors.", "language": "C", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# webkit-content-filter-validator\n\nCompile JSON rules into a [WebKit content filter store](https://webkitgtk.org/reference/webkit2gtk/2.36.2/WebKitUserContentFilterStore.html) to check for syntax errors.\n\nTo use, input a file in Apple's [JSON content blocker format](https://developer.apple.com/documentation/safariservices/creating_a_content_blocker), either as the first argument or through stdin.\n\n`webkit-content-filter-validator` will silently return a zero exit code if the file is well-formatted. Otherwise, it will print WebKit's error to stdout and return a nonzero exit code.\n\n## Dependencies\n\n`webkit-content-filter-validator` depends on [WebKit WPE](https://wpewebkit.org/).\n\nWebKit WPE is packaged as:\n- `libwpewebkit-1.0-dev` under Ubuntu\n- `wpewebkit` under Arch Linux\n\n## Building\n\n### Ubuntu 22.04\n\nRun `make webkit-content-filter-validator`.\n\n### Arch Linux\n\nReplace `wpe-webkit-1.0` with `wpe-webkit-1.1` in the Makefile, then proceed as above.\n\n### Docker\n\n```\ndocker build -t webkit-content-filter-validator .\n```\n\n## Running\n\nCheck the usage:\n\n```\nwebkit-content-filter-validator --help\n```\n\n### Running under Docker\n\nMaking input files accessible to the container's filesystem is complicated.\nThe easiest way to pass inputs to the command in the Docker image is through stdin, i.e.:\n\n```\ndocker run --rm -i webkit-content-filter-validator < test.json\n```\n\nor,\n\n```\necho \"[{...}]\" | docker run --rm -i webkit-content-filter-validator\n```\n\n## Developing\n\nRun `make compile_flags.txt` to setup `clangd` IDE integration.\n", "release_dates": []}, {"name": "webkit-cpu-profiler-tools", "description": "WebKit CPU Profile tools", "language": "JavaScript", "license": null, "readme": null, "release_dates": []}, {"name": "webpack-httpolyglot-server", "description": "Using mscdex/httpolyglot to serve http/https over the same port for Webpack development server", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# webpack-httpolyglot-server\n\n> Using [httpolyglot](https://github.com/mscdex/httpolyglot) to serve http/https over the same port for Webpack development server\n\n## Why?\n\nThe [React Chrome Extension Boilerplate](https://github.com/jhen0409/react-chrome-extension-boilerplate)  need a https webpack server on development mode ([Inject page](https://github.com/jhen0409/react-chrome-extension-boilerplate#development)), and we also need http for Window, Popup, Background features, I just don't want to open two webpack servers for that, so I made a tool, provide a easy way to achieve.\n\n## Installation\n\n```bash\n$ npm i --save-dev webpack-hot-middleware\n$ npm i --save-dev webpack-httpolyglot-server\n```\n\n## Usage\n\n#### CLI\n\nNot yet.\n\n#### Node\n\n```js\nvar createWebpackServer = require('webpack-httpolyglot-server');\n\nconst server = createWebpackServer(config, serverOptions);\n```\n\nThe `config` can be Array, it can use multiple config.\n\n## Configuration\n\n#### output.publicPath\n\nUse `//` as a prefix instead of `http://` or `https://`, but if you're making chrome extension (prefix: `chrome-extension://`), it's not applicable.\n\n#### `webpack-hot-middleware` [entry](https://github.com/glenjamin/webpack-hot-middleware#config)\n\nThis tool used `webpack-hot-middleware` for enable hot module replacement.\n\n#### devMiddleware\n\nApply [webpack-dev-middleware](https://github.com/webpack/webpack-dev-middleware) options.\n\n#### hotMiddleware\n\nApply [webpack-hot-middleware](https://github.com/glenjamin/webpack-hot-middleware) options.\n\n## Credits\n\n* The SSL keys is copied from [webpack-dev-server](https://github.com/webpack/webpack-dev-server/tree/master/ssl).\n\n## License\n\n[MIT](LICENSE.md)\n", "release_dates": []}, {"name": "webtorrent", "description": "\u26a1\ufe0f Streaming torrent client for the web", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<h1 align=\"center\">\n  <br>\n  <a href=\"https://webtorrent.io\"><img src=\"https://webtorrent.io/img/WebTorrent.png\" alt=\"WebTorrent\" width=\"200\"></a>\n  <br>\n  WebTorrent\n  <br>\n  <br>\n</h1>\n\n<h4 align=\"center\">The streaming torrent client. For node.js and the web.</h4>\n\n<p align=\"center\">\n  <a href=\"https://gitter.im/webtorrent/webtorrent\"><img src=\"https://img.shields.io/badge/gitter-join%20chat%20%E2%86%92-brightgreen.svg\" alt=\"gitter\"></a>\n  <a href=\"https://travis-ci.org/webtorrent/webtorrent\"><img src=\"https://img.shields.io/travis/webtorrent/webtorrent/master.svg\" alt=\"travis\"></a>\n  <a href=\"https://ci.appveyor.com/project/webtorrent/webtorrent\"><img src=\"https://ci.appveyor.com/api/projects/status/cgu85xlgl72uoswq/branch/master?svg=true\" alt=\"appveyor\"></a>\n  <a href=\"https://www.npmjs.com/package/webtorrent\"><img src=\"https://img.shields.io/npm/v/webtorrent.svg\" alt=\"npm version\"></a>\n  <a href=\"https://www.npmjs.com/package/webtorrent\"><img src=\"https://img.shields.io/npm/dm/webtorrent.svg\" alt=\"npm downloads\"></a>\n  <a href=\"https://standardjs.com\"><img src=\"https://img.shields.io/badge/code_style-standard-brightgreen.svg\" alt=\"Standard - JavaScript Style Guide\"></a>\n</p>\n<br>\n\n**WebTorrent** is a streaming torrent client for **node.js** and the **browser**. YEP,\nTHAT'S RIGHT. THE BROWSER. It's written completely in JavaScript \u2013 the language of the web\n\u2013 so the same code works in both runtimes.\n\nIn node.js, this module is a simple torrent client, using TCP and UDP to talk to\nother torrent clients.\n\nIn the browser, WebTorrent uses **WebRTC** (data channels) for peer-to-peer transport.\nIt can be used **without** browser plugins, extensions, or installations. It's Just\nJavaScript&trade;. Note: WebTorrent does **not** support UDP/TCP peers in browser.\n\nSimply include the\n[`webtorrent.min.js`](https://cdn.jsdelivr.net/npm/webtorrent@latest/webtorrent.min.js) script\non your page to start fetching files over WebRTC using the BitTorrent protocol, or\n`require('webtorrent')` with [browserify](http://browserify.org/). See [demo apps\n](#who-is-using-webtorrent-today) and [code examples](#usage) below.\n\n[![jsdelivr download count](https://data.jsdelivr.com/v1/package/npm/webtorrent/badge)](https://cdn.jsdelivr.net/npm/webtorrent@latest/webtorrent.min.js)\n\nTo make BitTorrent work over WebRTC (which is the only P2P transport that works on the\nweb) we made some protocol changes. Therefore, a browser-based WebTorrent client or **\"web\npeer\"** can only connect to other clients that support WebTorrent/WebRTC.\n\nTo seed files to web peers, use a client that supports WebTorrent, e.g.\n[WebTorrent Desktop][webtorrent-desktop], a desktop client with a\nfamiliar UI that can connect to web peers,\n[webtorrent-hybrid](https://github.com/webtorrent/webtorrent-hybrid), a command line program,\nor [Instant.io](https://instant.io/), a website. Established torrent clients like\n**Vuze** have [already added WebTorrent support](https://wiki.vuze.com/w/WebTorrent) so\nthey can connect to both normal *and* web peers. We hope other clients will follow.\n\n![Network](https://webtorrent.io/img/network.png)\n\n### Open Source Sponsors\n\n[<img src='https://webtorrent.io/img/supporters/brave.png' width=300>](https://brave.com)\n|---|\n\n### Features\n\n- **Torrent client for node.js & the browser** (same npm package!)\n- **Insanely fast**\n- Download **multiple torrents** simultaneously, efficiently\n- **Pure Javascript** (no native dependencies)\n- Exposes files as **streams**\n  - Fetches pieces from the network on-demand so seeking is supported (even before torrent is finished)\n  - Seamlessly switches between sequential and rarest-first piece selection strategy\n- Supports advanced torrent client features\n  - **magnet uri** support via **[ut_metadata](https://github.com/webtorrent/ut_metadata)**\n  - **peer discovery** via **[dht](https://github.com/webtorrent/bittorrent-dht)**,\n    **[tracker](https://github.com/webtorrent/bittorrent-tracker)**, and\n    **[ut_pex](https://github.com/fisch0920/ut_pex)**\n  - **[protocol extension api](https://github.com/webtorrent/bittorrent-protocol#extension-api)**\n    for adding new extensions\n- **Comprehensive test suite** (runs completely offline, so it's reliable and fast)\n\n#### Browser/WebRTC environment features\n\n- **WebRTC data channels** for lightweight peer-to-peer communication with **no plugins**\n- **No silos.** WebTorrent is a P2P network for the **entire web.** WebTorrent clients\n  running on one domain can connect to clients on any other domain.\n- Stream video torrents into a `<video>` tag (`webm (vp8, vp9)` or `mp4 (h.264)`)\n- Supports Chrome, Firefox, Opera and Safari.\n\n<p align=\"center\">\n  <a href=\"https://saucelabs.com/u/webtorrent\">\n    <img src=\"https://saucelabs.com/browser-matrix/webtorrent.svg\" alt=\"Sauce Labs\">\n  </a>\n</p>\n\n### Install\n\nTo install WebTorrent for use in node or the browser with `require('webtorrent')`, run:\n\n```bash\nnpm install webtorrent\n```\n\nTo install a `webtorrent`\n[command line program](https://github.com/webtorrent/webtorrent-cli), run:\n\n```bash\nnpm install webtorrent-cli -g\n```\n\nTo install a WebTorrent desktop application for Mac, Windows, or Linux, see\n[WebTorrent Desktop][webtorrent-desktop].\n\n### Ways to help\n\n- **Join us in [Gitter][webtorrent-gitter-url]** or on freenode at `#webtorrent` to help\n  with development or to hang out with some mad science hackers :)\n- **[Create a new issue](https://github.com/webtorrent/webtorrent/issues/new)** to report bugs\n- **[Fix an issue](https://github.com/webtorrent/webtorrent/issues?state=open)**. WebTorrent\n  is an [OPEN Open Source Project](CONTRIBUTING.md)!\n\n### Who is using WebTorrent today?\n\n**[Lots of folks!](docs/faq.md#who-is-using-webtorrent-today)**\n\n### WebTorrent API Documentation\n\n**[Read the full API Documentation](docs/api.md).**\n\n### Usage\n\nWebTorrent is the first BitTorrent client that works in the browser, using open web\nstandards (no plugins, just HTML5 and WebRTC)! It's easy to get started!\n\n#### In the browser\n\n##### Downloading a file is simple:\n\n```js\nvar WebTorrent = require('webtorrent')\n\nvar client = new WebTorrent()\nvar magnetURI = '...'\n\nclient.add(magnetURI, function (torrent) {\n  // Got torrent metadata!\n  console.log('Client is downloading:', torrent.infoHash)\n\n  torrent.files.forEach(function (file) {\n    // Display the file by appending it to the DOM. Supports video, audio, images, and\n    // more. Specify a container element (CSS selector or reference to DOM node).\n    file.appendTo('body')\n  })\n})\n```\n\n##### Seeding a file is simple, too:\n\n```js\nvar dragDrop = require('drag-drop')\nvar WebTorrent = require('webtorrent')\n\nvar client = new WebTorrent()\n\n// When user drops files on the browser, create a new torrent and start seeding it!\ndragDrop('body', function (files) {\n  client.seed(files, function (torrent) {\n    console.log('Client is seeding:', torrent.infoHash)\n  })\n})\n```\n\nThere are more examples in [docs/get-started.md](docs/get-started.md).\n\n##### Browserify\n\nWebTorrent works great with [browserify](http://browserify.org/), an npm package that let's\nyou use [node](http://nodejs.org/)-style require() to organize your browser code and load modules installed by [npm](https://www.npmjs.com/) (as seen in the previous examples).\n\n##### Webpack\n\nWebTorrent also works with [webpack](http://webpack.github.io/), a module bundler similar\nto browserify. However, webpack requires the following extra configuration:\n\n```js\n{\n  target: 'web',\n  node: {\n    fs: 'empty'\n  }\n}\n```\n\nIf you are on webpack 1.x, you will also need to add the `json-loader`:\n```js\n{\n  module: {\n    loaders: [\n      // make sure to install the 'json-loader' package: npm install json-loader\n      {\n        test: /\\.json$/,\n        loader: 'json'\n      }\n    ]\n  }\n}\n```\n\nOtherwise you could also directly use the pre-built version via `require('webtorrent/webtorrent.min')`.\n\n##### Script tag\n\nWebTorrent is also available as a standalone script\n([`webtorrent.min.js`](webtorrent.min.js)) which exposes `WebTorrent` on the `window`\nobject, so it can be used with just a script tag:\n\n```html\n<script src=\"webtorrent.min.js\"></script>\n```\n\nThe WebTorrent script is also hosted on fast, reliable CDN infrastructure (Cloudflare and\nMaxCDN) for easy inclusion on your site:\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/webtorrent@latest/webtorrent.min.js\"></script>\n```\n\n#### In Node.js\n\nWebTorrent also works in node.js, using the *same npm package!* It's mad science!\n\n**NOTE**: To connect to \"web peers\" (browsers) in addition to normal BitTorrent peers, use\n[webtorrent-hybrid](https://github.com/webtorrent/webtorrent-hybrid) which includes WebRTC\nsupport for node.\n\n#### As a command line app\n\nWebTorrent is also available as a\n[command line app](https://github.com/webtorrent/webtorrent-cli). Here's how to use it:\n\n```bash\n$ npm install webtorrent-cli -g\n$ webtorrent --help\n```\n\nTo download a torrent:\n\n```bash\n$ webtorrent magnet_uri\n```\n\nTo stream a torrent to a device like **AirPlay** or **Chromecast**, just pass a flag:\n\n```bash\n$ webtorrent magnet_uri --airplay\n```\n\nThere are many supported streaming options:\n\n```bash\n--airplay               Apple TV\n--chromecast            Chromecast\n--mplayer               MPlayer\n--mpv                   MPV\n--omx [jack]            omx [default: hdmi]\n--vlc                   VLC\n--xbmc                  XBMC\n--stdout                standard out [implies --quiet]\n```\n\nIn addition to magnet uris, WebTorrent supports [many ways](docs/api.md#clientaddtorrentid-opts-function-ontorrent-torrent-) to specify a torrent.\n\n### Talks about WebTorrent\n\n- Sep 2017 - Nordic JS - [Get Rich Quick With P2P Crypto Currency](https://www.youtube.com/watch?v=8N_4Furztjo)\n- May 2017 - Char.la - [WebTorrent and Peerify](https://youtu.be/D-04vg5hvEQ?t=54m20s) (Spanish)\n- Nov 2016 - NodeConf Argentina - [Real world Electron: Building Cross-platform desktop apps with JavaScript](https://www.youtube.com/watch?v=YLExGgEnbFY)\n- May 2016 - SIGNAL Conference - [BitTorrent in the Browser](https://www.youtube.com/watch?v=2qrUx-C5Np4)\n- May 2015 - Data Terra Nemo - [WebTorrent: Mother of all demos](https://www.youtube.com/watch?v=RRtNEcAaUO8)\n- May 2015 - Data Terra Nemo - [WebRTC Everywhere](https://www.youtube.com/watch?v=RRtNEcAaUO8)\n- Nov 2014 - JSConf Asia - [How WebTorrent Works](https://www.youtube.com/watch?v=kxHRATfvnlw)\n- Sep 2014 - NodeConf EU - [WebRTC Mad Science](https://www.youtube.com/watch?v=BVBXkzVjvPc) (first working WebTorrent demo)\n- Apr 2014 - CraftConf - [Bringing BitTorrent to the Web](https://www.youtube.com/watch?v=PT8s_IVWDgw)\n- May 2014 - JS.LA - [How I Built a BitTorrent Client in the Browser](https://vimeo.com/97324247) (progress update; node client working)\n- Oct 2013 - RealtimeConf - [WebRTC Black Magic](https://vimeo.com/77265280) (first mention of idea for WebTorrent)\n\n### Modules\n\nMost of the active development is happening inside of small npm packages which are used by WebTorrent.\n\n#### The Node Way&trade;\n\n> \"When applications are done well, they are just the really application-specific, brackish residue that can't be so easily abstracted away. All the nice, reusable components sublimate away onto github and npm where everybody can collaborate to advance the commons.\" \u2014 substack from [\"how I write modules\"](http://substack.net/how_I_write_modules)\n\n![node.js is shiny](https://feross.net/x/node2.gif)\n\n#### Modules\n\nThese are the main modules that make up WebTorrent:\n\n| module | tests | version | description |\n|---|---|---|---|\n| **[webtorrent][webtorrent]** | [![][webtorrent-ti]][webtorrent-tu] | [![][webtorrent-ni]][webtorrent-nu] | **torrent client (this module)**\n| [bittorrent-dht][bittorrent-dht] | [![][bittorrent-dht-ti]][bittorrent-dht-tu] | [![][bittorrent-dht-ni]][bittorrent-dht-nu] | distributed hash table client\n| [bittorrent-peerid][bittorrent-peerid] | [![][bittorrent-peerid-ti]][bittorrent-peerid-tu] | [![][bittorrent-peerid-ni]][bittorrent-peerid-nu] | identify client name/version\n| [bittorrent-protocol][bittorrent-protocol] | [![][bittorrent-protocol-ti]][bittorrent-protocol-tu] | [![][bittorrent-protocol-ni]][bittorrent-protocol-nu] | bittorrent protocol stream\n| [bittorrent-tracker][bittorrent-tracker] | [![][bittorrent-tracker-ti]][bittorrent-tracker-tu] | [![][bittorrent-tracker-ni]][bittorrent-tracker-nu] | bittorrent tracker server/client\n| [create-torrent][create-torrent] | [![][create-torrent-ti]][create-torrent-tu] | [![][create-torrent-ni]][create-torrent-nu] | create .torrent files\n| [magnet-uri][magnet-uri] | [![][magnet-uri-ti]][magnet-uri-tu] | [![][magnet-uri-ni]][magnet-uri-nu] | parse magnet uris\n| [parse-torrent][parse-torrent] | [![][parse-torrent-ti]][parse-torrent-tu] | [![][parse-torrent-ni]][parse-torrent-nu] | parse torrent identifiers\n| [render-media][render-media] | [![][render-media-ti]][render-media-tu] | [![][render-media-ni]][render-media-nu] | intelligently render media files\n| [torrent-discovery][torrent-discovery] | [![][torrent-discovery-ti]][torrent-discovery-tu] | [![][torrent-discovery-ni]][torrent-discovery-nu] | find peers via dht and tracker\n| [ut_metadata][ut_metadata] | [![][ut_metadata-ti]][ut_metadata-tu] | [![][ut_metadata-ni]][ut_metadata-nu] | metadata for magnet uris (protocol extension)\n| [ut_pex][ut_pex] | [![][ut_pex-ti]][ut_pex-tu] | [![][ut_pex-ni]][ut_pex-nu] | peer discovery (protocol extension)\n\n[webtorrent]: https://github.com/webtorrent/webtorrent\n[webtorrent-gitter-url]: https://gitter.im/webtorrent/webtorrent\n[webtorrent-ti]: https://img.shields.io/travis/webtorrent/webtorrent/master.svg\n[webtorrent-tu]: https://travis-ci.org/webtorrent/webtorrent\n[webtorrent-ni]: https://img.shields.io/npm/v/webtorrent.svg\n[webtorrent-nu]: https://www.npmjs.com/package/webtorrent\n[webtorrent-desktop]: https://webtorrent.io/desktop\n\n[bittorrent-dht]: https://github.com/webtorrent/bittorrent-dht\n[bittorrent-dht-ti]: https://img.shields.io/travis/webtorrent/bittorrent-dht/master.svg\n[bittorrent-dht-tu]: https://travis-ci.org/webtorrent/bittorrent-dht\n[bittorrent-dht-ni]: https://img.shields.io/npm/v/bittorrent-dht.svg\n[bittorrent-dht-nu]: https://www.npmjs.com/package/bittorrent-dht\n\n[bittorrent-peerid]: https://github.com/webtorrent/bittorrent-peerid\n[bittorrent-peerid-ti]: https://img.shields.io/travis/webtorrent/bittorrent-peerid.svg\n[bittorrent-peerid-tu]: https://travis-ci.org/webtorrent/bittorrent-peerid\n[bittorrent-peerid-ni]: https://img.shields.io/npm/v/bittorrent-peerid.svg\n[bittorrent-peerid-nu]: https://www.npmjs.com/package/bittorrent-peerid\n\n[bittorrent-protocol]: https://github.com/webtorrent/bittorrent-protocol\n[bittorrent-protocol-ti]: https://img.shields.io/travis/webtorrent/bittorrent-protocol/master.svg\n[bittorrent-protocol-tu]: https://travis-ci.org/webtorrent/bittorrent-protocol\n[bittorrent-protocol-ni]: https://img.shields.io/npm/v/bittorrent-protocol.svg\n[bittorrent-protocol-nu]: https://www.npmjs.com/package/bittorrent-protocol\n\n[bittorrent-tracker]: https://github.com/webtorrent/bittorrent-tracker\n[bittorrent-tracker-ti]: https://img.shields.io/travis/webtorrent/bittorrent-tracker/master.svg\n[bittorrent-tracker-tu]: https://travis-ci.org/webtorrent/bittorrent-tracker\n[bittorrent-tracker-ni]: https://img.shields.io/npm/v/bittorrent-tracker.svg\n[bittorrent-tracker-nu]: https://www.npmjs.com/package/bittorrent-tracker\n\n[create-torrent]: https://github.com/webtorrent/create-torrent\n[create-torrent-ti]: https://img.shields.io/travis/webtorrent/create-torrent/master.svg\n[create-torrent-tu]: https://travis-ci.org/webtorrent/create-torrent\n[create-torrent-ni]: https://img.shields.io/npm/v/create-torrent.svg\n[create-torrent-nu]: https://www.npmjs.com/package/create-torrent\n\n[magnet-uri]: https://github.com/webtorrent/magnet-uri\n[magnet-uri-ti]: https://img.shields.io/travis/webtorrent/magnet-uri/master.svg\n[magnet-uri-tu]: https://travis-ci.org/webtorrent/magnet-uri\n[magnet-uri-ni]: https://img.shields.io/npm/v/magnet-uri.svg\n[magnet-uri-nu]: https://www.npmjs.com/package/magnet-uri\n\n[parse-torrent]: https://github.com/webtorrent/parse-torrent\n[parse-torrent-ti]: https://img.shields.io/travis/webtorrent/parse-torrent/master.svg\n[parse-torrent-tu]: https://travis-ci.org/webtorrent/parse-torrent\n[parse-torrent-ni]: https://img.shields.io/npm/v/parse-torrent.svg\n[parse-torrent-nu]: https://www.npmjs.com/package/parse-torrent\n\n[render-media]: https://github.com/feross/render-media\n[render-media-ti]: https://img.shields.io/travis/feross/render-media/master.svg\n[render-media-tu]: https://travis-ci.org/feross/render-media\n[render-media-ni]: https://img.shields.io/npm/v/render-media.svg\n[render-media-nu]: https://www.npmjs.com/package/render-media\n\n[torrent-discovery]: https://github.com/webtorrent/torrent-discovery\n[torrent-discovery-ti]: https://img.shields.io/travis/webtorrent/torrent-discovery/master.svg\n[torrent-discovery-tu]: https://travis-ci.org/webtorrent/torrent-discovery\n[torrent-discovery-ni]: https://img.shields.io/npm/v/torrent-discovery.svg\n[torrent-discovery-nu]: https://www.npmjs.com/package/torrent-discovery\n\n[ut_metadata]: https://github.com/webtorrent/ut_metadata\n[ut_metadata-ti]: https://img.shields.io/travis/webtorrent/ut_metadata/master.svg\n[ut_metadata-tu]: https://travis-ci.org/webtorrent/ut_metadata\n[ut_metadata-ni]: https://img.shields.io/npm/v/ut_metadata.svg\n[ut_metadata-nu]: https://www.npmjs.com/package/ut_metadata\n\n[ut_pex]: https://github.com/webtorrent/ut_pex\n[ut_pex-ti]: https://img.shields.io/travis/webtorrent/ut_pex.svg\n[ut_pex-tu]: https://travis-ci.org/webtorrent/ut_pex\n[ut_pex-ni]: https://img.shields.io/npm/v/ut_pex.svg\n[ut_pex-nu]: https://www.npmjs.com/package/ut_pex\n\n#### Enable debug logs\n\nIn **node**, enable debug logs by setting the `DEBUG` environment variable to the name of the\nmodule you want to debug (e.g. `bittorrent-protocol`, or `*` to print **all logs**).\n\n```bash\nDEBUG=* webtorrent\n```\n\nIn the **browser**, enable debug logs by running this in the developer console:\n\n```js\nlocalStorage.debug = '*'\n```\n\nDisable by running this:\n\n```js\nlocalStorage.removeItem('debug')\n```\n\n### License\n\nMIT. Copyright (c) [Feross Aboukhadijeh](https://feross.org) and [WebTorrent, LLC](https://webtorrent.io).\n", "release_dates": []}, {"name": "windows-installer", "description": "Build Windows Installers for Electron apps", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Electron Installer\n\n[![AppVeyor Build status](https://ci.appveyor.com/api/projects/status/nxhep80va4d7afjb/branch/master?svg=true)](https://ci.appveyor.com/project/kevinsawicki/windows-installer/branch/master)\n[![Travis CI Build Status](https://travis-ci.org/electron/windows-installer.svg?branch=master)](https://travis-ci.org/electronjs/windows-installer)\n\nNPM module that builds Windows installers for\n[Electron](https://github.com/atom/electron) apps using\n[Squirrel](https://github.com/Squirrel/Squirrel.Windows).\n\n## Installing\n\n```sh\nnpm install --save-dev muon-winstaller\n```\n\n## Usage\n\nRequire the package:\n\n```js\nvar electronInstaller = require('muon-winstaller');\n```\n\nThen do a build like so..\n\n```js\nresultPromise = electronInstaller.createWindowsInstaller({\n    appDirectory: '/tmp/build/my-app-64',\n    outputDirectory: '/tmp/build/installer64',\n    authors: 'My App Inc.',\n    exe: 'myapp.exe'\n  });\n\nresultPromise.then(() => console.log(\"It worked!\"), (e) => console.log(`No dice: ${e.message}`));\n```\n\nAfter running you will have an `.nupkg`, a\n`RELEASES` file, and a `.exe` installer file in the `outputDirectory` folder\nfor each multi task target given under the config entry.\n\nThere are several configuration settings supported:\n\n| Config Name           | Required | Description |\n| --------------------- | -------- | ----------- |\n| `appDirectory`        | Yes      | The folder path of your Electron app |\n| `outputDirectory`     | No       | The folder path to create the `.exe` installer in. Defaults to the `installer` folder at the project root. |\n| `loadingGif`          | No       | The local path to a `.gif` file to display during install. |\n| `authors`             | Yes      | The authors value for the nuget package metadata. Defaults to the `author` field from your app's package.json file when unspecified. |\n| `owners`              | No       | The owners value for the nuget package metadata. Defaults to the `authors` field when unspecified. |\n| `exe`                 | No       | The name of your app's main `.exe` file. This uses the `name` field in your app's package.json file with an added `.exe` extension when unspecified. |\n| `description`         | No       | The description value for the nuget package metadata. Defaults to the `description` field from your app's package.json file when unspecified. |\n| `version`             | No       | The version value for the nuget package metadata. Defaults to the `version` field from your app's package.json file when unspecified. |\n| `title`               | No       | The title value for the nuget package metadata. Defaults to the `productName` field and then the `name` field from your app's package.json file when unspecified. |\n| `name`                | No      | Windows Application Model ID (appId). Defaults to the `name` field in your app's package.json file. |\n| `certificateFile`     | No       | The path to an Authenticode Code Signing Certificate |\n| `certificatePassword` | No       | The password to decrypt the certificate given in `certificateFile` |\n| `signWithParams`      | No       | Params to pass to signtool.  Overrides `certificateFile` and `certificatePassword`. |\n| `iconUrl`             | No       | A URL to an ICO file to use as the application icon (displayed in Control Panel > Programs and Features). Defaults to the Atom icon. |\n| `setupIcon`           | No       | The ICO file to use as the icon for the generated Setup.exe |\n| `setupExe`            | No       | The name to use for the generated Setup.exe file |\n| `setupMsi`            | No       | The name to use for the generated Setup.msi file |\n| `noMsi`               | No       | Should Squirrel.Windows create an MSI installer? |\n| `remoteReleases`      | No       | A URL to your existing updates. If given, these will be downloaded to create delta updates |\n| `remoteToken`         | No       | Authentication token for remote updates |\n\n## Sign your installer or else bad things will happen\n\nFor development / internal use, creating installers without a signature is okay, but for a production app you need to sign your application. Internet Explorer's SmartScreen filter will block your app from being downloaded, and many anti-virus vendors will consider your app as malware unless you obtain a valid cert.\n\nAny certificate valid for \"Authenticode Code Signing\" will work here, but if you get the right kind of code certificate, you can also opt-in to [Windows Error Reporting](http://en.wikipedia.org/wiki/Windows_Error_Reporting). [This MSDN page](http://msdn.microsoft.com/en-us/library/windows/hardware/hh801887.aspx) has the latest links on where to get a WER-compatible certificate. The \"Standard Code Signing\" certificate is sufficient for this purpose.\n\n## Handling Squirrel Events\n\nSquirrel will spawn your app with command line flags on first run, updates,\nand uninstalls. it is **very** important that your app handle these events as _early_\nas possible, and quit **immediately** after handling them. Squirrel will give your\napp a short amount of time (~15sec) to apply these operations and quit.\n\nThe [electron-squirrel-startup](https://github.com/mongodb-js/electron-squirrel-startup) module will handle\nthe most common events for you, such as managing desktop shortcuts.  Just\nadd the following to the top of your `main.js` and you're good to go:\n\n```js\nif (require('electron-squirrel-startup')) return;\n```\n\nYou should handle these events in your app's `main` entry point with something\nsuch as:\n\n```js\nconst app = require('app');\n\n// this should be placed at top of main.js to handle setup events quickly\nif (handleSquirrelEvent()) {\n  // squirrel event handled and app will exit in 1000ms, so don't do anything else\n  return;\n}\n\nfunction handleSquirrelEvent() {\n  if (process.argv.length === 1) {\n    return false;\n  }\n\n  const ChildProcess = require('child_process');\n  const path = require('path');\n\n  const appFolder = path.resolve(process.execPath, '..');\n  const rootAtomFolder = path.resolve(appFolder, '..');\n  const updateDotExe = path.resolve(path.join(rootAtomFolder, 'Update.exe'));\n  const exeName = path.basename(process.execPath);\n\n  const spawn = function(command, args) {\n    let spawnedProcess, error;\n\n    try {\n      spawnedProcess = ChildProcess.spawn(command, args, {detached: true});\n    } catch (error) {}\n\n    return spawnedProcess;\n  };\n\n  const spawnUpdate = function(args) {\n    return spawn(updateDotExe, args);\n  };\n\n  const squirrelEvent = process.argv[1];\n  switch (squirrelEvent) {\n    case '--squirrel-install':\n    case '--squirrel-updated':\n      // Optionally do things such as:\n      // - Add your .exe to the PATH\n      // - Write to the registry for things like file associations and\n      //   explorer context menus\n\n      // Install desktop and start menu shortcuts\n      spawnUpdate(['--createShortcut', exeName]);\n\n      setTimeout(app.quit, 1000);\n      return true;\n\n    case '--squirrel-uninstall':\n      // Undo anything you did in the --squirrel-install and\n      // --squirrel-updated handlers\n\n      // Remove desktop and start menu shortcuts\n      spawnUpdate(['--removeShortcut', exeName]);\n\n      setTimeout(app.quit, 1000);\n      return true;\n\n    case '--squirrel-obsolete':\n      // This is called on the outgoing version of your app before\n      // we update to the new version - it's the opposite of\n      // --squirrel-updated\n\n      app.quit();\n      return true;\n  }\n};\n```\n\nNotice that the first time the installer launches your app, your app will see a ```--squirrel-firstrun``` flag. This allows you to do things like showing up a splash screen or presenting a settings UI. Another thing to be aware of is that, since the app is spawned by squirrel and squirrel acquires a file lock during installation, you won't be able to successfully check for app updates till a few seconds later when squirrel releases the lock.\n\n## Debugging this package\n\nYou can get debug messages from this package by running with the environment variable `DEBUG=muon-winstaller:main` e.g.\n\n```\nDEBUG=muon-winstaller:main node tasks/muon-winstaller.js\n```\n", "release_dates": []}, {"name": "wordpress-well-known", "description": "A plugin that enables \"Well-Known URIs\" support for WordPress (RFC 5785: http://tools.ietf.org/html/rfc5785).", "language": "PHP", "license": null, "readme": null, "release_dates": []}, {"name": "zerotrace", "description": "Go package that provides an implementation of the 0trace traceroute technique to determine the round trip time to a remote client.", "language": "Go", "license": {"key": "mpl-2.0", "name": "Mozilla Public License 2.0", "spdx_id": "MPL-2.0", "url": "https://api.github.com/licenses/mpl-2.0", "node_id": "MDc6TGljZW5zZTE0"}, "readme": "# ZeroTrace\n\n[![GoDoc](https://pkg.go.dev/badge/github.com/brave/zerotrace?utm_source=godoc)](https://pkg.go.dev/github.com/brave/zerotrace)\n\nImagine you run a Web service\nand want to determine the network-layer round trip time to clients\nthat connect to your Web service.\nAn ICMP ping is unlikely to work\nas most home routers don't respond to ICMP echo requests.\nA TCP ping is also unlikely to work\nbecause home routers typically don't respond to unexpected segments\nwith a TCP RST segment.\nIt is generally difficult to get home routers to respond to unsolicited traffic.\n\nThe key insight of the\n[0trace technique](https://seclists.org/fulldisclosure/2007/Jan/145)\nis to piggyback onto an already-established TCP connection\nto conduct a traceroute measurement.\nAs long as the client has an open TCP connection to our Web service,\nwe can inject segments with increasing TTL into the TCP connection.\nFirewalls along the path are more likely to respond to packets\nwith an exceeded TTL if they are part of an established TCP connection.\nWhile this technique may not always make it all the way to the client,\nit tends to get close.\n\nThis Go package implements the 0trace traceroute technique.\nThe API is straightforward:\nInstantiate a new `ZeroTrace` object by calling `NewZeroTrace`.\nThen, start the object by invoking its `Start` method.\nAfterwards, you can invoke the `CalcRTT` method\nby providing the `net.Conn` object of an already-established TCP connection.\n`CalcRTT` returns the round trip time to the client\n(or the hop that's closest) as `time.Duration`, or an error.\n\n## Configuration\n\nZeroTrace's\n[constructor](https://pkg.go.dev/github.com/brave/zerotrace#NewZeroTrace)\nexpects a configuration object as argument.  Take a look at the\n[`Config`](https://pkg.go.dev/github.com/brave/zerotrace#Config)\nstruct to learn more about configuration options.  The function\n[`NewDefaultConfig`](https://pkg.go.dev/github.com/brave/zerotrace#NewDefaultConfig)\nreturns a default configuration object with reasonable defaults.\n\n## Example\n\nUse the code in the [example](example/) directory to get started.\n\n## Development\n\nTo test and lint the code, run:\n\n    make\n", "release_dates": []}]