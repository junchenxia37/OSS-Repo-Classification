[{"name": "auto-emissions", "description": null, "language": "Python", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Solana Automatic Token Emissions\n\n## Introduction\n\nAutoEmissions is Carta for cryptocurrency projects. The product allows a user to manage their Token Emission Schedule and distribute token allocations to various individuals such as employees, advisors, and investors in an automated capacity.\n\n## Quick start\n\n### Setup Environment\n\n1. Clone the repository from <https://github.com/solana-labs/auto-emissions.git>.\n2. Install the latest Solana tools from <https://docs.solana.com/cli/install-solana-cli-tools>. If you already have Solana tools, run `solana-install update` to get the latest compatible version.\n3. Install the latest Rust stable from <https://rustup.rs/>. If you already have Rust, run `rustup update` to get the latest version.\n4. Install the latest Anchor framework from <https://www.anchor-lang.com/docs/installation>. If you already have Anchor, run `avm update` to get the latest version.\n\nRustfmt is used to format the code. It requires `nightly` features to be activated:\n\n5. Install `nightly` rust toolchain. <https://rust-lang.github.io/rustup/installation/index.html#installing-nightly>\n6. Execute `git config core.hooksPath .githooks` to activate pre-commit hooks.\n\n#### [Optional] Vscode setup\n\n1. Install `rust-analyzer` extension\n2. If formatting doesn't work, make sure that `rust-analyzer.rustfmt.extraArgs` is set to `+nightly`\n\n### Build\n\nFirst, generate a new key for the program address with `solana-keygen new -o <PROG_ID_JSON>`. Then replace the existing program ID with the newly generated address in `Anchor.toml` and `programs/auto-emissions/src/lib.rs`.\n\nAlso, ensure the path to your wallet in `Anchor.toml` is correct. Alternatively, when running Anchor deploy or test commands, you can specify your wallet with `--provider.wallet` argument. The wallet's pubkey will be set as an upgrade authority upon initial deployment of the program. It is strongly recommended to make upgrade authority a multisig when deploying to the mainnet.\n\nTo build the program run `anchor build` command from the root `auto-emissions` directory:\n\n```sh\ncd auto-emissions\nanchor build\n```\n\n### Test\n\nUnit tests are executed with the `cargo test` command:\n\n```sh\ncargo test -- --nocapture\n```\n\nIntegration tests can be started as follows:\n\n```sh\nnpm install\nanchor test -- --features test\n```\n\nBy default, integration tests are executed on a local validator, so it won't cost you any SOL.\n\n### Deploy\n\nTo deploy the program to the devnet and upload the IDL use the following commands:\n\n```sh\nanchor deploy --provider.cluster devnet --program-keypair <PROG_ID_JSON>\nanchor idl init --provider.cluster devnet --filepath ./target/idl/auto_emissions.json <PROGRAM ID>\n```\n\n### Initialize\n\nBefore the first use of the AutoEmissions program it must be initialized with the `init` instruction.\n\n## Support\n\nIf you are experiencing technical difficulties while working with the AutoEmissions codebase, open an issue on [Github](https://github.com/solana-labs/auto-emissions/issues). For more general questions about programming on Solana blockchain use [StackExchange](https://solana.stackexchange.com).\n\nIf you find a bug in the code, you can raise an issue on [Github](https://github.com/solana-labs/auto-emissions/issues). But if this is a security issue, please don't disclose it on Github or in public channels. Send information to defi@solana.com instead.\n\n## Contributing\n\nContributions are very welcome. Please refer to the [Contributing](https://github.com/solana-labs/solana/blob/master/CONTRIBUTING.md) guidelines for more information.\n\n## License\n\nSolana AutoEmissions codebase is released under [Apache License 2.0](LICENSE).\n\n## Disclaimer\n\nBy accessing or using Solana AutoEmissions or any of its components, you accept and agree with the [Disclaimer](DISCLAIMER.md).\n", "release_dates": []}, {"name": "bench-tps-dos-test", "description": "UDP and QUIC dos test for buildkite using bench-tps utility", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# bench-tps-dos Test \nThis is a implementation for\n[bench-tps-dos gist](https://gist.github.com/joeaba/aba74e87dcd45c132a1ba2ddcaa2af7c)\n\n## Usage\n    Check  bench-tps-dos-QUIC & bench-tps-dos-UDP in buildkite.\n\n## Environment in buildkite example\n```\n  TEST_TYPE: \"QUIC\"         # This will show on report\n  GIT_TOKEN: \"xxxxx\"     \n  BUILD_SOLANA: \"true\"\n  SOLANA_BUILD_BRANCH: \"master\"  # same-as-cluster / master /v1.10 / v1.10.32 ...\n  # api.inernal\n  NDPOINT: \"http://123.123.123.123\"\n  NUM_CLIENT: 2\n  SLACK_WEBHOOK: \"\"\n  USE_TPU_CLIENT: \"false\"\n  TPU_DISABLE_QUIC: \"false\" # add --tpu-disable-quic\n  DURATION: 1800\n  TX_COUNT: 2000\n  THREAD_BATCH_SLEEP_MS: 10\n  SUSTAINED: \"true\"\n  KEYPAIR_FILE: \"xxxx.yaml\"\n  KEEP_INSTANCES: \"true\"  # do not delete instances after bench-tps test\n```\n+ Mandatory: ENDPOINT / NUM_CLIENT / SLACK_WEBHOOK / TEST_TYPE\n+ BUILD_SOLANA: \"true\" to build bench-tps from solana source\n+ SOLANA_BUILD_BRANCH: git checkout branch/version to build solana (same-as-cluster/master/v1.10.32/10.1 ...etc.) default: same-as-cluster\n+ AVAILABLE_ZONE: zones to create google cloud instance. (Be aware of quota issue)\n+ NUM_CLIENT: 10 (default 10 for QUIC & 1 for UDP)\n+ USE_TPU_CLIENT/DURATION/TX_COUNT/SUSTAINED/THREAD_BATCH_SLEEP_MS arguments for bench-tps\n+ KEYPAIR_FILE: keypair_files to use\n\n## Flow\n+ creates NUM_CLIENT google clound instances \n+ builds solana to use the latest bench-tps (option)\n    + use BUILD_SOLANA=true to enable\n    + downloads and builds https://github.com/solana-labs/solana\n    + waits for NUM_CLIENT finishing build (blocking)\n+ starts UDP/QUIC bench-tps DOS test by runing scripts in the instances\n+ analyzes data by querying influxcloud\n+ sends report to slack channel(SLACK_WEBHOOK)\n\n## Files\n+ dos-run.sh \n    Main process. To prepare environment variables, create google cloud instances, run benchmark and generate a report then send to slack\n+ start-build-solana.sh\n    The script downloads and builds solana \n+ start-dos-test.sh\n    The script runs bench-tps DOS test in dynamically created gc instances\n+ exec-start-template.sh \n    This file is used to generate exec-start-build-solana.sh to execute start-build-solana.sh \n    This file is used to generate exec-start-dos-test.sh to execute start-dos-test.sh \n+ dos-report-env.sh \n    The script is stored in bench-tps-dos bucket. It is downloaded by start-dos-test.sh. It has confidential environment for executing start-dos-test.sh\n+ dos-report.sh\n    The script generates a report from influxCloud and send it to a slack channel\n+ influx_data.sh\n    The script stores flux commands.\n\n## Files in cloud storage\n    Private files are stored in bench-tps-dos bucket in cloud storage.\n    + environment variables for report\n    + a key to ssh to dynamically created google cloud instances\n    + keypair files for bench-tps\n    + key for bench-tps\n\n\n", "release_dates": []}, {"name": "break", "description": "Break Solana Game", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "## Break Solana Game [![Build Status](https://github.com/solana-labs/break/actions/workflows/break_action.yml/badge.svg?branch=main)](https://github.com/solana-labs/break/actions/workflows/break_action.yml/badge.svg?branch=main)\n\n### How it works\n\nThe Break Solana Game consists of a 3 parts: a web client frontend, a web server backend, and an on-chain Solana program. The web server backend\nis not strictly required but it helps with certain performance improvements.\n\nAt a basic level, the Break Solana Game allows a player to send simple smart contract transactions as fast as they can to showcase Solana's speed.\nThe web frontend is responsible for creating, sending, and confirming transactions and displays the status of each transaction in a colored grid.\nThe web backend helps out by acting as a fast relay for transactions. It will forward transactions directly to the TPU (transaction processing unit)\nUDP port of the current cluster leader node (typically transactions are first sent to an RPC API node for forwarding). It also helps by creating a\nsupply of game accounts ahead of time to speed up game setup time (these accounts can be tracked across server restarts using Redis).\n\nRather than subscribing to each transaction signature, the web client subscribes to account data updates. Each transaction will set a bit in the state\nwithin a Break program account, so each transaction can be uniquely identified by the bit it sets.\n\n### Prerequisites\n\nSolana CLI Tooling: https://docs.solana.com/cli/install-solana-cli-tools\nFor running this application you need to have [NodeJs](https://nodejs.org/en/) and [NPM](https://www.npmjs.com/).\nWe recommend to use [NVM](https://github.com/creationix/nvm) for managing NodeJs versions\nFor NVM installation please refer to [manual](https://github.com/creationix/nvm#install--update-script)\n\n### Install\n\n```\nnpm install\n```\n\n### Run Server\n\n_Note: If the cluster you connect to doesn't provide a faucet, you will need to supply the server with a payer key. (See 'Configuration' below)._\n\n```\n# Start local node\nsolana-test-validator\n\n# Deploy program to local node\ncd program\ncargo build-bpf\nsolana program deploy target/deploy/break_solana_program.so --url localhost\n\n# Connect to local node\ncd server\nnpm run start:dev\n```\n\n#### Configuration\n\nBy default, the Break server will connect to a local node for RPC. To configure this behavior, set the following environment variables when running the server:\n\n##### `PORT`\n\nSet this option to specify the port for the API server. Default is 8080.\n\n```\nPORT=80 npm run start:dev\n```\n\n##### `RPC_URL`\n\nSet this option to connect to a specific remote RPC API server.\n\n```\nRPC_URL=http://api.mainnet-beta.solana.com npm run start:dev\n```\n\n##### `LIVE`\n\nEnable this option to connect to a remote cluster. The default cluster is devnet.\n\n```\nLIVE=true npm run start:dev\n```\n\n##### `CLUSTER`\n\nEnable this option along with `LIVE=true` to connect to a specific remote cluster.\n\n```\nLIVE=true CLUSTER=devnet npm run start:dev\nLIVE=true CLUSTER=testnet npm run start:dev\nLIVE=true CLUSTER=mainnet-beta npm run start:dev\n```\n\n##### `DEPLOYED_PROGRAM_ADDRESS`\n\nSet this option to use an existing loaded Break Solana program rather than load a new version.  If the program doesn't exist, the server will exit with an error.\n\n```\nDEPLOYED_PROGRAM_ADDRESS=<BASE58 ENCODED ADDRESS> npm run start:dev\n```\n\nTo use the Break Solana program that's used on https://break.solana.com, use the following address:\n```\nDEPLOYED_PROGRAM_ADDRESS=BrEAK7zGZ6dM71zUDACDqJnekihmwF15noTddWTsknjC npm run start:dev\n```\n\n##### `SEND_TO_RPC`\n\nEnable this option to send transactions to the RPC API rather than directly to a validator TPU port.\n\n```\nSEND_TO_RPC=true npm run start:dev\n```\n\n### Run Client\n\n```\ncd client\nnpm run start\n```\n\n#### Configuration\n\nClient behavior can be modified with the usage of url parameters.\n\n##### `cluster`\n\nSet this parameter to pick a remote cluster. This parameter is automatically set when using the UI cluster selector.\n\n```\nhttps://break.solana.com/game?cluster=devnet\n```\n\n##### `commitment`\n\nSet this parameter to set the commitment level used for confirming transactions. Default is `'confirmed'` but `'processed'`\nis also supported.\n\n```\nhttps://break.solana.com/game?commitment=processed\n```\n\n##### `debug`\n\nSet this parameter to enable \"debug mode\" which will display a table of confirmation times instead of the colored grid.\n\n```\nhttps://break.solana.com/game?debug\n```\n\n##### `retry`\n\nSet this parameter to disable retrying transactions which have not yet been confirmed. Retry behavior is enabled by default because\nsome transactions will be forwarded to a leader who skips their block slot.\n\n```\nhttps://break.solana.com/game?retry=disabled\n```\n\n##### `split`\n\nSet this parameter to split transactions across multiple payer and program accounts to increase transaction parallelization. Default is 4.\n\n```\nhttps://break.solana.com/game?split=1\n```\n\n##### `test`\n\nSet this parameter to enable \"test mode\" which will automatically send approximately 33 transactions per second.\n\n```\nhttps://break.solana.com/game?test\n```\n\n## Built With\n\n- [React](https://github.com/facebook/react/) - Framework\n- [TypeScript](https://www.typescriptlang.org/) - Primary language\n- [Torus](https://tor.us/) - Wallet Key Management\n", "release_dates": []}, {"name": "bridge-adapter", "description": null, "language": "TypeScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Unified Bridge Adapter\n\n## Overview\n\nThe unified bridge adapter SDK solves the challenge of having an increasing number of chains and growing liquidity fragmentation in two ways. By leveraging existing bridge infrastructure to go cross-chain, and by leveraging existing DEXes to increase the total pool of tokens that can be used with these bridge infrastructure.\n\nIf you want to integrate another bridge or DEX into the SDK read the following [document](./BRIDGE_OVERVIEW.md).\n\n### Unifying Existing Bridges\n\nThe unified bridge adapter SDK provides a unified framework for interacting with all the various bridges out there. Instead of having to integrate each bridge 1 by 1, a developer simply needs to integrate this sdk to get the benefit of integrating multiple bridges.\n\n### Leveraging Existing Decentralized Exchanges (DEXes)\n\nWhile leveraging various existing bridges allows us to move more seamlessly between chains, we also leverage existing DEXes to increase the total pool of tokens that can be taken cross chain.\nDevelopers simply integrate a single SDK and get the combined benefits of the existing bridges and DEXes that exist today.\n\n## Features\n\nThis section covers the existing bridges available and how this package attempts to unify the various bridges out there into a unified interface that is easily extensible while still providing a great developer experience.\n\n### Chains\n\nAs of today, this bridge supports swapping and bridging tokens between 7 chains. Your Mileage might vary depending on which bridges you want to use.\n\n- Ethereum\n- Polygon\n- Solana\n- Arbitrum\n- Optimism\n- Binance Smart Chain\n- Avalanche\n\n### Bridges\n\nThe SDK supports 3 bridges out of the box. You can choose any of them.\n\n- Wormhole\n- DeBridge\n- Mayan Finance\n- Allbridge Core (WIP)\n- Allbridge Classic (WIP)\n\n### Supported DEXes\n\nThe SDK supports 4 DEXes out of the box that is integrated with the various bridges.\n\nUnfortunately, there is no way to select specific DEXes to use right now. The SDK will automatically select the best DEX to use based on the token pair and the amount being swapped.\n\n- Paraswap (EVM)\n- 1inch (EVM)\n- Jupiter (Solana)\n- Prism (Solana)\n\n## Terminology\n\nThis section goes over some quick basic terminology that might be useful.\n\n### Source and Target\n\nThe source refers to what the user starts on. We use terms like source token, source chain etc. freely\nTarget refers to where the user wants to end up in. We use terms like target token, target chain etc. freely\nNote that Source and Target might well be the same chain or token.\n\n### Accounts and Wallets and Signers\n\nAll these refer to an owner who has the ability to sign for a transaction. For the most part, we use terms like source account, target account etc. freely.\nDue to the proliferation of various packages in the space, we might inevitably refer to these accounts as wallets or signers, but know that they are referring to the same thing unless explicitly stated otherwise.\n\n## API overview\n\nDevelopers interact directly with a high level BridgeSdk that abstracts away the underlying implementation for the various bridge implementation.\n\n### Goals\n\n- The developer can allow users to easily bridge assets from one chain to another within their app\n- Developers can easily get users to pay them from tokens on another chain while still receiving the expected assets on the target chain\n- Great DX for developers. Interruptions should be handled. Errors should be graceful and human readable.\n\n### React SDK\n\nThe react package allows you to easily integrate the core BridgeAdapterSdk into your React application with a UI.\n\n#### Installation\n\n```bash\npnpm add @solana/bridge-adapter-debridge-adapter\npnpm add @solana/bridge-adapter-wormhole-adapter\npnpm add @solana/bridge-adapter-react\npnpm add @solana/bridge-adapter-react-ui\n```\n\n#### Initializing the SDK\n\nOnce you install the SDK, you can integrate it into your code like so:\n\n```typescript\n\"use client\";\nimport \"@solana/bridge-adapter-react-ui/index.css\";\nimport {\n  BridgeAdapterProvider,\n  EvmWalletProvider,\n  SolanaWalletProvider,\n} from \"@solana/bridge-adapter-react\";\nimport { BridgeAdapter } from \"@solana/bridge-adapter-react-ui\";\nimport { DeBridgeBridgeAdapter } from \"@solana/bridge-adapter-debridge-adapter/esm\";\nimport { WormholeBridgeAdapter } from \"@solana/bridge-adapter-wormhole-adapter/esm\";\n\nexport function HomePage() {\n  return (\n    <SolanaWalletProvider wallets={[/* list of desired wallets */]}>\n      <EvmWalletProvider\n        coinbaseWalletSettings={/* settings */}\n        walletConnectProjectId={/* walletConnect id */}\n      >\n        <BridgeAdapterProvider\n          adapters={[/* needed bridges, for ex.: */ DeBridgeBridgeAdapter, WormholeBridgeAdapter]}\n        >\n          <BridgeAdapter title=\"Bridge Adapter\" />\n        </BridgeAdapterProvider>\n      </EvmWalletProvider>\n    </SolanaWalletProvider>\n  );\n}\n```\n\nFor more details on the respective components, see theirs sources or try the demo application at `/apps`.\n\n#### Integrating with `wagmi`\n\nThe only thing you have to do when integrating with `wagmi` is to omit the `EvmWalletProvider`. This is because in using `wagmi`, you already wrap your app in a wagmi client which is what `EvmWalletProvider` uses under the hood.\n\n#### Inegrating with @solana/wallet-adapter-react\n\nSimilarly, for integrating with `@solana/wallet-adapter-react`, you have to omit the `SolanaWalletProvider`. This is because in using `@solana/wallet-adapter-react` you already wrap your app in a `WalletProvider` which is what `SolanaWalletProvider` uses under the hood.\n\n#### API\n\n##### Bridge Adapter Dialog\n\nThe `BridgeAdapterDialog` forms the core of the React SDK. It attaches an `onClick` handler to a child element that is responsible for opening the modal when clicked.\n\nNote: You might also integrate the SDK to you app without the dialog component. See the example at `react-ui` stories.\n\n```tsx\nimport { BridgeAdapterDialog } from \"@solana/bridge-adapter-react-ui\";\n// Note that you have to import this wherever you import your global css stylesheet\n// put this before your own stylesheet in case you want to override certain variables\nimport \"@solana/bridge-adapter-react-ui/index.css\";\n\n<BridgeAdapterDialog theme=\"dark\">\n  <Button>Open</Button>\n</BridgeAdapterDialog>;\n```\n\n###### Advance styling\n\nIf you want more than the light and dark theme included, you can easilyl override the given style with your own.\n\nBelow are the following variables that you can override. The values in HSL format are the current default for `light` mode.\n\nTo override the dark mode theme, simply wrap the variables in the `bsa-dark` selector.\n\n```css\n--bsa-background: 224 71% 4%;\n--bsa-foreground: 213 31% 91%;\n\n--bsa-muted: 223 47% 11%;\n--bsa-muted-foreground: 215.4 16.3% 56.9%;\n\n--bsa-accent: 216 34% 17%;\n--bsa-accent-foreground: 210 40% 98%;\n\n--bsa-popover: 224 71% 4%;\n--bsa-popover-foreground: 215 20.2% 65.1%;\n\n--bsa-border: 216 34% 17%;\n--bsa-input: 216 34% 17%;\n\n--bsa-card: 224 71% 4%;\n--bsa-card-foreground: 213 31% 91%;\n\n--bsa-primary: 210 40% 98%;\n--bsa-primary-foreground: 222.2 47.4% 1.2%;\n\n--bsa-secondary: 222.2 47.4% 11.2%;\n--bsa-secondary-foreground: 210 40% 98%;\n\n--bsa-destructive: 0 63% 31%;\n--bsa-destructive-foreground: 210 40% 98%;\n\n--bsa-ring: 216 34% 17%;\n```\n\n\n##### `BridgeAdapterProvider`\n\nThe `BridgeAdapterProvider` is used to hold the values that would be used to instantiate the underlying `BridgeSdk`.\n\n###### Usage\n\n```tsx\nimport { BridgeAdapterProvider } from \"@solana/bridge-adapter-react\";\n\n<BridgeAdapterProvider\n  adapters=[/* desired bridge adapters */]\n  settings={{\n    evm: {\n      alchemyApiKey: process.env.NEXT_PUBLIC_ALCHEMY_API_KEY ?? \"\",\n      infuraApiKey: process.env.NEXT_PUBLIC_INFURA_PROJECT_ID ?? \"\",\n    },\n    solana: {\n      solanaRpcUrl: process.env.NEXT_PUBLIC_SOLANA_RPC_URL ?? \"\",\n    },\n  }}\n  sourceChain=\"Ethereum\"\n  targetChain=\"Solana\"\n>\n  <BridgeAdapterDialog>\n    <Button>Open</Button>\n  </BridgeAdapterDialog>\n</BridgeAdapterProvider;\n```\n\n##### `EvmWalletProvider`\n\nThis provider is only needed if your app does not currently use [`wagmi`](https://wagmi.sh/) already.\n\n###### Usage\n\n```tsx\nimport { EvmWalletProvider } from \"@solana/bridge-adapter-react\";\n\n<EvmWalletProvider\n  coinbaseWalletSettings={{\n    appName: \"Example Defi Dapp\",\n  }}\n  walletConnectProjectId={process.env.NEXT_PUBLIC_WALLET_CONNECT_PROJECT_ID ?? \"\"}\n>\n  <BridgeAdapterProvider>\n    <BridgeAdapterDialog>\n      <Button>Open</Button>\n    </BridgeAdapterDialog>\n  </BridgeAdapterProvider>\n</EvmWalletProvider>;\n```\n\n##### `SolanaWalletProvider`\n\nThis provider is only needed if your app does not currently use [`@solana/wallet-adapter-react`](https://github.com/solana-labs/wallet-adapter) already.\n\n###### Usage\n\n```tsx\nimport { SolanaWalletProvider } from \"@solana/bridge-adapter-react\";\n\n<SolanaWalletProvider wallets={adapters} autoConnect={false}>\n  <BridgeAdapterProvider>\n    <BridgeAdapterDialog>\n      <Button>Open</Button>\n    </BridgeAdapterDialog>\n  </BridgeAdapterProvider>\n</SolanaWalletProvider>;\n```\n\n###### Configurations\n\nSee more details about the props to the `SolanaWalletProvider`. See the props pass into the `WalletProvider` [here](https://github.com/solana-labs/wallet-adapter/blob/master/APP.md).\n\nFor convinience, here is the interface:\n\n```typescript\ninterface SolanaWalletProviderProps {\n  children: ReactNode;\n  autoConnect?: boolean;\n  localStorageKey?: string;\n  onError?: (error: WalletError, adapter?: Adapter) => void;\n  wallets?: Adapter[];\n  rpcUrl?: string;\n}\n```\n\n### End User vanilla JS SDK usage details\n\n#### Get Started\n\nTo get started, grab the vanilla Javascript NPM package\n```bash\npnpm add @solana/bridge-adapter-base\n```\n\nOnce you install the SDK, you can instantiate the SDK and begin using it like so:\n\n```typescript\nimport { BridgeAdapterSdk } from \"@solana/bridge-adapter-base\";\n \nconst sdk = new BridgeAdapterSdk({\n  sourceChain: \"\",\n  targetChain: \"\",\n});\n \nconst chains = await sdk.getSupportedChains(); // ['Ethereum', 'Avalanche', 'Solana', ...]\n \n// contrived for the example\nconst sourceChain = 'Ethereum';\nconst targetChain = 'Solana';\n \nconst supportedSourceTokens = await sdk.getSupportedTokens(\"source\", {\n  sourceChain,\n});\nconst supportedTargetTokens = await sdk.getSupportedTokens(\"target\", {\n  targetChain,\n});\n \n// contrived for the example\nconst tokenToSwapFrom = supportedSourceTokens[0];\nconst tokenToSwapTo = supportedTargetTokens[0];\n \nconst swapRoutes = await sdk.getSwapInformation({\n    ...tokenToSwapFrom,\n    // contrived\n    selectedAmountInBaseUnits: \"1000000\";\n    selectedAmountFormatted: \"1\";\n  },\n  tokenToSwapTo\n);\n \nconst isSuccess = sdk.bridge({\n  sourceAccount: walletClientFromViemSomehow,\n  targetAccount: {\n    signTransaction(transaction) => {\n      // sign the transaction and return the signed transaction\n    },\n    publicKey: new PublicKey(\"\") // public key of the account that signed the transaction\n  },\n  swapRoutes[0],\n  onStatusUpdate(update) {\n    console.log(update)\n  },\n});\n```\n\n#### Bridge Adapter SDK usage\n\n##### Getting supported chains\n\nThis function returns the list of chains supported by all the bridges that is being used under the hood.\n\n###### Usage\n\n```typescript\nconst chains = await sdk.getSupportedChains(); // ['Ethereum', 'Avalanche', 'Solana', ...]\n```\n\n###### Currently supported chains\n\nThe `chains` variable returned is of type `ChainName[]`, which correspond to one of the following chain names:\n\n```typescript\nexport const CHAIN_NAMES = [\n    \"Ethereum\",\n    \"Solana\",\n    \"Polygon\",\n    \"Avalanche\",\n    \"Arbitrum\",\n    \"Optimism\",\n\"BSC\",\n] as const;\n\nexport type ChainName = typeof CHAIN_NAMES[number];\n```\n\n##### Getting supported tokens\n\nThis function returns the list of tokens that is available for swapping and bridging across all the bridges and DEXes.\n\n###### Usage\n\n```typescript\n// getting tokens to swap from\nconst sourceTokens = await sdk.getSupportedTokens(\n  \"source\",\n  {\n    sourceChain,\n    targetChain, //optional\n  },\n  // this is optional\n  {\n    sourceToken,\n    targetToken,\n  }\n);\nconsole.log(\"sourceTokens\", sourceTokens);\n\n// getting tokens to swap to\nconst targetTokens = await sdk.getSupportedTokens(\n  \"target\",\n  {\n    sourceChain, //optional\n    targetChain,\n  },\n  // this is optional\n  {\n    sourceToken,\n    targetToken,\n  }\n);\nconsole.log(\"targetTokens\", targetTokens);\n```\n\n###### Return Type\n\nThe return type is an array of `Token` objects. The `Token` object is defined as follows:\n\n```typescript\nexport type Token = {\n  logoUri: string;\n  name: string;\n  symbol: string;\n  address: string;\n  decimals: number;\n  chain: ChainName;\n  bridgeNames: Bridges[];\n};\n```\n\n##### Getting the routes for a source-target token pair\n\n###### Usage\n\n```typescript\nconst swapRoutes = await sdk.getSwapInformation({\n    ...sourceToken,\n    // contrived\n    selectedAmountInBaseUnits: \"1000000\";\n    selectedAmountFormatted: \"1\";\n  },\n  targetToken\n);\n\nconsole.log(\"swapRoutes\", swapRoutes);\n```\n\n###### Return Type\n\n```typescript\n// Note the various token types all have the expected info, such as decimals, symbol, names etc.\n// They vary only in the extra params that is specific to the token type.\nexport type SwapInformation = {\n  sourceToken: TokenWithAmount;\n  targetToken: TokenWithExpectedOutput;\n  bridgeName: string;\n  tradeDetails: {\n    fee: FeeToken[];\n    priceImpact: number;\n    estimatedTimeMinutes: number;\n    routeInformation: {\n      fromTokenSymbol: string;\n      toTokenSymbol: string;\n    }[];\n  };\n};\n```\n\n##### Bridging or Swapping the Assets\n\nThis function will take in a `SwapInformation` after you chose the route and initiate the bridging of the assets. It will return `true` if the bridging was successful. If it was not successful, this function _will throw_ and you can see the error in the console.\n\n###### Usage\n\n```typescript\nconst isSuccess = sdk.bridge({\n  sourceAccount,\n  targetAccount,\n  swapsInformation[0], // this is from sdk.getSwapInformation above\n  onStatusUpdate,\n});\n\nconsole.log(\"isSuccess\", isSuccess);\n```\n", "release_dates": []}, {"name": "browser-extension", "description": "Solana Chrome Extension", "language": "TypeScript", "license": null, "readme": "# Solana Wallet - Browser Extension\n\n## Development\n\n```\nyarn install\nyarn start\n```\n\n**Note** You can safely discard the browser page opening on `localhost:3000` (we tried to disable it but did not succeed yet)\n\nIn this mode, each time you save a file, development server will re-compile the files and you can\nsimply reload to see the changes (no need to unload).\n\nFor background page, from the `Inspect` view, simply hit reload shortcut (`\u2318-R` on Apple, or `Ctrl-R`). For the popup,\neither close it and re-open or from `Inspect` view, hit reload shortcut (same as above).\n\n### Add extension to Chrome\n\n**Important** Unload any previously loaded Solana Wallet extension, only one extension can be loaded at one time.\n\n- Go to chrome://extensions\n- Enable developer mode\n- Click \"Load Unpacked\"\n- Browse to this project `./dist`, hit select\n\n### Open Extensions Pages (Chrome only)\n\nYou can open background and popup page (in full view) using simply:\n\n```\n./bin/open_ext.sh <extension_id>\n```\n\nWhere `<extension_id>` is the value reported by Chrome Extension manager for you loaded unpacked extension.\nTo ease your life, you can also define `SOLANA_EXTENSION_ID` as an enviornment variable and it will be use as\nthe default value for `<extension_id>` parameter, so you can do `./bin/open_ext.sh`.\n\n## Production\n\n```\nyarn install\nyarn build\n```\n\n### Add extension to Chrome\n\n**Important** Unload any previously loaded Solana Wallet extension, only one extension can be loaded at one time.\n\n- Go to chrome://extensions\n- Enable developer mode\n- Click \"Load Unpacked\"\n- Browse to this project `./build`, hit select\n\n## Configuring IDE\n\n### Prettier\n\nThis project expects all contributors to have a suitable format on save that uses Prettier\nconfig to run.\n\nFollow the links IDE to fromat on save using Prettier:\n\n- [VSCode](https://prettier.io/docs/en/editors.html#visual-studio-code)\n- [WebStorm](https://prettier.io/docs/en/webstorm.html#running-prettier-on-save-using-file-watcher)\n- [Emacs](https://prettier.io/docs/en/editors.html#emacs)\n- [Vim](https://prettier.io/docs/en/editors.html#vim)\n- [Others](https://prettier.io/docs/en/editors.html)\n\n## Enable debug\n\n- Open chrome dev tools (background, popup or content-script)\n- Go to Application\n- Add a Local Storage entry: Key:debug, Value:\\*\n\n## Disable JS minification\n\n`config.optimization.minimize = false` in `rewire-webex.js`\n\n## Usage\n\n```ts\n// @ts-ignore\nimport bs58 from \"bs58\"\nimport { Connection, LAMPORTS_PER_SOL, PublicKey, SystemProgram } from \"@solana/web3.js\"\n\ntype WalletState = {\n  state: \"locked\" | \"unlocked\" | \"uninitialized\"\n}\n\ntype Cluster = {\n  title: string\n  endpoint: string\n  cluster: string\n}\n\nwindow.addEventListener(\"solana#initialized\", function (event) {\n  // @ts-ignore\n  solana = window.solana\n  solana.on(\"stateChanged\", async (state: WalletState) => {\n    if (state.state === \"unlocked\") {\n      const { cluster } = await solana.request({ method: \"wallet_getCluster\", params: {} })\n      const connection = new Connection(cluster.endpoint)\n\n      await sendTransaction(connection)\n    }\n  })\n})\n\nasync function sendTransaction(connection: Connection) {\n  let { accountResult } = await solana.request({ method: \"wallet_requestAccounts\", params: {} })\n  const accounts = accountResult.accounts as string[]\n\n  const transaction = SystemProgram.transfer({\n    fromPubkey: new PublicKey(accounts[0]),\n    toPubkey: new PublicKey(accounts[0]),\n    lamports: 2 * LAMPORTS_PER_SOL,\n  })\n\n  const { blockhash } = await connection.getRecentBlockhash()\n  transaction.recentBlockhash = blockhash\n\n  const message = bs58.encode(transaction.serializeMessage())\n  const { result } = await solana.request({\n    method: \"wallet_signTransaction\",\n    params: { message: message, signer: accounts },\n  })\n\n  result.signatureResults.forEach((signatureResult: any) => {\n    transaction.addSignature(\n      new PublicKey(signatureResult.publicKey),\n      bs58.decode(signatureResult.signature)\n    )\n  })\n\n  let transactionID = await connection.sendRawTransaction(transaction.serialize())\n  await connection.confirmTransaction(transactionID)\n}\n```\n\nFirst you need to add a window event listener for the event `solana#initialized`. That event will be triggered when the solana extension is done injecting the `solana` client into the `window` object.\n\n```ts\nwindow.addEventListener(\"solana#initialized\", function (event) {\n  solana = window.solana\n})\n```\n\nOnce you got access to the solana client, you should fetch the extension state using `wallet_getState` request.\n\n```ts\nconst { result } = await solana.request({ method: \"wallet_getState\", params: {} })\nif (result.state === \"unlocked\") {\n  // you are now granted to access user accounts\n}\n```\n\nWhen your web application granted with the permission to access users account you can retrieve them using the `wallet_requestAccounts` request.\n\n```ts\nlet { accountResult } = await solana.request({ method: \"wallet_requestAccounts\", params: {} })\nconst accounts = accountResult.accounts as string[]\n```\n\nUse the `wallet_getCluster` request to get the cluster selected by users and set your solana web3 connection accordenly\n\n```ts\nconst { cluster } = await solana.request({ method: \"wallet_getCluster\", params: {} })\n```\n\n`wallet_signTransaction` request is used to sign transaction messages by a list of signer account keys. Signatures need to be added to the transaction from which the message was serialized before being sent as raw using solana web3 connection.\n\n```ts\nconst message = bs58.encode(transaction.serializeMessage())\nconst { result } = await solana.request({\n  method: \"wallet_signTransaction\",\n  params: { message: message, signer: accounts },\n})\n\nresult.signatureResults.forEach((signatureResult: any) => {\n  transaction.addSignature(\n    new PublicKey(signatureResult.publicKey),\n    bs58.decode(signatureResult.signature)\n  )\n})\n```\n\n**_Handling events from extension_**\n\n`stateChanged` event is triggered when extension state change (`uninitialized` | `locked` | `unlocked`). Only when state is `unlocked` then your web application will be able to access the accounts of the user and sign transactions. The state will change to `unlocked` once the user unlocks is wallet and grant your web application access to is accounts.\n\n```ts\nsolana.on(\"stateChanged\", async (state: WalletState) => {\n  if (state.state === \"unlocked\") {\n    // you are now granted to access user accounts\n  }\n})\n```\n\nThe `clusterChanged` event will happen when cluster configuration is changed by the user in the extension. That\u2019s when you should reset your solana web3 connection.\n\n```ts\nsolana.on(\"clusterChanged\", (cluster: Cluster) => {\n  connection = new Connection(cluster.endpoint)\n})\n```\n\nThe `accountsChanged` event is triggered when users add or remove accounts from their wallets from the extension. You will then receive an up-to-date list of account public keys encoded in base58\n\n```ts\nsolana.on(\"accountsChanged\", (updatedAccounts: string[]) => {\n  accounts = updatedAccounts\n})\n```\n", "release_dates": []}, {"name": "buffer-layout", "description": "TypeScript fork of buffer-layout, for translating between JavaScript values and Buffers", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# @solana/buffer-layout\n\n`@solana/buffer-layout` is a TypeScript fork of `buffer-layout`. Same API, just adds types and TypeScript docs.\n\n## Installation\n\nInstall with `npm install @solana/buffer-layout`.\n\nDevelopment and testing is done using Node.js, supporting versions 5.10\nand later.\n\n# buffer-layout\n\n[![NPM version](https://img.shields.io/npm/v/buffer-layout.svg)](https://www.npmjs.com/package/buffer-layout \"View this project on NPM\")\n[![Build Status](https://travis-ci.org/pabigot/buffer-layout.svg?branch=master)](https://travis-ci.org/pabigot/buffer-layout \"Check build status on TravisCI\")\n[![Coverage Status](https://coveralls.io/repos/pabigot/buffer-layout/badge.svg?branch=master&service=github)](https://coveralls.io/github/pabigot/buffer-layout?branch=master \"Check coverage status on Coveralls\")\n\nbuffer-layout is a utility module implemented in pure JavaScript that\nsupports translations between JavaScript values and Buffers.  It is made\navailable through [github](https://github.com/pabigot/buffer-layout) and\nreleased under the MIT license.\n\nLayout support is provided for these types of data:\n\n* Signed and unsigned integral values from 1 to 6 bytes in length, in\n  little-endian or big-endian format;\n* Signed and unsigned 64-bit integral values decoded as integral\n  Numbers;\n* Float and double values (also little-endian or big-endian);\n* Sequences of instances of an arbitrary layout, with constant or\n  data-dependent length;\n* Structures with named fields containing arbitrary layouts;\n* Unions of variant layouts where the type of data is recorded in a\n  prefix value, another layout element, or provided externally;\n* Bit fields within 8, 16, 24, or 32-bit unsigned integers, numbering\n  from the least or most significant bit;\n* NUL-terminated C strings;\n* Blobs of fixed or variable-length raw data.\n\n## Examples\n\nAll examples are from the `test/examples.js` unit test and assume the\nfollowing context:\n\n    const assert = require('assert');\n    const util = require('util');\n    const lo = require('buffer-layout');\n\nThe examples give only a taste of what can be done.  Structures, unions,\nand sequences can nest; [union\ndiscriminators](http://pabigot.github.io/buffer-layout/module-Layout-UnionDiscriminator.html)\ncan be within the union or external to it; sequence and blob lengths may\nbe fixed or read from the buffer.\n\nFor full details see the [documentation](http://pabigot.github.io/buffer-layout/).\n\n### Four-element array of 16-bit signed little-endian integers\n\nThe C definition:\n\n    int16_t arr[4] = { 1, -1, 3, -3 };\n\nThe buffer-layout way:\n\n    const ds = lo.seq(lo.s16(), 4);\n    const b = Buffer.alloc(8);\n    assert.equal(ds.encode([1, -1, 3, -3], b), 4 * 2);\n    assert.equal(Buffer.from('0100ffff0300fdff', 'hex').compare(b), 0);\n    assert.deepEqual(ds.decode(b), [1, -1, 3, -3]);\n\nSee [Int](http://pabigot.github.io/buffer-layout/module-Layout-Int.html)\nand [Sequence](http://pabigot.github.io/buffer-layout/module-Layout-Sequence.html).\n\n### A native C `struct` on a 32-bit little-endian machine\n\nThe C definition:\n\n    struct ds {\n      uint8_t v;\n      uint32_t u32;\n    } st;\n\nThe buffer-layout way:\n\n    const ds = lo.struct([lo.u8('v'),\n                        lo.seq(lo.u8(), 3), // alignment padding\n                        lo.u32('u32')]);\n    assert.equal(ds.offsetOf('u32'), 4);\n    const b = Buffer.alloc(8);\n    b.fill(0xbd);\n    assert.equal(ds.encode({v: 1, u32: 0x12345678}, b), 1 + 3 + 4);\n    assert.equal(Buffer.from('01bdbdbd78563412', 'hex').compare(b), 0);\n    assert.deepEqual(ds.decode(b), {v: 1, u32: 0x12345678});\n\nNote that the C language requires padding which must be explicitly added\nin the buffer-layout structure definition.  Since the padding is not\naccessible, the corresponding layout has no\n[property](http://pabigot.github.io/buffer-layout/module-Layout-Layout.html#property).\n\nSee [Structure](http://pabigot.github.io/buffer-layout/module-Layout-Structure.html).\n\n### A packed C `struct` on a 32-bit little-endian machine\n\nThe C definition:\n\n    struct ds {\n      uint8_t v;\n      uint32_t u32;\n    } __attribute__((__packed__)) st;\n\nThe buffer-layout way:\n\n    const ds = lo.struct([lo.u8('v'),\n                        lo.u32('u32')]);\n    assert.equal(ds.offsetOf('u32'), 1);\n    const b = Buffer.alloc(5);\n    b.fill(0xbd);\n    assert.equal(ds.encode({v: 1, u32: 0x12345678}, b), 1 + 4);\n    assert.equal(Buffer.from('0178563412', 'hex').compare(b), 0);\n    assert.deepEqual(ds.decode(b), {v: 1, u32: 0x12345678});\n\n### A tagged union of 4-byte values\n\nAssume a 5-byte packed structure where the interpretation of the last\nfour bytes depends on the first byte.  The C definition:\n\n    struct {\n      uint8_t t;\n      union ds {\n        uint8_t u8[4];  // default interpretation\n        int16_t s16[2]; // when t is 'h'\n        uint32_t u32;   // when t is 'w'\n        float f32;      // when t is 'f'\n      } u;\n    } __attribute__((__packed__)) un;\n\nThe buffer-layout way:\n\n    const t = lo.u8('t');\n    const un = lo.union(t, lo.seq(lo.u8(), 4, 'u8'));\n    const nul = un.addVariant('n'.charCodeAt(0), 'nul');\n    const u32 = un.addVariant('w'.charCodeAt(0), lo.u32(), 'u32');\n    const s16 = un.addVariant('h'.charCodeAt(0), lo.seq(lo.s16(), 2), 's16');\n    const f32 = un.addVariant('f'.charCodeAt(0), lo.f32(), 'f32');\n    const b = Buffer.alloc(un.span);\n    assert.deepEqual(un.decode(b), {t: 0, u8: [0, 0, 0, 0]});\n    assert.deepEqual(un.decode(Buffer.from('6e01020304', 'hex')),\n                     {nul: true});\n    assert.deepEqual(un.decode(Buffer.from('7778563412', 'hex')),\n                     {u32: 0x12345678});\n    assert.deepEqual(un.decode(Buffer.from('660000bd41', 'hex')),\n                     {f32: 23.625});\n    assert.deepEqual(un.decode(Buffer.from('a5a5a5a5a5', 'hex')),\n                     {t: 0xa5, u8: [0xa5, 0xa5, 0xa5, 0xa5]});\n    assert.equal(s16.encode({s16: [123, -123]}, b), 1 + 2 * 2);\n    assert.equal(Buffer.from('687b0085ff', 'hex').compare(b), 0);\n\nSee [Union](http://pabigot.github.io/buffer-layout/module-Layout-Union.html).\n\n### Decoding into class instances\n\nUsing the same 5-byte packet structure but with JavaScript classes\nrepresenting the union and the variants:\n\n    function Union() { }\n    lo.bindConstructorLayout(Union,\n                             lo.union(lo.u8('t'), lo.seq(lo.u8(), 4, 'u8')));\n\n    function Vn() {}\n    util.inherits(Vn, Union);\n    lo.bindConstructorLayout(Vn,\n                             Union.layout_.addVariant('n'.charCodeAt(0), 'nul'));\n\n    function Vu32(v) { this.u32 = v; }\n    util.inherits(Vu32, Union);\n    lo.bindConstructorLayout(Vu32,\n                             Union.layout_.addVariant('w'.charCodeAt(0), lo.u32(), 'u32'));\n\n    function Vs16(v) { this.s16 = v; }\n    util.inherits(Vs16, Union);\n    lo.bindConstructorLayout(Vs16,\n                             Union.layout_.addVariant('h'.charCodeAt(0), lo.seq(lo.s16(), 2), 's16'));\n\n    function Vf32(v) { this.f32 = v; }\n    util.inherits(Vf32, Union);\n    lo.bindConstructorLayout(Vf32,\n                             Union.layout_.addVariant('f'.charCodeAt(0), lo.f32(), 'f32'));\n\n    let v = Union.decode(Buffer.from('7778563412', 'hex'));\n    assert(v instanceof Vu32);\n    assert(v instanceof Union);\n    assert.equal(v.u32, 0x12345678);\n\n    v = Union.decode(Buffer.from('a5a5a5a5a5', 'hex'));\n    assert(v instanceof Union);\n    assert.equal(v.t, 0xa5);\n    assert.deepEqual(v.u8, [0xa5, 0xa5, 0xa5, 0xa5]);\n\n    const b = Buffer.alloc(Union.layout_.span);\n    v = new Vf32(23.625);\n    v.encode(b);\n    assert.equal(Buffer.from('660000bd41', 'hex').compare(b), 0);\n\n    b.fill(0xFF);\n    v = new Vn();\n    v.encode(b);\n    assert.equal(Buffer.from('6effffffff', 'hex').compare(b), 0);\n\nNote that one variant (`'n'`) carries no data, leaving the remainder of\nthe buffer unchanged when stored.\n\nSee\n[Layout.makeDestinationObject()](http://pabigot.github.io/buffer-layout/module-Layout-Layout.html#makeDestinationObject)\nand\n[bindConstructorLayout](http://pabigot.github.io/buffer-layout/module-Layout.html#.bindConstructorLayout).\n\n### Packed bit fields on a little-endian machine\n\nThe C definition:\n\n    struct ds {\n      unsigned int b00l03: 3;\n      unsigned int flg03: 1;\n      unsigned int b04l18: 24;\n      unsigned int b1Cl04: 4;\n    } st;\n\nThe buffer-layout way:\n\n    const ds = lo.bits(lo.u32());\n    const b = Buffer.alloc(4);\n    ds.addField(3, 'b00l03');\n    ds.addBoolean('flg03');\n    ds.addField(24, 'b04l18');\n    ds.addField(4, 'b1Cl04');\n    b.fill(0xff);\n    assert.equal(ds.encode({b00l03: 3, b04l18: 24, b1Cl04: 4}, b), 4);\n    assert.equal(Buffer.from('8b010040', 'hex').compare(b), 0);\n    assert.deepEqual(ds.decode(b),\n                     {b00l03: 3, flg03: true, b04l18: 24, b1Cl04: 4});\n\nSee [BitStructure](http://pabigot.github.io/buffer-layout/module-Layout-BitStructure.html).\n\n### 64-bit values as Numbers\n\nThe C definition:\n\n    uint64_t v = 0x0102030405060708ULL;\n\nThe buffer-layout way:\n\n    const ds = lo.nu64be();\n    const b = Buffer.from('0102030405060708', 'hex');\n    const v = 72623859790382856;\n    const nv = v - 6;\n    assert.equal(v, nv);\n    assert.equal(ds.decode(b), nv);\n\nNote that because the exact value is not less than 2^53 it cannot be\nrepresented as a JavaScript Number, and is instead approximated by a\nnearby representable integer that is equivalent within Numbers.\n\nSee [NearUInt64](http://pabigot.github.io/buffer-layout/module-Layout-NearUInt64.html).\n\n### A NUL-terminated C string\n\nThe C definition:\n\n    const char str[] = \"hi!\";\n\nThe buffer-layout way:\n\n    const ds = lo.cstr();\n    const b = Buffer.alloc(8);\n    assert.equal(ds.encode('hi!', b), 3 + 1);\n    const slen = ds.getSpan(b);\n    assert.equal(slen, 4);\n    assert.equal(Buffer.from('68692100', 'hex').compare(b.slice(0, slen)), 0);\n    assert.equal(ds.decode(b), 'hi!');\n\nSee [CString](http://pabigot.github.io/buffer-layout/module-Layout-CString.html).\n\n### A fixed-length block of data offset within a buffer\n\nThe buffer-layout way:\n\n    const ds = lo.blob(4);\n    const b = Buffer.from('0102030405060708', 'hex');\n    assert.equal(Buffer.from('03040506', 'hex').compare(ds.decode(b, 2)), 0);\n\nSee [Blob](http://pabigot.github.io/buffer-layout/module-Layout-Blob.html).\n\n### A variable-length array of pairs of C strings\n\nThe buffer-layout way:\n\n    const pr = lo.seq(lo.cstr(), 2);\n    const n = lo.u8('n');\n    const vla = lo.seq(pr, lo.offset(n, -1), 'a');\n    const st = lo.struct([n, vla], 'st');\n    const b = Buffer.alloc(32);\n    const arr = [['k1', 'v1'], ['k2', 'v2'], ['k3', 'etc']];\n    b.fill(0);\n    assert.equal(st.encode({a: arr}, b),\n                 1 + (2 * ((2 + 1) + (2 + 1)) + (2 + 1) + (3 + 1)));\n    const span = st.getSpan(b);\n    assert.equal(span, 20);\n    assert.equal(Buffer.from('036b31007631006b32007632006b330065746300', 'hex')\n                 .compare(b.slice(0, span)), 0);\n    assert.deepEqual(st.decode(b), {n: 3, a: arr});\n\nSee [OffsetLayout](http://pabigot.github.io/buffer-layout/module-Layout-OffsetLayout.html).\n\n### A C flexible array member with implicit length\n\nWhen data is obtained over a packetized interface the length of the\npacket can provide implicit limits on the last field.\n\nThe C definition:\n\n    struct ds {\n      uint8_t prop;\n      uint16_t data[];\n    };\n\nThe buffer-layout way:\n\n    const st = lo.struct([lo.u8('prop'),\n                        lo.seq(lo.u16(),\n                               lo.greedy(lo.u16().span),\n                               'data')],\n                       'ds');\n    const b = Buffer.from('21010002030405', 'hex');\n    assert.deepEqual(st.decode(b), {prop: 33, data: [0x0001, 0x0302, 0x0504]});\n    b.fill(0xFF);\n    assert.equal(st.encode({prop: 9, data: [5, 6]}, b), 1 + 2 * 2);\n    assert.equal(Buffer.from('0905000600FFFF', 'hex').compare(b), 0);\n\n### Tagged values, or variable-length unions\n\nStoring arbitrary data using a leading byte to identify the content then\na value that takes up only as much room as is necessary.\n\nThe example also shows how to extend the variant recognition API to\nsupport abitrary constant without consuming space for them in the\nencoded union.  This could be used to make something similar to\n[BSON](http://bsonspec.org/spec.html).\n\nHere's the code that defines the union, the variants, and the\nrecognition of `true` and `false` values for `b` as distinct variants:\n\n    const un = lo.union(lo.u8('t'));\n    const u8 = un.addVariant('B'.charCodeAt(0), lo.u8(), 'u8');\n    const s16 = un.addVariant('h'.charCodeAt(0), lo.s16(), 's16');\n    const s48 = un.addVariant('Q'.charCodeAt(0), lo.s48(), 's48');\n    const cstr = un.addVariant('s'.charCodeAt(0), lo.cstr(), 'str');\n    const tr = un.addVariant('T'.charCodeAt(0), lo.const(true), 'b');\n    const fa = un.addVariant('F'.charCodeAt(0), lo.const(false), 'b');\n    const b = Buffer.alloc(1 + 6);\n    un.configGetSourceVariant(function(src) {\n      if (src.hasOwnProperty('b')) {\n        return src.b ? tr : fa;\n      }\n      return this.defaultGetSourceVariant(src);\n    });\n\nAnd here are examples of encoding, checking the encoded length, and\ndecoding each of the alternatives:\n\n    b.fill(0xff);\n    assert.equal(un.encode({u8: 1}, b), 1 + 1);\n    assert.equal(un.getSpan(b), 2);\n    assert.equal(Buffer.from('4201ffffffffff', 'hex').compare(b), 0);\n    assert.equal(un.decode(b).u8, 1);\n\n    b.fill(0xff);\n    assert.equal(un.encode({s16: -32000}, b), 1 + 2);\n    assert.equal(un.getSpan(b), 3);\n    assert.equal(Buffer.from('680083ffffffff', 'hex').compare(b), 0);\n    assert.equal(un.decode(b).s16, -32000);\n\n    b.fill(0xff);\n    const v48 = Math.pow(2, 47) - 1;\n    assert.equal(un.encode({s48: v48}, b), 1 + 6);\n    assert.equal(un.getSpan(b), 7);\n    assert.equal(Buffer.from('51ffffffffff7f', 'hex').compare(b), 0);\n    assert.equal(un.decode(b).s48, v48);\n\n    b.fill(0xff);\n    assert.equal(un.encode({b: true}, b), 1);\n    assert.equal(un.getSpan(b), 1);\n    assert.equal(Buffer.from('54ffffffffffff', 'hex').compare(b), 0);\n    assert.strictEqual(un.decode(b).b, true);\n\n    b.fill(0xff);\n    assert.equal(un.encode({b: false}, b), 1);\n    assert.equal(un.getSpan(b), 1);\n    assert.equal(Buffer.from('46ffffffffffff', 'hex').compare(b), 0);\n    assert.strictEqual(un.decode(b).b, false);\n\n**NOTE** This code tickles a long-standing [bug in\nBuffer.writeInt{L,B}E](https://github.com/nodejs/node/pull/3994); if you\nare using Node prior to 4.2.4 or 5.2.0 you should update.\n", "release_dates": []}, {"name": "buffer-layout-utils", "description": "TypeScript utilities for using buffer-layout with Solana programs", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# `@solana/buffer-layout-utils`\n\nComing soon.\n", "release_dates": []}, {"name": "cfg-if", "description": "A if/elif-like macro for Rust #[cfg] statements", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# cfg-if\n\n[Documentation](https://docs.rs/cfg-if)\n\nA macro to ergonomically define an item depending on a large number of #[cfg]\nparameters. Structured like an if-else chain, the first matching branch is the\nitem that gets emitted.\n\n```toml\n[dependencies]\ncfg-if = \"1.0\"\n```\n\n## Example\n\n```rust\ncfg_if::cfg_if! {\n    if #[cfg(unix)] {\n        fn foo() { /* unix specific functionality */ }\n    } else if #[cfg(target_pointer_width = \"32\")] {\n        fn foo() { /* non-unix, 32-bit functionality */ }\n    } else {\n        fn foo() { /* fallback implementation */ }\n    }\n}\n\nfn main() {\n    foo();\n}\n```\nThe `cfg_if!` block above is expanded to:\n```rust\n#[cfg(unix)]\nfn foo() { /* unix specific functionality */ }\n#[cfg(all(target_pointer_width = \"32\", not(unix)))]\nfn foo() { /* non-unix, 32-bit functionality */ }\n#[cfg(not(any(unix, target_pointer_width = \"32\")))]\nfn foo() { /* fallback implementation */ }        \n```\n\n# License\n\nThis project is licensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or\n   http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in `cfg-if` by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n", "release_dates": []}, {"name": "chatgpt-plugin", "description": null, "language": "TypeScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Solana ChatGPT Plugin\nA ChatGPT plugin for Solana. Install as an unverified plugin with url `https://chatgpt.solanalabs.com`.\n\n<div>\n<img width=\"350\" alt=\"Search NFTs in ChatGPT\" src=\"https://user-images.githubusercontent.com/7481857/231182274-40b42f0e-5e5d-4050-9e31-2f75375481c1.png\">\n</div>\n\n## Endpoints\n\nChatGPT can POST to the following resources, as described by `.well-known/openapi.yaml`.\n\n\n<details>\n<summary>\n/getAccountInfo { address }\n</summary>\n\nReturns the output of `getAccountInfo` method from the RPC with buffer data, and if it can be deserialized by its program IDL, then the response payload has additional field called `extended` that has a JSON serialized string of the anchor data. Chat GPT's plugin model seems to be able to read this pretty well.\n\n```json\n{\n  ...,\n  \"extended\": \"{\\\"authority\\\":\\\"8fbqVvpK3Dj7fdP2c8JJhtD7Zy3n9qtwAeGfbkgPu625\\\",\\\"numMinted\\\":50}\"\n}\n```\n</details>\n\n<details>\n<summary>/getBalance { address }</summary>\n\nReturns\n```json\n{\n  \"sol\": 0.40296\n}\n```\n</details>\n\n<details>\n<summary>/getAssetsByOwner { address }</summary>\n\nReturns the assets returned by the [Metaplex Read API spec](https://github.com/metaplex-foundation/api-specifications/blob/main/specifications/read_api/openrpc_spec.json)\n</details>\n\n<details>\n<summary>/getTransaction { signature } </summary>\n\nAccepts\n```json\n{\n  \"signature\": \"h51pjmFcn8LkxejofUQoDYkyubUKaB7bNtyMMSCCamSEYRutS2G2vm2w1ERShko8boRqdaaTAs4MR6sGYkTByNF\"\n}\n```\n\nReturns human-readable transaction information, parsed from the `getTransaction` method of the Solana RPC.\n</details>\n\n<details>\n<summary>/getTokenAccounts { address }</summary>\n\nReturns the token accounts owned by a user with an amount > 0. Derived from the `getTokenAccountsByOwner` method on the Solana RPC.\n\n</details>\n\n<details>\n<summary>/getSignaturesForAddress { address } </summary>\n\nReturns the transaction signatures returned in `getSignaturesForAddress` method from the Solana RPC.\n\n</details>\n\n\n<details>\n<summary>\n/getTotalValue { address }\n</summary>\n\nReturns the total value of the assets owned by `address`, broken down by NFTs and tokens. Token prices and NFT price estimates are provided by HelloMoon. An example output is provided below\n\n```json\n{\n  \"total\": \"50.00\",\n  \"nftTotal\": \"25.00\",\n  \"tokenTotal\": \"25.00\"\n}\n```\n</details>\n\n### Endpoints for NFT discovery \nThese endpoints are under development and subject to rapid change. These currently use the [Hyperspace API](https://docs.hyperspace.xyz).\n\n<details>\n<summary>/getCollectionsByFloorPrice { maxFloorPrice, minFloorPrice, orderBy, pageSize } </summary>\n\nReturns\n```json\n{\n  \"projects\": [\n    {\n      \"id\": \"<hyperspace-collection-id or pubkey>\",\n      \"desc\": \"collection description\",\n      \"img\": \"collection image url\",\n      \"website\": \"collection website url\",\n      \"floor_price\": 0.1\n    }\n  ],\n  \"hasMore\": true,\n  \"currentPage'\": 1\n}\n```\n</details>\n\n<details>\n<summary>/getListedCollectionNFTs { projectId, pageSize, priceOrder }</summary>\n\nReturns LLM friendly response of available NFTs:\n```json\n{ \n  \"listings\": [\n    {\n      \"price\": 0.1,\n      \"token\": \"<token-address-pubkey>\",\n      \"marketplace\": \"<marketplace-pubkey>\"\n    }\n  ],\n  \"hasMore\": true,\n  \"currentPage\": 1\n} \n```\n</details>\n\n\n## Private endpoints (not LLM accessible)\n\n### Endpoints for Sending Transactions\n\nNote: these endpoints are currently disabled in the production version of the ChatGPT plugin\n\n<details>\n<summary> /createBuyTransaction { token, price }</summary>\n\nRight now we are trusting Hyperspace to craft a valid transaction for us. \nIn the future we will setup a write interface for programs on Solana to adhere to in order to \nbe a target of LLM transaction composition.\n\nReturns\n```json\n{\n  \"linkToSign\": \"<url-to-sign-transaction>\" \n}\n```\n</details>\n\n<details>\n<summary> /createTransferSol { destination, amount }</summary>\n\nCreates a transaction to transfer an amount in Sol.\n\nReturns\n```json\n{\n  \"linkToSign\": \"<url-to-sign-transaction>\" \n}\n```\n</details>\n\n<details>\n<summary> /createTransferToken { destination, mint, amount }</summary>\n\nCreates a transaction to transfer an amount of token (from the mint).\n\nReturns\n```json\n{\n  \"linkToSign\": \"<url-to-sign-transaction>\" \n}\n```\n</details>\n\n### Endpoints for Transaction Composition\n\nThese are also subject to change, and we may create actual webpages to inspect\nthe transaction before signing. However for now, these are simply redirect links \nto ensure that SolanaPay QR codes show up in the ChatGPT link previews.\n\n<details>\n<summary>/page/:methodName</summary>\n\nReturns a webpage with [OpenGraph](https://ogp.me/) metadata that will be rendered in the ChatGPT \nrich link preview. All ChatGPT links should be proxied through this sort of pipeline to maximize\nuser engagement of links. The `og:image` tag is to `/qr/:methodName` to show a SolanaPay QR code in link previews.\n\nThis is currently a blank page, but we may show a preview of the transaction in the future.\n</details>\n\n<details>\n<summary>/qr/:methodName</summary>\n\nReturns a PNG QR code that has been optimized to show in the particular aspect ratio of ChatGPT plugins. \nThis just encodes a SolanaPay link that redirects to `/sign/:methodName`. \n</details>\n\n<details>\n<summary>/sign/:methodName</summary>\n\nThis is the final redirect link that actually returns transaction bytes in a SolanaPay compatible format\nso users can sign transactions that are recommended by ChatGPT.\n\n```json\n{\n  \"transaction\": \"<base64-encoded-transaction-bytes>\"\n}\n```\n</details>\n\n## Development\n\nTo install dependencies, just execute `yarn`. This project uses `node` with version `>=16.17.0`.\n\nTo start a development server, execute `yarn dev`. This will start the plugin available from `localhost:3333` with its own configuration settings in `.well-known-dev/`.\n\n# License\n\nThis codebase is released under [Apache License 2.0](LICENSE.md).\n\n# Disclaimer\n\nBy accessing or using this codebase or any of its components, you accept and agree with the [Disclaimer](DISCLAIMER.md).\n", "release_dates": []}, {"name": "clang", "description": "Mirror of official clang git repository located at http://llvm.org/git/clang.  Updated every five minutes.", "language": "C++", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "//===----------------------------------------------------------------------===//\n// C Language Family Front-end\n//===----------------------------------------------------------------------===//\n\nWelcome to Clang.  This is a compiler front-end for the C family of languages\n(C, C++, Objective-C, and Objective-C++) which is built as part of the LLVM\ncompiler infrastructure project.\n\nUnlike many other compiler frontends, Clang is useful for a number of things\nbeyond just compiling code: we intend for Clang to be host to a number of\ndifferent source-level tools.  One example of this is the Clang Static Analyzer.\n\nIf you're interested in more (including how to build Clang) it is best to read\nthe relevant web sites.  Here are some pointers:\n\nInformation on Clang:             http://clang.llvm.org/\nBuilding and using Clang:         http://clang.llvm.org/get_started.html\nClang Static Analyzer:            http://clang-analyzer.llvm.org/\nInformation on the LLVM project:  http://llvm.org/\n\nIf you have questions or comments about Clang, a great place to discuss them is\non the Clang development mailing list:\n  http://lists.llvm.org/mailman/listinfo/cfe-dev\n\nIf you find a bug in Clang, please file it in the LLVM bug tracker:\n  http://llvm.org/bugs/\n\n", "release_dates": []}, {"name": "clang-tools-extra", "description": "Mirror of official clang-tools-extra git repository located at http://llvm.org/git/clang-tools-extra. Updated every five minutes.", "language": "C++", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "//===----------------------------------------------------------------------===//\n// Clang Tools repository\n//===----------------------------------------------------------------------===//\n\nWelcome to the repository of extra Clang Tools.  This repository holds tools\nthat are developed as part of the LLVM compiler infrastructure project and the\nClang frontend.  These tools are kept in a separate \"extra\" repository to\nallow lighter weight checkouts of the core Clang codebase.\n\nThis repository is only intended to be checked out inside of a full LLVM+Clang\ntree, and in the 'tools/extra' subdirectory of the Clang checkout.\n\nAll discussion regarding Clang, Clang-based tools, and code in this repository\nshould be held using the standard Clang mailing lists:\n  http://lists.llvm.org/mailman/listinfo/cfe-dev\n\nCode review for this tree should take place on the standard Clang patch and\ncommit lists:\n  http://lists.llvm.org/mailman/listinfo/cfe-commits\n\nIf you find a bug in these tools, please file it in the LLVM bug tracker:\n  http://llvm.org/bugs/\n", "release_dates": []}, {"name": "cluster", "description": "Cluster Infrastructure", "language": "Shell", "license": null, "readme": "_WARNING_: THIS README IS OUTDATED\n\n# Machine Overview\n\nEach machine is configured as similarly as possible.  The solana sofware runs\nunder the user `sol` as a systemd service.  The name of the systemd service\nis the same across all nodes, `sol`.\n\nThe ledger is stored in /home/sol/ledger\n\n## Cluster Entrypoint Node\n* DNS: cluster.solana.com\n* Static IP: 35.227.139.150\n* GCE Instance Name: cluster-entrypoint\n* OS Image: Ubuntu 20.04 LTS Minimal\n* Boot disk: Standard disk, 200GB\n* Machine type: n1-standard-1\n* Region: us-west-1\n* ssh: `gcloud --project solana-cluster compute ssh cluster-entrypoint`\n\n## Bootstrap Validator Node\n* DNS: none\n* Static IP: none\n* GCE Instance Name: cluster-bootstrap-validator\n* OS Image: Ubuntu 20.04 LTS Minimal\n* Boot disk: Standard disk, 2TB\n* Machine type: n1-standard-16\n* Region: us-west-1\n* ssh: `gcloud --project solana-cluster compute ssh cluster-bootstrap-validator`\n\n## RPC Node\n* DNS: api.cluster.solana.com\n* Static IP: 35.197.59.229\n* GCE Resource Name: cluster-api\n* OS Image: Ubuntu 20.04 LTS Minimal\n* Boot disk: Standard disk, 2TB\n* Machine type: n1-standard-16\n* Region: us-west-1\n* ssh: `gcloud --project solana-cluster compute ssh cluster-api`\n\n## Warehouse Node\n* DNS: none\n* Static IP: none\n* GCE Instance Name: cluster-warehouse\n* OS Image: Ubuntu 20.04 LTS Minimal\n* Boot disk: Standard disk, 2TB\n* Machine type: n1-standard-16\n* Region: us-west-1\n* ssh: `gcloud --project solana-cluster compute ssh cluster-warehouse`\n\n## Watchtower Node\n* DNS: none\n* Static IP: none\n* GCE Instance Name: cluster-watchtower\n* OS Image: Ubuntu 20.04 LTS Minimal\n* Boot disk: Standard disk, 200GB\n* Machine type: n1-standard-1\n* Region: us-west-1\n* ssh: `gcloud --project solana-cluster compute ssh cluster-watchtower`\n\n# Metrics\nThe following metrics configuration is used in production:\n```\n# These public credentials are a known risk\nSOLANA_METRICS_CONFIG=\"host=https://metrics.solana.com:8086,db=cluster,u=cluster_write,p=2aQdShmtsPSAgABLQiK2FpSCJGLtG8h3vMEVz1jE7Smf\"\n```\n\nProduction metrics [dashboard](http://bit.ly/solana-cluster)\n\n# Internal Workflows\n## Changing the deployed Solana software version\nThere are two places to be modified to update the Solana software version to deploy:\n1. On your machine as genesis will be build on your local machine.  Run `solana-install init <desired version>`.\n1. Modify the `RELEASE_CHANNEL_OR_TAG=` variable in `launch-cluster.sh`.\n\n## Launch a development cluster\nA development cluster can be created at any time by anybody.   The instances\nwill be created in the standard GCE development project, scoped by your\nusername.\n\nProcedure:\n1. Ensure the desired Solana release is installed on your machine\n1. Run `./genesis.sh` to produce the genesis configuration.  To override the\n   default cluster creation time of _now_, include the `--creation-time` argument\n   (eg `./genesis.sh --creation-time '2020-01-01T12:00:00-08:00'`)\n1. If metrics are desired set SOLANA_METRICS_CONFIG in your environment\n1. Run `./launch-cluster.sh` to create the development cluster instances\n\nWhen done run `./delete-cluster.sh` to delete the instances.\n\n## Launch *THE* cluster\nSame as launching a development cluster except:\n1. You need access to the `solana-cluster` GCE project\n1. `SOLANA_METRICS_CONFIG` is automatically configured\n1. `export CLUSTER=cluster` before running `./launch-cluster.sh`\n\nThe `./launch-cluster.sh` script programmatically creates and configures the\ncluster instances.\n\n## Manipulating the systemd service\nThe file `/etc/systemd/system/sol.service` describes the systemd service for\neach of the instances.\n\nFrom a shell on the instance, view the current status of the services with\n```\n$ sudo systemctl status sol\n```\n\nFollow logs with:\n```\n$ journalctl -u sol -f\n```\n\nIf `/etc/systemd/system/sol.service` is modified, apply the changes with:\n```\n$ sudo systemctl daemon-reload\n$ sudo systemctl restart sol\n```\n\n## Updating the solana software\nFrom a shell on the instance run:\n```\n$ /solana-update.sh 0.22.0\n```\n\nThere's no mechanism to automatically update the software across all the nodes\nat once.\n\n## Delegating Stake to a Validator\nAs external validators boot they receive 1m SOL in equal stake.\n\nTo locate the online validators run:\n```bash\n$ solana show-validators\n```\n\nThe `solana catchup` command can be used to block until a given validator has\ncaught up to the cluster.\n\nThen use the `solana delegate-stake` command for each validator using a **TBD**\nstake account.\n\n## Fetching a ledger snapshot\nTo view the available ledger snapshots, run:\n```bash\n$ ./fetch-ledger-snapshot.sh\n```\n\nDownloading a snapshot can be accomplished with:\n```bash\n$ ./fetch-ledger-snapshot.sh 2019-12-03T22:54:59Z  # <-- replace with the desired snapshot timestamp\n```\n\nBoot a validator from the downloaded snapshot with:\n```bash\n$ solana-validator \\\n  --ledger ledger-snapshot \\\n  --no-genesis-fetch \\\n  --no-snapshot-fetch ...\n```\n\n# Validator Workflow\nThe minimal steps required of a validator participating in the initial boot of the cluster are:\n\n## Installing the software\n`\n  $ curl -sSf https://raw.githubusercontent.com/solana-labs/solana/v0.21.1/install/solana-install-init.sh | sh -s - 0.21.2\n`\n\nthen configure the command-line tool's RPC endpoint URL:\n```bash\n$ solana set --url http://34.82.79.31/\n```\n\n## Starting your validator:\nAssuming that `~/validator-keypair.json` and `~/validator-vote-keypair.json`\ncontain the validator identity and vote keypairs that were registered in the\ngenesis configuration, run:\n\n```bash\n# These public credentials are a known risk\n$ export SOLANA_METRICS_CONFIG=\"host=https://metrics.solana.com:8086,db=cluster,u=cluster_write,p=2aQdShmtsPSAgABLQiK2FpSCJGLtG8h3vMEVz1jE7Smf\"\n$ export EXPECTED_GENESIS_HASH=##### <--- To be communicated by Solana\n$ solana-validator \\\n  --identity-keypair ~/validator-keypair.json \\\n  --voting-keypair ~/validator-vote-keypair.json \\\n  --ledger ~/validator-ledger \\\n  --rpc-port 8899 \\\n  --entrypoint 34.83.130.52:8001\n  --limit-ledger-size \\\n  --expected-genesis-hash $EXPECTED_GENESIS_HASH \\\n  --expected-shred-version ${EXPECTED_SHRED_VERSION} \\\n```\n", "release_dates": []}, {"name": "compiler-rt", "description": "Mirror of official compiler-rt git repository located at http://llvm.org/git/compiler-rt.  Updated every five minutes.", "language": "C", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "Compiler-RT\n================================\n\nThis directory and its subdirectories contain source code for the compiler\nsupport routines.\n\nCompiler-RT is open source software. You may freely distribute it under the\nterms of the license agreement found in LICENSE.txt.\n\n================================\n\n", "release_dates": []}, {"name": "configure_mango", "description": "(FORK) Typescript library with multiple functions to help configure new mango instance for a cluster", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Configure Mango - A faster and easier way to configure Mango Markets on a cluster\n\nThis code can be used to configure mango group, tokens, spot market, perp markets and oracles on local solana validator and create 50 mango user accounts.\nIt will create authority.json which is keypair of authority file, accounts.json which contains all user data and ids.json which contains info about mango group.\n\nThe project also contains necessary binary files. You can always update the binary files by compiling from source and replacing the binaries locally. You have to apply bin/mango.patch to your mango repository to use it to create a local cluster.\nFrom the root directory of this project do:\n\n## How to use\n\nTo install all the dependencies :\n```sh\nyarn install\n```\n\nTo start a solana test validator\n```sh\nsh scripts/start_test_validator.sh\n```\nOr\nTo start a local solana validator\n```sh\nsh scripts/configure_local.sh\n```\n\nTo configure mango\n```sh\nyarn ts-node index.ts\n```\n\nTo run mango keeper (deprecated)\n```sh\nyarn ts-node keeper.ts\n```\n\nTo create 50 users and store in the file accounts.json\n```sh\nts-node create-users.ts 50 accounts.json\n```\n\nTo refund users in account file with some sols\n```sh\nts-node refund_users.ts accounts.json \n```\n\nPyth oracle is a mock it is a program which will just rewrite an account with a binary data.", "release_dates": []}, {"name": "contributor-access-policy", "description": "This document outlines the procedure for getting contributor access to various Solana Labs source code repositories", "language": null, "license": null, "readme": "## Summary\n\nThis document outlines the procedure for getting contributor access to various Solana Labs source code repositories and the Solana Tech Discord server.\n\nEveryone is welcome to contribute to the Solana Labs codebase. Contributing doesn\u2019t just mean submitting pull requests, \nthere are many different ways for you to get involved, including answering questions on Stack Exchange or Discord, and reporting or triaging bugs.\n\n#### Repositories\n\nAccess is granted based on the repository you are interested in contributing to:\n\n1. The [Solana Program Library (SPL) repository](https://github.com/solana-labs/solana-program-library).\n2. The [Solana Labs monorepo](https://github.com/solana-labs/solana).\n\n#### Access Levels\n\nThere are 3 levels of Github access, in the order of increasing access:\n\n1. Triage\n\n    Requirement: One voucher from anyone with level 2 or above access. A contributor with Triage access will be able to manage issues\nin accordance with Github access policies.\n\n2. Write\n\n    Requirement: Two vouchers from anyone with level 3 access or two from\nanyone with level 2 access. A contributor with Write access will be able to merge pull requests\nin accordance with Github access policies.\n\n3. Maintain\n\n    Requirement: Two vouchers from anyone with level 3 access. This permission\nis usually reserved for those maintaining the respective repositories.\n\nEach of the levels implies having the previous levels - e.g. level 2 implies\nlevel 1. \n\n## Detailed Design\n\n### Level 1 - Triage Access\n\nRequirements: One voucher from any user with level 2 or above access to the respective repository.\n\nContributors with Triage access will have the associated [triage Github access\npolicy](https://docs.github.com/en/organizations/managing-user-access-to-your-organizations-repositories/repository-roles-for-an-organization#permissions-for-each-role)\nfor the [Solana Program Library](https://github.com/solana-labs/solana-program-library) (SPL) repository or the\n[Solana](https://github.com/solana-labs/solana) monorepo as well as access to Solana Labs' Buildkite CI.\n\n### Level 2 - Write Access\n\nRequirements: Two vouchers from anyone with level 2/3 access to the respective repository. Applicants must have level 1 access to apply for level 2.\n\nContributors with Write access will have the associated [write Github access\npolicy](https://docs.github.com/en/organizations/managing-user-access-to-your-organizations-repositories/repository-roles-for-an-organization#permissions-for-each-role)\nfor the [Solana Program Library](https://github.com/solana-labs/solana-program-library) (SPL) repository or the \n[Solana](https://github.com/solana-labs/solana) monorepo.\n\nMost notably these permissions allow the contributor to approve and merge pull\nrequests.\n\n### Level 3 - Maintain Access\n\nRequirements: Two vouchers from anyone with level 3 access to the respective repository.\n\nContributors with Maintain access will have the associated [maintain Github access\npolicy](https://docs.github.com/en/organizations/managing-user-access-to-your-organizations-repositories/repository-roles-for-an-organization#permissions-for-each-role)\nfor the [Solana Program Library](https://github.com/solana-labs/solana-program-library) (SPL) repository or the \n[Solana](https://github.com/solana-labs/solana) monorepo.\n\nUsers with Maintain access are responsible for managing the repositories and\ngranting user access based on the above requirements.\n\n### Discord Access\n\nAny of the above access levels will grant you the Contributor role in the Solana Tech Discord server and a role tag with your current access level and the respective repository (e.g. SLP-Triage, Mono-Triage).\n\nIf you are only interested in getting the Contributor role on Discord without requesting GitHub access, then you can request an existing Contributor to vouch for you in the #contributor-roles-requests channel. The requests should be made in the following format:\n\n```\n\"I'd like to request the Contributor role for @USER\"\n```\n\nIf you'd like to request a role removal for an existing Contributor, you should do it in the #contributor-roles-requests channel and follow this format:\n\n```\n\"I'd like to request Contributor role removal for @USER because [REASON]\"\n```\n\n### Vouching Process \n\nTo receive any access level to the SPL repository or the monorepo, follow these steps:\n\n1. Open an issue on the [Contributor Access Policy](https://github.com/solana-labs/contributor-access-policy) repository\nfollowing the [templates for the respective access level](https://github.com/solana-labs/contributor-access-policy/issues/new/choose).\n2. Gather your vouchers to add a comment on the issue expressing their support.\n3. Once the issue has received enough support, notify a user with Maintain\naccess to the respective repository by adding a comment tagging him. A list of members and their access levels can be found [here](https://github.com/solana-labs/contributor-access-policy/tree/master/access-control-list).\n4. It would take 3 business days for the request to be processed.\n\n**Note**: The vouching comments on the issue should be made in the following format:\n\n```\n\"I support the promotion of USER to LEVEL for X reasons\"\n```\n\n### Access Removal Process\n\nIn the event that a user requires their access to be removed, follow these steps:\n\n1. Open an issue on the [Contributor Access Policy](https://github.com/solana-labs/contributor-access-policy) repository\nwith the title in the following format: \"Revoke Access (Level X) for [Username]\".\n2. Other users with the appropriate level of access should comment on the issue\nto express their support for the removal of access.\n3. Once the issue has received enough support, the user's access will be\nrevoked.\n\nRequirements:\n\n- If a user's level 3 access is being revoked, support from at least two other\nusers with level 3 access is required.\n- If a user's level 1 or 2 access is being revoked, support from at least two \nother users with level 2 or one user with level 3 is required.\n- If a user opens the issue to revoke their own access, no support from others\nis required.\n\n## Security Considerations\n\nIn the event of a malicious actor gaining any level of access, users must\nfollow the Access Removal Process to revoke that actor's access.\n", "release_dates": []}, {"name": "create-react-app-buildpack", "description": "\u269b\ufe0f Heroku Buildpack for create-react-app: static hosting for React.js web apps", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "Heroku Buildpack for create-react-app\n=====================================\n\nDeploy React.js web apps generated with [create-react-app](https://github.com/facebook/create-react-app). Automates deployment with the built-in bundler and serves it up via [Nginx](http://nginx.org/en/). See the [introductory blog post](https://blog.heroku.com/deploying-react-with-zero-configuration) and entry in [Heroku elements](https://elements.heroku.com/buildpacks/mars/create-react-app-buildpack).\n\n* \ud83d\udea6 [Purpose](#user-content-purpose)\n* \u26a0\ufe0f [Requirements](#user-content-requires)\n* \ud83d\ude80 [Quick Start](#user-content-quick-start)\n* \ud83d\udee0 [Usage](#user-content-usage)\n  1. [Generate a React app](#user-content-generate-a-react-app)\n  1. [Make it a git repo](#user-content-make-it-a-git-repo)\n  1. [Create the Heroku app](#user-content-create-the-heroku-app)\n  1. [Commit & deploy \u267b\ufe0f](#user-content-commit--deploy-\ufe0f)\n  1. [Continue Development](#user-content-continue-development)\n  1. [Push to Github](#user-content-push-to-github)\n  1. [Testing](#user-content-testing)\n* \ud83d\udc53 [Customization](#user-content-customization)\n  * [Procfile](#user-content-procfile)\n  * [Web server](#user-content-web-server)\n    * [Routing](#user-content-routing)\n    * [HTTPS-only](#user-content-https-only)\n    * [Proxy](#user-content-proxy)\n  * [Environment variables](#user-content-environment-variables)\n    * [Set vars on Heroku](#user-content-set-vars-on-heroku)\n    * [Set vars for local dev](#user-content-set-vars-for-local-dev)\n    * [Compile-time vs Runtime](#user-content-compile-time-vs-runtime)\n      * [Compile-time config](#user-content-compile-time-configuration)\n      * [Runtime config](#user-content-runtime-configuration)\n        * [Custom bundle location](#user-content-custom-bundle-location)\n    * [using an Add-on's config](#user-content-add-on-config-vars)\n  * [npm Private Packages](#user-content-npm-private-packages)\n* \ud83d\udd75\ufe0f\u00a0[Troubleshooting](#user-content-troubleshooting)\n* \ud83d\udccd [Version compatibility](#user-content-version-compatibility)\n* \ud83c\udfd9 [Architecture](#user-content-architecture-)\n\n-----\n\nPurpose\n-------\n\n**This buildpack deploys a React UI as a static web site.** The [Nginx](http://nginx.org/en/) web server provides optimum performance and security for the runtime. See [Architecture](#user-content-architecture-) for details.\n\nIf your goal is to make a single app that combines React UI with a server-side backend (Node, Ruby, Python\u2026), then this buildpack is not the answer.\n\nCheck out these alternatives to use React with a server-side app:\n\n* **[create-react-app + Node.js server](https://github.com/mars/heroku-cra-node)** \u2b50\ufe0f simplest solution\n* **[create-react-app + Ruby on Rails server](https://blog.heroku.com/a-rock-solid-modern-web-stack)** \n\nRequires\n--------\n\n* [Heroku](https://www.heroku.com/home)\n  * [command-line tools (CLI)](https://toolbelt.heroku.com)\n  * [a free account](https://signup.heroku.com)\n* [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)\n* [Node.js](https://nodejs.org)\n\nQuick Start\n-----------\n\nEnsure [requirements](#user-content-requires) are met, then execute the following in a terminal.\n\n\u270f\ufe0f *Replace `$APP_NAME` with the name for your unique app.*\n\n```bash\nnpx create-react-app@3.x $APP_NAME\ncd $APP_NAME\nheroku create $APP_NAME --buildpack mars/create-react-app\ngit push heroku master\nheroku open\n```\n\nOnce deployed, [continue development](#user-content-continue-development) \ud83c\udf31\n\nFor explanation about these steps, continue reading the [next section](#user-content-usage).\n\n\nUsage\n-----\n\n### Generate a React app\n\n\u270f\ufe0f *Replace `$APP_NAME` with the name for your unique app.*\n\n```bash\nnpx create-react-app@3.x $APP_NAME\ncd $APP_NAME\n```\n\n* as of create-react-app v3, it automatically performs `git init` and an initial commit\n* [npx](https://medium.com/@maybekatz/introducing-npx-an-npm-package-runner-55f7d4bd282b) comes with npm 5.2+ and higher, see [instructions for older npm versions](https://gist.github.com/gaearon/4064d3c23a77c74a3614c498a8bb1c5f)\n* if [yarn](https://yarnpkg.com) is installed locally, the new app will use it instead of [npm](https://www.npmjs.com)\n\n### Create the Heroku app\n\n\u270f\ufe0f *Replace `$APP_NAME` with the name for your unique app.*\n\n```bash\nheroku create $APP_NAME --buildpack mars/create-react-app\n```\n\nThis command:\n\n* sets the [app name](https://devcenter.heroku.com/articles/creating-apps#creating-a-named-app) & its default URL `https://$APP_NAME.herokuapp.com`\n* sets the app to use this [buildpack](https://devcenter.heroku.com/articles/buildpacks)\n* configures the [`heroku` git remote](https://devcenter.heroku.com/articles/git#creating-a-heroku-remote) in the local repo, so `git push heroku master` will push to this new Heroku app.\n\n### Deploy \u267b\ufe0f\n\n```bash\ngit push heroku master\n```\n\n\u2026or if you are ever working on a branch other than `master`:\n\n\u270f\ufe0f *Replace `$BRANCH_NAME` with the name for the current branch.*\n\n```bash\ngit push heroku $BRANCH_NAME:master\n```\n\n### Visit the app's public URL in your browser\n\n```bash\nheroku open\n```\n\n### Visit the Heroku Dashboard for the app\n\nFind the app on [your dashboard](https://dashboard.heroku.com).\n\n### Continue Development\n\nWork with your app locally using `npm start`. See: [create-react-app docs](https://github.com/facebookincubator/create-react-app#getting-started)\n\nThen, `git commit` your changes & `git push heroku master` \u267b\ufe0f\n\n### Push to Github\n\nEventually, to share, collaborate, or simply back-up your code, [create an empty repo at Github](https://github.com/new), and then follow the instructions shown on the repo to **push an existing repository from the command line**.\n\n### Testing\n\nUse [create-react-app's built-in Jest testing](https://github.com/facebookincubator/create-react-app/blob/master/packages/react-scripts/template/README.md#user-content-running-tests) or whatever testing library you prefer.\n\n[Heroku CI](https://devcenter.heroku.com/articles/heroku-ci) is supported with minimal configuration. The CI integration is compatible with npm & yarn (see [`bin/test`](bin/test)).\n\n#### Minimal `app.json`\n\nHeroku CI uses [`app.json`](https://devcenter.heroku.com/articles/app-json-schema) to provision test apps. To support Heroku CI, commit this minimal example `app.json`:\n\n```json\n{\n  \"buildpacks\": [\n    {\n      \"url\": \"mars/create-react-app\"\n    }\n  ]\n}\n```\n\nCustomization\n-------------\n\n### Procfile\n\nHeroku apps may declare what processes are launched for a successful deployment by way of the [`Procfile`](https://devcenter.heroku.com/articles/procfile). This buildpack's default process comes from [`heroku/static` buildpack](https://github.com/heroku/heroku-buildpack-static). (See: \ud83c\udfd9 [Architecture](#user-content-architecture-)). The implicit `Procfile` to start the static web server is:\n\n```\nweb: bin/boot\n```\n\nTo customize an app's processes, commit a `Procfile` and deploy. Include `web: bin/boot` to launch the default web process, or you may replace the default web process. Additional [process types](https://devcenter.heroku.com/articles/procfile#declaring-process-types) may be added to run any number of dynos with whatever arbitrary commands you want, and scale each independently.\n\n\ud83d\udea6 *If replacing the default web process, please check this buildpack's [Purpose](#user-content-purpose) to avoid misusing this buildpack (such as running a Node server) which can lead to confusing deployment issues.*\n\n### Web server\n\nThe web server may be [configured via the static buildpack](https://github.com/heroku/heroku-buildpack-static#configuration).\n\nThe config file `static.json` should be committed at the root of the repo. It will not be recognized, if this file in a sub-directory\n\nThe default `static.json`, if it does not exist in the repo, is:\n\n```json\n{\n  \"root\": \"build/\",\n  \"routes\": {\n    \"/**\": \"index.html\"\n  }\n}\n```\n\n### Changing the root\n\nIf a different web server `\"root\"` is specified, such as with a highly customized, ejected create-react-app project, then the new bundle location may need to be [set to enable runtime environment variables](#user-content-custom-bundle-location).\n\n### Routing\n\n\ud83d\udea5 ***Client-side routing is supported by default.** Any server request that would result in 404 Not Found returns the React app.*\n\n\ud83d\udc53 See [custom routing w/ the static buildpack](https://github.com/heroku/heroku-buildpack-static/blob/master/README.md#user-content-custom-routes).\n\n### HTTPS-only\n\nEnforce secure connections by automatically redirecting insecure requests to **https://**, in `static.json`:\n\n```json\n{\n  \"root\": \"build/\",\n  \"routes\": {\n    \"/**\": \"index.html\"\n  },\n  \"https_only\": true\n}\n```\n\n#### Strict transport security (HSTS)\n\nPrevent downgrade attacks with [HTTP strict transport security](https://developer.mozilla.org/en-US/docs/Web/Security/HTTP_strict_transport_security). Add HSTS `\"headers\"` to `static.json`.\n\n\u26a0\ufe0f **Do not set HSTS headers if the app's hostname will not permantly support HTTPS/SSL/TLS.** Once HSTS is set, switching back to plain HTTP will cause security errors in browsers that received the headers, until the max-age is reached. Heroku's built-in `herokuapp.com` hostnames are safe to use with HSTS.\n\n```json\n{\n  \"root\": \"build/\",\n  \"routes\": {\n    \"/**\": \"index.html\"\n  },\n  \"https_only\": true,\n  \"headers\": {\n    \"/**\": {\n      \"Strict-Transport-Security\": \"max-age=31557600\"\n    }\n  }\n}\n```\n\n* `max-age` is the number of seconds to enforce HTTPS since the last connection; the example is one-year\n\n### Proxy\n\nProxy XHR requests from the React UI in the browser to API backends. Use to prevent same-origin errors when [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS) is not supported on the backend.\n\n#### Proxy URL prefix\n\nTo make calls through the proxy, use relative URL's in the React app which will be proxied to the configured target URL. For the example URL prefix of `/api/`, here's how the proxy would rewrite the requests:\n\n```\n/api/search-items\n  \u2192 https://backend.example.com/search-items\n  \n/api/users/me\n  \u2192 https://backend.example.com/users/me\n```\n\nYou may choose any prefix and may have multiple proxies with different prefixes.\n\n#### Proxy for deployment\n\nThe [`heroku/static` buildpack](https://github.com/heroku/heroku-buildpack-static) (see: \ud83c\udfd9 [Architecture](#user-content-architecture-))  provides [Proxy Backends configuration](https://github.com/heroku/heroku-buildpack-static/blob/master/README.md#proxy-backends) to utilize  Nginx for high-performance proxies in production.\n\nAdd `\"proxies\"` to `static.json`:\n\n```json\n{\n  \"root\": \"build/\",\n  \"routes\": {\n    \"/**\": \"index.html\"\n  },\n  \"proxies\": {\n    \"/api/\": {\n      \"origin\": \"${API_URL}\"\n    }\n  }\n}\n```\n\nThen, point the React UI app to a specific backend API:\n\n```bash\nheroku config:set API_URL=\"https://backend.example.com\"\n```\n\n#### Proxy for local development\n\ncreate-react-app itself provides a built-in [proxy for development](https://github.com/facebookincubator/create-react-app/blob/master/packages/react-scripts/template/README.md#user-content-proxying-api-requests-in-development). This may be configured to match the behavior of [proxy for deployment](#user-content-proxy-for-deployment).\n\nAdd `\"proxy\"` to `package.json`:\n\n```json\n{\n  \"proxy\": {\n    \"/api\": {\n      \"target\": \"http://localhost:8000\",\n      \"pathRewrite\": {\n        \"^/api\": \"/\"\n      }\n    }\n  }\n}\n```\n\nReplace `http://localhost:8000` with the URL to your local or remote backend service.\n\n\n### Environment variables\n\n[`REACT_APP_*` environment variables](https://facebook.github.io/create-react-app/docs/adding-custom-environment-variables) are fully supported with this buildpack.\n\n\ud83d\udeab\ud83e\udd10 ***Not for secrets.** These values may be accessed by anyone who can see the React app.*\n\n### [Set vars on Heroku](https://devcenter.heroku.com/articles/config-vars)\n\n```bash\nheroku config:set REACT_APP_HELLO='I love sushi!'\n```\n\n### Set vars for local dev\n\n*Requires at least create-react-app 0.7. Earlier versions only support Compile-time.*\n\nCreate a `.env` file that sets a variable per line:\n\n```bash\nREACT_APP_API_URL=http://api.example.com\nREACT_APP_CLIENT_ID=XyzxYzxyZ\n```\n\n### Compile-time vs Runtime\n\nTwo versions of variables are supported. In addition to compile-time variables applied during [build](https://github.com/facebookincubator/create-react-app#npm-run-build) the app supports variables set at runtime, applied as each web dyno starts-up.\n\nRequirement | [Compile-time](#user-content-compile-time-configuration) | [Runtime](#user-content-runtime-configuration)\n:--- |:---:|:---: \nnever changes for a build | \u2713 |  \nsupport for [continuous delivery](https://www.heroku.com/continuous-delivery) |  | \u2713\nupdates immediately when setting new [config vars](https://devcenter.heroku.com/articles/config-vars) |   | \u2713\ndifferent values for staging & production (in a [pipeline](https://devcenter.heroku.com/articles/pipelines)) |   | \u2713\nex: `REACT_APP_BUILD_VERSION` (static fact about the bundle) | \u2713 | \nex: `REACT_APP_DEBUG_ASSERTIONS` ([prune code from bundle](https://webpack.github.io/docs/list-of-plugins.html#defineplugin)) | \u2713 | \nex: `REACT_APP_API_URL` (transient, external reference) |   | \u2713\nex: `REACT_APP_FILEPICKER_API_KEY` ([Add-on config vars](#user-content-add-on-config-vars)) |   | \u2713\n\n### Compile-time configuration\n\nSupports all config vars, including [`REACT_APP_`](https://github.com/facebook/create-react-app/blob/master/packages/react-scripts/template/README.md#adding-custom-environment-variables), `NODE_`, `NPM_`, & `HEROKU_` prefixed variables.\n\n\u261d\ufe0f\ud83e\udd10 ***Use secrets carefully.** If these values are embedded in the JavaScript bundle, like with `REACT_APP_` vars, then they may be accessed by anyone who can see the React app.*\n\nUse Node's [`process.env` object](https://nodejs.org/dist/latest-v10.x/docs/api/process.html#process_process_env).\n\n```javascript\nimport React, { Component } from 'react';\n\nclass App extends Component {\n  render() {\n    return (\n      <code>Runtime env var example: { process.env.REACT_APP_HELLO }</code>\n    );\n  }\n}\n```\n\n\u267b\ufe0f The app must be re-deployed for compiled changes to take effect, because during the build, these references will be replaced with their quoted string value.\n\n```bash\nheroku config:set REACT_APP_HELLO='I love sushi!'\n\ngit commit --allow-empty -m \"Set REACT_APP_HELLO config var\"\ngit push heroku master\n```\n\nOnly `REACT_APP_` vars are replaced in create-react-app's build. To make any other variables visible to React, they must be prefixed for the build command in `package.json`, like this:\n\n```bash\nREACT_APP_HEROKU_SLUG_COMMIT=$HEROKU_SLUG_COMMIT react-scripts build\n```\n\n### Runtime configuration\n\nSupports only [`REACT_APP_`](https://github.com/facebook/create-react-app/blob/master/packages/react-scripts/template/README.md#adding-custom-environment-variables) prefixed variables.\n\n\ud83d\udeab\ud83e\udd10 ***Not for secrets.** These values may be accessed by anyone who can see the React app.*\n\nInstall the [runtime env npm package](https://www.npmjs.com/package/@mars/heroku-js-runtime-env):\n\n```bash\nnpm install @mars/heroku-js-runtime-env --save\n```\n\nThen, require/import it to use the vars within components:\n\n```javascript\nimport React, { Component } from 'react';\nimport runtimeEnv from '@mars/heroku-js-runtime-env';\n\nclass App extends Component {\n  render() {\n    // Load the env object.\n    const env = runtimeEnv();\n\n    // \u2026then use values just like `process.env`\n    return (\n      <code>Runtime env var example: { env.REACT_APP_HELLO }</code>\n    );\n  }\n}\n```\n\n\u26a0\ufe0f *Avoid setting backslash escape sequences, such as `\\n`, into Runtime config vars. Use literal UTF-8 values only; they will be automatically escaped.*\n\n#### Custom bundle location\n\nIf the javascript bundle location is customized, such as with an ejected created-react-app project, then the runtime may not  be able to locate the bundle to inject runtime variables.\n\nTo solve this so the runtime can locate the bundle, set the custom bundle path:\n\n```bash\nheroku config:set JS_RUNTIME_TARGET_BUNDLE=/app/my/custom/path/js/*.js\n```\n\n\u2733\ufe0f *Note this path is a `*` glob, selecting multiple files, because as of create-react-app version 2 the [bundle is split](https://reactjs.org/blog/2018/10/01/create-react-app-v2.html).*\n\nTo unset this config and use the default path for **create-react-app**'s bundle, `/app/build/static/js/*.js`:\n\n```bash\nheroku config:unset JS_RUNTIME_TARGET_BUNDLE\n```\n\n### Add-on config vars\n\n\ud83d\udeab\ud83e\udd10 ***Be careful not to export secrets.** These values may be accessed by anyone who can see the React app.*\n\nUse a custom [`.profile.d` script](https://devcenter.heroku.com/articles/buildpack-api#profile-d-scripts) to make variables set by other components available to the React app by prefixing them with `REACT_APP_`.\n\n1. create `.profile.d/000-react-app-exports.sh`\n1. make it executable `chmod +x .profile.d/000-react-app-exports.sh`\n1. add an `export` line for each variable:\n\n   ```bash\n   export REACT_APP_ADDON_CONFIG=${ADDON_CONFIG:-}\n   ```\n1. set-up & use [Runtime configuration](#user-content-runtime-configuration) to access the variables\n\nFor example, to use the API key for the [Filestack](https://elements.heroku.com/addons/filepicker) JS image uploader:\n\n```bash\nexport REACT_APP_FILEPICKER_API_KEY=${FILEPICKER_API_KEY:-}\n```\n\nnpm Private Packages\n-------------------\nPrivate modules are supported during build.\n\n1. Setup your app with a `.npmrc` file following [npm's guide for CI/deployment](https://docs.npmjs.com/private-modules/ci-server-config).\n1. Set your secret in the `NPM_TOKEN` config var:\n\n    ```bash\n    heroku config:set NPM_TOKEN=xxxxx\n    ```\n\nTroubleshooting\n---------------\n\n1. Confirm that your app is using this buildpack:\n\n    ```bash\n    heroku buildpacks\n    ```\n    \n    If it's not using `create-react-app-buildpack`, then set it:\n\n    ```bash\n    heroku buildpacks:set mars/create-react-app\n    ```\n\n    \u2026and deploy with the new buildpack:\n\n    ```bash\n    git commit --allow-empty -m 'Switch to create-react-app-buildpack'\n    git push heroku master\n    ```\n    \n    If the error still occurs, then at least we know it's really using this buildpack! Proceed with troubleshooting.\n1. Check this README to see if it already mentions the issue.\n1. Search our [issues](https://github.com/mars/create-react-app-buildpack/issues?utf8=\u2713&q=is%3Aissue%20) to see if someone else has experienced the same problem.\n1. Search the internet for mentions of the error message and its subject module, e.g. `ENOENT \"node-sass\"`\n1. File a new [issue](https://github.com/mars/create-react-app-buildpack/issues/new). Please include:\n   * build log output\n   * link to GitHub repo with the source code (if private, grant read access to @mars)\n\n\nVersion compatibility\n---------------------\n\nThis buildpack will never intentionally cause previously deployed apps to become undeployable. Using master [as directed in the main instructions](#user-content-create-the-heroku-app) will always deploy an app with the most recent version of this buildpack.\n\n[Releases are tagged](https://github.com/mars/create-react-app-buildpack/releases), so you can lock an app to a specific version, if that kind of determinism pleases you:\n\n```bash\nheroku buildpacks:set https://github.com/mars/create-react-app-buildpack.git#v6.0.0\n```\n\n\u270f\ufe0f *Replace `v6.0.0` with the desired [release tag](https://github.com/mars/create-react-app-buildpack/releases).*\n\n\u267b\ufe0f Then, commit & deploy to rebuild on the new buildpack version.\n\n\nArchitecture \ud83c\udfd9\n------------\n\nThis buildpack combines several buildpacks, specified in [`.buildpacks`](.buildpacks), to support **zero-configuration deployment** on Heroku:\n\n1. [`heroku/nodejs` buildpack](https://github.com/heroku/heroku-buildpack-nodejs)\n   * installs `node`, puts on the `$PATH`\n   * version specified in [`package.json`, `engines.node`](https://devcenter.heroku.com/articles/nodejs-support#specifying-a-node-js-version)\n   * `node_modules/` cached between deployments\n   * production build for create-react-app\n     * [executes the npm package's build script](https://devcenter.heroku.com/changelog-items/1557); create-react-app default is `react-scripts build`\n     * exposes all env vars to the build script\n     * generates a production bundle regardless of `NODE_ENV` setting\n     * customize further with [Node.js build configuration](https://devcenter.heroku.com/articles/nodejs-support#customizing-the-build-process)\n2. [`mars/create-react-app-inner-buildpack`](https://github.com/mars/create-react-app-inner-buildpack)\n   * sets default [web server config](#user-content-web-server) unless `static.json` already exists\n   * enables [runtime environment variables](#user-content-environment-variables)\n3. [`heroku/static` buildpack](https://github.com/heroku/heroku-buildpack-static)\n   * [Nginx](http://nginx.org/en/) web server\n   * [configure with `static.json`](#user-content-web-server) (see also [all static web server config](https://github.com/heroku/heroku-buildpack-static#user-content-configuration))\n\n\ud83d\ude80 The runtime `web` process is the [last buildpack](https://github.com/mars/create-react-app-buildpack/blob/master/.buildpacks)'s default processes. heroku-buildpack-static uses [`bin/boot`](https://github.com/heroku/heroku-buildpack-static/blob/master/bin/release) to launch its Nginx web server. Processes may be customized by committing a [Procfile](#user-content-procfile) to the app.\n\n\n### General-purpose SPA deployment\n\n[Some kind feedback](https://github.com/mars/create-react-app-buildpack/issues/2) pointed out that this buildpack is not necessarily specific to `create-react-app`.\n\nThis buildpack can deploy any SPA [single-page app] as long as it meets the following requirements:\n\n* `npm run build` performs the transpile/bundling\n* the file `build/index.html` or [the root specified in `static.json`](#user-content-customization) exists at runtime.\n", "release_dates": []}, {"name": "crossbeam", "description": "Tools for concurrent programming in Rust", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Crossbeam\n\n[![Build Status](https://github.com/crossbeam-rs/crossbeam/workflows/CI/badge.svg)](\nhttps://github.com/crossbeam-rs/crossbeam/actions)\n[![License](https://img.shields.io/badge/license-MIT_OR_Apache--2.0-blue.svg)](\nhttps://github.com/crossbeam-rs/crossbeam#license)\n[![Cargo](https://img.shields.io/crates/v/crossbeam.svg)](\nhttps://crates.io/crates/crossbeam)\n[![Documentation](https://docs.rs/crossbeam/badge.svg)](\nhttps://docs.rs/crossbeam)\n[![Rust 1.38+](https://img.shields.io/badge/rust-1.38+-lightgray.svg)](\nhttps://www.rust-lang.org)\n[![chat](https://img.shields.io/discord/569610676205781012.svg?logo=discord)](https://discord.com/invite/JXYwgWZ)\n\nThis crate provides a set of tools for concurrent programming:\n\n#### Atomics\n\n* [`AtomicCell`], a thread-safe mutable memory location.<sup>(no_std)</sup>\n* [`AtomicConsume`], for reading from primitive atomic types with \"consume\" ordering.<sup>(no_std)</sup>\n\n#### Data structures\n\n* [`deque`], work-stealing deques for building task schedulers.\n* [`ArrayQueue`], a bounded MPMC queue that allocates a fixed-capacity buffer on construction.<sup>(alloc)</sup>\n* [`SegQueue`], an unbounded MPMC queue that allocates small buffers, segments, on demand.<sup>(alloc)</sup>\n\n#### Memory management\n\n* [`epoch`], an epoch-based garbage collector.<sup>(alloc)</sup>\n\n#### Thread synchronization\n\n* [`channel`], multi-producer multi-consumer channels for message passing.\n* [`Parker`], a thread parking primitive.\n* [`ShardedLock`], a sharded reader-writer lock with fast concurrent reads.\n* [`WaitGroup`], for synchronizing the beginning or end of some computation.\n\n#### Utilities\n\n* [`Backoff`], for exponential backoff in spin loops.<sup>(no_std)</sup>\n* [`CachePadded`], for padding and aligning a value to the length of a cache line.<sup>(no_std)</sup>\n* [`scope`], for spawning threads that borrow local variables from the stack.\n\n*Features marked with <sup>(no_std)</sup> can be used in `no_std` environments.*<br/>\n*Features marked with <sup>(alloc)</sup> can be used in `no_std` environments, but only if `alloc`\nfeature is enabled.*\n\n[`AtomicCell`]: https://docs.rs/crossbeam/latest/crossbeam/atomic/struct.AtomicCell.html\n[`AtomicConsume`]: https://docs.rs/crossbeam/latest/crossbeam/atomic/trait.AtomicConsume.html\n[`deque`]: https://docs.rs/crossbeam/latest/crossbeam/deque/index.html\n[`ArrayQueue`]: https://docs.rs/crossbeam/latest/crossbeam/queue/struct.ArrayQueue.html\n[`SegQueue`]: https://docs.rs/crossbeam/latest/crossbeam/queue/struct.SegQueue.html\n[`channel`]: https://docs.rs/crossbeam/latest/crossbeam/channel/index.html\n[`Parker`]: https://docs.rs/crossbeam/latest/crossbeam/sync/struct.Parker.html\n[`ShardedLock`]: https://docs.rs/crossbeam/latest/crossbeam/sync/struct.ShardedLock.html\n[`WaitGroup`]: https://docs.rs/crossbeam/latest/crossbeam/sync/struct.WaitGroup.html\n[`epoch`]: https://docs.rs/crossbeam/latest/crossbeam/epoch/index.html\n[`Backoff`]: https://docs.rs/crossbeam/latest/crossbeam/utils/struct.Backoff.html\n[`CachePadded`]: https://docs.rs/crossbeam/latest/crossbeam/utils/struct.CachePadded.html\n[`scope`]: https://docs.rs/crossbeam/latest/crossbeam/fn.scope.html\n\n## Crates\n\nThe main `crossbeam` crate just [re-exports](src/lib.rs) tools from\nsmaller subcrates:\n\n* [`crossbeam-channel`](crossbeam-channel)\n  provides multi-producer multi-consumer channels for message passing.\n* [`crossbeam-deque`](crossbeam-deque)\n  provides work-stealing deques, which are primarily intended for building task schedulers.\n* [`crossbeam-epoch`](crossbeam-epoch)\n  provides epoch-based garbage collection for building concurrent data structures.\n* [`crossbeam-queue`](crossbeam-queue)\n  provides concurrent queues that can be shared among threads.\n* [`crossbeam-utils`](crossbeam-utils)\n  provides atomics, synchronization primitives, scoped threads, and other utilities.\n\nThere is one more experimental subcrate that is not yet included in `crossbeam`:\n\n* [`crossbeam-skiplist`](crossbeam-skiplist)\n  provides concurrent maps and sets based on lock-free skip lists.\n\n## Usage\n\nAdd this to your `Cargo.toml`:\n\n```toml\n[dependencies]\ncrossbeam = \"0.8\"\n```\n\n## Compatibility\n\nCrossbeam supports stable Rust releases going back at least six months,\nand every time the minimum supported Rust version is increased, a new minor\nversion is released. Currently, the minimum supported Rust version is 1.38.\n\n## Contributing\n\nCrossbeam welcomes contribution from everyone in the form of suggestions, bug reports,\npull requests, and feedback. \ud83d\udc9b\n\nIf you need ideas for contribution, there are several ways to get started:\n\n* Found a bug or have a feature request?\n  [Submit an issue](https://github.com/crossbeam-rs/crossbeam/issues/new)!\n* Issues and PRs labeled with\n  [feedback wanted](https://github.com/crossbeam-rs/crossbeam/issues?utf8=%E2%9C%93&q=is%3Aopen+sort%3Aupdated-desc+label%3A%22feedback+wanted%22+)\n  need feedback from users and contributors.\n* Issues labeled with\n  [good first issue](https://github.com/crossbeam-rs/crossbeam/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc+label%3A%22good+first+issue%22)\n  are relatively easy starter issues.\n\n#### RFCs\n\nWe also have the [RFCs](https://github.com/crossbeam-rs/rfcs) repository for more\nhigh-level discussion, which is the place where we brainstorm ideas and propose\nsubstantial changes to Crossbeam.\n\nYou are welcome to participate in any open\n[issues](https://github.com/crossbeam-rs/rfcs/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc)\nor\n[pull requests](https://github.com/crossbeam-rs/rfcs/pulls?q=is%3Apr+is%3Aopen+sort%3Aupdated-desc).\n\n#### Learning resources\n\nIf you'd like to learn more about concurrency and non-blocking data structures, there's a\nlist of learning resources in our [wiki](https://github.com/crossbeam-rs/rfcs/wiki),\nwhich includes relevant blog posts, papers, videos, and other similar projects.\n\nAnother good place to visit is [merged RFCs](https://github.com/crossbeam-rs/rfcs/tree/master/text).\nThey contain elaborate descriptions and rationale for features we've introduced to\nCrossbeam, but keep in mind that some of the written information is now out of date.\n\n#### Conduct\n\nThe Crossbeam project adheres to the\n[Rust Code of Conduct](https://www.rust-lang.org/policies/code-of-conduct).\nThis describes the minimum behavior expected from all contributors.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\nSome Crossbeam subcrates have additional licensing notices.\nTake a look at other readme files in this repository for more information.\n\n#### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in the work by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n", "release_dates": []}, {"name": "curve25519-dalek", "description": "A pure-Rust implementation of group operations on Ristretto and Curve25519", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "<p align=\"center\">\n<img\n alt=\"dalek-cryptography logo: a dalek with edwards curves as sparkles coming out of its radar-schnozzley blaster thingies\"\n width=\"200px\"\n src=\"https://cdn.jsdelivr.net/gh/dalek-cryptography/curve25519-dalek/docs/assets/dalek-logo-clear.png\"/>\n</p>\n\n# Dalek elliptic curve cryptography\n\nThis repo contains pure-Rust crates for elliptic curve cryptography:\n[![curve25519 Rust]()](https://github.com/dalek-cryptography/curve25519-dalek/actions/workflows/curve25519-dalek.yml)\n\n|                 Crate                    |   Description  | Crates.io | Docs | CI                                                                                                                                                                                                                          |\n-------------------------------------------|----------------|-----------|------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n| [`curve25519\u2011dalek`](./curve25519-dalek) | A library for arithmetic over the Curve25519 and Ristretto elliptic curves and their associated scalars. | [![](https://img.shields.io/crates/v/curve25519-dalek.svg)](https://crates.io/crates/curve25519-dalek) | [![](https://img.shields.io/docsrs/curve25519-dalek)](https://docs.rs/curve25519-dalek) | [![CI](https://github.com/dalek-cryptography/curve25519-dalek/actions/workflows/curve25519-dalek.yml/badge.svg?branch=main)](https://github.com/dalek-cryptography/curve25519-dalek/actions/workflows/curve25519-dalek.yml) |\n| [`ed25519\u2011dalek`](./ed25519-dalek)       | An implementation of the EdDSA digital signature scheme over Curve25519. | [![](https://img.shields.io/crates/v/ed25519-dalek.svg)](https://crates.io/crates/ed25519-dalek) | [![](https://docs.rs/ed25519-dalek/badge.svg)](https://docs.rs/ed25519-dalek) | [![CI](https://github.com/dalek-cryptography/curve25519-dalek/actions/workflows/ed25519-dalek.yml/badge.svg?branch=main)](https://github.com/dalek-cryptography/curve25519-dalek/actions/workflows/ed25519-dalek.yml)       |\n| [`x25519\u2011dalek`](./x25519-dalek)         | An implementation of elliptic curve Diffie-Hellman key exchange over Curve25519. | [![](https://img.shields.io/crates/v/x25519-dalek.svg)](https://crates.io/crates/x25519-dalek) | [![](https://docs.rs/x25519-dalek/badge.svg)](https://docs.rs/x25519-dalek) | [![CI](https://github.com/dalek-cryptography/curve25519-dalek/actions/workflows/x25519-dalek.yml/badge.svg?branch=main)](https://github.com/dalek-cryptography/curve25519-dalek/actions/workflows/x25519-dalek.yml)         |\n\nThere is also the [`curve25519-dalek-derive`](./curve25519-dalek-derive) crate, which is just a helper crate with some macros that make curve25519-dalek easier to write.\n\n# Contributing\n\nPlease see [`CONTRIBUTING.md`](./CONTRIBUTING.md).\n\n# Code of Conduct\n\nWe follow the [Rust Code of Conduct](http://www.rust-lang.org/conduct.html),\nwith the following additional clauses:\n\n* We respect the rights to privacy and anonymity for contributors and people in\n  the community.  If someone wishes to contribute under a pseudonym different to\n  their primary identity, that wish is to be respected by all contributors.\n", "release_dates": []}, {"name": "dapp-scaffold", "description": "Scaffolding for a dapp built on Solana", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "\n# Solana dApp Scaffold Next\n\nThe Solana dApp Scaffold repos are meant to house good starting scaffolds for ecosystem developers to get up and running quickly with a front end client UI that integrates several common features found in dApps with some basic usage examples. Wallet Integration. State management. Components examples. Notifications. Setup recommendations.\n\nResponsive                     |  Desktop\n:-------------------------:|:-------------------------:\n![](scaffold-mobile.png)  |  ![](scaffold-desktop.png)\n\n## Getting Started\n\nThis is a [Next.js](https://nextjs.org/) project bootstrapped with [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app).\n\nThe responsive version for wallets and wallet adapter may not function or work as expected for mobile based on plugin and wallet compatibility. For more code examples and implementations please visit the [Solana Cookbook](https://solanacookbook.com/)\n\n## Installation\n\n```bash\nnpm install\n# or\nyarn install\n```\n\n## Build and Run\n\nNext, run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nYou can start editing the page by modifying `pages/index.tsx`. The page auto-updates as you edit the file.\n\n[API routes](https://nextjs.org/docs/api-routes/introduction) can be accessed on [http://localhost:3000/api/hello](http://localhost:3000/api/hello). This endpoint can be edited in `pages/api/hello.ts`.\n\nThe `pages/api` directory is mapped to `/api/*`. Files in this directory are treated as [API routes](https://nextjs.org/docs/api-routes/introduction) instead of React pages.\n\n## Features\n\nEach Scaffold will contain at least the following features:\n\n```\nWallet Integration with Auto Connec / Refresh\n\nState Management\n\nComponents: One or more components demonstrating state management\n\nWeb3 Js: Examples of one or more uses of web3 js including a transaction with a connection provider\n\nSample navigation and page changing to demonstate state\n\nClean Simple Styling \n\nNotifications (optional): Example of using a notification system\n\n```\n\nA Solana Components Repo will be released in the near future to house a common components library.\n\n\n### Structure\n\nThe scaffold project structure may vary based on the front end framework being utilized. The below is an example structure for the Next js Scaffold.\n \n```\n\u251c\u2500\u2500 public : publically hosted files\n\u251c\u2500\u2500 src : primary code folders and files \n\u2502   \u251c\u2500\u2500 components : should house anything considered a resuable UI component\n\u2502   \u251c\u2500\u2500 contexts` : any context considered reusable and useuful to many compoennts that can be passed down through a component tree\n\u2502   \u251c\u2500\u2500 hooks` : any functions that let you 'hook' into react state or lifecycle features from function components\n\u2502   \u251c\u2500\u2500 models` : any data structure that may be reused throughout the project\n\u2502   \u251c\u2500\u2500 pages` : the pages that host meta data and the intended `View` for the page\n\u2502   \u251c\u2500\u2500 stores` : stores used in state management\n\u2502   \u251c\u2500\u2500 styles` : contain any global and reusable styles\n\u2502   \u251c\u2500\u2500 utils` : any other functionality considered reusable code that can be referenced\n\u2502   \u251c\u2500\u2500 views` : contains the actual views of the project that include the main content and components within\nstyle, package, configuration, and other project files\n\n```\n\n## Contributing\n\nAnyone is welcome to create an issue to build, discuss or request a new feature or update to the existing code base. Please keep in mind the following when submitting an issue. We consider merging high value features that may be utilized by the majority of scaffold users. If this is not a common feature or fix, consider adding it to the component library or cookbook. Please refer to the project's architecture and style when contributing. \n\nIf submitting a feature, please reference the project structure shown above and try to follow the overall architecture and style presented in the existing scaffold.\n\n### Committing\n\nTo choose a task or make your own, do the following:\n\n1. [Add an issue](https://github.com/solana-dev-adv/solana-dapp-next/issues/new) for the task and assign it to yourself or comment on the issue\n2. Make a draft PR referencing the issue.\n\nThe general flow for making a contribution:\n\n1. Fork the repo on GitHub\n2. Clone the project to your own machine\n3. Commit changes to your own branch\n4. Push your work back up to your fork\n5. Submit a Pull request so that we can review your changes\n\n**NOTE**: Be sure to merge the latest from \"upstream\" before making a \npull request!\n\nYou can find tasks on the [project board](https://github.com/solana-dev-adv/solana-dapp-next/projects/1) \nor create an issue and assign it to yourself.\n\n\n## Learn More Next Js\n\nTo learn more about Next.js, take a look at the following resources:\n\n- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\n- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\n\nYou can check out [the Next.js GitHub repository](https://github.com/vercel/next.js/) - your feedback and contributions are welcome!\n\n## Deploy on Vercel\n\nThe easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.\n\nCheck out our [Next.js deployment documentation](https://nextjs.org/docs/deployment) for more details.\n", "release_dates": []}, {"name": "dc-homedir-skeleton", "description": "Base directory struct for the `solana` user on Solana's datacenter infrastructure", "language": "Shell", "license": null, "readme": null, "release_dates": []}, {"name": "defi-hackathon", "description": null, "language": null, "license": null, "readme": "# Solana Foundation x Serum DeFi Hackathon &middot; Up to $400k in prizes\n#### Bringing Blazing Speed, Low Fees, and Scalability to Decentralized Finance\n\n* Hackathon deadline: March 1, 2021 | 11:59pm PT\n* Type: Online and global\n* Submission form: [Official Website](https://solana.com/defi)\n* More details: [Announcement Blog Post](https://medium.com/solana-labs/announcing-the-solana-foundation-x-serum-defi-hackathon-7e34290f8262)\n\n## Introduction\nSolana is a fast, low-fee, and censorship-resistant blockchain designed to enable builders to quickly deploy and scale applications to billions of users globally. The Solana Foundation has teamed up with Serum, the largest DeFi project in the ecosystem, to host a hackathon focused on allowing developers to experiment and leverage our technology to create a plethora of DeFi (Decentralized Finance) applications.\n\nAs long as you have an Internet connection, you're invited to join the global hackathon! Combining Serum's infrastructure and tooling with Solana\u2019s core features gives hackers an open design space to expand the overall DeFi ecosystem. While participants are encouraged to build novel DeFi apps, hackers can build infrastructure or any tool they believe will have an impact on the ecosystem. The only requirement is that teams must incorporate Solana into their project in some way.  Take a look at this list of [DeFi ideas for inspiration](https://github.com/solana-labs/defi-hackathon/blob/main/ideas.md).\n\n## Get Started Building\n\n* [Solana Documentation](https://docs.solana.com/)\n* [Solana Dapp Scaffolding](https://github.com/solana-labs/dapp-scaffold)\n* [Intro to Programming on Solana](https://paulx.dev/blog/2021/01/14/programming-on-solana-an-introduction/)\n* [Serum Developer Resources](https://serum-academy.com/en/developer-resources/)\n* [Framework for building on Serum](https://github.com/project-serum/anchor)\n* [Solana Cluster Overview](https://docs.solana.com/cluster/overview)\n* [Getting started with Rust](https://www.rust-lang.org/learn)\n* [Solana Program Library Documentation](https://spl.solana.com/)\n* [Hello World Example](https://github.com/solana-labs/example-helloworld)\n* [Discord Support Chat](https://discord.gg/uNHzdyZRMB): Live technical support and help\n* [Find a teammate directory](https://airtable.com/shrKQ0KdkKjoejQex/tblRhtznXGRg28mnJ)\n\n## Other Resources + DeFi Building Blocks\n\n* [Automated Market Maker + Swap Reference Implementation](https://github.com/solana-labs/oyster-swap)\n* [Borrow/Lend Reference Implementation](https://github.com/solana-labs/oyster-lending)\n* [Margin Reference Implementation](https://github.com/solana-labs/oyster-margin)\n* [Wormhole Documentation: Ethereum<>Solana bi-directional bridge](https://github.com/certusone/wormhole)\n* [Chainlink<>Solana Oracle Implementation](https://github.com/czl1378/solana-flux-aggregator)\n* [Full Stack dApp Development Environment by Decentology](https://dappstarter.decentology.com/)\n* [Run your own Serum DEX](https://serum-academy.com/en/dex-list/)\n* [List tokens on the Serum DEX](https://serum-academy.com/en/add-market/)\n* [Solana Development Tutorial](https://solongwallet.medium.com/solana-development-tutorial-things-you-should-know-before-structuring-your-code-807f0e2ee43)\n\n## Judging\n\nParticipants may submit a maximum of 1 project by the hackathon deadline. Once all submissions are collected, Solana will distribute a list to the judges for the evaluation process. Teams and individuals are evaluated on the following criteria:\n\n1. Functionality\n2. Potential impact\n3. Novelty\n4. Design + UX\n5. Composability\n\nAfter judges complete individual evaluations, the hackathon organizers will discuss with the judges to choose the winners based on the project's weighted scores. Winners of the event will be announced shortly after the end of the hackathon. \n\nOnce winners have been selected, the top 9 teams will have the opportunity to compete for an additional $200k in seed funding. This gives serious builders a chance at jumping full-time into the Solana ecosystem and receive extensive resources from the Solana Foundation, Project Serum, and leading venture capital firms.\n\n**Prizes**\n\n| Place                                  | Prize                                        |\n|----------------------------------------|----------------------------------------------|\n| Grand Prize Winner                           | $200k in seed funding  |\n| First Place Winners                            | 2 winners up to $50k each + Solana Swag |\n| Second Place Winners                          | 3 teams of $20k each + Solana Swag              |\n| Third Place Winners                            | 4 teams of $10k each + Solana Swag              |\n| Community Choice Prize                 | $5k + Solana Swag              |\n| Torus Prize                            | $2k                                          |\n| All participants that submit a project | $100                         |\n\n## Discord Discussion Channels\n\n* [#hackathon-announcements](https://discord.gg/PDy4D4EZw9): Announcements from the Solana Foundation and Serum team\n* [#hackathon-questions](https://discord.gg/uNHzdyZRMB): Technical support and help from Solana and Serum Engineers\n* [#hackathon-team-formation](https://discord.gg/gYAEpBJace): Introduce yourself, find a team, or seek additional team members\n\n## Code of Conduct \n\nThe Solana x Serum DeFi Hackathon welcomes any one from around the world to participate and is intended to create an inclusive environment for building, collaboration, creativity, and impact. We value the participation of each member of the community and want everyone involved to be respected. Accordingly, hackathon administrators, judges, and participants are expected to adhere to the Code of Conduct outlined below for the duration of the hackathon. Event organizers will enforce this code and have the right to disqualify any individual or team that breaks the code.\n\n* Be Respectful: Be kind to all who participate in the event. Do not insult or put down other attendees.\n\n* Behave Professionally. Remember that harassment, racism, sexism, or exclusionary jokes are not appropriate for this event. Harassment includes offensive verbal comments related to gender, sexual orientation, disability, physical appearance, race, and/or religion. Sexual images in public forums, deliberate intimidation, online stalking, following, sustained disruption of virtual presentations, or any other inappropriate action is strictly prohibited\n\n* Be Thoughtful: In the spirit of open source and inclusiveness, there may be minors participating in the hackathon. Keep this in mind when communicating or speaking in public forums.\n\n* Be Open: We welcome attendees from all backgrounds. This event is about increasing awareness for Solana and the greater crypto space. Please be welcoming to all who register for the event and help us create a friendly environment for all.\n\n* Believe in Yourself: Crypto opens the door for anyone to permissionlessly build applications that will change how we all interact with finance, gaming, and the Internet as a whole. Dream big and use this powerful technology to create a better world.\n\n## Legal Disclaimer\n\nThe Solana Foundation x Serum DeFi Hackathon is a competition where projects will be evaluated by judges on their technological merits without consideration of legal viability. Participants in the Hackathon will create software solely for purposes of evaluation by judges as part of a competition and not for commercial deployment or release as part of the Hackathon.All participants must comply with applicable laws and regulations when releasing any software that they develop as part of the Hackathon.\n\nThe Hackathon ideas and developer resources that Solana Foundation (\u201cSF\u201d) provides are for educational and inspirational purposes only. SF does not encourage, induce or sanction the deployment of any such applications in violation of applicable laws or regulations. SF does not encourage, induce or sanction the deployment, integration or use of any such applications (including the code comprising the Solana blockchain protocol) in violation of applicable laws or regulations and hereby prohibits any such deployment, integration or use. This includes use of any such applications by the reader (a) in violation of export control or sanctions laws of the United States or any other applicable jurisdiction, (b) if the reader is located in or ordinarily resident in a country or territory subject to comprehensive sanctions administered by the U.S. Office of Foreign Assets Control (OFAC), (c) if the reader is or is working on behalf of a Specially Designated National (SDN) or a person subject to similar blocking or denied party prohibitions, or (d) in violation of the Commodities and Exchange Act.\n\nThe reader should be aware that U.S. export control and sanctions laws prohibit U.S. persons (and other persons that are subject to such laws) from transacting with persons in certain countries and territories or that are on the SDN list. As a project based primarily on open-source software, it is possible that such sanctioned persons may nevertheless bypass prohibitions, obtain the code comprising the Solana blockchain protocol (or other project code or applications) and deploy, integrate, or otherwise use it. Accordingly, there is a risk to individuals that other persons using the Solana blockchain protocol may be sanctioned persons and that transactions with such persons would be a violation of U.S. export controls and sanctions law. This risk applies to individuals, organizations, and other ecosystem participants that deploy, integrate, or use the Solana blockchain protocol code directly (e.g., as a node operator), and individuals that transact on the Solana blockchain through light clients, third party interfaces, and/or wallet software.\n\nIn accordance with the open source Apache 2.0 license (\"OS License\") pursuant to which the Solana Services are provided, by participating in the Hackathon, you hereby grant to Company and the Solana community a perpetual, irrevocable, royalty-free, worldwide, nonexclusive copyright license to reproduce, publicly display, publicly perform, distribute, create derivative works based upon, and otherwise use and sublicense any contributions or developments (\"Developments\") provided by you in connection with the Hackathon and such derivative works in source code or object code form. We may reproduce and distribute copies of the Developments or derivative works thereof in any medium, with or without modifications, and in source code or object code form subject to the OS License. Any contribution intentionally submitted for inclusion as part of the Hackathon shall be under the terms and conditions of the OS License. You agree not to challenge or contest our rights or anyone else's rights to use the Developments. You agree that it is your sole responsibility to obtain all permissions and releases necessary for the grant of the rights contained in this Section. You agree to take, at your expense, any further action (including execution of affidavits, tax forms, and other documents) reasonably requested by us to effect, perfect or confirm the rights as set forth in this Section. You will not be entitled to compensation for any use by Company, or its agents, licensees or assignees, of your contributions or developments, except as expressly provided herein.\n", "release_dates": []}, {"name": "dexterity", "description": "Reference implementation of a decentralized exchange for custom instruments, risk, and fees", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Dexterity\n## What is Dexterity\nAt a high level, Dexterity is a smart contract (or collection of smart contracts) that allow for the creation of a decentralized exchange on the Solana blockchain. The modular design of these contracts allows operators to create generic instruments with customizable risk and fee models.\n\n## To Deploy\nIn order to deploy Dexterity, you will need to modify the mock keys in `master_program_config.json` to match the target program IDs. The build script will automatically fill in the keys into the program files.\n\nIf you would like to use the `deploy_all.sh` script. Paste the upgrade authority keypair for each of these contracts into the file `~/.config/solana/dexterity_shared.json`. Be sure to not commit this file.\n\n## Build and Run Tests \n**Requirements:**\n- rust nightly\n- solana clis\n- [Optional] solana-test-validator\n\nFirst, install poetry for the python client (only needed the first time around):\n\n```bash\ncd client\npoetry install\n```\n\nThen build and test the protocol\n\n```bash\ngit submodule init\ngit submodule update\n./build.sh\n./test.sh\n```\n\nNote that if you use the `--replace` option in the `build.sh` script, you will need to explicitly call `cargo build-bpf` in the root directory to seed the target folder with program keypair files.\n", "release_dates": []}, {"name": "diem-devtools", "description": null, "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# diem-devtools\n\nThis repository contains the source code for developer tools and libraries built for\n[Diem Core](https://github.com/diem/diem/). Currently, this includes:\n\n* [**nextest**](nextest): a new, faster Cargo test runner [![Documentation (main)](https://img.shields.io/badge/docs-main-brightgreen)](https://diem.github.io/diem-devtools/rustdoc/nextest-runner/)\n* [**quick-junit**](quick-junit): a data model, serializer (and in the future deserializer) for JUnit/XUnit XML [![quick-junit on crates.io](https://img.shields.io/crates/v/quick-junit)](https://crates.io/crates/quick-junit) [![Documentation (latest release)](https://img.shields.io/badge/docs-latest-brightgreen)](https://docs.rs/quick-junit/) [![Documentation (main)](https://img.shields.io/badge/docs-main-purple)](https://diem.github.io/diem-devtools/rustdoc/quick_junit/)\n* [**datatest-stable**](datatest-stable): data-driven testing on stable Rust [![datatest-stable on crates.io](https://img.shields.io/crates/v/datatest-stable)](https://crates.io/crates/datatest-stable) [![Documentation (latest release)](https://img.shields.io/badge/docs-latest-brightgreen)](https://docs.rs/datatest-stable/) [![Documentation (main)](https://img.shields.io/badge/docs-main-purple)](https://diem.github.io/diem-devtools/rustdoc/datatest_stable/) \n\n## Minimum supported Rust version\n\nThese crates target the latest stable version of Rust.\n\nWhile a crate is pre-release status (0.x.x) it may have its MSRV bumped in a patch release. Once a crate has reached\n1.x, any MSRV bump will be accompanied with a new minor version.\n\n## Contributing\n\nSee the [CONTRIBUTING](CONTRIBUTING.md) file for how to help out.\n\n## License\n\nThis project is available under the terms of either the [Apache 2.0 license](LICENSE-APACHE) or the [MIT\nlicense](LICENSE-MIT).\n", "release_dates": []}, {"name": "ecosystem", "description": "Project files for Solana ecosystem members", "language": null, "license": null, "readme": "---\n# NOTE: This repository is deprecated. To submit your project info, please visit https://solana.com/ecosystem/submit-project.\n---\n\n# Solana Ecosystem\n\nThis repository is the data source for the Solana Ecosystem page,\nlocated at [solana.com/ecosystem](https://solana.com/ecosystem).\n\n# Contributing Guidelines\n\nA project is composed of two files: a Markdown file with headers, and an\nimage. To add a new project to the ecosystem page, create both a new Markdown\nfile in the `projects` directory and add a new image in the `img` directory.\n\n**!Important!**:\nShould your Project already exist within this repo, refrain from creating a new\nMarkdown file in the `projects` directory! Rather adapt your old one in a new PR.\nSame goes for changed images or Logos for your Project.\n\n### Example File\n\n```\n---\nslug: \"yourslug\"\ndate: \"2020-09-30\"\ntitle: \"Project Title\"\nlogline: \"Write a short description about your project.\"\ncta: \"https://yourwebsite.tld/call-to-action\"\nlogo: /img/yourimage.svg\ncategory: amm, app\nstatus: building\nwebsite: https://yourwebsite.tld/\ntwitter: https://twitter.com/yourproject\ntelegram: https://t.me/yourproject\ndiscord: https://discord.com/invite/12A3bcDE1f\n---\n\nThis project will look nicely on the ecosystem page and very much advance\nthe Solana Ecosystem. All while following the community rules, and the ones\nstated herein.\n```\n\nExample(!) Markdown headers are above. Below are guidelines for each field:\n\n- **(required)** `slug`: The page URL that follows after solana.com/ecosystem/\n- **(required)** `date`: The date of project addition\n- **(required)** `title`: The title of the project\n- **(required)** `logline`: The one line summary of the project and its integration to Solana\n- **(required)** `cta`: A URL to direct users to at the bottom of the page\n- **(required)** `logo`: A relative path to the corresponding image\n- **(enforced)** `category`: A comma separated list of categories describing the project from the ones below!\n- **(required)** `status`: The status of the project: `live`, `building`, or `closed`\n- **(optional)** `website`: URL to the website (optional)\n- **(required)** `twitter`: URL to Twitter page (required)\n- **(optional)** `telegram`: URL to Telegram channel (optional)\n- **(optional)** `discord`: URL to Discord invite (optional)\n\n### Categories\n\nAvailable classifications for projects are as follows:\n\n```\namm\napp\ndefi\ndex\nexchange\nexplorer\nfund\ngame\ngovernance\ninfra\ninvestmentfund\nmetaplex\nnft\noracle\nrpc\nsdk\nspl\nstablecoin\nstake-pool\ntools\nwallet\n```\n\nPlease only use existing ones and _watch out for typos_!  \nIf you think there is need for another one to be added, ask so in your PR.\n\n### Image Guidelines\n\nAll image files must be 100x100px / at an aspect ratio of ~1.  \nOnly .svg, .png, and .jpg and .jpeg files are accepted.\nPlease refrain from using SVGs with embedded PNG or JPG images!\n\n### Linting\n\n**Everything of the above gets linted against, see the created comments.**\n\n## Questions\n\nHave any questions? Email [ryan@solana.com](mailto:ryan@solana.com) or find me on [Discord](https://solana.com/discord)!\n", "release_dates": []}, {"name": "ed25519", "description": "Portable C implementation of Ed25519, a high-speed high-security public-key signature system.", "language": "C", "license": {"key": "zlib", "name": "zlib License", "spdx_id": "Zlib", "url": "https://api.github.com/licenses/zlib", "node_id": "MDc6TGljZW5zZTI3"}, "readme": "Ed25519\n=======\n\nThis is a portable implementation of [Ed25519](http://ed25519.cr.yp.to/) based\non the SUPERCOP \"ref10\" implementation. Additionally there is key exchanging\nand scalar addition included to further aid building a PKI using Ed25519. All\ncode is licensed under the permissive zlib license.\n\nAll code is pure ANSI C without any dependencies, except for the random seed\ngeneration which uses standard OS cryptography APIs (`CryptGenRandom` on\nWindows, `/dev/urandom` on nix). If you wish to be entirely portable define\n`ED25519_NO_SEED`. This disables the `ed25519_create_seed` function, so if your\napplication requires key generation you must supply your own seeding function\n(which is simply a 256 bit (32 byte) cryptographic random number generator).\n\n\nPerformance\n-----------\n\nOn a Windows machine with an Intel Pentium B970 @ 2.3GHz I got the following\nspeeds (running on only one a single core):\n\n    Seed generation: 64us (15625 per second)\n    Key generation: 88us (11364 per second)\n    Message signing (short message): 87us (11494 per second)\n    Message verifying (short message): 228us (4386 per second)\n    Scalar addition: 100us (10000 per second)\n    Key exchange: 220us (4545 per second)\n\nThe speeds on other machines may vary. Sign/verify times will be higher with\nlonger messages. The implementation significantly benefits from 64 bit\narchitectures, if possible compile as 64 bit.\n\n\nUsage\n-----\n\nSimply add all .c and .h files in the `src/` folder to your project and include\n`ed25519.h` in any file you want to use the API. If you prefer to use a shared\nlibrary, only copy `ed25519.h` and define `ED25519_DLL` before importing. A\nwindows DLL is pre-built.\n\nThere are no defined types for seeds, private keys, public keys, shared secrets\nor signatures. Instead simple `unsigned char` buffers are used with the\nfollowing sizes:\n\n```c\nunsigned char seed[32];\nunsigned char signature[64];\nunsigned char public_key[32];\nunsigned char private_key[64];\nunsigned char scalar[32];\nunsigned char shared_secret[32];\n```\n\nAPI\n---\n\n```c\nint ed25519_create_seed(unsigned char *seed);\n```\n\nCreates a 32 byte random seed in `seed` for key generation. `seed` must be a\nwritable 32 byte buffer. Returns 0 on success, and nonzero on failure.\n\n```c\nvoid ed25519_create_keypair(unsigned char *public_key, unsigned char *private_key,\n                            const unsigned char *seed);\n```\n\nCreates a new key pair from the given seed. `public_key` must be a writable 32\nbyte buffer, `private_key` must be a writable 64 byte buffer and `seed` must be\na 32 byte buffer.\n\n```c\nvoid ed25519_sign(unsigned char *signature,\n                  const unsigned char *message, size_t message_len,\n                  const unsigned char *public_key, const unsigned char *private_key);\n```\n\nCreates a signature of the given message with the given key pair. `signature`\nmust be a writable 64 byte buffer. `message` must have at least `message_len`\nbytes to be read. \n\n```c\nint ed25519_verify(const unsigned char *signature,\n                   const unsigned char *message, size_t message_len,\n                   const unsigned char *public_key);\n```\n\nVerifies the signature on the given message using `public_key`. `signature`\nmust be a readable 64 byte buffer. `message` must have at least `message_len`\nbytes to be read. Returns 1 if the signature matches, 0 otherwise.\n\n```c\nvoid ed25519_add_scalar(unsigned char *public_key, unsigned char *private_key,\n                        const unsigned char *scalar);\n```\n\nAdds `scalar` to the given key pair where scalar is a 32 byte buffer (possibly\ngenerated with `ed25519_create_seed`), generating a new key pair. You can\ncalculate the public key sum without knowing the private key and vice versa by\npassing in `NULL` for the key you don't know. This is useful for enforcing\nrandomness on a key pair by a third party while only knowing the public key,\namong other things.  Warning: the last bit of the scalar is ignored - if\ncomparing scalars make sure to clear it with `scalar[31] &= 127`.\n\n\n```c\nvoid ed25519_key_exchange(unsigned char *shared_secret,\n                          const unsigned char *public_key, const unsigned char *private_key);\n```\n\nPerforms a key exchange on the given public key and private key, producing a\nshared secret. It is recommended to hash the shared secret before using it.\n`shared_secret` must be a 32 byte writable buffer where the shared secret will\nbe stored.\n\nExample\n-------\n\n```c\nunsigned char seed[32], public_key[32], private_key[64], signature[64];\nunsigned char other_public_key[32], other_private_key[64], shared_secret[32];\nconst unsigned char message[] = \"TEST MESSAGE\";\n\n/* create a random seed, and a key pair out of that seed */\nif (ed25519_create_seed(seed)) {\n    printf(\"error while generating seed\\n\");\n    exit(1);\n}\n\ned25519_create_keypair(public_key, private_key, seed);\n\n/* create signature on the message with the key pair */\ned25519_sign(signature, message, strlen(message), public_key, private_key);\n\n/* verify the signature */\nif (ed25519_verify(signature, message, strlen(message), public_key)) {\n    printf(\"valid signature\\n\");\n} else {\n    printf(\"invalid signature\\n\");\n}\n\n/* create a dummy keypair to use for a key exchange, normally you'd only have\nthe public key and receive it through some communication channel */\nif (ed25519_create_seed(seed)) {\n    printf(\"error while generating seed\\n\");\n    exit(1);\n}\n\ned25519_create_keypair(other_public_key, other_private_key, seed);\n\n/* do a key exchange with other_public_key */\ned25519_key_exchange(shared_secret, other_public_key, private_key);\n\n/* \n    the magic here is that ed25519_key_exchange(shared_secret, public_key,\n    other_private_key); would result in the same shared_secret\n*/\n\n```\n\nLicense\n-------\nAll code is released under the zlib license. See license.txt for details.\n", "release_dates": []}, {"name": "ed25519-dalek", "description": "Only used for upstreaming fixes", "language": "Rust", "license": {"key": "bsd-3-clause", "name": "BSD 3-Clause \"New\" or \"Revised\" License", "spdx_id": "BSD-3-Clause", "url": "https://api.github.com/licenses/bsd-3-clause", "node_id": "MDc6TGljZW5zZTU="}, "readme": "# ed25519-dalek [![](https://img.shields.io/crates/v/ed25519-dalek.svg)](https://crates.io/crates/ed25519-dalek) [![](https://docs.rs/ed25519-dalek/badge.svg)](https://docs.rs/ed25519-dalek) [![](https://travis-ci.org/dalek-cryptography/ed25519-dalek.svg?branch=master)](https://travis-ci.org/dalek-cryptography/ed25519-dalek?branch=master)\n\nFast and efficient Rust implementation of ed25519 key generation, signing, and\nverification in Rust.\n\n# Documentation\n\nDocumentation is available [here](https://docs.rs/ed25519-dalek).\n\n# Benchmarks\n\nOn an Intel Skylake i9-7900X running at 3.30 GHz, without TurboBoost, this code achieves\nthe following performance benchmarks:\n\n    \u2203!isis\u24b6mistakenot:(master *=)~/code/rust/ed25519-dalek \u2234 cargo bench\n       Compiling ed25519-dalek v0.7.0 (file:///home/isis/code/rust/ed25519-dalek)\n        Finished release [optimized] target(s) in 3.11s\n          Running target/release/deps/ed25519_benchmarks-721332beed423bce\n\n    Ed25519 signing                     time:   [15.617 us 15.630 us 15.647 us]\n    Ed25519 signature verification      time:   [45.930 us 45.968 us 46.011 us]\n    Ed25519 keypair generation          time:   [15.440 us 15.465 us 15.492 us]\n\nBy enabling the avx2 backend (on machines with compatible microarchitectures),\nthe performance for signature verification is greatly improved:\n\n    \u2203!isis\u24b6mistakenot:(master *=)~/code/rust/ed25519-dalek \u2234 export RUSTFLAGS=-Ctarget_cpu=native\n    \u2203!isis\u24b6mistakenot:(master *=)~/code/rust/ed25519-dalek \u2234 cargo bench --features=avx2_backend\n       Compiling ed25519-dalek v0.7.0 (file:///home/isis/code/rust/ed25519-dalek)\n        Finished release [optimized] target(s) in 4.28s\n          Running target/release/deps/ed25519_benchmarks-e4866664de39c84d\n    Ed25519 signing                     time:   [15.923 us 15.945 us 15.967 us]\n    Ed25519 signature verification      time:   [33.382 us 33.411 us 33.445 us]\n    Ed25519 keypair generation          time:   [15.246 us 15.260 us 15.275 us]\n\nIn comparison, the equivalent package in Golang performs as follows:\n\n    \u2203!isis\u24b6mistakenot:(master *=)~/code/go/src/github.com/agl/ed25519 \u2234 go test -bench .\n    BenchmarkKeyGeneration     30000             47007 ns/op\n    BenchmarkSigning           30000             48820 ns/op\n    BenchmarkVerification      10000            119701 ns/op\n    ok      github.com/agl/ed25519  5.775s\n\nMaking key generation and signing a rough average of 2x faster, and\nverification 2.5-3x faster depending on the availability of avx2.  Of course, this\nis just my machine, and these results\u2014nowhere near rigorous\u2014should be taken\nwith a handful of salt.\n\nTranslating to a rough cycle count: we multiply by a factor of 3.3 to convert\nnanoseconds to cycles per second on a 3300 Mhz CPU, that's 110256 cycles for\nverification and 52618 for signing, which is competitive with hand-optimised\nassembly implementations.\n\nAdditionally, if you're using a CSPRNG from the `rand` crate, the `nightly`\nfeature will enable `u128`/`i128` features there, resulting in potentially\nfaster performance.\n\nIf your protocol or application is able to batch signatures for verification,\nthe `verify_batch()` function has greatly improved performance.  On the\naforementioned Intel Skylake i9-7900X, verifying a batch of 96 signatures takes\n1.7673ms.  That's 18.4094us, or roughly 60750 cycles, per signature verification,\nmore than double the speed of batch verification given in the original paper\n(this is likely not a fair comparison as that was a Nehalem machine).\nThe numbers after the `/` in the test name refer to the size of the batch:\n\n    \u2203!isis\u24b6mistakenot:(master *=)~/code/rust/ed25519-dalek \u2234 export RUSTFLAGS=-Ctarget_cpu=native\n    \u2203!isis\u24b6mistakenot:(master *=)~/code/rust/ed25519-dalek \u2234 cargo bench --features=avx2_backend batch\n       Compiling ed25519-dalek v0.8.0 (file:///home/isis/code/rust/ed25519-dalek)\n        Finished release [optimized] target(s) in 34.16s\n          Running target/release/deps/ed25519_benchmarks-cf0daf7d68fc71b6\n    Ed25519 batch signature verification/4   time:   [105.20 us 106.04 us 106.99 us]\n    Ed25519 batch signature verification/8   time:   [178.66 us 179.01 us 179.39 us]\n    Ed25519 batch signature verification/16  time:   [325.65 us 326.67 us 327.90 us]\n    Ed25519 batch signature verification/32  time:   [617.96 us 620.74 us 624.12 us]\n    Ed25519 batch signature verification/64  time:   [1.1862 ms 1.1900 ms 1.1943 ms]\n    Ed25519 batch signature verification/96  time:   [1.7611 ms 1.7673 ms 1.7742 ms]\n    Ed25519 batch signature verification/128 time:   [2.3320 ms 2.3376 ms 2.3446 ms]\n    Ed25519 batch signature verification/256 time:   [5.0124 ms 5.0290 ms 5.0491 ms]\n\nAs you can see, there's an optimal batch size for each machine, so you'll likely\nwant to your the benchmarks on your target CPU to discover the best size.  For\nthis machine, around 100 signatures per batch is the optimum:\n\n![](https://github.com/dalek-cryptography/ed25519-dalek/blob/master/res/batch-violin-benchmark.svg)\n\nAdditionally, thanks to Rust, this implementation has both type and memory\nsafety.  It's also easily readable by a much larger set of people than those who\ncan read qhasm, making it more readily and more easily auditable.  We're of\nthe opinion that, ultimately, these features\u2014combined with speed\u2014are more\nvaluable than simply cycle counts alone.\n\n### A Note on Signature Malleability\n\nThe signatures produced by this library are malleable, as discussed in\n[the original paper](https://ed25519.cr.yp.to/ed25519-20110926.pdf):\n\n![](https://github.com/dalek-cryptography/ed25519-dalek/blob/master/res/ed25519-malleability.png)\n\nWe could eliminate the malleability property by multiplying by the curve\ncofactor, however, this would cause our implementation to *not* match the\nbehaviour of every other implementation in existence.  As of this writing,\n[RFC 8032](https://tools.ietf.org/html/rfc8032), \"Edwards-Curve Digital\nSignature Algorithm (EdDSA),\" advises that the stronger check should be done.\nWhile we agree that the stronger check should be done, it is our opinion that\none shouldn't get to change the definition of \"ed25519 verification\" a decade\nafter the fact, breaking compatibility with every other implementation.\n\nIn short, if malleable signatures are bad for your protocol, don't use them.\nConsider using a curve25519-based Verifiable Random Function (VRF), such as\n[Trevor Perrin's VXEdDSA](https://www.whispersystems.org/docs/specifications/xeddsa/),\ninstead.  We\n[plan](https://github.com/dalek-cryptography/curve25519-dalek/issues/9) to\neventually support VXEdDSA in curve25519-dalek.\n\n# Installation\n\nTo install, add the following to your project's `Cargo.toml`:\n\n```toml\n[dependencies.ed25519-dalek]\nversion = \"1\"\n```\n\nThen, in your library or executable source, add:\n\n```rust\nextern crate ed25519_dalek;\n```\n\n# Features\n\nTo cause your application to build `ed25519-dalek` with the nightly feature\nenabled by default, instead do:\n\n```toml\n[dependencies.ed25519-dalek]\nversion = \"1\"\nfeatures = [\"nightly\"]\n```\n\nTo cause your application to instead build with the nightly feature enabled\nwhen someone builds with `cargo build --features=\"nightly\"` add the following\nto the `Cargo.toml`:\n\n```toml\n[features]\nnightly = [\"ed25519-dalek/nightly\"]\n```\n\nTo enable [serde](https://serde.rs) support, build `ed25519-dalek` with:\n\n```toml\n[dependencies.ed25519-dalek]\nversion = \"1\"\nfeatures = [\"serde\"]\n```\n\nBy default, `ed25519-dalek` builds against `curve25519-dalek`'s `u64_backend`\nfeature, which uses Rust's `i128` feature to achieve roughly double the speed as\nthe `u32_backend` feature.  When targetting 32-bit systems, however, you'll\nlikely want to compile with\n `cargo build --no-default-features --features=\"u32_backend\"`.\nIf you're building for a machine with avx2 instructions, there's also the\nexperimental `avx2_backend`.  To use it, compile with\n`RUSTFLAGS=\"-C target_cpu=native\" cargo build --no-default-features --features=\"avx2_backend\"`\n", "release_dates": []}, {"name": "elastic-ci-stack-for-aws", "description": "A simple, flexible, auto-scaling cluster of build agents running in your own AWS VPC", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<h1><img alt=\"Elastic CI Stack for AWS\" src=\"https://cdn.rawgit.com/buildkite/elastic-ci-stack-for-aws/master/images/banner.png\"></h1>\n\n![Build status](https://badge.buildkite.com/d178ab942e2f606a83e79847704648437d82a9c5fdb434b7ae.svg?branch=master)\n\nThe Buildkite Elastic CI Stack gives you a private, autoscaling [Buildkite Agent](https://buildkite.com/docs/agent) cluster. Use it to parallelize legacy tests across hundreds of nodes, run tests and deployments for all your Linux-based services and apps, or run AWS ops tasks.\n\n**For documentation on a [release](https://github.com/buildkite/elastic-ci-stack-for-aws/releases), such as [the latest stable release](https://github.com/buildkite/elastic-ci-stack-for-aws/releases/latest), please see its _Documentation_ section.**\n\nFeatures:\n\n- All major AWS regions\n- Configurable instance size\n- Configurable number of buildkite agents per instance\n- Configurable spot instance bid price\n- Configurable auto-scaling based on build activity\n- Docker and Docker Compose support\n- Per-pipeline S3 secret storage (with SSE encryption support)\n- Docker Registry push/pull support\n- CloudWatch logs for system and buildkite agent events\n- CloudWatch metrics from the Buildkite API\n- Support for stable, beta or edge Buildkite Agent releases\n- Create as many instances of the stack as you need\n- Rolling updates to stack instances to reduce interruption\n\n## Contents\n\n<!-- toc -->\n\n- [Getting Started](#getting-started)\n- [Build Secrets](#build-secrets)\n- [What\u2019s On Each Machine?](#whats-on-each-machine)\n- [What Type of Builds Does This Support?](#what-type-of-builds-does-this-support)\n- [Multiple Instances of the Stack](#multiple-instances-of-the-stack)\n- [Autoscaling](#autoscaling)\n- [Docker Registry Support](#docker-registry-support)\n- [Versions](#versions)\n- [Updating Your Stack](#updating-your-stack)\n- [CloudWatch Metrics](#cloudwatch-metrics)\n- [Reading Instance and Agent Logs](#reading-instance-and-agent-logs)\n- [Optimizing for Slow Docker Builds](#optimizing-for-slow-docker-builds)\n- [Security](#security)\n- [Development](#development)\n- [Questions and Support](#questions-and-support)\n- [Licence](#licence)\n\n<!-- tocstop -->\n\n## Getting Started\n\nSee the [Elastic CI Stack for AWS guide](https://buildkite.com/docs/guides/elastic-ci-stack-aws) for a step-by-step guide, or jump straight in:\n\n[![Launch AWS Stack](https://cdn.rawgit.com/buildkite/cloudformation-launch-stack-button-svg/master/launch-stack.svg)](https://console.aws.amazon.com/cloudformation/home#/stacks/new?stackName=buildkite&templateURL=https://s3.amazonaws.com/buildkite-aws-stack/latest/aws-stack.json)\n\nCurrent release is ![](https://img.shields.io/github/release/buildkite/elastic-ci-stack-for-aws.svg). See [Releases](https://github.com/buildkite/elastic-ci-stack-for-aws/releases) for older releases, or [Versions](#versions) for development version\n\n> Although the stack will create it's own VPC by default, we highly recommend following best practice by setting up a separate development AWS account and using role switching and consolidated billing\u2014see the [Delegate Access Across AWS Accounts tutorial](http://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html) for more information.\n\nIf you'd like to use the [AWS CLI](https://aws.amazon.com/cli/), download [`config.json.example`](config.json.example), rename it to `config.json`, and then run the below command:\n\n```bash\naws cloudformation create-stack \\\n  --output text \\\n  --stack-name buildkite \\\n  --template-url \"https://s3.amazonaws.com/buildkite-aws-stack/latest/aws-stack.json\" \\\n  --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \\\n  --parameters $(cat config.json)\n```\n\n## Build Secrets\n\nThe stack will have created an S3 bucket for you (or used the one you provided as the `SecretsBucket` parameter). This will be where the agent will fetch your SSH private keys for source control, and environment hooks to provide other secrets to your builds.\n\nThe following s3 objects are downloaded and processed:\n\n* `/env` - An [agent environment hook](https://buildkite.com/docs/agent/hooks)\n* `/private_ssh_key` - A private key that is added to ssh-agent for your builds\n* `/git-credentials` - A [git-credentials](https://git-scm.com/docs/git-credential-store#_storage_format) file for git over https\n* `/{pipeline-slug}/env` - An [agent environment hook](https://buildkite.com/docs/agent/hooks), specific to a pipeline\n* `/{pipeline-slug}/private_ssh_key` - A private key that is added to ssh-agent for your builds, specific to the pipeline\n* `/{pipeline-slug}/git-credentials` - A [git-credentials](https://git-scm.com/docs/git-credential-store#_storage_format) file for git over https, specific to a pipeline\n\nThese files are encrypted using [Amazon's KMS Service](https://aws.amazon.com/kms/). See the [Security](#security) section for more details.\n\nHere's an example that shows how to generate a private SSH key, and upload it with KMS encryption to an S3 bucket:\n\n```bash\n# generate a deploy key for your project\nssh-keygen -t rsa -b 4096 -f id_rsa_buildkite\npbcopy < id_rsa_buildkite.pub # paste this into your github deploy key\n\naws s3 cp --acl private --sse aws:kms id_rsa_buildkite \"s3://${SecretsBucket}/private_ssh_key\"\n```\n\nIf you want to set secrets that your build can access, create a file that sets environment variables and upload it:\n\n```bash\necho \"export MY_ENV_VAR=something secret\" > myenv\naws s3 cp --acl private --sse aws:kms myenv \"s3://${SecretsBucket}/env\"\nrm myenv\n```\n\n**Note: Currently only using the default KMS key for s3 can be used, follow [#235](https://github.com/buildkite/elastic-ci-stack-for-aws/issues/235) for progress on using specific KMS keys**\n\nIf you really want to store your secrets unencrypted, you can disable it entirely with `BUILDKITE_USE_KMS=false`.\n\n## What\u2019s On Each Machine?\n\n* [Amazon Linux 2017.09.1](https://aws.amazon.com/amazon-linux-ami/)\n* [Buildkite Agent](https://buildkite.com/docs/agent)\n* [Docker 17.12.0-ce](https://www.docker.com)\n* [Docker Compose 1.18.0](https://docs.docker.com/compose/)\n* [aws-cli](https://aws.amazon.com/cli/) - useful for performing any ops-related tasks\n* [jq](https://stedolan.github.io/jq/) - useful for manipulating JSON responses from cli tools such as aws-cli or the Buildkite API\n\n## What Type of Builds Does This Support?\n\nThis stack is designed to run your builds in a share-nothing pattern similar to the [12 factor application principals](http://12factor.net):\n\n* Each project should encapsulate it's dependencies via Docker and Docker Compose\n* Build pipeline steps should assume no state on the machine (and instead rely on [build meta-data](https://buildkite.com/docs/guides/build-meta-data), [build artifacts](https://buildkite.com/docs/guides/artifacts) or S3)\n* Secrets are configured via environment variables exposed using the S3 secrets bucket\n\nBy following these simple conventions you get a scaleable, repeatable and source-controlled CI environment that any team within your organization can use.\n\n## Multiple Instances of the Stack\n\nIf you need to different instances sizes and scaling characteristics between pipelines, you can create multiple stack. Each can run on a different [Agent Queue](https://buildkite.com/docs/agent/queues), with it's own configuration, or even in a different AWS account.\n\nExamples:\n\n* A `docker-builders` stack that provides always-on workers with hot docker caches (see [Optimizing for Slow Docker Builds](#optimizing-for-slow-docker-builds))\n* A `pipeline-uploaders` stack with tiny, always-on instances for lightning fast `buildkite-agent pipeline upload` jobs.\n* A `deploy` stack with added credentials and permissions specifically for deployment.\n\n## Autoscaling\n\nIf you have configured `MinSize` < `MaxSize`, the stack will automatically scale up and down based on the number of scheduled jobs.\n\nThis means you can scale down to zero when idle, which means you can use larger instances for the same cost.\n\nMetrics are collected with a Lambda function, polling every minute.\n\n## Docker Registry Support\n\nIf you want to push or pull from registries such as [Docker Hub](https://hub.docker.com/) or [Quay](https://quay.io/) you can use the `environment` hook in your secrets bucket to export the following environment variables:\n\n* `DOCKER_LOGIN_USER=\"the-user-name\"`\n* `DOCKER_LOGIN_PASSWORD=\"the-password\"`\n* `DOCKER_LOGIN_SERVER=\"\"` - optional. By default it will log into Docker Hub\n\nSetting these will perform a `docker login` before each pipeline step is run, allowing you to `docker push` to them from within your build scripts.\n\nIf you are using [Amazon ECR](https://aws.amazon.com/ecr/) you can set the `ECRAccessPolicy` parameter to the stack to either `readonly`, `poweruser`, or `full` depending on [the access level you want](http://docs.aws.amazon.com/AmazonECR/latest/userguide/ecr_managed_policies.html) your builds to have\n\nYou can disable this in individual pipelines by setting `AWS_ECR_LOGIN=false`.\n\nIf you want to login to an ECR server on another AWS account, you can set `AWS_ECR_LOGIN_REGISTRY_IDS=\"id1,id2,id3\"`.\n\nThe AWS ECR options are powered by an embedded version of the [ECR plugin](https://github.com/buildkite-plugins/ecr-buildkite-plugin), so if you require options that aren't listed here, you can disable the embedded version as above and call the plugin directly. See [it's README](https://github.com/buildkite-plugins/ecr-buildkite-plugin) for more examples (requires Agent v3.x).\n\n## Versions\n\nWe recommend running the latest release, which is available at `https://s3.amazonaws.com/buildkite-aws-stack/aws-stack.json`, or on the [releases page](https://github.com/buildkite/elastic-ci-stack-for-aws/releases).\n\nThe latest build of the stack is published to `https://s3.amazonaws.com/buildkite-aws-stack/master/aws-stack.json`, along with a version for each commit in the form of `https://s3.amazonaws.com/buildkite-aws-stack/master/${COMMIT}.aws-stack.json`.\n\nBranches are published in the form of `https://s3.amazonaws.com/buildkite-aws-stack/${BRANCH}/aws-stack.json`.\n\n## Updating Your Stack\n\nTo update your stack to the latest version use CloudFormation\u2019s stack update tools with one of the urls in the [Versions](#versions) section.\n\nPrior to updating, it's a good idea to set the desired instance size on the AutoscalingGroup to 0 manually.\n\n## CloudWatch Metrics\n\nMetrics are calculated every minute from the Buildkite API using a lambda function.\n\n<img width=\"544\" alt=\"cloudwatch\" src=\"https://cloud.githubusercontent.com/assets/153/16836158/85abdbc6-49ff-11e6-814c-eaf2400e8333.png\">\n\nYou\u2019ll find the stack\u2019s metrics under \"Custom Metrics > Buildkite\" within CloudWatch.\n\n## Reading Instance and Agent Logs\n\nEach instance streams both system messages and Buildkite Agent logs to CloudWatch Logs under two log groups:\n\n* `/var/log/messages` - System logs\n* `/var/log/buildkite-agent.log` - Buildkite Agent logs\n* `/var/log/docker` - Docker daemon logs\n* `/var/log/elastic-stack.log` - Boot process logs\n\nWithin each stream the logs are grouped by instance id.\n\nTo debug an agent first find the instance id from the agent in Buildkite, head to your [CloudWatch Logs Dashboard](https://console.aws.amazon.com/cloudwatch/home?#logs:), choose either the system or Buildkite Agent log group, and then search for the instance id in the list of log streams.\n\n## Optimizing for Slow Docker Builds\n\nFor large legacy applications the Docker build process might take a long time on new instances. For these cases it\u2019s recommended to create an optimized \"builder\" stack which doesn't scale down, keeps a warm docker cache and is responsible for building and pushing the application to Docker Hub before running the parallel build jobs across your normal CI stack.\n\nAn example of how to set this up:\n\n1. Create a Docker Hub repository for pushing images to\n1. Update the pipeline\u2019s `env` hook in your secrets bucket to perform a `docker login`\n1. Create a builder stack with its own queue (i.e. `elastic-builders`), making sure to use `beta` agents so you can use the [Docker Compose Buildkite Plugin](https://github.com/buildkite-plugins/docker-compose-buildkite-plugin) and [pre-building](https://github.com/buildkite-plugins/docker-compose-buildkite-plugin#pre-building-the-image)\n\nHere is an example build pipeline based on a production Rails application:\n\n```yaml\nsteps:\n  - name: \":docker: :package:\"\n    plugins:\n      docker-compose:\n        build: app\n        image-repository: my-docker-org/my-repo\n    agents:\n      queue: elastic-builders\n  - wait\n  - name: \":hammer:\"\n    command: \".buildkite/steps/tests\"\n    plugins:\n      docker-compose:\n        run: app\n    agents:\n      queue: elastic\n    parallelism: 75\n```\n\nSee [Issue 81](https://github.com/buildkite/elastic-ci-stack-for-aws/issues/81) for ideas on other solutions (contributions welcome!).\n\n## Security\n\nThis repository hasn't been reviewed by security researchers so exercise caution and careful thought with what credentials you make available to your builds.\n\nAnyone with commit access to your codebase (including third-party pull-requests if you've enabled them in Buildkite) will have access to your secrets bucket files.\n\nAlso keep in mind the EC2 HTTP metadata server is available from within builds, which means builds act with the same IAM permissions as the instance.\n\n## Development\n\nTo get started with customizing your own stack, or contributing fixes and features:\n\n```bash\n# Build an AMI\nmake build\n\n# Or, to set things up locally and create the stack on AWS\nmake create-stack\n\n# You can use any of the AWS* environment variables that the aws-cli supports\nAWS_PROFILE=\"some-profile\" make create-stack\n\n# You can also use aws-vault or similar\naws-vault exec some-profile -- make create-stack\n```\n\nIf you need to build your own AMI (because you've changed something in the `packer` directory), run:\n\n```bash\nmake clean build-ami\n```\n\n## Questions and Support\n\nFeel free to drop an email to support@buildkite.com with questions. It helps us if you can provide the following details:\n\n```\n# List your stack parameters\naws cloudformation describe-stacks --stack-name MY_STACK_NAME \\\n  --query 'Stacks[].Parameters[].[ParameterKey,ParameterValue]' --output table\n```\n\nProvide us with logs from Cloudwatch Logs:\n\n```\n/buildkite/elastic-stack-init/{instance-id}\n/buildkite/docker-daemon/{instance-id}\n```\n\nAlternately, drop by `#aws-stack` and `#aws` channels in [Buildkite Community Slack](https://chat.buildkite.com/) and ask your question!\n\n## Licence\n\nSee [Licence.md](Licence.md) (MIT)\n", "release_dates": []}, {"name": "eslint-config-solana", "description": "ESLint rules to be shared across all Solana Labs projects", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Solana ESLint config\n\nLet's share this ESLint config across all of our projects, to keep things consistent.\n\n## Installation\n\n1. Install this package in the target project, along with the required peer dependencies\n   ```bash\n   pnpx install-peerdeps@2 --pnpm --dev @solana/eslint-config-solana\n   ```\n2. Create an `.eslint.json` file in your target project that extends this module\n   ```json\n   {\n     \"extends\": [\"@solana/eslint-config-solana\"]\n   }\n   ```\n", "release_dates": []}, {"name": "eslint-plugin-require-extensions", "description": null, "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# eslint-plugin-require-extensions\n\nTypeScript [doesn't transform extensions](https://github.com/microsoft/TypeScript/issues/16577) and [doesn't enforce file extensions](https://github.com/microsoft/TypeScript/issues/42813).\n\nThis is a simple eslint plugin that ensures that relative imports _and_ exports have `.js` extensions.\n\nCredit for [the original implementation](https://github.com/solana-labs/wallet-adapter/pull/547) goes to [johnrees](https://github.com/johnrees). \u2764\ufe0f\n\n1. Install\n```shell\nnpm install --save-dev eslint-plugin-require-extensions\n```\n\n2. Edit `.eslintrc`\n```json\n{\n    \"extends\": [\n        \"plugin:require-extensions/recommended\"\n    ],\n    \"plugins\": [\n        \"require-extensions\"\n    ]\n}\n```\n\n3. Code\n```js\n// source.js\n\nimport Target from './target';\n```\n\n4. Lint\n\n```shell\neslint .\n```\n```\nsource.js\n  1:1  error  Relative imports and exports must end with .js  require-extensions/require-extensions\n```\n\n5. Fix\n\n```shell\neslint --fix .\n```\n```js\n// source.js\n\nimport Target from './target.js';\n```\n", "release_dates": []}, {"name": "example-helloworld", "description": "Hello world on Solana", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<p align=\"center\">\n  <a href=\"https://solana.com\">\n    <img alt=\"Solana\" src=\"https://i.imgur.com/uBVzyX3.png\" width=\"250\" />\n  </a>\n</p>\n\n# Hello world on Solana\n\nThis hello world guide has moved to the [main Solana documentation](https://docs.solana.com/getstarted/rust).\n", "release_dates": []}, {"name": "example-messagefeed", "description": "Simple message feed built on Solana", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "[![Build status][travis-image]][travis-url]\n\n[travis-image]: https://travis-ci.org/solana-labs/example-messagefeed.svg?branch=v1.1\n[travis-url]: https://travis-ci.org/solana-labs/example-messagefeed\n\n# Solana Feed\n\nThis project demonstrates how to use the [Solana Javascript API](https://github.com/solana-labs/solana-web3.js)\nto build, deploy, and interact with programs on the Solana blockchain,\nimplementing a simple feed of messages and prediction polls.\nTo see it running go to https://solana-example-messagefeed.herokuapp.com/\n\n## Table of Contents\n- [Solana Feed](#solana-feed)\n  - [Table of Contents](#table-of-contents)\n  - [Overview](#overview)\n  - [Message Feed](#message-feed)\n    - [User Login](#user-login)\n    - [Posting a message](#posting-a-message)\n    - [Banning a user](#banning-a-user)\n  - [Learn about Solana](#learn-about-solana)\n  - [Prediction Polls](#prediction-polls)\n    - [Creating a poll](#creating-a-poll)\n    - [Voting](#voting)\n    - [Claim winnings](#claim-winnings)\n    - [Limitations](#limitations)\n  - [Getting Started](#getting-started)\n    - [Select a Network](#select-a-network)\n    - [Build the BPF program](#build-the-bpf-program)\n    - [Start the web server](#start-the-web-server)\n    - [Run the Command-Line Front End](#run-the-command-line-front-end)\n    - [Run the WebApp Front End](#run-the-webapp-front-end)\n\n\n## Overview\n\nThis project uses two Solana programs and a Node server to power a single webapp.\nThe [Message Feed](#message-feed) program allows users to post messages and ban\neach other for bad behavior. The [Prediction Poll](#prediction-polls) program\nallows users to create wager-able polls that reward the winning side.\n\n## Message Feed\n\nMessages are represented as a singly-linked list of Solana accounts.\n\nEach Message account contains the message text, public key of the next message,\nand the public key of the User Account who posted it.\n\nTo post a new message, a User Account is required.  The only way to obtain a\nUser Account is to present credentials to the Https Server that created the\nfirst message in the chain.\n\nA User Account contains a bit which indicates if they have been banned by another user.\n\n### User Login\nOnly the mechanism to obtain User Accounts is centralized.  This will ensure\neach User Account is associated with a real person using whatever user\nauthentication system (such as Google) is preferred.  The only requirement on\nthe authentication system is that that each authenticated user have a unique\nuser id.\n\n1. Https Server loads the Message Feed program on Solana and posts the first message\n1. New User authenticates against Google and receives a JWT\n1. New User sends JWT to Https Server\n1. Https Server verifies the JWT contents and extracts their unique user id\n1. Https Server creates a User Account on behalf of New User if not already created\n1. Https Server returns the private key for the User Account to the New User, and the public key of the first message\n\nNote: presently the JWT workflow is not fully implemented.  No technical reason, just work that hasn't been done yet :)\n\n### Posting a message\n1. With the public key of the first message and a User Account, the user uses\n   the RPC APIs of a Solana fullnode to fetch the latest message in the chain.\n1. The user constructs a new Transaction with the user message, the public key\n   of their User Account and the public key of the latest message.  The\n   Transaction is signed with their User Account private key, then submitted to\n   the Solana cluster.\n1. The Message Feed program processes the Transaction on-chain, confirms the user is not\n   banned and links the new message to the chain.\n\n### Banning a user\nAny user can construct a Transaction that bans any other user.  All messages\nposted by a user contains the public key of their User Account, so it's easy to\nidentify the origin of each post.\n\n1. The ban Transaction includes the public key of the User Account to ban, the\n   public key of the banning user's User Account, and a message to include with\n   the ban.  The ban Transaction is signed with the banning user's User Account\n   private key, then submitted to the Solana cluster.\n1. The Message Feed program processes the Transaction on chain, confirms the banning user\n   is not also banned, and then sets the banned bit on the target user.\n\n## Learn about Solana\n\nMore information about how Solana works is available in the [Book](https://docs.solana.com/book/)\n\n## Prediction Polls\n\nPolls propose a question and 2 option to choose from. They allow users to wager\ntokens on which answer will be the most popular. The winning side gets to split\nup the losers' wagers!\n\nPolls are stored in a single Collection account on Solana. The Collection account\ncontains a list of public keys for the Poll accounts.\n\nIn addition to the display text, each poll also has an expiration block height\nand 2 tally keys for tracking wagers.\n\nTally Accounts record wagers for a particular poll option. When the poll\nexpires, they are used to distribute winnings\n\n### Creating a poll\nTo create a new poll, a User Account is required. Similar to posting messages,\nthe user account is retrieved from the server.\n\n1. The user signs in and fetches the prediction poll program id and the current\ncollection key.\n1. The user inputs the poll header and options as well as a block timeout which\nwill be added to the current block height to compute the poll expiration.\n1. A Transaction is constructed with instructions for creating the poll account\nand 2 tally accounts and an instruction for initializing the poll with the text\nand timeout.\n1. Solana then creates the accounts and the prediction poll program processes\nthe poll initialization instruction to set the poll account data.\n\n### Voting\nVoting on a poll involves a token wager which will be transferred to the poll\naccount and recorded in the poll account data.\n\n1. A user selects a poll option and chooses an appropriate token wager\n1. A Transaction is constructed with instructions to create a one-off account\nwith a balance equal to the token wager and submit a vote.\n1. The prediction poll program then drains the one-off account balance and\nrecords the wager in the poll account and the selected option tally account.\n\n### Claim winnings\nOnce the poll expires, anyone can trigger the distribution of the winnings.\n\n1. Transaction is created which references all of the winning wager keys in a\nclaim instruction.\n1. The prediction poll program verifies that the poll has expired and then\ndrains the poll account balance and proportionally distributes the tokens to the\nwinners according to their wagers.\n\n### Limitations\n- The number of polls in a collection is limited to the size of the Collection\naccount data\n- The number of participants in a tally are limited by the size of the Tally\naccount data as well as the maximum size of a transaction. Serialized\ntransactions must fit inside the MTU size of 1280 bytes.\n\n## Getting Started\n\nThe following dependencies are required to build and run this example, \ndepending on your OS they may already be installed:\n\n```sh\n$ npm --version\n$ docker -v\n$ wget --version\n$ rustc --version\n```\n\nNext fetch the npm dependencies, including `@solana/web3.js`, by running:\n```sh\n$ npm install\n```\n\n### Select a Network\nThe example connects to a local Solana cluster by default.\n\nTo enable on-chain program logs, set the `RUST_LOG` environment variable:\n```sh\n$ export RUST_LOG=solana_runtime::system_instruction_processor=trace,solana_runtime::message_processor=info,solana_bpf_loader=debug,solana_rbpf=debug\n```\n\nTo start a local Solana cluster run:\n```sh\n$ npm run localnet:update\n$ npm run localnet:up\n```\n\nSolana cluster logs are available with:\n```sh\n$ npm run localnet:logs\n```\n\nTo stop the local solana cluster run:\n```sh\n$ npm run localnet:down\n```\n\nFor more details on working with a local cluster, see the [full instructions](https://github.com/solana-labs/solana-web3.js#local-network).\n\n### Build the BPF program\nThe prediction poll program is only written in Rust. The build command will\nproduce a BPF ELF shared object called `dist/programs/prediction_poll.so`.\n\n```sh\n$ npm run build:bpf-rust\n```\nor\n```sh\n$ npm run build:bpf-c\n```\n\n### Start the web server\nThe message feed and prediction poll programs are deployed by the web server at `src/server/index.js`,\nso start it first:\n```sh\n$ npm run dev-server\n```\n\n### Run the Command-Line Front End\nAfter building the program and starting the web server, you can view the current\nmessage feed by running\n\n```sh\n$ npm run message-cli\n```\n\nand post a new message with:\n```sh\n$ npm run message-cli -- \"This is a message\"\n```\n\nand can create a test poll by running:\n```sh\n$ npm run poll-cli\n```\n\n### Run the WebApp Front End\nAfter building the program and starting the web server, start the webapp\nlocally by running:\n```sh\n$ npm run dev\n```\nthen go to http://localhost:8080/ in your browser.\n", "release_dates": []}, {"name": "example-move", "description": "Solana example which runs a Libra Move program", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "[![Build status][travis-image]][travis-url]\n\n[travis-image]: https://api.travis-ci.org/solana-labs/example-move.svg?branch=master\n[travis-url]: https://travis-ci.org/solana-labs/example-move\n\n# Move on Solana\n\n* **Note: Move on Solana is under construction and therefore this example project is not currently functioning.  Please use it as a learning tool or a reference until construction is complete**\n\nThis project demonstrates how to use the [Solana Javascript API](https://github.com/solana-labs/solana-web3.js)\nto build, deploy, and interact with Libra Move programs on the Solana blockchain.\n\nThere is a wealth of information about Libra and the Move language on the [Libra developers page](https://developers.libra.org/docs/welcome-to-libra)\n\n## What's here\n\nThe project comprises of:\n\n* A `LibraPay` library to interact with the on-chain Move loader and virtual machine to create Genesis accounts, and mint and pay Libra coins: [`./src/program`](https://github.com/solana-labs/example-move/tree/master/src/program)\n* Move programs used to mint and pay Libra coins: [`./programs`](https://github.com/solana-labs/example-move/tree/master/programs)\n* Command-line front-end that demonstrates how to use the `LibraPay` library: [`src/cli/`](https://github.com/solana-labs/example-move/tree/master/src/cli)\n\n## Getting started\n\nFirst fetch the npm dependencies, including `@solana/web3.js`, by running:\n\n```sh\n$ npm install\n```\n\n### Select a Network\n\nThe example connects to a local Solana cluster by default.\n\nTo enable on-chain Move loader/VM logs, set the `RUST_LOG` environment variable:\n```sh\n$ export RUST_LOG=solana_runtime::system_instruction_processor=trace,solana_runtime::message_processor=info,solana_bpf_loader=debug,solana_rbpf=debug,solana_move_loader_program=debug\n```\n\nTo start a local Solana cluster run:\n```sh\n$ npm run localnet:update\n$ npm run localnet:up\n```\n\nSolana cluster logs are available with:\n```sh\n$ npm run localnet:logs\n```\n\nFor more details on working with a local cluster, see the [full instructions](https://github.com/solana-labs/solana-web3.js#local-network).\n\nAlternatively to connect to the public testnet, `export LIVE=1` in your\nenvironment.  By default `LIVE=1` will connect to the\nbeta testnet.  To use the edge testnet instead, define `export CHANNEL=edge' in\nyour environment (see [url.js](https://github.com/solana-labs/solana/tree/master/urj.js) for more)\n\n### Run the Command-Line Front End\n\n```sh\n$ npm run start\n```\n\n## Customizing the Program\nTo customize, make changes to the files under [`/src`](https://github.com/solana-labs/example-move/tree/master/src)\n\nNow when you run `npm run start` again you should see the results of your changes.\n", "release_dates": []}, {"name": "example-tictactoe", "description": "Tic-Tac-Toe built on Solana", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "[![Build status][travis-image]][travis-url]\n\n[travis-image]: https://travis-ci.org/solana-labs/example-tictactoe.svg?branch=v1.1\n[travis-url]: https://travis-ci.org/solana-labs/example-tictactoe\n\n# Tic-Tac-Toe on Solana\n\nThis project demonstrates how to use the [Solana Javascript API](https://github.com/solana-labs/solana-web3.js)\nto build, deploy, and interact with programs on the Solana blockchain, implementing an interactive tic-tac-toe game between two users.\nTo see the final product, go to https://solana-example-tictactoe.herokuapp.com/ and wait for another player to join.\n(Direct a second browser window to the web app to play against yourself.)\n\nThe project comprises:\n\n* The on-chain Tic-Tac-Toe program, a BPF program written in Rust `program-bpf-rust` and C `program-bpf-c`\n* Easy program build and deployment using the `@solana/web3.js` library\n* Command-line and web front-end: `src/`\n\n## Learn about Solana\n\nMore information about how Solana works is available in the [Book](https://docs.solana.com/book/)\n\n## Getting Started\n\nThe following dependencies are required to build and run this example,\ndepending on your OS they may already be installed:\n\n```sh\n$ npm --version\n$ docker -v\n$ wget --version\n$ rustc --version\n```\n\nNext fetch the npm dependencies, including `@solana/web3.js`, by running:\n```sh\n$ npm install\n```\n\n### Select a Network\nThe example connects to a local Solana cluster by default.\n\nTo enable on-chain program logs, set the `RUST_LOG` environment variable:\n```sh\n$ export RUST_LOG=solana_runtime::native_loader=trace,solana_runtime::system_instruction_processor=trace,solana_runtime::bank=debug,solana_bpf_loader=debug,solana_rbpf=debug\n```\n\nTo start a local Solana cluster run:\n```sh\n$ npm run localnet:update\n$ npm run localnet:up\n```\n\nSolana cluster logs are available with:\n```sh\n$ npm run localnet:logs\n```\n\nTo stop the local solana cluster run:\n```sh\n$ npm run localnet:down\n```\n\nFor more details on working with a local cluster, see the [full instructions](https://github.com/solana-labs/solana-web3.js#local-network).\n\n### Build the BPF program\n```sh\n$ npm run build:bpf-rust\n```\nor\n```\n$ npm run build:bpf-c\n```\n\nThe compiler places output files in `dist/program`. Program build scripts contain the compiler settings and can be found in the [Solana SDK](https://github.com/solana-labs/solana/tree/master/sdk/bpf/rust)\n\n### Run the Command-Line Front End\nAfter building the program,\n\n```sh\n$ npm run start\n```\n\nThis script uses the Solana Javascript API `BpfLoader` to deploy the Tic-Tac-Toe program to the blockchain.\nOnce the deploy transaction is confirmed on the chain, the script calls the program to instantiate a new dashboard\nto track the open and completed games (`findDashboard`), and starts a new game (`dashboard.startGame`), waiting for an opponent.\n\nTo play the game, open a second terminal and again run the `npm run start` script.\n\nTo see the program or game state on the blockchain, send a `getAccountInfo` [JSON-RPC request](https://solana-labs.github.io/solana/jsonrpc-api.html#getaccountinfo) to the cluster, using the id printed by the script, eg.:\n* `Dashboard programId: HFA4x4oZKWeGcRVbUYaCHM59i5AFfP3nCfc4NkrBvVtP`\n* `Dashboard: HmAEDrGpsRK2PkR51E9mQrKQG7Qa3iyv4SvZND9uEkdR`\n* `Advertising our game (Gx1kjBieYgaPgDhaovzvvZapUTg5Mz6nhXTLWSQJpNMv)`\n\n### Run the WebApp Front End\nAfter building the program,\n\n```sh\n$ npm run dev\n```\n\nThis script deploys the program to the blockchain and also boots up a local webserver\nfor gameplay.\n\nTo instantiate a dashboard and game, open your browser to [http://localhost:8080/](http://localhost:8080/).\n\n## Customizing the Program\nTo customize Tic-Tac-Toe, make changes to the program in `program-bpf-rust/src`, rebuild it, and restart the network.\nNow when you run `npm run start`, you should see your changes.\n\nTo deploy a program with a different name, edit `src/server/config.js`.\n\n## Pointing to a public Solana cluster\n\nSolana maintains three public clusters:\n- `devnet` - Development cluster with airdrops enabled\n- `testnet` - Tour De Sol test cluster without airdrops enabled\n- `mainnet-beta` -  Main cluster\n  \nUse npm scripts to configure which cluster.\n\nTo point to `devnet`:\n```bash\n$ npm run cluster:devnet\n```\n\nTo point back to the local cluster:\n```bash\n$ npm run cluster:localnet\n```", "release_dates": ["2019-06-26T20:22:57Z", "2019-05-29T05:14:18Z", "2019-05-02T23:35:58Z"]}, {"name": "example-token", "description": "Obsoleted by https://spl.solana.com/token (Token Example)", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "[![Build status][travis-image]][travis-url]\n\n[travis-image]: https://travis-ci.org/solana-labs/example-token.svg?branch=v1.1\n[travis-url]: https://travis-ci.org/solana-labs/example-token\n\n# Token Example on Solana\n\nThis project demonstrates how to use the [Solana Javascript API](https://github.com/solana-labs/solana-web3.js)\nto build, deploy, and interact with an ERC20-like Token example program on the Solana blockchain.\n\nThe project comprises of:\n\n* A library to interact with the on-chain program\n* Test client that exercises the program\n\n## Getting Started\n\nFirst fetch the npm dependencies, including `@solana/web3.js`, by running:\n```sh\n$ npm install\n```\n\n### Select a Network\n\nThis example connects to a local Solana cluster by default.\n\nTo enable on-chain program logs, set the `RUST_LOG` environment variable:\n\n```bash\n$ export RUST_LOG=solana_runtime::system_instruction_processor=trace,solana_runtime::message_processor=info,solana_bpf_loader=debug,solana_rbpf=debug\n```\n\nTo start a local Solana cluster run:\n```bash\n$ npm run localnet:update\n$ npm run localnet:up\n```\n\nSolana cluster logs are available with:\n```bash\n$ npm run localnet:logs\n```\n\nFor more details on working with a local cluster, see the [full instructions](https://github.com/solana-labs/solana-web3.js#local-network).\n\nBy default the program will connect to the\nbeta testnet.  To use the edge testnet instead, define `export CHANNEL=edge' in\nyour environment (see [url.js](https://github.com/solana-labs/solana/tree/master/urj.js) for more)\n\n### Run the test client\n\n```sh\n$ npm run start\n```\n\n## Customizing the Program\n\nTo customize the example, make changes to the files under `/src`\n\nNow when you run `npm run start`, you should see the results of your changes.\n\n## Pointing to a public Solana cluster\n\nSolana maintains three public clusters:\n- `devnet` - Development cluster with airdrops enabled\n- `testnet` - Tour De Sol test cluster without airdrops enabled\n- `mainnet-beta` -  Main cluster\n  \nUse npm scripts to configure which cluster.\n\nTo point to `devnet`:\n```bash\n$ npm run cluster:devnet\n```\n\nTo point back to the local cluster:\n```bash\n$ npm run cluster:localnet\n```\n", "release_dates": []}, {"name": "explorer", "description": "Explorer for Solana clusters", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<p align=\"center\">\n    <img alt=\"Solana\" src=\"https://i.imgur.com/IKyzQ6T.png\" width=\"250\" />\n</p>\n\n# Solana Explorer\n\n## Development\n\n-   `pnpm dev` \\\n    Runs the app in the development mode. \\\n    Open [http://localhost:3000](http://localhost:3000) to view it in the browser. \\\n    \\\n    The page will reload if you make edits. \\\n    You will also see any lint errors in the console.\n\n-   `pnpm test` \\\n    Launches the test runner in the interactive watch mode.<br />\n\n# Disclaimer\n\nAll claims, content, designs, algorithms, estimates, roadmaps,\nspecifications, and performance measurements described in this project\nare done with the Solana Foundation's (\"SF\") best efforts. It is up to\nthe reader to check and validate their accuracy and truthfulness.\nFurthermore nothing in this project constitutes a solicitation for\ninvestment.\n\nAny content produced by SF or developer resources that SF provides, are\nfor educational and inspiration purposes only. SF does not encourage,\ninduce or sanction the deployment, integration or use of any such\napplications (including the code comprising the Solana blockchain\nprotocol) in violation of applicable laws or regulations and hereby\nprohibits any such deployment, integration or use. This includes use of\nany such applications by the reader (a) in violation of export control\nor sanctions laws of the United States or any other applicable\njurisdiction, (b) if the reader is located in or ordinarily resident in\na country or territory subject to comprehensive sanctions administered\nby the U.S. Office of Foreign Assets Control (OFAC), or (c) if the\nreader is or is working on behalf of a Specially Designated National\n(SDN) or a person subject to similar blocking or denied party\nprohibitions.\n\nThe reader should be aware that U.S. export control and sanctions laws\nprohibit U.S. persons (and other persons that are subject to such laws)\nfrom transacting with persons in certain countries and territories or\nthat are on the SDN list. As a project based primarily on open-source\nsoftware, it is possible that such sanctioned persons may nevertheless\nbypass prohibitions, obtain the code comprising the Solana blockchain\nprotocol (or other project code or applications) and deploy, integrate,\nor otherwise use it. Accordingly, there is a risk to individuals that\nother persons using the Solana blockchain protocol may be sanctioned\npersons and that transactions with such persons would be a violation of\nU.S. export controls and sanctions law. This risk applies to\nindividuals, organizations, and other ecosystem participants that\ndeploy, integrate, or use the Solana blockchain protocol code directly\n(e.g., as a node operator), and individuals that transact on the Solana\nblockchain through light clients, third party interfaces, and/or wallet\nsoftware.\n", "release_dates": []}, {"name": "farms", "description": "Solana Farms", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Solana Farms\n\n**_This repository is EOL and no longer maintained._**\n\n## Introduction\n\nSolana Farms is a collection of easy-to-use tools and blockchain contracts for yield optimization strategies.\n\nIt is powered by the Solana blockchain to allow for frequent automatic compounding, staking, and rebalancing.\n\nOne of the distinct features of this platform is the on-chain Reference Database. Metadata for all objects: Tokens, Pools, Farms, Vaults, Funds, etc., is stored in the blockchain, so clients don't need any state or hard-coded data.\n\nSolana Farms provides a unified interface to Funds, Vaults, regular AMM Pools, Farms, and basic operations on tokens and accounts. Raydium, Saber, and Orca protocols are currently supported.\n\nThis source code is an example that third parties can utilize to create and use their own version of a yield farming or aggregation service.\n\n## Quick start\n\nTo quickly build, test and deploy Solana Farms and try it out in action, please follow the [Quick Start](https://github.com/solana-labs/farms/blob/master/docs/quick_start.md) guide.\nFor devnet use [Quick Start Devnet](https://github.com/solana-labs/farms/blob/master/docs/quick_start_devnet.md)\n\n## Dive in\n\nIf you want to learn more about the tools and building blocks of the Solana Farms suite, follow the links below:\n\n[Rust Client](https://github.com/solana-labs/farms/blob/master/docs/rust_client.md)\n\n[Http Client](https://github.com/solana-labs/farms/blob/master/docs/http_client.md)\n\n[Farm Client CLI](https://github.com/solana-labs/farms/blob/master/docs/farm_client_cli.md)\n\n[Farm Control CLI](https://github.com/solana-labs/farms/blob/master/docs/farm_ctrl_cli.md)\n\n[Farm SDK](https://github.com/solana-labs/farms/blob/master/docs/sdk.md)\n\n[Routers](https://github.com/solana-labs/farms/blob/master/docs/routers.md)\n\n[Vaults](https://github.com/solana-labs/farms/blob/master/docs/vaults.md)\n\n[Fund](https://github.com/solana-labs/farms/blob/master/docs/fund.md)\n\n[Multisig](https://github.com/solana-labs/farms/blob/master/docs/multisig.md)\n\n[Governance](https://github.com/solana-labs/farms/blob/master/docs/governance.md)\n\n## Support\n\nFor details on how to get help or report a problem, see the [Support](https://github.com/solana-labs/farms/blob/master/docs/support.md) page.\n\n## Contributing\n\nContributions are very welcome. Please refer to the [Contributing](https://github.com/solana-labs/solana/blob/master/CONTRIBUTING.md) guidelines for more information.\n\n## License\n\nSolana Farms is released under [Apache License 2.0](https://github.com/solana-labs/farms/blob/master/LICENSE).\n\n## Disclaimer\n\nBy accessing or using Solana Farms or any of its components, you accept and agree with the [Disclaimer](https://github.com/solana-labs/farms/blob/master/docs/disclaimer.md).\n", "release_dates": []}, {"name": "gatsby-plugin-intl", "description": "Gatsby plugin that turns your website into an internationalization-framework out of the box.", "language": "JavaScript", "license": null, "readme": "# gatsby-plugin-intl\n\nInternationalize your Gatsby site.\n\n## Features\n\n- Turn your gatsby site into an internationalization-framework out of the box powered by [react-intl](https://github.com/yahoo/react-intl).\n\n- Support automatic redirection based on the user's preferred language in browser provided by [browser-lang](https://github.com/wiziple/browser-lang).\n\n- Support multi-language url routes in a single page component. This means you don't have to create separate pages such as `pages/en/index.js` or `pages/ko/index.js`.\n\n## Why?\n\nWhen you build multilingual sites, Google recommends using different URLs for each language version of a page rather than using cookies or browser settings to adjust the content language on the page. [(read more)](https://support.google.com/webmasters/answer/182192?hl=en&ref_topic=2370587)\n\n## Starters\n\nDemo: [http://gatsby-starter-default-intl.netlify.com](http://gatsby-starter-default-intl.netlify.com)\n\nSource: [https://github.com/wiziple/gatsby-plugin-intl/tree/master/examples/gatsby-starter-default-intl](https://github.com/wiziple/gatsby-plugin-intl/tree/master/examples/gatsby-starter-default-intl)\n\n\n## Showcase\n\n- [https://picpick.app](https://picpick.app)\n- [https://www.krashna.nl](https://www.krashna.nl) [(Source)](https://github.com/krashnamusika/krashna-site)\n- [https://vaktija.eu](https://vaktija.eu)\n- [https://anhek.dev](https://anhek.dev) [(Source)](https://github.com/anhek/anhek-portfolio)\n- [https://pkhctech.ineo.vn](https://pkhctech.ineo.vn) [(Source)](https://github.com/hoangbaovu/gatsby-pkhctech)\n\n*Feel free to send us PR to add your project.*\n\n## How to use\n\n### Install package\n\n`npm install --save gatsby-plugin-intl`\n\n### Add a plugin to your gatsby-config.js\n\n```javascript\n// In your gatsby-config.js\nplugins: [\n  {\n    resolve: `gatsby-plugin-intl`,\n    options: {\n      // language JSON resource path\n      path: `${__dirname}/src/intl`,\n      // supported language\n      languages: [`en`, `ko`, `de`],\n      // language file path\n      defaultLanguage: `ko`,\n      // option to redirect to `/ko` when connecting `/`\n      redirect: true,\n    },\n  },\n]\n```\n\n### You'll also need to add language JSON resources to the project.\n\nFor example,\n\n| language resource file | language |\n| --- | --- |\n| [src/intl/en.json](https://github.com/wiziple/gatsby-plugin-intl/blob/master/examples/gatsby-starter-default-intl/src/intl/en.json) | English |\n| [src/intl/ko.json](https://github.com/wiziple/gatsby-plugin-intl/blob/master/examples/gatsby-starter-default-intl/src/intl/ko.json) | Korean |\n| [src/intl/de.json](https://github.com/wiziple/gatsby-plugin-intl/blob/master/examples/gatsby-starter-default-intl/src/intl/de.json) | German |\n\n\n### Change your components\n\nYou can use `injectIntl` HOC on any react components including page components.\n\n```jsx\nimport React from \"react\"\nimport { injectIntl, Link, FormattedMessage } from \"gatsby-plugin-intl\"\n\nconst IndexPage = ({ intl }) => {\n  return (\n    <Layout>\n      <SEO\n        title={intl.formatMessage({ id: \"title\" })}\n      />\n      <Link to=\"/page-2/\">\n        {intl.formatMessage({ id: \"go_page2\" })}\n        {/* OR <FormattedMessage id=\"go_page2\" /> */}\n      </Link>\n    </Layout>\n  )\n}\nexport default injectIntl(IndexPage)\n```\nOr you can use the new `useIntl` hook.\n```jsx\nimport React from \"react\"\nimport { useIntl, Link, FormattedMessage } from \"gatsby-plugin-intl\"\n\nconst IndexPage = () => {\n  const intl = useIntl()\n  return (\n    <Layout>\n      <SEO\n        title={intl.formatMessage({ id: \"title\" })}\n      />\n      <Link to=\"/page-2/\">\n        {intl.formatMessage({ id: \"go_page2\" })}\n        {/* OR <FormattedMessage id=\"go_page2\" /> */}\n      </Link>\n    </Layout>\n  )\n}\nexport default IndexPage\n```\n\n\n## How It Works\n\nLet's say you have two pages (`index.js` and `page-2.js`) in your `pages` directory. The plugin will create static pages for every language.\n\nfile | English | Korean | German | Default*\n-- | -- | -- | -- | --\nsrc/pages/index.js | /**en** | /**ko** | /**de** | /\nsrc/pages/page-2.js | /**en**/page-2 | /**ko**/page-2 | /**de**/page-2 | /page-2\n\n**Default Pages and Redirection**\n\nIf redirect option is `true`, `/` or `/page-2` will be redirected to the user's preferred language router. e.g) `/ko` or `/ko/page-2`. Otherwise, the pages will render `defaultLangugage` language. You can also specify additional component to be rendered on redirection page by adding `redirectComponent` option.\n\n\n## Plugin Options\n\nOption | Type | Description\n-- | -- | --\npath | string | language JSON resource path\nlanguages | string[] | supported language keys\ndefaultLanguage | string | default language when visiting `/page` instead of `ko/page`\nredirect | boolean | if the value is `true`, `/` or `/page-2` will be redirected to the user's preferred language router. e.g) `/ko` or `/ko/page-2`. Otherwise, the pages will render `defaultLangugage` language.\nredirectComponent | string (optional) | additional component file path to be rendered on with a redirection component for SEO.\n\n\n## Components\n\nTo make it easy to handle i18n with multi-language url routes, the plugin provides several components.\n\nTo use it, simply import it from `gatsby-plugin-intl`.\n\nComponent | Type | Description\n-- | -- | --\nLink | component | This is a wrapper around @gatsby\u2019s Link component that adds useful enhancements for multi-language routes. All props are passed through to @gatsby\u2019s Link component.\nnavigate | function | This is a wrapper around @gatsby\u2019s navigate function that adds useful enhancements for multi-language routes. All options are passed through to @gatsby\u2019s navigate function.\nchangeLocale | function | A function that replaces your locale. `changeLocale(locale, to = null)`\nIntlContextConsumer | component | A context component to get plugin configuration on the component level.\ninjectIntl | component | https://github.com/yahoo/react-intl/wiki/API#injection-api\nFormattedMessage | component | https://github.com/yahoo/react-intl/wiki/Components#string-formatting-components\nand more... | | https://github.com/yahoo/react-intl/wiki/Components\n\n\n## License\n\nMIT &copy; [Daewoong Moon](https://github.com/wiziple)\n", "release_dates": []}, {"name": "governance-api", "description": null, "language": "TypeScript", "license": null, "readme": "<p align=\"center\">\n  <a href=\"http://nestjs.com/\" target=\"blank\"><img src=\"https://nestjs.com/img/logo-small.svg\" width=\"200\" alt=\"Nest Logo\" /></a>\n</p>\n\n[circleci-image]: https://img.shields.io/circleci/build/github/nestjs/nest/master?token=abc123def456\n[circleci-url]: https://circleci.com/gh/nestjs/nest\n\n  <p align=\"center\">A progressive <a href=\"http://nodejs.org\" target=\"_blank\">Node.js</a> framework for building efficient and scalable server-side applications.</p>\n    <p align=\"center\">\n<a href=\"https://www.npmjs.com/~nestjscore\" target=\"_blank\"><img src=\"https://img.shields.io/npm/v/@nestjs/core.svg\" alt=\"NPM Version\" /></a>\n<a href=\"https://www.npmjs.com/~nestjscore\" target=\"_blank\"><img src=\"https://img.shields.io/npm/l/@nestjs/core.svg\" alt=\"Package License\" /></a>\n<a href=\"https://www.npmjs.com/~nestjscore\" target=\"_blank\"><img src=\"https://img.shields.io/npm/dm/@nestjs/common.svg\" alt=\"NPM Downloads\" /></a>\n<a href=\"https://circleci.com/gh/nestjs/nest\" target=\"_blank\"><img src=\"https://img.shields.io/circleci/build/github/nestjs/nest/master\" alt=\"CircleCI\" /></a>\n<a href=\"https://coveralls.io/github/nestjs/nest?branch=master\" target=\"_blank\"><img src=\"https://coveralls.io/repos/github/nestjs/nest/badge.svg?branch=master#9\" alt=\"Coverage\" /></a>\n<a href=\"https://discord.gg/G7Qnnhy\" target=\"_blank\"><img src=\"https://img.shields.io/badge/discord-online-brightgreen.svg\" alt=\"Discord\"/></a>\n<a href=\"https://opencollective.com/nest#backer\" target=\"_blank\"><img src=\"https://opencollective.com/nest/backers/badge.svg\" alt=\"Backers on Open Collective\" /></a>\n<a href=\"https://opencollective.com/nest#sponsor\" target=\"_blank\"><img src=\"https://opencollective.com/nest/sponsors/badge.svg\" alt=\"Sponsors on Open Collective\" /></a>\n  <a href=\"https://paypal.me/kamilmysliwiec\" target=\"_blank\"><img src=\"https://img.shields.io/badge/Donate-PayPal-ff3f59.svg\"/></a>\n    <a href=\"https://opencollective.com/nest#sponsor\"  target=\"_blank\"><img src=\"https://img.shields.io/badge/Support%20us-Open%20Collective-41B883.svg\" alt=\"Support us\"></a>\n  <a href=\"https://twitter.com/nestframework\" target=\"_blank\"><img src=\"https://img.shields.io/twitter/follow/nestframework.svg?style=social&label=Follow\"></a>\n</p>\n  <!--[![Backers on Open Collective](https://opencollective.com/nest/backers/badge.svg)](https://opencollective.com/nest#backer)\n  [![Sponsors on Open Collective](https://opencollective.com/nest/sponsors/badge.svg)](https://opencollective.com/nest#sponsor)-->\n\n## Description\n\n[Nest](https://github.com/nestjs/nest) framework TypeScript starter repository.\n\n## Installation\n\n```bash\n$ yarn install\n```\n\n## Setup\n\nYou'll need to have a postgresql instance running locally.\n\n```bash\n$ yarn run db:setup\n```\n\n## Running the app\n\n```bash\n# development\n$ yarn run start\n\n# watch mode\n$ yarn run start:dev\n\n# production mode\n$ yarn run start:prod\n```\n\n## Test\n\n```bash\n# unit tests\n$ yarn run test\n\n# e2e tests\n$ yarn run test:e2e\n\n# test coverage\n$ yarn run test:cov\n```\n\n## Support\n\nNest is an MIT-licensed open source project. It can grow thanks to the sponsors and support by the amazing backers. If you'd like to join them, please [read more here](https://docs.nestjs.com/support).\n\n## Stay in touch\n\n- Author - [Kamil My\u015bliwiec](https://kamilmysliwiec.com)\n- Website - [https://nestjs.com](https://nestjs.com/)\n- Twitter - [@nestframework](https://twitter.com/nestframework)\n\n## License\n\nNest is [MIT licensed](LICENSE).\n", "release_dates": []}, {"name": "governance-docs", "description": null, "language": "JavaScript", "license": null, "readme": "# Website\n\nThis website is built using [Docusaurus 2](https://docusaurus.io/), a modern static website generator.\n\n### Installation\n\n```\n$ yarn\n```\n\n### Local Development\n\n```\n$ yarn start\n```\n\nThis command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.\n\n### Build\n\n```\n$ yarn build\n```\n\nThis command generates static content into the `build` directory and can be served using any static contents hosting service.\n\n### Deployment\n\nUsing SSH:\n\n```\n$ USE_SSH=true yarn deploy\n```\n\nNot using SSH:\n\n```\n$ GIT_USER=<Your GitHub username> yarn deploy\n```\n\nIf you are using GitHub pages for hosting, this command is a convenient way to build the website and push to the `gh-pages` branch.\n", "release_dates": []}, {"name": "governance-program-library", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# governance-program-library", "release_dates": ["2023-06-02T13:14:52Z", "2023-04-25T14:44:05Z", "2022-03-24T23:30:01Z"]}, {"name": "governance-sdk", "description": "Governance SDK ", "language": "TypeScript", "license": null, "readme": null, "release_dates": []}, {"name": "governance-ui", "description": null, "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "", "release_dates": []}, {"name": "governance-ui-landing", "description": "Governance UI Landing Page - realms.today", "language": "TypeScript", "license": null, "readme": "<div align=\"center\">\n  <h1>\ud83d\udd0b ts-nextjs-tailwind-starter</h1>\n  <p>Next.js + Tailwind CSS + TypeScript starter packed with useful development features.</p>\n  <p>Made by <a href=\"https://theodorusclarence.com\">Theodorus Clarence</a></p>\n  \n  \n  [![CodeFactor](https://www.codefactor.io/repository/github/theodorusclarence/ts-nextjs-tailwind-starter/badge/main)](https://www.codefactor.io/repository/github/theodorusclarence/ts-nextjs-tailwind-starter/overview/main)\n  [![Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=theodorusclarence_ts-nextjs-tailwind-starter&metric=sqale_rating)](https://sonarcloud.io/dashboard?id=theodorusclarence_ts-nextjs-tailwind-starter)\n  [![Bugs](https://sonarcloud.io/api/project_badges/measure?project=theodorusclarence_ts-nextjs-tailwind-starter&metric=bugs)](https://sonarcloud.io/dashboard?id=theodorusclarence_ts-nextjs-tailwind-starter)\n  [![GitHub Repo stars](https://img.shields.io/github/stars/theodorusclarence/ts-nextjs-tailwind-starter)](https://github.com/theodorusclarence/ts-nextjs-tailwind-starter/stargazers)\n  \n  [![Depfu](https://badges.depfu.com/badges/fc6e730632ab9dacaf7df478a08684a7/overview.svg)](https://depfu.com/github/theodorusclarence/ts-nextjs-tailwind-starter?project_id=30160)\n  [![Last Update](https://img.shields.io/badge/deps%20update-every%20sunday-blue.svg)](https://shields.io/)\n</div>\n\n## Features\n\nThis repository is \ud83d\udd0b battery packed with:\n\n- \u26a1\ufe0f Next.js 12\n- \u269b\ufe0f React 18\n- \u2728 TypeScript\n- \ud83d\udca8 Tailwind CSS 3 \u2014 Configured with CSS Variables to extend the **primary** color\n- \ud83d\udc8e Pre-built Components \u2014 Components that will **automatically adapt** with your brand color, [check here for the demo](https://tsnext-tw.thcl.dev/components)\n- \ud83c\udccf Jest \u2014 Configured for unit testing\n- \ud83d\udcc8 Absolute Import and Path Alias \u2014 Import components using `@/` prefix\n- \ud83d\udccf ESLint \u2014 Find and fix problems in your code, also will **auto sort** your imports\n- \ud83d\udc96 Prettier \u2014 Format your code consistently\n- \ud83d\udc36 Husky & Lint Staged \u2014 Run scripts on your staged files before they are committed\n- \ud83e\udd16 Conventional Commit Lint \u2014 Make sure you & your teammates follow conventional commit\n- \u23f0 Standard Version Changelog \u2014 Generate your changelog using `yarn release`\n- \ud83d\udc77 Github Actions \u2014 Lint your code on PR\n- \ud83d\ude98 Automatic Branch and Issue Autolink \u2014 Branch will be automatically created on issue **assign**, and auto linked on PR\n- \ud83d\udd25 Snippets \u2014 A collection of useful snippets\n- \ud83d\udc40 Default Open Graph \u2014 Awesome open graph generated using [og.thcl.dev](https://github.com/theodorusclarence/og), fork it and deploy!\n- \ud83d\uddfa Site Map \u2014 Automatically generate sitemap.xml\n- \ud83d\udce6 Expansion Pack \u2014 Easily install common libraries, additional components, and configs\n\nSee the \ud83d\udc49 [feature details and changelog](https://github.com/theodorusclarence/ts-nextjs-tailwind-starter/blob/main/CHANGELOG.md) \ud83d\udc48 for more.\n\nYou can also check all of the **details and demos** on my blog post:\n\n- [One-stop Starter to Maximize Efficiency on Next.js & Tailwind CSS Projects](https://theodorusclarence.com/blog/one-stop-starter)\n\n## Getting Started\n\n### 1. Clone this template using one of the three ways:\n\n1. Use this repository as template\n\n   **Disclosure:** by using this repository as a template, there will be an attribution on your repository.\n\n   I'll appreciate if you do, so this template can be known by others too \ud83d\ude04\n\n   ![Use as template](https://user-images.githubusercontent.com/55318172/129183039-1a61e68d-dd90-4548-9489-7b3ccbb35810.png)\n\n2. Using `create-next-app`\n\n   ```bash\n   npx create-next-app -e https://github.com/theodorusclarence/ts-nextjs-tailwind-starter project-name\n   ```\n\n3. Deploy to Vercel\n\n   [![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/git/external?repository-url=https%3A%2F%2Fgithub.com%2Ftheodorusclarence%2Fts-nextjs-tailwind-starter)\n\n### 2. Install dependencies\n\nIt is encouraged to use **yarn** so the husky hooks can work properly.\n\n```bash\nyarn install\n```\n\n### 3. Run the development server\n\nYou can start the server using this command:\n\n```bash\nyarn dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result. You can start editing the page by modifying `src/pages/index.tsx`.\n\n### 4. Change defaults\n\nThere are some things you need to change including title, urls, favicons, etc.\n\nFind all comments with !STARTERCONF, then follow the guide.\n\nDon't forget to change the package name in package.json\n\n### 5. Commit Message Convention\n\nThis starter is using [conventional commits](https://www.conventionalcommits.org/en/v1.0.0/), it is mandatory to use it to commit changes.\n\n## Expansion Pack \ud83d\udce6\n\nThis starter is now equipped with an [expansion pack](https://github.com/theodorusclarence/expansion-pack).\n\nYou can easily add expansion such as React Hook Form + Components, Storybook, and more just using a single command line.\n\nhttps://user-images.githubusercontent.com/55318172/146631994-e1cac137-1664-4cfe-950b-a96decc1eaa6.mp4\n\nCheck out the [expansion pack repository](https://github.com/theodorusclarence/expansion-pack) for the commands\n", "release_dates": []}, {"name": "hashbrown", "description": "Rust port of Google's SwissTable hash map", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "hashbrown\n=========\n\n[![Build Status](https://travis-ci.com/rust-lang/hashbrown.svg?branch=master)](https://travis-ci.com/rust-lang/hashbrown)\n[![Crates.io](https://img.shields.io/crates/v/hashbrown.svg)](https://crates.io/crates/hashbrown)\n[![Documentation](https://docs.rs/hashbrown/badge.svg)](https://docs.rs/hashbrown)\n\nThis crate is a Rust port of Google's high-performance [SwissTable] hash\nmap, adapted to make it a drop-in replacement for Rust's standard `HashMap`\nand `HashSet` types.\n\nThe original C++ version of SwissTable can be found [here], and this\n[CppCon talk] gives an overview of how the algorithm works.\n\nSince Rust 1.36, this is now the `HashMap` implementation for the Rust standard\nlibrary. However you may still want to use this crate instead since it works\nin environments without `std`, such as embedded systems and kernels.\n\n[SwissTable]: https://abseil.io/blog/20180927-swisstables\n[here]: https://github.com/abseil/abseil-cpp/blob/master/absl/container/internal/raw_hash_set.h\n[CppCon talk]: https://www.youtube.com/watch?v=ncHmEUmJZf4\n\n## [Change log](CHANGELOG.md)\n\n## Features\n\n- Drop-in replacement for the standard library `HashMap` and `HashSet` types.\n- Uses `AHash` as the default hasher, which is much faster than SipHash.\n- Around 2x faster than the previous standard library `HashMap`.\n- Lower memory usage: only 1 byte of overhead per entry instead of 8.\n- Compatible with `#[no_std]` (but requires a global allocator with the `alloc` crate).\n- Empty hash maps do not allocate any memory.\n- SIMD lookups to scan multiple hash entries in parallel.\n\n## Performance\n\nCompared to the previous implementation of `std::collections::HashMap` (Rust 1.35).\n\nWith the hashbrown default AHash hasher (not HashDoS-resistant):\n\n```text\n name                       oldstdhash ns/iter  hashbrown ns/iter  diff ns/iter   diff %  speedup \n insert_ahash_highbits        20,846              7,397                   -13,449  -64.52%   x 2.82 \n insert_ahash_random          20,515              7,796                   -12,719  -62.00%   x 2.63 \n insert_ahash_serial          21,668              7,264                   -14,404  -66.48%   x 2.98 \n insert_erase_ahash_highbits  29,570              17,498                  -12,072  -40.83%   x 1.69 \n insert_erase_ahash_random    39,569              17,474                  -22,095  -55.84%   x 2.26 \n insert_erase_ahash_serial    32,073              17,332                  -14,741  -45.96%   x 1.85 \n iter_ahash_highbits          1,572               2,087                       515   32.76%   x 0.75 \n iter_ahash_random            1,609               2,074                       465   28.90%   x 0.78 \n iter_ahash_serial            2,293               2,120                      -173   -7.54%   x 1.08 \n lookup_ahash_highbits        3,460               4,403                       943   27.25%   x 0.79 \n lookup_ahash_random          6,377               3,911                    -2,466  -38.67%   x 1.63 \n lookup_ahash_serial          3,629               3,586                       -43   -1.18%   x 1.01 \n lookup_fail_ahash_highbits   5,286               3,411                    -1,875  -35.47%   x 1.55 \n lookup_fail_ahash_random     12,365              4,171                    -8,194  -66.27%   x 2.96 \n lookup_fail_ahash_serial     4,902               3,240                    -1,662  -33.90%   x 1.51 \n```\n\nWith the libstd default SipHash hasher (HashDoS-resistant):\n\n```text\n name                       oldstdhash ns/iter  hashbrown ns/iter  diff ns/iter   diff %  speedup \n insert_std_highbits        32,598              20,199                  -12,399  -38.04%   x 1.61 \n insert_std_random          29,824              20,760                   -9,064  -30.39%   x 1.44 \n insert_std_serial          33,151              17,256                  -15,895  -47.95%   x 1.92 \n insert_erase_std_highbits  74,731              48,735                  -25,996  -34.79%   x 1.53 \n insert_erase_std_random    73,828              47,649                  -26,179  -35.46%   x 1.55 \n insert_erase_std_serial    73,864              40,147                  -33,717  -45.65%   x 1.84 \n iter_std_highbits          1,518               2,264                       746   49.14%   x 0.67 \n iter_std_random            1,502               2,414                       912   60.72%   x 0.62 \n iter_std_serial            6,361               2,118                    -4,243  -66.70%   x 3.00 \n lookup_std_highbits        21,705              16,962                   -4,743  -21.85%   x 1.28 \n lookup_std_random          21,654              17,158                   -4,496  -20.76%   x 1.26 \n lookup_std_serial          18,726              14,509                   -4,217  -22.52%   x 1.29 \n lookup_fail_std_highbits   25,852              17,323                   -8,529  -32.99%   x 1.49 \n lookup_fail_std_random     25,913              17,760                   -8,153  -31.46%   x 1.46 \n lookup_fail_std_serial     22,648              14,839                   -7,809  -34.48%   x 1.53 \n```\n\n## Usage\n\nAdd this to your `Cargo.toml`:\n\n```toml\n[dependencies]\nhashbrown = \"0.8\"\n```\n\nThen:\n\n```rust\nuse hashbrown::HashMap;\n\nlet mut map = HashMap::new();\nmap.insert(1, \"one\");\n```\n\nThis crate has the following Cargo features:\n\n- `nightly`: Enables nightly-only features: `#[may_dangle]`.\n- `serde`: Enables serde serialization support.\n- `rayon`: Enables rayon parallel iterator support.\n- `raw`: Enables access to the experimental and unsafe `RawTable` API.\n- `inline-more`: Adds inline hints to most functions, improving run-time performance at the cost\n  of compilation time. (enabled by default)\n- `ahash`: Compiles with ahash as default hasher. (enabled by default)\n- `ahash-compile-time-rng`: Activates the `compile-time-rng` feature of ahash, to increase the\n   DOS-resistance, but can result in issues for `no_std` builds. More details in\n   [issue#124](https://github.com/rust-lang/hashbrown/issues/124). (enabled by default)\n\n## License\n\nLicensed under either of:\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any\nadditional terms or conditions.\n", "release_dates": []}, {"name": "heroku-buildpack-rust-wasm-pack", "description": "A buildpack for wasm-pack applications on Heroku, with full support for Rustup, cargo and build caching.", "language": "Shell", "license": null, "readme": "# Heroku buildpack for Rust and wasm-pack\n\nThis is a Heroku buildpack for Rust and wasm-pack with support for [cargo][] and [rustup][].  Features include:\n\n- Caching of builds between deployments.\n- Automatic updates to the latest stable Rust by default.\n- Support for `export` so that other buildpacks can access the Rust toolchain.\n- Support for compiling Rust-based extensions for projects written in other languages.\n\n[cargo]: http://crates.io/\n[rustup]: https://www.rustup.rs/\n\n## Active projects\n\n- [example-messagefeed][] uses Wasm to serialize Solana program instructions\n\n[example-messagefeed]: https://github.com/solana-labs/example-messagefeed\n\n## Using this buildpack\n\nTo deploy an application to Heroku, we recommend installing the [Heroku CLI][].\n\nIf you're creating a new Heroku application, `cd` to the directory containing your code, and run:\n\n```sh\nheroku create --buildpack https://github.com/solana-labs/heroku-buildpack-rust-wasm-pack.git\n```\n\nThis will only work if your application has a `Cargo.toml` and uses `git`. If you want to set a particular name for application, see `heroku create --help` first.\n\nTo use this as the buildpack for an existing application, run:\n\n```sh\nheroku buildpacks:add --index 1 https://github.com/solana-labs/heroku-buildpack-rust-wasm-pack.git\n```\n", "release_dates": []}, {"name": "heroku-buildpack-static", "description": "Heroku buildpack for handling static sites and single page web apps", "language": "Ruby", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# heroku-buildpack-static\n**NOTE**: This buildpack is in an experimental OSS project.\n\nThis is a buildpack for handling static sites and single page web apps.\n\nFor a guide, read the [Getting Started with Single Page Apps on Heroku](https://gist.github.com/hone/24b06869b4c1eca701f9).\n\n## Features\n* serving static assets\n* gzip on by default\n* error/access logs support in `heroku logs`\n* custom [configuration](#configuration)\n\n## Deploying\nThe `static.json` file is required to use this buildpack. This file handles all the configuration described below.\n\n1. Set the app to this buildpack: `$ heroku buildpacks:set heroku-community/static`.\n2. Deploy: `$ git push heroku master`\n\n### Configuration\nYou can configure different options for your static application by writing a `static.json` in the root folder of your application.\n\n#### Root\nThis allows you to specify a different asset root for the directory of your application. For instance, if you're using ember-cli, it naturally builds a `dist/` directory, so you might want to use that instead.\n\n```json\n{\n  \"root\": \"dist/\"\n}\n\n```\n\nBy default this is set to `public_html/`\n\n#### Canonical Host\nThis allows you to perform 301 redirects to a specific hostname, which can be useful for redirecting www to non-www (or vice versa).\n\n```json\n{\n  \"canonical_host\": \"www.example.com\"\n}\n```\n\nYou can use environment variables as well:\n\n```json\n{\n  \"canonical_host\": \"${HOST}\"\n}\n```\n\n#### Default Character Set\nThis allows you to specify a character set for your text assets (HTML, Javascript, CSS, and so on). For most apps, this should be the default value of \"UTF-8\", but you can override it by setting `encoding`:\n\n```json\n{\n    \"encoding\": \"US-ASCII\"\n}\n```\n\n#### Clean URLs\nFor SEO purposes, you can drop the `.html` extension from URLs for say a blog site. This means users could go to `/foo` instead of `/foo.html`.\n\n\n```json\n{\n  \"clean_urls\": true\n}\n```\n\nBy default this is set to `false`.\n\n\n#### Logging\nYou can disable the access log and change the severity level for the error log.\n\n```json\n{\n  \"logging\": {\n    \"access\": false,\n    \"error\": \"warn\"\n  }\n}\n```\n\nBy default `access` is set to `true` and `error` is set to `error`.\n\nThe environment variable `STATIC_DEBUG` can be set, to override the `error` log level to `error`.\n\n\n#### Custom Routes\nYou can define custom routes that combine to a single file. This allows you to preserve routing for a single page web application. The following operators are supported:\n\n* `*` supports a single path segment in the URL. In the configuration below, `/baz.html` would match but `/bar/baz.html` would not.\n* `**` supports any length in the URL.  In the configuration below, both `/route/foo` would work and `/route/foo/bar/baz`.\n\n```json\n{\n  \"routes\": {\n    \"/*.html\": \"index.html\",\n    \"/route/**\": \"bar/baz.html\"\n  }\n}\n```\n\n##### Browser history and asset files\nWhen serving a single page app, it's useful to support wildcard URLs that serves the index.html file, while also continuing to serve JS and CSS files correctly. Route ordering allows you to do both:\n\n```json\n{\n  \"routes\": {\n    \"/assets/*\": \"/assets/\",\n    \"/**\": \"index.html\"\n  }\n}\n```\n\n#### Custom Redirects\nWith custom redirects, you can move pages to new routes but still preserve the old routes for SEO purposes. By default, we return a `301` status code, but you can specify the status code you want.\n\n```json\n{\n  \"redirects\": {\n    \"/old/gone/\": {\n      \"url\": \"/\",\n      \"status\": 302\n    }\n  }\n}\n```\n\n##### Interpolating Env Var Values\nIt's common to want to be able to test the frontend against various backends. The `url` key supports environment variable substitution using `${ENV_VAR_NAME}`. For instance, if there was a staging and production Heroku app for your API, you could setup the config above like the following:\n\n```json\n{\n  \"redirects\": {\n    \"/old/gone/\": {\n      \"url\": \"${NEW_SITE_DOMAIN}/new/here/\"\n    }\n  }\n}\n```\n\nThen using the [config vars](https://devcenter.heroku.com/articles/config-vars), you can point the frontend app to the appropriate backend. To match the original proxy setup:\n\n```bash\n$ heroku config:set NEW_SITE_DOMAIN=\"https://example.herokapp.com\"\n```\n\n#### Custom Error Pages\nYou can replace the default nginx 404 and 500 error pages by defining the path to one in your config.\n\n```json\n{\n  \"error_page\": \"errors/error.html\"\n}\n```\n\n#### HTTPS Only\n\nYou can redirect all HTTP requests to HTTPS.\n\n```\n{\n  \"https_only\": true\n}\n```\n\n#### Basic Authentication\n\nYou can enable Basic Authentication so all requests require authentication.\n\n```\n{\n  \"basic_auth\": true\n}\n```\n\nThis will generate `.htpasswd` using environment variables `BASIC_AUTH_USERNAME` and `BASIC_AUTH_PASSWORD` if they are present. Otherwise it will use a standard `.htpasswd` file present in the `app` directory.\n\nPasswords set via `BASIC_AUTH_PASSWORD` can be generated using OpenSSL or Apache Utils. For instance: `openssl passwd -apr1`.\n\n#### Proxy Backends\nFor single page web applications like Ember, it's common to back the application with another app that's hosted on Heroku. The down side of separating out these two applications is that now you have to deal with CORS. To get around this (but at the cost of some latency) you can have the static buildpack proxy apps to your backend at a mountpoint. For instance, we can have all the api requests live at `/api/` which actually are just requests to our API server.\n\n```json\n{\n  \"proxies\": {\n    \"/api/\": {\n      \"origin\": \"https://hone-ember-todo-rails.herokuapp.com/\"\n    }\n  }\n}\n```\n\n##### Interpolating Env Var Values\nIt's common to want to be able to test the frontend against various backends. The `origin` key supports environment variable substitution using `${ENV_VAR_NAME}`. For instance, if there was a staging and production Heroku app for your API, you could setup the config above like the following:\n\n```json\n{\n  \"proxies\": {\n    \"/api/\": {\n      \"origin\": \"https://${API_APP_NAME}.herokuapp.com/\"\n    }\n  }\n}\n```\n\nThen using the [config vars](https://devcenter.heroku.com/articles/config-vars), you can point the frontend app to the appropriate backend. To match the original proxy setup:\n\n```bash\n$ heroku config:set API_APP_NAME=\"hone-ember-todo-rails\"\n```\n\n#### Custom Headers\nUsing the headers key, you can set custom response headers. It uses the same operators for pathing as [Custom Routes](#custom-routes).\n\n```json\n{\n  \"headers\": {\n    \"/\": {\n      \"Cache-Control\": \"no-store, no-cache\"\n    },\n    \"/assets/**\": {\n      \"Cache-Control\": \"public, max-age=512000\"\n    },\n    \"/assets/webfonts/*\": {\n      \"Access-Control-Allow-Origin\": \"*\"\n    }\n  }\n}\n```\n\nFor example, to enable CORS for all resources, you just need to enable it for all routes like this:\n\n```json\n{\n  \"headers\": {\n    \"/**\": {\n      \"Access-Control-Allow-Origin\": \"*\"\n    }\n  }\n}\n```\n\n##### Precedence\nWhen there are header conflicts, the last header definition always wins. The headers do not get appended. For example,\n\n```json\n{\n  \"headers\": {\n    \"/**\": {\n      \"X-Foo\": \"bar\",\n      \"X-Bar\": \"baz\"\n    },\n    \"/foo\": {\n      \"X-Foo\": \"foo\"\n    }\n  }\n}\n```\n\nwhen accessing `/foo`, `X-Foo` will have the value `\"foo\"` and `X-Bar` will not be present.\n\n### Route Ordering\n\n* HTTPS redirect\n* Root Files\n* Clean URLs\n* Proxies\n* Redirects\n* Custom Routes\n* 404\n\n### Procfile / multiple buildpacks\n\nIn case you have multiple buildpacks for the application you can ensure static rendering in `Procfile` with `web: bin/boot`.\n\n## Testing\nFor testing we use Docker to replicate Heroku locally. You'll need to have [it setup locally](https://docs.docker.com/installation/). We're also using rspec for testing with Ruby. You'll need to have those setup and install those deps:\n\n```sh\n$ bundle install\n```\n\nTo run the test suite just execute:\n\n```sh\n$ bundle exec rspec\n```\n\n### Structure\nTo add a new test, add another example inside `spec/simple_spec.rb` or create a new file based off of `spec/simple_spec.rb`. All the example apps live in `spec/fixtures`.\n\nWhen writing a test, `BuildpackBuilder` creates the docker container we need that represents the heroku cedar-14 stack. `AppRunner.new` takes the name of a fixture and mounts it in the container built by `BuildpackBuilder` to run tests against. The `AppRunner` instance provides convenience methods like `get` that just wrap `net/http` for analyzing the response.\n\n### Boot2docker\n\nIf you are running docker with boot2docker, the buildpack will automatically send tests to the right ip address.\nYou need to forward the docker's port 3000 to the virtual machine's port though.\n\n```\nVBoxManage modifyvm \"boot2docker-vm\" --natpf1 \"tcp-port3000,tcp,,3000,,3000\";\n```\n\n## Releasing new binaries\n\nThe steps buildpack maintainers need to perform when releasing new nginx\nbinaries (either for a new stack or `ngx_mruby` version), are:\n\n1. Update the stacks list in `Makefile` and/or the ngx_mruby version\n  in `scripts/build_ngx_mruby.sh`.\n2. Run `make build` to build all stacks or `make build-heroku-NN` to build just one stack.\n3. Ensure the AWS CLI is installed (eg `brew install awscli`).\n4. Authenticate with the relevant AWS account (typically by setting the environment variables from PCSK).\n5. Run `make sync` (or if using a custom S3 bucket, `S3_BUCKET=... make sync`).\n6. Update `bin/compile` to reference the new stacks and/or nginx version URLs.\n7. Open a PR with the changes from (1) and (6).\n", "release_dates": []}, {"name": "inc-20210825", "description": "Tool for audit and reclaim of delegated SPL Token accounts", "language": "Rust", "license": null, "readme": "## Usage\n### Install prerequisites\n#### System development libraries\n```\nsudo apt install libssl-dev libudev-dev pkg-config gcc\n```\n#### Rust\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n```\n### Minimum Solana Configuration\n\n#### Initialize default keypair file\n\nThis is only needed as part of program's initialization.\nSOL isn't used for `audit` mode. Only needed for `cleanup` mode to send actual\ncleanup transactions if any.\n\n```\nsolana-keygen new\n```\n\nOtherwise, this program would fail to execute at all with\n`error: No such file or directory (os error 2)`.\n\n### Availability of private keys\n\n`cleanup` mode requires the existence of private keys of spl-token owners locally.\nThis usually means the need to store them in the Solana CLI's JSON format.\n\nHowever, only public key _addresses_ will be needed with its `--dry-run` option.\nIn that case, equivalent `spl-token revoke ...` must be executed with corresponding\nprivate keys to clean-up them.\n\n`audit` mode doesn't require private keys, only public key _addresses_ of\nspl-token owners.\n\n### Targeted vulnerable account cleanup\nThe following command will revoke any existing delegations on all wallet:mint\npairs provided. Specify addresses for all mints that your organization supports\nas well as every user deposit SOL wallet generated before epoch 216. Wallets\nmust be specified as the path to a keypair file in `solana-keygen new` format.\nIt may be necessary to run this command in multiple batches if the command line\nis too long for the shell.\n#### Dry-run\nFirst a dry-run to be sure everything looks OK\n```\ncargo run -- cleanup \\\n--dry-run \\\n--mint MINT1_ADDRESS \\\n--mint MINT2_ADDRESS \\\n... \\\n--mint MINTN_ADDRESS \\\nDEPOSIT_SOL_WALLET1_PATH \\\nDEPOSIT_SOL_WALLET2_PATH \\\n... \\\nDEPOSIT_SOL_WALLETN_PATH\n```\n#### Effective run\nIf everything looks OK from the [dry-run](#dry-run), run the same command again\nwith the `--dry-run` argument removed.\n### Targeted transaction history audit\nThe following will generate an audit report for the transaction history of each\ntoken account, flagging suspicious and malicious behavior. As with\n[cleanup](#targeted-vulnerable-account-cleanup), specify the addresses for every\nmint your organization supports as well as every user deposit SOL wallet\ngenerated before epoch 216. Wallets must be specified as the path to a keypair\nfile in `solana-keygen new` format. It may be necessary to run this command in\nmultiple batches if the command line is to long for the shell.\n#### Run\n```\ncargo run -- audit \\\n--mint MINT1_ADDRESS \\\n--mint MINT2_ADDRESS \\\n... \\\n--mint MINTN_ADDRESS \\\nDEPOSIT_SOL_WALLET1_PATH \\\nDEPOSIT_SOL_WALLET2_PATH \\\n... \\\nDEPOSIT_SOL_WALLETN_PATH | tee report.csv\n```\n#### Expected output\n\n```\naudit\nSummary Reassigned Token Account Report\nStatus,Account Address,Owner Address,Set Owner Signature,Delegation Signature,Possibly Fraudulent Transfer and Burn Signatures\n<Records for each address with Safe or other status>\n...\n```\n\nIf you only see the headers with no records, the pointed RPC URL might not have\nfull transaction history. Try to use other RPC by the `-u` option or edit the\nsolana cli config file on your environment.\n\nAlso, there will be no records printed if the given owner address holds no spl-token\nat all.\n\n### Full vulnerable account cleanup\nIt is possible that an attacker created vulnerable accounts for mints that your\norganization does not yet support in the hope that one day they will be supported\nand deposits can be exploited. To clean up all potentially vulnerable accounts,\nre-run the [cleanup](#targeted-vulnerable-account-cleanup) command, this time\nomitting all `--mint ...` arguments. This process may take quite some time depending\non how many unique tokens have been sent to each wallet.\n\n# Disclaimer\n\nAll claims, content, designs, algorithms, estimates, roadmaps,\nspecifications, and performance measurements described in this project\nare done with the Solana Foundation's (\"SF\") good faith efforts. It is up to\nthe reader to check and validate their accuracy and truthfulness.\nFurthermore nothing in this project constitutes a solicitation for\ninvestment.\n\nAny content produced by SF or developer resources that SF provides, are\nfor educational and inspiration purposes only. SF does not encourage,\ninduce or sanction the deployment, integration or use of any such\napplications (including the code comprising the Solana blockchain\nprotocol) in violation of applicable laws or regulations and hereby\nprohibits any such deployment, integration or use. This includes use of\nany such applications by the reader (a) in violation of export control\nor sanctions laws of the United States or any other applicable\njurisdiction, (b) if the reader is located in or ordinarily resident in\na country or territory subject to comprehensive sanctions administered\nby the U.S. Office of Foreign Assets Control (OFAC), or (c) if the\nreader is or is working on behalf of a Specially Designated National\n(SDN) or a person subject to similar blocking or denied party\nprohibitions.\n\nThe reader should be aware that U.S. export control and sanctions laws\nprohibit U.S. persons (and other persons that are subject to such laws)\nfrom transacting with persons in certain countries and territories or\nthat are on the SDN list. As a project based primarily on open-source\nsoftware, it is possible that such sanctioned persons may nevertheless\nbypass prohibitions, obtain the code comprising the Solana blockchain\nprotocol (or other project code or applications) and deploy, integrate,\nor otherwise use it. Accordingly, there is a risk to individuals that\nother persons using the Solana blockchain protocol may be sanctioned\npersons and that transactions with such persons would be a violation of\nU.S. export controls and sanctions law. This risk applies to\nindividuals, organizations, and other ecosystem participants that\ndeploy, integrate, or use the Solana blockchain protocol code directly\n(e.g., as a node operator), and individuals that transact on the Solana\nblockchain through light clients, third party interfaces, and/or wallet\nsoftware.\n", "release_dates": []}, {"name": "interns-codehub", "description": "Public repo for Solana interns", "language": "TypeScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# interns-codehub\nPublic repo for Solana interns\n", "release_dates": []}, {"name": "ipfs-ledger", "description": null, "language": null, "license": null, "readme": "# ipfs-ledger", "release_dates": []}, {"name": "jsonrpc", "description": "Rust JSON-RPC implementation; OBSOLETE, required by Solana v0.9.0 - v0.11.0", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Parity JSON-RPC\n\nRust implementation of JSON-RPC 2.0 Specification.\nTransport-agnostic `core` and transport servers for `http`, `ipc`, `websockets` and `tcp`.\n\n[![Build Status][travis-image]][travis-url]\n[![Build Status][appveyor-image]][appveyor-url]\n\n[travis-image]: https://travis-ci.org/paritytech/jsonrpc.svg?branch=master\n[travis-url]: https://travis-ci.org/paritytech/jsonrpc\n[appveyor-image]: https://ci.appveyor.com/api/projects/status/github/paritytech/jsonrpc?svg=true\n[appveyor-url]: https://ci.appveyor.com/project/paritytech/jsonrpc/branch/master\n\n[Documentation](http://paritytech.github.io/jsonrpc/)\n\n## Sub-projects\n- [jsonrpc-core](./core) [![crates.io][core-image]][core-url]\n- [jsonrpc-http-server](./http) [![crates.io][http-server-image]][http-server-url]\n- [jsonrpc-minihttp-server](./minihttp)\n- [jsonrpc-ipc-server](./ipc)\n- [jsonrpc-tcp-server](./tcp) [![crates.io][tcp-server-image]][tcp-server-url]\n- [jsonrpc-ws-server](./ws)\n- [jsonrpc-stdio-server](./stdio)\n- [jsonrpc-macros](./macros) [![crates.io][macros-image]][macros-url]\n- [jsonrpc-server-utils](./server-utils) [![crates.io][server-utils-image]][server-utils-url]\n- [jsonrpc-pubsub](./pubsub) [![crates.io][pubsub-image]][pubsub-url]\n\n[core-image]: https://img.shields.io/crates/v/jsonrpc-core.svg\n[core-url]: https://crates.io/crates/jsonrpc-core\n[http-server-image]: https://img.shields.io/crates/v/jsonrpc-http-server.svg\n[http-server-url]: https://crates.io/crates/jsonrpc-http-server\n[tcp-server-image]: https://img.shields.io/crates/v/jsonrpc-tcp-server.svg\n[tcp-server-url]: https://crates.io/crates/jsonrpc-tcp-server\n[macros-image]: https://img.shields.io/crates/v/jsonrpc-macros.svg\n[macros-url]: https://crates.io/crates/jsonrpc-macros\n[server-utils-image]: https://img.shields.io/crates/v/jsonrpc-server-utils.svg\n[server-utils-url]: https://crates.io/crates/jsonrpc-server-utils\n[pubsub-image]: https://img.shields.io/crates/v/jsonrpc-pubsub.svg\n[pubsub-url]: https://crates.io/crates/jsonrpc-pubsub\n\n## Examples\n\n- [core](./core/examples)\n- [macros](./macros/examples)\n- [pubsub](./pubsub/examples)\n\n### Basic Usage (with HTTP transport)\n\n```rust\nextern crate jsonrpc_core;\nextern crate jsonrpc_minihttp_server;\n\nuse jsonrpc_core::{IoHandler, Value, Params};\nuse jsonrpc_minihttp_server::{ServerBuilder};\n\nfn main() {\n\tlet mut io = IoHandler::new();\n\tio.add_method(\"say_hello\", |_params: Params| {\n\t\tOk(Value::String(\"hello\".to_string()))\n\t});\n\n\tlet server = ServerBuilder::new(io)\n\t\t.threads(3)\n\t\t.start_http(&\"127.0.0.1:3030\".parse().unwrap())\n\t\t.unwrap();\n\n\tserver.wait().unwrap();\n}\n```\n\n### Basic usage with macros\n\n```rust\nextern crate jsonrpc_core;\n#[macro_use]\nextern crate jsonrpc_macros;\n\nuse jsonrpc_core::Result;\n\nbuild_rpc_trait! {\n\tpub trait Rpc {\n\t\t/// Adds two numbers and returns a result\n\t\t#[rpc(name = \"add\")]\n\t\tfn add(&self, u64, u64) -> Result<u64>;\n\t}\n}\n\npub struct RpcImpl;\nimpl Rpc for RpcImpl {\n\tfn add(&self, a: u64, b: u64) -> Result<u64> {\n\t\tOk(a + b)\n\t}\n}\n\n\nfn main() {\n\tlet mut io = jsonrpc_core::IoHandler::new();\n\tio.extend_with(RpcImpl.to_delegate())\n}\n", "release_dates": ["2018-12-07T21:54:49Z", "2018-10-15T19:46:44Z", "2018-10-11T19:15:31Z", "2018-10-11T19:02:07Z", "2018-09-28T22:34:46Z"]}, {"name": "k8s-cluster", "description": null, "language": null, "license": null, "readme": "# k8s-cluster", "release_dates": []}, {"name": "kurtosis-solana-testing", "description": null, "language": "Rust", "license": null, "readme": "Solana Testing\n==============\nUses Kurtosis to run holistic integration tests on Solana, referencing Solana's benchmark local cluster documentation: https://docs.solana.com/cluster/bench-tps . To execute the testsuite, run `scripts/build-and-run.sh all`.\n\n### Genesis and Faucet Configuration Files\nThe genesis configuration inside `genesis_config.rs` was created using the `scripts/generate-genesis-ledger.sh` script.\n\nThe docker images used by Kurtosis for Solana testnets come with these configurations pre-loaded, allowing faucet and bootstrap nodes to start the networks.\n\n### Solana Testnets\nA Solana testnet consists of a faucet node, a bootstrap node, and then the rest of the validators.\nThe faucet spins up first, the bootstrap spins up referencing the faucet.\n", "release_dates": []}, {"name": "launchpad", "description": "Solana launchpad reference implementation", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Solana Launchpad\n\n## Introduction\n\nSolana Launchpad is a trustless and decentralized token distribution platform. It can assist you in launching a new token or selling already existing tokens via flexible price discovery mechanisms. Launchpad program initiates the token sale process by locking tokens provided by a seller and then offering them at the dynamic price, set by one of the pricing models.\n\nMain Goals:\n\n- Maximize funds raised with token sales.\n- Provide transparency and trust to the sale process.\n- Provide flexibility and full control to the sellers.\n\n## Contributing\n\nContributions are very welcome. Please refer to the [Contributing](https://github.com/solana-labs/solana/blob/master/CONTRIBUTING.md) guidelines for more information.\n\n## License\n\nSolana Launchpad is a part of the Solana Program Library, which is released under this [License](https://github.com/solana-labs/solana-program-library/blob/master/LICENSE).\n\n## Disclaimer\n\nBy accessing or using Solana Launchpad or any of its components, you accept and agree with the [Disclaimer](DISCLAIMER.md).\n", "release_dates": []}, {"name": "ledger-app-solana", "description": "Solana app for Ledger Wallet", "language": null, "license": null, "readme": "This repository is now tracked at [LedgerHQ](https://github.com/LedgerHQ/app-solana)\n", "release_dates": ["2020-09-02T17:33:58Z", "2020-08-26T04:29:36Z", "2020-05-04T20:05:53Z", "2020-04-30T18:09:05Z", "2020-04-21T23:02:17Z", "2020-03-03T04:20:35Z", "2020-02-24T16:18:28Z"]}, {"name": "libra", "description": "Fork of Libra for the purpose of publishing crates to crates.io", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<a href=\"https://developers.libra.org\">\n\t<img width=\"200\" src=\"./.assets/libra.png\" alt=\"Libra Logo\" />\n</a>\n\n---\n\n[![CircleCI](https://circleci.com/gh/libra/libra.svg?style=shield)](https://circleci.com/gh/libra/libra)\n[![License](https://img.shields.io/badge/license-Apache-green.svg)](LICENSE)\n\nLibra Core implements a decentralized, programmable database which provides a financial infrastructure that can empower billions of people.\n\n## Note to Developers\n* Libra Core is a prototype.\n* The APIs are constantly evolving and designed to demonstrate types of functionality. Expect substantial changes before the release.\n* We\u2019ve launched a testnet that is a live demonstration of an early prototype of the Libra Blockchain software.\n\n## Contributing\n\nRead our [Contributing guide](https://developers.libra.org/docs/community/contributing). Find out what\u2019s coming on our [blog](https://developers.libra.org/blog/2019/06/18/the-path-forward).\n\n## Getting Started\n\n### Learn About Libra\n* [Welcome](https://developers.libra.org/docs/welcome-to-libra)\n* [Libra Protocol: Key Concepts](https://developers.libra.org/docs/libra-protocol)\n* [Life of a Transaction](https://developers.libra.org/docs/life-of-a-transaction)\n\n### Try Libra Core\n* [My First Transaction](https://developers.libra.org/docs/my-first-transaction)\n* [Getting Started With Move](https://developers.libra.org/docs/move-overview)\n\n### Technical Papers\n* [The Libra Blockchain](https://developers.libra.org/docs/the-libra-blockchain-paper)\n* [Move: A Language With Programmable Resources](https://developers.libra.org/docs/move-paper)\n* [State Machine Replication in the Libra Blockchain](https://developers.libra.org/docs/state-machine-replication-paper)\n\n### Blog\n* [Libra: The Path Forward](https://developers.libra.org/blog/2019/06/18/the-path-forward/)\n\n### Libra Codebase\n\n* [Libra Core Overview](https://developers.libra.org/docs/libra-core-overview)\n* [Admission Control](https://developers.libra.org/docs/crates/admission-control)\n* [Bytecode Verifier](https://developers.libra.org/docs/crates/bytecode-verifier)\n* [Consensus](https://developers.libra.org/docs/crates/consensus)\n* [Crypto](https://developers.libra.org/docs/crates/crypto)\n* [Execution](https://developers.libra.org/docs/crates/execution)\n* [Mempool](https://developers.libra.org/docs/crates/mempool)\n* [Move IR Compiler](https://developers.libra.org/docs/crates/ir-to-bytecode)\n* [Move Language](https://developers.libra.org/docs/crates/move-language)\n* [Network](https://developers.libra.org/docs/crates/network)\n* [Storage](https://developers.libra.org/docs/crates/storage)\n* [Virtual Machine](https://developers.libra.org/docs/crates/vm)\n\n\n## Community\n\n* Join us on the [Libra Discourse](https://community.libra.org).\n* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/libra).\n* Get the latest updates to our project by signing up for our [newsletter](https://developers.libra.org/newsletter_form).\n\n## License\n\nLibra Core is licensed as [Apache 2.0](https://github.com/libra/libra/blob/master/LICENSE).\n", "release_dates": ["2020-05-01T16:52:46Z", "2019-10-25T20:00:20Z", "2019-10-25T17:40:13Z", "2019-10-25T16:53:26Z", "2019-10-25T15:54:02Z", "2019-08-06T16:51:46Z", "2019-07-27T18:30:52Z", "2019-07-27T15:16:29Z", "2019-07-27T12:05:43Z", "2019-07-27T05:27:17Z", "2019-07-26T17:11:51Z", "2019-07-27T05:17:48Z", "2019-07-26T20:13:08Z", "2019-07-26T19:57:16Z", "2019-07-26T19:43:52Z", "2019-07-26T18:00:55Z", "2019-07-26T17:29:14Z", "2019-07-26T22:22:25Z", "2019-07-26T22:11:19Z", "2019-07-26T21:46:13Z", "2019-07-26T20:56:15Z", "2019-07-24T19:14:16Z", "2019-07-24T16:26:34Z", "2019-07-22T18:20:10Z", "2019-07-18T15:39:23Z"]}, {"name": "lld", "description": "Mirror of official lld git repository located at http://llvm.org/git/lld. Updated every five minutes.", "language": "C++", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "LLVM Linker (lld)\n=================\n\nThis directory and its subdirectories contain source code for the LLVM Linker, a\nmodular cross platform linker which is built as part of the LLVM compiler\ninfrastructure project.\n\nlld is open source software. You may freely distribute it under the terms of\nthe license agreement found in LICENSE.txt.\n\nBenchmarking\n============\n\nIn order to make sure various developers can evaluate patches over the\nsame tests, we create a collection of self contained programs.\n\nIt is hosted at https://s3-us-west-2.amazonaws.com/linker-tests/lld-speed-test.tar.xz\n\nThe current sha256 is 10eec685463d5a8bbf08d77f4ca96282161d396c65bd97dc99dbde644a31610f.\n", "release_dates": []}, {"name": "llvm", "description": "Mirror of official llvm git repository located at http://llvm.org/git/llvm.  Updated every five minutes.", "language": "LLVM", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "The LLVM Compiler Infrastructure\n================================\n\nThis directory and its subdirectories contain source code for LLVM,\na toolkit for the construction of highly optimized compilers,\noptimizers, and runtime environments.\n\nLLVM is open source software. You may freely distribute it under the terms of\nthe license agreement found in LICENSE.txt.\n\nPlease see the documentation provided in docs/ for further\nassistance with LLVM, and in particular docs/GettingStarted.rst for getting\nstarted with LLVM and docs/README.txt for an overview of LLVM's\ndocumentation setup.\n\nIf you are writing a package for LLVM, see docs/Packaging.rst for our\nsuggestions.\n\n", "release_dates": []}, {"name": "llvm-builder", "description": "Builds customized LLVM for Solana", "language": "Dockerfile", "license": null, "readme": "# Customized LLVM binaries for Solana\n\nBuilds LLVM binaries that incorporate customizations and fixes required\nby Solana but not yet upstreamed into the LLVM mainline.\n\n* Builds LLVM for Linux (Debian)\n* Builds LLVM for MacOS natively therefore skipped if not building on a Mac\n* Results in tarballs in `/deploy` that can be released\n\n### Building\n\n```bash\n$ ./build.sh\n```\n\n* Builds LLVM for Linux in Docker, tags and pushes `solanalabs/llvm`\n* Copies LLVM for Linux out of Docker the zips the products into `/deploy`\n* Builds LLVM for MacOS natively and zips the products into `/deploy`\n\n### Releases\n\nThis repo depends on the following:\n\n* https://github.com/solana-labs/llvm\n* https://github.com/solana-labs/clang\n* https://github.com/solana-labs/clang-tools-extra\n* https://github.com/solana-labs/compiler-rt\n* https://github.com/solana-labs/lld\n\nAny changes that need to go into an LLVM release must be made in the appropriate repos listed above.\n\n* See `linux/Dockerfile` for an example of how to sync and build for Linux\n* See `macos/build.sh` for an example of how to sync and build for MacOS\n", "release_dates": ["2020-02-11T05:37:53Z", "2019-08-29T17:11:02Z", "2019-08-21T02:53:57Z", "2019-07-11T21:32:55Z", "2019-07-09T06:14:33Z", "2019-06-07T20:26:16Z", "2019-02-26T19:53:31Z", "2018-12-22T01:59:18Z", "2018-12-12T08:58:36Z", "2018-12-11T05:36:13Z", "2018-12-05T05:04:09Z", "2018-12-03T05:04:31Z", "2018-12-02T21:37:45Z", "2018-11-30T21:34:46Z", "2018-11-30T05:53:23Z"]}, {"name": "mango-simulation", "description": "(FORK) A simulator for trading on mango by market makers, used for testing solana cluster.", "language": "Rust", "license": null, "readme": "# Mango Simulation - test solana cluster by simulating mango markets\n\nThis project is use to stress a solana cluster like devnet, testnet or local solana cluster by simulating mango markets. This code requires ids.json which describe mango group for a cluster and accounts.json file which has preconfigured user accounts in mango.\n\nTo create a new configuration for mango for your cluster please check the following project:\n<https://github.com/godmodegalactus/configure_mango>\n\nThe code then will create transaction request (q) requests per seconds for (n) seconds per perp market perp user. Each transaction request will contains remove following instruction CancelAllPerpOrders and two PlacePerpOrder (one for bid and another for ask).\n\nFor the best results to avoid limits by quic it is better to fill the argument \"identity\" of a valid staked validator for the cluster you are testing with.\n\nDo not use localhost use http://127.0.0.1:8899 instead.\n\n## Build\n\nInstall configure-mango\n```sh\ngit clone https://github.com/godmodegalactus/configure_mango.git\ncd configure_mango\nyarn install\nsh scripts/configure_local.sh\n\n# open a new terminal as the previous one will continue running a solana validator\n# this command will hang for around a minute, just wait for it to finish\nNB_USERS=50 yarn ts-node index.ts\n\n```\n\nInstall mango-simulation\n```sh\ngit clone https://github.com/blockworks-foundation/mango-simulation.git\ncd mango-simulation\ncargo build\n\n# copy over files from configure_mango while you wait for the build to finish\nmkdir -p localnet\ncp ../configure_mango/ids.json localnet\ncp ../configure_mango/accounts.json localnet\ncp ../configure_mango/authority.json localnet\ncp ../configure_mango/config/validator-identity.json localnet\n```\n\n## Run\n\n\nTo run against your local validator:\n```sh\ncargo run --bin mango-simulation -- -u http://127.0.0.1:8899 --identity localnet/validator-identity.json --keeper-authority localnet/authority.json --accounts localnet/accounts.json  --mango localnet/ids.json --mango-cluster localnet --duration 10 -q 2 --transaction-save-file tlog.csv --block-data-save-file blog.csv\n```\n\nYou can also run the simulation against testnet, but you will need to run configure_mango \n\nDetails for each argument:\n```\nUSAGE:\n    mango-simulation [OPTIONS] --accounts <FILENAME> --mango <FILENAME>\n\nFLAGS:\n    -h, --help       Prints help information\n    -V, --version    Prints version information\n\nOPTIONS:\n    -a, --accounts <FILENAME>                 Read account keys from JSON file generated with mango-client-v3\n        --batch-size <UINT>                   If specified, transactions are send in batches of specified size\n    -b, --block-data-save-file <FILENAME>     To save details of all block containing mm transactions\n    -C, --config <FILEPATH>                   Configuration file to use [default:\n                                              /home/galactus/.config/solana/cli/config.yml]\n    -d, --duration <SECS>                     Seconds to run benchmark, then exit; default is forever\n    -n, --entrypoint <HOST:PORT>              Rendezvous with the cluster at this entry point; defaults to\n                                              127.0.0.1:8001\n    -i, --identity <FILEPATH>                 Identity used in the QUIC connection. Identity with a lot of stake has a\n                                              better chance to send transaction to the leader\n    -u, --url <URL_OR_MONIKER>                URL for Solana's JSON RPC or moniker (or their first letter): [mainnet-\n                                              beta, testnet, devnet, 127.0.0.1:8899]\n    -k, --keeper-authority <FILEPATH>         If specified, authority keypair would be used to pay for keeper\n                                              transactions\n    -c, --mango-cluster <STR>                 Name of mango cluster from ids.json\n    -m, --mango <FILENAME>                    Read mango keys from JSON file generated with mango-client-v3\n        --markets-per-mm <UINT>               Number of markets a market maker will trade on at a time\n        --prioritization-fees <UINT>          Takes percentage of transaction we want to add random prioritization fees\n                                              to, prioritization fees are random number between 100-1000\n    -q, --quotes-per-second <QPS>             Number of quotes per second\n    -t, --transaction-save-file <FILENAME>    To save details of all transactions during a run\n        --ws <URL>                            WebSocket URL for the solana cluster\n\n```\n", "release_dates": []}, {"name": "mango-simulation-dos", "description": "mango_bencher project", "language": "Shell", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# mango-simulation-dos\n    Purpose is to use mango-simulation to do DOS test in Testnet\n## Files\n+ main.sh : main procedure\n+ prepare-envs.sh: save envs from buildkite steps and buildkite envs to env-artifact.sh file. This enable share env between clients.\n+ create-instatnce.sh\n    - to create google cloud machines\n+ start-build-dependency.sh : script to run in remote client to build dependencies\n+ start-dos-test.sh : script to run in remore client to run mango_bencher dos test\n+ start-upload-logs.sh : script to upload logs to google cloud bucket\n+ dos-report: generates dos report from influxdb\n+ discord.sh/slack.sh: send the dos report to slack or discord\n+ print-log: print log of remote clients\n\n\n\n\n", "release_dates": []}, {"name": "metaplex", "description": "The Metaplex protocol", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<p align=\"center\">\n  <a href=\"https://metaplex.com\">\n    <img alt=\"Metaplex\" src=\"https://metaplex.com/meta.svg\" width=\"250\" />\n  </a>\n</p>\n\nMetaplex is a protocol built on top of Solana that allows:\n\n- **Creating/Minting** non-fungible tokens;\n- **Starting** a variety of auctions for primary/secondary sales;\n- and **Visualizing** NFTs in a standard way across wallets and applications.\n\nMetaplex is comprised of two core components: an on-chain program, and a self-hosted front-end web2 application.\n\n## In Depth Developer's Guide\n\nIf you want to deep dive on the Architecture, you can do so here:\n\nhttps://www.notion.so/Metaplex-Developer-Guide-afefbc19841744c28587ab948a08cfac\n\n## Installing\n\nClone the repo, and run `yarn start` to deploy.\n\n```bash\n$ git clone https://github.com/metaplex-foundation/metaplex.git\n$ cd metaplex\n$ cd js\n$ yarn install\n$ yarn bootstrap\n$ yarn start\n```\n\n## Rust Programs\n\nThe Rust programs will soon be added to this repo with JavaScript\nbindings that allow interactivity.\n\n## Community\n\nWe have a few channels for contact:\n\n- [Discord](https://discord.gg/metaplex)\n- [@metaplexNFT](https://twitter.com/metaplexNFT) on Twitter\n- [GitHub Issues](https://github.com/metaplex-foundation/metaplex/issues)\n\n# Protocol\n\n## Non-fungible tokens\n\nMetaplex's non-fungible-token standard is a part of the Solana Program Library (SPL), and can be characterized as a unique token with a fixed supply of 1 and 0 decimals. We extended the basic definition of an NFT on Solana to include additional metadata such as URI as defined in ERC-721 on Ethereum.\n\nBelow are the types of NFTs that can be created using the Metaplex protocol.\n\n### **Master Edition**\n\nA master edition token, when minted, represents both a non-fungible token on Solana and metadata that allows creators to control the provenance of prints created from the master edition.\n\nRights to create prints are tokenized itself, and the owner of the master edition can distribute tokens that allow users to create prints from master editions. Additionally, the creator can set the max supply of the master edition just like a regular mint on Solana, with the main difference being that each print is a numbered edition created from it.\n\nA notable and desirable effect of master editions is that as prints are sold, the artwork will still remain visible in the artist's wallet as a master edition, while the prints appear in the purchaser's wallets.\n\n### **Print**\n\nA **print** represents a copy of an NFT, and is created from a Master Edition. Each print has an edition number associated with it.\n\nUsually, prints are created as a part of an auction that has happened on Metaplex, but they could also be created by the creator manually.\n\nFor limited auctions, each print number is awarded based on the bid placement.\n\nPrints can be created during [Open Edition](#open-edition) or [Limited Edition](#limited-edition) auction.\n\n### Normal NFT\n\nA normal NFT (like a Master Edition) when minted represents a non-fungible token on Solana and metadata, but lacks rights to print.\n\nAn example of a normal NFT would be an artwork that is a one-of-a-kind that, once sold, is no longer within the artist's own wallet, but is in the purchaser's wallet.\n\n## Types of Auctions\n\nMetaplex currently supports four types of auctions that are all derived from English auctions.\n\nBasic parameters include:\n\n- Auction start time\n- Auction end time\n- Reservation price\n\nAdditionally, Metaplex includes a novel concept of the participation NFT. Each bidding participant can be rewarded a unique NFT for participating in the auction.\n\nThe creator of an auction also has the ability to configure a minimal price that should be charged for redemption, with the option to set it as \"free\".\n\n### Single Item\n\nThis type of auction can be used to sell normal NFTs and re-sell Prints, as well as the sale of Master Edition themselves (and the associated printing rights) if the artist so wishes. While this last behavior is not exposed in the current UI, it does exist in the protocol.\n\n### Open Edition\n\nAn open edition auction requires the offering of a Master Edition NFT that specifically has no set supply. The auction will only create Prints of this item for bidders: each bidder is guaranteed to get a print, as there are no true \"winners\" of this auction type.\n\nAn open edition auction can either have a set fixed price (equivalent to a Buy Now sale), can be set to the bid price (Pay what you want), or can be free (Make any bid to get it for free).\n\n### Limited Edition\n\nFor a limited edition auction, a Master Edition NFT (of limited or unlimited supply) may be provided to the auction with a number of copies as the set amount of winning places.\n\nFor each prize place, a Print will be minted in order of prize place, and awarded to the winning bidder of that place.\n\nFor example, the first place winner will win Print #1; the second place winner Print #2; and so on.\n\nIt is required for limited supply NFTs that there is at least as much supply remaining as there are desired winners in the auction.\n\n### Tiered Auction\n\nA tiered auction can contain a mix of the other three auction types as winning placements. For instance, the first place winner could win a Print of Limited Edition NFT A, while the second-place winner could win Normal NFT, and so on. Additionally, all participants who did not win any place could get a Participation NFT Print from a Master Edition (if the Master Edition had no supply limit).\n\n## Royalties\n\nMetaplex can seamlessly create on-chain artist splits that remove the awkwardness out of collaboration.\n\nTag each collaborator, set custom percentages, and you\u2019re off to the races. Each NFT can also be minted with configurable royalty payments that are then sent automatically back to the original creators whenever an artwork is resold on a Metaplex marketplace in the future.\n\n## Storefronts\n\nMetaplex's off-chain component allows creators to launch a custom storefront, similar to Shopify or WordPress. This open-source project provides a graphical interface to the on-chain Metaplex program, for creators, buyers, and curators of NFTs. The design and layout of storefronts can be customized to suit the needs of the entity creating it, either as a permanent storefront or an auction hub for a specific auction or collection.\n\nAll identification on the Storefront is based on wallet addresses. Creators and store admins sign through their wallets, and users place bids from connected wallets. Custom storefronts allow creators to create unique experiences per auction. Additionally, the Metaplex Foundation is working on multiple partnerships that will enable building immersive storefronts using VR/AR.\n", "release_dates": []}, {"name": "metrics-tee", "description": null, "language": null, "license": null, "readme": "# metrics-tee\n\nMetrics-tee is a simple node.js http service that accepts http requests and forwards them to multiple other endpoints. It was built to send [Solana](https://solana.com/) node metrics to multiple influxdb instances.\n\n## Prerequisites\n\nMake sure you have installed the following prerequisites on your machine:\n* [node.js](https://nodejs.org/en/) and npm\n\n```bash\nsudo apt install -y nodejs npm\n```\n* [pm2](https://pm2.io/) process manager for Node.js apps (optional)\n\n```bash\nnpm install pm2 -g\n```\n\n## Installation\n\n```bash\ngit clone https://github.com/coverlet/metrics-tee.git\ncd metrics-tee\nnpm i\n```\nRename `config.sample.json` to `config.json` and add all the endpoints that you want the metrics to be forwarded to:\n```text\n{\n    \"port\": 3311,\n    \"endpoints\": [\n        \"https://metrics.solana.com:8086/write?db=netdb&u=user&p=pass&precision=ms\",\n        \"http://yourinfluxdcinstance.com:8096/write?db=db&u=user&p=pass&precision=ms\",\n        ...\n    ]\n}\n```\n\n## Running\n\nPoint solana metrics config env variable to the metrics-tee instance:\n```bash\nEnvironment=\"SOLANA_METRICS_CONFIG=host=http://127.0.0.1:3311,db=a,u=a,p=a\"\n```\nNote that `db=a,u=a,p=a` are not used (you already configured the influxdb config for each endpoint in `config.js`), but if they are not present the node will not export the metrics.\n\n### Run with PM2\nBuild and start the app with pm2:\n```bash\nnpm run pm2\n```\nMake sure the process starts on system reboot:\n ```bash\npm2 startup\npm2 save\n```\n\n### Run with systemd\nAlternatively, you can use systemd service manager to handle app execution. In your `.service` file, use this for ExecStart:\n```bash\nExecStart=/usr/bin/node /path/to/metrics-tee/build/index.js\n```\n", "release_dates": []}, {"name": "networkexplorer", "description": "Retired", "language": "JavaScript", "license": null, "readme": "[![Build status][travis-image]][travis-url]\n[![npm][npm-image]][npm-url]\n[![npm-downloads][npm-downloads-image]][npm-url]\n[![semantic-release][semantic-release-image]][semantic-release-url]\n\n[travis-image]: https://api.travis-ci.org/solana-labs/networkexplorer.svg?branch=master\n[travis-url]: https://travis-ci.org/solana-labs/networkexplorer\n[npm-image]: https://img.shields.io/npm/v/@solana/blockexplorer.svg?style=flat\n[npm-downloads-image]: https://img.shields.io/npm/dm/@solana/blockexplorer.svg?style=flat\n[npm-url]: https://www.npmjs.com/package/@solana/blockexplorer\n[semantic-release-image]: https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg\n[semantic-release-url]: https://github.com/semantic-release/semantic-release\n\n# Solana Block Explorer\n## Prerequisites\n### Redis\n* Ubuntu: `apt-get install redis-server`\n* MacOS: `brew install redis`\n\n### NodeJS\n* Install node.js via your favorite mechanism\n* Install yarn (typically `npm install -g yarn`)\n\n## Quick Start\nEnsure Redis is running with `redis-cli ping`.  If the ping fails, start redis\nwith:\n```bash\n$ redis-server &\n```\n\nThen install the block explorer:\n```bash\n$ npm install -g @solana/blockexplorer\n```\n\nBuild and run a local Solana node:\n```bash\n$ git clone https://github.com/solana-labs/solana.git\n$ cd solana/\n$ cargo build --all\n$ ./run.sh\n```\n\nIn another terminal start the block explorer:\n```bash\n$ solana-blockexplorer\n```\n\n## Development Info\nSetup the workspace:\n```bash\n$ yarn\n```\n\nStart the API service and Web UI manually with:\n```bash\n$ yarn start:api\n$ yarn start:ui\n```\n\nThen configure and start a local Solana node.  From the main solana repository:\n```bash\n$ cargo build --all\n$ ./run.sh\n```\nand if desired for UI testing:\n```bash\n$ ./multinode-demo/client.sh --tx_count 40 --threads 2 -z 400\n```\n\n## High Performance Use Cases\n\n### Redis via Unix Domain Socket\n\nRedis is known as a very fast in-memory data structure server. To keep up with Solana\nspeeds, it may be useful to enable Unix Domain Socket communication for added performance\n(potentially 10-40% or more depending on the operations).\n\nAdd configuration similar to the following to your `/etc/redis/redis.conf` (or equivalent):\n```\nunixsocket /var/run/redis/redis-server.sock\nunixsocketperm 770\n```\n\nIncreasing max socket connections on Linux may also prove useful:\n```bash\nsudo sysctl net.core.somaxconn=16384\n```\n\nRemember to restart `redis-server` to pick up the new configuration:\n```bash\nsudo service redis-server restart\n```\n\nEnsure that your API unix user is in the same group as your `redis` user so it can read\nthe file. For example, you may need to do something like this:\n```bash\nsudo chgrp -R ubuntu /var/run/redis\n```\n\nFinally, update the redis section of `api/config.js` to enable the `path` configuration\nwhich takes precedence over the host/port options:\n```js\n  ...\n  redis: {\n    ...\n    path: '/var/run/redis/redis-server.sock',\n  },\n  ...\n```\n\nIf you would like to test Redis performance, the `redis-benchmark` tool is very handy\nfor quick sanity checks while tuning configuration.\n\nResults using localhost TCP socket:\n```bash\n$ redis-benchmark -q -n 2000000 -c 1000 -P 40\nPING_INLINE: 567215.00 requests per second\nPING_BULK: 1021450.50 requests per second\nSET: 587026.69 requests per second\nGET: 741839.75 requests per second\nINCR: 619195.06 requests per second\nLPUSH: 671366.19 requests per second\nRPUSH: 810701.25 requests per second\nLPOP: 473372.78 requests per second\nRPOP: 769230.81 requests per second\nSADD: 925925.88 requests per second\nHSET: 693721.81 requests per second\nSPOP: 914494.75 requests per second\nLPUSH (needed to benchmark LRANGE): 547495.19 requests per second\nLRANGE_100 (first 100 elements): 34660.24 requests per second\nLRANGE_300 (first 300 elements): 9543.71 requests per second\nLRANGE_500 (first 450 elements): 6180.72 requests per second\nLRANGE_600 (first 600 elements): 4716.88 requests per second\nMSET (10 keys): 123137.54 requests per second\n```\n\nResults using Unix Domain Socket:\n```bash\n$ redis-benchmark -q -n 2000000 -c 1000 -P 40 -s /var/run/redis/redis-server.sock\nPING_INLINE: 1038421.62 requests per second\nPING_BULK: 1673640.12 requests per second\nSET: 896459.00 requests per second\nGET: 1175779.00 requests per second\nINCR: 1107419.75 requests per second\nLPUSH: 814995.94 requests per second\nRPUSH: 768049.12 requests per second\nLPOP: 775494.38 requests per second\nRPOP: 884564.38 requests per second\nSADD: 1047120.44 requests per second\nHSET: 758437.62 requests per second\nSPOP: 1275510.25 requests per second\nLPUSH (needed to benchmark LRANGE): 810372.81 requests per second\nLRANGE_100 (first 100 elements): 58491.50 requests per second\nLRANGE_300 (first 300 elements): 12462.15 requests per second\nLRANGE_500 (first 450 elements): 7449.32 requests per second\nLRANGE_600 (first 600 elements): 4019.78 requests per second\nMSET (10 keys): 120279.05 requests per second\n```\n\n", "release_dates": ["2020-03-17T16:49:30Z", "2020-03-11T15:46:17Z", "2020-02-21T17:59:24Z", "2020-02-21T17:28:28Z", "2020-02-21T07:36:50Z", "2020-02-19T22:57:46Z", "2020-02-01T05:16:57Z", "2020-02-01T04:45:53Z", "2020-01-20T23:00:19Z", "2020-01-20T20:52:35Z", "2020-01-02T17:00:14Z", "2019-12-31T21:44:41Z", "2019-12-31T17:59:20Z", "2019-12-23T19:56:24Z", "2019-12-23T19:35:53Z", "2019-12-23T19:13:10Z", "2019-12-23T18:22:08Z", "2019-12-23T17:22:52Z", "2019-11-01T22:29:40Z", "2019-11-01T22:16:38Z", "2019-11-01T22:00:48Z", "2019-10-31T17:23:30Z", "2019-10-31T14:43:25Z", "2019-10-31T13:32:24Z", "2019-10-31T03:34:13Z", "2019-10-30T18:56:29Z", "2019-10-30T18:22:30Z", "2019-10-30T17:14:15Z", "2019-10-30T03:24:04Z", "2019-10-29T23:59:46Z"]}, {"name": "network_simulation", "description": null, "language": "Python", "license": null, "readme": "## Solana network simulation\n\nWIP simulation of Solana's network components, namely:\n\n- Network: controls message broadcast and slot progression\n- Node: staked validator nodes. Eligible for leader rotation and block voting\n- Block: Basic unit of message/data to broadcast (some duration of PoH)\n- BlockTransmission: <Block, Ticks> where 'ticks' represent leader transmissions of previously failed slots. Leader transmits current 'block' and a set of ticks, if any, from it's history leading up it's rotation as Leader\n\nSimulation run/controlled from `global.py`.\n\n### WIP/TODO\n- Lockout function tuning\n- Node BlockTransmission cache\n- Node save/tick/vote logic\n- Node stakes\n- Destaking/leakage\n- E&M\n", "release_dates": []}, {"name": "nohash-hasher", "description": "An implementation of `std :: hash :: Hasher` which does not hash at all.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# NoHashHasher\n\nFor an enabled type `T`, a `NoHashHasher<T>` implements `std::hash::Hasher` and\nuses the value set by one of the `write_{u8, u16, u32, u64, usize, i8, i16, i32,\ni64, isize}` methods as its hash output.\n\n`NoHashHasher` does not implement any hashing algorithm and can only be used\nwith types which can be mapped directly to a numeric value. Out of the box\n`NoHashHasher` is enabled for `u8`, `u16`, `u32`, `u64`, `usize`, `i8`, `i16`,\n`i32`, `i64`, and `isize`. Types that should be used with `NoHashHasher` need\nto implement [`IsEnabled`] and by doing so assert that their `Hash` impl invokes\n*only one* of the `Hasher::write_{u8, u16, u32, u64, usize, i8, i16, i32, i64,\nisize}` methods *exactly once*.\n\n## License\n\nLicensed under either of\n\n * Apache License, Version 2.0\n   ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license\n   ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\nat your option.\n\n## Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in the work by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n", "release_dates": []}, {"name": "ntapi", "description": "Rust FFI bindings for Native API", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# ntapi [![AppVeyor][appveyor_badge]][appveyor_link] [![Crates.io][crates_badge]][crates_link] [![Documentation][docs_badge]][docs_link] [![Lines of Code][loc_badge]][loc_link] [![Unsafe][unsafe_badge]][unsafe_link]\n\nRust FFI bindings for Native API. Mostly based on Process Hacker [phnt](https://github.com/processhacker/processhacker/tree/master/phnt) headers as the most complete source of bindings to be found. The comments there also contain useful information on how to use specific things.\n\n### Minimum supported Rust\n1.64\n\n[appveyor_link]: https://ci.appveyor.com/project/MSxDOS/ntapi\n[appveyor_badge]: https://ci.appveyor.com/api/projects/status/i1fcmm0c5b7c6b6u/branch/master?svg=true\n[crates_link]: https://crates.io/crates/ntapi\n[crates_badge]: https://img.shields.io/crates/v/ntapi.svg\n[docs_link]: https://docs.rs/ntapi/*/x86_64-pc-windows-msvc/ntapi/\n[docs_badge]: https://docs.rs/ntapi/badge.svg\n[loc_link]: https://github.com/Aaronepower/tokei\n[loc_badge]: https://tokei.rs/b1/github/MSxDOS/ntapi\n[unsafe_link]: https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html\n[unsafe_badge]: https://img.shields.io/badge/unsafe-%E2%9C%94-C901DD.svg\n", "release_dates": []}, {"name": "obsolete-dontuse-example-webwallet", "description": "Example Solana Web-based Wallet", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "[![Build status][travis-image]][travis-url]\n\n[travis-image]: https://api.travis-ci.org/solana-labs/example-webwallet.svg?branch=master\n[travis-url]: https://travis-ci.org/solana-labs/example-webwallet\n\n# Example Web Wallet\n\nThis project demonstrates how to use the [Solana Javascript API](https://github.com/solana-labs/solana-web3.js)\nto implement a simple web wallet.\n\n**IMPORTANT: This wallet does not sufficently protect the private keys it\ngenerates and should NOT be used in a non-test environment**\n\n## Getting Started\n\n```\n$ npm install\n$ npm run start\n```\n\nThen open your browser to http://localhost:8080/\n\n## Development\n\nWhen making changes, using the webpack-dev-server can be quite convenient as it\nwill rebuild and reload the app automatically\n\n```\n$ npm run dev\n```\n\n## Funding dApps\n\nIf this wallet is opened by a dApp, it will accept requests for funds. In order to\nrequest funds from your dApp, follow these steps:\n\n1. Attach a message event listener to the dApp window\n```js\nwindow.addEventListener('message', (e) => { /* ... */ });\n```\n2. Open the wallet url in a window from the dApp\n```js\nconst walletWindow = window.open(WALLET_URL, 'wallet', 'toolbar=no, location=no, status=no, menubar=no, scrollbars=yes, resizable=yes, width=500, height=600');\n```\n3. Wait for the wallet to load, it will post a `'ready'` message when it's ready to handle requests\n```js\nwindow.addEventListener('message', (e) => {\n  if (e.data) {\n    switch (e.data.method) {\n      case 'ready': {\n        // ...\n        break;\n      }\n    }\n  }\n});\n```\n4. Send an `'addFunds'` request\n```js\nwalletWindow.postMessage({\n  method: 'addFunds',\n  params: {\n    pubkey: '7q4tpevKWZFSXszPfnvWDuuE19EhSnsAmt5x4MqCyyVb',\n    amount: 150,\n    network: 'https://devnet.solana.com',\n  },\n}, WALLET_URL);\n```\n5. Listen for an `'addFundsResponse'` event which will include the amount transferred and the transaction signature\n```js\nwindow.addEventListener('message', (e) => {\n  // ...\n  switch (e.data.method) {\n    case 'ready': {\n      // ...\n      break;\n    }\n    case 'addFundsResponse': {\n      const {amount, signature} = e.data.params;\n      // ...\n      break;\n    }\n  }\n});\n```\n", "release_dates": []}, {"name": "obsolete-spl-zk-token", "description": "Obsolete - don't use", "language": "Rust", "license": null, "readme": "\n# Confidential Token Program\nThis program is a companion to the SPL Token program that enables confidential\n(**not** anonymous) transfers of SPL Tokens.\n\nAny SPL Token can take enable confidential transfers. However SPL Tokens with a\nfreeze authority can optionally enable a feature that allows a global auditor to\nalso view all confidential transfer balances, and the freeze authority extends\nto confidential token accounts.\n\nThe overview and the description of the cryptographic protocol can be found in\nthe work-in-progress documents [part1](/paper/part1.pdf) and\n[part2](paper/part2.pdf).\n\n## Development Environment\n\n### Setup\nA master branch of the Solana monorepo is required for development.\n\nThen clone this repository, then run\n```\n$ ./setup.sh\n```\n\n### Transfer Demo\n\nTo run the simple confidential transfer demo, first build the BPF program:\n```\n$ cd ./program/\n$ cargo build-bpf\n```\n\nThen start the `solana-test-validator`:\n```\n$ ./solana/validator/solana-test-validator --reset --limit-ledger-size 500000000 \\\n    --bpf-program ZkTokenXHhH6t1juaWF74WLcfv4XoNocjXA6sPWHNg1 \\\n    target/deploy/spl_zk_token.so\n```\n\nFinally in another shell, run:\n```\n$ cd ./demo/\n$ cargo run -- -ul\n```\n\n## Use cases\n\n### Enabling confidential transfers for an SPL Token mint\nBefore a confidential transfers may be used on a given SPL Token, the\n`ConfidentialTokenInstruction::ConfigureMint` instruction must be executed.\nDepending on the configuration of the SPL Token, this instruction may either be\npermissionless or require the Mint's freeze authority to sign.\n\n`ConfidentialTokenInstruction::ConfigureMint` notably creates the single omnibus\ntoken account used to store all SPL Tokens deposited into the confidential token\naccounts.\n\nNote: As there is one omnibus token account for each token mint, confidential\ntoken deposits and withdrawals for a given SPL Token will be implicitly\nserialized by the runtime during transaction execution. An alternative would be\nfor each SPL Token to have several omnibus token accounts that users could\nrandom select for deposits and withdrawals.  However this complicates\nwithdrawals in particular, as now clients need to potentially check multiple\nomnibus accounts to to find one with sufficient funds for the withdrawal. A\nrebalancing scheme between multiple omnibus accounts would likely be needed as\nwell.\n\n### Determining if confidential transfers has been enabled for an SPL Token mint\nCheck for the existence of the omnibus SPL Token account. Use\n`get_omnibus_token_address()` to derive its address for an SPL Token mint.  The\ntoken balance of the omnibus account contains the total number of tokens that\nhave been deposited into the confidential transfer system\n\nReading the contents of the `get_transfer_auditor_address()` account will\nindicate if a transfer auditor is enabled for the SPL Token mint. If so, all\nconfidential transfers for the SPL Token must include additional ciphertext to\nallow the transfer auditor to observe the transfer amount.\n\n### Enabling confidential transfers for a particular token holder\nOnce confidential transfers are enabled for a SPL Token mint, a token holder can\nopt in to confidential transfers by executing the\n`ConfidentialTokenInstruction::ConfigureAccount` instruction and providing their\nconfidential public encryption key.\n\nThe confidential token account address is a PDA derived from their normal token.\n\n### Determining if a token holder has enabled confidential transfers\nCheck for the existence of the user's confidential token account.  Use\n`get_confidential_token_address()` to derive its address from the user's SPL\nToken account.\n\n### Depositing funds into a confidential token account\nSPL Tokens can be deposited into any confidential token account using the\n`ConfidentialTokenInstruction::Deposit` instruction.\n\n### Withdrawing funds from a confidential token account\nSPL Tokens can be withdrawn from a confidential token account using the\n`ConfidentialTokenInstruction::Withdraw` instruction.\n\n### Confidential token account ownership changes\nSince the confidential token account is a companion to a normal SPL Token\naccount, ownership changes of the SPL Token account automatically convey to the\nconfidential token account.\n\nHowever the close authority of the SPL Token account *does not* convey to the\nconfidential token account.\n\nNote that it is possible to \"brick\" a confidential token account by closing the\ncorresponding SPL Token account, as no future instructions that require the\naccount authority would be permitted.  This is unlikely to occur unintentionally\nbecause the confidential token account must be created by the same wallet that\nholds the SPL Token account, and therefore is already confidential token aware.\n\n### Freezing of confidential funds\nFreezing the primary SPL Token account also causes the companion confidential token account to be frozen.\n\n### Making a confidential transfer [TODO: This section is out of date]\nMultiple transactions are required to perform a confidential transfer due to the\ncurrent max the transaction size of 1232 bytes.\n\nTo affect a transfer, the sender must issue two\n`ConfidentialTokenInstruction::SubmitTransferProof` instructions, in separate\ntransactions in parallel.  Once both transactions are confirmed they then issue\na `ConfidentialTokenInstruction::Transfer` instruction.\n**These instructions are in flux and are likely to change as the design evolves**\n\nSince the transfer process is not atomic, it's possible for multiple senders to\nrace during a transfer to the same recipient. In this case, one of the senders\nwill lose the race and will need to retry the entire transfer sequence. This\ncondition will be reported via a specific program error code.\n\nConfidential transfers are not supported in cross-program invocations.\n", "release_dates": []}, {"name": "oyster", "description": null, "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "## Setup\n\nBe sure to be running Node v12.16.2 and yarn version 1.22.10.\n\n`yarn bootstrap`\n\nThen run:\n\n`yarn start lending`\n\nYou may have to rebuild your package more than one time to secure a\nrunning environment.\n\n## Known Issues\n\n### Can't find CSS files in common\n\nCommon currently uses a less library to compile down less files into css in both the src directory for the TS server\nin vscode to pick up and in the dist folder for importers like lending and proposal projects to pick up. If you do not see these files appear when running the `npm start lending` or other commands, and you see missing CSS errors,\nyou likely did not install the packages for common correctly. Try running:\n\n`lerna exec npm install --scope @oyster/common` to specifically install packages for common.\n\nThen, test that css transpiling is working:\n\n`lerna exec npm watch-css-src --scope @oyster/common` and verify css files appear next to their less counterparts in src.\n\n## \u26a0\ufe0f Warning\n\nAny content produced by Solana, or developer resources that Solana provides, are for educational and inspiration purposes only. Solana does not encourage, induce or sanction the deployment of any such applications in violation of applicable laws or regulations.\n\n# Disclaimer\n\nAll claims, content, designs, algorithms, estimates, roadmaps,\nspecifications, and performance measurements described in this project\nare done with the Solana Foundation's (\"SF\") best efforts. It is up to\nthe reader to check and validate their accuracy and truthfulness.\nFurthermore nothing in this project constitutes a solicitation for\ninvestment.\n\nAny content produced by SF or developer resources that SF provides, are\nfor educational and inspiration purposes only. SF does not encourage,\ninduce or sanction the deployment, integration or use of any such\napplications (including the code comprising the Solana blockchain\nprotocol) in violation of applicable laws or regulations and hereby\nprohibits any such deployment, integration or use. This includes use of\nany such applications by the reader (a) in violation of export control\nor sanctions laws of the United States or any other applicable\njurisdiction, (b) if the reader is located in or ordinarily resident in\na country or territory subject to comprehensive sanctions administered\nby the U.S. Office of Foreign Assets Control (OFAC), or (c) if the\nreader is or is working on behalf of a Specially Designated National\n(SDN) or a person subject to similar blocking or denied party\nprohibitions.\n\nThe reader should be aware that U.S. export control and sanctions laws\nprohibit U.S. persons (and other persons that are subject to such laws)\nfrom transacting with persons in certain countries and territories or\nthat are on the SDN list. As a project based primarily on open-source\nsoftware, it is possible that such sanctioned persons may nevertheless\nbypass prohibitions, obtain the code comprising the Solana blockchain\nprotocol (or other project code or applications) and deploy, integrate,\nor otherwise use it. Accordingly, there is a risk to individuals that\nother persons using the Solana blockchain protocol may be sanctioned\npersons and that transactions with such persons would be a violation of\nU.S. export controls and sanctions law. This risk applies to\nindividuals, organizations, and other ecosystem participants that\ndeploy, integrate, or use the Solana blockchain protocol code directly\n(e.g., as a node operator), and individuals that transact on the Solana\nblockchain through light clients, third party interfaces, and/or wallet\nsoftware.\n", "release_dates": []}, {"name": "oyster-bridge", "description": null, "language": null, "license": null, "readme": "# Oyster Wormhole bridge\n\nRepositry is used to deploy oyster bridge. Code is available [here](https://github.com/solana-labs/oyster/tree/main/packages/bridge)\n", "release_dates": []}, {"name": "oyster-lending", "description": null, "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "## \u26a0\ufe0f Warning\n\nAny content produced by Solana, or developer resources that Solana provides, are for educational and inspiration purposes only. Solana does not encourage, induce or sanction the deployment of any such applications in violation of applicable laws or regulations.\n", "release_dates": []}, {"name": "oyster-margin", "description": null, "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "## \u26a0\ufe0f Warning\n\nAny content produced by Solana, or developer resources that Solana provides, are for educational and inspiration purposes only. Solana does not encourage, induce or sanction the deployment of any such applications in violation of applicable laws or regulations.\n", "release_dates": []}, {"name": "oyster-swap", "description": null, "language": "TypeScript", "license": null, "readme": "## \u26a0\ufe0f Warning\n\nAny content produced by Solana, or developer resources that Solana provides, are for educational and inspiration purposes only.  Solana does not encourage, induce or sanction the deployment of any such applications in violation of applicable laws or regulations.\n\n## Deployment\n\nApp is using to enviroment variables that can be set before deployment:\n* `SWAP_PROGRAM_OWNER_FEE_ADDRESS` used to distribute fees to owner of the pool program (Note: this varibale reuqires special version of token-swap program)\n* `SWAP_HOST_FEE_ADDRESS` used to distribute fees to host of the application\n\nTo inject varibles to the app, set the SWAP_PROGRAM_OWNER_FEE_ADDRESS and/or SWAP_HOST_FEE_ADDRESS environment variables to the addresses of your SOL accounts.\n\nYou may want to put these in local environment files (e.g. .env.development.local, .env.production.local). See the documentation on environment variables for more information.\n\nNOTE: remember to re-build your app before deploying for your referral addresses to be reflected.", "release_dates": []}, {"name": "perpetuals", "description": "Solana perpetuals reference implementation", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Solana Perpetuals\n\n## Introduction\n\nSolana Perpetuals protocol is an open-source implementation of a non-custodial decentralized exchange that supports leveraged trading in a variety of assets.\n\n## Quick start\n\n### Setup Environment\n\n1. Clone the repository from <https://github.com/solana-labs/perpetuals.git>.\n2. Install the latest Solana tools from <https://docs.solana.com/cli/install-solana-cli-tools>. If you already have Solana tools, run `solana-install update` to get the latest compatible version.\n3. Install the latest Rust stable from <https://rustup.rs/>. If you already have Rust, run `rustup update` to get the latest version.\n4. Install the latest Anchor framework from <https://www.anchor-lang.com/docs/installation>. If you already have Anchor, run `avm update` to get the latest version.\n\nRustfmt is used to format the code. It requires `nightly` features to be activated:\n\n5. Install `nightly` rust toolchain. <https://rust-lang.github.io/rustup/installation/index.html#installing-nightly>\n6. Execute `git config core.hooksPath .githooks` to activate pre-commit hooks.\n\n#### [Optional] Vscode setup\n\n1. Install `rust-analyzer` extension\n2. If formatting doesn't work, make sure that `rust-analyzer.rustfmt.extraArgs` is set to `+nightly`\n\n### Build\n\nFirst, generate a new key for the program address with `solana-keygen new -o <PROG_ID_JSON>`. Then replace the existing program ID with the newly generated address in `Anchor.toml` and `programs/perpetuals/src/lib.rs`.\n\nAlso, ensure the path to your wallet in `Anchor.toml` is correct. Alternatively, when running Anchor deploy or test commands, you can specify your wallet with `--provider.wallet` argument. The wallet's pubkey will be set as an upgrade authority upon initial deployment of the program. It is strongly recommended to make upgrade authority a multisig when deploying to the mainnet.\n\nTo build the program run `anchor build` command from the `perpetuals` directory:\n\n```sh\ncd perpetuals\nanchor build\n```\n\n### Test\n\nIntegration and unit tests (Rust) can be started as follows:\n\n```sh\ncargo test-bpf -- --nocapture\n```\n\nIntegration tests (Typescript) can be started as follows:\n\n```sh\nnpm install\nanchor test -- --features test\n```\n\nBy default, integration tests are executed on a local validator, so it won't cost you any SOL.\n\n### Deploy\n\nTo deploy the program to the devnet and upload the IDL use the following commands:\n\n```sh\nanchor deploy --provider.cluster devnet --program-keypair <PROG_ID_JSON>\nanchor idl init --provider.cluster devnet --filepath ./target/idl/perpetuals.json <PROGRAM ID>\n```\n\n### Initialize\n\nA small CLI Typescript client is included to help you initialize and manage the program. By default script uses devnet cluster. Add `-u https://api.mainnet-beta.solana.com` to all of the commands if you plan to execute them on mainnet.\n\nTo initialize deployed program, run the following commands:\n\n```sh\ncd app\nnpm install\nnpm install -g npx\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> init --min-signatures <int> <ADMIN_PUBKEY1> <ADMIN_PUBKEY2> ...\n```\n\nWhere `<ADMIN_WALLET>` is the file path to the wallet that was set as the upgrade authority of the program upon deployment. `<ADMIN_PUBKEY1>`, `<ADMIN_PUBKEY2>` etc., will be set as protocol admins, and `min-signatures` will be required to execute privileged instructions. To provide multiple signatures, just execute exactly the same command multiple times specifying different `<ADMIN_WALLET>` with `-k` option. The intermediate state is recorded on-chain so that commands can be executed on different computers.\n\nTo change program authority, run:\n\n```sh\nsolana program set-upgrade-authority <PROGRAM_ADDRESS> --new-upgrade-authority <NEW_UPGRADE_AUTHORITY>\n```\n\nTo change program authority back, run:\n\n```sh\nsolana program set-upgrade-authority <PROGRAM_ADDRESS> --new-upgrade-authority <NEW_UPGRADE_AUTHORITY> -k <CURRENT_AUTHORITY_KEYPAIR>\n```\n\nTo change protocol admins or minimum required signatures, run:\n\n```sh\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> set-authority --min-signatures <int> <ADMIN_PUBKEY1> <ADMIN_PUBKEY2> ...\n```\n\nTo validate initialized program:\n\n```sh\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> get-multisig\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> get-perpetuals\n```\n\nBefore the program can accept any liquidity or open a trade, you need to create a token pool and add one or more token custodies to it:\n\n```sh\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> add-pool <POOL_NAME>\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> add-custody [-s] [-v] [-t] <POOL_NAME> <TOKEN_MINT> <TOKEN_ORACLE>\n```\n\nWhere `<POOL_NAME>` is a random name you want to assign to the pool, `<TOKEN_MINT>` is the mint address of the token, and `<TOKEN_ORACLE>` is the corresponding Pyth price account that can be found on [this page](https://pyth.network/price-feeds?cluster=devnet). `-s` flag specifies whether the custody is for a stablecoin. `-v` flag is used to create a virtual/synthetic custody. More information on the latter can be found [here](SYNTHETICS.md). `-t` flag specifies the type of the oracle to be used for the custody: `custom`, `pyth` or `none`.\n\nFor example:\n\n```sh\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> add-pool TestPool1\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> add-custody TestPool1 So11111111111111111111111111111111111111112 J83w4HKfqxwcq3BEMMkPFSppX3gqekLyLJBexebFVkix\n```\n\nTo validate added pools and custodies, run:\n\n```sh\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> get-pool <POOL_NAME>\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> get-custody <POOL_NAME> <TOKEN_MINT>\n```\n\nor\n\n```sh\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> get-pools\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> get-custodies <POOL_NAME>\n```\n\nTo add liquidity, run:\n\n```sh\nnpx ts-node src/cli.ts -k <WALLET> add-liquidity <POOL_NAME> <TOKEN_MINT> --amount-in <AMOUNT_IN> --min-amount-out <MIN_AMOUNT_OUT>\n```\n\nFor it to work, make sure the wallet's LM token ATA is initialized and the wallet hold enough tokens to provide as liquidity.\n\nTo initialize wallet's token ATA, run:\n\n```sh\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> get-lp-token-mint <POOL_NAME>\n\nspl-token create-account <LM_TOKEN_MINT> --owner <WALLET> --fee-payer <PAYER_WALLET>\n```\n\nCLI offers other useful commands. You can get the list of all of them by running the following:\n\n```sh\nnpx ts-node src/cli.ts --help\n```\n\n## UI (Deprecated)\n\n### UI doesn't support the latest version of the on-chain program. The code is still available but for the reference only. Latest supported commit is 34f9bbb.\n\nWe have implemented a coressponding UI for the smartcontract, written in Typescript/Tailwind/Next. To quickly spin up a UI linked to the contract, first follow the previous directions to build the contract, and to init the exchange.\n\nIn the main directory, run `./migrations/migrate-target.sh` to copy over the target build directory to the ui.\n\nNow, you can use the following CLI commands to quickly spin-up a `TestPool1` consisting of the three following tokens.\n\nSol Token: `J83w4HKfqxwcq3BEMMkPFSppX3gqekLyLJBexebFVkix`\n\nTest Token oracle: `BLArYBCUYhdWiY8PCUTpvFE21iaJq85dvxLk9bYMobcU`\n\nUSDC oracle: `5SSkXsEKQepHHAewytPVwdej4epN1nxgLVM84L4KXgy7`\n\n```\ncd app\n\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> add-pool TestPool1\n\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> add-custody TestPool1 So11111111111111111111111111111111111111112 J83w4HKfqxwcq3BEMMkPFSppX3gqekLyLJBexebFVkix\n\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> add-custody TestPool1 6QGdQbaZEgpXqqbGwXJZXwbZ9xJnthfyYNZ92ARzTdAX BLArYBCUYhdWiY8PCUTpvFE21iaJq85dvxLk9bYMobcU\n\nnpx ts-node src/cli.ts -k <ADMIN_WALLET> add-custody TestPool1 Gh9ZwEmdLJ8DscKNTkTqPbNwLNNBjuSzaG9Vp2KGtKJr 5SSkXsEKQepHHAewytPVwdej4epN1nxgLVM84L4KXgy7 true\n```\n\nNow, use the following commands to build and run the UI, (navigate to localhost:3000 to use the UI):\n\n```\ncd ../ui\nyarn install\nyarn dev\n```\n\n## Support\n\nIf you are experiencing technical difficulties while working with the Perpetuals codebase, open an issue on [Github](https://github.com/solana-labs/perpetuals/issues). For more general questions about programming on Solana blockchain use [StackExchange](https://solana.stackexchange.com).\n\nIf you find a bug in the code, you can raise an issue on [Github](https://github.com/solana-labs/perpetuals/issues). But if this is a security issue, please don't disclose it on Github or in public channels. Send information to solana.farms@protonmail.com instead.\n\n## Contributing\n\nContributions are very welcome. Please refer to the [Contributing](https://github.com/solana-labs/solana/blob/master/CONTRIBUTING.md) guidelines for more information.\n\n## License\n\nSolana Perpetuals codebase is released under [Apache License 2.0](LICENSE).\n\n## Disclaimer\n\nBy accessing or using Solana Perpetuals or any of its components, you accept and agree with the [Disclaimer](DISCLAIMER.md).\n", "release_dates": []}, {"name": "prettier-config-solana", "description": "A Prettier config consistent to all Solana Labs projects", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Solana Prettier config\n\nLet's share this Prettier config across all of our projects, to keep things consistent.\n\n## Installation\n\n1. Install this package in the target project, along with the required peer dependencies\n   ```bash\n   pnpx install-peerdeps@2 --pnpm --dev @solana/prettier-config-solana\n   ```\n2. Add a reference to this module in your `package.json`\n   ```json\n   \"prettier\": \"@solana/prettier-config-solana\"\n   ```\n", "release_dates": []}, {"name": "qr-code-styling", "description": "Automaticly generate your styled QR code in your web app.", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# QR Code Styling\n[![Version](https://img.shields.io/npm/v/qr-code-styling.svg)](https://www.npmjs.org/package/qr-code-styling)\n\nJavaScript library for generating QR codes with a logo and styling.\n\nTry it here https://qr-code-styling.com\n\nIf you have issues / suggestions / notes / questions, please open an issue or contact me. Let's create a cool library together.\n### Examples\n<p float=\"left\">\n<img style=\"display:inline-block\" src=\"https://raw.githubusercontent.com/kozakdenys/qr-code-styling/master/src/assets/facebook_example_new.png\" width=\"240\" />\n<img style=\"display:inline-block\" src=\"https://raw.githubusercontent.com/kozakdenys/qr-code-styling/master/src/assets/qr_code_example.png\" width=\"240\" />\n<img style=\"display:inline-block\" src=\"https://raw.githubusercontent.com/kozakdenys/qr-code-styling/master/src/assets/telegram_example_new.png\" width=\"240\" />\n</p>\n\n### Installation\n\n```\nnpm install qr-code-styling\n```\n\n### Usage\n\n```HTML\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>QR Code Styling</title>\n    <script type=\"text/javascript\" src=\"https://unpkg.com/qr-code-styling@1.5.0/lib/qr-code-styling.js\"></script>\n</head>\n<body>\n<div id=\"canvas\"></div>\n<script type=\"text/javascript\">\n\n    const qrCode = new QRCodeStyling({\n        width: 300,\n        height: 300,\n        type: \"svg\",\n        data: \"https://www.facebook.com/\",\n        image: \"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\",\n        dotsOptions: {\n            color: \"#4267b2\",\n            type: \"rounded\"\n        },\n        backgroundOptions: {\n            color: \"#e9ebee\",\n        },\n        imageOptions: {\n            crossOrigin: \"anonymous\",\n            margin: 20\n        }\n    });\n\n    qrCode.append(document.getElementById(\"canvas\"));\n    qrCode.download({ name: \"qr\", extension: \"svg\" });\n</script>\n</body>\n</html>\n```\n---\n\n[**React example (Codesandbox)**](https://codesandbox.io/s/qr-code-styling-react-example-l8rwl?file=/src/App.js)\n\n[**Angular example (Codesandbox)**](https://codesandbox.io/s/agitated-panini-tpgb2?file=/src/app/app.component.ts)\n\n---\n\n[**React example (source)**](https://github.com/kozakdenys/qr-code-styling-examples/tree/master/examples/react)\n\n[**Angular example (source)**](https://github.com/kozakdenys/qr-code-styling-examples/tree/master/examples/angular)\n\n[**Vue example (source)**](https://github.com/kozakdenys/qr-code-styling-examples/tree/master/examples/vue)\n\n---\n\n### API Documentation\n\n#### QRCodeStyling instance\n`new QRCodeStyling(options) => QRCodeStyling`\n\nParam  |Type  |Description\n-------|------|------------\noptions|object|Init object\n\n`options` structure\n\nProperty               |Type                     |Default Value|Description\n-----------------------|-------------------------|-------------|-----------------------------------------------------\nwidth                  |number                   |`300`        |Size of canvas\nheight                 |number                   |`300`        |Size of canvas\ntype                   |string (`'canvas' 'svg'`)|`canvas`     |The type of the element that will be rendered\ndata                   |string                   |             |The date will be encoded to the QR code\nimage                  |string                   |             |The image will be copied to the center of the QR code\nmargin                 |number                   |`0`          |Margin around canvas\nqrOptions              |object                   |             |Options will be passed to `qrcode-generator` lib\nimageOptions           |object                   |             |Specific image options, details see below\ndotsOptions            |object                   |             |Dots styling options\ncornersSquareOptions   |object                   |             |Square in the corners styling options\ncornersDotOptionsHelper|object                   |             |Dots in the corners styling options\nbackgroundOptions      |object                   |             |QR background styling options\n\n`options.qrOptions` structure\n\nProperty            |Type                                              |Default Value\n--------------------|--------------------------------------------------|-------------\ntypeNumber          |number (`0 - 40`)                                 |`0`\nmode                |string (`'Numeric' 'Alphanumeric' 'Byte' 'Kanji'`)|\nerrorCorrectionLevel|string (`'L' 'M' 'Q' 'H'`)                        |`'Q'`\n\n`options.imageOptions` structure\n\nProperty          |Type                                   |Default Value|Description\n------------------|---------------------------------------|-------------|------------------------------------------------------------------------------\nhideBackgroundDots|boolean                                |`true`       |Hide all dots covered by the image\nimageSize         |number                                 |`0.4`        |Coefficient of the image size. Not recommended to use ove 0.5. Lower is better\nmargin            |number                                 |`0`          |Margin of the image in px\ncrossOrigin       |string(`'anonymous' 'use-credentials'`)|             |Set \"anonymous\" if you want to download QR code from other origins.\n\n`options.dotsOptions` structure\n\nProperty|Type                                                                          |Default Value|Description\n--------|------------------------------------------------------------------------------|-------------|-------------------\ncolor   |string                                                                        |`'#000'`     |Color of QR dots\ngradient|object                                                                        |             |Gradient of QR dots\ntype    |string (`'rounded' 'dots' 'classy' 'classy-rounded' 'square' 'extra-rounded'`)|`'square'`   |Style of QR dots\n\n`options.backgroundOptions` structure\n\nProperty|Type  |Default Value\n--------|------|-------------\ncolor   |string|`'#fff'`\ngradient|object|\n\n`options.cornersSquareOptions` structure\n\nProperty|Type                                     |Default Value|Description\n--------|-----------------------------------------|-------------|-----------------\ncolor   |string                                   |             |Color of Corners Square\ngradient|object                                   |             |Gradient of Corners Square\ntype    |string (`'dot' 'square' 'extra-rounded'`)|             |Style of Corners Square\n\n`options.cornersDotOptions` structure\n\nProperty|Type                     |Default Value|Description\n--------|-------------------------|-------------|-----------------\ncolor   |string                   |             |Color of Corners Dot\ngradient|object                   |             |Gradient of Corners Dot\ntype    |string (`'dot' 'square'`)|             |Style of Corners Dot\n\nGradient structure\n\n`options.dotsOptions.gradient`\n\n`options.backgroundOptions.gradient`\n\n`options.cornersSquareOptions.gradient`\n\n`options.cornersDotOptions.gradient`\n\nProperty  |Type                        |Default Value|Description\n----------|----------------------------|-------------|---------------------------------------------------------\ntype      |string (`'linear' 'radial'`)|\"linear\"     |Type of gradient spread\nrotation  |number                      |0            |Rotation of gradient in radians (Math.PI === 180 degrees)\ncolorStops|array of objects            |             |Gradient colors. Example `[{ offset: 0, color: 'blue' }, {  offset: 1, color: 'red' }]`\n\nGradient colorStops structure\n\n`options.dotsOptions.gradient.colorStops[]`\n\n`options.backgroundOptions.gradient.colorStops[]`\n\n`options.cornersSquareOptions.gradient.colorStops[]`\n\n`options.cornersDotOptions.gradient.colorStops[]`\n\nProperty|Type            |Default Value|Description\n--------|----------------|-------------|-----------------------------------\noffset  |number (`0 - 1`)|             |Position of color in gradient range\ncolor   |string          |             |Color of stop in gradient range\n\n#### QRCodeStyling methods\n`QRCodeStyling.append(container) => void`\n\nParam    |Type       |Description\n---------|-----------|-----------\ncontainer|DOM element|This container will be used for appending of the QR code\n\n`QRCodeStyling.getRawData(extension) => Promise<Blob>`\n\nParam    |Type                                |Default Value|Description\n---------|------------------------------------|-------------|------------\nextension|string (`'png' 'jpeg' 'webp' 'svg'`)|`'png'`      |Blob type\n\n`QRCodeStyling.update(options) => void`\n\nParam  |Type  |Description\n-------|------|--------------------------------------\noptions|object|The same options as for initialization\n\n`QRCodeStyling.applyExtension(extension) => void`\n\nParam    |Type                  |Description\n---------|----------------------|------------------------------------------------------------------------------------------\nextension|(svg, options) => void|Extension is a function that takes svg and previously applied options and modifies an svg\n\n`applyExtension` example\n\n```JS\nconst extension = (svg, options) => {\n    const { width, height } = options;\n    const size = Math.min(width, height);\n    const border = document.createElementNS(\"http://www.w3.org/2000/svg\", \"rect\");\n    const borderAttributes = {\n        \"fill\": \"none\",\n        \"x\": (width - size + 40) / 2,\n        \"y\": (height - size + 40) / 2,\n        \"width\": size - 40,\n        \"height\": size - 40,\n        \"stroke\": 'black',\n        \"stroke-width\": 40,\n        \"rx\": 100,\n    };\n    Object.keys(borderAttributes).forEach(attribute => {\n      border.setAttribute(attribute, borderAttributes[attribute]);\n    });\n    svg.appendChild(border);\n};\n```\n\n`QRCodeStyling.deleteExtension() => void`\n\n`QRCodeStyling.download(downloadOptions) => Promise<void>`\n\nParam          |Type  |Description\n---------------|------|------------\ndownloadOptions|object|Options with extension and name of file (not required)\n\n`downloadOptions` structure\n\nProperty |Type                                |Default Value|Description\n---------|------------------------------------|-------------|-----------------------------------------------------\nname     |string                              |`'qr'`       |Name of the downloaded file\nextension|string (`'png' 'jpeg' 'webp' 'svg'`)|`'png'`      |File extension\n\n### Building this repo\n\nIf you get an error running `npm install` referring to `node-pre-gyp`, this is caused by an attempt to compile the [`canvas` dependency](https://github.com/Automattic/node-canvas#compiling). See Compiling instructions in the README. For example on MacOS you need to install dependencies: `brew install pkg-config cairo pango libpng jpeg giflib librsvg pixman`.\n\nCurrently this repo will not build (`npm run build`) on Node v18, recommended version is v16. See https://stackoverflow.com/q/69692842/1375972 \n\n\n\n### License\n\n[MIT License](https://raw.githubusercontent.com/kozakdenys/qr-code-styling/master/LICENSE). Copyright (c) 2021 Denys Kozak\n\n", "release_dates": []}, {"name": "quinn", "description": "Async-friendly QUIC implementation in Rust", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<h1 align=\"center\"><img width=\"500\" src=\"https://raw.githubusercontent.com/quinn-rs/quinn/51a3cea225670757cb844a342428e4e1341d9f13/docs/thumbnail.svg\" /></h1>\n\n[![Documentation](https://docs.rs/quinn/badge.svg)](https://docs.rs/quinn/)\n[![Crates.io](https://img.shields.io/crates/v/quinn.svg)](https://crates.io/crates/quinn)\n[![Build status](https://github.com/quinn-rs/quinn/workflows/CI/badge.svg)](https://github.com/djc/quinn/actions?query=workflow%3ACI)\n[![codecov](https://codecov.io/gh/quinn-rs/quinn/branch/main/graph/badge.svg)](https://codecov.io/gh/quinn-rs/quinn)\n[![Chat](https://img.shields.io/badge/chat-%23quinn:matrix.org-%2346BC99?logo=matrix)](https://matrix.to/#/#quinn:matrix.org)\n[![Chat](https://badges.gitter.im/gitterHQ/gitter.svg)](https://gitter.im/djc/quinn)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE-MIT)\n[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE-APACHE)\n\nQuinn is a pure-rust, async-compatible implementation of the IETF [QUIC][quic] transport protocol.\n\n## Features\n\n- Simultaneous client/server operation\n- Ordered and unordered stream reads for improved performance\n- Works on stable Rust, tested on Linux, macOS and Windows\n- Pluggable cryptography, with a standard implementation backed by\n  [rustls][rustls] and [*ring*][ring]\n- Application-layer datagrams for small, unreliable messages\n- Future-based async API\n- Minimum supported Rust version of 1.53.0\n\n## Overview\n\n- **quinn:** High-level async API based on tokio, see for usage. This will be used by most developers. (Basic benchmarks are included.)\n- **quinn-proto:** Deterministic state machine of the protocol which performs [**no** I/O][sans-io] internally and is suitable for use with custom event loops (and potentially a C or C++ API).\n- **quinn-udp:** UDP sockets with ECN information tuned for the protocol.\n- **bench:** Benchmarks without any framework.\n- **fuzz:** Fuzz tests.\n\n# Getting Started\n\n**Examples**\n\n```sh\n$ cargo run --example server ./\n$ cargo run --example client https://localhost:4433/Cargo.toml\n```\n\nThis launches an HTTP 0.9 server on the loopback address serving the current\nworking directory, with the client fetching `./Cargo.toml`. By default, the\nserver generates a self-signed certificate and stores it to disk, where the\nclient will automatically find and trust it.\n\n**Links**\n\n- Talk at [RustFest Paris (May 2018) presentation][talk]; [slides][slides]; [YouTube][youtube]\n- Usage [examples][examples]\n- Guide [book][documentation]\n\n## Usage Notes\n\n<details>\n<summary>\nClick to show the notes\n</summary>\n\n### Buffers\n\nA Quinn endpoint corresponds to a single UDP socket, no matter how many\nconnections are in use. Handling high aggregate data rates on a single endpoint\ncan require a larger UDP buffer than is configured by default in most\nenvironments. If you observe erratic latency and/or throughput over a stable\nnetwork link, consider increasing the buffer sizes used. For example, you could\nadjust the `SO_SNDBUF` and `SO_RCVBUF` options of the UDP socket to be used\nbefore passing it in to Quinn. Note that some platforms (e.g. Linux) require\nelevated privileges or modified system configuration for a process to increase\nits UDP buffer sizes.\n\n### Certificates\n\nBy default, Quinn clients validate the cryptographic identity of servers they\nconnect to. This prevents an active, on-path attacker from intercepting\nmessages, but requires trusting some certificate authority. For many purposes,\nthis can be accomplished by using certificates from [Let's Encrypt][letsencrypt]\nfor servers, and relying on the default configuration for clients.\n\nFor some cases, including peer-to-peer, trust-on-first-use, deliberately\ninsecure applications, or any case where servers are not identified by domain\nname, this isn't practical. Arbitrary certificate validation logic can be\nimplemented by enabling the `dangerous_configuration` feature of `rustls` and\nconstructing a Quinn `ClientConfig` with an overridden certificate verifier by\nhand.\n\nWhen operating your own certificate authority doesn't make sense, [rcgen][rcgen]\ncan be used to generate self-signed certificates on demand. To support\ntrust-on-first-use, servers that automatically generate self-signed certificates\nshould write their generated certificate to persistent storage and reuse it on\nfuture runs.\n\n</details>\n<p></p>\n\n## Contribution\n\nAll feedback welcome. Feel free to file bugs, requests for documentation and\nany other feedback to the [issue tracker][issues].\n\nThe quinn-proto test suite uses simulated IO for reproducibility and to avoid\nlong sleeps in certain timing-sensitive tests. If the `SSLKEYLOGFILE`\nenvironment variable is set, the tests will emit UDP packets for inspection\nusing external protocol analyzers like Wireshark, and NSS-compatible key logs\nfor the client side of each connection will be written to the path specified in\nthe variable.\n\nThe minimum supported Rust version for published releases of our\ncrates will always be at least 6 months old at the time of release.\n\n## Authors\n\n* **Dirkjan Ochtman** - *Project owner & founder*\n* **Benjamin Saunders** - *Project owner & founder*\n* **Jean-Christophe Begue** - *Project collaborator, author of the HTTP/3 Implementation*\n\n[quic]: https://quicwg.github.io/\n[issues]: https://github.com/djc/quinn/issues\n[rustls]: https://github.com/ctz/rustls\n[ring]: https://github.com/briansmith/ring\n[talk]: https://paris.rustfest.eu/sessions/a-quic-future-in-rust\n[slides]: https://dirkjan.ochtman.nl/files/quic-future-in-rust.pdf\n[animation]: https://dirkjan.ochtman.nl/files/head-of-line-blocking.html\n[youtube]: https://www.youtube.com/watch?v=EHgyY5DNdvI\n[letsencrypt]: https://letsencrypt.org/\n[rcgen]: https://crates.io/crates/rcgen\n[examples]: https://github.com/djc/quinn/tree/main/quinn/examples\n[documentation]: https://quinn-rs.github.io/quinn/networking-introduction.html\n[sans-io]: https://sans-io.readthedocs.io/how-to-sans-io.html\n", "release_dates": []}, {"name": "rbpf", "description": "Rust virtual machine and JIT compiler for eBPF programs", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# solana_rbpf\n\n![](misc/rbpf_256.png)\n\nRust (user-space) virtual machine for eBPF\n\n[![Build Status](https://github.com/solana-labs/rbpf/actions/workflows/main.yml/badge.svg)](https://github.com/solana-labs/rbpf/actions/workflows/main.yml)\n[![Crates.io](https://img.shields.io/crates/v/solana_rbpf.svg)](https://crates.io/crates/solana_rbpf)\n\n## Description\n\nThis is a fork of [RBPF](https://github.com/qmonnet/rbpf) by Quentin Monnet.\n\nThis crate contains a virtual machine for eBPF program execution. BPF, as in\n_Berkeley Packet Filter_, is an assembly-like language initially developed for\nBSD systems, in order to filter packets in the kernel with tools such as\ntcpdump so as to avoid useless copies to user-space. It was ported to Linux,\nwhere it evolved into eBPF (_extended_ BPF), a faster version with more\nfeatures. While BPF programs are originally intended to run in the kernel, the\nvirtual machine of this crate enables running it in user-space applications;\nit contains an interpreter, an x86_64 JIT-compiler for eBPF programs, as well as\nan assembler, disassembler and verifier.\n\nThe crate is supposed to compile and run on Linux, MacOS X, and Windows,\nalthough the JIT-compiler does not work with Windows at this time.\n\n## Link to the crate\n\nThis crate is available from [crates.io](https://crates.io/crates/solana_rbpf),\nso it should work out of the box by adding it as a dependency in your\n`Cargo.toml` file:\n\n```toml\n[dependencies]\nsolana_rbpf = \"0.8.0\"\n```\n\nYou can also use the development version from this GitHub repository. This\nshould be as simple as putting this inside your `Cargo.toml`:\n\n```toml\n[dependencies]\nsolana_rbpf = { git = \"https://github.com/solana-labs/rbpf\", branch = \"main\" }\n```\n\nOf course, if you prefer, you can clone it locally, possibly hack the crate,\nand then indicate the path of your local version in `Cargo.toml`:\n\n```toml\n[dependencies]\nsolana_rbpf = { path = \"path/to/solana_rbpf\" }\n```\n\nThen indicate in your source code that you want to use the crate:\n\n```rust,ignore\nextern crate solana_rbpf;\n```\n\n## API\n\nThe API is pretty well documented inside the source code. You should also be\nable to access [an online version of the documentation from\nhere](https://docs.rs/solana_rbpf/), automatically generated from the\n[crates.io](https://crates.io/crates/solana_rbpf)\nversion (may not be up-to-date with master branch).\n[Examples](examples), [unit tests](tests) and [performance benchmarks](benches)\nshould also prove helpful.\n\nHere are the steps to follow to run an eBPF program with rbpf:\n\n1. Create the config and a loader built-in program, add some functions.\n2. Create an executable, either from the bytecode or an ELF.\n3. If you want a JIT-compiled program, compile it.\n4. Create a memory mapping, consisting of multiple memory regions.\n5. Create a context object which will also acts as instruction meter.\n6. Create a virtual machine using all of the previous steps.\n7. Execute your program: Either run the interpreter or call the JIT-compiled\n   function.\n\n## Developer\n\n### Dependencies\n- rustc version 1.72 or higher\n\n### Build and test instructions\n- To build run `cargo build`\n- To test run `cargo test`\n\n## License\n\nFollowing the effort of the Rust language project itself in order to ease\nintegration with other projects, the rbpf crate is distributed under the terms\nof both the MIT license and the Apache License (Version 2.0).\n\nSee [LICENSE-APACHE](LICENSE-APACHE) and [LICENSE-MIT](LICENSE-MIT) for details.\n", "release_dates": ["2023-10-19T13:07:44Z", "2023-09-25T13:10:03Z", "2023-09-19T16:35:09Z", "2023-09-06T17:38:33Z", "2023-09-06T17:02:39Z", "2023-06-28T18:55:34Z", "2023-06-02T12:53:36Z", "2023-05-11T14:09:51Z", "2023-04-04T11:59:56Z", "2023-03-10T10:26:31Z", "2023-02-17T23:32:29Z", "2022-12-08T12:04:08Z", "2022-11-17T17:34:28Z", "2022-11-14T23:05:24Z", "2022-10-24T22:23:54Z", "2022-10-06T11:28:46Z", "2022-09-27T17:57:38Z", "2022-08-15T07:46:47Z", "2022-06-06T17:50:25Z", "2022-06-03T11:33:17Z", "2022-05-18T16:07:59Z", "2022-04-29T14:33:35Z", "2022-04-26T13:57:08Z", "2022-04-08T21:16:19Z", "2022-03-24T00:01:41Z", "2022-03-17T19:09:47Z", "2022-03-17T19:09:18Z", "2022-03-17T19:09:05Z", "2022-01-01T18:22:36Z", "2021-12-29T15:26:05Z"]}, {"name": "reddit-scaling-demo", "description": "Demo for Reddit scaling", "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "<p align=\"center\">\n  <a href=\"https://solana.com\">\n    <img alt=\"Solana\" src=\"https://i.imgur.com/OMnvVEz.png\" width=\"250\" />\n  </a>\n</p>\n\n# Reddit Demo\n\nSource for Solana Reddit demo, which uses the solana token program to run the Reddit benchmark challenge.\nThis is a fork of the solana-program-library repo.\n\n## Build the token program\n\nThese programs cannot be built directly via cargo and instead require the build scripts located in Solana's BPF-SDK.\n\nDownload or update the BPF-SDK by running:\n```bash\n$ ./do.sh update\n```\n\nBuild the token program:\n```bash\n$ ./do.sh build <program>\n```\n\n## Running the token demo\n\nSet the RPC_URL environment variable to point to the cluster desired:\n\n```bash\nexport RPC_URL=https://testnet.solana.com\nexport RPC_URL=https://api.mainnet-beta.solana.com\n```\n\nYou'll need npm installed, then perform the following:\n\n```bash\n$ cd token/js\n$ npm install\n$ npm run bench -- --num_accounts 1 --num_transfer 1 --num_burn 1 --num_mint 1 --payer_account payer.json --id 0 --num_payers 4\n```\n\nThat should print a message like:\n> Loading payer account from payer.json\n> loaded 9Rd5aWW84WtnM2QznNHqN1FmtEyb6hUf4eewp9BFBvE1\n\nIf the network you are running on doesn't have a faucet, then fund that key with some sol, then run the program again,\nadjusting the arguments to the desired accounts/tranfers to generate:\n```bash\n$ npm run bench -- --num_accounts 10 --num_transfer 1000 --num_burn 1000 --num_mint 10 --payer_account payer.json --id 0 --num_payers 4\n```\n\nTo run more than one instance, there is another script run.sh:\n\n```bash\n./run.sh <number-of-instances>\n```\n\nThat will run a number of demo programs in parallel.\n", "release_dates": []}, {"name": "reed-solomon-erasure", "description": "Rust implementation of Reed-Solomon erasure coding", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# reed-solomon-erasure\n[![Build Status](https://travis-ci.org/darrenldl/reed-solomon-erasure.svg?branch=master)](https://travis-ci.org/darrenldl/reed-solomon-erasure)\n[![Build status](https://ci.appveyor.com/api/projects/status/47c0emjoa9bhpjlb/branch/master?svg=true)](https://ci.appveyor.com/project/darrenldl/reed-solomon-erasure/branch/master)\n[![codecov](https://codecov.io/gh/darrenldl/reed-solomon-erasure/branch/master/graph/badge.svg)](https://codecov.io/gh/darrenldl/reed-solomon-erasure)\n[![Coverage Status](https://coveralls.io/repos/github/darrenldl/reed-solomon-erasure/badge.svg?branch=master)](https://coveralls.io/github/darrenldl/reed-solomon-erasure?branch=master)\n[![Crates](https://img.shields.io/crates/v/reed-solomon-erasure.svg)](https://crates.io/crates/reed-solomon-erasure)\n[![Documentation](https://docs.rs/reed-solomon-erasure/badge.svg)](https://docs.rs/reed-solomon-erasure)\n[![dependency status](https://deps.rs/repo/github/darrenldl/reed-solomon-erasure/status.svg)](https://deps.rs/repo/github/darrenldl/reed-solomon-erasure)\n\nRust implementation of Reed-Solomon erasure coding\n\nThis is a port of [BackBlaze's Java implementation](https://github.com/Backblaze/JavaReedSolomon), [Klaus Post's Go implementation](https://github.com/klauspost/reedsolomon), and [Nicolas Trangez's Haskell implementation](https://github.com/NicolasT/reedsolomon).\n\nVersion `1.X.X` copies BackBlaze's implementation, and is less performant as there were fewer places where parallelism could be added.\n\nVersion `>= 2.0.0` copies Klaus Post's implementation. The SIMD C code is copied from Nicolas Trangez's implementation with minor modifications.\n\nSee [Notes](#notes) and [License](#license) section for details.\n\n## Usage\nAdd the following to your `Cargo.toml` for the normal version(tries to compile with SIMD operations when applicable)\n```toml\n[dependencies]\nreed-solomon-erasure = \"3.1\"\n```\nor the following for the pure rust version\n```toml\n[dependencies]\nreed-solomon-erasure = { version = \"3.1\", default-features = false }\n```\nand the following to your crate root\n```rust\nextern crate reed_solomon_erasure;\n```\n\n## Example\n```rust\n#[macro_use(shards)]\nextern crate reed_solomon_erasure;\n\nuse reed_solomon_erasure::*;\n\nfn main () {\n    let r = ReedSolomon::new(3, 2).unwrap(); // 3 data shards, 2 parity shards\n\n    let mut master_copy = shards!(\n      [0, 1,  2,  3],\n      [4, 5,  6,  7],\n      [8, 9, 10, 11],\n      [0, 0,  0,  0], // last 2 rows are parity hards\n      [0, 0,  0,  0]\n    );\n\n    // Construct the parity shards\n    r.encode(&mut master_copy).unwrap();\n\n    // Make a copy and transform it into option shards arrangement\n    // for feeding into reconstruct_shards\n    let mut shards: Vec<_> = master_copy.into_iter().map(Some).collect();\n\n    // We can remove up to 2 shards, which may be data or parity shards\n    shards[0] = None;\n    shards[4] = None;\n\n    // Try to reconstruct missing shards\n    r.reconstruct(&mut shards).unwrap();\n\n    // Convert back to normal shard arrangement\n    let result: Vec<_> = shards.into_iter().filter_map(|x| x).collect();\n\n    assert!(r.verify(&result).unwrap());\n    assert_eq!(master_copy, result);\n}\n```\n\n## Benchmark it yourself\nYou can test performance under different configurations quickly(e.g. data parity shards ratio, parallel parameters)\nby cloning this repo: https://github.com/darrenldl/rse-benchmark\n\n`rse-benchmark` contains a copy of this library(usually a fully functional dev version), so you only need to adjust `main.rs`\nthen do `cargo run --release` to start the benchmark.\n\n## Performance\nVersion `1.X.X`, `2.0.0` do not utilise SIMD.\n\nVersion `2.1.0` onward uses Nicolas's C files for SIMD operations.\n\nMachine: laptop with `Intel(R) Core(TM) i5-3337U CPU @ 1.80GHz (max 2.70GHz) 2 Cores 4 Threads`\n\nBelow shows the result of one of the test configurations, other configurations show similar results in terms of ratio.\n\n|Configuration| Klaus Post's | >= 2.1.0 | 2.0.X | 1.X.X |\n|---|---|---|---|---|\n| 10x2x1M | ~7800MB/s |~4500MB/s | ~1000MB/s | ~240MB/s |\n\n## Changelog\n[Changelog](CHANGELOG.md)\n\n## Contributions\nContributions are welcome. Note that by submitting contributions, you agree to license your work under the same license used by this project as stated in the LICENSE file.\n\n## Credits\nMany thanks to the following people for testing and benchmarking on various platforms\n\n  - [lnicola](https://github.com/lnicola/) (platforms: (Linux, Intel))\n\n  - [hexjelly](https://github.com/hexjelly) (platforms: (Windows, AMD))\n\n## Notes\n#### Code quality review\nIf you'd like to evaluate the quality of this library, you may find audit comments helpful.\n\nSimply search for \"AUDIT\" to see the dev notes that are aimed at facilitating code reviews.\n\n#### Implementation notes\nThe `1.X.X` implementation mostly copies [BackBlaze's Java implementation](https://github.com/Backblaze/JavaReedSolomon).\n\n`2.0.0` onward mostly copies [Klaus Post's Go implementation](https://github.com/klauspost/reedsolomon), and copies C files from [Nicolas Trangez's Haskell implementation](https://github.com/NicolasT/reedsolomon).\n\nThe test suite for all versions copies [Klaus Post's Go implementation](https://github.com/klauspost/reedsolomon) as basis.\n\n## License\n#### BackBlaze's Java Reed-Solomon implementation\nThe tables and main functions of ```build.rs``` are translated from [BackBlaze Java Implementation](https://github.com/Backblaze/JavaReedSolomon), and are under the same MIT License as used by the BackBlaze project\n\nThe source code copied directly from BackBlaze's project repo are under the MIT License as used by the project, the files are in `BackBlaze_JavaReedSolomon`\n\n#### Klaus Post's Go Reed-Solomon implementation\nThe tables and main functions of ```src/*``` are translated from [Klaus Post's Go Implementation](https://github.com/klauspost/reedsolomon), and are under the same MIT License as used by Klaus Post's project\n\nThe source code copied directly from Klaus Post's project repo are under the MIT License as used by the project, the files are in `KlausPost_reedsolomon`\n\n#### Nicolas Trangez's Haskell Reed-Solomon implementation\nThe C files for SIMD operations are copied (with no/minor modifications) from [Nicolas Trangez's Haskell implementation](https://github.com/NicolasT/reedsolomon), and are under the same MIT License as used by NicolasT's project\n\nThe source code copied directly from Nicolas Trangez's project repo are under the MIT License as used by the project, the files are in `NicolasT_reedsolomon`\n\n#### TL;DR\nAll files are released under the MIT License\n", "release_dates": []}, {"name": "rosetta-solana", "description": "Rosetta Server for Solana Blockchain", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<p align=\"center\">\n  <a href=\"https://www.rosetta-api.org\">\n    <img width=\"90%\" alt=\"Rosetta\" src=\"https://www.rosetta-api.org/img/rosetta_header.png\">\n  </a>\n</p>\n\n<h3 align=\"center\">\n   Rosetta Solana\n</h3>\n\n<p align=\"center\"><b>\nROSETTA-SOLANA IS CONSIDERED <a href=\"https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha\">ALPHA SOFTWARE</a>.\nUSE AT YOUR OWN RISK!\n</b></p>\n\n## Overview\n`rosetta-solana` provides a reference implementation of the Rosetta API for\nSolana in Rust. If you haven't heard of the Rosetta API, you can find more\ninformation [here](https://rosetta-api.org).\n\n## Features\n* Rosetta API implementation (both Data API and Construction API)\n* Stateless, offline, curve-based transaction construction\n* Simpler alternative Operations structure using metadata\n* Supports most system and spl instructions\n\n## Usage\nAs specified in the [Rosetta API Principles](https://www.rosetta-api.org/docs/automated_deployment.html),\nall Rosetta implementations must be deployable via Docker and support running via either an\n[`online` or `offline` mode](https://www.rosetta-api.org/docs/node_deployment.html#multiple-modes).\n\n### Docker Install\nRunning the following commands will create a Docker image called `rosetta-solana:latest`.\n\n##### From Source\nAfter cloning this repository, run:\n```text\ndocker build -t rosetta-solana .\ndocker-compose up\n```\n\n### Direct Install\nAfter cloning this repository, run:\n```text\ncargo run build --release\n```\n\n## Testing with rosetta-cli\nTo validate `rosetta-solana`, [install `rosetta-cli`](https://github.com/coinbase/rosetta-cli#install)\nand run one of the following commands:\n* `rosetta-cli check:data --configuration-file rosetta-cli-conf/devnet.json`\n* `rosetta-cli check:construction --configuration-file rosetta-cli-conf/devnet.json`\n\nNote: If cli test gives EOF error it's probably due to golang trying to reuse connection and server closing it. I have disabled keep-alive for that reason. It's recommended to run cli test in dev mode.\n\n## Development\n* `cargo run` to run server\n* `cargo run test` to run tests\n* `cargo docs` to create docs\n\n## Details\n\n### Endpoints Implemented\n\n```\n    /network/list (network_list)\n    /network/options (network_options)\n    /network/status (network_status)\n    /account/balance (account_balance)\n    /block (get_block)\n    /block/transaction (block_transaction)\n    /call (call)\n    /construction/combine (construction_combine)\n    /construction/derive (construction_derive)\n    /construction/hash (construction_hash)\n    /construction/metadata (construction_metadata)\n    /construction/parse (construction_parse)\n    /construction/payloads (construction_payloads)\n    /construction/preprocess (construction_preprocess)\n    /construction/submit (construction_submit)\n    \n```\n#### Default environment variables\n```\nRPC_URL = \"https://devnet.solana.com\"\nNETWORK_NAME = \"devnet\"\nHOST = \"127.0.0.1\"\nPORT = \"8080\"\nMODE = \"online\" //online/offline\n```\n\n#### Operations supported\nSee `types::OperationType` to see full list of current operations supported . This list might not be up to date.\n\n```\n \n    System__CreateAccount,\n    System__Assign,\n    System__Transfer,\n    System__CreateNonceAccount,\n    System__AdvanceNonce,\n    System__WithdrawFromNonce,\n    System__AuthorizeNonce,\n    System__Allocate,\n    SplToken__InitializeMint,\n    SplToken__InitializeAccount,\n    SplToken__CreateToken,\n    SplToken__CreateAccount,\n    SplToken__Transfer,\n    SplToken__Approve,\n    SplToken__Revoke,\n    SplToken__MintTo,\n    SplToken__Burn,\n    SplToken__CloseAccount,\n    SplToken__FreezeAccount,\n    SplToken__ThawAccount,\n    SplToken__TransferChecked,\n    SplToken__CreateAssocAccount,\n\n    Stake__CreateAccount,\n    Stake__Delegate,\n    Stake__Split,\n    Stake__Merge,\n    Stake__Authorize,\n    Stake__Withdraw,\n    Stake__Deactivate,\n    Stake__SetLockup,\n\n    Vote__CreateAccount,\n    Vote__Authorize,\n    Vote__Withdraw,\n    Vote__UpdateValidatorIdentity,\n    Vote__UpdateCommission,\n    Unknown,\n```\n\n#### Simpler Operations\n\nThis implementation also supports writing operations using metadata only. Instead of writing two operations for a simple transfer transaction one can simply write a single operation and fill it's metadata e.g `source`, `destination`, `authority`, `lamports`. \n\ne.g \n```\n[\n    Operation{\n        account: {address: \"Sender\"},\n        amount: { value: \"-10\",...},\n        ...\n    },\n    Operation{\n        account: {address: \"Receiver\"},\n        amount: {value: \"10\",...},\n        ...\n    }\n]\n```\n```\n[\n    Operation{\n        metadata: {\n            source: \"Sender\",\n            destination: \"Receiver\",\n            lamports: 10\n        },\n        ...\n    },\n]\n```\nBoth are same operations although the first one (Rosetta spec) always overwrites the second one.\n\n#### Nonce transfers\n\nTo send a transaction with a nonce you need to add metadata to construction_preprosess with `{\"metadata\": {\"with_nonce\": {\"account\": \"address of nonce account\"}}}`\n\n#### Balance changing Operations\n\nSee imp of `OperationType` in `src/types.rs` for list of balance changing operations. They might also require additional metadata depending on operation. Operation where only change is fees are not considered balance changing operation. Operation with only 1 balance change with no equal opposite signed opration are also not balance changing e.g mint or burn.\n\n\n### Examples \nSee tests in `src/construction.rs` to see complete working examples.\n\n## TODO\n\n* Add optional commitment option to every operation that accepts\n* All preprocess metadata fetching for every operation type\n* Suport all operation types\n* Better errors\n* Separate crates for proper docs\n\n## License\nThis project is available open source under the terms of the [Apache 2.0 License](https://opensource.org/licenses/Apache-2.0).\n", "release_dates": []}, {"name": "rpc-websockets", "description": "JSON-RPC 2.0 implementation over WebSockets for Node.js and JavaScript/TypeScript", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "<div align=\"center\">\n  <a href=\"https://github.com/elpheria/rpc-websockets\">\n    <img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/logo.png\">\n  </a>\n  <br>\n  <p>\n    WebSockets for <a href=\"http://nodejs.org\">Node.js</a> and <a href=\"https://en.wikipedia.org/wiki/JavaScript\">JavaScript</a>/<a href=\"https://en.wikipedia.org/wiki/TypeScript\">TypeScript</a> with <a href=\"https://www.jsonrpc.org/specification\">JSON RPC 2.0</a> support on top.  </p>\n  <a href=\"https://www.npmjs.com/package/rpc-websockets\">\n                <img src=\"https://img.shields.io/npm/v/rpc-websockets.svg\">\n  </a>\n  <a href=\"https://travis-ci.org/elpheria/rpc-websockets\">\n\t\t<img src=\"https://travis-ci.org/elpheria/rpc-websockets.svg?branch=master\">\n  </a>\n  <a href=\"https://coveralls.io/github/elpheria/rpc-websockets?branch=master\">\n\t\t<img src=\"https://coveralls.io/repos/github/elpheria/rpc-websockets/badge.svg?branch=master\">\n  </a>\n  <a href=\"https://www.npmjs.com/package/rpc-websockets\">\n    <img src=\"https://img.shields.io/npm/dm/rpc-websockets.svg?maxAge=2592000\">\n  </a>\n  <br><br><br>\n</div>\n\n## About\n\nThe **rpc-websockets** library enables developers to easily implement their business logic that includes messaging between users, machines or any devices. It provides a possibility to send and receive JSON data through the WebSocket communication protocol in order to support two-way notification push, running RPC methods and firing any types of event signalling. Only clients can call RPC methods and not vice versa at the moment. Both frontend (HTML/JS-based) and backend (Node.js-based) development environments are supported.\n\n**rpc-websockets** is built on Node.js and supports both LTS and Current versions.\n\nUse the free OSS edition in order to implement and manage your own WebSocket server instances, or subscribe for our [Pro plan](#pro-features) and have us manage your instances and provide you with management of your methods, events and notifications on an easy-to-use Web Management portal.\n\n## Quick start\n\nInstall our OSS library in your project:\n```\nnpm install rpc-websockets\n```\n\nWrite your source code using `rpc-websockets`:\n```js\nvar WebSocket = require('rpc-websockets').Client\nvar WebSocketServer = require('rpc-websockets').Server\n\n// instantiate Server and start listening for requests\nvar server = new WebSocketServer({\n  port: 8080,\n  host: 'localhost'\n})\n\n// register an RPC method\nserver.register('sum', function(params) {\n  return params[0] + params[1]\n})\n\n// ...and maybe a protected one also\nserver.register('account', function() {\n  return ['confi1', 'confi2']\n}).protected()\n\n// create an event\nserver.event('feedUpdated')\n\n// get events\nconsole.log(server.eventList())\n\n// emit an event to subscribers\nserver.emit('feedUpdated')\n\n// close the server\nserver.close()\n\n// instantiate Client and connect to an RPC server\nvar ws = new WebSocket('ws://localhost:8080')\n\nws.on('open', function() {\n  // call an RPC method with parameters\n  ws.call('sum', [5, 3]).then(function(result) {\n    require('assert').equal(result, 8)\n  })\n\n  // send a notification to an RPC server\n  ws.notify('openedNewsModule')\n\n  // subscribe to receive an event\n  ws.subscribe('feedUpdated')\n\n  ws.on('feedUpdated', function() {\n    updateLogic()\n  })\n\n  // unsubscribe from an event\n  ws.unsubscribe('feedUpdated')\n\n  // login your client to be able to use protected methods\n  ws.login({'username': 'confi1', 'password':'foobar'}).then(function() {\n    ws.call('account').then(function(result) {\n      require('assert').equal(result, ['confi1', 'confi2'])\n    })\n  }).catch(function(error) {\n    console.log('auth failed')\n  })\n\n  // close a websocket connection\n  ws.close()\n})\n```\n\n## Documentation\n\nPlease consult our [API documentation](API.md) for both WebSocket server and client JavaScript and TypeScript classes.\n\n## OSS Features\n\nFeatures of the free open-source edition.\n\n![OSS Features](assets/oss-features.png)\n\nAll library's open-source features are documented in our [API documentation](API.md) and can be used free of charge. You are free to implement your solutions based on provided methods in any way you are comfortable with, as long as you use our work along our very permissive [license](LICENSE) conditions.\n\n## Pro Features\n\nIn order to support your production-ready environments, we can provide you with additional features built on top of our free OSS edition along with the skill set to turn your business case or a Proof-of-Concept idea into reality.\n\n![Pro Features](assets/pro-features.png)\n\nDescribe us your use case by [contacting us](mailto:info@elpheria.com?subject=Pro%20Plan%20enquiry) and we will swiftly get back to you with a proposed solution that meets your needs.\n\n## Professional support\n\nWe offer professional support for **rpc-websockets** and beyond. We have many years of expertise on building robust, scalable Node.js applications and can help you overcome issues and challenges preventing you to ship your great products. We excel in software architecture and implementation, being able to provide you with development, planning, consulting, training and customization services. Feel free to [contact us](mailto:support@elpheria.com?subject=rpc-websockets%20support%20enquiry) so we can discuss how to help you finish your products!\n\n## Users\n\n**rpc-websockets** is being actively used in production by multiple companies in a variety of different use cases.\n\n<br>\n<a href=\"https://scratchbox.io\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-scratchbox.png\" alt=\"Scratchbox\" height=50px></a>&emsp;\n<a href=\"https://loomx.io\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-loom.png\" alt=\"Loom Network\" height=50px></a>&emsp;\n<a href=\"https://www.uniqcast.com\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-uniqcast.png\" alt=\"uniqCast\" height=50px></a>&emsp;\n<a href=\"https://leapdao.org\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-leapdao.png\" alt=\"LeapDAO\" height=50px></a>&emsp;\n<a href=\"https://klika-tech.com\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-klikatech.png\" alt=\"Klika Tech, Inc.\" height=50px></a>&emsp;\n<a href=\"https://kodebox.io\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-kodebox.png\" alt=\"Kodebox, Inc.\" height=50px></a>&emsp;\n<a href=\"https://hey.network\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-heynetwork.png\" alt=\"Hey-Group S.A./N.V.\" height=50px></a>&emsp;\n<a href=\"https://www.hylo.com\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-hylo.png\" alt=\"Hylo, Inc.\" height=50px></a>&emsp;\n<a href=\"https://witnet.foundation\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-witnet.png\" alt=\"Witnet Foundation\" height=50px></a>&emsp;\n<a href=\"https://www.scaleleap.com\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-scaleleap.png\" alt=\"Scale Leap\" height=50px></a>&emsp;\n<a href=\"https://codice.org\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-codice.png\" alt=\"Codice Foundation, Inc.\" height=50px></a>&emsp;\n<a href=\"https://holo.host\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-holo.png\" alt=\"Holo Ltd.\" height=50px></a>&emsp;\n<a href=\"https://solana.com\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/elpheria/rpc-websockets/master/assets/user-solana.png\" alt=\"Solana Labs, Inc.\" height=50px></a>&emsp;\n\n## Sponsors\nBecome a sponsor and get your logo on project's README on GitHub with a link to your site. Feel free to [contact us](mailto:info@elpheria.com?subject=Sponsors) for the arrangement!\n\n## License\n\nThis library is licensed under LGPLv3. Please see [LICENSE](LICENSE) for licensing details.\n", "release_dates": []}, {"name": "rust-bpf-builder", "description": null, "language": "Dockerfile", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Customized Rust binaries for Solana that support Berkley Packer Filter (BPF)\n\n[![Build Status](https://travis-ci.org/solana-labs/rust-bpf-builder.svg?branch=master)](https://travis-ci.org/solana-labs/rust-bpf-builder)\n\nBuilds Rust binaries that incorporate customizations and fixes required\nby Solana but not yet upstreamed into Rust or LLVM.\n\n* Builds Rust for Linux (Debian)\n* Builds Rust for MacOS natively therefore skipped if not building on a Mac\n* Results in tarballs in `/deploy` that can be released\n\n### Building\n\n```bash\n$ ./build.sh\n```\n\n* Builds Rust for Linux in Docker, tags and pushes `solanalabs/rust`\n* Copies Rust for Linux out of Docker the zips the products into `/deploy`\n* Builds Rust for MacOS natively and zips the products into `/deploy`\n\n### Releases\n\nThis repo depends on the following:\n\n* https://github.com/solana-labs/rust\n\nAny changes that need to go into a Rust release must be made in the appropriate repos listed above.\n\n* See `linux/Dockerfile` for an example of how to sync and build for Linux\n* See `macos/build.sh` for an example of how to sync and build for MacOS)\n", "release_dates": ["2021-02-11T19:24:40Z", "2020-10-26T18:30:49Z", "2020-09-20T22:11:28Z", "2020-04-28T21:09:53Z", "2020-03-03T20:55:29Z", "2020-02-11T07:31:55Z", "2019-12-11T05:43:26Z", "2019-10-16T21:18:45Z", "2019-09-26T18:32:23Z", "2019-09-20T16:45:08Z", "2019-08-29T17:10:57Z", "2019-08-21T02:55:10Z", "2019-07-11T21:48:08Z", "2019-06-21T08:30:14Z", "2019-06-05T00:52:24Z", "2019-05-16T15:40:13Z", "2019-02-28T05:27:50Z", "2019-02-25T18:19:23Z"]}, {"name": "rust-bpf-sysroot", "description": "Rust sysroot source for Berkley Packet Filter Rust programs", "language": "C", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# rust-bpf-sysroot\n\n[![Build Status](https://travis-ci.org/solana-labs/rust-bpf-sysroot.svg?branch=master)](https://travis-ci.org/solana-labs/rust-bpf-sysroot)\n\nRust sysroot source for Berkley Packet Filter Rust programs\n\nContains submodules, to sync use:\n\n``` bash\ngit clone --recurse-submodules\n```\n\n---\n\nBuilding Rust modules require a collection of standard libraries that\nprovide the fundamentals of the Rust language.  These standard\nlibraries include things like types and trait definitions, arithmetic\noperations, formatting definitions, structure definitions (slice, vec)\nand operations.  Typically Rust modules link in the `std` libraries\nwhich expose the underlying operating system features like threads,\ndisplay and file io, networking, etc.\n\nRust modules for Solana are built using the Berkley Packet Filter\n(BPF) ABI and run within a limited virtual machine that will not\nprovide most of the native OS features.  One reason is that program\nstate must be recordable in the ledger with known inputs and outputs.\nThings like files provide an untraceable input to the ledger,\nmulti-threading can lead to timing differences that may result in\nunpredictable program output based on the same inputs.\n[Rust-cross](https://github.com/japaric/rust-cross) is a good overview\nof cross-compiling Rust.\n\nThis repo contains only the pieces of the Rust libraries required by\nSolana modules, and in some cases, these pieces might include\ncustomizations required by either Solana or to be compatible with the\nBPF ABI.  It is the goal of this repo to be temporary, as support is\nadded to Solana and BPF for things like unsigned division, 128-bit\ntypes, etc. Solana should be able to refer to the libraries in the\nRust mainline eventually.\n\nThe Solana SDK pulls this repo in as source to make it available to\n[xargo](https://github.com/japaric/xargo).  Xargo then builds and uses\nit as the cargo sysroot for Solana modules.\n\nYou can build this repo independently of the Solana SDK in the same\nway that CI ensures the repo stays healthy.  The build script\ndownloads Solana's custom [rustc and\nclang](https://github.com/solana-labs/bpf-tools) binaries and updates\nthe forked submodules.  Take a look at\n[`test/build.sh`](https://github.com/dmakarov/rust-bpf-sysroot/blob/master/test/build.sh)\nfor details.\n\nTo build the test:\n``` bash\n./test/build.sh\n```\n\nNotes:\n- If building on Linux, ensure you are using Ubuntu 18 or newer since\n  Solana's custom rustc is not compatible with older versions.\n- `src/lib.rs` is only provided to enable building this repo\n  independently of the Solana SDK; it is not built as part of the\n  sysroot by Xargo.\n\nUpgrading Solana BPF toolchain\n------------------------------\n\nRust-bpf-sysroot is an essential part of Solana Rust/Clang/LLVM BPF\ntoolchain. Whenever the toolchain is upraded to a new version of\nrust/clang/llvm, rust-bpf-sysroot must be upgraded to match the\nchanges in the Rust/Clang/LLVM compilers. The following is an outline\nand checklist of the upgrade process\n\n1. Upgrade the compilers\n\n    - choose the version of\n      [rust-lang/rust](https://github.com/rust-lang/rust/tags) to upgrade\n      the toolchain to.\n    - upgrade\n      [solana-labs/llvm-project](https://github.com/solana-labs/llvm-project)\n      to the version of\n      [rust-lang/llvm-project](https://github.com/rust-lang/llvm-project)\n      that corresponds to the selected rust-lang/rust version.\n    - upgrade [solana-labs/rust](https://github.com/solana-labs/rust) to\n      the chosen version of\n      [rust-lang/rust](https://github.com/rust-lang/rust).\n    - build the compiler binaries and keep them available.\n\n2. Upgrade rust-bpf-sysroot submodules\n\n    rust-bpf-sysroot includes 4 submodules\n    - Solana forks\n      - [solana-labs/cfg-if](https://github.com/solana-labs/cfg-if) of [alexcrichton/cfg-if](https://github.com/alexcrichton/cfg-if)\n      - [solana-labs/compiler-builtins](https://github.com/solana-labs/compiler-builtins)\n        of [rust-lang/compiler-builtins](https://github.com/rust-lang/compiler-builtins)\n      - [solana-labs/hashbrown](https://github.com/solana-labs/hashbrown)\n        of [rust-lang/hashbrown](https://github.com/rust-lang/hashbrown)\n    - [rust-lang/stdarch](https://github.com/rust-lang/stdarch)\n\n    Check which version of each submodule is used by the chosen\n    version of [rust-lang/rust](https://github.com/rust-lang/rust) and\n    update Solana's forks and bump the version of\n    [rust-lang/stdarch](https://github.com/rust-lang/stdarch) in\n    [`src`](https://github.com/solana-labs/rust-bpf-sysroot/tree/master/src)\n    subdirectory. The versions required by rust-lang/rust can be\n    checked in\n    [rust-lang/rust/libraries/std/Cargo.toml](https://github.com/rust-lang/rust/blob/master/library/std/Cargo.toml).\n\n    If a Solana fork submodule is updated it is better to postpone\n    committing the updated submodule to its Solana repository until\n    the upgrade of\n    [solana-labs/rust-bpf-sysroot](https://github.com/solana-labs/rust-bpf-sysroot)\n    is finalized. In `solana-labs/rust-bpf-sysroot/src/<submodule>`\n    pull from your fork of the submodule the branch that contains the\n    version of the submodule with the Solana specific changes. When\n    the updates to rust-bpf-sysroot are finalized the changes to the\n    submodules must be committed to their corresponding solana-labs\n    repositories.\n\n3. Upgrade rust-bpf-sysroot\n\n   - pull the latest master of\n     [solana-labs/rust-bpf-sysroot](https://github.com/solana-labs/rust-bpf-sysroot)\n   - copy the subdirectories of `solana-labs/rust-bpf-sysroot/src`\n     which are not submodules from the corresponding subidrectories of\n     updated `solana-labs/rust/libraries`, overwriting the contents of\n     these subdirectories. The directories are\n     - `alloc`\n     - `core`\n     - `panic_abort`\n     - `rustc-std-workspace-alloc`\n     - `rustc-std-workspace-core`\n     - `std`\n     - `unwind`\n     - `compiler-rt` is copied from `solana-labs/llvm-project/compiler-rt`.\n   - commit the changes with the commit message \"_Pull in Rust 1.XX\n     changes_\" where _XX_ is the chosen version of rust-lang/rust. Note\n     the committed changes should be only what was copied from\n     `solana-labs/rust/libraries` and\n     `solana-labs/llvm-project/compiler-rt`. Thus we can keep the\n     local changes in separate commits, which should make subsequents\n     upgrades manageable.\n   - cherry-pick the commits starting from the commit following the\n     previous commit with the commit message \"_Pull in Rust 1.XX\n     changes_\" and reapply them on top of the just committed new _Pull\n     in Rust 1.XX changes_ commit. Note, that some commits in the\n     history will not have changes in the libraries source files. Such\n     commits must not be cherry-picked and applied. To make this\n     process manageable, commits must never mix changes to files in\n     libraries with any other changes. The description line of commits\n     that modify libraries files should have the prefix _[SOL]_ and\n     other commits should not have such prefix to clearly distinguish\n     betweeen the commits that need to be cherry-picked.\n   - after reapplying all Solana specific changes on top of the\n     updated libraries source files, start building the source tree,\n     by running the script `./test/build.sh`. Make sure to build the\n     tree using the updated compiler binaries from the step 1. An easy\n     way to use a custom compiler binaries is to create a subdirectory\n     `bpf-tools` in the directory `rust-bpf-sysroot/test/dependencies`\n     and in `bpf-tools` create two symbolic links, e.g.\n     ``` bash\n     ln -s <path to solana-labs/rust>/build/x86_64-apple-darwin/llvm llvm\n     ln -s <path to solana-labs/rust>/build/x86_64-apple-darwin/stage1 rust\n     ```\n     Fix any build errors, and compiler warnings.\n   - build and run `solana-labs/solana/programs/bpf` using the new\n     rust-bpf-sysroot and the new rust/clang compilers. To use the new\n     rust-bpf-sysroot redirect the symbolic link `rust-bpf-sysroot` in\n     `<path to solana-labs/solana>/sdk/bpf/dependencies/` to `<path to\n     solana-labs/rust-bpf-sysroot>`. When all tests build and run\n     successfully\n        - commit updated submodules to their corresponding repositories,\n        - commit changes that had to be done in libraries source files\n          with the description line prefixed with _[SOL]_ tag,\n        - make a new release branch of rust-bpf-sysroot,\n        - make a new release of\n          [solana-labs/bpf-tools](https://github.com/solana-labs/bpf-tools)\n          that contains the tarball packages with the new compiler binaries.\n   - update\n     [`solana-labs/solana/sdk/bpf/scripts/install.sh`](https://github.com/solana-labs/solana/blob/master/sdk/bpf/scripts/install.sh)\n     to install the new version of compiler binaries and\n     rust-bpf-sysroot source tree for the Solana SDK. Other files that\n     may have to be updated are\n     - `solana-labs/solana/sdk/bpf/env.sh`\n     - `solana-labs/solana/sdk/bpf/scripts/{dump.sh,objcopy.sh,strip.sh}`\n     - `solana-labs/solana/sdk/bpd/c/{bpf.ld,bpf.mk}`\n     - `solana-labs/solana/sdk/bpd/rust/bpf.ld`\n   - update this file with any corrections and changes to the upgrade\n     process.\n", "release_dates": ["2019-07-16T07:21:18Z", "2019-06-20T21:49:47Z", "2019-06-20T21:48:48Z", "2019-02-27T01:48:55Z", "2019-02-25T19:23:21Z"]}, {"name": "sealevel", "description": "A parallel runtime for layer 1 blockchains", "language": null, "license": null, "readme": "# Sealevel, A Parallel Runtime for Blockchain\n\nComing soon!\n", "release_dates": []}, {"name": "secure-wrap-token", "description": null, "language": "Rust", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Secure Wrap Token\n\n## This code is not audited. Use at your own risk.\n\n## Introduction\n\nSecure Wrap Token (SWT) is an open-source reference implementation of a custodial token wrap program.\n\nIt's an additive program that a DeFi protocol team can independently deploy on-chain to enhance the security over their user assets.\n\nUsers wrap their SPL-Tokens to receive (mint) wrapped tokens 1:1. The SWT program retains full custody of the original tokens.\nUsers can always unwrap (burn) wrapped tokens 1:1 for original tokens. This unwrapping has a time delay of e.g. 24 hours.\n\n## Motivation\n\nNumerous DeFi protocols have had bugs, allowing attackers to drain the protocols of their custodied user assets.\nThese attacks are possible because the trade execution layer and the custody layer have been tightly coupled.\n\nWith Secure Wrap Token, custody is decoupled into a separate program.\n\nUpon an exploit of a DeFi protocol using SWT, the attacker would still obtain illicit wrapped tokens.\nBut the attacker faces a time delay to unwrap their stolen tokens. During this time, the DeFi protocol team and relevant authorities can intervene to prevent permanent loss of user assets.\n\n### Actors\n\nThere are two actors: Program Authority, User.\n\nUser capabilities:\n\n- Wrap any `SPL-Token` with the program, receiving wrapped tokens in exchange. Wrapped tokens are still `SPL-Token`. Original tokens are custodied by the program. Wrapped tokens are custodied by the user and can be transfered at will.\n- Unwrap any amount at any time.  Unwraps are \"released\" after a time delay.\n- Participate in Wrap/Unwrap market to facilitate other users who want to unwrap immediately. Supports two-sided order making and taking. Orders will always be at a discount or premium to directly wrapping/unwrapping 1:1. **Importantly, the marketplace is peer-to-peer. Participants are liable for clawback if they accept stolen tokens.**\n\nProgram Authority capabilities:\n\n- Freeze any User's wrapped token account for a period of time, maximum up to 14 days.\n  The subsequent thaw is permissionless and self-executable by the user.\n  Once frozen, an account cannot be frozen again until 3 days after its thaw. The authority cannot freeze a frozen account to indefinitely extend its freeze period.\n- Permanently freeze and redistribute funds from an account as necessary.  Described in next section.\n- Temporarily halt all token unwraps and orders.  Usually done during incidents to prevent permanent loss of funds.\n\nAt a high level, the User trusts their assets to the Program Authority in exchange for remediation when things go wrong.\n\n### Permanent Freeze & Clawback Mechanism\n\nThe Program Authority retains the right to clawback the funds from any SWT account.\n\nThis clawback is only executable after the SWT account has been \"permanently frozen\" by the authority.\n\nTo permanently freeze an SWT account, the program requires that the user's original token account (same `owner` as the SWT account) has also been frozen by the original token authority -- most likely in compliance to legal court orders.\n\nOnce permanently frozen, an SWT account can never be thawed.\nThe SWT protocol allows the authority to mint new wrapped tokens exactly up to the balance of the permanently frozen account. The authority distributes these newly minted tokens to whichever addresses it wishes -- presumably to return funds to victims from an attack.\n\n## Quick start\n\n### Setup Environment\n\n1. Clone the repository from <https://github.com/solana-labs/secure-wrap-token.git>.\n2. Install the latest Solana tools from <https://docs.solana.com/cli/install-solana-cli-tools>. If you already have Solana tools, run `solana-install update` to get the latest compatible version.\n3. Install the latest Rust stable from <https://rustup.rs/>. If you already have Rust, run `rustup update` to get the latest version.\n4. Install the latest Anchor framework from <https://www.anchor-lang.com/docs/installation>. If you already have Anchor, run `avm update` to get the latest version.\nRustfmt is used to format the code. It requires `nightly` features to be activated:\n5. Install `nightly` rust toolchain. <https://rust-lang.github.io/rustup/installation/index.html#installing-nightly>\n\n#### [Optional] Vscode setup\n\n1. Install `rust-analyzer` extension\n2. If formatting doesn't work, make sure that `rust-analyzer.rustfmt.extraArgs` is set to `+nightly`\n\n### Build\n\nFirst, generate a new key for the program address with `solana-keygen new -o <PROG_ID_JSON>`. Then replace the existing program ID with the newly generated address in `Anchor.toml` and `programs/secure-wrap-token/src/lib.rs`.\nAlso, ensure the path to your wallet in `Anchor.toml` is correct. Alternatively, when running Anchor deploy or test commands, you can specify your wallet with `--provider.wallet` argument. The wallet's pubkey will be set as an upgrade authority upon initial deployment of the program. It is strongly recommended to make upgrade authority a multisig when deploying to the mainnet.\nTo build the program run `anchor build` command from the `secure-wrap-token/` directory:\n\n```sh\nanchor build\n```\n\n### Test\n\nIntegration tests (Typescript) can be run using anchor:\n\n```sh\nnpm install\nanchor test\n```\n\nBy default, integration tests are executed on a local validator, so it won't cost you any SOL.\n\n### Deploy\n\nTo deploy the program to the devnet and upload the IDL use the following commands:\n\n```sh\nanchor deploy --provider.cluster devnet --program-keypair <PROG_ID_JSON>\nanchor idl init --provider.cluster devnet --filepath ./target/idl/secure_wrap_token.json <PROGRAM ID>\n```\n\n### Initialize\n\nTODO: Add instructions and npx utility for managing SWT deployment.\n\n## Support\n\nIf you are experiencing technical difficulties while working with the Secure Wrap Token codebase, open an issue on [Github](https://github.com/solana-labs/secure-wrap-token/issues). For more general questions about programming on Solana blockchain use [StackExchange](https://solana.stackexchange.com).\nIf you find a bug in the code, you can raise an issue on [Github](https://github.com/solana-labs/secure-wrap-token/issues). But if this is a security issue, please don't disclose it on Github or in public channels. Send information to <defi@solana.com> instead.\n\n## Contributing\n\nContributions are very welcome. Please refer to the [Contributing](https://github.com/solana-labs/solana/blob/master/CONTRIBUTING.md) guidelines for more information.\n\n## License\n\nSolana Secure Wrap Token codebase is released under [Apache License 2.0](LICENSE).\n\n## Disclaimer\n\nBy accessing or using Solana Secure Wrap Token or any of its components, you accept and agree with the [Disclaimer](DISCLAIMER.md).\n", "release_dates": []}, {"name": "security-audits", "description": "Published security audits", "language": null, "license": null, "readme": "# Solana Security Audits\n\n## Solana\n\n### v1.16\n\n  - [Solana_Runtime_1c862f0b66_7cbe7d30f9_Halborn_Audit.pdf](solana/Solana_Runtime_1c862f0b66_7cbe7d30f9_Halborn_Audit.pdf)\n  - [Solana_Runtime_7cbe7d30f9_13107b4eb6_Halborn_Audit.pdf](solana/Solana_Runtime_7cbe7d30f9_13107b4eb6_Halborn_Audit.pdf)\n  - [Solana_Runtime_13107b4_77a56b0_Halborn_Audit.pdf](solana/Solana_Runtime_13107b4_77a56b0_Halborn_Audit.pdf)\n  - [Solana_Runtime_77a56b0_124aaa9_Halborn_Audit.pdf](solana/Solana_Runtime_77a56b0_124aaa9_Halborn_Audit.pdf)\n  - [Solana_Runtime_124aaa95_v1.16.8_Halborn_Audit.pdf](solana/Solana_Runtime_124aaa95_v1.16.8_Halborn_Audit.pdf)\n\n### v1.14\n\n  - [Solana_Runtime_v1.11.3_Halborn_Audit.pdf](./solana/Solana_Runtime_v1.11.3_Halborn_Audit.pdf)\n  - [Solana_Runtime_v1.14.1_Halborn_Audit.pdf](./solana/Solana_Runtime_v1.14.1_Halborn_Audit.pdf)\n  - [Solana_Runtime_v1.14.6_Halborn_Audit.pdf](./solana/Solana_Runtime_v1.14.6_Halborn_Audit.pdf)\n  - [Solana_Runtime_v1.14.10_Halborn_Audit.pdf](./solana/Solana_Runtime_v1.14.10_Halborn_Audit.pdf)\n  - [Solana_Runtime_v1.14.13_Halborn_Audit.pdf](./solana/Solana_Runtime_v1.14.13_Halborn_Audit.pdf)\n  - [Solana_Runtime_v1.14.17_Halborn_Audit.pdf](./solana/Solana_Runtime_v1.14.17_Halborn_Audit.pdf)\n  - [Solana_Runtime_Commission_Update_Halborn_Audit.pdf](./solana/Solana_Runtime_Commission_Update_Halborn_Audit.pdf)\n\n### Durable Nonce\n\n  - [Halborn Audit (2022-06-15).pdf](./solana/DurableNonce_Halborn_2022-06-15.pdf)\n  - [OtterSec Audit (2022-06-20).pdf](./solana/DurableNonce_OtterSec_2022-06-20.pdf)\n\n### Versioned Transactions & Address Lookup Table Program\n\n  - [OtterSec Audit (2022-08-23).pdf](./solana/AddressLookupTable_OtterSec_2022-08-23.pdf)\n  - [Halborn Audit (2022-08-31).pdf](./solana/AddressLookupTable_Halborn_2022-08-31.pdf)\n\n### Elf parser\n\n  - [OtterSec Audit (2022-07-22).pdf](./solana/ElfParser_OtterSec_2022-07-22.pdf)\n  - [Halborn Audit (2022-08-04).pdf](./solana/ElfParser_Halborn_2022-08-04.pdf)\n\n## Solang\n\n- [Trail of Bits Solang Parser/Sema Audit](./solang/Trail_of_Bits_Solang_Final_report.pdf)\n- [Trail of Bits Solang Codegen Audit](./solang/Solang_Code_Generation_Summary_Report.pdf)\n- [Trail of Bits Solang Emit Audit](./solang/Assurance_Report_Solana_Solang_Emit.pdf)\n- [Trail of Bits Solang Solana Library Audit](./solang/Solang_Solana_Library_Summary_Report.pdf)\n\n## Solana Program Library\n\n### Token\n\n  - [Kudelski Audit (2020-09-21).pdf](./spl/KudelskiTokenAudit-2020-09-21.pdf)\n\n### Stake Pool\n\n  - [Kudelski Audit (2021-07-07).pdf](./spl/KudelskiStakePoolAudit-2021-07-07.pdf)\n  - [Neodyme Audit (2021-10-16).pdf](./spl/NeodymeStakePoolAudit-2021-10-16.pdf)\n  - [Quantstamp Audit (2021-10-22).pdf](./spl/QuantstampStakePoolAudit-2021-10-22.pdf)\n  - [Neodyme Audit (2022-12-10).pdf](./spl/NeodymeStakePoolAudit-2022-12-10.pdf)\n  - [Neodyme Audit (2023-01-31).pdf](./spl/NeodymeStakePoolAudit-2023-01-31.pdf)\n  - [OtterSec Audit (2023-01-20).pdf](./spl/OtterSecStakePoolAudit-2023-01-20.pdf)\n  - [Halborn Audit (2023-01-25).pdf](./spl/HalbornStakePoolAudit-2023-01-25.pdf)\n  - [Neodyme Audit (2023-11-14).pdf](./spl/NeodymeStakePoolAudit-2023-11-14.pdf)\n  - [Halborn Audit (2023-12-31).pdf](./spl/HalbornStakePoolAudit-2023-12-31.pdf)\n\n### Token Swap & Shared Memory\n\n  - [Kudelski Audit (2021-02-25).pdf](./spl/KudelskiTokenSwapSharedMemAudit-2021-02-25.pdf)\n\n### Token-2022\n\n  - [Halborn Audit (2022-07-27).pdf](./spl/HalbornToken2022Audit-2022-07-27.pdf)\n  - [Zellic Audit (2022-12-05).pdf](./spl/ZellicToken2022Audit-2022-12-05.pdf)\n  - [Trail of Bits Audit (2023-02-10).pdf](./spl/TrailOfBitsToken2022Audit-2023-02-10.pdf)\n  - [NCC Group (2023-04-05).pdf](./spl/NCCToken2022Audit-2023-04-05.pdf)\n  - [OtterSec Audit (2023-11-03).pdf](./spl/OtterSecToken2022Audit-2023-11-03.pdf)\n  - [OtterSec ZK Token SDK Audit (2023-11-04).pdf](./spl/OtterSecZkTokenSdkAudit-2023-11-04.pdf)\n\n### Account Compression\n\n  - [OtterSec Audit (2022-12-03).pdf](./spl/OtterSecAccountCompressionAudit-2022-12-03.pdf)\n\n### Single Stake Pool\n\n  - [Zellic Audit (2023-06-21](./spl/ZellicSinglePoolAudit-2023-06-21.pdf)\n  - [Neodyme Audit (2023-08-08](./spl/NeodymeSinglePoolAudit-2023-08-08.pdf)\n  - [Zellic Audit (2024-01-02](./spl/ZellicSinglePoolAudit-2024-01-02.pdf)\n", "release_dates": []}, {"name": "serum-dex", "description": "Project Serum Rust monorepo.", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<div align=\"center\">\n  <img height=\"170\" src=\"http://github.com/project-serum/awesome-serum/blob/master/logo-serum.png?raw=true\" />\n\n  <h1>serum-dex</h1>\n\n  <p>\n    <strong>Project Serum Rust Monorepo</strong>\n  </p>\n\n  <p>\n    <a href=\"https://travis-ci.com/project-serum/serum-dex\"><img alt=\"Build Status\" src=\"https://travis-ci.com/project-serum/serum-dex.svg?branch=master\" /></a>\n    <a href=\"https://discord.com/channels/739225212658122886\"><img alt=\"Discord Chat\" src=\"https://img.shields.io/discord/739225212658122886?color=blueviolet\" /></a>\n    <a href=\"https://opensource.org/licenses/Apache-2.0\"><img alt=\"License\" src=\"https://img.shields.io/github/license/project-serum/serum-dex?color=blue\" /></a>\n  </p>\n\n  <h4>\n    <a href=\"https://projectserum.com/\">Website</a>\n    <span> | </span>\n    <a href=\"https://serum-academy.com/en/\">Academy</a>\n    <span> | </span>\n    <a href=\"https://github.com/project-serum/awesome-serum\">Awesome</a>\n    <span> | </span>\n    <a href=\"https://dex.projectserum.com/#/\">DEX</a>\n    <span> | </span>\n    <a href=\"https://github.com/project-serum/serum-ts\">TypeScript</a>\n  </h4>\n</div>\n\n## Program Deployments\n\n| Program | Devnet | Mainnet Beta |\n| --------|--------|------------- |\n| [DEX](/dex)     | `DESVgJVGajEgKGXhb6XmqDHGz3VjdgP7rEVESBgxmroY` | `9xQeWvG816bUx9EPjHmaT23yvVM2ZWbrrpZb9PusVFin` |\n\n## Note\n\n* **Serum is in active development so all APIs and protocols are subject to change.**\n* **The code is unaudited. Use at your own risk.**\n\n## Contributing\n\n### Install Rust\n\n```bash\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource $HOME/.cargo/env\nrustup component add rustfmt\n```\n\nOn Linux systems you may need to install additional dependencies. On Ubuntu,\n\n```bash\nsudo apt-get install -y pkg-config build-essential python3-pip jq\n```\n\n### Install Solana\n\n```bash\ncurl -sSf https://raw.githubusercontent.com/solana-labs/solana/v1.4.14/install/solana-install-init.sh | sh -s - v1.4.14\nexport PATH=\"/home/ubuntu/.local/share/solana/install/active_release/bin:$PATH\"\n```\n\n### Download the source\n\n```bash\ngit clone https://github.com/project-serum/serum-dex.git\n```\n\n### Install the BPF SDK\n\n```bash\n./do.sh update\n```\n\n### Build, deploy, and test programs\n\nSee individual crates for documentation. For example, to build the dex see its [README](https://github.com/project-serum/serum-dex/tree/master/dex).\n\n## Running a local Solana cluster\n\nThe easiest way to run a local cluster is to run the docker container provided by Solana.\nInstructions can be found [here](https://solana-labs.github.io/solana-web3.js/). For local development, however, it's often convenient to build and run a validator from [source](https://github.com/solana-labs/solana#building).\n\n## Directories\n\n* `assert-owner`: Solana utility program for checking account ownership.\n* `cli`: Serum command line interface.\n* `common`: Common rust utilities.\n* `context`: Global environment used by Serum crates, read from a configuration file.\n* `dex`: Serum DEX program and client utility.\n* `docker`: Docker image definitions.\n* `pool`: Serum pool protocol.\n* `scripts`: Bash scripts for development.\n", "release_dates": []}, {"name": "serum-dex-ui", "description": "An implementation of a UI for the Serum DEX", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Serum DEX UI\n\nAn implementation of a UI for the Serum DEX.\n\n### Running the UI\n\nRun `yarn` to install dependencies, then run `yarn start` to start a development server or `yarn build` to create a production build that can be served by a static file server.\n\n### Collect referral fees\n\nIf you are hosting a public UI using this codebase, you can collect referral fees when your users trade through your site.\n\nTo do so, set the `REACT_APP_USDT_REFERRAL_FEES_ADDRESS` and `REACT_APP_USDC_REFERRAL_FEES_ADDRESS` environment variables to the addresses of your USDT and USDC SPL token accounts.\n\nYou may want to put these in local environment files (e.g. `.env.development.local`, `.env.production.local`). See the [documentation](https://create-react-app.dev/docs/adding-custom-environment-variables) on environment variables for more information.\n\nNOTE: remember to re-build your app before deploying for your referral addresses to be reflected.\n\n### Add Trading View charts\n\nIt is possible to add OHLCV candles built from on chain data using [Bonfida's API](https://docs.bonfida.com). Here is how to do it:\n\n1. Get access to the [TradingView Charting Library](https://github.com/tradingview/charting_library/) repository. This is a **private repository** and it will **return a 404 if you don't have access to it**. To get access to the repository please refer to [TradingView's website](https://www.tradingview.com/HTML5-stock-forex-bitcoin-charting-library/)\n\n2. Once you have access to the Charting Library repository:\n\n- Copy `charting_library` folder from https://github.com/tradingview/charting_library/ to `/public` and to `/src` folders.\n- Copy `datafeeds` folder from https://github.com/tradingview/charting_library/ to `/public`.\n\n3. Import `TVChartContainer` from `/src/components/TradingView` and add it to your `TradePage.tsx`. The TradingView widget will work out of the box using [Bonfida's](https://bonfida.com) datafeed.\n\n4. Remove the following from the `tsconfig.json`\n\n```json\n\"./src/components/TradingView/index.tsx\"\n```\n\n5. Uncomment the following in `public/index.html`\n\n```\n<script src=\"%PUBLIC_URL%/datafeeds/udf/dist/polyfills.js\"></script>\n<script src=\"%PUBLIC_URL%/datafeeds/udf/dist/bundle.js\">\n```\n\n<p align=\"center\">\n<img height=\"300\" src=\"https://i.imgur.com/UyFKmTv.png\">\n</p>\n\n---\n\nSee the [Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started) for other commands and options.\n\n---\n\nSee [A technical introduction to the Serum DEX](https://projectserum.com/blog/serum-dex-introduction) to learn more about the Serum DEX.\n\nSee [serum-js](https://github.com/project-serum/serum-js) for DEX client-side code. Serum DEX UI uses this library.\n\nSee [sol-wallet-adapter](https://github.com/project-serum/sol-wallet-adapter) for an explanation of how the Serum DEX UI interacts with wallet services to sign and send requests to the Serum DEX.\n\nSee [spl-token-wallet](https://github.com/project-serum/spl-token-wallet) for an implementation of such a wallet, live at [sollet.io](https://sollet.io).\n", "release_dates": []}, {"name": "solana", "description": "Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<p align=\"center\">\n  <a href=\"https://solana.com\">\n    <img alt=\"Solana\" src=\"https://i.imgur.com/IKyzQ6T.png\" width=\"250\" />\n  </a>\n</p>\n\n[![Solana crate](https://img.shields.io/crates/v/solana-core.svg)](https://crates.io/crates/solana-core)\n[![Solana documentation](https://docs.rs/solana-core/badge.svg)](https://docs.rs/solana-core)\n[![Build status](https://badge.buildkite.com/8cc350de251d61483db98bdfc895b9ea0ac8ffa4a32ee850ed.svg?branch=master)](https://buildkite.com/solana-labs/solana/builds?branch=master)\n[![codecov](https://codecov.io/gh/solana-labs/solana/branch/master/graph/badge.svg)](https://codecov.io/gh/solana-labs/solana)\n\n# Building\n\n## **1. Install rustc, cargo and rustfmt.**\n\n```bash\n$ curl https://sh.rustup.rs -sSf | sh\n$ source $HOME/.cargo/env\n$ rustup component add rustfmt\n```\n\nWhen building the master branch, please make sure you are using the latest stable rust version by running:\n\n```bash\n$ rustup update\n```\n\nWhen building a specific release branch, you should check the rust version in `ci/rust-version.sh` and if necessary, install that version by running:\n```bash\n$ rustup install VERSION\n```\nNote that if this is not the latest rust version on your machine, cargo commands may require an [override](https://rust-lang.github.io/rustup/overrides.html) in order to use the correct version.\n\nOn Linux systems you may need to install libssl-dev, pkg-config, zlib1g-dev, protobuf etc.\n\nOn Ubuntu:\n```bash\n$ sudo apt-get update\n$ sudo apt-get install libssl-dev libudev-dev pkg-config zlib1g-dev llvm clang cmake make libprotobuf-dev protobuf-compiler\n```\n\nOn Fedora:\n```bash\n$ sudo dnf install openssl-devel systemd-devel pkg-config zlib-devel llvm clang cmake make protobuf-devel protobuf-compiler perl-core\n```\n\n## **2. Download the source code.**\n\n```bash\n$ git clone https://github.com/solana-labs/solana.git\n$ cd solana\n```\n\n## **3. Build.**\n\n```bash\n$ ./cargo build\n```\n\n# Testing\n\n**Run the test suite:**\n\n```bash\n$ ./cargo test\n```\n\n### Starting a local testnet\n\nStart your own testnet locally, instructions are in the [online docs](https://docs.solanalabs.com/clusters/benchmark).\n\n### Accessing the remote development cluster\n\n* `devnet` - stable public cluster for development accessible via\ndevnet.solana.com. Runs 24/7. Learn more about the [public clusters](https://docs.solanalabs.com/clusters)\n\n# Benchmarking\n\nFirst, install the nightly build of rustc. `cargo bench` requires the use of the\nunstable features only available in the nightly build.\n\n```bash\n$ rustup install nightly\n```\n\nRun the benchmarks:\n\n```bash\n$ cargo +nightly bench\n```\n\n# Release Process\n\nThe release process for this project is described [here](RELEASE.md).\n\n# Code coverage\n\nTo generate code coverage statistics:\n\n```bash\n$ scripts/coverage.sh\n$ open target/cov/lcov-local/index.html\n```\n\nWhy coverage? While most see coverage as a code quality metric, we see it primarily as a developer\nproductivity metric. When a developer makes a change to the codebase, presumably it's a *solution* to\nsome problem.  Our unit-test suite is how we encode the set of *problems* the codebase solves. Running\nthe test suite should indicate that your change didn't *infringe* on anyone else's solutions. Adding a\ntest *protects* your solution from future changes. Say you don't understand why a line of code exists,\ntry deleting it and running the unit-tests. The nearest test failure should tell you what problem\nwas solved by that code. If no test fails, go ahead and submit a Pull Request that asks, \"what\nproblem is solved by this code?\" On the other hand, if a test does fail and you can think of a\nbetter way to solve the same problem, a Pull Request with your solution would most certainly be\nwelcome! Likewise, if rewriting a test can better communicate what code it's protecting, please\nsend us that patch!\n\n# Disclaimer\n\nAll claims, content, designs, algorithms, estimates, roadmaps,\nspecifications, and performance measurements described in this project\nare done with the Solana Labs, Inc. (\u201cSL\u201d) good faith efforts. It is up to\nthe reader to check and validate their accuracy and truthfulness.\nFurthermore, nothing in this project constitutes a solicitation for\ninvestment.\n\nAny content produced by SL or developer resources that SL provides are\nfor educational and inspirational purposes only. SL does not encourage,\ninduce or sanction the deployment, integration or use of any such\napplications (including the code comprising the Solana blockchain\nprotocol) in violation of applicable laws or regulations and hereby\nprohibits any such deployment, integration or use. This includes the use of\nany such applications by the reader (a) in violation of export control\nor sanctions laws of the United States or any other applicable\njurisdiction, (b) if the reader is located in or ordinarily resident in\na country or territory subject to comprehensive sanctions administered\nby the U.S. Office of Foreign Assets Control (OFAC), or (c) if the\nreader is or is working on behalf of a Specially Designated National\n(SDN) or a person subject to similar blocking or denied party\nprohibitions.\n\nThe reader should be aware that U.S. export control and sanctions laws prohibit \nU.S. persons (and other persons that are subject to such laws) from transacting \nwith persons in certain countries and territories or that are on the SDN list. \nAccordingly, there is a risk to individuals that other persons using any of the \ncode contained in this repo, or a derivation thereof, may be sanctioned persons \nand that transactions with such persons would be a violation of U.S. export \ncontrols and sanctions law.\n", "release_dates": ["2024-03-03T02:52:52Z", "2024-03-03T02:53:50Z", "2024-02-24T04:11:45Z", "2024-02-24T04:10:33Z", "2024-02-13T04:20:57Z", "2024-02-13T04:25:15Z", "2024-02-13T23:33:42Z", "2024-02-06T11:36:44Z", "2024-02-06T10:43:43Z", "2024-01-31T04:05:57Z", "2024-01-26T22:44:46Z", "2024-01-26T22:43:41Z", "2024-01-20T16:35:43Z", "2024-01-12T21:17:40Z", "2024-01-10T22:46:47Z", "2024-01-07T04:25:16Z", "2024-01-07T04:25:18Z", "2024-01-02T22:37:12Z", "2023-12-21T14:05:16Z", "2024-01-03T20:16:19Z", "2023-12-17T03:19:38Z", "2023-12-15T22:31:02Z", "2023-12-15T22:32:03Z", "2023-12-13T21:01:26Z", "2023-12-10T15:11:46Z", "2023-12-09T03:06:03Z", "2023-12-10T15:09:12Z", "2023-12-09T03:07:49Z", "2023-12-03T01:36:20Z", "2023-11-30T23:38:59Z"]}, {"name": "solana-accountsdb-plugin-postgres", "description": null, "language": "Rust", "license": null, "readme": "The `solana-geyser-plugin-postgres` crate implements a plugin storing\naccount data to a PostgreSQL database to illustrate how a plugin can be\ndeveloped to work with Solana validators using the [Plugin Framework](https://docs.solana.com/developing/plugins/geyser-plugins).\n\n### Configuration File Format\n\nThe plugin is configured using the input configuration file. An example\nconfiguration file looks like the following:\n\n```\n{\n\t\"libpath\": \"/solana/target/release/libsolana_geyser_plugin_postgres.so\",\n\t\"host\": \"postgres-server\",\n\t\"user\": \"solana\",\n\t\"port\": 5433,\n\t\"threads\": 20,\n\t\"batch_size\": 20,\n\t\"panic_on_db_errors\": true,\n\t\"accounts_selector\" : {\n\t\t\"accounts\" : [\"*\"]\n\t}\n}\n```\n\nThe `host`, `user`, and `port` control the PostgreSQL configuration\ninformation. For more advanced connection options, please use the\n`connection_str` field. Please see [Rust Postgres Configuration](https://docs.rs/postgres/0.19.2/postgres/config/struct.Config.html).\n\nTo improve the throughput to the database, the plugin supports connection pooling\nusing multiple threads, each maintaining a connection to the PostgreSQL database.\nThe count of the threads is controlled by the `threads` field. A higher thread\ncount usually offers better performance.\n\nTo further improve performance when saving large numbers of accounts at\nstartup, the plugin uses bulk inserts. The batch size is controlled by the\n`batch_size` parameter. This can help reduce the round trips to the database.\n\nThe `panic_on_db_errors` can be used to panic the validator in case of database\nerrors to ensure data consistency.\n\n### Support Connection Using SSL\n\nTo connect to the PostgreSQL database via SSL, set `use_ssl` to true, and specify\nthe server certificate, the client certificate and the client key files in PEM format\nusing the `server_ca`, `client_cert` and `client_key` fields respectively.\nFor example:\n\n```\n    \"use_ssl\": true,\n    \"server_ca\": \"/solana/.ssh/server-ca.pem\",\n    \"client_cert\": \"/solana/.ssh/client-cert.pem\",\n    \"client_key\": \"/solana/.ssh/client-key.pem\",\n```\n\n### Account Selection\n\nThe `accounts_selector` can be used to filter the accounts that should be persisted.\n\nFor example, one can use the following to persist only the accounts with particular\nBase58-encoded Pubkeys,\n\n```\n    \"accounts_selector\" : {\n         \"accounts\" : [\"pubkey-1\", \"pubkey-2\", ..., \"pubkey-n\"],\n    }\n```\n\nOr use the following to select accounts with certain program owners:\n\n```\n    \"accounts_selector\" : {\n         \"owners\" : [\"pubkey-owner-1\", \"pubkey-owner-2\", ..., \"pubkey-owner-m\"],\n    }\n```\n\nTo select all accounts, use the wildcard character (*):\n\n```\n    \"accounts_selector\" : {\n         \"accounts\" : [\"*\"],\n    }\n```\n\n### Transaction Selection\n\n`transaction_selector`, controls if and what transactions to store.\nIf this field is missing, none of the transactions are stored.\n\nFor example, one can use the following to select only the transactions\nreferencing accounts with particular Base58-encoded Pubkeys,\n\n```\n\"transaction_selector\" : {\n    \"mentions\" : \\[\"pubkey-1\", \"pubkey-2\", ..., \"pubkey-n\"\\],\n}\n```\n\nThe `mentions` field supports wildcards to select all transaction or\nall 'vote' transactions. For example, to select all transactions:\n\n```\n\"transaction_selector\" : {\n    \"mentions\" : \\[\"*\"\\],\n}\n```\n\nTo select all vote transactions:\n\n```\n\"transaction_selector\" : {\n    \"mentions\" : \\[\"all_votes\"\\],\n}\n```\n\n### Database Setup\n\n#### Install PostgreSQL Server\n\nPlease follow [PostgreSQL Ubuntu Installation](https://www.postgresql.org/download/linux/ubuntu/)\non instructions to install the PostgreSQL database server. For example, to\ninstall postgresql-14,\n\n```\nsudo sh -c 'echo \"deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main\" > /etc/apt/sources.list.d/pgdg.list'\nwget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\nsudo apt-get update\nsudo apt-get -y install postgresql-14\n```\n#### Control the Database Access\n\nModify the pg_hba.conf as necessary to grant the plugin to access the database.\nFor example, in /etc/postgresql/14/main/pg_hba.conf, the following entry allows\nnodes with IPs in the CIDR 10.138.0.0/24 to access all databases. The validator\nruns in a node with an ip in the specified range.\n\n```\nhost    all             all             10.138.0.0/24           trust\n```\n\nIt is recommended to run the database server on a separate node from the validator for\nbetter performance.\n\n#### Configure the Database Performance Parameters\n\nPlease refer to the [PostgreSQL Server Configuration](https://www.postgresql.org/docs/14/runtime-config.html)\nfor configuration details. The referential implementation uses the following\nconfigurations for better database performance in the /etc/postgresql/14/main/postgresql.conf\nwhich are different from the default postgresql-14 installation.\n\n```\nmax_connections = 200                  # (change requires restart)\nshared_buffers = 1GB                   # min 128kB\neffective_io_concurrency = 1000        # 1-1000; 0 disables prefetching\nwal_level = minimal                    # minimal, replica, or logical\nfsync = off                            # flush data to disk for crash safety\nsynchronous_commit = off               # synchronization level;\nfull_page_writes = off                 # recover from partial page writes\nmax_wal_senders = 0                    # max number of walsender processes\n```\n\nThe sample scripts/postgresql.conf can be used for reference.\n\n#### Create the Database Instance and the Role\n\nStart the server:\n\n```\nsudo systemctl start postgresql@14-main\n```\n\nCreate the database. For example, the following creates a database named 'solana':\n\n```\nsudo -u postgres createdb solana -p 5433\n```\n\nCreate the database user. For example, the following creates a regular user named 'solana':\n\n```\nsudo -u postgres createuser -p 5433 solana\n```\n\nVerify the database is working using psql. For example, assuming the node running\nPostgreSQL has the ip 10.138.0.9, the following command will land in a shell where\nSQL commands can be entered:\n\n```\npsql -U solana -p 5433 -h 10.138.0.9 -w -d solana\n```\n\n#### Create the Schema Objects\n\nUse the scripts/create_schema.sql\n\n```\npsql -U solana -p 5433 -h 10.138.0.9 -w -d solana -f scripts/create_schema.sql\n```\n\nAfter this, start the validator with the plugin by using the `--geyser-plugin-config`\nargument mentioned above.\n\n#### Destroy the Schema Objects\n\nTo destroy the database objects, created by `create_schema.sql`, use\ndrop_schema.sql. For example,\n\n```\npsql -U solana -p 5433 -h 10.138.0.9 -w -d solana -f scripts/drop_schema.sql\n```\n\n### Capture Historical Account Data\n\nTo capture account historical data, in the configuration file, turn\n`store_account_historical_data` to true.\n\nAnd ensure the database trigger is created to save data in the `audit_table` when\nrecords in `account` are updated, as shown in `create_schema.sql`,\n\n```\nCREATE FUNCTION audit_account_update() RETURNS trigger AS $audit_account_update$\n    BEGIN\n\t\tINSERT INTO account_audit (pubkey, owner, lamports, slot, executable, rent_epoch, data, write_version, updated_on)\n            VALUES (OLD.pubkey, OLD.owner, OLD.lamports, OLD.slot,\n                    OLD.executable, OLD.rent_epoch, OLD.data, OLD.write_version, OLD.updated_on);\n        RETURN NEW;\n    END;\n\n$audit_account_update$ LANGUAGE plpgsql;\n\nCREATE TRIGGER account_update_trigger AFTER UPDATE OR DELETE ON account\n    FOR EACH ROW EXECUTE PROCEDURE audit_account_update();\n```\n\nThe trigger can be dropped to disable this feature, for example,\n\n```\nDROP TRIGGER account_update_trigger ON account;\n```\n\nOver time, the account_audit can accumulate large amount of data. You may choose to\nlimit that by deleting older historical data.\n\nFor example, the following SQL statement can be used to keep up to 1000 of the most\nrecent records for an account:\n\n```\ndelete from account_audit a2 where (pubkey, write_version) in\n    (select pubkey, write_version from\n        (select a.pubkey, a.updated_on, a.slot, a.write_version, a.lamports,\n            rank() OVER ( partition by pubkey order by write_version desc) as rnk\n            from account_audit a) ranked\n            where ranked.rnk > 1000)\n```\n\n### Main Tables\n\nThe following are the tables in the Postgres database\n\n| Table         | Description             |\n|:--------------|:------------------------|\n| account       | Account data            |\n| block         | Block metadata          |\n| slot          | Slot metadata           |\n| transaction   | Transaction data        |\n| account_audit | Account historical data |\n\n\n### Performance Considerations\n\nWhen a validator lacks sufficient computing power, the overhead of saving the\naccount data can cause it to fall behind the network especially when all\naccounts or a large number of accounts are selected. The node hosting the\nPostgreSQL database needs to be powerful enough to handle the database loads\nas well. It has been found using GCP n2-standard-64 machine type for the\nvalidator and n2-highmem-32 for the PostgreSQL node is adequate for handling\ntransmitting all accounts while keeping up with the network. In addition, it is\nbest to keep the validator and the PostgreSQL in the same local network to\nreduce latency. You may need to size the validator and database nodes\ndifferently if serving other loads.\n", "release_dates": []}, {"name": "solana-bigtable", "description": null, "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Setting up a Solana Bigtable Instance\n\n 1. [Introduction](#solana-bigtable)\n 2. [Requirements](#requirements)\n 2. [Setting up a Warehouse node](#setting-up-a-warehouse-node)\n 2. [Setting up a Google Cloud Bigtable instance](#setting-up-a-google-cloud-bigtable-instance)\n 2. [Import Solana's Bigtable Instance](#import-solana's-bigtable-instance)\n 2. [Requirements](#requirements)\n 2. [Restoring Missing Blocks](#restoring-missing-blocks)\n\n## Solana Bigtable\n\nBy design an RPC node with a default `--limit-ledger-size` will store roughly 2 epochs worth of data so Solana relies on Google Cloud's Bigtable for long term storage.\nThe public endpoint that Solana provides https://api.mainnet-beta.solana.com has configured its own Bigtable instance to server requests since the Genesis Block.\nThis guide is meant to allow anyone to run his own Bigtable instance for long term storage in the Solana Blockchain.\n\n## Requirements\n\n1. A Warehouse node\n2. A Google Cloud Bigtable instance\n3. A Google Cloud Storage bucket (optional)\n\n## Setting up a Warehouse node\n\nA Warehouse node is responsible for feeding Bigtable with ledger data, so setting up one is the first thing that needs to be done in order for you to have your own Solana Bigtable instance.\nStructurally a Warehouse node is similar to an RPC node that doesn't server RPC calls, but instead uploads ledger data to Bigtable.\nKeeping your ledger history consistent is very important on a Warehouse node, since any gap on your local ledger will translate to a gap on your Bigtable instance, although these gaps could be potentially patched up by using `solana-ledger-tool`.\nHere you'll find all the necessary scripts to run your own Warehouse node.\n\nWhat different scripts do:\n1. `warehouse.sh` \u2192 Startup script for the Warehouse node:\n2. `warehouse-upload-to-storage-bucket.sh` \u2192 Script to upload the hourly snapshots to Google Cloud Storage every epoch.\n3. `service-env.sh` \u2192 Source file for `warehouse.sh`.\n4. `service-env-warehouse.sh` \u2192 Source file for `warehouse-upload-to-storage-bucket.sh`.\n5. `warehouse-basic.sh` \u2192 Simplified command to start the warehouse node. Run this *instead* of `warehouse.sh`.\n\n**IMPORTANT NOTE:** If all you want is write to bigtable, you only need to use the `warehouse-basic.sh` script as a template. All of the scripts above are meant not only to write to bigtable but also create hourly snapshots and ledger backups every epoch and upload them to Google's Cloud Storage.\n\nBefore you begin:\n1. [Install solana-cli](https://docs.solana.com/cli/install-solana-cli-tools)\n2. [Install gcloud sdk](https://cloud.google.com/sdk/docs/install)\n3. [Create a gcloud service account](https://cloud.google.com/iam/docs/creating-managing-service-account-keys).\n    * When creating the account give it the `Bigtable User` role.\n    * You will get back a file with a name similar to `play-gcp-329606-cccf2690b876.json`. Point `GOOGLE_APPLICATION_CREDENTIALS` variable to the file's path.\n    * Needless to say, keep the file private and don't commit to github.\n4. [Tune your system](https://docs.solana.com/running-validator/validator-start#system-tuning)\n\nTo start the validator:\n1. Fill in the missing variables (eg `<path_to_your_ledger>`) inside the below files. Hint: CTRL-F for \"`<`\" to find all quickly.\n    * `warehouse.sh`\n    * `service-env.sh`\n    * `service-env-warehouse.sh`\n2. If it's the first time you're running a validator, you can leave `ledger_dir` and `ledger_snapshots_dir` blank. This will tell the node to fetch genesis & the latest snapshot from the cluster.\n2. `chmod +x` the following files:\n    * `warehouse.sh`\n    * `metrics-write-dashboard.sh`\n4. Update the `EXPECTED_SHRED_VERSION` in `service-env.sh` to the appropriate version.\n5. `./warehouse.sh`\n\nTo upload to bigtable:\n1. Fill in the missing variables inside `<...>` in `warehouse-upload-to-storage-bucket.sh`.\n2. `chmod +x warehouse-upload-to-storage-bucket.sh`\n3. `./warehouse-upload-to-storage-bucket.sh`\n\nTo run as a continuous process as `systemctl`:\n1. Update the user in both `.service` files (currently set to `sol`).\n2. Fill in the missing variables inside `<...>` in both `.service` files.\n3. `cp` both files into `/etc/systemd/system`\n4. `sudo systemctl enable --now warehouse-upload-to-storage-bucket && sudo systemctl enable --now warehouse`\n\n## Setting up a Google Cloud Bigtable instance\n\nIn order to import Solana's Bigtable Instance, you'll first need to set own Bigtable instance:\n\n1. Enable the `BigTable API` if you have not done it already, then click on the `Create Instance` inside the `Console`.\n2. Name your `Instance` and then Select Storage type from HDD and SSD. Set the instance id and name to `solana-ledger`.\n3. Select a location \u2192 Region \u2192 Zone.\n4. Choose the number of `Nodes` for the cluster, each node provides 16TB of storage for HDD nodes (as of 09/12/21 at least 4 HDD nodes are required).\n5. Create the following tables with the respective column family names:\n\n| Table ID   | Column Family Name |\n| :--------- | :----------------: |\n| blocks     | x                  |\n| entries    | x                  |\n| tx         | x                  |\n| tx-by-addr | x                  |\n\n**NOTE:** the `entries` table is new and will be populated as of solana CLI tools v1.18.0\n\n6. It's very important to give the same `Table ID` and `Column Family Name` inside your Bigtable instance or the Dataflow job will fail.\n\nAlternatively, you create the tables by running the following commands through CLI:\n\n1. Update the `.cbtrc` file with credentials of the project and Bigtable instance in which we want to do the read and write operations:\n    * `echo project = [PROJECT ID] > ~/.cbtrc`\n    * `echo instance = [BIGTABLE INSTANCE ID] >> ~/.cbtrc`\n    * `cat ~/.cbtr`\n2. Create the tables inside the Bigtable instance with the family name defined inside it:\n    * `cbt createtable [TABLE NAME] \u201cfamilies=[COLUMN FAMILY1]`\n3. When creating the table inside the instance remember the transfer through Dataflow always occurs within tables having the same column family name otherwise it will throw an error like \u201cRequested column family not found = 1\u201d.\n\n## Import Solana's Bigtable Instance\n\nOnce your Warehouse node has stored ledger data for 1 epoch successfully and you have set up your Bigtable instance as explained above, you are ready to import Solana's Bigtable to yours.\nThe import process is done through a Dataflow template that allows importing [Cloud Storage SequenceFile to Bigtable](https://cloud.google.com/dataflow/docs/guides/templates/provided-batch#cloud-storage-sequencefile-to-bigtable):\n1. Create a new `Service Account`.\n2. Assign a `Service Account Admin` role to it.\n3. Enable the `Dataflow API` in the project.\n4. Create the Dataflow job from the `SequenceFile Files on Cloud Storage to Cloud BigTable` template.\n5. Fill in the `Required parameters` (we will share the Cloud Storage storage path with you).\n\nNOTE: Before creating the Dataflow job, you'll need to send the email address of the Service Account you created (i.e., `xxx@xxx.iam.gserviceaccount.com`) to joe@solana.com or axl@solana.com.\n\n## Restoring Missing Blocks\nSometimes blocks could be missing from your BigTable instance. This will be apparent on Explorer where the parent slot & child slot links won't form cycles. For example, before 59437028 was restored 59437027 incorrectly listed 59437029 as a child:\n\n* https://explorer.solana.com/block/59437029: parent is 59437028\n* https://explorer.solana.com/block/59437028: missing\n* https://explorer.solana.com/block/59437027: child is 59437029\n\nThe missing blocks can be restored from GCS as follows:\n\n1. Download appropriate ledger data from one of these buckets based on your node's location:\n    * gs://mainnet-beta-ledger-us-ny5\n    * gs://mainnet-beta-ledger-europe-fr2\n    * gs://mainnet-beta-ledger-asia-sg1\n\n    * Find the bucket with the largest slot number that is smaller than the missing block. For example block 59437028 is in 59183944\n    * Download rocksdb.tar.bz2:\n      * `~/missingBlocks/59183944$ wget https://storage.googleapis.com/mainnet-beta-ledger-us-ny5/59183944/rocksdb.tar.bz2`\n    * Also note the version number in version.txt:\n      * `curl https://storage.googleapis.com/mainnet-beta-ledger-us-ny5/59183944/version.txt`\n        * `solana-ledger-tool 1.4.21 (src:50ebc3f4; feat:2221549166)`\n2. Extract the data\n    * `~/missingBlocks/59183944$ tar -I lbzip2 -xf rocksdb.tar.bz2`\n        * This can take a while so use a screen session if your connection is unstable.\n        * More recent epochs have the ledger comrpes with zstd so you should use `tar --use-compress-program=unzstd -xvf rocksdb.tar.zst instead`\n3. Build the ledger tool from the version listed in version.txt\n    * `~/solana$ git checkout 50ebc3f4` (can also checkout v1.4.21)\n    * `~/solana$ cd ledger-tool && ../cargo build --release`\n        * The cargo script in the solana repo uses the rust version associated with the release to solve backwards compatibility problems.\n4. Check blocks\n    * `~/missingBlocks/59183944$ ~/solana/target/release/solana-ledger-tool slot 59437028 -l . | head -n 2`\n        * Output should include the correct parent & child. If you get a SlotNotRooted error see below.\n5. Upload missing block(s) to big table\n    * `~/missingBlocks/59183944$ GOOGLE_APPLICATION_CREDENTIALS=<json credentials file with write permission> ~/solana/target/release/solana-ledger-tool bigtable upload 59437028 59437028 -l .`\n        * Specify two blocks to upload a range. Earlier block (smaller number) first.\n        * `-l` should specify a directory that contains the rocksdb directory.\n6. If the previous steps produced a `SlotNotRooted` error, first run the repair-roots command.\n    * `~/missingBlocks/59183944$ ~/github/solana/target/release/solana-ledger-tool repair-roots --before 59437029 --until 59437027  -l .`\n        * If you get `error: Found argument 'repair-roots' which wasn't expected, or isn't valid in this context` then the ledger tool version pre-dates the repair-roots command. Add it to your local code by cherry picking `ddfbae2` or manually applying the changes from [PR #17045](https://github.com/solana-labs/solana/pull/17045/files)\n", "release_dates": []}, {"name": "solana-build", "description": null, "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "### Environment Setup\n1. Install Rust from https://rustup.rs/\n2. Install Solana v1.6.2 or later from https://docs.solana.com/cli/install-solana-cli-tools#use-solanas-install-tool\n\n### Build and test for program compiled natively\n```\n$ cargo build\n$ cargo test\n```\n\n### Build and test the program compiled for BPF\n```\n$ cargo build-bpf\n$ cargo test-bpf\n```\n", "release_dates": []}, {"name": "solana-flagged-accounts", "description": "A community-maintained registry of flagged accounts", "language": "JavaScript", "license": null, "readme": "# solana-flagged-accounts\n\nA community maintained registry of flagged accounts\n\n## How is this repository used?\n\nSolana's blockchain explorer (https://explorer.solana.com/) uses this registry to inform users about accounts flagged as potential scams.\n\n## How can I contribute?\n\n  1. Modify `flagged.txt` by adding the address to be flagged on a new line.\n  2. Create a pull request with your changes (https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request).\n  3. Submit reasoning and evidence for why an account should be flagged (e.g. a screenshot, url, telegram channel).\n", "release_dates": []}, {"name": "solana-graphql-playground", "description": "GraphQL web IDE for working with the Solana RPC-GraphQL resolver", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "This is a [Next.js](https://nextjs.org/) project bootstrapped with [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app).\n\n## Getting Started\n\nFirst, run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nYou can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.\n\nThis project uses [`next/font`](https://nextjs.org/docs/basic-features/font-optimization) to automatically optimize and load Inter, a custom Google Font.\n\n## Learn More\n\nTo learn more about Next.js, take a look at the following resources:\n\n-   [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\n-   [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\n\nYou can check out [the Next.js GitHub repository](https://github.com/vercel/next.js/) - your feedback and contributions are welcome!\n\n## Deploy on Vercel\n\nThe easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.\n\nCheck out our [Next.js deployment documentation](https://nextjs.org/docs/deployment) for more details.\n", "release_dates": []}, {"name": "solana-json-rpc-https-proxy", "description": "DEPRECATED - Provides a TLS proxy for web-based Solana JSON RPC users", "language": "Shell", "license": null, "readme": "## Solana JSON RPC HTTPS Proxy\n\nThis repository provides an https proxy to the JSON RPC endpoint of a Solana\nfull node.\n\n## Prerequisites\n\nThe machine must have the following:\n1. Docker installed\n1. TCP ports 80 and 443 available\n1. A static IP with an associated FQDN\n\n## Usage:\n\nThe following command will create/start a Docker container (restarts on boot) that forwards\nhttps traffic from `my-fullnode-domain.example.com:443` to the standard JSON RPC port of\n`my-fullnode-domain.example.com:8899`:\n```bash\n$ ./start.sh my-fullnode-domain.example.com me@example.com / my-fullnode-domain.example.com\n```\n\nFor multiple forwards:\n```bash\n$ ./start.sh api.testnet.solana.com user@example.com \\\n   /master master.testnet.solana.com \\\n   / testnet.solana.com\n```\n\nRun `./start.sh` with no arguments for more usage information.\n\n## Copyright\n\nThis repository is derived from https://github.com/jgoerzen/docker-apache-proxy:\n```\nDocker scripts, etc. are\nCopyright (c) 2018 John Goerzen\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions\nare met:\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and/or other materials provided with the distribution.\n3. Neither the name of the University nor the names of its contributors\n   may be used to endorse or promote products derived from this software\n   without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE AUTHORS AND CONTRIBUTORS ``AS IS'' AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\nOR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\nHOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\nLIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\nOUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGE.\n\nAdditional software copyrights as noted.\n```\n", "release_dates": []}, {"name": "solana-labs.github.io", "description": "Organization Pages", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# solana-labs.github.io\nOrganization Pages\n", "release_dates": []}, {"name": "solana-payments-app", "description": "Solana Pay for Commerce Platforms", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Solana Payments App\n\n<p align=\"center\"><img src=\"apps/docs/docs/assets/solana_shopify.jpeg\" alt=\"Solana_Shopify\"/></p>\n\n<p align=\"center\">\n    <b>\n        <a href=\"https://commercedocs.solanapay.com\">documentation</a>\n    </b>\n    &nbsp;|&nbsp;\n    <b>\n        <a href=\"https://www.youtube.com/channel/UCAbEl-Jr7kx2JqjTjhpoT-Q\">walkthroughs</a>\n    </b>\n    &nbsp;|&nbsp;\n    <b>\n        <a href=\"https://apps.shopify.com/solana-pay\">installation</a>\n    </b>\n    &nbsp;|&nbsp;\n    <b>\n        <a href=\"https://solanatest1.myshopify.com/\">live store</a>\n    </b>\n    &nbsp;|&nbsp;\n    <b>\n        <a href=\"https://merchant.solanapay.com\">merchant login</a>\n    </b>\n</p>\n\nTransact on Shopify using Solana\n\n# Quickstart\n\nPre Setup Dependencies:\n\n-   [Docker Desktop](https://docs.docker.com/desktop/)\n-   [MySql](https://dev.mysql.com/doc/mysql-installation-excerpt/5.7/en/)\n\nInstallation:\n\n```\ngit clone https://github.com/solana-labs/solana-payments-app\nyarn install\nyarn setup:env\n```\n\nIn `apps/backend-serverless/.env.dev`, add a Keypair secret for a wallet with SOL to pay for gas\nIn `apps/backend-serverless/.env.dev`, setup a [Helius API key](https://www.helius.dev)\n\nTo run:\n\n```\nyarn dev\nyarn seed\n```\n\n## Testing\n\nUse these links to test out the local development flow\n\n[Local Merchant Portal](https://localhost:4004/install)\n\n[Local Payment Simulation](https://localhost:4004/payment)\n\n** Note **\n\nThese links redirect you to the frontend local deployments. We included sample development certificates in `backend-serverless` and `mock-shopify-serverless`, however, you might need to ignore browser errors. [Follow this guide](https://blog.simontimms.com/2021/10/12/serverless-offline-https/) to setup your own local dev certificates\n\nFor various helper scripts you might need while extending the code, in apps/backend-serverless, you can run\n\n```\nnode --loader ts-node/esm scripts/nft-setup.ts\n```\n\n## Deploying\n\nWe use the [Serverless Framework](https://www.serverless.com), follow their directions to setup your appropriate aws & serverless credentials.\n\nEnsure you setup the following dependencies in the respective `.env` files\n\n-   Sentry for logging\n-   TRM for scanning for suspicious wallets\n-   Helius for Solana rpc\n-   Coingecko for price data\n-   Persona for kyb\n-   Planetscale (recommended) or any mysql database provider\n-   AWS Lambda for Serverless deployment\n-   Vercel for frontend hosting\n\nIn `apps/backend-serverless`, deploy with\n\n```\nyarn deploy:production:purple\nyarn deploy:production:green\n```\n\nIn `apps/transaction-request-serverless`, deploy with\n\n```\nyarn deploy:production\n```\n\n(change production to staging for a staging environment)\n\n_Make sure to use more secure JWTs in the .envs when deploying to staging and production_\n", "release_dates": ["2023-08-18T14:58:18Z", "2023-07-15T15:23:40Z"]}, {"name": "solana-perf-libs", "description": "C and CUDA libraries to enhance Solana", "language": "C", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "[![Build status](https://badge.buildkite.com/dcc97a44f655a7473ff0f836a2cf154dff016a66db8e4f7405.svg?branch=master)](https://buildkite.com/solana-labs/wool)\n\n# solana-perf-libs\nCUDA, and more!\n\n## Building\nAfter cloning this repo use the makefile in the root to build the tree\nwith nvcc in your path:\n\n```bash\n$ export PATH=/usr/local/cuda/bin:$PATH\n$ make -j$(nproc)\n```\n\nThis should generate the libraries:\n* libcuda-crypt.so - ed25519 verify and poh verify cuda implementations\n* libcl-crypt.so - ed25519 verify and poh verify OpenCL implementations\n\nCopy libraries to the main Solana repo:\n```bash\n$ make DESTDIR=${SOLANA_ROOT:?}/target/perf-libs install\n```\n\nBuild Solana:\n```bash\n$ cd $SOLANA_ROOT\n$ cargo build --release\n```\n\nThe library is loaded at startup by `solana_perf::perf_libs`.\nSee `perf/src/perf_libs.rs` in the main Solana repo for details.\n", "release_dates": ["2022-06-18T19:14:34Z", "2020-08-12T06:16:38Z", "2020-08-04T18:11:53Z", "2020-07-31T00:05:48Z", "2020-06-16T17:08:43Z", "2020-05-06T16:08:03Z", "2020-01-25T03:55:22Z", "2019-12-25T19:47:02Z", "2019-12-13T23:25:44Z", "2019-10-31T21:59:41Z", "2019-10-31T16:54:42Z", "2019-06-24T20:54:48Z", "2019-06-21T21:19:40Z", "2019-06-18T16:10:22Z", "2018-11-06T21:48:51Z", "2018-07-16T02:24:28Z", "2018-06-22T21:40:54Z", "2018-05-01T04:06:20Z", "2018-04-27T22:42:30Z"]}, {"name": "solana-ping-api", "description": "solana ping api server", "language": "Go", "license": null, "readme": "# Solana Ping Service \n\n## Functions Provided\n- High frequently send transactions and record results\n- provide http API service \n- generate a report and submit to slack periodically\n- actively check confirmation losses and send an alert to slack\n- Spam Filter of slack alert\n\n## Server Setup\n### API Service\nAPI service for getting the results of ping service. \nUse `APIServer: Enabled: true` to turn on in in config-{cluster}.yaml.\n\n### PingService\nThis is similar to  \"solana ping\" tool in solana tool but can do concurrent rpc query.\nIt send transactions to rpc endpoint and wait for transactions is confirmed. \nUse `PingServiceEnabled: true` to turn on in config-{cluster}.yaml.\n### RetensionService\nUse `Retension: Enabled: true` in config.yaml to turn on. Default is Off.\nClean database data periodically.\n\n### ReportService\nUse `Report: Enabled:true` in config-{cluster}.yaml to turn on. \nping-api service supports sedning report & alert to both slack and discord.\nUse `Report: Slack: Report: Enabled:true` to turn on Slack Report.\nThis sends summary of ping result to a slack channel periodically.\nUse `Report: Slack: Alert: Enabled:true` to turn on Slack Alert. \nThis will send alert when a event is triggered. See  **Alert Spam Filter** for more info.\nUse `Report: Discord: Report: Enabled:true` to turn on Discord Report.\nUse `Report: Discord: Alert: Enabled:true` to turn on Discord Alert.\n\n\n+ Example:Run only API Query Server\nIn config.yaml ServerSetup: \n\n```\n(config.yaml)\nRetension:\n Enabled: false\n(config-{cluster}.yaml)\nPingEnabled: true     \nReport:\n Enabled: true\n Slack:\n  Report:\n   Enabled: true\n  Alert: \n   Enabled: true   \n Discord:\n  Enabled: true\n  Report:\n   Enabled: false\n  Alert: \n   Enabled: true                  \n```\n## Installation\n- download executable file \n- or build from source\n    - Install golang \n    - clone from github.com/solana-labs/solana-ping-api\n    - go mod tidy to download packages\n    - go build \n- mkdir ~/.config/ping-api\n- put config.yaml in ~/.config/ping-api/config.yaml\n\n### Using GCP Database\n- Install & Setup google cloud CLI\n- download [Cloud SQL Auth proxy](https://cloud.google.com/sql/docs/postgres/sql-proxy)\n- chmod +x cloud_sql_proxy\n- run cloud_sql_proxy\n\n## setup recommendation\n- mkdir ~/ping-api-server\n- cp scripts in script to ~/ping-api-server\n- make solana-ping-api system service \n    - create a /etc/systemd/system/solana-ping-api.service\n    - remember to reload by ```sudo systemctl daemon-reload```\n\n```\n[Unit]\nDescription=Solana Ping API Service\nAfter=network.target\nStartLimitIntervalSec=1\n\n[Service]\nType=simple\nRestart=always\nRestartSec=30\nUser=sol\nLogRateLimitIntervalSec=0\nExecStart=/home/sol/ping-api-server/solana-ping-restart.sh\n\n[Install]\nWantedBy=multi-user.target\n\n```\n\n- put executable file in ~/ping-api-server\n- cp config.yaml.samle to ~/ping-api-server/config.yaml and modify it \n- use cp-to-real-config.sh to copy config.yaml to ~/.config/ping-api/config.yaml\n- start service by sudo sysmtemctl start solana-ping-api.service\n- you can check log by ```sudo tail -f /var/log/syslog | grep ping-api```\n\n## Alert Spam Filter\n\nAlert Spam Filter could be changed frequently. The updte to date (4/18/2022) setting  is as below.\n```\n    Threshold increases when\n    Loss > 20 % -> new threshold = 50% -> send alert\n    Loss > 50 % -> new threshold = 75% -> send alert\n    Loss > 75 % -> new threshold = 100% -> send alert\n    Threshold decreases when\n    Loss > 75 % to < 75%  -> new threshold = 75% -> send alert\n    Loss > 50 % to < 50%  -> new threshold = 50% -> send alert\n    Loss > 20 % to < 20%  -> new threshold = 20% -> NOT send alert\n```", "release_dates": ["2022-03-30T07:56:41Z", "2022-01-20T09:30:40Z"]}, {"name": "solana-pkcs8", "description": "A utility to parse DER-encoded PKCS #8 files", "language": "Rust", "license": null, "readme": null, "release_dates": ["2019-08-09T03:29:59Z", "2019-08-09T03:28:11Z"]}, {"name": "solana-program-library", "description": "A collection of Solana programs maintained by Solana Labs", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Solana Program Library\n\nThe Solana Program Library (SPL) is a collection of on-chain programs targeting\nthe [Sealevel parallel\nruntime](https://medium.com/solana-labs/sealevel-parallel-processing-thousands-of-smart-contracts-d814b378192).\nThese programs are tested against Solana's implementation of Sealevel,\nsolana-runtime, and some are deployed to Mainnet Beta.  As others implement\nSealevel, we will graciously accept patches to ensure the programs here are\nportable across all implementations.\n\nFor more information see the [SPL documentation](https://spl.solana.com) and the [Token TypeDocs](https://solana-labs.github.io/solana-program-library/token/js/).\n\n## Deployments\n\nOnly a subset of programs within the Solana Program Library repo are deployed to\nthe Solana Mainnet Beta. Currently, this includes:\n\n| Program | Version |\n| --- | --- |\n| [token](https://github.com/solana-labs/solana-program-library/tree/master/token/program) | [3.4.0](https://github.com/solana-labs/solana-program-library/releases/tag/token-v3.4.0) |\n| [associated-token-account](https://github.com/solana-labs/solana-program-library/tree/master/associated-token-account/program) | [1.1.0](https://github.com/solana-labs/solana-program-library/releases/tag/associated-token-account-v1.1.0) |\n| [token-2022](https://github.com/solana-labs/solana-program-library/tree/master/token/program-2022) | [1.0.0](https://github.com/solana-labs/solana-program-library/releases/tag/token-2022-v1.0.0) |\n| [governance](https://github.com/solana-labs/solana-program-library/tree/master/governance/program) | [3.1.0](https://github.com/solana-labs/solana-program-library/releases/tag/governance-v3.1.0) |\n| [stake-pool](https://github.com/solana-labs/solana-program-library/tree/master/stake-pool/program) | [1.0.0](https://github.com/solana-labs/solana-program-library/releases/tag/stake-pool-v1.0.0) |\n| [account-compression](https://github.com/solana-labs/solana-program-library/tree/master/account-compression/programs/account-compression) | [0.1.3](https://github.com/solana-labs/solana-program-library/releases/tag/account-compression-v0.1.3) |\n| [shared-memory](https://github.com/solana-labs/solana-program-library/tree/master/shared-memory/program) | [1.0.0](https://github.com/solana-labs/solana-program-library/commit/b40e0dd3fd6c0e509dc1e8dd3da0a6d609035bbd) |\n| [feature-proposal](https://github.com/solana-labs/solana-program-library/tree/master/feature-proposal/program) | [1.0.0](https://github.com/solana-labs/solana-program-library/releases/tag/feature-proposal-v1.0.0) |\n| [name-service](https://github.com/solana-labs/solana-program-library/tree/master/name-service/program) | [0.3.0](https://github.com/solana-labs/solana-program-library/releases/tag/name-service-v0.3.0) |\n| [memo](https://github.com/solana-labs/solana-program-library/tree/master/memo/program) | [3.0.0](https://github.com/solana-labs/solana-program-library/releases/tag/memo-v3.0.0) |\n\nIn addition, one program is planned for deployment to Solana Mainnet Beta:\n\n| Program | Version |\n| --- | --- |\n| [single-pool](https://github.com/solana-labs/solana-program-library/tree/master/single-pool/program) | [1.0.1](https://github.com/solana-labs/solana-program-library/releases/tag/single-pool-v1.0.1) |\n\n## Audits\n\nOnly a subset of programs within the Solana Program Library repo are audited. Currently, this includes:\n\n| Program | Last Audit Date | Version |\n| --- | --- | --- |\n| [token](https://github.com/solana-labs/solana-program-library/tree/master/token/program) | 2022-08-04 (Peer review) | [4fadd55](https://github.com/solana-labs/solana-program-library/commit/4fadd553e1c549afd1d62aeb5ffa7ef31d1999d1) |\n| [associated-token-account](https://github.com/solana-labs/solana-program-library/tree/master/associated-token-account/program) | 2022-08-04 (Peer review) | [c00194d](https://github.com/solana-labs/solana-program-library/commit/c00194d2257302f028f44a403c6dee95c0f9c3bc) |\n| [token-2022](https://github.com/solana-labs/solana-program-library/tree/master/token/program-2022) | [2023-11-03](https://github.com/solana-labs/security-audits/blob/master/spl/OtterSecToken2022Audit-2023-11-03.pdf) | [e924132](https://github.com/solana-labs/solana-program-library/tree/e924132d65ba0896249fb4983f6f97caff15721a) |\n| [stake-pool](https://github.com/solana-labs/solana-program-library/tree/master/stake-pool/program) | [2023-12-31](https://github.com/solana-labs/security-audits/blob/master/spl/HalbornStakePoolAudit-2023-12-31.pdf) | [a17fffe](https://github.com/solana-labs/solana-program-library/commit/a17fffe70d6cc13742abfbc4a4a375b087580bc1) |\n| [account-compression](https://github.com/solana-labs/solana-program-library/tree/master/account-compression/programs/account-compression) | [2022-12-05](https://github.com/solana-labs/security-audits/blob/master/spl/OtterSecAccountCompressionAudit-2022-12-03.pdf) | [6e81794](https://github.com/solana-labs/solana-program-library/commit/6e81794) |\n| [shared-memory](https://github.com/solana-labs/solana-program-library/tree/master/shared-memory/program) | [2021-02-25](https://github.com/solana-labs/security-audits/blob/master/spl/KudelskiTokenSwapSharedMemAudit-2021-02-25.pdf) | [b40e0dd](https://github.com/solana-labs/solana-program-library/commit/b40e0dd3fd6c0e509dc1e8dd3da0a6d609035bbd) |\n| [single-pool](https://github.com/solana-labs/solana-program-library/tree/master/single-pool/program) | [2024-01-02](https://github.com/solana-labs/security-audits/blob/master/spl/ZellicSinglePoolAudit-2024-01-02.pdf) | [ef44df9](https://github.com/solana-labs/solana-program-library/commit/ef44df985e76a697ee9a8aabb3a223610e4cf1dc) |\n\nAll other programs may be updated from time to time. These programs are not\naudited, so fork and deploy them at your own risk. Here is the full list of\nunaudited programs:\n\n* [binary-option](https://github.com/solana-labs/solana-program-library/tree/master/binary-option/program)\n* [binary-oracle-pair](https://github.com/solana-labs/solana-program-library/tree/master/binary-oracle-pair/program)\n* [feature-proposal](https://github.com/solana-labs/solana-program-library/tree/master/feature-proposal/program)\n* [instruction-padding](https://github.com/solana-labs/solana-program-library/tree/master/instruction-padding/program)\n* [managed-token](https://github.com/solana-labs/solana-program-library/tree/master/managed-token/program)\n* [memo](https://github.com/solana-labs/solana-program-library/tree/master/memo/program)\n* [name-service](https://github.com/solana-labs/solana-program-library/tree/master/name-service/program)\n* [record](https://github.com/solana-labs/solana-program-library/tree/master/record/program)\n* [stateless-asks](https://github.com/solana-labs/solana-program-library/tree/master/stateless-asks/program)\n* [token-lending](https://github.com/solana-labs/solana-program-library/tree/master/token-lending/program)\n* [token-swap](https://github.com/solana-labs/solana-program-library/tree/master/token-swap/program)\n* [token-upgrade](https://github.com/solana-labs/solana-program-library/tree/master/token-upgrade/program)\n\nMore information about the repository's security policy at\n[SECURITY.md](https://github.com/solana-labs/solana-program-library/tree/master/SECURITY.md).\n\nThe [security-audits repo](https://github.com/solana-labs/security-audits) contains\nall past and present program audits.\n\n## Program Packages\n\n| Package | Description | Version | Docs |\n| :-- | :-- | :--| :-- |\n| `spl-token` | ERC20-like token program on Solana | [![Crates.io](https://img.shields.io/crates/v/spl-token)](https://crates.io/crates/spl-token) | [![Docs.rs](https://docs.rs/spl-token/badge.svg)](https://docs.rs/spl-token) |\n| `spl-token-2022` | Token program compatible with `spl-token`, with extensions | [![Crates.io](https://img.shields.io/crates/v/spl-token-2022)](https://crates.io/crates/spl-token-2022) | [![Docs.rs](https://docs.rs/spl-token-2022/badge.svg)](https://docs.rs/spl-token-2022) |\n| `spl-associated-token-account` | Stateless protocol defining a canonical \"associated\" token account for a wallet | [![Crates.io](https://img.shields.io/crates/v/spl-associated-token-account)](https://crates.io/crates/spl-associated-token-account) | [![Docs.rs](https://docs.rs/spl-associated-token-account/badge.svg)](https://docs.rs/spl-associated-token-account) |\n| `spl-governance` | DAO program using tokens for voting | [![Crates.io](https://img.shields.io/crates/v/spl-governance)](https://crates.io/crates/spl-governance) | [![Docs.rs](https://docs.rs/spl-governance/badge.svg)](https://docs.rs/spl-governance) |\n| `spl-account-compression` | Program for managing compressed accounts stored in an off-chain merkle tree | [![Crates.io](https://img.shields.io/crates/v/spl-account-compression)](https://crates.io/crates/spl-account-compression) | [![Docs.rs](https://docs.rs/spl-account-compression/badge.svg)](https://docs.rs/spl-account-compression) |\n| `spl-feature-proposal` | Program using tokens to vote on enabling Solana network features | [![Crates.io](https://img.shields.io/crates/v/spl-feature-proposal)](https://crates.io/crates/spl-feature-proposal) | [![Docs.rs](https://docs.rs/spl-feature-proposal/badge.svg)](https://docs.rs/spl-feature-proposal) |\n| `spl-noop` | Program that does nothing, used for logging instruction data | [![Crates.io](https://img.shields.io/crates/v/spl-noop)](https://crates.io/crates/spl-noop) | [![Docs.rs](https://docs.rs/spl-noop/badge.svg)](https://docs.rs/spl-noop) |\n| `spl-memo` | Program for logging signed memos on-chain | [![Crates.io](https://img.shields.io/crates/v/spl-memo)](https://crates.io/crates/spl-memo) | [![Docs.rs](https://docs.rs/spl-memo/badge.svg)](https://docs.rs/spl-memo) |\n| `spl-name-service` | Program for managing ownership of data on-chain | [![Crates.io](https://img.shields.io/crates/v/spl-name-service)](https://crates.io/crates/spl-name-service) | [![Docs.rs](https://docs.rs/spl-name-service/badge.svg)](https://docs.rs/spl-name-service) |\n| `spl-shared-memory` | Program for sharing data between programs | [![Crates.io](https://img.shields.io/crates/v/spl-shared-memory)](https://crates.io/crates/spl-shared-memory) | [![Docs.rs](https://docs.rs/spl-shared-memory/badge.svg)](https://docs.rs/spl-shared-memory) |\n| `spl-stake-pool` | Program for pooling stake accounts, managed by another entity | [![Crates.io](https://img.shields.io/crates/v/spl-stake-pool)](https://crates.io/crates/spl-stake-pool) | [![Docs.rs](https://docs.rs/spl-stake-pool/badge.svg)](https://docs.rs/spl-stake-pool) |\n| `spl-instruction-padding` | Program to padding to other instructions | [![Crates.io](https://img.shields.io/crates/v/spl-instruction-padding)](https://crates.io/crates/spl-instruction-padding) | [![Docs.rs](https://docs.rs/spl-instruction-padding/badge.svg)](https://docs.rs/spl-instruction-padding) |\n| `spl-concurrent-merkle-tree` | Library for on-chain representation of merkle tree | [![Crates.io](https://img.shields.io/crates/v/spl-concurrent-merkle-tree)](https://crates.io/crates/spl-concurrent-merkle-tree) | [![Docs.rs](https://docs.rs/spl-concurrent-merkle-tree/badge.svg)](https://docs.rs/spl-concurrent-merkle-tree) |\n| `spl-math` | Library for on-chain math | [![Crates.io](https://img.shields.io/crates/v/spl-math)](https://crates.io/crates/spl-math) | [![Docs.rs](https://docs.rs/spl-math/badge.svg)](https://docs.rs/spl-math) |\n| `spl-token-lending` | Over-collateralized lending program for tokens | [![Crates.io](https://img.shields.io/crates/v/spl-token-lending)](https://crates.io/crates/spl-token-lending) | [![Docs.rs](https://docs.rs/spl-token-lending/badge.svg)](https://docs.rs/spl-token-lending) |\n| `spl-token-swap` | AMM for trading tokens | [![Crates.io](https://img.shields.io/crates/v/spl-token-swap)](https://crates.io/crates/spl-token-swap) | [![Docs.rs](https://docs.rs/spl-token-swap/badge.svg)](https://docs.rs/spl-token-swap) |\n| `spl-token-upgrade` | Protocol for burning one token type in exchange for another | [![Crates.io](https://img.shields.io/crates/v/spl-token-upgrade)](https://crates.io/crates/spl-token-upgrade) | [![Docs.rs](https://docs.rs/spl-token-upgrade/badge.svg)](https://docs.rs/spl-token-upgrade) |\n\n## CLI Packages\n\n| Package | Description | Version |\n| :-- | :-- | :--|\n| `spl-token-cli` | CLI for the token, token-2022, and associated-token-account programs | [![Crates.io](https://img.shields.io/crates/v/spl-token-cli)](https://crates.io/crates/spl-token-cli) |\n| `spl-stake-pool-cli` | CLI for the stake-pool program | [![Crates.io](https://img.shields.io/crates/v/spl-stake-pool-cli)](https://crates.io/crates/spl-stake-pool-cli) |\n| `spl-feature-proposal-cli` | CLI for the feature-proposal program | [![Crates.io](https://img.shields.io/crates/v/spl-feature-proposal-cli)](https://crates.io/crates/spl-feature-proposal-cli) |\n| `spl-token-lending-cli` | CLI for the token-lending program | [![Crates.io](https://img.shields.io/crates/v/spl-token-lending-cli)](https://crates.io/crates/spl-token-lending-cli) |\n| `spl-token-upgrade-cli` | CLI for the token-upgrade program | [![Crates.io](https://img.shields.io/crates/v/spl-token-upgrade-cli)](https://crates.io/crates/spl-token-upgrade-cli) |\n\n## JavaScript Packages\n\n| Package | Description | Version | Docs |\n| :-- | :-- | :--| :-- |\n| `@solana/spl-token` | Bindings for the token, token-2022, and associated-token-account programs | [![npm](https://img.shields.io/npm/v/@solana/spl-token.svg)](https://www.npmjs.com/package/@solana/spl-token) | [![Docs](https://img.shields.io/badge/docs-typedoc-blue)](https://solana-labs.github.io/solana-program-library/token/js) |\n| `@solana/spl-governance` | Bindings for the governance program | [![npm](https://img.shields.io/npm/v/@solana/spl-governance.svg)](https://www.npmjs.com/package/@solana/spl-governance) | N/A |\n| `@solana/spl-account-compression` | Bindings for the account-compression program | [![npm](https://img.shields.io/npm/v/@solana/spl-account-compression.svg)](https://www.npmjs.com/package/@solana/spl-account-compression) | [![Docs](https://img.shields.io/badge/docs-typedoc-blue)](https://solana-labs.github.io/solana-program-library/account-compression/sdk/docs) |\n| `@solana/spl-memo` | Bindings for the memo program | [![npm](https://img.shields.io/npm/v/@solana/spl-memo.svg)](https://www.npmjs.com/package/@solana/spl-memo) | N/A |\n| `@solana/spl-name-service` | Bindings for the name-service program | [![npm](https://img.shields.io/npm/v/@solana/spl-name-service.svg)](https://www.npmjs.com/package/@solana/spl-name-service) | N/A |\n| `@solana/spl-stake-pool` | Bindings for the stake-pool program | [![npm](https://img.shields.io/npm/v/@solana/spl-stake-pool.svg)](https://www.npmjs.com/package/@solana/spl-stake-pool) | N/A |\n| `@solana/spl-token-lending` | Bindings for the token-lending program | [![npm](https://img.shields.io/npm/v/@solana/spl-token-lending.svg)](https://www.npmjs.com/package/@solana/spl-token-lending) | N/A |\n| `@solana/spl-token-swap` | Bindings for the token-swap program | [![npm](https://img.shields.io/npm/v/@solana/spl-token-swap.svg)](https://www.npmjs.com/package/@solana/spl-token-swap) | N/A |\n\n## Development\n\n### Environment Setup\n\n1. Install the latest [Solana tools](https://docs.solana.com/cli/install-solana-cli-tools).\n2. Install the latest [Rust stable](https://rustup.rs/). If you already have Rust, run `rustup update` to get the latest version.\n3. Install the `libudev` development package for your distribution (`libudev-dev` on Debian-derived distros, `libudev-devel` on Redhat-derived).\n\n### Build\n\n### Build on-chain programs\n\n```bash\n# To build all on-chain programs\n$ cargo build-sbf\n\n# To build a specific on-chain program\n$ cd <program_name>/program\n$ cargo build-sbf\n```\n\n### Build clients\n\n```bash\n# To build all clients\n$ cargo build\n\n# To build a specific client\n$ cd <program_name>/cli\n$ cargo build\n```\n\n### Test\n\nUnit tests contained within all projects can be run with:\n```bash\n$ cargo test      # <-- runs host-based tests\n$ cargo test-sbf  # <-- runs BPF program tests\n```\n\nTo run a specific program's tests, such as SPL Token:\n```bash\n$ cd token/program\n$ cargo test      # <-- runs host-based tests\n$ cargo test-sbf  # <-- runs BPF program tests\n```\n\nIntegration testing may be performed via the per-project .js bindings.  See the\n[token program's js project](token/js) for an example.\n\n### Common Issues\n\nSolutions to a few issues you might run into are mentioned here.\n\n1. `Failed to open: ../../deploy/spl_<program-name>.so`\n\n    Update your Rust and Cargo to the latest versions and re-run `cargo build-sbf` in the relevant `<program-name>` directory,\n    or run it at the repository root to rebuild all on-chain programs.\n\n2. [Error while loading shared libraries. (libssl.so.1.1)](https://solana.stackexchange.com/q/3029/36)\n\n    A working solution was mentioned [here](https://solana.stackexchange.com/q/3029/36).\n    Install libssl.\n    ```bash\n    wget http://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1l-1ubuntu1.2_amd64.deb\n    sudo dpkg -i libssl1.1_1.1.1l-1ubuntu1.2_amd64.deb\n    ```\n\n3.  CPU or Memory usage at 100%\n\n    This is to be expected while building some of the programs in this library.\n    The simplest solution is to add the `--jobs 1` flag to the build commands to limit the number of parallel jobs to 1 and check if that fixes the issue. Although this will mean much longer build times.\n\n\n### Clippy\n```bash\n$ cargo clippy\n```\n\n### Coverage\n```bash\n$ ./coverage.sh  # Help wanted! Coverage build currently fails on MacOS due to an XCode `grcov` mismatch...\n```\n\n#### MacOS\n\nYou may need to pin your grcov version, and then rustup with the apple-darwin nightly toolchain:\n```bash\n$ cargo install grcov --version 0.6.1\n$ rustup toolchain install nightly-x86_64-apple-darwin\n```\n\n\n## Release Process\n\nSPL programs are currently tagged and released manually. Each program is\nversioned independently of the others, with all new development occurring on\nmaster. Once a program is tested and deemed ready for release:\n\n### Bump Version\n\n  * Increment the version number in the program's Cargo.toml\n  * Run `cargo build-sbf <program>` to build binary. Note the\n    location of the generated `spl_<program>.so` for attaching to the Github\n    release.\n  * Open a PR with these version changes and merge after passing CI.\n\n### Create Github tag\n\nProgram tags are of the form `<program>-vX.Y.Z`.\nCreate the new tag at the version-bump commit and push to the\nsolana-program-library repository, eg:\n\n```\n$ git tag token-v1.0.0 b24bfe7\n$ git push upstream --tags\n```\n\n### Publish Github release\n\n  * Go to [GitHub Releases UI](https://github.com/solana-labs/solana-program-library/releases)\n  * Click \"Draft new release\", and enter the new tag in the \"Tag version\" box.\n  * Title the release \"SPL <Program> vX.Y.Z\", complete the description, and attach the `spl_<program>.so` binary\n  * Click \"Publish release\"\n\n### Publish to Crates.io\n\nNavigate to the program directory and run `cargo package`\nto test the build. Then run `cargo publish`.\n\n # Disclaimer\n\nAll claims, content, designs, algorithms, estimates, roadmaps,\nspecifications, and performance measurements described in this project\nare done with the Solana Labs, Inc. (\u201cSL\u201d) best efforts. It is up to\nthe reader to check and validate their accuracy and truthfulness.\nFurthermore nothing in this project constitutes a solicitation for\ninvestment.\n\nAny content produced by SL or developer resources that SL provides, are\nfor educational and inspiration purposes only. SL does not encourage,\ninduce or sanction the deployment, integration or use of any such\napplications (including the code comprising the Solana blockchain\nprotocol) in violation of applicable laws or regulations and hereby\nprohibits any such deployment, integration or use. This includes use of\nany such applications by the reader (a) in violation of export control\nor sanctions laws of the United States or any other applicable\njurisdiction, (b) if the reader is located in or ordinarily resident in\na country or territory subject to comprehensive sanctions administered\nby the U.S. Office of Foreign Assets Control (OFAC), or (c) if the\nreader is or is working on behalf of a Specially Designated National\n(SDN) or a person subject to similar blocking or denied party\nprohibitions.\n\nThe reader should be aware that U.S. export control and sanctions laws \nprohibit U.S. persons (and other persons that are subject to such laws) \nfrom transacting with persons in certain countries and territories or \nthat are on the SDN list. Accordingly, there is a risk to individuals \nthat other persons using any of the code contained in this repo, or a \nderivation thereof, may be sanctioned persons and that transactions with \nsuch persons would be a violation of U.S. export controls and sanctions law.\n", "release_dates": ["2024-02-24T17:00:49Z", "2024-02-05T22:35:11Z", "2024-01-29T21:07:54Z", "2024-01-25T13:38:28Z", "2024-01-19T20:01:37Z", "2024-01-19T23:02:46Z", "2024-01-19T20:03:59Z", "2024-01-19T07:31:15Z", "2024-01-29T21:07:34Z", "2024-01-05T22:30:48Z", "2024-01-03T15:25:47Z", "2023-12-12T11:22:44Z", "2023-12-11T17:59:29Z", "2023-12-11T18:00:45Z", "2023-12-13T13:11:10Z", "2023-12-13T13:09:45Z", "2023-12-11T12:25:08Z", "2023-12-11T17:56:48Z", "2023-12-04T23:47:05Z", "2023-11-14T16:42:00Z", "2023-11-14T14:17:50Z", "2023-10-25T07:45:39Z", "2023-10-24T11:18:00Z", "2023-10-24T09:33:20Z", "2023-10-24T09:34:03Z", "2023-10-20T17:13:05Z", "2023-10-18T09:53:31Z", "2023-12-13T11:56:55Z", "2023-09-26T18:04:04Z", "2023-09-26T18:08:52Z"]}, {"name": "solana-season", "description": null, "language": null, "license": null, "readme": "# Solana Season Hackathon &middot; Up to $1 million in prizes & seed funding\n\n#### Jumpstart your next project on Solana & join the fastest growing ecosystem in crypto\n\n- Hackathon dates: May 15 - June 7, 2021\n- Type: Online and global\n- Project Submission Form: [Official Website](https://solana.com/solanaszn)\n\n## Introduction\n\nSolana is a fast, low-fee, and censorship-resistant blockchain designed to enable builders to quickly deploy and scale applications to billions of users globally. The Solana Foundation is excited to host its 3rd virtual hackathon focused on allowing developers to experiment and leverage the Solana blockchain to create a plethora of projects spanning DeFi (Decentralized Finance), NFTs, and Web3.\n\nAs long as you have an Internet connection, you're invited to join the global hackathon! In addition, if you are located in China, Eastern Europe (CIS region), India, Vietnam, Africa, or Brazil, you're eligible for regional prizes (see prize tracks below). While participants are encouraged to build novel crypto apps, hackers can build infrastructure or any tool they believe will have an impact on the Solana ecosystem. The only requirement is that teams must incorporate Solana into their project in some way. Take a look at this list of [hackathon project ideas](https://github.com/solana-labs/solana-season/blob/master/ideas.md).\n\nThroughout the registration period and hackathon, there will be live-streamed presentations, workshops, and panels on a variety of crypto-related topics. See the full schedule here, and make sure to join a few sessions on Twitch!\n\n## Get Started Building\n\n### Solana Docs\n\n- [Solana Docs - Home](https://docs.solana.com/)\n- [Solana Docs - Programming Model](https://docs.solana.com/developing/programming-model/overview)\n- [Solana Program Library Docs](https://spl.solana.com/)\n- [Wormhole Documentation: Ethereum<>Solana bi-directional bridge](https://github.com/certusone/wormhole)\n\n### Rest Resources\n\n- [Rust Resources](https://github.com/solana-labs/solana-season/blob/master/rust-resources.md)\n\n### RPC Endpoints\n\n- [Devnet Endpoint and Rate Limits](https://docs.solana.com/cluster/rpc-endpoints#devnet)\n- [Testnet Endpoint and Rate Limits](https://docs.solana.com/cluster/rpc-endpoints#testnet)\n\n### Video\n\n- [Solana Tutorial | Solana for Developers](https://www.youtube.com/watch?v=qNIhClYDjR8)\n- [Intro to Solana programming model - Technical Workshop](https://www.twitch.tv/videos/1021435633)\n- [Programming Solana Smart Contracts](https://www.youtube.com/watch?v=i6Ycr5nhjH8)\n\n### Walkthroughs\n\n- [Intro to Programming on Solana](https://paulx.dev/blog/2021/01/14/programming-on-solana-an-introduction/)\n- [Development Tutorial by Solong](https://solongwallet.medium.com/solana-development-tutorial-things-you-should-know-before-structuring-your-code-807f0e2ee43)\n\n### Examples and Reference Implementations\n\n- [Hello World Example](https://github.com/solana-labs/example-helloworld)\n- [Serum DEX Example](https://github.com/project-serum/anchor/blob/master/examples/swap/programs/swap/src/lib.rs)\n- [Automated Market Maker + Swap Reference Implementation](https://github.com/solana-labs/oyster-swap)\n- [Borrow/Lend Reference Implementation](https://github.com/solana-labs/oyster-lending)\n- [Margin Reference Implementation](https://github.com/solana-labs/oyster-margin)\n- [Chainlink<>Solana Oracle Implementation](https://github.com/octopus-network/solana-flux-aggregator)\n\n### Development Frameworks\n\n- [Solana Dapp Scaffolding](https://github.com/solana-labs/dapp-scaffold)\n- [Full Stack dApp Development Environment by Decentology](https://dappstarter.decentology.com/)\n\n### Project Serum Resources\n\n- [Serum Developer Resources](https://serum-academy.com/en/developer-resources/)\n- [List tokens on the Serum DEX](https://serum-academy.com/en/add-market/)\n- [Anchor Framework by Project Serum](https://github.com/project-serum/anchor)\n\n## Engage with the Community\n\n- [Discord Support Chat](https://discord.gg/uNHzdyZRMB): Live technical support and help\n- [Find a teammate directory](https://airtable.com/shrGAmy0TzK9h73Us)\n\n## Submissions\n\nA submission form will be availble around June 1. It will require a description of the project, project logo/image, a list of teammates, project name, a link to the GitHub /gitlab repo, and a slide deck or video presentation.\n\n## Judging\n\nParticipants may submit a maximum of 1 project by the hackathon deadline. Once all submissions are collected, Solana will distribute a list to the judges for the evaluation process. Teams and individuals are evaluated on the following criteria:\n\n1. Functionality\n2. Potential impact\n3. Novelty\n4. Design + UX\n5. Composability\n\nAfter judges complete individual evaluations, the hackathon organizers will discuss with the judges to choose the winners based on the project's weighted scores. Winners of the event will be announced shortly after the end of the hackathon.\n\nThere are 3 global prize tracks: DeFi, NFTs, and Web3. There will be a 1st, 2nd, and 3rd place winner in each of those categories. In addition, there are sponsored prizes by supporting projects including Serum, Kin, Raydium, and Pyth for teams that best integrate with their respective technologies. And finally, as mentioned above, there are regional prize pools for teams submitting from China, Eastern Europe, India, Africa, Vietnam, and Brazil.\n\nThe project submission form will be published on or about June 1. It will require projects to provide a brief description of the project, a logo/image, a list of teammates, the project name, a link to the GitHub /gitlab repo, and a slide deck or video presentation.\n\n## Prizes\n\nAll prize amounts will be distributed in USDC-SPL.\n\n| Global                                                                  | Prize                                                             |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------- |\n| Grand Prize Winner                                                      | $30k & airfare+tickets to Solana's conference in Lisbon, Portugal |\n| DeFi                                                                    | 1st Place $20k, 2nd place $10k, 3rd place $5k                     |\n| NFTs                                                                    | 1st Place $20k, 2nd place $10k, 3rd place $5k                     |\n| Web3                                                                    | 1st Place $20k, 2nd place $10k, 3rd place $5k                     |\n| Community Choice Prize                                                  | $5k + Solana Swag                                                 |\n| Serum's Prize                                                           | $25k                                                              |\n| [Kin's Prize](https://github.com/kinecosystem/kin-solana-hackathon)     | $25k                                                              |\n| Our Network's Prize                                                     | $25k                                                              |\n| Raydium's Prize                                                         | 3k RAY tokens                                                     |\n| [Star Atlas' Prize](https://github.com/staratlasmeta/star-atlas-arcade) | $25k                                                              |\n| Orca's Prize                                                            | $5k                                                               |\n| Media Foundation's Prize                                                | $30k                                                              |\n| Pyth's Prize                                                            | $25k                                                              |\n\n#### Regional Prize Pools\n\n| China+Taiwan: Serum + Raydium Track    | Prize |\n| ------------------------------- | ----- |\n| 1st Place                       | $40k  |\n| 2nd Place                       | $25k  |\n| 3rd Place                       | $10k  |\n| Dorahacks Quadractic Vote Prize | $50k  |\n\n| Eastern Europe: Hacken Track                                                                        | Prize |\n| --------------------------------------------------------------------------------------------------- | ----- |\n| 1st Place                                                                                           | $25k  |\n| 2nd Place                                                                                           | $15k  |\n| 3rd Place                                                                                           | $10k  |\n| Serum Prize                                                                                         | $50k  |\n| Velas Prize                                                                                         | $20k  |\n| [HAPI Prize](https://docs.google.com/document/d/1x1dttIurfxB_3yWPbvVnOJ6aydr8mEx5xK81TNk1Veo/edit)  | $20k  |\n| [Akash Prize](https://docs.google.com/document/d/1DYsAh591WUpr0gG5sKn4zn965e6kPY5AMbkitMLfPzs/edit) | $15k  |\n| [Spacemind Prize](https://docs.google.com/document/d/1-sX8xu8Nm0vtPj56jwGvMYjkCSkf2X_smHK2IkUEBJQ/edit) | $15k | \n\n| India: CoinDCX + Devfolio Track | Prize |\n| ------------------------------- | ----- |\n| 1st Place                       | $25k  |\n| 2nd Place                       | $15k  |\n| 3rd Place                       | $10k  |\n\n| Brazil: BRZ Track | Prize |\n| ----------------- | ----- |\n| Overall Winner       | $15k  |\n\n\n| Africa: Blockchain Nigeria + Bundle Track | Prize |\n| ----------------------------------------- | ----- |\n| 1st Place                                 | $15k  |\n| 2nd Place                                 | $7k   |\n| 3rd Place                                 | $3k   |\n\n| Vietnam: Kyber + Coin98 Track | Prize |\n| ----------------------------- | ----- |\n| 1st Place                     | $15k  |\n| 2nd Place                     | $7k   |\n| 3rd Place                     | $3k   |\n\n## Code of Conduct\n\nThe Solana Season Hackathon welcomes any one from around the world to participate and is intended to create an inclusive environment for building, collaboration, creativity, and impact. We value the participation of each member of the community and want everyone involved to be respected. Accordingly, hackathon administrators, judges, and participants are expected to adhere to the Code of Conduct outlined below for the duration of the hackathon. Event organizers will enforce this code and have the right to disqualify any individual or team that breaks the code.\n\n- Be Respectful: Be kind to all who participate in the event. Do not insult or put down other attendees.\n\n- Behave Professionally. Remember that harassment, racism, sexism, or exclusionary jokes are not appropriate for this event. Harassment includes offensive verbal comments related to gender, sexual orientation, disability, physical appearance, race, and/or religion. Sexual images in public forums, deliberate intimidation, online stalking, following, sustained disruption of virtual presentations, or any other inappropriate action is strictly prohibited\n\n- Be Thoughtful: In the spirit of open source and inclusiveness, there may be minors participating in the hackathon. Keep this in mind when communicating or speaking in public forums.\n\n- Be Open: We welcome attendees from all backgrounds. This event is about increasing awareness for Solana and the greater crypto space. Please be welcoming to all who register for the event and help us create a friendly environment for all.\n\n- Believe in Yourself: Crypto opens the door for anyone to permissionlessly build applications that will change how we all interact with finance, gaming, and the Internet as a whole. Dream big and use this powerful technology to create a better world.\n\n## Legal Disclaimer\n\nThe Solana Season Hackathon is a competition where projects will be evaluated by judges on their technological merits without consideration of legal viability. Participants in the Hackathon will create software solely for purposes of evaluation by judges as part of a competition and not for commercial deployment or release as part of the Hackathon.All participants must comply with applicable laws and regulations when releasing any software that they develop as part of the Hackathon.\n\nThe Hackathon ideas and developer resources that Solana Foundation (\u201cSF\u201d) provides are for educational and inspirational purposes only. SF does not encourage, induce or sanction the deployment of any such applications in violation of applicable laws or regulations. SF does not encourage, induce or sanction the deployment, integration or use of any such applications (including the code comprising the Solana blockchain protocol) in violation of applicable laws or regulations and hereby prohibits any such deployment, integration or use. This includes use of any such applications by the reader (a) in violation of export control or sanctions laws of the United States or any other applicable jurisdiction, (b) if the reader is located in or ordinarily resident in a country or territory subject to comprehensive sanctions administered by the U.S. Office of Foreign Assets Control (OFAC), (c) if the reader is or is working on behalf of a Specially Designated National (SDN) or a person subject to similar blocking or denied party prohibitions, or (d) in violation of the Commodities and Exchange Act.\n\nThe reader should be aware that U.S. export control and sanctions laws prohibit U.S. persons (and other persons that are subject to such laws) from transacting with persons in certain countries and territories or that are on the SDN list. As a project based primarily on open-source software, it is possible that such sanctioned persons may nevertheless bypass prohibitions, obtain the code comprising the Solana blockchain protocol (or other project code or applications) and deploy, integrate, or otherwise use it. Accordingly, there is a risk to individuals that other persons using the Solana blockchain protocol may be sanctioned persons and that transactions with such persons would be a violation of U.S. export controls and sanctions law. This risk applies to individuals, organizations, and other ecosystem participants that deploy, integrate, or use the Solana blockchain protocol code directly (e.g., as a node operator), and individuals that transact on the Solana blockchain through light clients, third party interfaces, and/or wallet software.\n\nIn accordance with the open source Apache 2.0 license (\"OS License\") pursuant to which the Solana Services are provided, by participating in the Hackathon, you hereby grant to Company and the Solana community a perpetual, irrevocable, royalty-free, worldwide, nonexclusive copyright license to reproduce, publicly display, publicly perform, distribute, create derivative works based upon, and otherwise use and sublicense any contributions or developments (\"Developments\") provided by you in connection with the Hackathon and such derivative works in source code or object code form. We may reproduce and distribute copies of the Developments or derivative works thereof in any medium, with or without modifications, and in source code or object code form subject to the OS License. Any contribution intentionally submitted for inclusion as part of the Hackathon shall be under the terms and conditions of the OS License. You agree not to challenge or contest our rights or anyone else's rights to use the Developments. You agree that it is your sole responsibility to obtain all permissions and releases necessary for the grant of the rights contained in this Section. You agree to take, at your expense, any further action (including execution of affidavits, tax forms, and other documents) reasonably requested by us to effect, perfect or confirm the rights as set forth in this Section. You will not be entitled to compensation for any use by Company, or its agents, licensees or assignees, of your contributions or developments, except as expressly provided herein.\n", "release_dates": []}, {"name": "solana-solidity.js", "description": "Compile, deploy, and use Solidity contracts on Solana", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# \ud83d\udea8\ud83d\udea8\ud83d\udea8 NO LONGER SUPPORTED \ud83d\udea8\ud83d\udea8\ud83d\udea8\n\nThe [Solang Compiler](https://github.com/hyperledger/solang) no longer supports\nthis library, and uses [Anchor](https://github.com/coral-xyz/anchor) instead.\n\nPlease see the [Solang docs](https://solang.readthedocs.io/en/latest/targets/solana.html) for how to use Solang with Anchor.\n\n# `@solana/solidity`\n\nThe [Solang Compiler](https://github.com/hyperledger/solang) compiles Solidity contracts to native Solana BPF programs.\n\nThis TypeScript library, inspired by [Ethers.js](https://github.com/ethers-io/ethers.js), can deploy and interact with Solidity contracts on Solana.\n\n## Features\n\n- Compile, load, and deploy Solidity contracts\n- Redeploy and reuse existing contract programs\n- Call contract functions to read and write data\n- Subscribe to contract events and program logs\n\n## Quick Setup\n\nThis is a short guide to deploying and interacting with the standard [ERC20](https://docs.openzeppelin.com/contracts/api/token/erc20) Solidity contract on Solana.\n\n1. Install [Docker](https://docker.com) and [Node.js](https://nodejs.org) (version 14 or higher).\n\n2. Clone the repositoy.\n\n```shell\ngit clone https://github.com/solana-labs/solana-solidity.js.git\ncd solana-solidity.js\n```\n\n3. Pull the Docker images to compile and deploy your contracts:\n\n```shell\nyarn docker\n```\n\n4. Start the Solana test validator:\n\n```shell\nyarn validator\n```\n\n5. In a new terminal window, initialize a project:\n\n```shell\nmkdir -p project/contracts project/build\ncd project\ncurl -o contracts/ERC20.sol \\\n     https://raw.githubusercontent.com/solana-labs/solana-solidity.js/master/test/examples/erc20/contracts/ERC20.sol\n```\n\n6. Compile the Solidity contract:\n\n```shell\ndocker run --rm -it -v $PWD:/project \\\n       ghcr.io/hyperledger/solang \\\n       -o /project/build --target solana -v /project/contracts/ERC20.sol\n```\n\nThis outputs `ERC20.abi` and `bundle.so` files to the `build` directory.\n\n7. Install the library:\n\n```shell\nyarn add @solana/solidity\n\n# OR\n\nnpm install @solana/solidity\n```\n\n8. Create a script file to run:\n\n```shell\ntouch erc20.js\n```\n\n9. Paste this code in the file and save it:\n\n```js\nconst { Connection, LAMPORTS_PER_SOL, Keypair } = require('@solana/web3.js');\nconst { Contract } = require('@solana/solidity');\nconst { readFileSync } = require('fs');\n\nconst ERC20_ABI = JSON.parse(readFileSync('./build/ERC20.abi', 'utf8'));\nconst BUNDLE_SO = readFileSync('./build/bundle.so');\n\n(async function () {\n    console.log('Connecting to your local Solana node ...');\n    const connection = new Connection('http://localhost:8899', 'confirmed');\n\n    const payer = Keypair.generate();\n\n    console.log('Airdropping SOL to a new wallet ...');\n    const signature = await connection.requestAirdrop(payer.publicKey, 10 * LAMPORTS_PER_SOL);\n    await connection.confirmTransaction(signature, 'confirmed');\n\n    const address = publicKeyToHex(payer.publicKey);\n    const program = Keypair.generate();\n    const storage = Keypair.generate();\n\n    const contract = new Contract(\n        connection,\n        program.publicKey,\n        storage.publicKey,\n        ERC20_ABI,\n        payer\n    );\n\n    console.log('Deploying the Solang-compiled ERC20 program ...');\n    await contract.load(program, BUNDLE_SO);\n\n    console.log('Program deployment finished, deploying the ERC20 contract ...');\n    await contract.deploy(\n        'ERC20',\n        ['Solana', 'SOL', '1000000000000000000'],\n        storage,\n        4096 * 8\n    );\n\n    console.log('Contract deployment finished, invoking some contract functions ...');\n    const symbol = await contract.symbol();\n    const balance = await contract.balanceOf(address);\n\n    console.log(`ERC20 contract for ${symbol} deployed!`);\n    console.log(`Your wallet at ${address} has a balance of ${balance} tokens.`);\n\n    contract.addEventListener(function (event) {\n        console.log(`${event.name} event emitted!`);\n        console.log(`${event.args[0]} sent ${event.args[2]} tokens to ${event.args[1]}`);\n    });\n\n    console.log('Sending tokens will emit a \"Transfer\" event ...');\n    const recipient = Keypair.generate();\n    await contract.transfer(recipient.publicKey.toBytes(), 1000000000000000000);\n\n    process.exit(0);\n})();\n```\n\n10. Run the script to deploy and interact with your contract on Solana!\n\n```\nnode erc20.js\n```\n\n## Build from source\n\n1. Clone the project:\n\n```shell\ngit clone https://github.com/solana-labs/solana-solidity.js.git\ncd solana-solidity.js\n```\n\n2. Install the dependencies:\n\n```shell\nyarn install\n```\n\n3. Compile the library from TypeScript to JavaScript:\n\n```shell\nyarn build\n```\n\n4. Pull the Docker images to build and run the tests:\n\n```shell\nyarn docker\n```\n\n5. Start the test validator:\n\n```shell\nyarn validator\n```\n\n6. In another terminal window, build and run the tests:\n\n```shell\nyarn build:test\nyarn test\n```\n", "release_dates": []}, {"name": "solana-tokens", "description": "Utility for distributing Solana tokens", "language": null, "license": null, "readme": "solana-tokens has moved to the main Solana repository: https://github.com/solana-labs/solana/tree/master/tokens\n", "release_dates": ["2020-05-12T23:16:00Z", "2020-05-06T17:20:31Z", "2020-04-04T03:14:59Z", "2020-04-03T23:25:33Z"]}, {"name": "solana-tokio", "description": "Solana Labs vendored fork of https://github.com/tokio-rs/tokio", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Tokio\n\nA runtime for writing reliable, asynchronous, and slim applications with\nthe Rust programming language. It is:\n\n* **Fast**: Tokio's zero-cost abstractions give you bare-metal\n  performance.\n\n* **Reliable**: Tokio leverages Rust's ownership, type system, and\n  concurrency model to reduce bugs and ensure thread safety.\n\n* **Scalable**: Tokio has a minimal footprint, and handles backpressure\n  and cancellation naturally.\n\n[![Crates.io][crates-badge]][crates-url]\n[![MIT licensed][mit-badge]][mit-url]\n[![Build Status][actions-badge]][actions-url]\n[![Discord chat][discord-badge]][discord-url]\n\n[crates-badge]: https://img.shields.io/crates/v/tokio.svg\n[crates-url]: https://crates.io/crates/tokio\n[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg\n[mit-url]: https://github.com/tokio-rs/tokio/blob/master/LICENSE\n[actions-badge]: https://github.com/tokio-rs/tokio/workflows/CI/badge.svg\n[actions-url]: https://github.com/tokio-rs/tokio/actions?query=workflow%3ACI+branch%3Amaster\n[discord-badge]: https://img.shields.io/discord/500028886025895936.svg?logo=discord&style=flat-square\n[discord-url]: https://discord.gg/tokio\n\n[Website](https://tokio.rs) |\n[Guides](https://tokio.rs/tokio/tutorial) |\n[API Docs](https://docs.rs/tokio/latest/tokio) |\n[Chat](https://discord.gg/tokio)\n\n## Overview\n\nTokio is an event-driven, non-blocking I/O platform for writing\nasynchronous applications with the Rust programming language. At a high\nlevel, it provides a few major components:\n\n* A multithreaded, work-stealing based task [scheduler].\n* A reactor backed by the operating system's event queue (epoll, kqueue,\n  IOCP, etc...).\n* Asynchronous [TCP and UDP][net] sockets.\n\nThese components provide the runtime components necessary for building\nan asynchronous application.\n\n[net]: https://docs.rs/tokio/latest/tokio/net/index.html\n[scheduler]: https://docs.rs/tokio/latest/tokio/runtime/index.html\n\n## Example\n\nA basic TCP echo server with Tokio.\n\nMake sure you activated the full features of the tokio crate on Cargo.toml:\n\n```toml\n[dependencies]\ntokio = { version = \"1.34.0\", features = [\"full\"] }\n```\nThen, on your main.rs:\n\n```rust,no_run\nuse tokio::net::TcpListener;\nuse tokio::io::{AsyncReadExt, AsyncWriteExt};\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let listener = TcpListener::bind(\"127.0.0.1:8080\").await?;\n\n    loop {\n        let (mut socket, _) = listener.accept().await?;\n\n        tokio::spawn(async move {\n            let mut buf = [0; 1024];\n\n            // In a loop, read data from the socket and write the data back.\n            loop {\n                let n = match socket.read(&mut buf).await {\n                    // socket closed\n                    Ok(n) if n == 0 => return,\n                    Ok(n) => n,\n                    Err(e) => {\n                        eprintln!(\"failed to read from socket; err = {:?}\", e);\n                        return;\n                    }\n                };\n\n                // Write the data back\n                if let Err(e) = socket.write_all(&buf[0..n]).await {\n                    eprintln!(\"failed to write to socket; err = {:?}\", e);\n                    return;\n                }\n            }\n        });\n    }\n}\n```\n\nMore examples can be found [here][examples]. For a larger \"real world\" example, see the\n[mini-redis] repository.\n\n[examples]: https://github.com/tokio-rs/tokio/tree/master/examples\n[mini-redis]: https://github.com/tokio-rs/mini-redis/\n\nTo see a list of the available features flags that can be enabled, check our\n[docs][feature-flag-docs].\n\n## Getting Help\n\nFirst, see if the answer to your question can be found in the [Guides] or the\n[API documentation]. If the answer is not there, there is an active community in\nthe [Tokio Discord server][chat]. We would be happy to try to answer your\nquestion. You can also ask your question on [the discussions page][discussions].\n\n[Guides]: https://tokio.rs/tokio/tutorial\n[API documentation]: https://docs.rs/tokio/latest/tokio\n[chat]: https://discord.gg/tokio\n[discussions]: https://github.com/tokio-rs/tokio/discussions\n[feature-flag-docs]: https://docs.rs/tokio/#feature-flags\n\n## Contributing\n\n:balloon: Thanks for your help improving the project! We are so happy to have\nyou! We have a [contributing guide][guide] to help you get involved in the Tokio\nproject.\n\n[guide]: https://github.com/tokio-rs/tokio/blob/master/CONTRIBUTING.md\n\n## Related Projects\n\nIn addition to the crates in this repository, the Tokio project also maintains\nseveral other libraries, including:\n\n* [`axum`]: A web application framework that focuses on ergonomics and modularity.\n\n* [`hyper`]: A fast and correct HTTP/1.1 and HTTP/2 implementation for Rust.\n\n* [`tonic`]: A gRPC over HTTP/2 implementation focused on high performance, interoperability, and flexibility.\n\n* [`warp`]: A super-easy, composable, web server framework for warp speeds.\n\n* [`tower`]: A library of modular and reusable components for building robust networking clients and servers.\n\n* [`tracing`] (formerly `tokio-trace`): A framework for application-level tracing and async-aware diagnostics.\n\n* [`mio`]: A low-level, cross-platform abstraction over OS I/O APIs that powers `tokio`.\n\n* [`bytes`]: Utilities for working with bytes, including efficient byte buffers.\n\n* [`loom`]: A testing tool for concurrent Rust code.\n\n[`axum`]: https://github.com/tokio-rs/axum\n[`warp`]: https://github.com/seanmonstar/warp\n[`hyper`]: https://github.com/hyperium/hyper\n[`tonic`]: https://github.com/hyperium/tonic\n[`tower`]: https://github.com/tower-rs/tower\n[`loom`]: https://github.com/tokio-rs/loom\n[`tracing`]: https://github.com/tokio-rs/tracing\n[`mio`]: https://github.com/tokio-rs/mio\n[`bytes`]: https://github.com/tokio-rs/bytes\n\n## Changelog\n\nThe Tokio repository contains multiple crates. Each crate has its own changelog.\n\n * `tokio` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio/CHANGELOG.md)\n * `tokio-util` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-util/CHANGELOG.md)\n * `tokio-stream` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-stream/CHANGELOG.md)\n * `tokio-macros` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-macros/CHANGELOG.md)\n * `tokio-test` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-test/CHANGELOG.md)\n\n## Supported Rust Versions\n\n<!--\nWhen updating this, also update:\n- .github/workflows/ci.yml\n- CONTRIBUTING.md\n- README.md\n- tokio/README.md\n- tokio/Cargo.toml\n- tokio-util/Cargo.toml\n- tokio-test/Cargo.toml\n- tokio-stream/Cargo.toml\n-->\n\nTokio will keep a rolling MSRV (minimum supported rust version) policy of **at\nleast** 6 months. When increasing the MSRV, the new Rust version must have been\nreleased at least six months ago. The current MSRV is 1.63.\n\nNote that the MSRV is not increased automatically, and only as part of a minor\nrelease. The MSRV history for past minor releases can be found below:\n\n * 1.30 to now - Rust 1.63\n * 1.27 to 1.29 - Rust 1.56\n * 1.17 to 1.26 - Rust 1.49\n * 1.15 to 1.16 - Rust 1.46\n * 1.0 to 1.14 - Rust 1.45\n\nNote that although we try to avoid the situation where a dependency transitively\nincreases the MSRV of Tokio, we do not guarantee that this does not happen.\nHowever, every minor release will have some set of versions of dependencies that\nworks with the MSRV of that minor release.\n\n## Release schedule\n\nTokio doesn't follow a fixed release schedule, but we typically make one to two\nnew minor releases each month. We make patch releases for bugfixes as necessary.\n\n## Bug patching policy\n\nFor the purposes of making patch releases with bugfixes, we have designated\ncertain minor releases as LTS (long term support) releases. Whenever a bug\nwarrants a patch release with a fix for the bug, it will be backported and\nreleased as a new patch release for each LTS minor version. Our current LTS\nreleases are:\n\n * `1.25.x` - LTS release until March 2024. (MSRV 1.49)\n * `1.32.x` - LTS release until September 2024. (MSRV 1.63)\n\nEach LTS release will continue to receive backported fixes for at least a year.\nIf you wish to use a fixed minor release in your project, we recommend that you\nuse an LTS release.\n\nTo use a fixed minor version, you can specify the version with a tilde. For\nexample, to specify that you wish to use the newest `1.25.x` patch release, you\ncan use the following dependency specification:\n```text\ntokio = { version = \"~1.25\", features = [...] }\n```\n\n### Previous LTS releases\n\n * `1.8.x` - LTS release until February 2022.\n * `1.14.x` - LTS release until June 2022.\n * `1.18.x` - LTS release until June 2023.\n * `1.20.x` - LTS release until September 2023.\n\n## License\n\nThis project is licensed under the [MIT license].\n\n[MIT license]: https://github.com/tokio-rs/tokio/blob/master/LICENSE\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in Tokio by you, shall be licensed as MIT, without any additional\nterms or conditions.\n", "release_dates": []}, {"name": "solana-voib-demo", "description": "Voice over Internet & Blockchain (VoIB) demo", "language": "Rust", "license": null, "readme": "# Solana VoIB Demo\n\n## Introduction\n\nDemonstration of the tokenization business model to implement Voice over\nInternet & Blockchain (VoIB).\n\n### Video Streaming Demo\nVideo streaming devices (currently Raspberry Pis) implement thin clients. They\ncommunicate with a *gatekeeper* application on a network gateway, which will open\na connection upon request from a device. The data is not part of the transaction\nto Solana, so the data itself is not stored on chain. Devices pay for data before\nopening a connection by funding an account controlled by the bandwidth-prepay\nprogram. The gatekeeper can send instructions to the program either spending the\naccount funds as data is sent, or refunding any remaining balance once the\nconnection is closed. The [client-tester](./client-tester) and\n[tcp-echo-server](./tcp-echo-server) modules can interact with the gatekeeper\ncode to test data transmission locally, not requiring any extra hardware.\n\nThe video demo right now is designed to run on a Raspberry Pi connected to an\nofficial [Raspberry Pi Foundation camera v2](https://www.raspberrypi.org/products/camera-module-v2/),\nand an official [Raspberry Pi Foundation touchscreen](https://www.raspberrypi.org/products/raspberry-pi-touch-display/).\n\n## Installing\n\nTo build the UI, you need to install gtk. Instructions [here](http://gtk-rs.org/docs/requirements.html).\n\n\n### Installing ffmpeg and mpv\n\n`ffmpeg` and `mpv` need to be installed on the Pis for the video demo. We run\nwith versions built on the Pis by [this script](https://www.raspberrypi.org/forums/viewtopic.php?p=1249934),\nbut have had varying success with the script. We have had to resort to copying\nsuccessful builds onto unsuccessful machines. Versions of `ffmpeg` and `mpv`\ninstalled by other methods such as `apt-get` will likely work, but may have\nhigher latency and/or CPU usage.\n\n\n## Cross compiling for the Raspberry Pi\n\nWhile it is possible to build the project on a Raspberry Pi directly using\nCargo, it will take a very long time (Initial build >30 min on a Pi 3 B+).\nInstead, you can easily build a cross compiler with Docker, then use `scp` or\nsome other method to transfer the binaries to the Pis.\n\nTo start, install [Docker](https://www.docker.com/) and ensure that it is\nrunning in the background.\n\nNext, navigate to the [docker-xc](./docker-xc) directory and run (This will\ntake a while)\n\n```shell\n$ docker build -t rust-pi-xc .\n```\n\nThis builds a new docker image called `rust-pi-xc` that is ready to cross\ncompile any rust project to Cargo's `armv7-unknown-linux-gnueabihf` target.\n\nNow, any time you want to cross compile the `stream-video` package, go to the\n[stream-video](./stream-video) directory and run\n\n```shell\n$ docker run -v </absolute/path/to/repo/root>:/mnt -v </absolute/path/to/$HOME/.cargo/registry>:/root/.cargo/registry rust-pi-xc /mnt/stream-video/rpxc.sh\n```\n\nThis runs `rpxc.sh` in the Docker container. The script tells the instance of\nCargo in the container to cross compile the `stream-video` project. The script\nneeds to be adapted to build other projects. `docker run`'s `-v` options link\ndirectories in the host system to directories in the container, so that the\nbuild files persist. Once the compile is done, the binaries can be found in\n`target/armv7-unknown-linux-gnueabihf/debug/`. The rest of this guide assumes\nthat you have copied the compiled binaries to the `target/xc/` directory in the\nproject directory on the Pis.\n\n\n## Setting up the video demo\n\n### Deploying the bandwidth prepay program\n\nThis repository depends on a [Solana](https://github.com/solana-labs/solana)\ncluster, currently synced to v0.18.0. On the machine that will run the solana\ncluster, navigate to `solana-voib-demo` root and clone `solana` with the command:\n\n```shell\n$ git clone --branch v0.18.0 https://github.com/solana-labs/solana.git\n```\n\nThen build solana:\n\n```shell\n$ cd solana && cargo build --all\n```\n\nDeploy the bandwidth-prepay program:\n\n```shell\n$ cd bandwidth-prepay-program\n$ ./deploy.sh\n```\n\n### Setting up keypairs\n\nThe initiator, the gatekeeper, and the provider all need keypairs for the demo.\nThe initiator can be an instance of [client-tester](./client-tester) for a local\ndemo, or it can be an instance of [stream-video](./stream-video) running on a Pi\nfor a video demo.\n\nTo setup the device's pubkey, navigate to either the `client-tester` directory\nlocally, or the `stream-video` directory on a Pi and run\n\n```shell\n$ ./setup.sh\n```\nThis puts the device's id.json into the `config-local` direcory.\n\nTo setup the gatekeeper's pubkey, navigate to the `gatekeeper` directory and run\n\n```shell\n$ ./setup.sh gatekeeper\n```\nThis puts the gatekeeper's id.json and pubkey.json into the `config-local` directory.\n\nTo setup the provider's pubkey, run\n\n```shell\n$ ./setup.sh provider\n```\nThis puts the provider's id.json and pubkey.json in gatekeeper/config-local/\n\nBoth the `gatekeeper-pubkey.json` and `provider-pubkey.json` files need to be\ncopied to the `client-tester`'s or the `stream-video`'s `config-local` directory.\n\n\n## Running the video demo\n\nThe video demo runs in five parts (and should be started in this order):\n1. The solana cluster\n2. The provider drone\n3. The gatekeeper program\n4. The video listener\n5. The video connecter\n\nThe video receiver and sender should run on separate Pis. The gatekeeper and\ncluster can be run on the same computer, or separate ones. A complete local\ndemo, sending zeros instead of video data, can be run by replacing the video\nreceiver with [tcp-echo-server](./tcp-echo-server), and replacing the video\nsender with [client-tester](./client-tester).\n\n### Starting the Solana cluster\n\nSee the [Solana Book](https://solana-labs.github.io/book/getting-started.html)\nfor instructions on how to start a testnet from the `solana` repo. You can use\neither a single-node or multi-node testnet.\n\n### Starting the provider drone\n\nThe provider drone distributes lamports from the provider's account to clients\nupon request.\n\nIn a new shell, navigate to the `provider-drone` directory and run\n\n```shell\n$ cargo run -- -k ../gatekeeper/config-local/provider-id.json\n```\n\nFor useful messages from the drone, run with the environment variable\n```shell\nRUST_LOG=provider_drone=info,solana_drone::drone=info\n```\n\n### Starting the gatekeeper program\n\nIn a new shell, navigate to the `gatekeeper` directory and run\n\n```shell\n$ cargo run --bin gatekeeper -- -k config-local/gatekeeper-id.json\n```\nThis will listen on the default port of 8122.\n\nYou can get a complete set of command line options by running\n\n```shell\n$ cargo run --bin gatekeeper -- -h\n```\n\nIf you would like account balance change notifications and other debug messages,\nrun with the environment variable\n\n```shell\nRUST_LOG=gatekeeper,gatekeeper::contract=info\n```\n\n### Starting the video listener\n\n#### Running the GUI\n\nThe GUI operates bi-directionally, so it can act as either the video listener,\nor the video connecter, and can switch while running. A connection can be\nstarted from the GUI by pressing one of the call buttons at the top of the\nscreen. To start it, begin by navigating to the `stream-video` directory. Then,\nensure that the settings in `config-local/config.toml` are correct for your\nsetup. If you do not have a `config-local/config.toml`, use\n`template-config.toml` as a template in creating one. Finally, run the GUI in\none of the following ways:\n\n1. Running the cross-compiled version\n```shell\n$ DISPLAY=:0.0 ../target/xc/stream_gui\n```\n\n2. Running a locally compiled version\n```shell\n$ DISPLAY=:0.0 cargo run --bin stream_gui\n```\n\nTo get helpful debug messages, run with\n```shell\nRUST_LOG=stream_gui,stream_video::stream_video=debug\n```\n\n#### Running the CLI\n\nOn the Pi, navigate to the `stream-video` directory and run one of the\nfollowing:\n\n1. Running the cross-compiled version\n```shell\n$ ../target/xc/stream_cli listen\n```\n\n2. Running a locally compiled version\n```shell\n$ cargo run --bin stream_cli -- listen\n```\n\nTo get helpful debug messages, run with\n```shell\nRUST_LOG=stream_cli,stream_video::stream_video=debug\n```\n\n#### Local demo\n\nThe local demo replacement is to run `cargo run -- -p <PORT>` from the\n`tcp-echo-server` directory. `<PORT>` specifies the listening port.\n\n### Starting the video connecter\n\n#### Running the GUI\n\nSee \"Running the GUI\" in \"Starting the video listener\"\n\n#### Running the CLI\n\nOn the Pi, navigate to the `stream-video` directory and run one of the\nfollowing:\n\n1. Running the cross-compiled version\n```shell\n$ ../target/xc/stream_cli connect -g </path/to/gatekeeper-pubkey.json> -v </path/to/provider-pubkey.json> -k </path/to/id.json> -G <GATEKEEPER_ADDRESS:PORT> -f <FULLNODE_ADDRESS> -l <NUMBER> -d <DESTINATION_ADDRESS:PORT>\n```\n\n2. Running a locally compiled version\n```shell\n$ cargo run --bin stream_cli -- connect -g </path/to/gatekeeper-pubkey.json> -v </path/to/provider-pubkey.json> -k </path/to/id.json> -G <GATEKEEPER_ADDRESS:PORT> -f <FULLNODE_ADDRESS> -l <NUMBER> -d <DESTINATION_ADDRESS:PORT>\n```\nwhere `<FULLNODE_ADDRESS>` is the IP address of a node in the solana cluster,\n`<NUMBER>` is the number of tokens to prepay into the contract, and\n`<DESTINATION_ADDRESS:PORT>` is the address and port of the video listener.\n\n\nYou can get a complete set of command line options by running\n\n```shell\n$ cargo run --bin stream_cli -- connect -h\n```\n\nTo get helpful debug messages, run with\n```shell\nRUST_LOG=stream_cli,stream_video::stream_video=debug\n```\n\n#### Local demo\n\nThe local demo replacement is to run the `client-tester`. The arguments are the\nsame, with the addition of the optional arguments `-n <NUMBER>` to specify the\nnumber of packets to send before closing the connection, and `-s <SIZE>` to\nspecity the size in bytes of the packets. A complete set of its CLI options can\nbe found by running `cargo run -- -h` from the `client-tester` directory.\n\n### Observing provider funds\n\nYou can optionally observe changes to the provider account's balance by\nnavigating to the `gatekeeper` directory and running\n\n```shell\n$ cargo run --bin provider-account -- -f <FULLNODE ADDRESS> -p </path/to/provider-pubkey.json>\n```\nwhere `<FULLNODE_ADDRESS>` is the IP address of a node in the solana cluster.\n", "release_dates": []}, {"name": "solana-web3.js", "description": "Solana JavaScript SDK", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "[![npm][npm-image]][npm-url]\n[![npm-downloads][npm-downloads-image]][npm-url]\n[![semantic-release][semantic-release-image]][semantic-release-url]\n<br />\n[![code-style-prettier][code-style-prettier-image]][code-style-prettier-url]\n\n[code-style-prettier-image]: https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\n[code-style-prettier-url]: https://github.com/prettier/prettier\n[npm-downloads-image]: https://img.shields.io/npm/dm/@solana/web3.js.svg?style=flat\n[npm-image]: https://img.shields.io/npm/v/@solana/web3.js.svg?style=flat\n[npm-url]: https://www.npmjs.com/package/@solana/web3.js\n[semantic-release-image]: https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg\n[semantic-release-url]: https://github.com/semantic-release/semantic-release\n\n# Solana JavaScript SDK\n\nUse this to interact with accounts and programs on the Solana network through the Solana [JSON RPC API](https://solana.com/docs/rpc).\n\n## Installation\n\n### For use in Node.js or a web application\n\n```\n$ npm install --save @solana/web3.js\n```\n\n### For use in a browser, without a build system\n\n```html\n<!-- Development (un-minified) -->\n<script src=\"https://unpkg.com/@solana/web3.js@latest/lib/index.iife.js\"></script>\n\n<!-- Production (minified) -->\n<script src=\"https://unpkg.com/@solana/web3.js@latest/lib/index.iife.min.js\"></script>\n```\n\n## Documentation and examples\n\n-   [The Solana Cookbook](https://solanacookbook.com/) has extensive task-based documentation using this library.\n-   For more detail on individual functions, see the [latest API Documentation](https://solana-labs.github.io/solana-web3.js)\n\n## Getting help\n\nHave a question or a problem? Check the [Solana Stack Exchange](https://solana.stackexchange.com) to see if anyone else is having the same one. If not, [post a new question](https://solana.stackexchange.com/questions/ask).\n\nInclude:\n\n-   A detailed description of what you're trying to achieve\n-   Source code, if possible\n-   The text of any errors you encountered, with stacktraces if available\n\n## Compatibility\n\nThis library requires a JavaScript runtime that supports [`BigInt`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt) and the [exponentiation operator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Exponentiation). Both are supported in the following runtimes:\n\n-   Browsers, by [release date](https://caniuse.com/bigint):\n    -   Chrome: May 2018\n    -   Firefox: July 2019\n    -   Safari: September 2020\n    -   Mobile Safari: September 2020\n    -   Edge: January 2020\n    -   Opera: June 2018\n    -   Samsung Internet: April 2019\n-   Runtimes, [by version](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt):\n    -   Deno: >=1.0\n    -   Node: >=10.4.0\n-   React Native:\n    -   \\>=0.7.0 using the [Hermes](https://reactnative.dev/blog/2022/07/08/hermes-as-the-default) engine ([integration guide](https://solanacookbook.com/integrations/react-native.html#how-to-use-solana-web3-js-in-a-react-native-app)):\n\n## Development environment setup\n\n### Testing\n\n#### Unit tests\n\nTo run the full suite of unit tests, execute the following in the root:\n\n```shell\n$ npm test\n```\n\n#### Integration tests\n\nIntegration tests require a validator client running on your machine.\n\nTo install a test validator:\n\n```shell\n$ npm run test:live-with-test-validator:setup\n```\n\nTo start the test validator and run all of the integration tests in live mode:\n\n```shell\n$ cd packages/library-legacy\n$ npm run test:live-with-test-validator\n```\n\n### Speed up build times with remote caching\n\nCache build artifacts remotely so that you, others, and the CI server can take advantage of each others' build efforts.\n\n1. Log the Turborepo CLI into the Solana Vercel account\n    ```shell\n    pnpm turbo login\n    ```\n2. Link the repository to the remote cache\n    ```shell\n    pnpm turbo link\n    ```\n\n## Contributing\n\nIf you found a bug or would like to request a feature, please [file an issue](https://github.com/solana-labs/solana-web3.js/issues/new). If, based on the discussion on an issue you would like to offer a code change, please make a [pull request](https://github.com/solana-labs/solana-web3.js/compare). If neither of these describes what you would like to contribute, read the [getting help](#getting-help) section above.\n\n## Disclaimer\n\nAll claims, content, designs, algorithms, estimates, roadmaps,\nspecifications, and performance measurements described in this project\nare done with the Solana Foundation's (\"SF\") best efforts. It is up to\nthe reader to check and validate their accuracy and truthfulness.\nFurthermore nothing in this project constitutes a solicitation for\ninvestment.\n\nAny content produced by SF or developer resources that SF provides, are\nfor educational and inspiration purposes only. SF does not encourage,\ninduce or sanction the deployment, integration or use of any such\napplications (including the code comprising the Solana blockchain\nprotocol) in violation of applicable laws or regulations and hereby\nprohibits any such deployment, integration or use. This includes use of\nany such applications by the reader (a) in violation of export control\nor sanctions laws of the United States or any other applicable\njurisdiction, (b) if the reader is located in or ordinarily resident in\na country or territory subject to comprehensive sanctions administered\nby the U.S. Office of Foreign Assets Control (OFAC), or (c) if the\nreader is or is working on behalf of a Specially Designated National\n(SDN) or a person subject to similar blocking or denied party\nprohibitions.\n\nThe reader should be aware that U.S. export control and sanctions laws\nprohibit U.S. persons (and other persons that are subject to such laws)\nfrom transacting with persons in certain countries and territories or\nthat are on the SDN list. As a project based primarily on open-source\nsoftware, it is possible that such sanctioned persons may nevertheless\nbypass prohibitions, obtain the code comprising the Solana blockchain\nprotocol (or other project code or applications) and deploy, integrate,\nor otherwise use it. Accordingly, there is a risk to individuals that\nother persons using the Solana blockchain protocol may be sanctioned\npersons and that transactions with such persons would be a violation of\nU.S. export controls and sanctions law. This risk applies to\nindividuals, organizations, and other ecosystem participants that\ndeploy, integrate, or use the Solana blockchain protocol code directly\n(e.g., as a node operator), and individuals that transact on the Solana\nblockchain through light clients, third party interfaces, and/or wallet\nsoftware.\n", "release_dates": ["2024-03-02T11:42:08Z", "2024-02-07T02:46:26Z", "2024-01-15T20:52:34Z", "2024-01-11T10:54:47Z", "2024-01-05T18:10:53Z", "2023-11-11T03:29:27Z", "2023-11-07T14:21:58Z", "2023-11-06T18:38:49Z", "2023-10-26T16:17:08Z", "2023-10-19T14:56:31Z", "2023-10-09T07:46:31Z", "2023-10-06T16:26:54Z", "2023-10-06T10:41:11Z", "2023-10-06T09:42:46Z", "2023-10-06T09:38:13Z", "2023-10-06T09:32:42Z", "2023-10-06T09:21:12Z", "2023-10-06T08:42:50Z", "2023-10-06T08:38:26Z", "2023-10-06T08:16:01Z", "2023-10-04T14:14:30Z", "2023-10-04T13:24:57Z", "2023-09-12T11:13:12Z", "2023-08-10T15:13:46Z", "2023-08-04T16:31:57Z", "2023-07-31T16:23:38Z", "2023-07-28T23:31:36Z", "2023-07-07T04:45:10Z", "2023-05-31T21:39:41Z", "2023-05-28T03:24:15Z"]}, {"name": "solminer", "description": "Cross-platform Solana Replicator UI \u26cf\ufe0f ", "language": "JavaScript", "license": null, "readme": "[![Travis build status][travis-image]][travis-url]\n[![Appveyor build status][appveyor-image]][appveyor-url]\n\n[travis-image]: https://travis-ci.org/solana-labs/solminer.svg?branch=master\n[travis-url]: https://travis-ci.org/solana-labs/solminer\n[appveyor-image]: https://ci.appveyor.com/api/projects/status/tcu6rndl1cf8klqn/branch/master?svg=true\n[appveyor-url]: https://ci.appveyor.com/project/solana-labs/solminer/history\n\n## Solminer\nCross-platform Solana Replicator UI\n\n### Log file\nSolminer writes a log of its activities, which can be a useful debugging aid:\n* macOS: `~/Library/Logs/solminer/log.log`\n* Windows: `%APPDATA%\\solminer\\log.log`\n", "release_dates": ["2019-10-21T23:19:34Z", "2019-09-20T20:57:15Z", "2019-09-20T18:16:02Z", "2019-09-19T21:51:55Z", "2019-09-19T14:05:26Z", "2019-09-18T19:47:49Z", "2019-09-18T03:20:15Z", "2019-09-17T20:49:25Z", "2019-09-17T00:53:22Z", "2019-09-16T20:36:28Z", "2019-08-26T19:38:39Z", "2019-08-21T16:01:29Z", "2019-07-16T04:46:15Z", "2019-07-04T04:24:44Z", "2019-07-04T02:44:32Z", "2019-07-04T00:48:26Z", "2019-07-03T20:20:02Z", "2019-07-03T17:17:58Z", "2019-07-03T06:00:24Z", "2019-07-03T05:34:32Z", "2019-07-03T00:46:15Z", "2019-07-02T23:21:15Z", "2019-07-02T05:40:39Z", "2019-06-29T00:49:16Z", "2019-06-27T22:30:45Z", "2019-06-27T18:09:39Z", "2019-06-27T17:55:31Z", "2019-06-27T07:41:58Z", "2019-06-26T19:57:05Z", "2019-06-26T18:46:56Z"]}, {"name": "spl-token-subscription", "description": null, "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": null, "release_dates": []}, {"name": "stdsimd", "description": "Rust's standard library vendor-specific APIs and run-time feature detection", "language": "HTML", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Fork of the Rust Programming Language's stdsimd library\n\nUsed by [rust-bpf-sysroot](https://github.com/solana-labs/rust-bpf-sysroot) and contains submodules, to sync use:\n\n```git clone --recurse-submodules ```\n\n---\n\nstdsimd - Rust's standard library SIMD components\n=======\n\n[![Travis-CI Status]][travis] [![Appveyor Status]][appveyor] \n\n# Crates\n\nThis repository contains two main crates:\n\n* [![core_arch_crate_badge]][core_arch_crate_link]\n  [![core_arch_docs_badge]][core_arch_docs_link]\n  [`core_arch`](crates/core_arch/README.md) implements `core::arch` - Rust's\n  core library architecture-specific intrinsics, and\n  \n* [![std_detect_crate_badge]][std_detect_crate_link]\n  [![std_detect_docs_badge]][std_detect_docs_link]\n  [`std_detect`](crates/std_detect/README.md) implements `std::detect` - Rust's\n  standard library run-time CPU feature detection.\n\nThe `std::simd` component now lives in the\n[`packed_simd`](https://github.com/rust-lang-nursery/packed_simd) crate.\n\n# How to do a release\n\nTo do a release of the `core_arch` and `std_detect` crates, \n\n* bump up the version appropriately,\n* comment out the `dev-dependencies` in their `Cargo.toml` files (due to\n  https://github.com/rust-lang/cargo/issues/4242),\n* publish the crates.\n\n[travis]: https://travis-ci.com/rust-lang-nursery/stdsimd\n[Travis-CI Status]: https://travis-ci.com/rust-lang-nursery/stdsimd.svg?branch=master\n[appveyor]: https://ci.appveyor.com/project/rust-lang-libs/stdsimd/branch/master\n[Appveyor Status]: https://ci.appveyor.com/api/projects/status/ix74qhmilpibn00x/branch/master?svg=true\n[core_arch_crate_badge]: https://img.shields.io/crates/v/core_arch.svg\n[core_arch_crate_link]: https://crates.io/crates/core_arch\n[core_arch_docs_badge]: https://docs.rs/core_arch/badge.svg\n[core_arch_docs_link]: https://docs.rs/core_arch/\n[std_detect_crate_badge]: https://img.shields.io/crates/v/std_detect.svg\n[std_detect_crate_link]: https://crates.io/crates/std_detect\n[std_detect_docs_badge]: https://docs.rs/std_detect/badge.svg\n[std_detect_docs_link]: https://docs.rs/std_detect/\n", "release_dates": []}, {"name": "superstruct", "description": "A simple and composable way to validate data in JavaScript (or TypeScript).", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": []}, {"name": "sync_test", "description": "For developing a Github Action to sync solana-labs/solana from anza-xyz/agave ", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": null, "release_dates": []}, {"name": "token-aggregator", "description": "Aggregates tokens listed in onchain token registry", "language": "TypeScript", "license": null, "readme": "# spl-token-aggregator\n\nAggregates and serves JSON token list of onchain token data. Token data is stored in SPL Name Service under the [token name registry](https://docs.bonfida.org/help/tokens).\n\n## Installation\n\n```bash\nyarn install\n```\n\n## Build\n\n```bash\nyarn run build\n```\n\n## Usage\n\n```bash\nyarn run start\n```\n\n## Token List\n[https://token-list.solana.com/solana.tokenlist.json](https://token-list.solana.com/solana.tokenlist.json)\n\n# Disclaimer\n\nAll claims, content, designs, algorithms, estimates, roadmaps,\nspecifications, and performance measurements described in this project\nare done with the Solana Foundation's (\"SF\") best efforts. It is up to\nthe reader to check and validate their accuracy and truthfulness.\nFurthermore nothing in this project constitutes a solicitation for\ninvestment.\n\nAny content produced by SF or developer resources that SF provides, are\nfor educational and inspiration purposes only. SF does not encourage,\ninduce or sanction the deployment, integration or use of any such\napplications (including the code comprising the Solana blockchain\nprotocol) in violation of applicable laws or regulations and hereby\nprohibits any such deployment, integration or use. This includes use of\nany such applications by the reader (a) in violation of export control\nor sanctions laws of the United States or any other applicable\njurisdiction, (b) if the reader is located in or ordinarily resident in\na country or territory subject to comprehensive sanctions administered\nby the U.S. Office of Foreign Assets Control (OFAC), or (c) if the\nreader is or is working on behalf of a Specially Designated National\n(SDN) or a person subject to similar blocking or denied party\nprohibitions.\n\nThe reader should be aware that U.S. export control and sanctions laws\nprohibit U.S. persons (and other persons that are subject to such laws)\nfrom transacting with persons in certain countries and territories or\nthat are on the SDN list. As a project based primarily on open-source\nsoftware, it is possible that such sanctioned persons may nevertheless\nbypass prohibitions, obtain the code comprising the Solana blockchain\nprotocol (or other project code or applications) and deploy, integrate,\nor otherwise use it. Accordingly, there is a risk to individuals that\nother persons using the Solana blockchain protocol may be sanctioned\npersons and that transactions with such persons would be a violation of\nU.S. export controls and sanctions law. This risk applies to\nindividuals, organizations, and other ecosystem participants that\ndeploy, integrate, or use the Solana blockchain protocol code directly\n(e.g., as a node operator), and individuals that transact on the Solana\nblockchain through light clients, third party interfaces, and/or wallet\nsoftware.\n", "release_dates": []}, {"name": "token-list", "description": "The community maintained Solana token registry", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "---\n# \ud83d\udea8\ud83d\udea8\ud83d\udea8This repository is EOL \ud83d\udea8\ud83d\udea8\ud83d\udea8\n## Read below for instructions on new token metadata flow\n---\n\nAs of June 20th, this repository will be archived and will receive no more updates. The repository will be set to read-only and the npm package will still exist at `@solana/spl-token-registry`.\n\n## Adding a New Token\n\nYou can use one of two tools at the time of writing:\n\n1. [Strata Protocol Token Launchpad](https://app.strataprotocol.com/launchpad/manual/new)\n2. [Token Creator Demo](https://token-creator-lac.vercel.app/)\n\nAll new token metadata will be added using Metaplex Fungible Token Metadata. The steps to add new Fungible Token Metadata are as follows:\n\n1. Use `CreateMetadataV2` instruction from Metaplex token metadata to create new metadata for token.\n2. Make sure you use the correct format for the token metadata.\n3. You must have mint authority in order to create or update the metadata\n\nThe token metadata for Metaplex Metadata Schema is in the following format:\n\n```json\n{\n  \"name\": \"TOKEN_NAME\", \n  \"symbol\": \"TOKEN_SYMBOL\",\n  \"uri\": \"TOKEN_URI\",\n  \"sellerFeeBasisPoints\": 0,\n  \"creators\": null,\n  \"collection\": null,\n  \"uses\": null\n}\n```\n\nThe `TOKEN_URI` must point to a file with the following format:\n\n```json\n{\n  \"name\": \"TOKEN_NAME\",\n  \"symbol\": \"TOKEN_SYMBOL\",\n  \"description\": \"TOKEN_DESC\",\n  \"image\": \"TOKEN_IMAGE_URL\"\n}\n```\n\nWhere `TOKEN_IMAGE_URL` is the image url.\n\nAn example of the `TOKEN_URI`: https://token-creator-lac.vercel.app/token_metadata.json\n\nWhich resolves to:\n\n```json\n{\n  \"name\": \"A test token\",\n  \"symbol\": \"TEST\",\n  \"description\": \"Fully for testing purposes only\",\n  \"image\": \"https://token-creator-lac.vercel.app/token_image.png\"\n}\n```\n\n## Updating Token Metadata\n\nTo update token metadata you must use `createUpdateMetadataAccountV2Instruction` in `@metaplex-foundation/js` in order to update an existing token's metadata.\n\nWhile updating, you provide the same details as when creating.\n\n## Tools for Adding/Updating/Migrating\n\nUpdate/migrate token metadata using [Strata Protocol update token tool](https://app.strataprotocol.com/edit-metadata).\n\nA tutorial for adding/updating metadata can be found at the [Token-Creator demo](https://github.com/jacobcreech/Token-Creator).\n\n\n## Reading Legacy Token-list\n\n`@solana/spl-token-registry`\n\n[![npm](https://img.shields.io/npm/v/@solana/spl-token-registry)](https://unpkg.com/@solana/spl-token-registry@latest/) [![GitHub license](https://img.shields.io/badge/license-APACHE-blue.svg)](https://github.com/solana-labs/token-list/blob/b3fa86b3fdd9c817139e38641d46c5a892542a52/LICENSE)\n\nSolana Token Registry is a package that allows application to query for list of tokens.\nThe JSON schema for the tokens includes: chainId, address, name, decimals, symbol, logoURI (optional), tags (optional), and custom extensions metadata.\n\n### Installation\n\n```bash\nnpm install @solana/spl-token-registry\n```\n\n```bash\nyarn add @solana/spl-token-registry\n```\n\n### Examples\n\n#### Query available tokens\n\n```typescript\nnew TokenListProvider().resolve().then((tokens) => {\n  const tokenList = tokens.filterByClusterSlug('mainnet-beta').getList();\n  console.log(tokenList);\n});\n```\n\n#### Render icon for token in React\n\n```typescript jsx\nimport React, { useEffect, useState } from 'react';\nimport { TokenListProvider, TokenInfo } from '@solana/spl-token-registry';\n\n\nexport const Icon = (props: { mint: string }) => {\n  const [tokenMap, setTokenMap] = useState<Map<string, TokenInfo>>(new Map());\n\n  useEffect(() => {\n    new TokenListProvider().resolve().then(tokens => {\n      const tokenList = tokens.filterByChainId(ENV.MainnetBeta).getList();\n\n      setTokenMap(tokenList.reduce((map, item) => {\n        map.set(item.address, item);\n        return map;\n      },new Map()));\n    });\n  }, [setTokenMap]);\n\n  const token = tokenMap.get(props.mint);\n  if (!token || !token.logoURI) return null;\n\n  return (<img src={token.logoURI} />);\n\n```\n\n# Disclaimer\n\nAll claims, content, designs, algorithms, estimates, roadmaps,\nspecifications, and performance measurements described in this project\nare done with the Solana Foundation's (\"SF\") good faith efforts. It is up to\nthe reader to check and validate their accuracy and truthfulness.\nFurthermore nothing in this project constitutes a solicitation for\ninvestment.\n\nAny content produced by SF or developer resources that SF provides, are\nfor educational and inspiration purposes only. SF does not encourage,\ninduce or sanction the deployment, integration or use of any such\napplications (including the code comprising the Solana blockchain\nprotocol) in violation of applicable laws or regulations and hereby\nprohibits any such deployment, integration or use. This includes use of\nany such applications by the reader (a) in violation of export control\nor sanctions laws of the United States or any other applicable\njurisdiction, (b) if the reader is located in or ordinarily resident in\na country or territory subject to comprehensive sanctions administered\nby the U.S. Office of Foreign Assets Control (OFAC), or (c) if the\nreader is or is working on behalf of a Specially Designated National\n(SDN) or a person subject to similar blocking or denied party\nprohibitions.\n\nThe reader should be aware that U.S. export control and sanctions laws\nprohibit U.S. persons (and other persons that are subject to such laws)\nfrom transacting with persons in certain countries and territories or\nthat are on the SDN list. As a project based primarily on open-source\nsoftware, it is possible that such sanctioned persons may nevertheless\nbypass prohibitions, obtain the code comprising the Solana blockchain\nprotocol (or other project code or applications) and deploy, integrate,\nor otherwise use it. Accordingly, there is a risk to individuals that\nother persons using the Solana blockchain protocol may be sanctioned\npersons and that transactions with such persons would be a violation of\nU.S. export controls and sanctions law. This risk applies to\nindividuals, organizations, and other ecosystem participants that\ndeploy, integrate, or use the Solana blockchain protocol code directly\n(e.g., as a node operator), and individuals that transact on the Solana\nblockchain through light clients, third party interfaces, and/or wallet\nsoftware.\n", "release_dates": []}, {"name": "token-ops", "description": "Scripts and tools for token accounting and operation", "language": "Shell", "license": null, "readme": "# token-ops\nScripts and tools for token accounting and operation\n", "release_dates": []}, {"name": "tour-de-sol", "description": "Tour de SOL", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "## Solana's Tour de SOL\nPlease see https://docs.solana.com/tour-de-sol/ for information on how to\nparticipate in Tour de SOL.\n\n### Winner Tool\nFor transparency, we have included the tool we will be using for calculating the\nwinners of the quantitative reward categories. You can find more details on how\nwinners are calculated by reading the [forum announcement].\n\n[forum announcement]: https://forums.solana.com/t/tour-de-sol-stage-1-preliminary-compensation-design/79\n\n```bash\n$ solana-tds-winner-tool --ledger /path/to/tds/ledger \\\n    --baseline-validator boot1Z6jb15CLqpaMTn2CxktktwZpRAVAgHZEW6SxQ7 \\\n    --exclude-pubkey rpc1io1gmhuEq26wTBARGJfGGw48S7GYaHfKVEf9Dvv \\\n    --exclude-pubkey va11wrZ2pD668e2dKXohuXiyALPxfVQjjH7zzpePavQ \\\n    --exclude-pubkey va12u4o9DipLEB2z4fuoHszroq1U9NcAB9aooFDPJSf \\\n    --exclude-pubkey va13en4eUarJtf8mbhFF386nvQh12g6ESkjoR7Ji8hm \\\n    --exclude-pubkey 5n8KCdzqtvTnhkvCrFR7errH6ZUp11kL97r2awXkfzFe \\\n    --exclude-pubkey 7suRNpX7bJsXphHJtBv4ZsLjJZ1dTGeX256pLqJZdEAm \\\n    --exclude-pubkey 2te46rxywMdCNdkvjumiBBPQoVczJFxhxEaxFavQNqe3 \\\n    --exclude-pubkey ChorusXqjLC2NbiStKR6k9WoD7wu6TVTtFG8qCL5XBVa \\\n    --exclude-pubkey GeZ5PrJi9muVCJiJAaFBNGoCEdxGEqTp7L2BmT2WTTy1 \\\n    --exclude-pubkey Fe5sLQAAT7RBT8mcH1AAGCbExJQcYxcwXvp1GjrGbvxs \\\n    --exclude-pubkey 44e8VyWoyZSE2oYHxMHMedAiHkGJqJgPd3tdt6iKoAFL \\\n    --exclude-pubkey Ez4iUU87ViJLCnmSy1t1Ti3DLoysFXiBseNfnRfoehyY \\\n    --exclude-pubkey GUdGALCHQBeqkNc2ZAht3tBXab1N5u9qJC3PAzpL54r7 \\\n    --exclude-pubkey HavuVVDXXsJqMzPwQ4KcF5kFm2xqjbChhyi1bgGeCQif \\\n    --exclude-pubkey pbAxyqHHPMwgEjv8kmjGxysk9rhNtN7q22eAjReq6Hj\n```\n", "release_dates": []}, {"name": "twamm", "description": "Solana twamm reference implementation", "language": "TypeScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Solana TWAMM\n\n## Introduction\n\nPermissionless TWAMM (time-weighted average price market maker) service helps traders on Solana efficiently execute large orders. It pools large orders together, breaks them down into small pieces, and executes them over a specified time interval. Orders with opposite sides are internally matched using the oracle price, and net outstanding liquidity is settled via the best possible execution route available with Jupiter. Additionally, market makers (or literally anyone) have the opportunity to settle the outstanding net balance at the oracle price (i.e. perform a swap against TWAMM pools), saving on swap fees for themselves and the protocol.\n\nProject goals:\n\n1. Reduce the price impact of large orders.\n2. Fill orders close to the average price over the specified time window.\n3. Reduce complexity and lower execution fees compared to the manual approach.\n4. Let users retain full custody of their tokens while orders are executed.\n5. Reduce adverse selection by providing full transparency.\n\nThe original idea belongs to [Paradigm](https://www.paradigm.xyz/2021/07/twamm). But instead of relying on internal pools that may lack liquidity, this project leverages Jupiter to settle the net outstanding balance as well as opens the opportunity to any liquidity providers to settle trades at the oracle price.\n\nService consists of three main pieces: web UI, backend, and the on-chain program.\n\n**Web UI** is an example user interface that displays active user orders, trade progress, min/max/avg fill price and allows to submit order instructions to the on-chain program.\n\n**Backend** is a Typescript program that triggers on-chain cranks. The backend program doesn't store any state and serves as an example of how permissionless cranks can be executed.\n\n**On-chain program** handles order instructions, stores user and token pairs related info, and holds tokens to be swapped and fees in custodies.\n\n### Design considerations:\n\n1. Orders can be canceled in full or partially at any given time. In this case, the result of the partially executed trade will be returned. It is also possible to top-up existing order.\n2. When the order is complete, the exchanged liquidity needs to be withdrawn explicitly. But this operation is permissionless, so it can be executed by the user or a crank job. Recovered rent SOL can be used as an incentive.\n3. To reduce fees, the number of swaps, and price impact, all orders for all time intervals are pooled together. Matching buy/sell amounts are exchanged based on the oracle price. The swap amount is based on the net (buy-sell) difference.\n4. Cranks are permissionless by default but can optionally require authority. Crank authority is set per token pair to reduce the number of accounts passed to the on-chain program.\n5. To minimize cumulative network fees and loss due to rounding, cranks frequency is based on the amount swapped in each iteration. It ranges from once per second to several times per target time interval. Minimum swap size is enforced and depends on time in force (TIF) period.\n6. Admin authority can initialize or modify token pair configurations or withdraw fees. There is a built-in multisig functionality.\n7. Allowed time in force (TIF) periods for new orders are configured per token pair and limited to ten different options (e.g. 5m, 15m, 1h, 4h, 12h, 24h, 1w, etc.). Available TIFs can be modified (added/deleted/modified) as long as there are no active pools for the TIF in question. Order expiration times that are displayed to the end user upon order placement are uneven and based on how long ago this particular period started on the chain. The user has the option to join the existing virtual pool (i.e., TIF period that has already started) or place a scheduled order that will start to trade upon the beginning of the next interval.\n8. One user order is tracked per TIF period per token pair. In other words, users can modify the existing order quantity or place multiple orders for the same token pair if they have different TIF.\n\n## Quick start\n\n### Setup Environment\n\n1. Clone the repository from <https://github.com/askibin/twamm.git>.\n2. Install the latest Solana tools from <https://docs.solana.com/cli/install-solana-cli-tools>. If you already have Solana tools, run `solana-install update` to get the latest compatible version.\n3. Install the latest Rust stable from <https://rustup.rs/>. If you already have Rust, run `rustup update` to get the latest version.\n4. Install the latest Anchor framework from <https://www.anchor-lang.com/docs/installation>. If you already have Anchor, run `avm update` to get the latest version.\n\n### Build\n\nFirst, generate a new key for the program address with `solana-keygen new -o <PROG_ID_JSON>`. Then replace the existing program ID with the newly generated address in `Anchor.toml` and `programs/twamm/src/lib.rs`.\n\nAlso, ensure the path to your wallet in `Anchor.toml` is correct. Alternatively, when running Anchor deploy or test commands, you can specify your wallet with `--provider.wallet` argument. The wallet's pubkey will be set as an upgrade authority upon initial deployment of the program. It is strongly recommended to make upgrade authority a multisig when deploying to the mainnet.\n\nTo build the program run `anchor build` command from the `twamm` directory:\n\n```sh\ncd twamm\nanchor build\n```\n\n### Test\n\nUnit tests are executed with the `cargo test` command:\n\n```sh\ncargo test -- --nocapture\n```\n\nIntegration tests can be started as follows:\n\n```sh\nnpm install\nanchor test -- --features test\n```\n\nBy default, integration tests are executed on a local validator, so it won't cost you any SOL.\n\n### Deploy\n\nTo deploy the program to the devnet and upload the IDL use the following commands:\n\n```sh\nanchor deploy --provider.cluster devnet --program-keypair <PROG_ID_JSON>\nanchor idl init --provider.cluster devnet --filepath ./target/idl/twamm.json <PROGRAM ID>\n```\n\n### Initialize\n\nTo initialize the program, you need to execute `init` instruction and then `initTokenPair` for each supported token pair. See `tests/1_basics.ts` for examples.\n\n### UI\n\nUI is built using NextJS, and its deployment is the same as for any similar app: [NextJS Deployment](https://nextjs.org/docs/deployment).\n\nTo launch a local instance for development purposes, you can use yarn:\n\n```sh\ncd app\nyarn install\nyarn dev\n```\n\nNote: UI won't work unless the program is properly deployed and initialized!\n\n### Vercel Deployment\n\n- Fork `twamm` repository into your Github account.\n- Login to Vercel.\n- Click `Create a New Project`.\n- Click `Import` next to twamm.\n- Click `Edit` for `Root Directory` and choose `app`.\n- Choose `Next.js` for `Framework Preset`.\n\n- Set `Environment Variables`:\n\n      NEXT_PUBLIC_PROGRAM_ADDRESS - address of the deployed twamm program\n      NEXT_PUBLIC_CLUSTER_API_URL - link to your RPC node (api.mainnet-beta.com won't work due to restrictions)\n      NEXT_PUBLIC_ENABLE_TX_SIMUL - set to 0\n      NEXT_PUBLIC_MAIN_TRADE_PAIR - insert a comma-separated list of token pair' mints to exchange by default and an exchange direction after (no spaces)\n\n\nFor example:\n\n    NEXT_PUBLIC_PROGRAM_ADDRESS: TWAMdUxafgDN2BJNFaC6pND63tjdLz4AmEKBzuxtbe9\n    NEXT_PUBLIC_CLUSTER_API_URL: https://rpc.ankr.com/solana\n    NEXT_PUBLIC_ENABLE_TX_SIMUL: 0\n    NEXT_PUBLIC_MAIN_TRADE_PAIR: So11111111111111111111111111111111111111112,EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v,buy\n\nClick `Deploy`.\n\nMake sure NodeJS version in `Settings`->`General` matches the one stored in `twamm/app/.nvmrc`.\n\n### Cranks\n\nIn order for program to properly function, periodic permissionless \"crank\" transactions must be executed. An example crank script is located in `app/src/crank.ts` and can be executed as following:\n\n```\nexport ANCHOR_WALLET=<ANY FUNDED WALLET>\nnpx ts-node -P tsconfig.json app/src/crank.ts https://rpc.ankr.com/solana <TOKEN_MINT1> <TOKEN_MINT2>\n```\n\nWhere `TOKEN_MINT1` and `TOKEN_MINT2` are corresponding mints of the token pair to crank.\n\n## Support\n\nIf you are experiencing technical difficulties while working with the Twamm codebase, ask your question on [StackExchange](https://solana.stackexchange.com) (tag your question with `twamm`).\n\nIf you find a bug in the code, you can raise an issue on [Github](https://github.com/askibin/twamm). But if this is a security issue, please don't disclose it on Github or in public channels. Send information to solana.farms@protonmail.com instead.\n\n## Contributing\n\nContributions are very welcome. Please refer to the [Contributing](https://github.com/solana-labs/solana/blob/master/CONTRIBUTING.md) guidelines for more information.\n\n## License\n\nSolana TWAMM codebase is released under [Apache License 2.0](LICENSE).\n\n## Disclaimer\n\nBy accessing or using Solana TWAMM or any of its components, you accept and agree with the [Disclaimer](DISCLAIMER.md).\n", "release_dates": []}, {"name": "update-electron-app", "description": "\ud83c\udf32 A drop-in module that adds autoUpdating capabilities to Electron apps", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# update-electron-app\n\n> A drop-in module that adds autoUpdating capabilities to Electron apps\n\nPowered by the free and open-source [update.electronjs.org](https://update.electronjs.org) service.\n\n![screenshot](screenshot.png)\n\n## Requirements\n\nBefore using this module, make sure your Electron app meets these criteria:\n\n- Your app runs on macOS or Windows\n- Your app has a public GitHub repository\n- Your builds are published to GitHub Releases\n- Your builds are [code signed]\n\n## Installation\n\n```sh\nnpm i update-electron-app\n```\n\n## Usage\n\nDrop this anywhere in your main process:\n\n```js\nrequire('update-electron-app')()\n```\n\nThat's it! Here's what happens by default:\n\n- Repository URL is found in your app's `package.json` file.\n- Your app will check for updates at startup, then every ten minutes. This interval is [configurable](#API).\n- No need to wait for your app's `ready` event; the module figures that out.\n- If an update is found, it will automatically be downloaded in the background.\n- When an update is finished downloading, a dialog is displayed allowing the user to restart the app now or later.\n\nYou can also specify custom options:\n\n```js\nrequire('update-electron-app')({\n  repo: 'github-user/repo',\n  updateInterval: '1 hour',\n  logger: require('electron-log')\n})\n```\n\n## API\n\n### `update(options)`\n\nOptions:\n\n- `repo` String (optional) - A GitHub repository in the format `owner/repo`. Defaults to your `package.json`'s `\"repository\"` field\n- `host` String (optional) - Defaults to `https://update.electronjs.org`\n- `updateInterval` String (optional) - How frequently to check for updates. Defaults to `10 minutes`. Minimum allowed interval is `5 minutes`.\n- `logger` Object (optional) - A custom logger object that defines a `log` function. Defaults to `console`. See [electron-log](https://github.com/megahertz/electron-log), a module that aggregates logs from main and renderer processes into a single file.\n- `nagUser` Boolean (optional) - Defaults to true.  When enabled the user will be\n  prompted to apply the update immediately after download.\n\n## FAQ\n\n#### What kinds of assets do I need to build?\n\nFor macOS, you'll need to build a `.zip` file and include it in your GitHub Release.\nUse [electron-forge] or [electron-installer-zip] to package your app as a zip.\n\nFor Windows, you'll need to build a `.exe` file and include it in your GitHub Release.\n\n#### Why is my app launching multiple times?\n\nWindows apps have an update process that requires multiple application restarts.\nYou can use the [electron-squirrel-startup](https://github.com/mongodb-js/electron-squirrel-startup) module to improve this\nbehavior.\n\n#### Can I use this module by uploading my private app's builds to a public GitHub repository?\n\nYes :)\n\n## License\n\nMIT\n\n## See Also\n\nIf your app is packaged with `electron-builder`, you may not need this module.\nBuilder has its own built-in mechanism for updating apps. Find out more at\n[electron.build/auto-update](https://www.electron.build/auto-update).\n\n[electron-forge]: https://github.com/electron-userland/electron-forge\n[electron-installer-zip]: https://github.com/mongodb-js/electron-installer-zip\n[code signed]: https://github.com/electron/electron/blob/master/docs/tutorial/code-signing.md\n", "release_dates": []}, {"name": "validator-tracker", "description": "https://metrics.solana.com:3000/d/jrdi4uUWz/validator-tracker", "language": "Shell", "license": null, "readme": null, "release_dates": []}, {"name": "wbtc", "description": null, "language": "TypeScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Summary\nThis is the Solana version of the WBTC contracts that enable wrapping the tokens in collaboration between merchants and a custodian 3rd party. The biggest focus of the program is to create a traceable chain of events on-chain to allow anyone to quickly be able to verify if the reserves among the custodian match the expected wrapped issuance along with matching any minting and redemtpions with their respective transactions on the native Token's chain being wrapped.\n\nUnlike in other chains, there will be just a single _smart contract_ capable of handling all the logistics given that we can rely on Solana\\`s native `Tokenkeg` program to deal with token minting/burning and `Squads` to handle the intricacies of DAO managament.\n\nThis program will have two main authorities: the `authority` is capable of changing the _authorities_ and custodian info, and the `merchant_authority` that is responsible with merchant management.\n\n# Deployment\n\nDevnet\n\nprogram - BkeUQWpHeYQDTynE3q3XjWVnmgE6WGoWgDvjfc5aSPMo\n\nmint - Hb5pJ53KeUPCkUvaDZm7Y7WafEjuP1xjD4owaXksJ86R\n\nsmall dao - 49kUge8LHR6FoYEQqE7fq8UkZTE3ouLDeFeH8NmaxKBN\n\nbig dao - BoY4qapYaJpHrbpPDmhRpMwzMTWgYJhx3ZYkViEDYLts\n\n# State\n\nThis program has four different accounts:\n\n* Config: contains basic global info regarding the state of the program like the authorities, the token mint, whether certain functionality is enabled or disabled and information related to the custodian. There is only one config per the entire program.\n* Merchant: contains wallet address and btc addresses on merchants\n* MintRequest: temporary state for mint requests. Stores info on the client, merchant and amounts.\n* RedeemRequest: temporary state for redeem requests. Stores info on the merchant and amounts.\n\n# Events\n\nIn order to make indexing easier, there are two main events surrouding the main functionality of this program:\n\n* MintEvent - Registers all the information and state changes on a given mint request. All fields are filled from the creation moment and all possible combinations of `EventKind` are used.\n* RedeemEvent - Register all the information and state changes on a given redeem request. All fields but `transaction_id` are filled from the moment of creation. `transaction_id` is only filled upon calling `approve_redeem_request` by the custodian after executing the transaction. Only `Created` and `Approved` variants of the `EventKind` are used here.\n# Instructions\n\nThe following instructions either create or set basic functioning paramethers:\n\n* initialize - creates the `Config` account, and the token mint. Sets the two authorities, custodian info and mint decimals.\n* claim_authority - acts as a security buffer after changing the authority, in case of a wrongly typed addresses, the previous authority can call `set_authority` again. On initialize, the previous authority is set as the signer of `initialize`, and should be the calling `set_authority` if unable to call `claim_authority` after `initialize`\n* create_merchant - creates a `Merchant`. Requires the merchant wallet and btc address.\n* delete_merchant - deletes a `Merchant`.\n* set_authority - changes the authority address.\n* set_merchant_authority - changes the `merchant_authority` address.\n* set_custodian_btc_address - changes the custodian btc deposit address stored in a given `Merchant` account.\n* set_custodian - changes the wallet that the custodian can use to interact with the program.\n* set_merchant_btc_address - changes the stored btc address for a given `Merchant`.\n\nNOTE: there is no `set_merchant` as it would break the PDA assumptions on account creation. Similar functionality can be easily done by calling `delete_merchant` and `create_merchant`. \n\nFor the intended workflow of the program, the following instructions are used:\n\n* create_mint_request - called by a merchant and creates a `MintRequest` with basic information needed for the custodian to aprove. Issues a `MintEvent` with kind `Created`.\n* approve_mint_request - called by the custodian over a given `MintRequest` that is deleted afterwards. This call will mint a number of tokens according to the information provided by the merchant on `create_mint_request`. Issues a `MintEvent` with kind `Approved`.\n* cancel_mint_request - called by the merchant that created a given `MintRequest`. This will delete the `MintRequest`. Issues a `MintEvent` with kind `Deleted`.\n* reject_mint_request - called by the custodian over a given `MintRequest` to reject the request and delete the account. Issues a `MintEvent` with kind `Rejected`.\n\n* create_redeem_request - called by a merchant and creates a `RedeemRequest` with basic information needed for the custodian to return the native tokens to the merchant. The wrapped tokens are burned immediately during this instruction. Issues a `RedeemEvent` with kind `Created`.\n* approve_redeem_request - called by the custodian to approve a given `RedeemRequest` and delete the temporary account afterwards. Issues a `RedeemEvent` with kind `Approved`.\n\nTwo more instructions are used to enable/disable certain functionality in the program:\n\n* toggle_merchant_enabled - changes a given `Merchant` `enabled` flag.\n* toggle_functionality_enabled - can change the following flags inside the `Config` account that will toggle the respective functionality: `mint_enabled`, `redeem_enabled`, `custodian_enabled`.\n\nNOTE: additional cancel_redeem_request POC provided, but I think it is ultimately non-functional under this workflow.\n## Permissions\n\nThe following table shows the permissions for calling each instruction:\n\n| instruction                  | authority | merchant_authority | merchant | custodian |\n| ---------------------------- | :-------: | :----------------: | :------: | :-------: |\n| create_merchant              |           |          x         |          |           |\n| delete_merchant              |           |          x         |          |           |\n|                              |           |                    |          |           |\n| create_mint_request          |           |                    |     x    |           |\n| cancel_mint_request          |           |                    |     x    |           |\n| approve_mint_request         |           |                    |          |     x     |\n| reject_mint_request          |           |                    |          |     x     |\n|                              |           |                    |          |           |\n| create_redeem_request        |           |                    |     x    |           |\n| approve_redeem_request       |           |                    |          |     x     |\n|                              |           |                    |          |           |\n| set_authority                |     x     |                    |          |           |\n| claim_authority              |the new one|                    |          |           |\n| set_merchant_authority       |     x     |                    |          |           |\n| set_custodian                |     x     |                    |          |     x     |\n| set_custodian_btc_address    |           |                    |          |     x     |\n| set_merchant_btc_address     |           |                    |     x    |           |\n|                              |           |                    |          |           |\n| toggle_functionality_enabled |     x     |                    |          |           |\n| toggle_merchant_enabled      |           |          x         |          |           |\n\nThe remaining `initialize` instruction can be called by anyone, but ideally by the person who deploys the program to setup the initial accounts properly.\n\n# Audits\n\nAudit performed by OtterSec can be reviewed [here](audits/ottersec_1.pdf). All issues that were found are resolved and comitted to the current master branch.", "release_dates": []}, {"name": "whitepaper", "description": "Solana whitepaper LaTeX source", "language": "TeX", "license": null, "readme": "[![Build Status](https://badge.buildkite.com/caf7ae5f41c9eadbce6c3e4d9f5197ffb7f3e4977873eb4971.svg?branch=master)](https://solana-ci-gate.herokuapp.com/buildkite_public_log?https://buildkite.com/solana-labs/whitepaper/builds/latest/master)\n\n## WIP Translations\n[English](solana-whitepaper-en.pdf)  \n[Italian](solana-whitepaper-it.pdf)  \n[French](solana-whitepaper-fr.pdf)  \n[Japanese](solana-whitepaper-ja.pdf)  \n\n\n## Building\nEnsure that Docker is installed on your system,\nhttps://docs.docker.com/install/, then run the following command to build a PDF\nversion of the whitepaper:\n```\n  $ ./ci/build.sh\n```\n\n### Reference\nThe `.tex` files in this directory are rendered to PDF by [LuaTeX](http://www.luatex.org/ \"LuaTex Official Website\").\n\n#### How to setup LuaTeX on Mac\n1. Install [MacTeX](http://www.tug.org/mactex/ \"MacTex Official Site\").\n\n2. Compile .tex file: \n```\n  $ lualatex solana-whitepaper-jp.tex\n```\n\n#### How to setup LuaTeX on Ubuntu Desktop\n1. Install [TeX Live](https://www.tug.org/texlive/ \"TeX Live Official Site\").\n```\n $ wget http://mirror.ctan.org/systems/texlive/tlnet/install-tl-unx.tar.gz\n $ tar xvf install-tl-unx.tar.gz && cd install-tl*\n $ sudo ./install-tl --repository http://mirror.ctan.org/systems/texlive/tlnet/\n```\nWhen prompted \"Enter command:\" type \"I\" and hit Enter key, then just wait until installation has completed. This may take a few hours.\n\n2. Deploy a symbolic link under /etc/local/bin\n```\n $ sudo /usr/local/texlive/2018/bin/x86_64-linux/tlmgr path add\n```\n\n3. Update TeX Live\n```\n $ sudo tlmgr update --self --all\n```\n\n4. Compile .tex file\n```\n $ lualatex solana-whitepaper-jp.tex\n```\n\n", "release_dates": []}, {"name": "wormhole-hackathon", "description": null, "language": null, "license": null, "readme": "# Solana's Wormhole Hackathon &middot; Up to $200k in prizes\n#### Boost your project at warp speed with Solana\n\n* Hackathon dates: October 28th through November 14\n* Type: Online and global\n* More details: [Announcement Blog Post](https://medium.com/solana-labs/wormhole-solana-ethereum-bridge-d5502e944acb)\n* Project submission form: [Submit here](https://solana.com/hackathon)\n\n## Introduction\nSolana is the fastest, low-fee, censorship-resistant blockchain designed to enable developers to permissionlessly build and scale applications to billions of users globally. Wormhole is the first bidirectional bridge that connects Ethereum with Solana. Wormhole allows new and existing crypto projects, businesses, and communities to move tokenized assets seamlessly across blockchains to benefit from Solana\u2019s high speed (50,000 transactions per second) and low cost (less than $0.00001 per transaction). \n\nAs long as you have an internet connection, you're invited to join our first global hackathon! Combining Wormhole with Solana\u2019s core features gives hackers an open design space to create entirely new applications that could bring in the next wave of crypto users. While we encourage participants to build with Wormhole, hackers can build any application or tool they believe will have an impact on the ecosystem. The only requirement is that teams must incorporate Solana into their project in some way.  Take a look at our list of [ideas for inspiration](https://github.com/solana-labs/wormhole-hackathon/blob/main/ideas.md).\n\n## Get Started Building\n\n* [Solana Documentation](https://docs.solana.com/)\n* [Hello World](https://github.com/solana-labs/example-helloworld)\n* [Discord Support Chat](https://discord.gg/4Gq2xgb): Technical support and help from Certus One and Solana engineers\n* [Find a teammate directory](https://airtable.com/shrkdku8nk6anh5mZ/tblPJxUnAsH4S5WHt)\n* [Solana Program Library Documentation](https://spl.solana.com/)\n* [Wormhole Documentation](https://github.com/certusone/wormhole)\n* [Examples](https://docs.solana.com/apps/hello-world)\n* [Overview](https://docs.solana.com/cluster/overview)\n* [Project ideas](https://github.com/solana-labs/wormhole-hackathon/blob/main/ideas.md)\n\n## Other Resources\n\n* [Find a teammate](https://discord.gg/fYpyaYh): We encourage hackers looking to join or form a team to search through the directory of participants. You can reach out on our dedicated Discord channel.\n* [Build a high-speed DEX on Solana using Serum infrastructure](https://serum-academy.com/en/developer-resources/)\n* [Run your own DEX](https://serum-academy.com/en/dex-list/)\n* [List tokens on the Serum DEX](https://serum-academy.com/en/add-market/)\n\nDon\u2019t choose between scale, security, and decentralization. Solana has solved the trilemma for you. Check out our tech stack below to learn how we did it:\n\n* [Proof of History (PoH)](https://medium.com/solana-labs/proof-of-history-a-clock-for-blockchain-cf47a61a9274) - A clock before consensus\n* [Tower BFT](https://medium.com/solana-labs/tower-bft-solanas-high-performance-implementation-of-pbft-464725911e79) - A PoH-optimized version of PBFT\n* [Turbine](https://medium.com/solana-labs/turbine-solanas-block-propagation-protocol-solves-the-scalability-trilemma-2ddba46a51db) - A block propagation protocol \n* [Gulf Stream](https://medium.com/solana-labs/gulf-stream-solanas-mempool-less-transaction-forwarding-protocol-d342e72186ad) - Mempool-less transaction forwarding protocol\n* [Sealevel](https://medium.com/solana-labs/sealevel-parallel-processing-thousands-of-smart-contracts-d814b378192) - World\u2019s first parallel smart contracts run-time\n* [Pipeline](https://medium.com/solana-labs/pipelining-in-solana-the-transaction-processing-unit-2bb01dbd2d8f) - Transaction processing unit for validation\n* [Cloudbreak](https://medium.com/solana-labs/cloudbreak-solanas-horizontally-scaled-state-architecture-9a86679dcbb1) - Horizontally scaled accounts database\n* [Archivers](https://medium.com/solana-labs/replicators-solanas-solution-to-petabytes-of-blockchain-data-storage-ef79db053fa1) - Distributed ledger storage\n\n## Judging\n\nParticipants may submit a maximum of 1 project by the hackathon deadline. Once all submissions are collected, Solana will distribute a list to the judges for the evaluation process. Teams and individuals are evaluated on the following criteria:\n\n1. Functionality\n2. Potential impact\n3. Novelty\n4. Design\n5. Extensibility\n\nAfter judges complete individual evaluations, the hackathon organizers will discuss with the judges to choose the winners based on the project's weighted scores. To culminate the hackathon, there will be a live-streamed event where the invited winners will present their project submissions. \n\n**Prizes**\n\n| Place                                  | Prize                                        |\n|----------------------------------------|----------------------------------------------|\n| First Place                            | 4 winners can win up to $30k and Solana Swag |\n| Second Place                           | 5 teams of $10k and Solana Swag              |\n| Third Place                            | 5 teams of $5k and Solana Swag               |\n| All participants that submit a project | $100 and Solana Swag                          |\n\n## Discussion Channels\n\n* [#hackathon-announcements](): Logistics from the Solana team \n* [#qa-general](https://discord.gg/4Gq2xgb): Technical support and help from Certus One and Solana team members\n* [#team-formation](https://discord.gg/fYpyaYh): Find a team or seek team members\n* [#ask-organizers](): Questions about the hackathon or prize delivery\n* [#hacker-introductions](): Introduce yourself!\n\n## Code of Conduct \n\nThe Solana Wormhole hackathon welcomes any one from around the world to participate and is intended to create an inclusive environment for building, collaboration, creativity, and impact. We value the participation of each member of the community and want everyone involved to be respected. Accordingly, hackathon administrators, judges, and participants are expected to adhere to the Code of Conduct outlined below for the duration of the hackathon. Event organizers will enforce this code and have the right to disqualify any individual or team that breaks the code.\n\n* Be Respectful: Be kind to all who participate in the event. Do not insult or put down other attendees.\n\n* Behave Professionally. Remember that harassment, racism, sexism, or exclusionary jokes are not appropriate for this event. Harassment includes offensive verbal comments related to gender, sexual orientation, disability, physical appearance, race, and/or religion. Sexual images in public forums, deliberate intimidation, online stalking, following, sustained disruption of virtual presentations, or any other inappropriate action is strictly prohibited\n\n* Be Thoughtful: In the spirit of open source and inclusiveness, there may be minors participating in the hackathon. Keep this in mind when communicating or speaking in public forums.\n\n* Be Open: We welcome attendees from all backgrounds. This event is about increasing awareness for Solana and the greater crypto space. Please be welcoming to all who register for the event and help us create a friendly environment for all.\n\n* Believe in Yourself: Crypto opens the door for anyone to permissionlessly build applications that will change how we all interact with finance, gaming, and the Internet as a whole. Dream big and use this powerful technology to create a better world.\n\n## Legal Disclaimer\n\nThe Wormhole Hackathon is a competition where projects will be evaluated by judges on their technological merits without consideration of legal viability. Participants in the Hackathon will create software solely for purposes of evaluation by judges as part of a competition and not for commercial deployment or release as part of the Hackathon.\n\nSolana does not encourage, induce or sanction the use of any software application in violation of applicable laws and regulations by offering prizes to participants in the Hackathon. All participants must comply with applicable laws and regulations when releasing any software that they develop as part of the Hackathon. \n\nThe Hackathon ideas and developer resources that Solana provides are for educational and inspiration purposes only. Solana does not encourage, induce or sanction the deployment of any such applications in violation of applicable laws or regulations.\n", "release_dates": []}, {"name": "ws-rs", "description": "Lightweight, event-driven WebSockets for Rust.", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# WS-RS\n\nLightweight, event-driven WebSockets for [Rust](https://www.rust-lang.org).\n```rust\n\n/// A WebSocket echo server\nlisten(\"127.0.0.1:3012\", |out| {\n    move |msg| {\n        out.send(msg)\n    }\n})\n```\n\nIntroduction\n------------\n[![Build Status](https://travis-ci.org/housleyjk/ws-rs.svg?branch=stable)](https://travis-ci.org/housleyjk/ws-rs)\n[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)\n[![Crate](http://meritbadge.herokuapp.com/ws)](https://crates.io/crates/ws)\n\n**[Homepage](https://ws-rs.org)**\n\n**[API Documentation](https://ws-rs.org/docs)**\n\nThis library provides an implementation of WebSockets,\n[RFC6455](https://tools.ietf.org/html/rfc6455) using [MIO](https://github.com/carllerche/mio). It\nallows for handling multiple connections on a single thread, and even spawning new client\nconnections on the same thread. This makes for very fast and resource efficient WebSockets. The API\ndesign abstracts away the menial parts of the WebSocket protocol and allows you to focus on\napplication code without worrying about protocol conformance. However, it is also possible to get\nlow-level access to individual WebSocket frames if you need to write extensions or want to optimize\naround the WebSocket protocol.\n\nGetting Started\n---------------\n\nFor detailed installation and usage instructions, check out the [guide](https://ws-rs.org/guide).\n\nFeatures\n--------\n\nWS-RS provides a complete implementation of the WebSocket specification. There is also support for\n[ssl](https://ws-rs.org/guide/ssl) and\n[permessage-deflate](https://ws-rs.org/guide/deflate).\n\nTesting\n-------\n\nWS-RS is thoroughly tested and passes the [Autobahn Test Suite](https://crossbar.io/autobahn/) for\nWebSockets, including the tests for `permessage-deflate`. Visit\n[ws-rs.org](https://ws-rs.org/testing/autobahn/results) to view the results of the latest test run.\n\nContributing\n------------\n\nPlease report bugs and make feature requests [here](https://github.com/housleyjk/ws-rs/issues).\n", "release_dates": []}]