[{"name": ".github", "description": "Default files for all repos in the Kubernetes GitHub org", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# .github\n\nThis repo contains org-wide default [community-health check files](https://docs.github.com/en/github/building-a-strong-community/creating-a-default-community-health-file#supported-file-types).\n\nCurrently, this repo only contains the org-wide default `SECURITY.md` file.\nAll other template files are located at https://github.com/kubernetes/kubernetes-template-project.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n- [Slack](https://kubernetes.slack.com/messages/sig-contribex)\n- [Mailing List](https://groups.google.com/forum/#!forum/kubernetes-sig-contribex)\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n", "release_dates": []}, {"name": "api", "description": "The canonical location of the Kubernetes API definition.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# api\n\nSchema of the external API types that are served by the Kubernetes API server.\n\n## Purpose\n\nThis library is the canonical location of the Kubernetes API definition. Most likely interaction with this repository is as a dependency of client-go.\n\nIt is published separately to avoid diamond dependency problems for users who\ndepend on more than one of `k8s.io/client-go`, `k8s.io/apimachinery`,\n`k8s.io/apiserver`...\n\n## Recommended Use\n\nWe recommend using the go types in this repo. You may serialize them directly to\nJSON.\n\nIf you want to store or interact with proto-formatted Kubernetes API objects, we\nrecommend using the \"official\" serialization stack in `k8s.io/apimachinery`.\nDirectly serializing these types to proto will not result in data that matches\nthe wire format or is compatible with other kubernetes ecosystem tools. The\nreason is that the wire format includes a magic prefix and an envelope proto.\nPlease see:\nhttps://kubernetes.io/docs/reference/using-api/api-concepts/#protobuf-encoding\n\nFor the same reason, we do not recommend embedding these proto objects within\nyour own proto definitions. It is better to store Kubernetes objects as byte\narrays, in the wire format, which is self-describing. This permits you to use\neither JSON or binary (proto) wire formats without code changes. It will be\ndifficult for you to operate on both Custom Resources and built-in types\notherwise.\n\n## Compatibility\n\nBranches track Kubernetes branches and are compatible with that repo.\n\n## Where does it come from?\n\n`api` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/api. Code changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n## Things you should *NOT* do\n\n1. https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/api is synced to k8s.io/api. All changes must be made in the former. The latter is read-only.\n\n\n", "release_dates": []}, {"name": "apiextensions-apiserver", "description": "API server for API extensions like CustomResourceDefinitions", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# apiextensions-apiserver\n\nImplements: https://github.com/kubernetes/design-proposals-archive/blob/main/api-machinery/thirdpartyresources.md\n\nIt provides an API for registering `CustomResourceDefinitions`.\n\n## Purpose\n\nThis API server provides the implementation for `CustomResourceDefinitions` which is included as\ndelegate server inside of `kube-apiserver`.\n\n\n## Compatibility\n\nHEAD of this repo will match HEAD of k8s.io/apiserver, k8s.io/apimachinery, and k8s.io/client-go.\n\n## Where does it come from?\n\n`apiextensions-apiserver` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apiextensions-apiserver.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n", "release_dates": ["2017-12-15T09:12:14Z"]}, {"name": "apimachinery", "description": null, "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# apimachinery\n\nScheme, typing, encoding, decoding, and conversion packages for Kubernetes and Kubernetes-like API objects.\n\n\n## Purpose\n\nThis library is a shared dependency for servers and clients to work with Kubernetes API infrastructure without direct\ntype dependencies. Its first consumers are `k8s.io/kubernetes`, `k8s.io/client-go`, and `k8s.io/apiserver`.\n\n\n## Compatibility\n\nThere are *NO compatibility guarantees* for this repository. It is in direct support of Kubernetes, so branches\nwill track Kubernetes and be compatible with that repo. As we more cleanly separate the layers, we will review the\ncompatibility guarantee.\n\n\n## Where does it come from?\n\n`apimachinery` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apimachinery.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n\n## Things you should *NOT* do\n\n 1. Add API types to this repo. This is for the machinery, not for the types.\n 2. Directly modify any files under `pkg` in this repo. Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/apimachinery`.\n 3. Expect compatibility. This repo is direct support of Kubernetes and the API isn't yet stable enough for API guarantees.\n\n", "release_dates": []}, {"name": "apiserver", "description": "Library for writing a Kubernetes-style API server.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# apiserver\n\nGeneric library for building a Kubernetes aggregated API server.\n\n\n## Purpose\n\nThis library contains code to create Kubernetes aggregation server complete with delegated authentication and authorization,\n`kubectl` compatible discovery information, optional admission chain, and versioned types.  It's first consumers are\n`k8s.io/kubernetes`, `k8s.io/kube-aggregator`, and `github.com/kubernetes-incubator/service-catalog`.\n\n\n## Compatibility\n\nThere are *NO compatibility guarantees* for this repository, yet.  It is in direct support of Kubernetes, so branches\nwill track Kubernetes and be compatible with that repo.  As we more cleanly separate the layers, we will review the\ncompatibility guarantee. We have a goal to make this easier to use in the future.\n\n\n## Where does it come from?\n\n`apiserver` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apiserver.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n\n## Things you should *NOT* do\n\n 1. Directly modify any files under `pkg` in this repo.  Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/apiserver`.\n 2. Expect compatibility.  This repo is changing quickly in direct support of\n    Kubernetes and the API isn't yet stable enough for API guarantees.\n\n", "release_dates": []}, {"name": "autoscaler", "description": "Autoscaling components for Kubernetes", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Autoscaler\n\n[![Release Charts](https://github.com/kubernetes/autoscaler/actions/workflows/release.yaml/badge.svg)](https://github.com/kubernetes/autoscaler/actions/workflows/release.yaml) [![Tests](https://github.com/kubernetes/autoscaler/actions/workflows/ci.yaml/badge.svg)](https://github.com/kubernetes/autoscaler/actions/workflows/ci.yaml) [![GoDoc Widget]][GoDoc]\n\nThis repository contains autoscaling-related components for Kubernetes.\n\n## What's inside\n\n[Cluster Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler) - a component that automatically adjusts the size of a Kubernetes\nCluster so that all pods have a place to run and there are no unneeded nodes. Supports several public cloud providers. Version 1.0 (GA) was released with kubernetes 1.8.\n\n[Vertical Pod Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler) - a set of components that automatically adjust the\namount of CPU and memory requested by pods running in the Kubernetes Cluster. Current state - beta.\n\n[Addon Resizer](https://github.com/kubernetes/autoscaler/tree/master/addon-resizer) - a simplified version of vertical pod autoscaler that modifies\nresource requests of a deployment based on the number of nodes in the Kubernetes Cluster. Current state - beta.\n\n[Charts](https://github.com/kubernetes/autoscaler/tree/master/charts) - Supported Helm charts for components above.\n\n## Contact Info\n\nInterested in autoscaling? Want to talk? Have questions, concerns or great ideas?\n\nPlease join us on #sig-autoscaling at https://kubernetes.slack.com/, or join one\nof our weekly meetings.  See [the Kubernetes Community Repo](https://github.com/kubernetes/community/blob/master/sig-autoscaling/README.md) for more information.\n\n## Getting the Code\n\nFork the repository in the cloud:\n1. Visit https://github.com/kubernetes/autoscaler\n1. Click Fork button (top right) to establish a cloud-based fork.\n\nThe code must be checked out as a subdirectory of `k8s.io`, and not `github.com`.\n\n```shell\nmkdir -p $GOPATH/src/k8s.io\ncd $GOPATH/src/k8s.io\n# Replace \"$YOUR_GITHUB_USERNAME\" below with your github username\ngit clone https://github.com/$YOUR_GITHUB_USERNAME/autoscaler.git\ncd autoscaler\n```\n\nPlease refer to Kubernetes [Github workflow guide] for more details.\n\n[GoDoc]: https://godoc.org/k8s.io/autoscaler\n[GoDoc Widget]: https://godoc.org/k8s.io/autoscaler?status.svg\n[Github workflow guide]: https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md\n", "release_dates": ["2024-02-05T15:00:06Z", "2023-12-27T17:25:04Z", "2023-12-19T11:40:53Z", "2023-12-06T09:34:31Z", "2023-12-05T17:36:29Z", "2023-12-05T17:33:47Z", "2023-12-05T17:31:36Z", "2023-12-04T13:28:18Z", "2023-11-27T14:16:29Z", "2023-12-04T16:20:11Z", "2023-11-23T21:26:00Z", "2023-11-23T21:17:49Z", "2023-11-23T21:07:12Z", "2023-11-17T14:26:32Z", "2023-11-16T22:32:15Z", "2023-11-15T17:40:07Z", "2023-11-15T05:43:19Z", "2023-11-14T22:11:02Z", "2023-10-23T14:02:01Z", "2023-10-23T14:24:10Z", "2023-08-29T11:49:56Z", "2023-08-31T16:59:32Z", "2023-08-22T22:46:39Z", "2023-07-27T11:43:31Z", "2023-07-27T11:41:09Z", "2023-07-27T11:37:08Z", "2023-07-27T11:33:51Z", "2023-06-29T18:52:51Z", "2023-06-22T12:46:32Z", "2023-06-13T12:06:40Z"]}, {"name": "cel-admission-webhook", "description": null, "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Template Project\n\nThe Kubernetes Template Project is a template for starting new projects in the GitHub organizations owned by Kubernetes. All Kubernetes projects, at minimum, must have the following files:\n\n- a `README.md` outlining the project goals, sponsoring sig, and community contact information\n- an `OWNERS` with the project leads listed as approvers ([docs on `OWNERS` files][owners])\n- a `CONTRIBUTING.md` outlining how to contribute to the project\n- an unmodified copy of `code-of-conduct.md` from this repo, which outlines community behavior and the consequences of breaking the code\n- a `LICENSE` which must be Apache 2.0 for code projects, or [Creative Commons 4.0] for documentation repositories, without any custom content\n- a `SECURITY_CONTACTS` with the contact points for the Product Security Team \n  to reach out to for triaging and handling of incoming issues. They must agree to abide by the\n  [Embargo Policy](https://git.k8s.io/security/private-distributors-list.md#embargo-policy)\n  and will be removed and replaced if they violate that agreement.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n- [Slack](https://slack.k8s.io/)\n- [Mailing List](https://groups.google.com/a/kubernetes.io/g/dev)\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n[owners]: https://git.k8s.io/community/contributors/guide/owners.md\n[Creative Commons 4.0]: https://git.k8s.io/website/LICENSE\n", "release_dates": []}, {"name": "cli-runtime", "description": "Set of helpers for creating kubectl commands and plugins.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# cli-runtime\n\nSet of helpers for creating kubectl commands, as well as kubectl plugins.\n\n\n## Purpose\n\nThis library is a shared dependency for clients to work with Kubernetes API infrastructure which allows\nto maintain kubectl compatible behavior.  Its first consumer is `k8s.io/kubectl`.\n\n\n## Compatibility\n\nThere are *NO compatibility guarantees* for this repository.  It is in direct support of Kubernetes, so branches\nwill track Kubernetes and be compatible with that repo.  As we more cleanly separate the layers, we will review the\ncompatibility guarantee.\n\n\n## Where does it come from?\n\n`cli-runtime` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/cli-runtime.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n\n## Things you should *NOT* do\n\n 1. Add API types to this repo.  This is for the helpers, not for the types.\n 2. Directly modify any files under `pkg` in this repo.  Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/cli-runtime`.\n 3. Expect compatibility.  This repo is direct support of Kubernetes and the API isn't yet stable enough for API guarantees.\n 4. Add any type that only makes sense only for `kubectl`.\n\n", "release_dates": []}, {"name": "client-go", "description": "Go client for Kubernetes.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# client-go\n\nGo clients for talking to a [kubernetes](http://kubernetes.io/) cluster.\n\nWe recommend using the `v0.x.y` tags for Kubernetes releases >= `v1.17.0` and\n`kubernetes-1.x.y` tags for Kubernetes releases < `v1.17.0`.\n\nThe fastest way to add this library to a project is to run `go get k8s.io/client-go@latest` with go1.16+.\nSee [INSTALL.md](/INSTALL.md) for detailed installation instructions and troubleshooting.\n\n[![GoDocWidget]][GoDocReference]\n\n[GoDocWidget]: https://godoc.org/k8s.io/client-go?status.svg\n[GoDocReference]:https://godoc.org/k8s.io/client-go \n\n## Table of Contents\n\n- [What's included](#whats-included)\n- [Versioning](#versioning)\n  - [Compatibility: your code <-> client-go](#compatibility-your-code---client-go)\n  - [Compatibility: client-go <-> Kubernetes clusters](#compatibility-client-go---kubernetes-clusters)\n  - [Compatibility matrix](#compatibility-matrix)\n  - [Why do the 1.4 and 1.5 branch contain top-level folder named after the version?](#why-do-the-14-and-15-branch-contain-top-level-folder-named-after-the-version)\n- [Kubernetes tags](#kubernetes-tags)\n- [How to get it](#how-to-get-it)\n- [How to use it](#how-to-use-it)\n- [Dependency management](#dependency-management)\n- [Contributing code](#contributing-code)\n\n### What's included\n\n* The `kubernetes` package contains the clientset to access Kubernetes API.\n* The `discovery` package is used to discover APIs supported by a Kubernetes API server.\n* The `dynamic` package contains a dynamic client that can perform generic operations on arbitrary Kubernetes API objects.\n* The `plugin/pkg/client/auth` packages contain optional authentication plugins for obtaining credentials from external sources.\n* The `transport` package is used to set up auth and start a connection.\n* The `tools/cache` package is useful for writing controllers.\n\n### Versioning\n\n- For each `v1.x.y` Kubernetes release, the major version (first digit)\nwould remain `0`.\n\n- Bugfixes will result in the patch version (third digit) changing. PRs that are\ncherry-picked into an older Kubernetes release branch will result in an update\nto the corresponding branch in `client-go`, with a corresponding new tag\nchanging the patch version.\n\n#### Branches and tags.\n\nWe will create a new branch and tag for each increment in the minor version\nnumber. We will create only a new tag for each increment in the patch\nversion number. See [semver](http://semver.org/) for definitions of major,\nminor, and patch.\n\nThe HEAD of the master branch in client-go will track the HEAD of the master\nbranch in the main Kubernetes repo.\n\n#### Compatibility: your code <-> client-go\n\nThe `v0.x.y` tags indicate that go APIs may change in incompatible ways in\ndifferent versions.\n\nSee [INSTALL.md](INSTALL.md) for guidelines on requiring a specific\nversion of client-go.\n\n#### Compatibility: client-go <-> Kubernetes clusters\n\nSince Kubernetes is backwards compatible with clients, older `client-go`\nversions will work with many different Kubernetes cluster versions.\n\nWe will backport bugfixes--but not new features--into older versions of\n`client-go`.\n\n\n#### Compatibility matrix\n\n|                               | Kubernetes 1.23 | Kubernetes 1.24 | Kubernetes 1.25 | Kubernetes 1.26 | Kubernetes 1.27 | Kubernetes 1.28 |\n| ----------------------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- |\n| `kubernetes-1.23.0`/`v0.23.0` | \u2713               | +-              | +-              | +-              | +-              | +-              |\n| `kubernetes-1.24.0`/`v0.24.0` | +-              | \u2713               | +-              | +-              | +-              | +-              |\n| `kubernetes-1.25.0`/`v0.25.0` | +-              | +-              | \u2713               | +-              | +-              | +-              |\n| `kubernetes-1.26.0`/`v0.26.0` | +-              | +-              | +-              | \u2713               | +-              | +-              |\n| `kubernetes-1.27.0`/`v0.27.0` | +-              | +-              | +-              | +-              | \u2713               | +-              |\n| `kubernetes-1.28.0`/`v0.28.0` | +-              | +-              | +-              | +-              | +-              | \u2713               |\n| `HEAD`                        | +-              | +-              | +-              | +-              | +-              | +-              |\n\nKey:\n\n* `\u2713` Exactly the same features / API objects in both client-go and the Kubernetes\n  version.\n* `+` client-go has features or API objects that may not be present in the\n  Kubernetes cluster, either due to that client-go has additional new API, or\n  that the server has removed old API. However, everything they have in\n  common (i.e., most APIs) will work. Please note that alpha APIs may vanish or\n  change significantly in a single release.\n* `-` The Kubernetes cluster has features the client-go library can't use,\n  either due to the server has additional new API, or that client-go has\n  removed old API. However, everything they share in common (i.e., most APIs)\n  will work.\n\nSee the [CHANGELOG](./CHANGELOG.md) for a detailed description of changes\nbetween client-go versions.\n\n| Branch         | Canonical source code location      | Maintenance status |\n| -------------- | ----------------------------------- | ------------------ |\n| `release-1.19` | Kubernetes main repo, 1.19 branch   | =-                 |\n| `release-1.20` | Kubernetes main repo, 1.20 branch   | =-                 |\n| `release-1.21` | Kubernetes main repo, 1.21 branch   | =-                 |\n| `release-1.22` | Kubernetes main repo, 1.22 branch   | =-                 |\n| `release-1.23` | Kubernetes main repo, 1.23 branch   | =-                 |\n| `release-1.24` | Kubernetes main repo, 1.24 branch   | =-                 |\n| `release-1.25` | Kubernetes main repo, 1.25 branch   | \u2713                  |\n| `release-1.26` | Kubernetes main repo, 1.26 branch   | \u2713                  |\n| `release-1.27` | Kubernetes main repo, 1.27 branch   | \u2713                  |\n| `release-1.28` | Kubernetes main repo, 1.28 branch   | \u2713                  |\n| client-go HEAD | Kubernetes main repo, master branch | \u2713                  |\n\nKey:\n\n* `\u2713` Changes in main Kubernetes repo are actively published to client-go by a bot\n* `=` Maintenance is manual, only severe security bugs will be patched.\n* `-` Deprecated; please upgrade.\n\n#### Deprecation policy\n\nWe will maintain branches for at least six months after their first stable tag\nis cut. (E.g., the clock for the release-2.0 branch started ticking when we\ntagged v2.0.0, not when we made the first alpha.) This policy applies to\nevery version greater than or equal to 2.0.\n\n#### Why do the 1.4 and 1.5 branch contain top-level folder named after the version?\n\nFor the initial release of client-go, we thought it would be easiest to keep\nseparate directories for each minor version. That soon proved to be a mistake.\nWe are keeping the top-level folders in the 1.4 and 1.5 branches so that\nexisting users won't be broken.\n\n### Kubernetes tags\n\nThis repository is still a mirror of\n[k8s.io/kubernetes/staging/src/client-go](https://github.com/kubernetes/kubernetes/tree/master/staging/src/k8s.io/client-go),\nthe code development is still done in the staging area.\n\nSince Kubernetes `v1.8.0`, when syncing the code from the staging area,\nwe also sync the Kubernetes version tags to client-go, prefixed with\n`kubernetes-`. From Kubernetes `v1.17.0`, we also create matching semver\n`v0.x.y` tags for each `v1.x.y` Kubernetes release.\n\nFor example, if you check out the `kubernetes-1.17.0` or the `v0.17.0` tag in\nclient-go, the code you get is exactly the same as if you check out the `v1.17.0`\ntag in Kubernetes, and change directory to `staging/src/k8s.io/client-go`.\n\nThe purpose is to let users quickly find matching commits among published repos,\nlike [sample-apiserver](https://github.com/kubernetes/sample-apiserver),\n[apiextension-apiserver](https://github.com/kubernetes/apiextensions-apiserver),\netc. The Kubernetes version tag does NOT claim any backwards compatibility\nguarantees for client-go. Please check the [semantic versions](#versioning) if\nyou care about backwards compatibility.\n\n### How to get it\n\nTo get the latest version, use go1.16+ and fetch using the `go get` command. For example:\n\n```\ngo get k8s.io/client-go@latest\n```\n\nTo get a specific version, use go1.11+ and fetch the desired version using the `go get` command. For example:\n\n```\ngo get k8s.io/client-go@v0.20.4\n```\n\nSee [INSTALL.md](/INSTALL.md) for detailed instructions and troubleshooting.\n\n### How to use it\n\nIf your application runs in a Pod in the cluster, please refer to the\nin-cluster [example](examples/in-cluster-client-configuration), otherwise please\nrefer to the out-of-cluster [example](examples/out-of-cluster-client-configuration).\n\n### Dependency management\n\nFor details on how to correctly use a dependency management for installing client-go, please see [INSTALL.md](INSTALL.md).\n\n### Contributing code\nPlease send pull requests against the client packages in the Kubernetes main [repository](https://github.com/kubernetes/kubernetes). Changes in the staging area will be published to this repository every day.\n", "release_dates": []}, {"name": "cloud-provider", "description": "cloud-provider defines the shared interfaces which Kubernetes cloud providers implement. These interfaces allow various controllers to integrate with any cloud provider in a pluggable fashion. Also serves as an issue tracker for SIG Cloud Provider.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# cloud-provider\n\nThis repository defines the cloud-provider interface and mechanism to initialize\na cloud-provider implementation into Kubernetes. Currently multiple processes\nuse this code although the intent is that it will eventually only be cloud\ncontroller manager.\n\n**Note:** go-get or vendor this package as `k8s.io/cloud-provider`.\n\n## Purpose\n\nThis library is a shared dependency for processes which need to be able to\nintegrate with cloud-provider specific functionality.\n\n## Compatibility\n\nCloud Providers are expected to keep the HEAD of their implementations in sync\nwith the HEAD of this repository.\n\n## Where does it come from?\n\n`cloud-provider` is synced from\nhttps://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/cloud-provider.\nCode changes are made in that location, merged into k8s.io/kubernetes and\nlater synced here.\n\n## Things you should NOT do\n\n 1. Add an cloud provider specific code to this repo.\n 2. Directly modify anything under vendor/k8s.io/cloud-provider in this repo. Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/cloud-provider`.\n 3. Make interface changes without first discussing them with\n    sig-cloudprovider.\n\n", "release_dates": []}, {"name": "cloud-provider-alibaba-cloud", "description": "CloudProvider for Alibaba Cloud ", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Cloud Controller Manager for Alibaba Cloud\n\nThank you for visiting the cloud-provider-alibaba-cloud repository!\n\n\n`cloud-provider-alibaba-cloud` is the external Kubernetes cloud controller manager implementation for Alibaba Cloud. Running `cloud-provider-alibaba-cloud` allows you build your kubernetes clusters leverage on many cloud services on Alibaba Cloud. You can read more about Kubernetes cloud controller manager [here](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/).\n\n## Development\n\nTest project with command ```make test``` and Build an image with command ```make image```\n\n## QuickStart\n\n- [Getting-started](docs/getting-started.md)\n- [Usage Guide](docs/usage.md)\n\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n- [Slack channel](https://kubernetes.slack.com/messages/sig-cloud-provider)\n- [Mailing list](https://groups.google.com/forum/#!forum/kubernetes-sig-cloud-provider)\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n## Testing\nSee more info in page [Test](https://github.com/kubernetes/cloud-provider-alibaba-cloud/tree/master/docs/testing.md)", "release_dates": ["2023-10-16T13:29:13Z", "2023-07-13T02:35:54Z", "2023-03-07T02:11:05Z", "2022-10-27T06:53:43Z", "2022-06-23T09:31:05Z", "2022-03-21T07:17:43Z", "2021-12-31T09:25:20Z", "2021-12-02T11:41:16Z", "2021-03-10T12:29:07Z", "2020-10-19T12:08:42Z", "2020-03-31T02:01:48Z", "2019-04-08T07:17:11Z"]}, {"name": "cloud-provider-aws", "description": "Cloud provider for AWS", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": null, "release_dates": ["2023-08-29T07:23:41Z", "2023-08-21T20:05:01Z", "2023-08-21T20:03:22Z", "2023-04-19T18:47:05Z", "2023-04-16T05:58:23Z", "2023-03-08T10:41:38Z", "2023-01-24T19:37:12Z", "2023-01-15T08:52:05Z", "2022-12-31T07:20:09Z", "2022-12-16T15:36:41Z", "2022-08-26T06:42:48Z", "2022-05-26T13:47:49Z", "2022-05-26T13:45:53Z", "2022-05-26T13:44:52Z", "2022-05-25T09:28:44Z", "2022-05-24T08:37:51Z", "2022-05-24T08:36:38Z", "2022-05-13T02:17:08Z", "2022-05-13T02:19:54Z", "2022-05-13T02:26:18Z", "2022-05-13T02:10:31Z", "2022-05-13T02:07:36Z", "2022-04-09T00:28:25Z", "2022-04-08T23:27:57Z", "2022-04-09T00:20:29Z", "2022-03-04T21:49:15Z", "2022-01-23T08:18:16Z", "2022-01-21T02:42:32Z", "2022-01-07T08:23:32Z", "2021-10-11T22:33:21Z"]}, {"name": "cloud-provider-gcp", "description": "cloud-provider-gcp contains several projects used to run Kubernetes in Google Cloud", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# cloud-provider-gcp\n\nThis repository holds the code for gcp-controller-manager as well as cloud-controller-manager\n\n## Publishing gcp-controller-manager image\n\nThis command will build and publish gcp-controller-manager\n`gcr.io/k8s-image-staging/gcp-controller-manager:latest`:\n\n```\nbazel run //cmd/gcp-controller-manager:publish\n```\n\nEnvironment variables `IMAGE_REGISTRY`, `IMAGE_REPO` and `IMAGE_TAG` can be\nused to override destination GCR repository and tag.\n\nThis command will build and publish\n`example.com/my-repo/gcp-controller-manager:v1`:\n\n\n```\nIMAGE_REGISTRY=example.com IMAGE_REPO=my-repo IMAGE_TAG=v1 bazel run //cmd/gcp-controller-manager:publish\n```\n\n## Publishing cloud-controller-manager image\n\nThis command will build and publish cloud-controller-manager\n`gcr.io/k8s-image-staging/cloud-controller-manager:latest`:\n\n```\nbazel run //cmd/cloud-controller-manager:publish\n```\n\nEnvironment variables `IMAGE_REGISTRY`, `IMAGE_REPO` and `IMAGE_TAG` can be\nused to override destination GCR repository and tag.\n\nThis command will build and publish\n`example.com/my-repo/gcp-controller-manager:v1`:\n\n\n```\nIMAGE_REGISTRY=example.com IMAGE_REPO=my-repo IMAGE_TAG=v1 bazel run //cmd/cloud-controller-manager:publish\n```\n\n# Cross-compiling\n\nSelecting the target platform is done with the `--platforms` option with `bazel`.\nThis command builds release tarballs for Windows:\n\n```\nbazel build --platforms=@io_bazel_rules_go//go/toolchain:windows_amd64 //release:release-tars\n```\n\nThis command explicitly targets Linux as the target platform:\n\n```\nbazel build --platforms=@io_bazel_rules_go//go/toolchain:linux_amd64 //release:release-tars\n```\n\n\n# Dependency management\n\nDependencies are managed using [Go modules](https://github.com/golang/go/wiki/Modules) (`go mod` subcommands).\n\nNote that builds are done with Bazel and not the Go tool. Don't follow public\nGo module docs, instead use instructions in this readme.\n\n## Working within GOPATH\n\nIf you work within `GOPATH`, `go mod` will error out unless you do one of:\n\n- move repo outside of GOPATH (it should \"just work\")\n- set env var `GO111MODULE=on`\n\n## Add a new dependency\n\n```\ngo get github.com/new/dependency && ./tools/update_vendor.sh\n```\n\n## Update an existing dependency\n\n```\ngo get -u github.com/existing/dependency && ./tools/update_vendor.sh\n```\n\n## Update all dependencies\n\n```\ngo get -u && ./tools/update_vendor.sh\n```\n\nNote that this most likely won't work due to cross-dependency issues or repos\nnot implementing modules correctly.\n\n# Bazel\n\nBazel is required to build and release cloud-provider-gcp.\n\nTo install:\n\n```sh\ngo get github.com/bazelbuild/bazelisk\nalias bazel=bazelisk\n```\n\nTo re-generate `BUILD` files:\n\n```sh\ntools/update_bazel.sh\n```\n\n# Tagging for new cloud-controller-manager versions\n\nTo trigger a new image for cloud-controller-manager, you need to add a git tag.\nThis needs to have the format `ccm/vX.Y.Z`. For example.\n\n```\ngit tag -a ccm/v27.1.0 -m \"CCM build for Kubernetes v1.27.1\"\n```\n\nThe major version X corresponds to the Kubernetes minor version. The minor\nversion Y corresponds to the Kubernetes patch version and the patch version Z\ncorresponds to the CCM patch version.\n", "release_dates": []}, {"name": "cloud-provider-openstack", "description": null, "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Cloud Provider OpenStack\n\nThank you for visiting the `Cloud Provider OpenStack` repository!\n\nThis Repository hosts various plugins relevant to OpenStack and Kubernetes Integration\n\n* [OpenStack Cloud Controller Manager](/docs/openstack-cloud-controller-manager/using-openstack-cloud-controller-manager.md/)\n* [Octavia Ingress Controller](/docs/octavia-ingress-controller/using-octavia-ingress-controller.md/)\n* [Cinder CSI Plugin](/docs/cinder-csi-plugin/using-cinder-csi-plugin.md/)\n* [Keystone Webhook Authentication Authorization](/docs/keystone-auth/using-keystone-webhook-authenticator-and-authorizer.md/)\n* [Client Keystone](/docs/keystone-auth/using-client-keystone-auth.md/)\n* [Manila CSI Plugin](/docs/manila-csi-plugin/using-manila-csi-plugin.md/)\n* [Barbican KMS Plugin](/docs/barbican-kms-plugin/using-barbican-kms-plugin.md/)\n* [Magnum Auto Healer](/docs/magnum-auto-healer/using-magnum-auto-healer.md/)\n\n**NOTE:**\n\n* Cinder Standalone Provisioner, Manila Provisioner and Cinder FlexVolume Driver were removed since release v1.18.0.\n* Version 1.17 was the last release of Manila Provisioner, which is unmaintained from now on. Due to dependency issues, we removed the code from master but it is still accessible in the [release-1.17](https://github.com/kubernetes/cloud-provider-openstack/tree/release-1.17) branch. Please consider migrating to Manila CSI Plugin.\n* Start from release v1.26.0, neutron lbaasv1 support is removed and only Octavia is supported.\n\n## Developing\n\nRefer to [Getting Started Guide](/docs/developers-guide.md/) for setting up development environment and contributing.\n\n## Contact\n\nPlease join us on [Kubernetes provider-openstack slack channel](https://kubernetes.slack.com/messages/provider-openstack)\n\nProject Co-Leads:\n* @dulek - Micha\u0142 Dulko\n* @jichenjc - Chen Ji\n* @kayrus\n* @zetaab - Jesse Haka\n\n## License\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n", "release_dates": ["2024-02-20T20:19:57Z", "2024-01-18T16:22:43Z", "2024-01-18T13:20:07Z", "2024-01-18T13:20:06Z", "2024-01-18T13:20:05Z", "2023-12-28T14:33:46Z", "2023-12-01T16:45:55Z", "2023-11-14T16:08:40Z", "2023-11-02T01:58:29Z", "2023-10-26T09:35:25Z", "2023-10-26T09:32:29Z", "2023-10-26T09:26:38Z", "2023-10-24T12:45:01Z", "2023-10-19T20:00:32Z", "2023-10-19T20:00:30Z", "2023-10-19T20:00:29Z", "2023-10-19T17:14:36Z", "2023-10-19T17:17:06Z", "2023-10-19T17:17:12Z", "2023-10-19T17:14:34Z", "2023-10-19T17:17:05Z", "2023-10-19T17:17:11Z", "2023-10-19T17:14:33Z", "2023-10-19T17:17:04Z", "2023-10-19T17:17:10Z", "2023-10-10T06:49:53Z", "2023-10-10T06:49:53Z", "2023-10-10T06:49:51Z", "2023-09-21T14:52:49Z", "2023-08-31T12:43:06Z"]}, {"name": "cloud-provider-sample", "description": "Sample of how to build a cloud provider repo. This will build a Kubernetes image which deploys on bare metal. It uses the fake cloud provider. It consumes the K8s/K8s build artifact and adds to it the Cloud Controller Manager and CSI Daemon Set.", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# cloud-provider-sample\n\nThis is a sample of how to build a cloud provider repo. This will build a Kubernetes image which deploys on bare metal.\nIt uses the fake cloud provider and consumes the [kubernetes/kubernetes](https://github.com/kubernetes/kubernetes)\nbuild artifact and adds to it the Cloud Controller Manager and CSI Daemon Set.\n\n**Note:** This is currently a work in progress.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n- [Slack](https://kubernetes.slack.com/messages/sig-cloud-provider)\n- [Mailing List](https://groups.google.com/forum/#!forum/kubernetes-sig-cloud-provider)\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n", "release_dates": []}, {"name": "cloud-provider-vsphere", "description": "Kubernetes Cloud Provider for vSphere https://cloud-provider-vsphere.sigs.k8s.io", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes vSphere Cloud Provider\n\n![GitHub release (latest SemVer including pre-releases](https://img.shields.io/github/v/release/kubernetes/cloud-provider-vsphere?include_prereleases)\n![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)\n\n![image](/docs/images/vsphere_kubernetes_logo.png)\n\n## vSphere Cloud Controller Manager\n\nThis repository contains the [Kubernetes cloud-controller-manager](https://kubernetes.io/docs/concepts/architecture/cloud-controller/) for vSphere.\n\nThis project replaces the deprecated in-tree vSphere cloud provider located within the [Kubernetes repository](https://github.com/kubernetes/kubernetes/tree/master/staging/src/k8s.io/legacy-cloud-providers/vsphere). If you want to create issues or pull requests for the in-tree cloud provider, please go to the [Kubernetes repository](https://github.com/kubernetes/kubernetes).\n\nThere is ongoing work for refactoring cloud providers out of the upstream repository. For more details, please check [this KEP](https://github.com/kubernetes/enhancements/blob/master/keps/sig-cloud-provider/2392-cloud-controller-manager/README.md).\n\n## Compatibility with Kubernetes\n\nThe vSphere cloud provider is released with a specific semantic version `MAJOR.MINOR.PATCH` that correlates with the Kubernetes upstream version. Compatibility with a new Kubernetes version requires upgrading existing cloud provider components since compatibility is ONLY guaranteed between a specific release and its corresponding Kubernetes version.\n\nIn the future, the major and minor versions of releases should be equivalent to the compatible upstream Kubernetes release, and the patch version is used for bug fixes pertaining to specific Kubernetes releases. See [the external cloud provider versioning KEP](https://github.com/kubernetes/enhancements/tree/master/keps/sig-cloud-provider/1771-versioning-policy-for-external-cloud-providers) for more details.\n\nVersion matrix:\n\n| Kubernetes Version | vSphere Cloud Provider Release Version | Cloud Provider Branch |\n|--------------------|----------------------------------------|-----------------------|\n| v1.29.X            | v1.29.X                                | release-1.29          |\n| v1.28.X            | v1.28.X                                | release-1.28          |\n| v1.27.X            | v1.27.X                                | release-1.27          |\n| v1.26.X            | v1.26.X                                | release-1.26          |\n| v1.25.X            | v1.25.X                                | release-1.25          |\n| v1.24.X            | v1.24.X                                | release-1.24          |\n| v1.23.X            | v1.23.X                                | release-1.23          |\n| v1.22.X            | v1.22.X                                | release-1.22          |\n| v1.21.X            | v1.21.X                                | release-1.21          |\n| v1.20.X            | v1.20.X                                | release-1.20          |\n| v1.19.X            | v1.19.X                                | release-1.19          |\n| v1.18.X            | v1.18.X                                | release-1.18          |\n\nOur current support policy is that when a new Kubernetes release comes out, we will bump our k8s dependencies to the new version and cut a new release for CPI, e.g. CPI v1.22.x was released after k8s v1.22 comes out.\n\nThe latest CPI version is ![GitHub release (latest SemVer including pre-releases](https://img.shields.io/github/v/release/kubernetes/cloud-provider-vsphere?include_prereleases). The recommended way to upgrade CPI can be found on [this page](https://github.com/kubernetes/cloud-provider-vsphere/blob/master/releases/README.md).\n\n## Quickstart\n\nGet started with Cloud controller manager for vSphere with Kubeadm with this [quickstart](https://cloud-provider-vsphere.sigs.k8s.io/tutorials/kubernetes-on-vsphere-with-kubeadm.html).\n\n## Quickstart using Helm\n\nGet started with Cloud controller manager for vSphere using Helm with this [Helm quickstart](https://github.com/kubernetes/cloud-provider-vsphere/blob/master/docs/book/tutorials/kubernetes-on-vsphere-with-helm.md).\n\n## Documentation\n\nDocumentation on how to install and use the Kubernetes vSphere Cloud Provider is located on the [docs site](https://cloud-provider-vsphere.sigs.k8s.io/).\n\n## Building the cloud provider\n\nThis section outlines how to build the cloud provider with and without Docker.\n\n### Building locally\n\nBuild locally with the following command:\n\n```shell\n$ git clone https://github.com/kubernetes/cloud-provider-vsphere && \\\n  make -C cloud-provider-vsphere\n```\n\nThe project uses [Go modules](https://github.com/golang/go/wiki/Modules) and:\n\n* Requires Go 1.11+\n* Should not be cloned into the `$GOPATH`\n\n### Building with Docker\n\nIt is also possible to build the cloud provider with Docker in order to ensure a clean build environment:\n\n```shell\n$ git clone https://github.com/kubernetes/cloud-provider-vsphere && \\\n  make -C cloud-provider-vsphere build-with-docker\n```\n\n## Container images\n\nOfficial releases of the vSphere Cloud Controller Manager container image can be found at:\n\n<https://gcr.io/cloud-provider-vsphere/cpi/release/manager>\n\nThe very latest builds from the tip of master, which may not be stable, can be found at:\n\n<https://gcr.io/cloud-provider-vsphere/cpi/ci/manager>\n\n## Contributing\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on how to contribute.\n\n### vSphere storage support\n\nOut of tree cloud providers no longer provide native storage support. Instead, a\nContainer Storage Interface (CSI) driver is required. The vSphere CSI driver is\nlocated [here](https://github.com/kubernetes-sigs/vsphere-csi-driver).\n", "release_dates": ["2024-01-17T05:40:27Z", "2024-01-16T12:30:46Z", "2023-09-04T17:56:26Z", "2023-09-04T17:55:09Z", "2023-08-29T03:17:36Z", "2023-08-28T16:45:24Z", "2023-08-25T05:15:33Z", "2023-07-19T06:25:07Z", "2023-06-01T03:08:40Z", "2023-06-01T03:13:12Z", "2023-06-01T03:13:14Z", "2023-05-31T18:58:05Z", "2023-05-03T17:06:25Z", "2023-05-03T17:10:42Z", "2023-05-03T17:14:43Z", "2023-04-30T20:22:35Z", "2023-03-07T20:29:09Z", "2023-03-07T19:59:40Z", "2023-03-07T19:57:05Z", "2023-03-07T19:53:30Z", "2023-03-04T10:07:13Z", "2023-03-04T10:07:15Z", "2023-03-02T06:50:50Z", "2023-03-02T06:05:16Z", "2023-02-25T01:38:21Z", "2022-12-08T18:46:58Z", "2022-12-09T00:30:41Z", "2022-12-09T00:33:16Z", "2022-10-19T23:54:44Z", "2022-10-19T17:47:18Z"]}, {"name": "cluster-bootstrap", "description": null, "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# cluster-bootstrap\n\nSet of constants and helpers in support of\nhttps://github.com/kubernetes/community/blob/master/contributors/design-proposals/cluster-lifecycle/bootstrap-discovery.md\n\n\n## Purpose\n\nCurrent user is kubeadm, the controller that cleans up the tokens, and the bootstrap authenticator.\n\n\n## Where does it come from?\n\n`cluster-bootstrap` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/cluster-bootstrap.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n\n## Things you should *NOT* do\n\n 1. Add API types to this repo.  This is for the helpers, not for the types.\n 2. Directly modify any files under `token` in this repo.  Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/cluster-bootstrap`.\n\n", "release_dates": []}, {"name": "code-generator", "description": "Generators for kube-like API types", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# code-generator\n\nGolang code-generators used to implement [Kubernetes-style API types](https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md).\n\n## Purpose\n\nThese code-generators can be used\n- in the context of [CustomResourceDefinition](https://kubernetes.io/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/) to build native, versioned clients,\n  informers and other helpers\n- in the context of [User-provider API Servers](https://github.com/kubernetes/apiserver) to build conversions between internal and versioned types, defaulters, protobuf codecs,\n  internal and versioned clients and informers.\n\n## Resources\n- The example [sample controller](https://github.com/kubernetes/sample-controller) shows a code example of a controller that uses the clients, listers and informers generated by this library.\n- The article [Kubernetes Deep Dive: Code Generation for CustomResources](https://cloud.redhat.com/blog/kubernetes-deep-dive-code-generation-customresources/) gives a step by step instruction on how to use this library.\n\n## Usage\n\nThe examples above are dated. The current recommended script to use is [kube_codegen.sh](kube_codegen.sh).\n\n## Compatibility\n\nHEAD of this repo will match HEAD of k8s.io/apiserver, k8s.io/apimachinery, and k8s.io/client-go.\n\n## Where does it come from?\n\n`code-generator` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/code-generator.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n", "release_dates": []}, {"name": "committee-security-response", "description": "Kubernetes Security Process and Security Committee docs", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Security\n\nKubernetes Security Release Process and Security Committee documentation.\n\nTo report a vulnerability, please refer to https://kubernetes.io/security.\n\n## Security Response Committee (SRC)\n\nThe Security Response Committee (SRC) is responsible for triaging and handling the security issues for Kubernetes. Following are the current Security Response Committee members:\n\n- CJ Cullen (**[@cjcullen](https://github.com/cjcullen)**) `<cjcullen@google.com>`\n- Craig Ingram (**[@cji](https://github.com/cji)**) `<cjingram@google.com>`\n- Joel Smith (**[@joelsmith](https://github.com/joelsmith)**) `<joelsmith@redhat.com>` [4096R/0x1688ADC79BECDDAF]\n- Micah Hausler (**[@micahhausler](https://github.com/micahhausler)**) `<mhausler@amazon.com>`\n- Mo Khan (**[@enj](https://github.com/enj)**) `<i@monis.app>`\n- Rita Zhang (**[@ritazh](https://github.com/ritazh)**) `rita.z.zhang@gmail.com`\n- Sri Saran Balaji (**[@SaranBalaji90](https://github.com/SaranBalaji90)**) `<srajakum@amazon.com>`\n- Tabitha Sable (**[@tabbysable](https://github.com/tabbysable)**) `<tabitha.c.sable@gmail.com>`\n\n### Contacting the SRC\n\nThere are a number of contact points for the SRC and release managers in charge of security releases. Please use the correct forum for the best and fastest response.\n\n| List or Group | Visibility | Uses |\n| ------------- | ---------- | ---- |\n| security@kubernetes.io | Private | Kubernetes security disclosures. This list is closely monitored and triaged by the SRC. [See the disclosure guide for full details.](http://kubernetes.io/security) |\n| [kubernetes-security-discuss Google Group](https://groups.google.com/forum/#!forum/kubernetes-security-discuss) | Public | Discussion about security disclosure handling, this document, and other updates. |\n| release-managers-private@kubernetes.io | Private | Release Managers private discussion. All members are subscribed to security@kubernetes.io. |\n| security-discuss-private@kubernetes.io | Private | SRC private discussion. All members are subscribed to security@kubernetes.io |\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n", "release_dates": []}, {"name": "community", "description": "Kubernetes community content", "language": "Jupyter Notebook", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Community\n\nWelcome to the Kubernetes community!\n\nThis is the starting point for joining and contributing to the Kubernetes community - improving docs, improving code, giving talks etc.\n\nTo learn more about the project structure and organization, please refer to [Project Governance] information.\n\n## Communicating\n\nThe [communication](communication/) page lists communication channels like chat,\nissues, mailing lists, conferences, etc.\n\nFor more specific topics, try a SIG.\n\n## Governance\n\nKubernetes has the following types of groups that are officially supported:\n\n* **Committees** are named sets of people that are chartered to take on sensitive topics.\n  This group is encouraged to be as open as possible while achieving its mission but, because of the nature of the topics discussed, private communications are allowed.\n  Examples of committees include the steering committee and things like security or code of conduct.\n* **Special Interest Groups (SIGs)** are persistent open groups that focus on a part of the project.\n  SIGs must have open and transparent proceedings.\n  Anyone is welcome to participate and contribute provided they follow the Kubernetes Code of Conduct.\n  The purpose of a SIG is to own and develop a set of **subprojects**.\n  * **Subprojects** Each SIG can have a set of subprojects.\n    These are smaller groups that can work independently.\n    Some subprojects will be part of the main Kubernetes deliverables while others will be more speculative and live in the `kubernetes-sigs` github org.\n* **Working Groups** are temporary groups that are formed to address issues that cross SIG boundaries.\n  Working groups do not own any code or other long term artifacts.\n  Working groups can report back and act through involved SIGs.\n\nSee the [full governance doc](governance.md) for more details on these groups.\n\nA SIG can have its own policy for contribution, described in a `README` or `CONTRIBUTING` file in the SIG folder in this repo (e.g. [sig-cli/CONTRIBUTING.md](sig-cli/CONTRIBUTING.md)), and its own mailing list, slack channel, etc.\n\nIf you want to edit details about a SIG (e.g. its weekly meeting time or its leads),\nplease follow [these instructions](./generator) that detail how our docs are auto-generated.\n\n## Learn to Build\n\nLinks in [contributors/devel/README.md](contributors/devel/README.md)\nlead to many relevant technical topics.\n\n## Contribute\n\nA first step to contributing is to pick from the [list of kubernetes SIGs](sig-list.md).\nStart attending SIG meetings, join the slack channel and subscribe to the mailing list.\nSIGs will often have a set of \"help wanted\" issues that can help new contributors get involved.\n\nThe [Contributor Guide](contributors/guide/README.md) provides detailed instruction on how to get your ideas and bug fixes seen and accepted, including:\n1. How to [file an issue]\n1. How to [find something to work on]\n1. How to [open a pull request]\n\n## Membership\n\nWe encourage all contributors to become members. We aim to grow an active, healthy community of contributors, reviewers, and code owners. Learn more about requirements and responsibilities of membership in our [Community Membership] page.\n\n[Project Governance]:/governance.md\n[Developer's Guide]: contributors/devel/development.md\n[Contributor Guide]:\ncontributors/guide/README.md\n[file an issue]:\ncontributors/guide/first-contribution.md#file-an-issue\n[find something to work on]:\ncontributors/guide/first-contribution.md#find-something-to-work-on\n[open a pull request]:\ncontributors/guide/contributing.md#opening-a-pull-request\n[Community Membership]:/community-membership.md\n", "release_dates": []}, {"name": "component-base", "description": "Shared code for kubernetes core components", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "## component-base\n\n## Purpose\n\nImplement KEP 32: https://github.com/kubernetes/enhancements/blob/master/keps/sig-cluster-lifecycle/wgs/783-component-base/README.md\n\nThe proposal is essentially about refactoring the Kubernetes core package structure in a way that all core components may share common code around:\n - ComponentConfig implementation\n - flag and command handling\n - HTTPS serving\n - delegated authn/z\n - logging.\n\n## Compatibility\n\nThere are *NO compatibility guarantees* for this repository, yet.  It is in direct support of Kubernetes, so branches\nwill track Kubernetes and be compatible with that repo.  As we more cleanly separate the layers, we will review the\ncompatibility guarantee. We have a goal to make this easier to use in the future.\n\n\n## Where does it come from?\n\nThis repository is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/component-base.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n## Things you should *NOT* do\n\n 1. Directly modify any files in this repo. Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/component-base`.\n 2. Expect compatibility. This repo is changing quickly in direct support of Kubernetes.\n\n### OWNERS\n\nWG Component Standard is working on this refactoring process, which is happening incrementally, starting in the v1.14 cycle.\nSIG API Machinery and SIG Cluster Lifecycle owns the code.\n\n", "release_dates": []}, {"name": "component-helpers", "description": "High-level helpers for Kubernetes components", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# component-helpers\n\nThis repository provides helpers primarily for core components (core components as described in [Create a k8s.io/component-base repo](https://github.com/kubernetes/enhancements/blob/master/keps/sig-cluster-lifecycle/wgs/783-component-base/README.md#component-definition)) which are required by at least two separate binaries in kubernetes org.\nYet, still with a high level of abstraction.\n\n`k8s.io/component-base` staging repository was considered as a candidate for hosting the helpers. Although, since the helpers are not required by the core components, the repository was deemed unsuitable.\n\nThe only allowed kubernetes dependencies are `k8s.io/apimachinery`, `k8s.io/api` and `k8s.io/client-go`.\n\n## Purpose\n\nOne of the goals is to provide a better location for helpers currently located under `k8s.io/kubernetes/pkg/apis`.\n\nRecent effort of moving [scheduling\n framework](https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/) under\n`k8s.io/kube-scheduler` requires duplication of many helper functions\n(see [#91782](https://github.com/kubernetes/kubernetes/issues/91782) for more details).\nImporting the helpers from this repository allows to minimize or remove already existing duplication.\n\nAnother example is shared RBAC code which is blocking extracting kubectl to staging (see https://github.com/kubernetes/enhancements/issues/1020). This problem dates all the way back to December 2018 (see SIG-CLI call from December 19, 2018: https://docs.google.com/document/d/1r0YElcXt6G5mOWxwZiXgGu_X6he3F--wKwg-9UBc29I/edit?pli=1). Recently the topic was touched during sig-auth call (see https://docs.google.com/document/d/1woLGRoONE3EBVx-wTb4pvp4CI7tmLZ6lS26VTbosLKM/edit?ts=5ef3be6a#heading=h.etc9yylhln8x).\n\n## Compatibility\n\nThere are NO compatibility guarantees for this repository. It is in direct support of Kubernetes, so branches will track Kubernetes and be compatible with that repo. As we more cleanly separate the layers, we will review the compatibility guarantee.\n\n## Where does it come from?\n\nThis repo is synced from https://github.com/kubernetes/kubernetes/tree/master/staging/src/k8s.io/component-helpers.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here by a bot.\n\n", "release_dates": []}, {"name": "contributor-site", "description": "Code for kubernetes.dev", "language": "HTML", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Contributor Site\n\nThis repository contains the [Hugo][hugo] site and generator scripts for the\nKubernetes Contributor site. The published website is available at\nhttps://kubernetes.dev/ (served via Netlify).\n\n## Site content\n\nThe content for the Contributor Site is sourced from multiple locations.\nContent managed within this repository is generated from [Markdown]\nfound within the [`content`][ct] directory. To update the site's content,\nmake changes to the Markdown sources and [submit a pull request][pr] to this\nrepository.\n\nSome content is externally sourced and changes to that must be made in the\noriginal location. A list of sources and their locations within the\n[`content`][ct] is available below:\n\n### External sources\n\n- **Source:** https://git.k8s.io/community/contributors/guide <br>\n  **Destination:** `/guide`\n- **Source:** https://github.com/cncf/foundation/blob/master/code-of-conduct.md <br>\n  **Destination:** `/code-of-conduct.md`\n- **Source:** https://git.k8s.io/sig-release/releases/release-1.18/README.md <br>\n  **Destination:** `/release.md`\n\n## Running the site locally\n\nTo develop site content, you can run the site locally using [Hugo][hugo] in\ntwo ways:\n\n1. [Inside a Docker container](#using-docker)\n2. [Natively](#natively) (not inside a Docker container)\n\nWhen you make changes to the site's content, Hugo will automatically update\nthe site and refresh your browser window.\n\n### Using Docker\n\nThe easiest and most cross-system-compatible way to run the Contributor\nSite is to use [Docker][docker]. To begin, create the docker image to be used\nwith generating the site by executing `make container-image`.\n\nTo ensure you can view the site with externally sourced content, run\n`make container-gen-content` before previewing the site by with\n`make container-server`.\n\n**NOTE to Apple Silicon Mac Users**\n\nBefore proceeding with the build steps, please ensure that you set the\n`DOCKER_DEFAULT_PLATFORM` environment variable to `linux/amd64` by using the \nfollowing command: \n\n```\nexport DOCKER_DEFAULT_PLATFORM=linux/amd64\n```\n\n### Natively\n\nFor instructions on installing and using Hugo, see the [Hugo Documentation][hugo-docs].\nNote that the extended version is required.\n\nIn addition to Hugo, the [postcss-cli] and [autoprefixer] JavaScript packages are\nrequired. These can be installed via the [Node Package Manager][npm] (`npm`) from a\nrecent version of [nodejs] with `npm install -g postcss-cli autoprefixer`.\n\nThe Contributor Site uses the [docsy] theme. It is included as a [git submodule].\nTo fetch docsy and its requirements, run the command:\n\n```\ngit submodule update --init --recursive --depth 1\n```\n\nTo ensure you can view the site with externally sourced content, run\n`make gen-content` before previewing the site by with `make server`.\n\n**NOTE to MacOS Users**\n\nThe `hack/gen-content.sh` script requires the gnu version\nof base packages such as `find`, `grep`, and `sed`. \n\n```\nbrew install coreutils findutils grep gnu-sed gnu-tar make readlink\n```\n\nYou will then need to update your path to include these:\n\n```\nexport PATH=\"/usr/local/opt/coreutils/libexec/gnubin:$PATH\"\n```\n\n## Community, discussion, contribution, and support\n\nThis project is managed by [SIG Contributor Experience][sig-contribex] as a\npart of [KEP-2225][kep-2225]\n\nYou can reach the maintainers of this project at:\n\n- [Slack][sig-contribex-slack]\n- [Mailing List][sig-contribex-list]\n\n## Evolution of this site:\n\nWe\u2019re building out this site in real-time! Want to join us and help? Here\u2019s what we have in store for next iterations:\n\n* [ ] Contributor guide/handbook: Feature launch date estimated January 2023\n* [ ] Developers' guide/handbook\n* [ ] Directory of Kubernetes SIGs and other community groups\n* [ ] Listing events beyond just Contributor Summits\n* [ ] Pathways to success for [new Kubernetes contributors](https://git.k8s.io/community/community-membership.md) and mentoring programs\n* [ ] Refactoring the hugo code and glue code behind the site\n\nSee the [Issues] for tasks and projects in progress\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the\n[Kubernetes Code of Conduct](code-of-conduct.md).\n\n[hugo]: https://gohugo.io/\n[Markdown]: https://www.markdownguide.org/\n[ct]: ./content/\n[pr]: https://help.github.com/en/articles/about-pull-requests\n[hugo-docs]: https://gohugo.io/getting-started/installing\n[npm]: https://nodejs.org/en/download/package-manager\n[frontmatter]: https://gohugo.io/content-management/front-matter/\n[docker]: https://www.docker.com/get-started\n[sig-contribex]: https://git.k8s.io/community/sig-contributor-experience/README.md\n[sig-contribex-slack]: http://slack.k8s.io/#sig-contribex\n[sig-contribex-list]: https://groups.google.com/forum/#!forum/kubernetes-sig-contribex\n[kep-2225]: https://github.com/kubernetes/enhancements/tree/master/keps/sig-contributor-experience/2225-contributor-site\n[docsy]: https://docsy.dev\n[postcss-cli]: https://postcss.org/\n[autoprefixer]: https://github.com/postcss/autoprefixer\n[git submodule]: https://git-scm.com/book/en/v2/Git-Tools-Submodules\n[Issues]: https://github.com/kubernetes/contributor-site/issues\n", "release_dates": []}, {"name": "controller-manager", "description": "This repo is intended to contain common public library code for kube-controller-manager, cloud-controller-manager as well as any other controller managers which people build.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Controller-manager\n\n## Purpose\n\nThis library contains common code for controller managers. Principally its for\nthe Kube-Controller-Manager and Cloud-Controller-Manager. However other\ncontroller managers are welcome to use this code.\n\n\n## Compatibility\n\nThere are *NO compatibility guarantees* for this repository, yet.  It is in direct support of Kubernetes, so branches\nwill track Kubernetes and be compatible with that repo.  As we more cleanly separate the layers, we will review the\ncompatibility guarantee. We have a goal to make this easier to use in the future.\n\n\n## Where does it come from?\n\nThis package comes from the common code between kube-controller-manager and\ncloud-controller-manager. The intent is for it to contain our current\nunderstanding of the right way to build a controller manager. There are legacy\naspects of these controller managers which should be cleaned before adding them\nhere.\n`controller-manager` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/controller-manager.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n\n## Things you should *NOT* do\n\n 1. Directly modify any files under `pkg` in this repo.  Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/controller-manager`.\n 2. Expect compatibility.  This repo is currently changing rapidly in direct support of\n    Kubernetes and the controller-manager processes and the cloud provider\n    extraction effort.\n\n", "release_dates": []}, {"name": "cri-api", "description": "Container Runtime Interface (CRI) \u2013 a plugin interface which enables kubelet to use a wide variety of container runtimes.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "## Purpose\n\nThis repository contains the definitions for the Container Runtime Interface (CRI).\nCRI is a plugin interface which enables kubelet to use a wide variety of container runtimes,\nwithout the need to recompile. CRI consists of a protocol buffers and gRPC API.\nRead more about CRI API at [kubernetes docs](https://kubernetes.io/docs/concepts/architecture/cri/).\n\nThe repository [kubernetes/cri-api](https://github.com/kubernetes/cri-api) is a mirror of https://github.com/kubernetes/kubernetes/tree/master/staging/src/k8s.io/cri-api.\nPlease do **not** file issues or submit PRs against the [kubernetes/cri-api](https://github.com/kubernetes/cri-api)\nrepository as it is readonly, all development is done in [kubernetes/kubernetes](https://github.com/kubernetes/kubernetes).\n\nThe CRI API is defined in [kubernetes/kubernetes](https://github.com/kubernetes/kubernetes)\nrepository and is **only** intended to be used for kubelet to container runtime \ninteractions, or for node-level troubleshooting using a tool such as `crictl`.\nIt is **not** a common purpose container runtime API for general use, and is intended\nto be Kubernetes-centric. We try to avoid it, but there may be logic within a container\nruntime that optimizes for the order or specific parameters of call(s) that the kubelet\nmakes.\n\n## Version skew policy\n\nOn a single Node there may be installed multiple components implementing\ndifferent versions of CRI API.\n\nFor example, on a single node there might be:\n\n- _Kubelet_ may call into _Container Runtime_ (e.g. [containerd](https://containerd.io))\n  and _Image Service Proxy_ (e.g. [stargz-snapshotter](https://github.com/containerd/stargz-snapshotter)).\n  _Container Runtime_ may be versioned with the OS Image, _Kubelet_ is installed\n  by system administrator and _Image Service proxy_ is versioned by the third party vendor.\n- _Image Service Proxy_ calls into _Container Runtime_.\n- _CRI tools_ (e.g. [crictl](https://kubernetes.io/docs/tasks/debug/debug-cluster/crictl/))\n  may be installed by end user to troubleshoot, same as a third party daemonsets.\n  All of them are used to call into the _Container Runtime_ to collect container information.\n\nSo on a single node it may happen that _Container Runtime_ is serving a newer\nversion'd kubelet and older versioned crictl. This is a supported scenario within\nthe version skew policy.\n\n### Version Skew Policy for CRI API\n\nCRI API has two versions:\n- Major semantic version (known versions are `v1alpha2` ([removed in 1.26](https://kubernetes.io/blog/2022/12/09/kubernetes-v1-26-release/#cri-v1alpha2-removed)), `v1`).\n- Kubernetes version (for example: `@1.23`). Note, the `cri-api` Golang library is versioned as `0.23` as it doesn't guarantee Go types backward compatibility.\n\nMajor semantic version (e.g. `v1`) is used to introduce breaking changes\nand major new features that are incompatible with the current API.\n\nKubernetes version is used to indicate a specific feature set implemented\non top of the major semantic version. All changes made without the change\nof a major semantic version API must be backward and forward compatible.\n\n- _Kubelet_ must work with the older _Container Runtime_ if it implements\n  the same semantic version of CRI API (e.g. `v1`) of up to three Kubernetes minor\n  versions back. New features implemented in CRI API must be gracefully degraded.\n  For example, _Kubelet_ of version 1.26 must work with _Container Runtime_\n  implementing `k8s.io/cri-api@v0.23.0`+.\n- _Kubelet_ must work with _Container Runtime_ if it implements\n  the same semantic version of CRI API (e.g. `v1`) of up to\n  three minor versions up. New features implemented in CRI API must not change\n  behavior of old method calls and response values. For example, _Kubelet_ of\n  version 1.22 must work with _Container Runtime_ implementing `k8s.io/cri-api@v0.25.5`.\n\n\n## Versioning\n\nThis library contains go classes generated from the CRI API protocol buffers and gRPC API.\n\nThe library versioned as `0.XX` as Kubernetes doesn't provide any guarantees\non backward compatibility of Go wrappers between versions. However CRI API itself\n(protocol buffers and gRPC API) is marked as stable `v1` version and it is\nbackward compatible between versions.\n\nVersions like `v0.<minor>.<patch>` (e.g. `v0.25.5`) are considered stable.\nIt is discouraged to introduce CRI API changes in patch releases and recommended\nto use versions like `v0.<minor>.0`.\n\nAll alpha and beta versions (e.g. `k8s.io/cri-api@v0.26.0-beta.0`) should be\nbackward and forward compatible.\n\n## Feature development\n\nSome features development requires changes in CRI API and corresponding changes\nin _Container Runtime_. Coordinating between Kubernetes branches and release\nversions and _Container Runtime_ versions is not always trivial.\n\nThe recommended feature development flow is following:\n\n- Review proposed CRI API changes during the KEP review stage.\n  Some field names and types may not be spelled out exactly at this stage.\n- Locally implement a prototype that implement changes in both - Kubernetes and Container Runtime.\n- Submit a Pull Request for Kubernetes implementing CRI API changes alongside the feature code.\n  Feature must be developed to degrade gracefully when used with older Container Runtime\n  according to the Version Skew policy.\n- Once PR is merged, wait for the next Kubernetes release tag being produced.\n  Find the corresponding CRI API tag (e.g. `k8s.io/cri-api@v0.26.0-beta.0`).\n- This tag can be used to implement the feature in Container Runtime. It is recommended\n  to switch to the stable tag like (`k8s.io/cri-api@v0.26.0`) once available.\n\n## Change history\n\nHere is the change history of the Container Runtime Interface protocol:\n\n### v1.20\n\n`git diff v1.19.0 v1.20.0 -- staging/src/k8s.io/cri-api/pkg/apis/runtime/v1/api.proto`\n\n- CRI [v1 introduced](https://github.com/kubernetes/kubernetes/pull/96387)\n\n### v1.21\n\n`git diff v1.20.0 v1.21.0 -- staging/src/k8s.io/cri-api/pkg/apis/runtime/v1/api.proto`\n\nNo changes\n\n### v1.22\n\n`git diff v1.21.0 v1.22.0 -- staging/src/k8s.io/cri-api/pkg/apis/runtime/v1/api.proto`\n\n- [Windows host process support](https://github.com/kubernetes/kubernetes/pull/99576)\n  - `PodSandboxConfig` has `windows` field  of type `WindowsPodSandboxConfig`\n  - New type `WindowsPodSandboxConfig` introduced\n  - New type `WindowsSandboxSecurityContext` introduced\n  - The type `WindowsContainerSecurityContext` has a new `host_process` boolean field\n\n- [Feature: add unified on CRI to support cgroup v2](https://github.com/kubernetes/kubernetes/pull/102578)\n - The type `LinuxContainerResources` has a new field `unified` which is a map of strings\n\n- [Alpha node swap support](https://github.com/kubernetes/kubernetes/pull/102823)\n  - The type `LinuxContainerResources` has a new `memory_swap_limit_in_bytes` int64 field\n\n### v1.23\n\n`git diff v1.22.0 v1.23.0 -- staging/src/k8s.io/cri-api/pkg/apis/runtime/v1/api.proto`\n\n- [CRI: add fields for pod level stats to satisfy the /stats/summary API](https://github.com/kubernetes/kubernetes/pull/102789)\n  - New functions `PodSandboxStats`, `ListPodSandboxStats` with the corresponding types of request and response objects are introduced\n\n- [pass sandbox resource requirements over CRI](https://github.com/kubernetes/kubernetes/pull/104886)\n  - New fields on `LinuxPodSandboxConfig`: `overhead` and `resources` of type `LinuxContainerResources`.\n\n- [prevents garbage collection from removing pinned images](https://github.com/kubernetes/kubernetes/pull/103299)\n  - The type `Image` has a new boolean field `pinned`\n\n### v1.24\n\n`git diff v1.23.0 v1.24.0 -- staging/src/k8s.io/cri-api/pkg/apis/runtime/v1/api.proto`\n\n- [Update CRI-API Capabilities to include a field that allows us to set ambient capabilities](https://github.com/kubernetes/kubernetes/pull/104620)\n  - The type `Capability` has a new string field `add_ambient_capabilities`\n\n- [CRI-API - Add rootfs size to WindowsContainerResources](https://github.com/kubernetes/kubernetes/pull/108894)\n  - The type `WindowsContainerResources` has a new int64 field `rootfs_size_in_bytes`\n\n### v1.25\n\n`git diff v1.24.0 v1.25.0 -- staging/src/k8s.io/cri-api/pkg/apis/runtime/v1/api.proto`\n\n\n- [kubelet: add CRI definitions for user namespaces](https://github.com/kubernetes/kubernetes/pull/110535)\n  - The new type `UserNamespace` introduced to represent user namespaces id mapping\n  - The type `NamespaceOption` has a new field `userns_options` of type `UserNamespace`\n\n- [Minimal checkpointing support](https://github.com/kubernetes/kubernetes/pull/104907)\n  - The new method `CheckpointContainer` introduced with the corresponding request and response types\n\n- [Update CRI API to support Evented PLEG](https://github.com/kubernetes/kubernetes/pull/111642)\n  - The new streaming method `GetContainerEvents` is introduced with the corresponding request and response types\n\n- [CRI changes to support in-place pod resize](https://github.com/kubernetes/kubernetes/pull/111645)\n  - The new type `ContainerResources` is introduced\n  - The type `ContainerStatus` has a new field `resources` of type `ContainerResources`\n  - The semantic of `UpdateContainerResources` updated. The method must be implemented as synchronous and return error on failure\n\n### v1.26\n\n`git diff v1.25.0 v1.26.0 -- staging/src/k8s.io/cri-api/pkg/apis/runtime/v1/api.proto`\n\n- [CRI: Add Windows Podsandbox Stats](https://github.com/kubernetes/kubernetes/pull/110754)\n  - Added fields to the type `WindowsPodSandboxStats` expressing stats required to be collected from windows pods.\n\n- [Windows hostnetwork alpha](https://github.com/kubernetes/kubernetes/pull/112961)\n  - New type `WindowsNamespaceOption` introduced\n  - The type `WindowsSandboxSecurityContext` has a new field `namespace_options` of type `WindowsNamespaceOption`\n\n- [Improve the API description of `PodSecurityContext.SupplementalGroups` to clarify its unfamiliar behavior](https://github.com/kubernetes/kubernetes/pull/113047)\n  - Clarified the expected behavior of `SupplementalGroups` field of `PodSecurityContext`\n\n- [Add Support for Evented PLEG](https://github.com/kubernetes/kubernetes/pull/111384)\n  - The type `ContainerEventResponse` updated: the field `pod_sandbox_metadata` removed and fields `pod_sandbox_status` and `containers_statuses` added.\n  - The type `PodSandboxStatusResponse` has a new fields `containers_statuses` and `timestamp`\n\n### v1.27\n\n`git diff v1.26.0 v1.27.0 -- staging/src/k8s.io/cri-api/pkg/apis/runtime/v1/api.proto`\n\n- [CRI: Add CDI device info for containers](https://github.com/kubernetes/kubernetes/pull/115891/)\n  - New type `CDIDevice` was introduced and added to container config\n\n- [Add mappings for volumes](https://github.com/kubernetes/kubernetes/pull/116377)\n  - Added new fields to the type `Mount` expressing runtime UID/GID mappings for the mount.\n\n### v1.28\n\n`git diff v1.27.0 v1.28.0 -- staging/src/k8s.io/cri-api/pkg/apis/runtime/v1/api.proto`\n\n- [cri-api: fix comment lines about PROPAGATION_PRIVATE](https://github.com/kubernetes/kubernetes/pull/115704)\n  - Fixed comment lines about PROPAGATION_PRIVATE\n\n- [Add user specified image to CRI ContainerConfig](https://github.com/kubernetes/kubernetes/pull/118652)\n  - Added the `user_specified_image` field to type `ImageSpec`\n\n- [kubelet: get cgroup driver config from CRI ](https://github.com/kubernetes/kubernetes/pull/118770)\n  - Added rpc for querying runtime configuration\n  - Added cavieats about cgroup driver field\n\n- [Add swap to stats to Summary API and Prometheus endpoints (/stats/summary and /metrics/resource)](https://github.com/kubernetes/kubernetes/pull/118865)\n  - Added `SwapUsage` type\n  - Added `SwapUsage` field to `ContainerStats` type\n\n- [Expose commit memory used in WindowsMemoryUsage struct](https://github.com/kubernetes/kubernetes/pull/119238)\n  - Added the `commit_memory_bytes` field to type `WindowsMemoryUsage`\n\n### v1.29\n\n`git diff v1.28.0 v1.29.0 -- staging/src/k8s.io/cri-api/pkg/apis/runtime/v1/api.proto`\n\n- [Add runtime handler field to ImageSpec struct](https://github.com/kubernetes/kubernetes/pull/121121)\n  - Added `runtime_handler` field to type `ImageSpec`\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community\npage](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this repository at:\n\n- Slack: #sig-node (on https://kubernetes.slack.com -- get an\n  invite at [slack.kubernetes.io](https://slack.kubernetes.io))\n- Mailing List:\n  https://groups.google.com/forum/#!forum/kubernetes-sig-node\n\n### Code of Conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes\nCode of Conduct](code-of-conduct.md).\n\n### Contribution Guidelines\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for more information. Please note that [kubernetes/cri-api](https://github.com/kubernetes/cri-api)\nis a readonly mirror repository, all development is done at [kubernetes/kubernetes](https://github.com/kubernetes/kubernetes).\n", "release_dates": []}, {"name": "csi-translation-lib", "description": "Staging repo for CSI Migration/Translation libraries", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "## Purpose\n\nThis repository contains functions to be consumed by various Kubernetes and\nout-of-tree CSI components like external provisioner to facilitate migration of\ncode from Kubernetes In-tree plugin code to CSI plugin repositories.\n\nConsumers of this repository can make use of functions like `TranslateToCSI` and\n`TranslateToInTree` functions to translate PV sources.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community\npage](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this repository at:\n\n- Slack: #sig-storage (on https://kubernetes.slack.com -- get an\n  invite at slack.kubernetes.io)\n- Mailing List:\n  https://groups.google.com/forum/#!forum/kubernetes-sig-storage\n\n### Code of Conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes\nCode of Conduct](code-of-conduct.md).\n\n### Contibution Guidelines\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for more information.\n\n", "release_dates": []}, {"name": "dashboard", "description": "General-purpose web UI for Kubernetes clusters", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Dashboard\n\n[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/dashboard)](https://goreportcard.com/report/github.com/kubernetes/dashboard)\n[![Coverage Status](https://codecov.io/github/kubernetes/dashboard/coverage.svg?branch=master)](https://codecov.io/github/kubernetes/dashboard?branch=master)\n[![GitHub release](https://img.shields.io/github/release/kubernetes/dashboard.svg)](https://github.com/kubernetes/dashboard/releases/latest)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/kubernetes/dashboard/blob/master/LICENSE)\n\n## Introduction\n\nKubernetes Dashboard is a general purpose, web-based UI for Kubernetes clusters. It allows users to manage applications running in the cluster and troubleshoot them, as well as manage the cluster itself.\n\n![Dashboard UI workloads page](docs/images/overview.png)\n\n## Getting Started\n\n**IMPORTANT:** Read the [Access Control](docs/user/access-control/README.md) guide before performing any further steps. The default Dashboard deployment contains a minimal set of RBAC privileges needed to run.\n\n## Installation\n\nKubernetes Dashboard supports both Helm and Manifest-based installation. Since release `v3.0.0` using Helm Chart should be faster and simpler in general as it will install\ndependencies such as `cert-manager`, `nginx-ingress-controller` and `metrics-server` for you. In case you are using different software to handle certificates, ingress/egress traffic, etc.\nit is possible to disable those dependencies by overriding [helm chart values](charts/kubernetes-dashboard/values.yaml).\n\n### Helm\n\nYou can install Dashboard using Helm as described [here](https://artifacthub.io/packages/helm/k8s-dashboard/kubernetes-dashboard).\n\n### Manifest\n\nYou can install Dashboard using `kubectl` as described in the installation instructions that can be found in the [latest release](https://github.com/kubernetes/dashboard/releases/latest).\n\n## Access\n\nYou can access Dashboard as described in the instructions that can be found in the [access guide](docs/user/accessing-dashboard/README.md).\n\n## Create An Authentication Token (RBAC)\nTo find out how to create sample user and log in follow [Creating sample user](docs/user/access-control/creating-sample-user.md) guide.\n\n**NOTE:**\n* Kubeconfig Authentication method does not support external identity providers or certificate-based authentication.\n* [Metrics-Server](https://github.com/kubernetes-sigs/metrics-server) has to be running in the cluster for the metrics and graphs to be available. Read more about it in [Integrations](docs/user/integrations.md) guide.\n\n## Documentation\n\nDashboard documentation can be found on [docs](docs/README.md) directory which contains:\n\n* [Common](docs/common/README.md): Entry-level overview.\n* [User Guide](docs/user/README.md): [Accessing Dashboard](docs/user/accessing-dashboard/README.md) and more for users.\n* [Developer Guide](docs/developer/README.md): Important information for contributors that would like to test, run and work on Dashboard locally.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n* [**#sig-ui on Kubernetes Slack**](https://kubernetes.slack.com)\n* [**kubernetes-sig-ui mailing list** ](https://groups.google.com/forum/#!forum/kubernetes-sig-ui)\n* [**Issue tracker**](https://github.com/kubernetes/dashboard/issues)\n* [**SIG info**](https://github.com/kubernetes/community/tree/master/sig-ui)\n* [**Roles**](ROLES.md)\n\n### Contribution\n\nLearn how to start contributing to the [Contributing Guideline](CONTRIBUTING.md).\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n## License\n\n[Apache License 2.0](https://github.com/kubernetes/dashboard/blob/master/LICENSE)\n\n----\n_Copyright 2019 [The Kubernetes Dashboard Authors](https://github.com/kubernetes/dashboard/graphs/contributors)_\n", "release_dates": ["2023-07-07T15:00:03Z", "2022-09-16T11:34:57Z", "2022-08-12T13:22:39Z", "2022-05-31T15:21:40Z", "2022-03-10T12:29:27Z", "2022-02-03T15:47:52Z", "2021-10-15T07:31:02Z", "2021-06-16T10:43:50Z", "2021-06-10T12:25:14Z", "2021-02-18T14:33:47Z", "2020-12-11T11:27:22Z", "2020-12-03T13:21:20Z", "2020-09-03T13:58:33Z", "2020-06-22T14:14:18Z", "2020-06-20T10:25:52Z", "2020-05-21T18:40:29Z", "2020-04-21T13:16:28Z", "2020-03-30T11:37:14Z", "2020-03-13T12:13:44Z", "2020-02-07T12:15:01Z", "2020-02-06T14:00:10Z", "2020-01-30T21:37:25Z", "2020-01-16T14:03:47Z", "2020-01-09T13:23:25Z", "2019-12-06T14:28:18Z", "2019-12-05T12:47:33Z", "2019-11-14T12:32:40Z", "2019-10-14T15:47:41Z", "2019-08-29T08:17:37Z", "2019-08-01T14:37:53Z"]}, {"name": "design-proposals-archive", "description": "Archive of Kubernetes Design Proposals", "language": "Makefile", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Design Proposals Archive\n\n\nThis directory contains **historical** Kubernetes design documents and proposals.\nThey should not be considered up to date or a reflection of the current state of\nthe Kubernetes project.\n\nFor current Kubernetes Enhancement Proposals, see the [kubernetes/enhancements] repo.\n\n\n[kubernetes/enhancements]: https://github.com/kubernetes/enhancements/\n", "release_dates": []}, {"name": "dns", "description": "Kubernetes DNS service", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes DNS\n\n[![Build Status](https://travis-ci.org/kubernetes/dns.svg?branch=master)](https://travis-ci.org/kubernetes/dns)\n[![Coverage Status](https://coveralls.io/repos/github/kubernetes/dns/badge.svg?branch=master)](https://coveralls.io/github/kubernetes/dns?branch=master)\n[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/dns)](https://goreportcard.com/report/github.com/kubernetes/dns)\n\nThis is the repository for [Kubernetes DNS(kube-dns and nodelocaldns)](https://kubernetes.io/docs/tasks/access-application-cluster/configure-dns-cluster/).\n\n## Images\n\n* [kube-dns](https://kubernetes.io/docs/tasks/access-application-cluster/configure-dns-cluster/)\n* [sidecar](docs/sidecar/README.md)\n* [dnsmasq](images/dnsmasq)\n* [node-cache](https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/)\n\n## Building\n\n`make` targets:\n\n| target | description |\n| ---- | ---- |\n|all, build   | build all binaries |\n|test         | run unit tests |\n|containers   | build the containers |\n|images-clean | clear image build artifacts from workdir |\n|push         | push containers to the registry |\n|help         | this help message |\n|version      | show package version |\n|{build,containers,push}-ARCH | do action for specific ARCH |\n|all-{build,containers,push}  | do action for all ARCH |\n|only-push-BINARY             | push just BINARY |\n\n* Setting `VERBOSE=1` will show additional build logging.\n* Setting `VERSION` will override the container version tag.\n\n## Vulnerability patching\n\nVulnerability patches are mainly for debian-base or debian-iptables images. They can be updated to the latest by modifying [rules.mk](https://github.com/kubernetes/dns/blob/master/rules.mk#L32-L33) and [dnsmasq Makefile](https://github.com/kubernetes/dns/blob/f44ede5f559a9a29fa23b438e6ce0cb70934d834/images/dnsmasq/Makefile#L30-L32).\n[Example PR](https://github.com/kubernetes/dns/pull/475).\n\nOnce the PR has merged, a new release tag should be cut. The rest of the release process is described below.\n\n## Release process\nFollow these steps to make changes and release a new binary.\n\n1. Make the necessary code changes and create a PR.\n2. Build and test locally (`make images-clean`; `make build`; `make containers`; `make test`). \n3. To build just the node-cache container, use `make containers CONTAINER_BINARIES=node-cache`.\n4. The same steps are executed via the presubmit script `presubmits.sh` which is run by the [test-infra prow job.](https://github.com/kubernetes/test-infra/blob/88cd2798f36010e071a30c9827f90e647b59fc65/config/jobs/kubernetes/sig-network/sig-network-misc.yaml#L182)\n5. Merge the PR.\n6. Cut a new release tag. We use [semantic versioning](http://semver.org) to\n   name releases.\n   Example:\n   ```\n   git tag -a 1.21.4 -m \"Build images using golang 1.17.\"\n   git push upstream 1.21.4\n   ```\n4. Wait for container images to be pushed via cloudbuild yaml. This will be done automatically by\n   `k8s.io/test-infra/.../k8s-staging-dns.yaml`. A manual cloud build can be submitted via\n   `gcloud builds submit --config cloudbuild.yaml`, but this requires owner permissions in k8s-staging-dns project.\n   The automated job pushes images for all architectures and makes them available in `gcr.io/k8s-staging-dns`.\n   Status for build jobs can be checked at - https://testgrid.k8s.io/sig-network-dns#dns-push-images\n5. Promote the images to `gcr.io/k8s-artifacts-prod` using the process described\n   in [this](https://github.com/kubernetes/k8s.io/tree/main/k8s.gcr.io#image-promoter) link.\n   The image SHAs should be added to [`images/k8s-staging-dns/images.yaml`](https://github.com/kubernetes/k8s.io/blob/main/k8s.gcr.io/images/k8s-staging-dns/images.yaml).\n   The SHAs can be obtained by running the command `python parse-image-sha.py <TAG>`\n   This will return the SHAs for kube-dns as well as node-cache images. Node-cache images are always promoted, kube-dns images are promoted if there is a change to kubedns/vulnerability fix.\n6. Images will be available in the repo registry.k8s.io/dns/. The node-cache image with tag 1.15.14 can be found at registry.k8s.io/dns/k8s-dns-node-cache:1.15.14. Older versions are at registry.k8s.io/k8s-dns-node-cache:<TAG>\n7. Submit a PR for the kubernetes/kubernetes repository to switch to the new\n   version of the containers. Example - https://github.com/kubernetes/kubernetes/pull/106189\n   \n## Version compatibility\n\nThere is no version compatibility requirements with Kubernetes releases. Version numbers in this repo are not related to Kubernetes versions.\n", "release_dates": ["2024-02-14T15:31:51Z", "2023-11-15T18:25:04Z", "2023-11-03T15:27:13Z", "2023-06-26T12:31:06Z", "2023-06-09T09:15:50Z", "2023-02-22T15:17:48Z", "2023-02-17T12:31:58Z", "2023-02-13T21:15:06Z", "2023-01-12T09:02:38Z", "2023-01-04T12:58:25Z", "2022-11-09T12:25:56Z", "2022-11-09T12:25:02Z", "2022-10-05T11:00:05Z", "2022-09-27T08:47:36Z", "2022-09-13T19:59:22Z", "2022-09-01T15:29:23Z", "2022-07-31T11:22:30Z", "2022-07-27T19:07:32Z", "2019-06-05T22:56:25Z", "2019-05-30T17:30:48Z", "2019-04-23T22:40:47Z", "2019-01-24T20:57:56Z", "2018-11-12T18:58:01Z"]}, {"name": "dynamic-resource-allocation", "description": null, "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# dynamic-resource-allocation\n\n## Purpose\n\nThis repository contains packages related to the [dynamic resource\nallocation](https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/3063-dynamic-resource-allocation)\nfeature.\n\n## Compatibility\n\nThere are *NO compatibility guarantees* for this repository, yet.  It is in direct support of Kubernetes, so branches\nwill track Kubernetes and be compatible with that repo.\n\n## Where does it come from?\n\nThis repository is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/dynamic-resource-allocation.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n## Things you should *NOT* do\n\n 1. Directly modify any files in this repo. Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/dynamic-resource-allocation`.\n 2. Expect compatibility. This repo is changing quickly in direct support of Kubernetes.\n\n### OWNERS\n\nSIG Node owns the code.\n", "release_dates": []}, {"name": "endpointslice", "description": null, "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# endpointslice\n\n## Purpose\n\nThis repository contains packages related to the [EndpointSlices](https://github.com/kubernetes/enhancements/tree/master/keps/sig-network/0752-endpointslices)\nfeature.\n\nThis EndpointSlice reconciler library is not sufficiently generic to be used by\nthe EndpointSlice Mirroring controller. The reconciler in the EndpointSlice\nmirroring controller has a 1:1 mapping between Service/Endpoints and\nEndpointSlice, which results in a simpler implementation then the EndpointSlice\nstaging lib. Contributions to move towards the shared code being used by the\nmirroring controller would be welcome.\n\n## Compatibility\n\nThere are *NO compatibility guarantees* for this repository, yet.  It is in direct support of Kubernetes, so branches\nwill track Kubernetes and be compatible with that repo.\n\n## Where does it come from?\n\nThis repository is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/endpointslice\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n## Things you should *NOT* do\n\n 1. Directly modify any files in this repo. Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/endpointslice`.\n 2. Expect compatibility. This repo is changing quickly in direct support of Kubernetes.\n\n### OWNERS\n\nSIG Network owns the code.\n", "release_dates": []}, {"name": "enhancements", "description": "Enhancements tracking repo for Kubernetes", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Enhancement Tracking and Backlog\n\n[![PkgGoDev](https://pkg.go.dev/badge/k8s.io/enhancements)](https://pkg.go.dev/k8s.io/enhancements)\n[![Go Report Card](https://goreportcard.com/badge/k8s.io/enhancements)](https://goreportcard.com/report/k8s.io/enhancements)\n[![Slack](https://img.shields.io/badge/Slack-%23enhancements-blueviolet)](https://kubernetes.slack.com/archives/C1L57L91V)\n\n- [Is My Thing an Enhancement?](#is-my-thing-an-enhancement)\n- [When to Create a New Enhancement Issue](#when-to-create-a-new-enhancement-issue)\n- [Why Are Enhancements Tracked](#why-are-enhancements-tracked)\n- [When to Comment on an Enhancement Issue](#when-to-comment-on-an-enhancement-issue)\n- [Enhancements Tracking Board](#enhancements-tracking-board)\n- [Enhancements Tracking Spreadsheet](#enhancements-tracking-spreadsheet)\n- [Current Release Cycle](#current-release-cycle)\n- [Exceptions to Enhancement Milestone Dates](#exceptions-to-enhancement-milestone-dates)\n- [Labels](#labels)\n- [Glossary](#glossary)\n\nEnhancement tracking repo for Kubernetes releases. Owned by [SIG Architecture](https://git.k8s.io/community/sig-architecture#enhancements).\n\nThis repo contains issues and [KEPs](https://git.k8s.io/enhancements/keps). These issues are umbrellas for new enhancements to be added to Kubernetes. An enhancement usually takes multiple releases to complete. And an enhancement can be tracked as backlog items before work begins. An enhancement may be filed once there is consensus in at least one [Kubernetes SIG](https://git.k8s.io/community/sig-list.md).\n\n## Is My Thing an Enhancement?\n\nWe are trying to figure out the exact shape of an enhancement. Until then, here are a few rough heuristics.\n\nAn enhancement is anything that:\n\n- a blog post would be written about after its release (ex. [minikube](https://kubernetes.io/blog/2016/07/minikube-easily-run-kubernetes-locally/), [StatefulSets](https://kubernetes.io/blog/2016/07/thousand-instances-of-cassandra-using-kubernetes-pet-set/), [rkt container runtime](https://kubernetes.io/blog/2016/07/rktnetes-brings-rkt-container-engine-to-kubernetes/))\n- requires multiple parties/SIGs/owners participating to complete (ex. GPU scheduling [API, Core, & Node], StatefulSets [Storage & API])\n- will be graduating from one stage to another (ex. alpha to beta, beta to GA)\n- needs significant effort or changes Kubernetes in a significant way (ex. something that would take 10 person-weeks to implement, introduce or redesign a system component, or introduces API changes)\n- impacts the UX or operation of Kubernetes substantially such that engineers using Kubernetes will need retraining\n- users will notice and come to rely on\n\nIt is unlikely an enhancement if it is:\n- implemented using a `CustomResourceDefinition`\n- fixing a flaky test\n- refactoring code\n- performance improvements, which are only visible to users as faster API operations, or faster control loops\n- adding error messages or events\n\nIf you are not sure, ask someone in the SIG where you initially circulated the idea. If they aren't sure, jump into\n[#enhancements](https://kubernetes.slack.com/messages/enhancements/) on Slack or ping someone listed in [OWNERS](https://github.com/kubernetes/enhancements/blob/master/OWNERS).\n\n## When to Create a New Enhancement Issue\n\nCreate an [issue](https://github.com/kubernetes/enhancements/issues/new) in this repository once you:\n- have circulated your idea to see if there is interest\n   - through Community Meetings, SIG meetings, SIG mailing lists, or an issue in github.com/kubernetes/kubernetes\n- (optionally) have done a prototype in your own fork\n- have identified people who agree to work on the enhancement\n  - many enhancements will take several releases to progress through Alpha, Beta, and Stable stages\n  - you and your team should be prepared to work on the approx. 9mo - 1 year that it takes to progress to Stable status\n- are ready to be the project manager for the enhancement\n\n## Why Are Enhancements Tracked\n\nOnce users adopt an enhancement, they expect to use it for an extended period of time. Therefore, we hold new enhancements to a high standard of conceptual integrity and require consistency with other parts of the system, thorough testing, and complete documentation. As the project grows, no single person can track whether all those requirements are met. \n\nThe development of an enhancement often spans three stages: Alpha, Beta, and Stable. Enhancement Tracking Issues provide a checklist that allows for different approvers for different aspects, and ensures that nothing is forgotten across the\ndevelopment lifetime of an enhancement.\n\n## When to Comment on an Enhancement Issue\n\nPlease comment on the enhancement issue to:\n- request a review or clarification on the process\n- update status of the enhancement effort\n- link to relevant issues in other repos\n\nPlease do not comment on the enhancement issue to:\n- discuss a detail of the design, code or docs. Use a linked-to-issue or PR for that\n\n## Enhancements Tracking Board\n\nAs of the 1.26 release, enhancements from this repo are visualized in the Enhancements Tracking Boards.\n\nLinks:\n\n- [1.30 Milestone](https://bit.ly/k8s130-enhancements)\n- [1.29 Milestone](https://bit.ly/k8s129-enhancements)\n- [1.28 Milestone](https://bit.ly/k8s128-enhancements)\n- [1.27 Milestone](https://bit.ly/k8s127-enhancements)\n- [1.26 Milestone](https://bit.ly/k8s126-enhancements)\n\n## Enhancements Tracking Spreadsheet\n\nPrior to the 1.26 release, enhancements from this repo were visualized using Enhancements Tracking Spreadsheets.\n\nPlease refer to the [Enhancements Tracking Spreadsheet Archive](docs/archived-tracking-sheets.md) for links to \nthese sheets.\n\nProcedure:\n*TBA*\n\n### Current Release Cycle\n\n[Dates and further information for the 1.28 Release](https://github.com/kubernetes/sig-release/tree/master/releases/release-1.28)\n\n## Exceptions to Enhancement Milestone Dates\n\nThe Exceptions Process is handled by the Release Team, please see their [documentation](https://github.com/kubernetes/sig-release/blob/master/releases/EXCEPTIONS.md) for further details.\n\n## Labels\n\n| Label Name | Purpose | How to use this label | Who should use this label |\n| ------ | ------ | ------ | ------ |\n| `sig/foo` | Denotes the SIG(s) which owns this enhancement\u2014e.g., `SIG Foo` | Set the label using the comment `/sig foo` (on a separate line) | Anyone |\n| `kind/feature` | Denotes that the issue should be tracked as an enhancement (all enhancement issues should be marked with this label) | Set the label using the comment `/kind feature` (on a separate line) | Anyone |\n| `stage/{alpha,beta,stable}` | Denotes the stage of an issue in the features process | Set the label using the comment `/stage alpha` (on a separate line) | Anyone |\n\n## Glossary\n\nPlease refer to the [Glossary](docs/glossary.md) for the definition of any terminology and acronyms used in the Enhancements subproject.\n", "release_dates": []}, {"name": "examples", "description": "Kubernetes application example tutorials", "language": "Shell", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Examples\n\nThis directory contains a number of examples of how to run real applications\nwith Kubernetes.\n\nRefer to the [Kubernetes documentation] for how to execute the tutorials.\n\n### Maintained Examples\n\nMaintained Examples are expected to be updated with every Kubernetes release, to\nuse the latest and greatest features, current guidelines and best practices,\nand to refresh command syntax, output, changed prerequisites, as needed.\n\n|Name | Description | Notable Features Used | Complexity Level|\n------------- | ------------- | ------------ | ------------ |\n|[Guestbook](guestbook/) | PHP app with Redis | Deployment, Service | Beginner |\n|[Guestbook-Go](guestbook-go/) | Go app with Redis | Deployment, Service | Beginner |\n|[WordPress](mysql-wordpress-pd/) | WordPress with MySQL | Deployment, Persistent Volume with Claim | Beginner|\n|[Cassandra](cassandra/) | Cloud Native Cassandra | Daemon Set, Stateful Set, Replication Controller | Intermediate\n\n> Note: Please add examples that are maintained to the list above.\n\nSee [Example Guidelines](guidelines.md) for a description of what goes\nin this directory, and what examples should contain.\n\n[Kubernetes documentation]: https://kubernetes.io/docs/tutorials/\n\n### Contributing\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on how to contribute.\n", "release_dates": []}, {"name": "gengo", "description": "gengo library for code generation.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# gengo\n\n[![Travis Widget]][Travis] [![GoDoc Widget]][GoDoc]  [![GoReport]][GoReportStatus]\n\n[Travis]: https://travis-ci.org/kubernetes/gengo\n[Travis Widget]: https://travis-ci.org/kubernetes/gengo.svg?branch=master\n[GoDoc]: https://godoc.org/k8s.io/gengo\n[GoDoc Widget]: https://godoc.org/k8s.io/gengo?status.svg\n[GoReport]: https://goreportcard.com/badge/github.com/kubernetes/gengo\n[GoReportStatus]: https://goreportcard.com/report/github.com/kubernetes/gengo\n\nNOTE: [`k8s.io/gengo/v2`](https://github.com/kubernetes/gengo/tree/master/v2) is the current development module.\n\nA package for generating things based on go files. This mechanism was first used\nin [Kubernetes code-generator](https://github.com/kubernetes/kubernetes/tree/master/staging/src/k8s.io/code-generator) and is split out here for ease of reuse and maintainability.\n\n`go get k8s.io/gengo/...`\n\n## Examples\n\nA set generator, deep-copy generator, defaulter generator and go-to-protobuf\ngenerator are included here. Also, import-boss will enforce arbitrary rules about\nimport trees.\n\n## args/\n\nPackage args defines common arguments for a generator binary.\n\n## generator/\n\nPackage generator defines interfaces for code generators to implement, and\nmachinery that will execute those code generators.\n\n## types/\n\nPackage types contains the type system definition. It is modeled after Go's type\nsystem, but it's intended that you could produce these types by parsing\nsomething else, if you want to write the parser/converter.\n\nWe don't directly use the go types in the go typecheck library because they are\nbased on implementing differing interfaces. A struct-based format is more\nconvenient input for template driven output.\n\n## parser/\n\nPackage parser parses go source files.\n\n## namer/\n\nPackage namer defines a naming system, for:\n* helping you reference go objects in a syntactically correct way\n* keeping track of what you reference, for importing the right packages\n* and defining parallel tracks of names, for making public interfaces and\n  private implementations.\n\n## Contributing\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on how to contribute.\n", "release_dates": []}, {"name": "git-sync", "description": "A sidecar app which clones a git repo and keeps it in sync with the upstream.", "language": "Shell", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# NOTE: THIS DOCUMENT COVERS GIT-SYNC v4\n\nThis is the \"master\" branch, which is under development.  If you are looking \nfor docs on older (v3) versions of git-sync, you probably want to use the\n[v3.x branch](https://github.com/kubernetes/git-sync/tree/release-3.x).\n\n# git-sync\n\ngit-sync is a simple command that pulls a git repository into a local\ndirectory, waits for a while, then repeats.  As the remote repository changes,\nthose changes will be synced locally.  It is a perfect \"sidecar\" container in\nKubernetes - it can pull files down from a repository so that an application\ncan consume them.\n\ngit-sync can pull one time, or on a regular interval.  It can pull from the\nHEAD of a branch, from a git tag, or from a specific git hash.  It will only\nre-pull if the referenced target has changed in the upstream repository (e.g. a\nnew commit on a branch).  It \"publishes\" each sync through a worktree and a\nnamed symlink.  This ensures an atomic update - consumers will not see a\npartially constructed view of the local repository.\n\ngit-sync can pull over HTTP(S) (with authentication or not) or SSH.\n\ngit-sync can also be configured to make a webhook call or exec a command upon\nsuccessful git repo synchronization. The call is made after the symlink is\nupdated.\n\n## Major update: v3.x -> v4.x\n\ngit-sync has undergone many significant changes between v3.x and v4.x.  [See\nhere](v3-to-v4.md) for more details.\n\n## Building it\n\nWe use [docker buildx](https://github.com/docker/buildx) to build images.\n\n```\n# build the container\nmake container REGISTRY=registry VERSION=tag\n```\n\n```\n# build the container behind a proxy\nmake container REGISTRY=registry VERSION=tag \\\n    HTTP_PROXY=http://<proxy_address>:<proxy_port> \\\n    HTTPS_PROXY=https://<proxy_address>:<proxy_port>\n```\n\n```\n# build the container for an OS/arch other than the current (e.g. you are on\n# MacOS and want to run on Linux)\nmake container REGISTRY=registry VERSION=tag \\\n    GOOS=linux GOARCH=amd64\n```\n\n## Usage\n\n```\n# make a directory (owned by you) for the volume\nexport DIR=\"/tmp/git-data\"\nmkdir -p $DIR\n\n# run the container (as your own UID)\n\n# run the container\ndocker run -d \\\n    -v $DIR:/tmp/git \\\n    -u$(id -u):$(id -g) \\\n    registry/git-sync:tag \\\n        --repo=https://github.com/kubernetes/git-sync \\\n        --root=/tmp/git/root \\\n        --period=30s\n\n# run an nginx container to serve the content\ndocker run -d \\\n    -p 8080:80 \\\n    -v $DIR:/usr/share/nginx/html \\\n    nginx\n```\n\n### Flags\n\ngit-sync has many flags and optional features (see the manual below).  Most of\nthose flags can be configured through environment variables, but in most cases\n(with the obvious exception of passwords) flags are preferred, because the\nprogram can abort if an invalid flag is specified, but a misspelled environment\nvariable will just be ignored.  We've tried to stay backwards-compatible across\nmajor versions (by accepting deprecated flags and environment variables), but\nsome things have evolved, and users are encouraged to use the most recent flags\nfor their major verion.\n\n### Volumes\n\nThe `--root` flag must indicate either a directory that either a) does not\nexist (it will be created); or b) exists and is empty; or c) can be emptied by\nremoving all of the contents.\n\nWhy?  Git really wants an empty directory, to avoid any confusion.  If the\ndirectory exists and is not empty, git-sync will try to empty it by removing\neverything in it (we can't just `rm -rf` the dir because it might be a mounted\nvolume).  If that fails, git-sync will abort.\n\nWith the above example or with a Kubernetes `emptyDir`, there is usually no\nproblem.  The problematic case is when the volume is the root of a filesystem,\nwhich sometimes contains metadata (e.g. ext{2,3,4} have a `lost+found` dir).\nThe only real solution is to use a sub-directory of the volume as the `--root`.\n\n## More docs\n\nMore documentation on specific topics can be [found here](./docs).\n\n## Manual\n\n```\nGIT-SYNC\n\nNAME\n    git-sync - sync a remote git repository\n\nSYNOPSIS\n    git-sync --repo=<repo> --root=<path> [OPTIONS]...\n\nDESCRIPTION\n\n    Fetch a remote git repository to a local directory, poll the remote for\n    changes, and update the local copy.\n\n    This is a perfect \"sidecar\" container in Kubernetes.  For example, it can\n    periodically pull files down from a repository so that an application can\n    consume them.\n\n    git-sync can pull one time, or on a regular interval.  It can read from the\n    HEAD of a branch, from a git tag, or from a specific git hash.  It will only\n    re-pull if the target has changed in the remote repository.  When it\n    re-pulls, it updates the destination directory atomically.  In order to do\n    this, it uses a git worktree in a subdirectory of the --root and flips a\n    symlink.\n\n    git-sync can pull over HTTP(S) (with authentication or not) or SSH.\n\n    git-sync can also be configured to make a webhook call upon successful git\n    repo synchronization.  The call is made after the symlink is updated.\n\nOPTIONS\n\n    Many options can be specified as either a commandline flag or an environment\n    variable, but flags are preferred because a misspelled flag is a fatal\n    error while a misspelled environment variable is silently ignored.\n\n    --add-user, $GITSYNC_ADD_USER\n            Add a record to /etc/passwd for the current UID/GID.  This is\n            needed to use SSH with an arbitrary UID.  This assumes that\n            /etc/passwd is writable by the current UID.\n\n    --askpass-url <string>, $GITSYNC_ASKPASS_URL\n            A URL to query for git credentials.  The query must return success\n            (200) and produce a series of key=value lines, including\n            \"username=<value>\" and \"password=<value>\".\n\n    --cookie-file <string>, $GITSYNC_COOKIE_FILE\n            Use a git cookiefile (/etc/git-secret/cookie_file) for\n            authentication.\n\n    --credential <string>, $GITSYNC_CREDENTIAL\n            Make one or more credentials available for authentication (see git\n            help credential).  This is similar to --username and --password or\n            --password-file, but for specific URLs, for example when using\n            submodules.  The value for this flag is either a JSON-encoded\n            object (see the schema below) or a JSON-encoded list of that same\n            object type.  This flag may be specified more than once.\n\n            Object schema:\n              - url:            string, required\n              - username:       string, required\n              - password:       string, optional\n              - password-file:  string, optional\n\n            One of password or password-file must be specified.  Users should\n            prefer password-file for better security.\n\n            Example:\n              --credential='{\"url\":\"https://github.com\", \"username\":\"myname\", \"password-file\":\"/creds/mypass\"}'\n\n    --depth <int>, $GITSYNC_DEPTH\n            Create a shallow clone with history truncated to the specified\n            number of commits.  If not specified, this defaults to syncing a\n            single commit.  Setting this to 0 will sync the full history of the\n            repo.\n\n    --error-file <string>, $GITSYNC_ERROR_FILE\n            The path to an optional file into which errors will be written.\n            This may be an absolute path or a relative path, in which case it\n            is relative to --root.\n\n    --exechook-backoff <duration>, $GITSYNC_EXECHOOK_BACKOFF\n            The time to wait before retrying a failed --exechook-command.  If\n            not specified, this defaults to 3 seconds (\"3s\").\n\n    --exechook-command <string>, $GITSYNC_EXECHOOK_COMMAND\n            An optional command to be executed after syncing a new hash of the\n            remote repository.  This command does not take any arguments and\n            executes with the synced repo as its working directory.  The\n            $GITSYNC_HASH environment variable will be set to the git hash that\n            was synced.  If, at startup, git-sync finds that the --root already\n            has the correct hash, this hook will still be invoked.  This means\n            that hooks can be invoked more than one time per hash, so they\n            must be idempotent.  This flag obsoletes --sync-hook-command, but\n            if sync-hook-command is specified, it will take precedence.\n\n    --exechook-timeout <duration>, $GITSYNC_EXECHOOK_TIMEOUT\n            The timeout for the --exechook-command.  If not specifid, this\n            defaults to 30 seconds (\"30s\").\n\n    --git <string>, $GITSYNC_GIT\n            The git command to run (subject to PATH search, mostly for\n            testing).  This defaults to \"git\".\n\n    --git-config <string>, $GITSYNC_GIT_CONFIG\n            Additional git config options in a comma-separated 'key:val'\n            format.  The parsed keys and values are passed to 'git config' and\n            must be valid syntax for that command.\n\n            Both keys and values can be either quoted or unquoted strings.\n            Within quoted keys and all values (quoted or not), the following\n            escape sequences are supported:\n                '\\n' => [newline]\n                '\\t' => [tab]\n                '\\\"' => '\"'\n                '\\,' => ','\n                '\\\\' => '\\'\n            To include a colon within a key (e.g. a URL) the key must be\n            quoted.  Within unquoted values commas must be escaped.  Within\n            quoted values commas may be escaped, but are not required to be.\n            Any other escape sequence is an error.\n\n    --git-gc <string>, $GITSYNC_GIT_GC\n            The git garbage collection behavior: one of \"auto\", \"always\",\n            \"aggressive\", or \"off\".  If not specified, this defaults to\n            \"auto\".\n\n            - auto: Run \"git gc --auto\" once per successful sync.  This mode\n              respects git's gc.* config params.\n            - always: Run \"git gc\" once per successful sync.\n            - aggressive: Run \"git gc --aggressive\" once per successful sync.\n              This mode can be slow and may require a longer --sync-timeout value.\n            - off: Disable explicit git garbage collection, which may be a good\n              fit when also using --one-time.\n\n    --group-write, $GITSYNC_GROUP_WRITE\n            Ensure that data written to disk (including the git repo metadata,\n            checked out files, worktrees, and symlink) are all group writable.\n            This corresponds to git's notion of a \"shared repository\".  This is\n            useful in cases where data produced by git-sync is used by a\n            different UID.  This replaces the older --change-permissions flag.\n\n    -h, --help\n            Print help text and exit.\n\n    --http-bind <string>, $GITSYNC_HTTP_BIND\n            The bind address (including port) for git-sync's HTTP endpoint.\n            The '/' URL of this endpoint is suitable for Kubernetes startup and\n            liveness probes, returning a 5xx error until the first sync is\n            complete, and a 200 status thereafter. If not specified, the HTTP\n            endpoint is not enabled.\n\n            Examples:\n              \":1234\": listen on any IP, port 1234\n              \"127.0.0.1:1234\": listen on localhost, port 1234\n\n    --http-metrics, $GITSYNC_HTTP_METRICS\n            Enable metrics on git-sync's HTTP endpoint at /metrics.  Requires\n            --http-bind to be specified.\n\n    --http-pprof, $GITSYNC_HTTP_PPROF\n            Enable the pprof debug endpoints on git-sync's HTTP endpoint at\n            /debug/pprof.  Requires --http-bind to be specified.\n\n    --link <string>, $GITSYNC_LINK\n            The path to at which to create a symlink which points to the\n            current git directory, at the currently synced hash.  This may be\n            an absolute path or a relative path, in which case it is relative\n            to --root.  Consumers of the synced files should always use this\n            link - it is updated atomically and should always be valid.  The\n            basename of the target of the link is the current hash.  If not\n            specified, this defaults to the leaf dir of --repo.\n\n    --man\n            Print this manual and exit.\n\n    --max-failures <int>, $GITSYNC_MAX_FAILURES\n            The number of consecutive failures allowed before aborting.\n            Setting this to a negative value will retry forever.  If not\n            specified, this defaults to 0, meaning any sync failure will\n            terminate git-sync.\n\n    --one-time, $GITSYNC_ONE_TIME\n            Exit after one sync.\n\n    --password <string>, $GITSYNC_PASSWORD\n            The password or personal access token (see github docs) to use for\n            git authentication (see --username).  NOTE: for security reasons,\n            users should prefer --password-file or $GITSYNC_PASSWORD_FILE for\n            specifying the password.\n\n    --password-file <string>, $GITSYNC_PASSWORD_FILE\n            The file from which the password or personal access token (see\n            github docs) to use for git authentication (see --username) will be\n            read.\n\n    --period <duration>, $GITSYNC_PERIOD\n            How long to wait between sync attempts.  This must be at least\n            10ms.  This flag obsoletes --wait, but if --wait is specified, it\n            will take precedence.  If not specified, this defaults to 10\n            seconds (\"10s\").\n\n    --ref <string>, $GITSYNC_REF\n            The git revision (branch, tag, or hash) to check out.  If not\n            specified, this defaults to \"HEAD\" (of the upstream repo's default\n            branch).\n\n    --repo <string>, $GITSYNC_REPO\n            The git repository to sync.  This flag is required.\n\n    --root <string>, $GITSYNC_ROOT\n            The root directory for git-sync operations, under which --link will\n            be created.  This must be a path that either a) does not exist (it\n            will be created); b) is an empty directory; or c) is a directory\n            which can be emptied by removing all of the contents.  This flag is\n            required.\n\n    --sparse-checkout-file <string>, $GITSYNC_SPARSE_CHECKOUT_FILE\n            The path to a git sparse-checkout file (see git documentation for\n            details) which controls which files and directories will be checked\n            out.  If not specified, the default is to check out the entire repo.\n\n    --ssh-key-file <string>, $GITSYNC_SSH_KEY_FILE\n            The SSH key(s) to use when using git over SSH.  This flag may be\n            specified more than once and the environment variable will be\n            parsed like PATH - using a colon (':') to separate elements.  If\n            not specified, this defaults to \"/etc/git-secret/ssh\".\n\n    --ssh-known-hosts, $GITSYNC_SSH_KNOWN_HOSTS\n            Enable SSH known_hosts verification when using git over SSH.  If\n            not specified, this defaults to true.\n\n    --ssh-known-hosts-file <string>, $GITSYNC_SSH_KNOWN_HOSTS_FILE\n            The known_hosts file to use when --ssh-known-hosts is specified.\n            If not specified, this defaults to \"/etc/git-secret/known_hosts\".\n\n    --stale-worktree-timeout <duration>, $GITSYNC_STALE_WORKTREE_TIMEOUT\n            The length of time to retain stale (not the current link target)\n            worktrees before being removed. Once this duration has elapsed,\n            a stale worktree will be removed during the next sync attempt\n            (as determined by --sync-timeout). If not specified, this defaults\n            to 0, meaning that stale worktrees will be removed immediately.\n\n    --submodules <string>, $GITSYNC_SUBMODULES\n            The git submodule behavior: one of \"recursive\", \"shallow\", or\n            \"off\".  If not specified, this defaults to \"recursive\".\n\n    --sync-on-signal <string>, $GITSYNC_SYNC_ON_SIGNAL\n            Indicates that a sync attempt should occur upon receipt of the\n            specified signal name (e.g. SIGHUP) or number (e.g. 1). If a sync\n            is already in progress, another sync will be triggered as soon as\n            the current one completes. If not specified, signals will not\n            trigger syncs.\n\n    --sync-timeout <duration>, $GITSYNC_SYNC_TIMEOUT\n            The total time allowed for one complete sync.  This must be at least\n            10ms.  This flag obsoletes --timeout, but if --timeout is specified,\n            it will take precedence.  If not specified, this defaults to 120\n            seconds (\"120s\").\n\n    --touch-file <string>, $GITSYNC_TOUCH_FILE\n            The path to an optional file which will be touched whenever a sync\n            completes.  This may be an absolute path or a relative path, in\n            which case it is relative to --root.\n\n    --username <string>, $GITSYNC_USERNAME\n            The username to use for git authentication (see --password-file or\n            --password).  If more than one username and password is required\n            (e.g. with submodules), use --credential.\n\n    -v, --verbose <int>, $GITSYNC_VERBOSE\n            Set the log verbosity level.  Logs at this level and lower will be\n            printed.  Logs follow these guidelines:\n\n            - 0: Minimal, just log updates\n            - 1: More details about updates\n            - 2: Log the sync loop\n            - 3: More details about the sync loop\n            - 4: More details\n            - 5: Log all executed commands\n            - 6: Log stdout/stderr of all executed commands\n            - 9: Tracing and debug messages\n\n    --version\n            Print the version and exit.\n\n    --webhook-backoff <duration>, $GITSYNC_WEBHOOK_BACKOFF\n            The time to wait before retrying a failed --webhook-url.  If not\n            specified, this defaults to 3 seconds (\"3s\").\n\n    --webhook-method <string>, $GITSYNC_WEBHOOK_METHOD\n            The HTTP method for the --webhook-url.  If not specified, this defaults to \"POST\".\n\n    --webhook-success-status <int>, $GITSYNC_WEBHOOK_SUCCESS_STATUS\n            The HTTP status code indicating a successful --webhook-url.  Setting\n            this to 0 disables success checks, which makes webhooks\n            \"fire-and-forget\".  If not specified, this defaults to 200.\n\n    --webhook-timeout <duration>, $GITSYNC_WEBHOOK_TIMEOUT\n            The timeout for the --webhook-url.  If not specified, this defaults\n            to 1 second (\"1s\").\n\n    --webhook-url <string>, $GITSYNC_WEBHOOK_URL\n            A URL for optional webhook notifications when syncs complete.  The\n            header 'Gitsync-Hash' will be set to the git hash that was synced.\n            If, at startup, git-sync finds that the --root already has the\n            correct hash, this hook will still be invoked.  This means that\n            hooks can be invoked more than one time per hash, so they must be\n            idempotent.\n\nEXAMPLE USAGE\n\n    git-sync \\\n        --repo=https://github.com/kubernetes/git-sync \\\n        --ref=HEAD \\\n        --period=10s \\\n        --root=/mnt/git\n\nAUTHENTICATION\n\n    Git-sync offers several authentication options to choose from.  If none of\n    the following are specified, git-sync will try to access the repo in the\n    \"natural\" manner.  For example, \"https://repo\" will try to use plain HTTPS\n    and \"git@example.com:repo\" will try to use SSH.\n\n    username/password\n            The --username (GITSYNC_USERNAME) and --password-file\n            (GITSYNC_PASSWORD_FILE) or --password (GITSYNC_PASSWORD) flags\n            will be used.  To prevent password leaks, the --password-file flag\n            or GITSYNC_PASSWORD environment variable is almost always\n            preferred to the --password flag.\n\n            A variant of this is --askpass-url (GITSYNC_ASKPASS_URL), which\n            consults a URL (e.g. http://metadata) to get credentials on each\n            sync.\n\n            When using submodules it may be necessary to specify more than one\n            username and password, which can be done with --credential\n            (GITSYNC_CREDENTIAL).  All of the username+password pairs, from\n            both --username/--password and --credential are fed into 'git\n            credential approve'.\n\n    SSH\n            When an SSH transport is specified, the key(s) defined in\n            --ssh-key-file (GITSYNC_SSH_KEY_FILE) will be used.  Users are\n            strongly advised to also use --ssh-known-hosts\n            (GITSYNC_SSH_KNOWN_HOSTS) and --ssh-known-hosts-file\n            (GITSYNC_SSH_KNOWN_HOSTS_FILE) when using SSH.\n\n    cookies\n            When --cookie-file (GITSYNC_COOKIE_FILE) is specified, the\n            associated cookies can contain authentication information.\n\nHOOKS\n\n    Webhooks and exechooks are executed asynchronously from the main git-sync\n    process.  If a --webhook-url or --exechook-command is configured, they will\n    be invoked whenever a new hash is synced, including when git-sync starts up\n    and find that the --root directory already has the correct hash.  For\n    exechook, that means the command is exec()'ed, and for webhooks that means\n    an HTTP request is sent using the method defined in --webhook-method.\n    Git-sync will retry both forms of hooks until they succeed (exit code 0 for\n    exechooks, or --webhook-success-status for webhooks).  If unsuccessful,\n    git-sync will wait --exechook-backoff or --webhook-backoff (as appropriate)\n    before re-trying the hook.  Git-sync does not ensure that hooks are invoked\n    exactly once, so hooks must be idempotent.\n\n    Hooks are not guaranteed to succeed on every single hash change.  For example,\n    if a hook fails and a new hash is synced during the backoff period, the\n    retried hook will fire for the newest hash.\n```\n", "release_dates": ["2024-02-06T17:53:45Z", "2024-01-17T06:30:14Z", "2023-10-14T23:51:56Z", "2023-08-18T19:01:49Z", "2023-07-31T21:31:27Z", "2023-07-30T06:51:44Z", "2023-07-28T20:16:24Z", "2023-07-17T15:44:15Z", "2023-06-26T18:27:05Z", "2023-06-13T22:59:08Z", "2023-06-23T20:54:27Z", "2023-06-19T18:03:12Z", "2023-05-05T23:22:16Z", "2023-03-18T02:18:06Z", "2023-02-07T19:46:54Z", "2023-01-17T22:03:51Z", "2022-11-22T23:26:03Z", "2022-08-25T02:48:03Z", "2022-07-14T20:30:19Z", "2022-07-06T19:55:47Z", "2022-03-11T19:56:16Z", "2022-01-24T19:25:01Z", "2021-11-24T21:22:43Z", "2021-07-01T21:01:09Z", "2021-06-24T15:37:46Z", "2021-05-29T16:34:00Z", "2021-05-24T17:10:19Z", "2021-04-16T15:36:15Z", "2021-01-07T20:34:59Z", "2020-12-08T22:02:44Z"]}, {"name": "ingress-gce", "description": "Ingress controller for Google Cloud", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# GLBC\n\n[![GitHub release](https://img.shields.io/github/release/kubernetes/ingress-gce.svg)](https://github.com/kubernetes/ingress-gce/releases)\n[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/ingress-gce)](https://goreportcard.com/report/github.com/kubernetes/ingress-gce)\n\nGLBC is a GCE L7 load balancer controller that manages external loadbalancers configured through the Kubernetes Ingress API.\n\n## Overview\n\nSee [here](https://kubernetes.io/docs/concepts/services-networking/ingress/) for high-level concepts on Ingress in Kubernetes.\n\nFor GCP-specific documentation, please visit [here](https://cloud.google.com/kubernetes-engine/docs/how-to/load-balance-ingress) (core use-cases) and [here](https://cloud.google.com/kubernetes-engine/docs/concepts/ingress) (other cool features).\n\n## Releases\n\nPlease visit the [changelog](CHANGELOG.md) for both high-level release notes and a detailed changelog.\n\n## Documentation\n\nPlease visit our [docs](docs/) for more information on how to run, contribute, troubleshoot and much more!\n\n## GKE Version Mapping\n\nThe table below describes what version of Ingress-GCE is running on GKE. Note that these versions are simply the defaults.\n\n   *Format: k8s version -> glbc version* ('+' indicates that version or above)\n\n       * 1.12.7-gke.16+ -> v1.5.2\n       * 1.13.7-gke.5+ -> v1.6.0\n       * 1.14.10-gke.31+ -> 1.6.2\n       * 1.14.10-gke.42+ -> 1.6.4\n       * 1.15.4-gke.21+ -> 1.7.2\n       * 1.15.9-gke.22+ -> 1.7.3\n       * 1.15.11-gke.15+ -> 1.7.4\n       * 1.15.12-gke.3+ -> 1.7.5\n       * 1.16.8-gke.3+ -> 1.9.1\n       * 1.16.8-gke.12+ -> 1.9.2\n       * 1.16.9-gke.2+ -> 1.9.3\n       * 1.16.10-gke.6+ -> 1.9.7\n       * 1.17.6-gke.11+ -> 1.9.7\n       * 1.18.4-gke.1201+ -> 1.9.7\n       * 1.16.13-gke.400+ -> 1.9.8\n       * 1.17.9-gke.600+ -> 1.9.8\n       * 1.18.6-gke.500+ -> 1.9.8\n       * 1.18.6-gke.4800+ -> 1.9.9\n       * 1.18.10-gke.1500+ -> 1.10.8\n       * 1.18.10-gke.2300+ -> 1.10.9\n       * 1.18.12-gke.1200+ -> 1.10.13\n       * 1.18.18-gke.1200+ -> 1.10.15\n       * 1.18.19-gke.1400+ -> 1.11.1\n       * 1.18.20-gke.5100+ -> 1.11.5\n       * 1.19.14-gke.1900 -> 1.11.5\n       * 1.20.10-gke.301 -> 1.11.5\n       * 1.21.3-gke.210 -> 1.13.4\n\n", "release_dates": ["2023-06-14T08:31:55Z", "2020-01-16T17:58:24Z", "2019-10-05T12:15:54Z", "2019-05-14T20:31:07Z", "2019-04-05T15:45:12Z", "2019-03-06T18:13:42Z", "2019-02-18T21:44:28Z", "2019-01-18T21:41:38Z", "2019-01-10T18:38:45Z", "2018-11-05T20:34:40Z", "2018-07-19T22:23:25Z", "2018-07-09T20:02:40Z", "2018-04-17T21:11:50Z", "2018-04-11T21:31:50Z", "2018-04-03T18:20:36Z", "2018-03-16T21:06:12Z", "2018-02-12T22:30:09Z", "2018-02-09T20:11:08Z", "2017-10-10T00:57:26Z"]}, {"name": "ingress-nginx", "description": "Ingress-NGINX Controller for Kubernetes", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Ingress NGINX Controller\n\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5691/badge)](https://bestpractices.coreinfrastructure.org/projects/5691)\n[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/ingress-nginx)](https://goreportcard.com/report/github.com/kubernetes/ingress-nginx)\n[![GitHub license](https://img.shields.io/github/license/kubernetes/ingress-nginx.svg)](https://github.com/kubernetes/ingress-nginx/blob/main/LICENSE)\n[![GitHub stars](https://img.shields.io/github/stars/kubernetes/ingress-nginx.svg)](https://github.com/kubernetes/ingress-nginx/stargazers)\n[![GitHub stars](https://img.shields.io/badge/contributions-welcome-orange.svg)](https://github.com/kubernetes/ingress-nginx/blob/main/CONTRIBUTING.md)\n\n\n## Overview\n\ningress-nginx is an Ingress controller for Kubernetes using [NGINX](https://www.nginx.org/) as a reverse proxy and load\nbalancer.\n\n[Learn more about Ingress on the main Kubernetes documentation site](https://kubernetes.io/docs/concepts/services-networking/ingress/).\n\n## Get started\n\nSee the [Getting Started](https://kubernetes.github.io/ingress-nginx/deploy/) document.\n\n## Troubleshooting\n\nIf you encounter issues, review the [troubleshooting docs](docs/troubleshooting.md),\n[file an issue](https://github.com/kubernetes/ingress-nginx/issues), or talk to us on the\n[#ingress-nginx channel](https://kubernetes.slack.com/messages/ingress-nginx) on the Kubernetes Slack server.\n\n## Changelog\n\nSee [the list of releases](https://github.com/kubernetes/ingress-nginx/releases) for all changes.\nFor detailed changes for each release, please check the [changelog-$version.md](./changelog) file for the release version.\nFor detailed changes on the `ingress-nginx` helm chart, please check the changelog folder for a specific version\n[CHANGELOG-$current-version.md](./charts/ingress-nginx/changelog) file.\n\n### Supported Versions table\n\nSupported versions for the ingress-nginx project mean that we have completed E2E tests, and they are passing for\nthe versions listed. Ingress-Nginx versions **may** work on older versions, but the project does not make that guarantee.\n\n|  Supported  | Ingress-NGINX version | k8s supported version        | Alpine Version | Nginx Version | Helm Chart Version |\n|:--:|-----------------------|------------------------------|----------------|---------------|------------------------------|\n| \ud83d\udd04 | **v1.10.0**            | 1.29, 1.28, 1.27, 1.26        | 3.19.1         | 1.25.3        | 4.10.0*                 |\n| \ud83d\udd04 | **v1.9.6**            | 1.29, 1.28, 1.27, 1.26, 1.25        | 3.19.0         | 1.21.6        | 4.9.1*                 |\n| \ud83d\udd04 | **v1.9.5**            | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.9.0*                       |\n| \ud83d\udd04 | **v1.9.4**            | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.3                        |\n| \ud83d\udd04 | **v1.9.3**            | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.*                        |\n| \ud83d\udd04 | **v1.9.1**            | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.*                        |\n| \ud83d\udd04 | **v1.9.0**            | 1.28, 1.27, 1.26, 1.25        | 3.18.2         | 1.21.6        | 4.8.*                        |\n|  | **v1.8.4**            | 1.27, 1.26, 1.25, 1.24        | 3.18.2         | 1.21.6        | 4.7.*                        |\n|  | **v1.8.2**            | 1.27, 1.26, 1.25, 1.24        | 3.18.2         | 1.21.6        | 4.7.*                        |\n|  | **v1.8.1**            | 1.27, 1.26, 1.25, 1.24        | 3.18.2         | 1.21.6        | 4.7.*              |\n|  | **v1.8.0**            | 1.27, 1.26, 1.25, 1.24        | 3.18.0         | 1.21.6        | 4.7.*              |\n|  | **v1.7.1**            | 1.27, 1.26, 1.25, 1.24        | 3.17.2         | 1.21.6        | 4.6.*              |\n|  | **v1.7.0**            | 1.26, 1.25, 1.24             | 3.17.2         | 1.21.6        | 4.6.*              |\n|    | v1.6.4                | 1.26, 1.25, 1.24, 1.23       | 3.17.0         | 1.21.6        | 4.5.*              |\n|    | v1.5.1                | 1.25, 1.24, 1.23             | 3.16.2         | 1.21.6        | 4.4.*              |\n|    | v1.4.0                | 1.25, 1.24, 1.23, 1.22       | 3.16.2         | 1.19.10\u2020      | 4.3.0              |\n|    | v1.3.1                | 1.24, 1.23, 1.22, 1.21, 1.20 | 3.16.2         | 1.19.10\u2020      | 4.2.5              |\n|    | v1.3.0                | 1.24, 1.23, 1.22, 1.21, 1.20 | 3.16.0         | 1.19.10\u2020      | 4.2.3              |\n\nSee [this article](https://kubernetes.io/blog/2021/07/26/update-with-ingress-nginx/) if you want upgrade to the stable\nIngress API.\n\n## Get Involved\n\nThanks for taking the time to join our community and start contributing!\n\n- This project adheres to the [Kubernetes Community Code of Conduct](https://git.k8s.io/community/code-of-conduct.md).\n  By participating in this project, you agree to abide by its terms.\n\n- **Contributing**: Contributions of all kinds are welcome!\n\n  - Read [`CONTRIBUTING.md`](CONTRIBUTING.md) for information about setting up your environment, the workflow that we\n    expect, and instructions on the developer certificate of origin that we require.\n  - Join our Kubernetes Slack channel for developer discussion : [#ingress-nginx-dev](https://kubernetes.slack.com/archives/C021E147ZA4).\n  - Submit GitHub issues for any feature enhancements, bugs, or documentation problems.\n    - Please make sure to read the [Issue Reporting Checklist](https://github.com/kubernetes/ingress-nginx/blob/main/CONTRIBUTING.md#issue-reporting-guidelines) before opening an issue. Issues not conforming to the guidelines **may be closed immediately**.\n  - Join our [ingress-nginx-dev mailing list](https://groups.google.com/a/kubernetes.io/g/ingress-nginx-dev/c/ebbBMo-zX-w)\n\n- **Support**:\n  - Join the [#ingress-nginx-users](https://kubernetes.slack.com/messages/CANQGM8BA/) channel inside the [Kubernetes Slack](http://slack.kubernetes.io/) to ask questions or get support from the maintainers and other users.\n  - The [GitHub issues](https://github.com/kubernetes/ingress-nginx/issues) in the repository are **exclusively** for bug reports and feature requests.\n  - **Discuss**: Tweet using the `#IngressNginx` hashtag or sharing with us [@IngressNginx](https://twitter.com/IngressNGINX).\n\n## License\n\n[Apache License 2.0](https://github.com/kubernetes/ingress-nginx/blob/main/LICENSE)\n", "release_dates": ["2024-02-29T00:42:04Z", "2024-02-29T03:01:01Z", "2024-01-29T14:01:16Z", "2024-01-29T14:02:36Z", "2024-01-27T07:46:14Z", "2024-01-29T16:18:21Z", "2023-12-21T09:56:01Z", "2023-12-21T10:00:31Z", "2023-10-25T16:35:49Z", "2023-10-25T18:42:03Z", "2023-10-12T14:07:09Z", "2023-10-12T18:23:13Z", "2023-10-12T14:08:13Z", "2023-10-12T15:54:57Z", "2023-10-03T20:23:43Z", "2023-10-03T20:25:45Z", "2023-09-23T20:48:23Z", "2023-09-23T20:57:47Z", "2023-09-18T11:53:39Z", "2023-09-18T22:30:40Z", "2023-09-09T15:45:25Z", "2023-09-09T23:04:52Z", "2023-07-05T17:33:30Z", "2023-06-30T21:38:32Z", "2023-05-30T18:41:20Z", "2023-05-30T19:34:25Z", "2023-05-05T12:46:22Z", "2023-05-05T12:48:54Z", "2023-03-24T17:53:44Z", "2023-03-24T17:30:58Z"]}, {"name": "k8s.io", "description": "Code and configuration to manage Kubernetes project infrastructure, including various *.k8s.io sites", "language": "HCL", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# k8s.io\n\nKubernetes project infrastructure, managed by the kubernetes community via [sig-k8s-infra]\n\n- `apps`: community-managed apps that run on the community-managed `aaa` cluster\n    - `codesearch`: instance of [codesearch] at https://cs-canary.k8s.io - owned by [sig-k8s-infra]\n    - `elekto`: instance of [elekto] at https://elections.k8s.io - owned by Elections officers (on behalf of [sig-contributor-experience])\n    - `gcsweb`: instance of [gcsweb] at https://gcsweb.k8s.io - owned by [sig-testing]\n    - `k8s.io`: instance of nginx that provides redirects/reverse-proxying for k8s.io and its subdomains - owned by [sig-contributor-experience] and [sig-testing]\n    - `kubernetes-external-secrets`: instance of [kubernetes-external-secrets] - owned by [sig-testing]\n    - `perfdash`: instance of [perfdash] - owned by [sig-scalability]\n    - `prow`: work-in-progress instance of [prow] - owned by [sig-testing]\n    - `publishing-bot`: instance of [publishing-bot] - owned by [sig-release]\n    - `slack-infra`: instance of [slack-infra] including https://slack.k8s.io - owned by [sig-contributor-experience]\n    - `triageparty-cli`: instance of [triage-party] - owned by [sig-cli]\n- `artifacts`: non-image artifacts published to `artifacts.k8s.io`\n- `audit`: scripts to export all relevant gcp resources, and the most recently-reviewed export\n- `dns`: DNS for kubernetes.io and k8s.io\n- `groups`: google groups on the kubernetes.io domain\n- `hack`: scripts used for development, testing, etc.\n- `images`: container images published to `gcr.io/k8s-staging-infra-tools`\n- `infra/gcp`: scripts and data to manage our GCP infrastructure\n    - `bash/namespaces`: scripts and data to manage K8s namespaces and RBAC for `aaa`\n    - `bash/prow`: scripts and data used to manage projects used for e2e testing and managed by boskos\n    - `bash/roles`: scripts and data to manage custom GCP IAM roles\n    - `terraform/modules`: terraform modules intended for re-use within this repo\n    - `terraform/projects`: terraform to manage (parts of) GCP projects\n- `k8s.gcr.io`: container images published by the project, promoted from `gcr.io/k8s-staging-*` repos\n- `policy`: [open policy agent][opa] policies used by [conftest] to validate resources in this repo\n- `registry.k8s.io`: work-in-progress to support cross-cloud mirroring/hosting of containers and binaries\n\nWe provide a [publicly viewable billing report][billing-report] accessible to members of [kubernetes-sig-k8s-infra@googlegroups.com][mailing-list]\n\nPlease see https://git.k8s.io/community/sig-k8s-infra for more information\n\n<!-- apps -->\n[cert-manager]: https://github.com/jetstack/cert-manager\n[codesearch]: https://cs-canary.k8s.io\n[elekto]: https://elekto.dev/\n[gcsweb]: https://git.k8s.io/test-infra/gcsweb\n[kubernetes-external-secrets]: https://github.com/external-secrets/kubernetes-external-secrets\n[perfdash]: https://git.k8s.io/perf-tests/perfdash\n[prow]: https://git.k8s.io/test-infra/prow\n[publishing-bot]: https://git.k8s.io/publishing-bot\n[slack-infra]: https://sigs.k8s.io/slack-infra\n[triage-party]: https://github.com/google/triage-party\n\n<!-- misc -->\n[billing-report]: https://datastudio.google.com/u/0/reporting/14UWSuqD5ef9E4LnsCD9uJWTPv8MHOA3e\n[opa]: https://www.openpolicyagent.org\n[conftest]: https://www.conftest.dev\n[mailing-list]: https://groups.google.com/g/kubernetes-sig-k8s-infra\n\n<!-- community groups -->\n[sig-architecture]: https://git.k8s.io/community/sig-architecture\n[sig-cli]: https://git.k8s.io/community/sig-cli\n[sig-contributor-experience]: https://git.k8s.io/community/sig-contributor-experience\n[sig-k8s-infra]: https://git.k8s.io/community/sig-k8s-infra\n[sig-node]: https://git.k8s.io/community/sig-node\n[sig-release]: https://git.k8s.io/community/sig-release\n[sig-scalability]: https://git.k8s.io/community/sig-scalability\n[sig-testing]: https://git.k8s.io/community/sig-testing\n[wg-reliability]: https://git.k8s.io/community/wg-reliability\n", "release_dates": []}, {"name": "klog", "description": "Leveled execution logs for Go (fork of https://github.com/golang/glog)", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "klog\n====\n\nklog is a permanent fork of https://github.com/golang/glog.\n\n## Why was klog created?\n\nThe decision to create klog was one that wasn't made lightly, but it was necessary due to some\ndrawbacks that are present in [glog](https://github.com/golang/glog). Ultimately, the fork was created due to glog not being under active development; this can be seen in the glog README:\n\n> The code in this repo [...] is not itself under development\n\nThis makes us unable to solve many use cases without a fork. The factors that contributed to needing feature development are listed below:\n\n * `glog` [presents a lot \"gotchas\"](https://github.com/kubernetes/kubernetes/issues/61006) and introduces challenges in containerized environments, all of which aren't well documented.\n * `glog` doesn't provide an easy way to test logs, which detracts from the stability of software using it\n * A long term goal is to implement a logging interface that allows us to add context, change output format, etc.\n \nHistorical context is available here:\n\n * https://github.com/kubernetes/kubernetes/issues/61006\n * https://github.com/kubernetes/kubernetes/issues/70264\n * https://groups.google.com/forum/#!msg/kubernetes-sig-architecture/wCWiWf3Juzs/hXRVBH90CgAJ\n * https://groups.google.com/forum/#!msg/kubernetes-dev/7vnijOMhLS0/1oRiNtigBgAJ\n\n## Release versioning\n\nSemantic versioning is used in this repository. It contains several Go modules\nwith different levels of stability:\n- `k8s.io/klog/v2` - stable API, `vX.Y.Z` tags\n- `examples` - no stable API, no tags, no intention to ever stabilize\n\nExempt from the API stability guarantee are items (packages, functions, etc.)\nwhich are marked explicitly as `EXPERIMENTAL` in their docs comment. Those\nmay still change in incompatible ways or get removed entirely. This can only\nbe used for code that is used in tests to avoid situations where non-test\ncode from two different Kubernetes dependencies depends on incompatible\nreleases of klog because an experimental API was changed.\n\n----\n\nHow to use klog\n===============\n- Replace imports for `\"github.com/golang/glog\"` with `\"k8s.io/klog/v2\"`\n- Use `klog.InitFlags(nil)` explicitly for initializing global flags as we no longer use `init()` method to register the flags\n- You can now use `log_file` instead of `log_dir` for logging to a single file (See `examples/log_file/usage_log_file.go`)\n- If you want to redirect everything logged using klog somewhere else (say syslog!), you can use `klog.SetOutput()` method and supply a `io.Writer`. (See `examples/set_output/usage_set_output.go`)\n- For more logging conventions (See [Logging Conventions](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md))\n- See our documentation on [pkg.go.dev/k8s.io](https://pkg.go.dev/k8s.io/klog).\n\n**NOTE**: please use the newer go versions that support semantic import versioning in modules, ideally go 1.11.4 or greater.\n\n### Coexisting with klog/v2\n\nSee [this example](examples/coexist_klog_v1_and_v2/) to see how to coexist with both klog/v1 and klog/v2.\n\n### Coexisting with glog\nThis package can be used side by side with glog. [This example](examples/coexist_glog/coexist_glog.go) shows how to initialize and synchronize flags from the global `flag.CommandLine` FlagSet. In addition, the example makes use of stderr as combined output by setting `alsologtostderr` (or `logtostderr`) to `true`.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n- [Slack](https://kubernetes.slack.com/messages/klog)\n- [Mailing List](https://groups.google.com/forum/#!forum/kubernetes-sig-architecture)\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n----\n\nglog\n====\n\nLeveled execution logs for Go.\n\nThis is an efficient pure Go implementation of leveled logs in the\nmanner of the open source C++ package\n\thttps://github.com/google/glog\n\nBy binding methods to booleans it is possible to use the log package\nwithout paying the expense of evaluating the arguments to the log.\nThrough the -vmodule flag, the package also provides fine-grained\ncontrol over logging at the file level.\n\nThe comment from glog.go introduces the ideas:\n\n\tPackage glog implements logging analogous to the Google-internal\n\tC++ INFO/ERROR/V setup.  It provides functions Info, Warning,\n\tError, Fatal, plus formatting variants such as Infof. It\n\talso provides V-style logging controlled by the -v and\n\t-vmodule=file=2 flags.\n\n\tBasic examples:\n\n\t\tglog.Info(\"Prepare to repel boarders\")\n\n\t\tglog.Fatalf(\"Initialization failed: %s\", err)\n\n\tSee the documentation of the V function for an explanation\n\tof these examples:\n\n\t\tif glog.V(2) {\n\t\t\tglog.Info(\"Starting transaction...\")\n\t\t}\n\n\t\tglog.V(2).Infoln(\"Processed\", nItems, \"elements\")\n\n\nThe repository contains an open source version of the log package\nused inside Google. The master copy of the source lives inside\nGoogle, not here. The code in this repo is for export only and is not itself\nunder development. Feature requests will be ignored.\n\nSend bug reports to golang-nuts@googlegroups.com.\n", "release_dates": ["2024-01-18T15:10:31Z", "2024-01-10T19:01:17Z", "2023-10-31T10:51:40Z", "2023-04-29T23:24:49Z", "2023-03-01T14:23:50Z", "2023-01-23T14:51:27Z", "2022-09-09T11:05:30Z", "2022-09-01T15:16:46Z", "2022-07-07T10:48:33Z", "2022-06-22T13:36:48Z", "2022-03-20T13:51:23Z", "2022-03-16T22:34:48Z", "2022-03-16T11:55:53Z", "2022-03-15T21:35:35Z", "2021-12-19T00:29:11Z", "2021-12-17T13:15:30Z", "2021-10-22T12:41:19Z", "2021-09-02T04:55:34Z", "2021-07-15T10:18:56Z", "2021-05-26T10:56:16Z", "2021-03-12T18:54:30Z", "2021-03-12T01:33:18Z", "2021-03-03T11:07:55Z", "2021-01-27T18:19:47Z", "2020-10-29T22:28:55Z", "2020-07-02T14:26:10Z", "2020-06-16T10:45:22Z", "2020-06-04T21:04:10Z", "2020-06-04T18:21:52Z", "2020-04-10T02:52:02Z"]}, {"name": "kms", "description": "Kubernetes KMS implementation", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# KMS\n\n<!-- TODO: Placeholder README. Update with more detail and repo contents once initial implementation is in place. -->\n\nThis repository contains the KMS proto APIs.\n\nSee https://github.com/kubernetes/enhancements/tree/master/keps/sig-auth/3299-kms-v2-improvements for more details.\n\n## Community, discussion, contribution, and support\n\nKMS a sub-project of [SIG-Auth](https://github.com/kubernetes/community/tree/master/sig-auth).\n\nYou can reach the maintainers of this project at:\n\n- Slack: [#sig-auth](https://kubernetes.slack.com/messages/sig-auth)\n- Mailing List: [kubernetes-sig-auth](https://groups.google.com/forum/#!forum/kubernetes-sig-auth)\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n", "release_dates": []}, {"name": "kompose", "description": "Convert Compose to Kubernetes", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kompose (Kubernetes + Compose)\n\n[![Build Status Widget]][Build Status] [![Coverage Status Widget]][Coverage Status] [![GoDoc Widget]][GoDoc]  [![GoReportCard Widget]][GoReportCardResult]\n\n![logo](/docs/assets/images/logo.png)\n\n`kompose` is a tool to help users who are familiar with `docker-compose` move to [Kubernetes](http://kubernetes.io). `kompose` takes a [Compose Specification](https://compose-spec.io/) file and translates it into Kubernetes resources.\n\n`kompose` is a convenience tool to go from local Compose environment to managing your application with Kubernetes. Transformation of the [Compose Specification](https://compose-spec.io/) format to Kubernetes resources manifest may not be exact, but it helps tremendously when first deploying an application on Kubernetes.\n\n## Use Case\n\nConvert [`compose.yaml`](https://raw.githubusercontent.com/kubernetes/kompose/main/examples/compose.yaml) into Kubernetes deployments and services with one simple command:\n\n```sh\n$ kompose convert -f compose.yaml\nINFO Kubernetes file \"frontend-service.yaml\" created\nINFO Kubernetes file \"redis-leader-service.yaml\" created\nINFO Kubernetes file \"redis-replica-service.yaml\" created\nINFO Kubernetes file \"frontend-deployment.yaml\" created\nINFO Kubernetes file \"redis-leader-deployment.yaml\" created\nINFO Kubernetes file \"redis-replica-deployment.yaml\" created\n```\n\nOther examples are provided in the _examples_ [directory](./examples).\n\n## Installation\n\nWe have multiple ways to install Kompose. Our preferred method is downloading the binary from the latest GitHub release.\n\nOur entire list of installation methods are located in our [installation.md](/docs/installation.md) document.\n\nInstallation methods:\n\n- [Binary (Preferred method)](/docs/installation.md#github-release)\n- [Go](/docs/installation.md#go)\n- [CentOS](/docs/installation.md#centos)\n- [openSUSE/SLE](/docs/installation.md#opensusesle)\n- [NixOS](/docs/installation.md#nixos)\n- [macOS (Homebrew and MacPorts)](/docs/installation.md#macos)\n- [Windows](/docs/installation.md#windows)\n- [Docker](/docs/installation.md#docker)\n\n#### Binary installation\n\nKompose is released via GitHub on a three-week cycle, you can see all current releases on the [GitHub release page](https://github.com/kubernetes/kompose/releases).\n\n**Linux and macOS:**\n\n```sh\n# Linux\ncurl -L https://github.com/kubernetes/kompose/releases/download/v1.32.0/kompose-linux-amd64 -o kompose\n\n# macOS\ncurl -L https://github.com/kubernetes/kompose/releases/download/v1.32.0/kompose-darwin-amd64 -o kompose\n\nchmod +x kompose\nsudo mv ./kompose /usr/local/bin/kompose\n```\n\n**Windows:**\n\nDownload from [GitHub](https://github.com/kubernetes/kompose/releases/download/v1.32.0/kompose-windows-amd64.exe) and add the binary to your PATH.\n\n## Shell autocompletion\n\nWe support Bash, Zsh and Fish autocompletion.\n\n```sh\n# Bash (add to .bashrc for persistence)\nsource <(kompose completion bash)\n\n# Zsh (add to .zshrc for persistence)\nsource <(kompose completion zsh)\n\n# Fish autocompletion\nkompose completion fish | source\n```\n\n## Development and building of Kompose\n\n### Building with `go`\n\n**Requisites:**\n\n1. [make](https://www.gnu.org/software/make/)\n2. [Golang](https://golang.org/) v1.6 or later\n3. Set `GOPATH` correctly or click [SettingGOPATH](https://github.com/golang/go/wiki/SettingGOPATH) for details\n\n**Steps:**\n\n1. Clone repository\n\n```console\n$ git clone https://github.com/kubernetes/kompose.git $GOPATH/src/github.com/kubernetes/kompose\n```\n\n2. Change directory to the cloned repo.\n\n```console\ncd $GOPATH/src/github.com/kubernetes/kompose\n```\n\n3. Build with `make`\n\n```console\n$ make bin\n```\n\n4. Or build with `go`\n\n```console\n$ go build -o kompose main.go\n```\n\n5. Test your changes\n\n```console\n$ make test\n```\n\n## Documentation\n\nDocumentation can be found at our [kompose.io](http://kompose.io) website or our [docs](https://github.com/kubernetes/kompose/tree/main/docs) folder.\n\nHere is a list of all available docs:\n\n- [Quick start](docs/getting-started.md)\n- [Installation](docs/installation.md)\n- [User guide](docs/user-guide.md)\n- [Conversion](docs/conversion.md)\n- [Architecture](docs/architecture.md)\n- [Development](docs/development.md)\n\n## Community, Discussion, Contribution, and Support\n\n**Issues:** If you find any issues, please [file it](https://github.com/kubernetes/kompose/issues).\n\n**Kubernetes Community:** As part of the Kubernetes ecosystem, we follow the Kubernetes community principles. More information can be found on the [community page](http://kubernetes.io/community/).\n\n**Chat (Slack):** We're fairly active on [Slack](http://slack.kubernetes.io#kompose) and you can find us in the #kompose channel.\n\n### Code of Conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n[Build Status]: https://github.com/kubernetes/kompose/actions?query=workflow%3A%22Kompose+CI%22\n[Build Status Widget]: https://github.com/kubernetes/kompose/workflows/Kompose%20CI/badge.svg\n[GoDoc]: https://godoc.org/github.com/kubernetes/kompose\n[GoDoc Widget]: https://godoc.org/github.com/kubernetes/kompose?status.svg\n[Coverage Status Widget]: https://coveralls.io/repos/github/kubernetes/kompose/badge.svg?branch=main\n[Coverage Status]: https://coveralls.io/github/kubernetes/kompose?branch=main\n[GoReportCard Widget]: https://goreportcard.com/badge/github.com/kubernetes/kompose\n[GoReportCardResult]: https://goreportcard.com/report/github.com/kubernetes/kompose\n", "release_dates": ["2024-01-18T15:05:08Z", "2023-10-12T12:55:31Z", "2023-10-06T17:39:36Z", "2023-09-29T15:45:28Z", "2023-07-18T12:50:59Z", "2023-07-05T18:57:41Z", "2023-01-23T18:48:42Z", "2022-11-18T16:44:49Z", "2022-01-10T20:47:03Z", "2021-11-13T14:57:01Z", "2021-10-23T06:55:43Z", "2021-08-29T15:22:47Z", "2021-07-13T13:42:21Z", "2020-10-28T18:39:47Z", "2020-02-25T17:13:34Z", "2019-12-23T17:08:51Z", "2019-10-16T17:43:28Z", "2019-03-01T20:40:29Z", "2018-11-05T15:41:14Z", "2018-07-24T16:58:19Z", "2018-06-28T16:09:33Z", "2018-06-04T17:59:47Z", "2018-05-14T13:20:58Z", "2018-04-18T14:08:57Z", "2018-03-26T16:13:30Z", "2018-03-06T16:07:45Z", "2018-02-13T21:06:10Z", "2018-01-24T16:07:08Z", "2018-01-04T17:15:03Z", "2017-12-11T19:07:52Z"]}, {"name": "kops", "description": "Kubernetes Operations (kOps) - Production Grade k8s Installation, Upgrades and Management", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# kOps - Kubernetes Operations\n\n[![CI](https://github.com/kubernetes/kops/actions/workflows/main.yml/badge.svg)](https://github.com/kubernetes/kops/actions/workflows/main.yml)\n![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/kubernetes/kops) [![Go Report Card](https://goreportcard.com/badge/k8s.io/kops)](https://goreportcard.com/report/k8s.io/kops)  [![GoDoc Widget]][GoDoc]\n\n[GoDoc]: https://pkg.go.dev/k8s.io/kops\n[GoDoc Widget]: https://godoc.org/k8s.io/kops?status.svg\n\n\nThe easiest way to get a production grade Kubernetes cluster up and running.\n\n## What is kOps?\n\nWe like to think of it as `kubectl` for clusters.\n\n`kops` will not only help you create, destroy, upgrade and maintain production-grade, highly\navailable, Kubernetes cluster, but it will also provision the necessary cloud infrastructure.\n\nAWS (Amazon Web Services) and GCE (Google Cloud Platform) are currently officially supported, with DigitalOcean, Hetzner and OpenStack in beta support, and Azure in alpha.\n\n## Can I see it in action?\n\n<p align=\"center\">\n  <a href=\"https://asciinema.org/a/97298\">\n  <img src=\"https://asciinema.org/a/97298.png\" width=\"885\"></image>\n  </a>\n</p>\n\n\n## Installing and launching a Kubernetes cluster hosted on AWS, GCE, DigitalOcean, Hetzner, OpenStack, Azure\n\nSee [Getting Started](https://kops.sigs.k8s.io/getting_started/install/)\n\n\n## Documentation\n\nDocumentation is in the `/docs` directory, and can be seen at [kops.sigs.k8s.io](https://kops.sigs.k8s.io/).\n\n\n## Releases and kubernetes Release Compatibility\n\nSee [Releases and versioning](https://kops.sigs.k8s.io/welcome/releases/)\n\n\n## Getting Involved and Contributing\n\nSee [Contributing](https://kops.sigs.k8s.io/contributing/)\n\n### Office Hours\n\nkOps maintainers set aside one hour every other week for **public** office hours. This time is used to gather with community members interested in kOps. This session is open to both developers and users.\n\nWe do maintain an [agenda](https://docs.google.com/document/d/12QkyL0FkNbWPcLFxxRGSPt_tNPBHbmni3YLY-lHny7E/edit) and stick to it as much as possible. If you want to hold the floor, put your item in this doc. Bullet/note form is fine. Even if your topic gets in late, we do our best to cover it.\n\nFor more information about the office hours and how to join, see [Office Hours](https://kops.sigs.k8s.io/welcome/office_hours/)\n", "release_dates": ["2024-02-02T15:49:46Z", "2024-02-02T14:33:35Z", "2024-01-26T15:49:41Z", "2023-12-22T14:40:37Z", "2023-12-22T15:03:39Z", "2023-11-13T08:25:01Z", "2023-11-13T09:59:01Z", "2023-11-13T09:58:06Z", "2023-09-23T16:18:37Z", "2023-09-23T06:14:33Z", "2023-09-08T14:53:23Z", "2023-09-08T07:00:07Z", "2023-09-03T06:45:32Z", "2023-09-03T12:00:24Z", "2023-08-11T00:43:25Z", "2023-07-17T08:59:55Z", "2023-07-16T07:09:01Z", "2023-07-02T03:03:22Z", "2023-06-25T06:34:57Z", "2023-06-20T12:53:46Z", "2023-06-17T16:15:47Z", "2023-06-17T16:16:06Z", "2023-05-20T04:15:20Z", "2023-05-06T16:18:47Z", "2023-03-10T14:44:10Z", "2023-03-09T11:57:47Z", "2023-01-14T03:27:29Z", "2022-12-27T19:23:18Z", "2022-12-23T10:58:04Z", "2022-11-25T21:44:59Z"]}, {"name": "kube-aggregator", "description": "Aggregator for Kubernetes-style API servers: dynamic registration, discovery summarization, secure proxy", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# kube-aggregator\n\nImplements the [Aggregated API Servers](https://github.com/kubernetes/design-proposals-archive/blob/main/api-machinery/aggregated-api-servers.md) design proposal.\n\nIt provides:\n\n* an API for registering API servers.\n* Summaries of discovery information from all the aggregated APIs\n* HTTP proxying of requests from clients on to specific API backends\n\n\n## Purpose\n\nWe want to divide the single monolithic API server into multiple aggregated\nservers. Anyone should be able to write their own aggregated API server to expose APIs they want.\nCluster admins should be able to expose new APIs at runtime by bringing up new\naggregated servers.\n\n\n## Compatibility\n\nHEAD of this repo will match HEAD of k8s.io/apiserver, k8s.io/apimachinery, and k8s.io/client-go.\n\n## Where does it come from?\n\n`kube-aggregator` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/kube-aggregator.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n", "release_dates": []}, {"name": "kube-controller-manager", "description": "kube-controller-manager component configs", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kube-controller-manager\n\n## Purpose\n\nThis library contains code to expose kube-controller-manager API.\n\n\n## Compatibility\n\nThere are *NO compatibility guarantees* for this repository, yet.  It is in direct support of Kubernetes, so branches\nwill track Kubernetes and be compatible with that repo.  As we more cleanly separate the layers, we will review the\ncompatibility guarantee. We have a goal to make this easier to use in the future.\n\n\n## Where does it come from?\n\n`kube-controller-manager` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/kube-controller-manager.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n\n## Things you should *NOT* do\n\n 1. Directly modify any files under `pkg` in this repo.  Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/kube-controller-manager`.\n 2. Expect compatibility.  This repo is changing quickly in direct support of\n    Kubernetes and the kube-controller-manager API.\n\n", "release_dates": []}, {"name": "kube-openapi", "description": "Kubernetes OpenAPI spec generation & serving", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kube OpenAPI\n\nThis repo is the home for Kubernetes OpenAPI discovery spec generation. The goal \nis to support a subset of OpenAPI features to satisfy kubernetes use-cases but \nimplement that subset with little to no assumption about the structure of the \ncode or routes. Thus, there should be no kubernetes specific code in this repo. \n\n\nThere are two main parts: \n - A model generator that goes through .go files, find and generate model \ndefinitions. \n - The spec generator that is responsible for dynamically generating \nthe final OpenAPI spec using web service routes or combining other \nOpenAPI/Json specs.\n\n## Contributing\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on how to contribute.\n", "release_dates": []}, {"name": "kube-proxy", "description": "kube-proxy component configs", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# kube-proxy\n## Coming Soon!\n\nImplements https://github.com/luxas/community/blob/master/keps/sig-cluster-lifecycle/0014-20180707-componentconfig-api-types-to-staging.md#kube-proxy-changes\n\nIt provides\n* Provide a versioned API for configuring kube-proxy.\n\n## Compatibility\n\nHEAD of this repo will match HEAD of k8s.io/apiserver, k8s.io/apimachinery, and k8s.io/client-go.\n\n## Where does it come from?\n\n`kube-proxy` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/kube-proxy.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n", "release_dates": []}, {"name": "kube-scheduler", "description": "kube-scheduler component configs", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# kube-scheduler\n\nImplements [KEP 115 - Moving ComponentConfig API types to staging repos](https://git.k8s.io/enhancements/keps/sig-cluster-lifecycle/wgs/115-componentconfig#kube-scheduler-changes)\n\nThis repo provides external, versioned ComponentConfig API types for configuring the kube-scheduler.\nThese external types can easily be vendored and used by any third-party tool writing Kubernetes\nComponentConfig objects.\n\n## Compatibility\n\nHEAD of this repo will match HEAD of k8s.io/apiserver, k8s.io/apimachinery, and k8s.io/client-go.\n\n## Where does it come from?\n\nThis repo is synced from https://github.com/kubernetes/kubernetes/tree/master/staging/src/k8s.io/kube-scheduler.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here by a bot.\n\n", "release_dates": []}, {"name": "kube-state-metrics", "description": "Add-on agent to generate and expose cluster-level metrics.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Overview\n\n[![Build Status](https://github.com/kubernetes/kube-state-metrics/workflows/continuous-integration/badge.svg)](https://github.com/kubernetes/kube-state-metrics/actions)\n[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/kube-state-metrics)](https://goreportcard.com/report/github.com/kubernetes/kube-state-metrics)\n[![Go Reference](https://pkg.go.dev/badge/github.com/kubernetes/kube-state-metrics.svg)](https://pkg.go.dev/github.com/kubernetes/kube-state-metrics)\n[![govulncheck](https://github.com/kubernetes/kube-state-metrics/actions/workflows/govulncheck.yml/badge.svg)](https://github.com/kubernetes/kube-state-metrics/actions/workflows/govulncheck.yml)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/kubernetes/kube-state-metrics/badge)](https://api.securityscorecards.dev/projects/github.com/kubernetes/kube-state-metrics)\n\nkube-state-metrics (KSM) is a simple service that listens to the Kubernetes API\nserver and generates metrics about the state of the objects. (See examples in\nthe Metrics section below.) It is not focused on the health of the individual\nKubernetes components, but rather on the health of the various objects inside,\nsuch as deployments, nodes and pods.\n\nkube-state-metrics is about generating metrics from Kubernetes API objects\nwithout modification. This ensures that features provided by kube-state-metrics\nhave the same grade of stability as the Kubernetes API objects themselves. In\nturn, this means that kube-state-metrics in certain situations may not show the\nexact same values as kubectl, as kubectl applies certain heuristics to display\ncomprehensible messages. kube-state-metrics exposes raw data unmodified from the\nKubernetes API, this way users have all the data they require and perform\nheuristics as they see fit.\n\nThe metrics are exported on the HTTP endpoint `/metrics` on the listening port\n(default 8080). They are served as plaintext. They are designed to be consumed\neither by Prometheus itself or by a scraper that is compatible with scraping a\nPrometheus client endpoint. You can also open `/metrics` in a browser to see\nthe raw metrics. Note that the metrics exposed on the `/metrics` endpoint\nreflect the current state of the Kubernetes cluster. When Kubernetes objects\nare deleted they are no longer visible on the `/metrics` endpoint.\n\n## Table of Contents\n\n* [Versioning](#versioning)\n  * [Kubernetes Version](#kubernetes-version)\n  * [Compatibility matrix](#compatibility-matrix)\n  * [Resource group version compatibility](#resource-group-version-compatibility)\n  * [Container Image](#container-image)\n* [Metrics Documentation](#metrics-documentation)\n  * [Conflict resolution in label names](#conflict-resolution-in-label-names)\n* [Kube-state-metrics self metrics](#kube-state-metrics-self-metrics)\n* [Resource recommendation](#resource-recommendation)\n* [Latency](#latency)\n* [A note on costing](#a-note-on-costing)\n* [kube-state-metrics vs. metrics-server](#kube-state-metrics-vs-metrics-server)\n* [Scaling kube-state-metrics](#scaling-kube-state-metrics)\n  * [Resource recommendation](#resource-recommendation)\n  * [Horizontal sharding](#horizontal-sharding)\n    * [Automated sharding](#automated-sharding)\n  * [Daemonset sharding for pod metrics](#daemonset-sharding-for-pod-metrics)\n* [Setup](#setup)\n  * [Building the Docker container](#building-the-docker-container)\n* [Usage](#usage)\n  * [Kubernetes Deployment](#kubernetes-deployment)\n  * [Limited privileges environment](#limited-privileges-environment)\n  * [Helm Chart](#helm-chart)\n  * [Development](#development)\n  * [Developer Contributions](#developer-contributions)\n\n### Versioning\n\n#### Kubernetes Version\n\nkube-state-metrics uses [`client-go`](https://github.com/kubernetes/client-go) to talk with\nKubernetes clusters. The supported Kubernetes cluster version is determined by `client-go`.\nThe compatibility matrix for client-go and Kubernetes cluster can be found\n[here](https://github.com/kubernetes/client-go#compatibility-matrix).\nAll additional compatibility is only best effort, or happens to still/already be supported.\n\n#### Compatibility matrix\n\nAt most, 5 kube-state-metrics and 5 [kubernetes releases](https://github.com/kubernetes/kubernetes/releases) will be recorded below.\nGenerally, it is recommended to use the latest release of kube-state-metrics. If you run a very recent version of Kubernetes, you might want to use an unreleased version to have the full range of supported resources. If you run an older version of Kubernetes, you might need to run an older version in order to have full support for all resources. Be aware, that the maintainers will only support the latest release. Older versions might be supported by interested users of the community.\n\n| kube-state-metrics | Kubernetes client-go Version |\n|--------------------|:----------------------------:|\n| **v2.6.0**         | v1.24                        |\n| **v2.7.0**         | v1.25                        |\n| **v2.8.2**         | v1.26                        |\n| **v2.9.2**         | v1.26                        |\n| **v2.10.0**        | v1.27                        |\n| **main**           | v1.28                        |\n\n#### Resource group version compatibility\n\nResources in Kubernetes can evolve, i.e., the group version for a resource may change from alpha to beta and finally GA\nin different Kubernetes versions. For now, kube-state-metrics will only use the oldest API available in the latest\nrelease.\n\n#### Container Image\n\nThe latest container image can be found at:\n\n* `registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.0` (arch: `amd64`, `arm`, `arm64`, `ppc64le` and `s390x`)\n* View all multi-architecture images at [here](https://explore.ggcr.dev/?image=registry.k8s.io%2Fkube-state-metrics%2Fkube-state-metrics:v2.10.0)\n\n### Metrics Documentation\n\nAny resources and metrics based on alpha Kubernetes APIs are excluded from any stability guarantee,\nwhich may be changed at any given release.\n\nSee the [`docs`](docs) directory for more information on the exposed metrics.\n\n#### Conflict resolution in label names\n\nThe `*_labels` family of metrics exposes Kubernetes labels as Prometheus labels.\nAs [Kubernetes](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set)\nis more liberal than\n[Prometheus](https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels)\nin terms of allowed characters in label names,\nwe automatically convert unsupported characters to underscores.\nFor example, `app.kubernetes.io/name` becomes `label_app_kubernetes_io_name`.\n\nThis conversion can create conflicts when multiple Kubernetes labels like\n`foo-bar` and `foo_bar` would be converted to the same Prometheus label `label_foo_bar`.\n\nKube-state-metrics automatically adds a suffix `_conflictN` to resolve this conflict,\nso it converts the above labels to\n`label_foo_bar_conflict1` and `label_foo_bar_conflict2`.\n\nIf you'd like to have more control over how this conflict is resolved,\nyou might want to consider addressing this issue on a different level of the stack,\ne.g. by standardizing Kubernetes labels using an\n[Admission Webhook](https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/)\nthat ensures that there are no possible conflicts.\n\n### Kube-state-metrics self metrics\n\nkube-state-metrics exposes its own general process metrics under `--telemetry-host` and `--telemetry-port` (default 8081).\n\nkube-state-metrics also exposes list and watch success and error metrics. These can be used to calculate the error rate of list or watch resources.\nIf you encounter those errors in the metrics, it is most likely a configuration or permission issue, and the next thing to investigate would be looking\nat the logs of kube-state-metrics.\n\nExample of the above mentioned metrics:\n\n```\nkube_state_metrics_list_total{resource=\"*v1.Node\",result=\"success\"} 1\nkube_state_metrics_list_total{resource=\"*v1.Node\",result=\"error\"} 52\nkube_state_metrics_watch_total{resource=\"*v1beta1.Ingress\",result=\"success\"} 1\n```\n\nkube-state-metrics also exposes some http request metrics, examples of those are:\n\n```\nhttp_request_duration_seconds_bucket{handler=\"metrics\",method=\"get\",le=\"2.5\"} 30\nhttp_request_duration_seconds_bucket{handler=\"metrics\",method=\"get\",le=\"5\"} 30\nhttp_request_duration_seconds_bucket{handler=\"metrics\",method=\"get\",le=\"10\"} 30\nhttp_request_duration_seconds_bucket{handler=\"metrics\",method=\"get\",le=\"+Inf\"} 30\nhttp_request_duration_seconds_sum{handler=\"metrics\",method=\"get\"} 0.021113919999999998\nhttp_request_duration_seconds_count{handler=\"metrics\",method=\"get\"} 30\n```\n\nkube-state-metrics also exposes build and configuration metrics:\n\n```\nkube_state_metrics_build_info{branch=\"main\",goversion=\"go1.15.3\",revision=\"6c9d775d\",version=\"v2.0.0-beta\"} 1\nkube_state_metrics_shard_ordinal{shard_ordinal=\"0\"} 0\nkube_state_metrics_total_shards 1\n```\n\n`kube_state_metrics_build_info` is used to expose version and other build information. For more usage about the info pattern,\nplease check the blog post [here](https://www.robustperception.io/exposing-the-software-version-to-prometheus).\nSharding metrics expose `--shard` and `--total-shards` flags and can be used to validate\nrun-time configuration, see [`/examples/prometheus-alerting-rules`](./examples/prometheus-alerting-rules).\n\nkube-state-metrics also exposes metrics about it config file and the Custom Resource State config file:\n\n```\nkube_state_metrics_config_hash{filename=\"crs.yml\",type=\"customresourceconfig\"} 2.38272279311849e+14\nkube_state_metrics_config_hash{filename=\"config.yml\",type=\"config\"} 2.65285922340846e+14\nkube_state_metrics_last_config_reload_success_timestamp_seconds{filename=\"crs.yml\",type=\"customresourceconfig\"} 1.6704882592037103e+09\nkube_state_metrics_last_config_reload_success_timestamp_seconds{filename=\"config.yml\",type=\"config\"} 1.6704882592035313e+09\nkube_state_metrics_last_config_reload_successful{filename=\"crs.yml\",type=\"customresourceconfig\"} 1\nkube_state_metrics_last_config_reload_successful{filename=\"config.yml\",type=\"config\"} 1\n```\n\n### Scaling kube-state-metrics\n\n#### Resource recommendation\n\nResource usage for kube-state-metrics changes with the Kubernetes objects (Pods/Nodes/Deployments/Secrets etc.) size of the cluster.\nTo some extent, the Kubernetes objects in a cluster are in direct proportion to the node number of the cluster.\n\nAs a general rule, you should allocate:\n\n* 250MiB memory\n* 0.1 cores\n\nNote that if CPU limits are set too low, kube-state-metrics' internal queues will not be able to be worked off quickly enough, resulting in increased memory consumption as the queue length grows. If you experience problems resulting from high memory allocation or CPU throttling, try increasing the CPU limits.\n\n### Latency\n\nIn a 100 node cluster scaling test the latency numbers were as follows:\n\n```\n\"Perc50\": 259615384 ns,\n\"Perc90\": 475000000 ns,\n\"Perc99\": 906666666 ns.\n```\n\n### A note on costing\n\nBy default, kube-state-metrics exposes several metrics for events across your cluster. If you have a large number of frequently-updating resources on your cluster, you may find that a lot of data is ingested into these metrics. This can incur high costs on some cloud providers. Please take a moment to [configure what metrics you'd like to expose](docs/cli-arguments.md), as well as consult the documentation for your Kubernetes environment in order to avoid unexpectedly high costs.\n\n### kube-state-metrics vs. metrics-server\n\nThe [metrics-server](https://github.com/kubernetes-incubator/metrics-server)\nis a project that has been inspired by\n[Heapster](https://github.com/kubernetes-retired/heapster) and is implemented\nto serve the goals of core metrics pipelines in [Kubernetes monitoring\narchitecture](https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/monitoring_architecture.md).\nIt is a cluster level component which periodically scrapes metrics from all\nKubernetes nodes served by Kubelet through Metrics API. The metrics are\naggregated, stored in memory and served in [Metrics API\nformat](https://git.k8s.io/metrics/pkg/apis/metrics/v1alpha1/types.go). The\nmetrics-server stores the latest values only and is not responsible for\nforwarding metrics to third-party destinations.\n\nkube-state-metrics is focused on generating completely new metrics from\nKubernetes' object state (e.g. metrics based on deployments, replica sets,\netc.). It holds an entire snapshot of Kubernetes state in memory and\ncontinuously generates new metrics based off of it. And just like the\nmetrics-server it too is not responsible for exporting its metrics anywhere.\n\nHaving kube-state-metrics as a separate project also enables access to these\nmetrics from monitoring systems such as Prometheus.\n\n### Horizontal sharding\n\nIn order to shard kube-state-metrics horizontally, some automated sharding capabilities have been implemented. It is configured with the following flags:\n\n* `--shard` (zero indexed)\n* `--total-shards`\n\nSharding is done by taking an md5 sum of the Kubernetes Object's UID and performing a modulo operation on it with the total number of shards. Each shard decides whether the object is handled by the respective instance of kube-state-metrics or not. Note that this means all instances of kube-state-metrics, even if sharded, will have the network traffic and the resource consumption for unmarshaling objects for all objects, not just the ones they are responsible for. To optimize this further, the Kubernetes API would need to support sharded list/watch capabilities. In the optimal case, memory consumption for each shard will be 1/n compared to an unsharded setup. Typically, kube-state-metrics needs to be memory and latency optimized in order for it to return its metrics rather quickly to Prometheus. One way to reduce the latency between kube-state-metrics and the kube-apiserver is to run KSM with the `--use-apiserver-cache` flag. In addition to reducing the latency, this option will also lead to a reduction in the load on etcd.\n\nSharding should be used carefully and additional monitoring should be set up in order to ensure that sharding is set up and functioning as expected (eg. instances for each shard out of the total shards are configured).\n\n#### Automated sharding\n\nAutomatic sharding allows each shard to discover its nominal position when deployed in a StatefulSet which is useful for automatically configuring sharding. This is an experimental feature and may be broken or removed without notice.\n\nTo enable automated sharding, kube-state-metrics must be run by a `StatefulSet` and the pod name and namespace must be handed to the kube-state-metrics process via the `--pod` and `--pod-namespace` flags. Example manifests demonstrating the autosharding functionality can be found in [`/examples/autosharding`](./examples/autosharding).\n\nThis way of deploying shards is useful when you want to manage KSM shards through a single Kubernetes resource (a single `StatefulSet` in this case) instead of having one `Deployment` per shard. The advantage can be especially significant when deploying a high number of shards.\n\nThe downside of using an auto-sharded setup comes from the rollout strategy supported by `StatefulSet`s. When managed by a `StatefulSet`, pods are replaced one at a time with each pod first getting terminated and then recreated. Besides such rollouts being slower, they will also lead to short downtime for each shard. If a Prometheus scrape happens during a rollout, it can miss some of the metrics exported by kube-state-metrics.\n\n### Daemonset sharding for pod metrics\n\nFor pod metrics, they can be sharded per node with the following flag:\n\n* `--node=$(NODE_NAME)`\n\nEach kube-state-metrics pod uses FieldSelector (spec.nodeName) to watch/list pod metrics only on the same node.\n\nA daemonset kube-state-metrics example:\n\n```\napiVersion: apps/v1\nkind: DaemonSet\nspec:\n  template:\n    spec:\n      containers:\n      - image: registry.k8s.io/kube-state-metrics/kube-state-metrics:IMAGE_TAG\n        name: kube-state-metrics\n        args:\n        - --resource=pods\n        - --node=$(NODE_NAME)\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n```\n\nTo track metrics for unassigned pods, you need to add an additional deployment and set `--node=\"\"`, as shown in the following example:\n\n```\napiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n      - image: registry.k8s.io/kube-state-metrics/kube-state-metrics:IMAGE_TAG\n        name: kube-state-metrics\n        args:\n        - --resources=pods\n        - --node=\"\"\n```\n\nOther metrics can be sharded via [Horizontal sharding](#horizontal-sharding).\n\n### Setup\n\nInstall this project to your `$GOPATH` using `go get`:\n\n```\ngo get k8s.io/kube-state-metrics\n```\n\n#### Building the Docker container\n\nSimply run the following command in this root folder, which will create a\nself-contained, statically-linked binary and build a Docker image:\n\n```\nmake container\n```\n\n### Usage\n\nSimply build and run kube-state-metrics inside a Kubernetes pod which has a\nservice account token that has read-only access to the Kubernetes cluster.\n\n#### For users of prometheus-operator/kube-prometheus stack\n\nThe ([`kube-prometheus`](https://github.com/prometheus-operator/kube-prometheus/)) stack installs kube-state-metrics as one of its [components](https://github.com/prometheus-operator/kube-prometheus#kube-prometheus); you do not need to install kube-state-metrics if you're using the kube-prometheus stack.\n\nIf you want to revise the default configuration for kube-prometheus, for example to enable non-default metrics, have a look at [Customizing Kube-Prometheus](https://github.com/prometheus-operator/kube-prometheus/blob/main/docs/customizing.md).\n\n#### Kubernetes Deployment\n\nTo deploy this project, you can simply run `kubectl apply -f examples/standard` and a Kubernetes service and deployment will be created. (Note: Adjust the apiVersion of some resource if your kubernetes cluster's version is not 1.8+, check the yaml file for more information).\n\nTo have Prometheus discover kube-state-metrics instances it is advised to create a specific Prometheus scrape config for kube-state-metrics that picks up both metrics endpoints. Annotation based discovery is discouraged as only one of the endpoints would be able to be selected, plus kube-state-metrics in most cases has special authentication and authorization requirements as it essentially grants read access through the metrics endpoint to most information available to it.\n\n**Note:** Google Kubernetes Engine (GKE) Users - GKE has strict role permissions that will prevent the kube-state-metrics roles and role bindings from being created. To work around this, you can give your GCP identity the cluster-admin role by running the following one-liner:\n\n```\nkubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=$(gcloud info --format='value(config.account)')\n```\n\nNote that your GCP identity is case sensitive but `gcloud info` as of Google Cloud SDK 221.0.0 is not. This means that if your IAM member contains capital letters, the above one-liner may not work for you. If you have 403 forbidden responses after running the above command and `kubectl apply -f examples/standard`, check the IAM member associated with your account at <https://console.cloud.google.com/iam-admin/iam?project=PROJECT_ID>. If it contains capital letters, you may need to set the --user flag in the command above to the case-sensitive role listed at <https://console.cloud.google.com/iam-admin/iam?project=PROJECT_ID>.\n\nAfter running the above, if you see `Clusterrolebinding \"cluster-admin-binding\" created`, then you are able to continue with the setup of this service.\n\n#### Limited privileges environment\n\nIf you want to run kube-state-metrics in an environment where you don't have cluster-reader role, you can:\n\n* create a serviceaccount\n\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: kube-state-metrics\n  namespace: your-namespace-where-kube-state-metrics-will-deployed\n```\n\n* give it `view` privileges on specific namespaces (using roleBinding) (*note: you can add this roleBinding to all the NS you want your serviceaccount to access*)\n\n```yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: kube-state-metrics\n  namespace: project1\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: view\nsubjects:\n  - kind: ServiceAccount\n    name: kube-state-metrics\n    namespace: your-namespace-where-kube-state-metrics-will-deployed\n```\n\n* then specify a set of namespaces (using the `--namespaces` option) and a set of kubernetes objects (using the `--resources`) that your serviceaccount has access to in the `kube-state-metrics` deployment configuration\n\n```yaml\nspec:\n  template:\n    spec:\n      containers:\n      - name: kube-state-metrics\n        args:\n          - '--resources=pods'\n          - '--namespaces=project1'\n```\n\nFor the full list of arguments available, see the documentation in [docs/cli-arguments.md](./docs/cli-arguments.md)\n\n#### Helm Chart\n\nStarting from the kube-state-metrics chart `v2.13.3` (kube-state-metrics image `v1.9.8`), the official [Helm chart](https://artifacthub.io/packages/helm/prometheus-community/kube-state-metrics/) is maintained in [prometheus-community/helm-charts](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-state-metrics). Starting from kube-state-metrics chart `v3.0.0` only kube-state-metrics images of `v2.0.0 +` are supported.\n\n#### Development\n\nWhen developing, test a metric dump against your local Kubernetes cluster by\nrunning:\n\n> Users can override the apiserver address in KUBE-CONFIG file with `--apiserver` command line.\n\n go install\n kube-state-metrics --port=8080 --telemetry-port=8081 --kubeconfig=<KUBE-CONFIG> --apiserver=<APISERVER>\n\nThen curl the metrics endpoint\n\n curl localhost:8080/metrics\n\nTo run the e2e tests locally see the documentation in [tests/README.md](./tests/README.md).\n\n#### Developer Contributions\n\nWhen developing, there are certain code patterns to follow to better your contributing experience and likelihood of e2e and other ci tests to pass. To learn more about them, see the documentation in [docs/developer/guide.md](./docs/developer/guide.md).\n", "release_dates": ["2023-11-09T15:45:43Z", "2023-08-31T16:56:17Z", "2023-05-31T09:28:35Z", "2023-05-28T22:44:37Z", "2023-05-23T17:33:43Z", "2023-03-16T10:34:42Z", "2023-02-22T14:23:43Z", "2023-02-09T19:02:38Z", "2022-11-24T16:16:07Z", "2022-08-24T16:40:23Z", "2022-06-03T10:16:51Z", "2022-03-08T14:27:47Z", "2022-02-22T13:14:31Z", "2022-02-22T10:24:13Z", "2021-12-09T15:37:11Z", "2021-11-09T18:19:30Z", "2021-10-11T14:40:10Z", "2021-10-11T13:45:20Z", "2021-09-27T09:18:33Z", "2021-08-24T13:23:59Z", "2021-07-29T18:15:59Z", "2021-06-04T15:12:07Z", "2021-05-25T14:31:55Z", "2021-04-27T21:21:57Z", "2021-04-13T07:06:16Z", "2021-04-07T21:21:27Z", "2021-03-30T11:18:15Z", "2021-03-26T22:45:16Z", "2021-03-04T13:27:18Z", "2021-02-23T10:14:31Z"]}, {"name": "kubeadm", "description": "Aggregator for issues filed against kubeadm", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubeadm\n\nThe purpose of this repo is to aggregate issues filed against the [kubeadm component](https://git.k8s.io/kubernetes/cmd/kubeadm).\n\n**NOTE:** This issue tracker is not designated for providing support for kubeadm users.\nPlease see the [Support](#support) section below.\n\n## What is Kubeadm ?\n\nKubeadm is a tool built to provide best-practice \"fast paths\" for creating Kubernetes clusters.\nIt performs the actions necessary to get a minimum viable, secure cluster up and running in a user-friendly way.\nKubeadm's scope is limited to the local node filesystem and the Kubernetes API, and it is intended to be a composable building block of higher level tools.\n\n\n## Common Kubeadm cmdlets\n1. **kubeadm init** to bootstrap the initial Kubernetes control-plane node.\n1. **kubeadm join** to bootstrap a Kubernetes worker node or an additional control plane node, and join it to the cluster.\n1. **kubeadm upgrade** to upgrade a Kubernetes cluster to a newer version.\n1. **kubeadm reset** to revert any changes made to this host by kubeadm init or kubeadm join.\n\n## Support\n\nOnly log issues here if you think there is an actual bug or if you have a feature request.\n\nThe Kubernetes and kubeadm troubleshooting guides can be found here:\n- [Kubernetes](https://kubernetes.io/docs/tasks/debug/debug-cluster/)\n- [kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/)\n\nSupport requests should be sent to the community support channels or `#kubeadm` on the k8s Slack:\n- https://git.k8s.io/kubernetes/SUPPORT.md\n\n## Documentation\n\n- [Installing kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n- [Creating a cluster](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)\n- [Command-line reference](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/)\n- [Customizing components](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/control-plane-flags/)\n- [Certificate management](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/)\n- [Configuration API reference](https://kubernetes.io/docs/reference/config-api/)\n- [Configuration API reference (godoc)](https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm)\n(pick an API version from the [list of packages](https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#section-directories))\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](https://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at the [Cluster Lifecycle SIG](https://git.k8s.io/community/sig-cluster-lifecycle#cluster-lifecycle-sig).\n\n## Roadmap\n\nThe full picture of which direction we're taking is described in [this blog post](https://kubernetes.io/blog/2017/01/stronger-foundation-for-creating-and-managing-kubernetes-clusters/).\n\nPlease also refer to the latest [milestones in this repo](https://github.com/kubernetes/kubeadm/milestones).\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n", "release_dates": []}, {"name": "kubectl", "description": "Issue tracker and mirror of kubectl code", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubectl\n\n![kubectl logo](./images/kubectl-logo-medium.png)\n\n[![Build Status](https://travis-ci.org/kubernetes/kubectl.svg?branch=master)](https://travis-ci.org/kubernetes/kubectl) [![GoDoc](https://godoc.org/k8s.io/kubectl?status.svg)](https://godoc.org/k8s.io/kubectl)\n\nThe `k8s.io/kubectl` repo is used to track issues for the kubectl cli distributed\nwith `k8s.io/kubernetes`. It also contains packages intended for use by client\nprograms. E.g. these packages are vendored into `k8s.io/kubernetes` for use in\nthe [kubectl](https://github.com/kubernetes/kubernetes/tree/master/cmd/kubectl)\ncli client. That client will eventually move here too.\n\n## Contribution Requirements\n\n- Full unit-test coverage.\n\n- Go tools compliant (`go get`, `go test`, etc.). It needs to be vendorable\n  somewhere else.\n\n- No dependence on `k8s.io/kubernetes`. Dependence on other repositories is fine.\n\n- Code must be usefully [commented](https://go.dev/doc/effective_go#commentary).\n  Not only for developers on the project, but also for external users of these packages.\n\n- When reviewing PRs, you are encouraged to use Golang's [code review\n  comments](https://github.com/golang/go/wiki/CodeReviewComments) page.\n\n- Packages in this repository should aspire to implement sensible, small\n  interfaces and import a limited set of dependencies.\n\n## Community, discussion, contribution, and support\n\nSee [this document](https://github.com/kubernetes/community/tree/master/sig-cli) for how to reach the maintainers of this project.\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n", "release_dates": []}, {"name": "kubelet", "description": "kubelet component configs", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# kubelet\n\nImplements [KEP 14 - Moving ComponentConfig API types to staging repos](https://git.k8s.io/enhancements/keps/sig-cluster-lifecycle/wgs/115-componentconfig/README.md#kubelet-changes)\n\nThis repo provides external, versioned ComponentConfig API types for configuring the kubelet.\nThese external types can easily be vendored and used by any third-party tool writing Kubernetes\nComponentConfig objects.\n\n## Compatibility\n\nHEAD of this repo will match HEAD of k8s.io/apiserver, k8s.io/apimachinery, and k8s.io/client-go.\n\n## Where does it come from?\n\nThis repo is synced from https://github.com/kubernetes/kubernetes/tree/master/staging/src/k8s.io/kubelet.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here by a bot.\n\n", "release_dates": []}, {"name": "kubernetes", "description": "Production-Grade Container Scheduling and Management", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes (K8s)\n\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/569/badge)](https://bestpractices.coreinfrastructure.org/projects/569) [![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/kubernetes)](https://goreportcard.com/report/github.com/kubernetes/kubernetes) ![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/kubernetes/kubernetes?sort=semver)\n\n<img src=\"https://github.com/kubernetes/kubernetes/raw/master/logo/logo.png\" width=\"100\">\n\n----\n\nKubernetes, also known as K8s, is an open source system for managing [containerized applications]\nacross multiple hosts. It provides basic mechanisms for the deployment, maintenance,\nand scaling of applications.\n\nKubernetes builds upon a decade and a half of experience at Google running\nproduction workloads at scale using a system called [Borg],\ncombined with best-of-breed ideas and practices from the community.\n\nKubernetes is hosted by the Cloud Native Computing Foundation ([CNCF]).\nIf your company wants to help shape the evolution of\ntechnologies that are container-packaged, dynamically scheduled,\nand microservices-oriented, consider joining the CNCF.\nFor details about who's involved and how Kubernetes plays a role,\nread the CNCF [announcement].\n\n----\n\n## To start using K8s\n\nSee our documentation on [kubernetes.io].\n\nTake a free course on [Scalable Microservices with Kubernetes].\n\nTo use Kubernetes code as a library in other applications, see the [list of published components](https://git.k8s.io/kubernetes/staging/README.md).\nUse of the `k8s.io/kubernetes` module or `k8s.io/kubernetes/...` packages as libraries is not supported.\n\n## To start developing K8s\n\nThe [community repository] hosts all information about\nbuilding Kubernetes from source, how to contribute code\nand documentation, who to contact about what, etc.\n\nIf you want to build Kubernetes right away there are two options:\n\n##### You have a working [Go environment].\n\n```\ngit clone https://github.com/kubernetes/kubernetes\ncd kubernetes\nmake\n```\n\n##### You have a working [Docker environment].\n\n```\ngit clone https://github.com/kubernetes/kubernetes\ncd kubernetes\nmake quick-release\n```\n\nFor the full story, head over to the [developer's documentation].\n\n## Support\n\nIf you need support, start with the [troubleshooting guide],\nand work your way through the process that we've outlined.\n\nThat said, if you have questions, reach out to us\n[one way or another][communication].\n\n[announcement]: https://cncf.io/news/announcement/2015/07/new-cloud-native-computing-foundation-drive-alignment-among-container\n[Borg]: https://research.google.com/pubs/pub43438.html\n[CNCF]: https://www.cncf.io/about\n[communication]: https://git.k8s.io/community/communication\n[community repository]: https://git.k8s.io/community\n[containerized applications]: https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/\n[developer's documentation]: https://git.k8s.io/community/contributors/devel#readme\n[Docker environment]: https://docs.docker.com/engine\n[Go environment]: https://go.dev/doc/install\n[kubernetes.io]: https://kubernetes.io\n[Scalable Microservices with Kubernetes]: https://www.udacity.com/course/scalable-microservices-with-kubernetes--ud615\n[troubleshooting guide]: https://kubernetes.io/docs/tasks/debug/\n\n## Community Meetings \n\nThe [Calendar](https://www.kubernetes.dev/resources/calendar/) has the list of all the meetings in the Kubernetes community in a single location.\n\n## Adopters\n\nThe [User Case Studies](https://kubernetes.io/case-studies/) website has real-world use cases of organizations across industries that are deploying/migrating to Kubernetes.\n\n## Governance \n\nKubernetes project is governed by a framework of principles, values, policies and processes to help our community and constituents towards our shared goals.\n\nThe [Kubernetes Community](https://github.com/kubernetes/community/blob/master/governance.md) is the launching point for learning about how we organize ourselves.\n\nThe [Kubernetes Steering community repo](https://github.com/kubernetes/steering) is used by the Kubernetes Steering Committee, which oversees governance of the Kubernetes project.\n\n## Roadmap \n\nThe [Kubernetes Enhancements repo](https://github.com/kubernetes/enhancements) provides information about Kubernetes releases, as well as feature tracking and backlogs.\n", "release_dates": ["2024-02-28T05:37:33Z", "2024-02-14T18:01:57Z", "2024-02-14T15:49:40Z", "2024-02-14T15:51:57Z", "2024-02-14T16:07:53Z", "2024-02-14T05:11:21Z", "2024-01-31T19:48:16Z", "2024-01-17T19:37:29Z", "2024-01-17T19:40:09Z", "2024-01-17T19:40:02Z", "2024-01-17T19:42:17Z", "2023-12-20T13:23:37Z", "2023-12-20T11:14:33Z", "2023-12-20T13:27:00Z", "2023-12-13T16:34:20Z", "2023-12-08T10:48:58Z", "2023-11-28T13:45:08Z", "2023-11-22T00:49:30Z", "2023-11-15T19:43:03Z", "2023-11-15T20:05:57Z", "2023-11-15T20:43:58Z", "2023-11-16T11:30:38Z", "2023-11-02T21:39:29Z", "2023-10-18T14:36:22Z", "2023-10-18T15:16:00Z", "2023-10-18T15:47:07Z", "2023-10-18T16:20:06Z", "2023-10-11T19:17:05Z", "2023-09-25T20:57:29Z", "2023-09-13T18:06:30Z"]}, {"name": "kubernetes-template-project", "description": "A template for starting new projects on the github.com/kubernetes organization", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Template Project\n\nThe Kubernetes Template Project is a template for starting new projects in the GitHub organizations owned by Kubernetes. All Kubernetes projects, at minimum, must have the following files:\n\n- a `README.md` outlining the project goals, sponsoring sig, and community contact information\n- an `OWNERS` with the project leads listed as approvers ([docs on `OWNERS` files][owners])\n- a `CONTRIBUTING.md` outlining how to contribute to the project\n- an unmodified copy of `code-of-conduct.md` from this repo, which outlines community behavior and the consequences of breaking the code\n- a `LICENSE` which must be Apache 2.0 for code projects, or [Creative Commons 4.0] for documentation repositories, without any custom content\n- a `SECURITY_CONTACTS` with the contact points for the Product Security Team \n  to reach out to for triaging and handling of incoming issues. They must agree to abide by the\n  [Embargo Policy](https://git.k8s.io/security/private-distributors-list.md#embargo-policy)\n  and will be removed and replaced if they violate that agreement.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n- [Slack](https://slack.k8s.io/)\n- [Mailing List](https://groups.google.com/a/kubernetes.io/g/dev)\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n[owners]: https://git.k8s.io/community/contributors/guide/owners.md\n[Creative Commons 4.0]: https://git.k8s.io/website/LICENSE\n", "release_dates": []}, {"name": "legacy-cloud-providers", "description": "This repository hosts the legacy in-tree cloud providers. Out-of-tree cloud providers can consume packages in this repo to support legacy implementations of their Kubernetes cloud provider.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# legacy-cloud-providers\n\nThis repository hosts the legacy cloud providers that were previously hosted under\n`k8s.io/kubernetes/pkg/cloudprovider/providers`. Out-of-tree cloud providers can consume\npackages in this repo to support legacy implementations of their Kubernetes cloud provider.\n\n**Note:** go-get or vendor this package as `k8s.io/legacy-cloud-providers`.\n\n## Purpose\n\nTo be consumed by out-of-tree cloud providers that wish to support legacy behavior\nfrom their in-tree equivalents.\n\n## Compatibility\n\nThe legacy providers here follow the same compatibility rules as cloud providers that\nwere previously in `k8s.io/kubernetes/pkg/cloudprovider/providers`.\n\n## Where does it come from?\n\n`legacy-cloud-providers` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/legacy-cloud-providers.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n## Things you should NOT do\n\n 1. Add a new cloud provider here.\n 2. Directly modify anything under this repo. Those are driven from `k8s.io/kubernetes/staging/src/k8s.io/legacy-cloud-providers`.\n    sig-cloudprovider.\n 3. Add new features/integrations to a cloud provider in this repo. Changes sync here should only be incremental bug fixes.\n\n", "release_dates": []}, {"name": "metrics", "description": "Kubernetes metrics-related API types and clients", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# metrics\n\nKubernetes metrics API type definitions and clients.\n\n## Purpose\n\nThis repository contains type definitions and client code for the metrics\nAPIs that Kubernetes makes use of.  Depending on the API, the actual\nimplementations live elsewhere.\n\nConsumers of the metrics APIs can make use of this repository to access\nimplementations of the APIs, while implementors should make use of this\nlibrary when implementing their API servers.\n\n## APIs\n\nThis repository contains types and clients for several APIs.\n\n### Custom Metrics API\n\nThis API allows consumers to access arbitrary metrics which describe\nKubernetes resources.\n\nThe API is intended to be implemented by monitoring pipeline vendors, on\ntop of their metrics storage solutions.\n\nIf you want to implement this as an API server for this API, please see the\n[kubernetes-sigs/custom-metrics-apiserver](https://github.com/kubernetes-sigs/custom-metrics-apiserver)\nlibrary, which contains the basic infrastructure required to set up such\nan API server.\n\nImport Path: `k8s.io/metrics/pkg/apis/custom_metrics`.\n\n### Resource Metrics API\n\nThis API allows consumers to access resource metrics (CPU and memory) for\npods and nodes.\n\nThe API is implemented by [metrics-server](https://github.com/kubernetes-sigs/metrics-server) and [prometheus-adapter](https://github.com/kubernetes-sigs/prometheus-adapter).\n\nImport Path: `k8s.io/metrics/pkg/apis/metrics`.\n\n## Compatibility\n\nThe APIs in this repository follow the standard guarantees for Kubernetes\nAPIs, and will follow Kubernetes releases.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community\npage](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this repository at:\n\n- Slack: [#sig-instrumentation channel](https://kubernetes.slack.com/messages/sig-instrumentation), you can get an\n  invite at [slack.kubernetes.io](https://slack.kubernetes.io).\n- [Mailing List](https://groups.google.com/forum/#!forum/kubernetes-sig-instrumentation)\n\n### Code of Conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes\nCode of Conduct](code-of-conduct.md).\n\n### Contibution Guidelines\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for more information.\n\n", "release_dates": []}, {"name": "minikube", "description": "Run Kubernetes locally", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# minikube\n\n[![Actions Status](https://github.com/kubernetes/minikube/workflows/build/badge.svg)](https://github.com/kubernetes/minikube/actions)\n[![GoReport Widget]][GoReport Status]\n[![GitHub All Releases](https://img.shields.io/github/downloads/kubernetes/minikube/total.svg)](https://github.com/kubernetes/minikube/releases/latest)\n[![Latest Release](https://img.shields.io/github/v/release/kubernetes/minikube?include_prereleases)](https://github.com/kubernetes/minikube/releases/latest)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/5015/badge)](https://www.bestpractices.dev/en/projects/5015)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/kubernetes/minikube/badge)](https://api.securityscorecards.dev/projects/github.com/kubernetes/minikube)\n \n\n[GoReport Status]: https://goreportcard.com/report/github.com/kubernetes/minikube\n[GoReport Widget]: https://goreportcard.com/badge/github.com/kubernetes/minikube\n\n<img src=\"https://github.com/kubernetes/minikube/raw/master/images/logo/logo.png\" width=\"100\" alt=\"minikube logo\">\n\nminikube implements a local Kubernetes cluster on macOS, Linux, and Windows. minikube's [primary goals](https://minikube.sigs.k8s.io/docs/concepts/principles/) are to be the best tool for local Kubernetes application development and to support all Kubernetes features that fit. \n\n<img src=\"https://raw.githubusercontent.com/kubernetes/minikube/master/site/static/images/screenshot.png\" width=\"575\" height=\"322\" alt=\"screenshot\">\n\n## Features\n\nminikube runs the latest stable release of Kubernetes, with support for standard Kubernetes features like:\n\n* [LoadBalancer](https://minikube.sigs.k8s.io/docs/handbook/accessing/#loadbalancer-access) - using `minikube tunnel`\n* Multi-cluster - using `minikube start -p <name>`\n* [NodePorts](https://minikube.sigs.k8s.io/docs/handbook/accessing/#nodeport-access) - using `minikube service`\n* [Persistent Volumes](https://minikube.sigs.k8s.io/docs/handbook/persistent_volumes/)\n* [Ingress](https://kubernetes.io/docs/tasks/access-application-cluster/ingress-minikube/)\n* [Dashboard](https://minikube.sigs.k8s.io/docs/handbook/dashboard/) - `minikube dashboard`\n* [Container runtimes](https://minikube.sigs.k8s.io/docs/handbook/config/#runtime-configuration) - `minikube start --container-runtime`\n* [Configure apiserver and kubelet options](https://minikube.sigs.k8s.io/docs/handbook/config/#modifying-kubernetes-defaults) via command-line flags\n* Supports common [CI environments](https://github.com/minikube-ci/examples)\n\nAs well as developer-friendly features:\n\n* [Addons](https://minikube.sigs.k8s.io/docs/handbook/deploying/#addons) - a marketplace for developers to share configurations for running services on minikube\n* [NVIDIA GPU support](https://minikube.sigs.k8s.io/docs/tutorials/nvidia/) - for machine learning\n* [Filesystem mounts](https://minikube.sigs.k8s.io/docs/handbook/mount/)\n\n**For more information, see the official [minikube website](https://minikube.sigs.k8s.io)**\n\n## Installation\n\nSee the [Getting Started Guide](https://minikube.sigs.k8s.io/docs/start/)\n\n:mega: **Please fill out our [fast 5-question survey](https://forms.gle/Gg3hG5ZySw8c1C24A)** so that we can learn how & why you use minikube, and what improvements we should make. Thank you! :dancers:\n\n## Documentation\n\nSee https://minikube.sigs.k8s.io/docs/\n\n## More Examples\n\nSee minikube in action [here](https://minikube.sigs.k8s.io/docs/handbook/controls/)\n\n## Governance\n\nKubernetes project is governed by a framework of principles, values, policies and processes to help our community and constituents towards our shared goals.\n\nThe [Kubernetes Community](https://github.com/kubernetes/community/blob/master/governance.md) is the launching point for learning about how we organize ourselves.\n\nThe [Kubernetes Steering community repo](https://github.com/kubernetes/steering) is used by the Kubernetes Steering Committee, which oversees governance of the Kubernetes project.\n\n## Community\n\nminikube is a Kubernetes [#sig-cluster-lifecycle](https://github.com/kubernetes/community/tree/master/sig-cluster-lifecycle)  project.\n\n* [**#minikube on Kubernetes Slack**](https://kubernetes.slack.com/messages/minikube) - Live chat with minikube developers!\n* [minikube-users mailing list](https://groups.google.com/g/minikube-users)\n* [minikube-dev mailing list](https://groups.google.com/g/minikube-dev)\n\n* [Contributing](https://minikube.sigs.k8s.io/docs/contrib/)\n* [Development Roadmap](https://minikube.sigs.k8s.io/docs/contrib/roadmap/)\n\nJoin our community meetings:\n* [Bi-weekly office hours, Mondays @ 11am PST](https://tinyurl.com/minikube-oh)\n* [Triage Party](https://minikube.sigs.k8s.io/docs/contrib/triage/)\n", "release_dates": ["2023-11-08T17:21:51Z", "2023-10-28T01:28:10Z", "2023-08-16T22:32:44Z", "2023-07-20T17:46:01Z", "2023-07-18T17:25:06Z", "2023-04-04T22:19:15Z", "2023-04-03T18:11:21Z", "2023-01-27T19:37:21Z", "2022-11-04T20:54:32Z", "2022-10-08T03:28:08Z", "2022-09-15T21:28:09Z", "2022-08-02T22:16:22Z", "2022-06-22T23:29:28Z", "2022-05-18T00:15:33Z", "2022-05-13T21:39:09Z", "2022-02-24T19:25:43Z", "2022-01-21T01:20:56Z", "2022-01-20T01:16:25Z", "2021-11-05T16:04:07Z", "2021-10-28T21:33:38Z", "2021-09-21T23:39:06Z", "2021-09-17T21:43:54Z", "2021-09-03T20:01:46Z", "2021-07-07T21:57:04Z", "2021-06-29T22:41:38Z", "2021-06-11T15:56:10Z", "2021-06-03T01:15:18Z", "2021-05-06T21:44:15Z", "2021-04-30T23:06:50Z", "2021-04-10T00:30:30Z"]}, {"name": "mount-utils", "description": "Package mount defines an interface to mounting filesystems.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "## Purpose\n\nThis repository defines an interface to mounting filesystems to be consumed by \nvarious Kubernetes and out-of-tree CSI components. \n\nConsumers of this repository can make use of functions like 'Mount' to mount \nsource to target as fstype with given options, 'Unmount' to unmount a target.\nOther useful functions include 'List' all mounted file systems and find all\nmount references to a path using 'GetMountRefs'\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community\npage](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this repository at:\n\n- Slack: #sig-storage (on https://kubernetes.slack.com -- get an\n  invite at slack.kubernetes.io)\n- Mailing List:\n  https://groups.google.com/forum/#!forum/kubernetes-sig-storage\n\n### Code of Conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes\nCode of Conduct](code-of-conduct.md).\n\n### Contibution Guidelines\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for more information.\n\n", "release_dates": []}, {"name": "node-api", "description": null, "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# [EOL] Node API\n\nThe node-api group was migrated to a built-in API in the\n[k8s.io/api](https://github.com/kubernetes/api) repo with the\nv1.14 release. **This repo is no longer maintained**, and no longer\nsynced with core kubernetes as of the v1.18 release.\n\nPlease use the `RuntimeClass` types located at\n[k8s.io/api](https://github.com/kubernetes/api), and the generated\nclients located at [k8s.io/client-go](https://github.com/kubernetes/client-go).\n\n## Original Purpose\n\nThis repository contains type definitions and client code for the Kubernetes\nAPIs in the node.k8s.io API group. These APIs are primarily used by the Kubelet\nfor managing node operations, such as container runtime support.\n\nConsumers of the node APIs can make use of this repository to access\nimplementations of the APIs.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community\npage](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this repository at:\n\n- Slack: #sig-node (on https://kubernetes.slack.com -- get an\n  invite at slack.kubernetes.io)\n- Mailing List:\n  https://groups.google.com/forum/#!forum/kubernetes-sig-node\n\n### Code of Conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes\nCode of Conduct](code-of-conduct.md).\n\n### Contibution Guidelines\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for more information.\n", "release_dates": []}, {"name": "node-problem-detector", "description": "This is a place for various problem detectors running on the Kubernetes nodes.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# node-problem-detector\n\n[![Build Status](https://travis-ci.org/kubernetes/node-problem-detector.svg?branch=master)](https://travis-ci.org/kubernetes/node-problem-detector)  [![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/node-problem-detector)](https://goreportcard.com/report/github.com/kubernetes/node-problem-detector)\n\nnode-problem-detector aims to make various node problems visible to the upstream\nlayers in the cluster management stack.\nIt is a daemon that runs on each node, detects node\nproblems and reports them to apiserver.\nnode-problem-detector can either run as a\n[DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/) or run standalone.\nNow it is running as a\n[Kubernetes Addon](https://github.com/kubernetes/kubernetes/tree/master/cluster/addons)\nenabled by default in the GKE cluster. It is also enabled by default in AKS as part of the\n[AKS Linux Extension](https://learn.microsoft.com/en-us/azure/aks/faq#what-is-the-purpose-of-the-aks-linux-extension-i-see-installed-on-my-linux-vmss-instances).\n# Background\n\nThere are tons of node problems that could possibly affect the pods running on the\nnode, such as:\n* Infrastructure daemon issues: ntp service down;\n* Hardware issues: Bad CPU, memory or disk;\n* Kernel issues: Kernel deadlock, corrupted file system;\n* Container runtime issues: Unresponsive runtime daemon;\n* ...\n\nCurrently, these problems are invisible to the upstream layers in the cluster management\nstack, so Kubernetes will continue scheduling pods to the bad nodes.\n\nTo solve this problem, we introduced this new daemon **node-problem-detector** to\ncollect node problems from various daemons and make them visible to the upstream\nlayers. Once upstream layers have visibility to those problems, we can discuss the\n[remedy system](#remedy-systems).\n\n# Problem API\n\nnode-problem-detector uses `Event` and `NodeCondition` to report problems to\napiserver.\n* `NodeCondition`: Permanent problem that makes the node unavailable for pods should\nbe reported as `NodeCondition`.\n* `Event`: Temporary problem that has limited impact on pod but is informative\nshould be reported as `Event`.\n\n# Problem Daemon\n\nA problem daemon is a sub-daemon of node-problem-detector. It monitors specific\nkinds of node problems and reports them to node-problem-detector.\n\nA problem daemon could be:\n* A tiny daemon designed for dedicated Kubernetes use-cases.\n* An existing node health monitoring daemon integrated with node-problem-detector.\n\nCurrently, a problem daemon is running as a goroutine in the node-problem-detector\nbinary. In the future, we'll separate node-problem-detector and problem daemons into\ndifferent containers, and compose them with pod specification.\n\nEach category of problem daemon can be disabled at compilation time by setting\ncorresponding build tags. If they are disabled at compilation time, then all their\nbuild dependencies, global variables and background goroutines will be trimmed out\nof the compiled executable.\n\nList of supported problem daemons types:\n\n| Problem Daemon Types |  NodeCondition  | Description | Configs | Disabling Build Tag |\n|----------------|:---------------:|:------------|:--------|:--------------------|\n| [SystemLogMonitor](https://github.com/kubernetes/node-problem-detector/tree/master/pkg/systemlogmonitor) | KernelDeadlock ReadonlyFilesystem FrequentKubeletRestart FrequentDockerRestart FrequentContainerdRestart | A system log monitor monitors system log and reports problems and metrics according to predefined rules. | [filelog](https://github.com/kubernetes/node-problem-detector/blob/master/config/kernel-monitor-filelog.json), [kmsg](https://github.com/kubernetes/node-problem-detector/blob/master/config/kernel-monitor.json), [kernel](https://github.com/kubernetes/node-problem-detector/blob/master/config/kernel-monitor-counter.json) [abrt](https://github.com/kubernetes/node-problem-detector/blob/master/config/abrt-adaptor.json) [systemd](https://github.com/kubernetes/node-problem-detector/blob/master/config/systemd-monitor-counter.json) | disable_system_log_monitor\n| [SystemStatsMonitor](https://github.com/kubernetes/node-problem-detector/tree/master/pkg/systemstatsmonitor) | None(Could be added in the future) | A system stats monitor for node-problem-detector to collect various health-related system stats as metrics. See the proposal [here](https://docs.google.com/document/d/1SeaUz6kBavI283Dq8GBpoEUDrHA2a795xtw0OvjM568/edit). | [system-stats-monitor](https://github.com/kubernetes/node-problem-detector/blob/master/config/system-stats-monitor.json) | disable_system_stats_monitor\n| [CustomPluginMonitor](https://github.com/kubernetes/node-problem-detector/tree/master/pkg/custompluginmonitor) | On-demand(According to users configuration), existing example: NTPProblem | A custom plugin monitor for node-problem-detector to invoke and check various node problems with user-defined check scripts. See the proposal [here](https://docs.google.com/document/d/1jK_5YloSYtboj-DtfjmYKxfNnUxCAvohLnsH5aGCAYQ/edit#). | [example](https://github.com/kubernetes/node-problem-detector/blob/4ad49bbd84b8ced45ac825eac01ec93d9235935e/config/custom-plugin-monitor.json) | disable_custom_plugin_monitor\n| [HealthChecker](https://github.com/kubernetes/node-problem-detector/tree/master/pkg/healthchecker) | KubeletUnhealthy ContainerRuntimeUnhealthy| A health checker for node-problem-detector to check kubelet and container runtime health. | [kubelet](https://github.com/kubernetes/node-problem-detector/blob/master/config/health-checker-kubelet.json) [docker](https://github.com/kubernetes/node-problem-detector/blob/master/config/health-checker-docker.json) [containerd](https://github.com/kubernetes/node-problem-detector/blob/master/config/health-checker-containerd.json) | \n\n# Exporter\n\nAn exporter is a component of node-problem-detector. It reports node problems and/or metrics to\ncertain backends. Some of them can be disabled at compile-time using a build tag. List of supported exporters:\n\n| Exporter |Description | Disabling Build Tag |\n|----------|:-----------|:--------------------|\n| Kubernetes exporter | Kubernetes exporter reports node problems to Kubernetes API server: temporary problems get reported as Events, and permanent problems get reported as Node Conditions. |\n| Prometheus exporter | Prometheus exporter reports node problems and metrics locally as Prometheus metrics |\n| [Stackdriver exporter](https://github.com/kubernetes/node-problem-detector/blob/master/config/exporter/stackdriver-exporter.json) | Stackdriver exporter reports node problems and metrics to Stackdriver Monitoring API. | disable_stackdriver_exporter\n\n# Usage\n\n## Flags\n\n* `--version`: Print current version of node-problem-detector.\n* `--hostname-override`: A customized node name used for node-problem-detector to update conditions and emit events. node-problem-detector gets node name first from `hostname-override`, then `NODE_NAME` environment variable and finally fall back to `os.Hostname`.\n\n#### For System Log Monitor\n\n* `--config.system-log-monitor`: List of paths to system log monitor configuration files, comma-separated, e.g.\n  [config/kernel-monitor.json](https://github.com/kubernetes/node-problem-detector/blob/master/config/kernel-monitor.json).\n  Node problem detector will start a separate log monitor for each configuration. You can\n  use different log monitors to monitor different system logs.\n\n#### For System Stats Monitor\n\n* `--config.system-stats-monitor`: List of paths to system stats monitor config files, comma-separated, e.g.\n  [config/system-stats-monitor.json](https://github.com/kubernetes/node-problem-detector/blob/master/config/system-stats-monitor.json).\n  Node problem detector will start a separate system stats monitor for each configuration. You can\n  use different system stats monitors to monitor different problem-related system stats.\n\n#### For Custom Plugin Monitor\n\n* `--config.custom-plugin-monitor`: List of paths to custom plugin monitor config files, comma-separated, e.g.\n  [config/custom-plugin-monitor.json](https://github.com/kubernetes/node-problem-detector/blob/master/config/custom-plugin-monitor.json).\n  Node problem detector will start a separate custom plugin monitor for each configuration.  You can\n  use different custom plugin monitors to monitor different node problems.\n  \n  \n#### For Health Checkers\n\n  Health checkers are configured as custom plugins, using the config/health-checker-*.json config files.\n\n#### For Kubernetes exporter\n\n* `--enable-k8s-exporter`: Enables reporting to Kubernetes API server, default to `true`.\n* `--apiserver-override`: A URI parameter used to customize how node-problem-detector\nconnects the apiserver.  This is ignored if `--enable-k8s-exporter` is `false`. The format is the same as the\n[`source`](https://github.com/kubernetes/heapster/blob/master/docs/source-configuration.md#kubernetes)\nflag of [Heapster](https://github.com/kubernetes/heapster).\nFor example, to run without auth, use the following config:\n   ```\n   http://APISERVER_IP:APISERVER_PORT?inClusterConfig=false\n   ```\n   Refer to [heapster docs](https://github.com/kubernetes/heapster/blob/master/docs/source-configuration.md#kubernetes) for a complete list of available options.\n* `--address`: The address to bind the node problem detector server.\n* `--port`: The port to bind the node problem detector server. Use 0 to disable.\n\n#### For Prometheus exporter\n\n* `--prometheus-address`: The address to bind the Prometheus scrape endpoint, default to `127.0.0.1`.\n* `--prometheus-port`: The port to bind the Prometheus scrape endpoint, default to 20257. Use 0 to disable.\n\n#### For Stackdriver exporter\n\n* `--exporter.stackdriver`: Path to a Stackdriver exporter config file, e.g. [config/exporter/stackdriver-exporter.json](https://github.com/kubernetes/node-problem-detector/blob/master/config/exporter/stackdriver-exporter.json), defaults to empty string. Set to empty string to disable.\n\n### Deprecated Flags\n\n* `--system-log-monitors`: List of paths to system log monitor config files, comma-separated. This option is deprecated, replaced by `--config.system-log-monitor`, and will be removed. NPD will panic if both `--system-log-monitors` and `--config.system-log-monitor` are set.\n\n* `--custom-plugin-monitors`: List of paths to custom plugin monitor config files, comma-separated. This option is deprecated, replaced by `--config.custom-plugin-monitor`, and will be removed. NPD will panic if both `--custom-plugin-monitors` and `--config.custom-plugin-monitor` are set.\n\n## Build Image\n\n* Install development dependencies for `libsystemd` and the ARM GCC toolchain\n  * Debian/Ubuntu: `apt install libsystemd-dev gcc-aarch64-linux-gnu`\n\n* `git clone git@github.com:kubernetes/node-problem-detector.git`\n\n* Run `make` in the top directory. It will:\n  * Build the binary.\n  * Build the docker image. The binary and `config/` are copied into the docker image.\n\nIf you do not need certain categories of problem daemons, you could choose to disable them at compilation time. This is the\nbest way of keeping your node-problem-detector runtime compact without unnecessary code (e.g. global\nvariables, goroutines, etc). You can do so via setting the `BUILD_TAGS` environment variable\nbefore running `make`. For example:\n\n`BUILD_TAGS=\"disable_custom_plugin_monitor disable_system_stats_monitor\" make`\n\nThe above command will compile the node-problem-detector without [Custom Plugin Monitor](https://github.com/kubernetes/node-problem-detector/tree/master/pkg/custompluginmonitor)\nand [System Stats Monitor](https://github.com/kubernetes/node-problem-detector/tree/master/pkg/systemstatsmonitor).\nCheck out the [Problem Daemon](https://github.com/kubernetes/node-problem-detector#problem-daemon) section\nto see how to disable each problem daemon during compilation time.\n\n## Push Image\n\n`make push` uploads the docker image to a registry. By default, the image will be uploaded to\n`staging-k8s.gcr.io`. It's easy to modify the `Makefile` to push the image\nto another registry.\n\n## Installation\n\nThe easiest way to install node-problem-detector into your cluster is to use the [Helm](https://helm.sh/) [chart](https://github.com/deliveryhero/helm-charts/tree/master/stable/node-problem-detector):\n\n```\nhelm repo add deliveryhero https://charts.deliveryhero.io/\nhelm install --generate-name deliveryhero/node-problem-detector\n```\n\nAlternatively, to install node-problem-detector manually:\n\n1. Edit [node-problem-detector.yaml](deployment/node-problem-detector.yaml) to fit your environment. Set `log` volume to your system log directory (used by SystemLogMonitor). You can use a ConfigMap to overwrite the `config` directory inside the pod.\n\n2. Edit [node-problem-detector-config.yaml](deployment/node-problem-detector-config.yaml) to configure node-problem-detector.\n\n3. Edit [rbac.yaml](deployment/rbac.yaml) to fit your environment.\n\n4. Create the ServiceAccount and ClusterRoleBinding with `kubectl create -f rbac.yaml`.\n\n4. Create the ConfigMap with `kubectl create -f node-problem-detector-config.yaml`.\n\n5. Create the DaemonSet with `kubectl create -f node-problem-detector.yaml`.\n\n## Start Standalone\n\nTo run node-problem-detector standalone, you should set `inClusterConfig` to `false` and\nteach node-problem-detector how to access apiserver with `apiserver-override`.\n\nTo run node-problem-detector standalone with an insecure apiserver connection:\n```\nnode-problem-detector --apiserver-override=http://APISERVER_IP:APISERVER_INSECURE_PORT?inClusterConfig=false\n```\n\nFor more scenarios, see [here](https://github.com/kubernetes/heapster/blob/master/docs/source-configuration.md#kubernetes)\n\n## Windows\n\nNode Problem Detector has preliminary support Windows. Most of the functionality has not been tested but filelog plugin works.\n\nFollow [Issue #461](https://github.com/kubernetes/node-problem-detector/issues/461) for development status of Windows support.\n\n### Development\n\nTo develop NPD on Windows you'll need to setup your Windows machine for Go development. Install the following tools:\n\n* [Git for Windows](https://git-scm.com/)\n* [Go](https://golang.org/)\n* [Visual Studio Code](https://code.visualstudio.com/)\n* [Make](http://gnuwin32.sourceforge.net/packages/make.htm)\n* [mingw-64 WinBuilds](http://mingw-w64.org/downloads)\n  * Tested with x86-64 Windows Native mode.\n  * Add the `$InstallDir\\bin` to [Windows `PATH` variable](https://answers.microsoft.com/en-us/windows/forum/windows_10-other_settings-winpc/adding-path-variable/97300613-20cb-4d85-8d0e-cc9d3549ba23).\n\n```powershell\n# Run these commands in the node-problem-detector directory.\n\n# Build in MINGW64 Window\nmake clean ENABLE_JOURNALD=0 build-binaries\n\n# Test in MINGW64 Window\nmake test\n\n# Run with containerd log monitoring enabled in Command Prompt. (Assumes containerd is installed.)\n%CD%\\output\\windows_amd64\\bin\\node-problem-detector.exe --logtostderr --enable-k8s-exporter=false --config.system-log-monitor=%CD%\\config\\windows-containerd-monitor-filelog.json --config.system-stats-monitor=config\\windows-system-stats-monitor.json\n\n# Configure NPD to run as a Windows Service\nsc.exe create NodeProblemDetector binpath= \"%CD%\\node-problem-detector.exe [FLAGS]\" start= demand \nsc.exe failure NodeProblemDetector reset= 0 actions= restart/10000\nsc.exe start NodeProblemDetector\n```\n\n## Try It Out\n\nYou can try node-problem-detector in a running cluster by injecting messages to the logs that node-problem-detector is watching. For example, Let's assume node-problem-detector is using [KernelMonitor](https://github.com/kubernetes/node-problem-detector/blob/master/config/kernel-monitor.json). On your workstation, run ```kubectl get events -w```. On the node, run ```sudo sh -c \"echo 'kernel: BUG: unable to handle kernel NULL pointer dereference at TESTING' >> /dev/kmsg\"```. Then you should see the ```KernelOops``` event.\n\nWhen adding new rules or developing node-problem-detector, it is probably easier to test it on the local workstation in the standalone mode. For the API server, an easy way is to use ```kubectl proxy``` to make a running cluster's API server available locally. You will get some errors because your local workstation is not recognized by the API server. But you should still be able to test your new rules regardless.\n\nFor example, to test [KernelMonitor](https://github.com/kubernetes/node-problem-detector/blob/master/config/kernel-monitor.json) rules:\n1. ```make``` (build node-problem-detector locally)\n2. ```kubectl proxy --port=8080``` (make a running cluster's API server available locally)\n3. Update [KernelMonitor](https://github.com/kubernetes/node-problem-detector/blob/master/config/kernel-monitor.json)'s ```logPath``` to your local kernel log directory. For example, on some Linux systems, it is ```/run/log/journal``` instead of ```/var/log/journal```.\n3. ```./bin/node-problem-detector --logtostderr --apiserver-override=http://127.0.0.1:8080?inClusterConfig=false --config.system-log-monitor=config/kernel-monitor.json --config.system-stats-monitor=config/system-stats-monitor.json --port=20256 --prometheus-port=20257``` (or point to any API server address:port and Prometheus port)\n4. ```sudo sh -c \"echo 'kernel: BUG: unable to handle kernel NULL pointer dereference at TESTING' >> /dev/kmsg\"```\n5. You can see ```KernelOops``` event in the node-problem-detector log.\n6. ```sudo sh -c \"echo 'kernel: INFO: task docker:20744 blocked for more than 120 seconds.' >> /dev/kmsg\"```\n7. You can see ```DockerHung``` event and condition in the node-problem-detector log.\n8. You can see ```DockerHung``` condition at [http://127.0.0.1:20256/conditions](http://127.0.0.1:20256/conditions).\n9. You can see disk-related system metrics in Prometheus format at [http://127.0.0.1:20257/metrics](http://127.0.0.1:20257/metrics).\n\n**Note**:\n- You can see more rule examples under [test/kernel_log_generator/problems](https://github.com/kubernetes/node-problem-detector/tree/master/test/kernel_log_generator/problems).\n- For [KernelMonitor](https://github.com/kubernetes/node-problem-detector/blob/master/config/kernel-monitor.json) message injection, all messages should have ```kernel: ``` prefix (also note there is a space after ```:```); or use [generator.sh](https://github.com/kubernetes/node-problem-detector/blob/master/test/kernel_log_generator/generator.sh).\n- To inject other logs into journald like systemd logs, use ```echo 'Some systemd message' | systemd-cat -t systemd```.\n\n## Dependency Management\n\nnode-problem-detector uses [go modules](https://github.com/golang/go/wiki/Modules)\nto manage dependencies. Therefore, building node-problem-detector requires\ngolang 1.11+. It still uses vendoring. See the\n[Kubernetes go modules KEP](https://github.com/kubernetes/enhancements/tree/master/keps/sig-architecture/917-go-modules#alternatives-to-vendoring-using-go-modules)\nfor the design decisions. To add a new dependency, update [go.mod](go.mod) and\nrun `go mod vendor`.\n\n# Remedy Systems\n\nA _remedy system_ is a process or processes designed to attempt to remedy problems\ndetected by the node-problem-detector. Remedy systems observe events and/or node\nconditions emitted by the node-problem-detector and take action to return the\nKubernetes cluster to a healthy state. The following remedy systems exist:\n\n* [**Draino**](https://github.com/planetlabs/draino) automatically drains Kubernetes\n  nodes based on labels and node conditions. Nodes that match _all_ of the supplied\n  labels and _any_ of the supplied node conditions will be prevented from accepting\n  new pods (aka 'cordoned') immediately, and\n  [drained](https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/)\n  after a configurable time. Draino can be used in conjunction with the\n  [Cluster Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler)\n  to automatically terminate drained nodes. Refer to\n  [this issue](https://github.com/kubernetes/node-problem-detector/issues/199)\n  for an example production use case for Draino.\n* [**Descheduler**](https://github.com/kubernetes-sigs/descheduler) strategy RemovePodsViolatingNodeTaints\n  evicts pods violating NoSchedule taints on nodes. The k8s scheduler's TaintNodesByCondition feature must\n  be enabled. The [Cluster Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler)\n  can be used to automatically terminate drained nodes.\n* [**mediK8S**](https://github.com/medik8s) is an umbrella project for automatic remediation\n  system build on [Node Health Check Operator (NHC)](https://github.com/medik8s/node-healthcheck-operator) that monitors\n  node conditions and delegates remediation to external remediators using the Remediation API.[Poison-Pill](https://github.com/medik8s/poison-pill)\n  is a remediator that will reboot the node and make sure all statefull workloads are rescheduled. NHC supports conditionally remediating if the cluster\n  has enough healthy capacity, or manually pausing any action to minimze cluster disruption.\n\n# Testing\n\nNPD is tested via unit tests, [NPD e2e tests](https://github.com/kubernetes/node-problem-detector/blob/master/test/e2e/README.md), Kubernetes e2e tests and Kubernetes nodes e2e tests. Prow handles the [pre-submit tests](https://github.com/kubernetes/test-infra/blob/master/config/jobs/kubernetes/node-problem-detector/node-problem-detector-presubmits.yaml) and [CI tests](https://github.com/kubernetes/test-infra/blob/master/config/jobs/kubernetes/node-problem-detector/node-problem-detector-ci.yaml).\n\nCI test results can be found below:\n1. [Unit tests](https://testgrid.k8s.io/sig-node-node-problem-detector#ci-npd-test)\n2. [NPD e2e tests](https://testgrid.k8s.io/sig-node-node-problem-detector#ci-npd-e2e-test)\n3. [Kubernetes e2e tests](https://testgrid.k8s.io/sig-node-node-problem-detector#ci-npd-e2e-kubernetes-gce-gci)\n4. [Kubernetes nodes e2e tests](https://testgrid.k8s.io/sig-node-node-problem-detector#ci-npd-e2e-node)\n\n## Running tests\n\nUnit tests are run via `make test`.\n\nSee [NPD e2e test documentation](https://github.com/kubernetes/node-problem-detector/blob/master/test/e2e/README.md) for how to set up and run NPD e2e tests.\n\n## Problem Maker\n\n[Problem maker](https://github.com/kubernetes/node-problem-detector/blob/master/test/e2e/problemmaker/README.md) is a program used in NPD e2e tests to generate/simulate node problems. It is ONLY intended to be used by NPD e2e tests. Please do NOT run it on your workstation, as it could cause real node problems.\n\n# Docs\n\n* [Custom plugin monitor](docs/custom_plugin_monitor.md)\n\n# Links\n\n* [Design Doc](https://docs.google.com/document/d/1cs1kqLziG-Ww145yN6vvlKguPbQQ0psrSBnEqpy0pzE/edit?usp=sharing)\n* [Slides](https://docs.google.com/presentation/d/1bkJibjwWXy8YnB5fna6p-Ltiy-N5p01zUsA22wCNkXA/edit?usp=sharing)\n* [Plugin Interface Proposal](https://docs.google.com/document/d/1jK_5YloSYtboj-DtfjmYKxfNnUxCAvohLnsH5aGCAYQ/edit#)\n* [Addon Manifest](https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/node-problem-detector)\n* [Metrics Mode Proposal](https://docs.google.com/document/d/1SeaUz6kBavI283Dq8GBpoEUDrHA2a795xtw0OvjM568/edit)\n", "release_dates": ["2024-02-04T04:07:28Z", "2023-08-26T16:25:13Z", "2023-03-23T00:28:36Z", "2022-09-09T13:51:13Z", "2022-08-02T03:26:46Z", "2021-08-31T22:40:02Z", "2021-06-25T20:39:12Z", "2021-05-15T01:21:40Z", "2021-02-19T01:15:14Z", "2021-01-22T21:29:42Z", "2020-11-19T00:26:35Z", "2020-09-01T05:10:57Z", "2020-07-30T18:08:33Z", "2020-05-28T17:04:22Z", "2020-02-26T00:24:43Z", "2019-10-31T00:10:41Z", "2019-08-27T18:56:33Z", "2019-08-13T18:52:42Z", "2019-07-26T00:05:06Z", "2019-07-24T21:12:32Z", "2019-06-13T20:59:27Z", "2019-04-05T17:24:18Z", "2019-01-07T19:27:15Z", "2018-11-29T00:36:25Z", "2018-11-27T21:48:11Z", "2018-06-22T23:15:17Z", "2017-06-21T23:01:04Z", "2017-06-01T00:24:38Z", "2017-03-15T21:01:57Z", "2017-03-02T01:11:25Z"]}, {"name": "org", "description": "Meta configuration for Kubernetes Github Org", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Github Organization\n\nThis repository contains the metadata [configuration](/config) for the Kubernetes Github\nOrganizations. The data here is consumed by the\n[peribolos](https://git.k8s.io/test-infra/prow/cmd/peribolos)\ntool to organization and team membership, as well as team creation and deletion.\n\nMembership in the Kubernetes project is governed by our\n[community guidelines](https://git.k8s.io/community/community-membership.md).\n\nThe application for membership in the Kubernetes organization can be made by opening an [issue](https://github.com/kubernetes/org/issues/new?assignees=&labels=area%2Fgithub-membership&template=membership.yml&title=REQUEST%3A+New+membership+for+%3Cyour-GH-handle%3E).\nHowever, if you are already part of the Kubernetes organization, you do not need to do this and can add yourself directly to the appropriate files.\nFor example, to also add yourself to the kubernetes-sigs organization, you can navigate to `/config/kubernetes-sigs/org.yaml` and add your GitHub username to the list of members (in alphabetical order); this works the same way for other organizations.\n\nRequirements\n\n* Add only one new member per commit (if you add two members separate it in two commits\n* Commit message format `Add <USERNAME> to <kubernetes, kubernetes-sigs, ...> org`. \n\nYou can use `make add-members WHO=username1,username2 REPOS=kubernetes-sigs,kubernetes` to add usernames\nto the config with the requirements listed above.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the\n[community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n- [#github-management](https://kubernetes.slack.com/messages/github-management) on slack\n- [Mailing List](https://groups.google.com/forum/#!forum/kubernetes-sig-contribex)\n\nTo report any sensitive information, please email the private github@kubernetes.io list.\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the\n[Kubernetes Code of Conduct](code-of-conduct.md).\n", "release_dates": []}, {"name": "perf-tests", "description": "Performance tests and benchmarks", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes perf-tests\n\n[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/perf-tests)](https://goreportcard.com/report/github.com/kubernetes/perf-tests)\n\nThis repo is dedicated for storing various Kubernetes-related performance test related tools. If you want to add your own load-test, benchmark, framework or other tool please contact with one of the Owners.\n\nBecause in general tools are independent and have their own ways of being configured or run, each subdirectory needs a separate README.md file with the description of its contents.\n\n## Repository setup\n\nTo run all verify* scripts before pushing to remote branch (useful for catching problems quickly) execute:\n\n```\ncp _hook/pre-push .git/hooks/pre-push\n```\n", "release_dates": []}, {"name": "pod-security-admission", "description": "Kubernetes Pod Security Standards implementation - https://github.com/kubernetes/enhancements/blob/master/keps/sig-auth/2579-psp-replacement/README.md", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Pod Security Admission\n\n<!-- TODO: Placeholder README. Update with more detail and repo contents once initial implementation is in place. -->\n\nThe **Pod Security Standards** are a set of best-practice profiles for running pods securely.\n\nThis repository contains the codified profile definitions, the implementation for the\n**PodSecurity** admission controller (library and webhook) that enforces the use of the standards,\nand testing resources for validating enforcement of the standards.\n\nSee https://github.com/kubernetes/enhancements/tree/master/keps/sig-auth/2579-psp-replacement for more details.\n\n## Community, discussion, contribution, and support\n\nThe Pod Security Standards are a sub-project of [SIG-Auth](https://github.com/kubernetes/community/tree/master/sig-auth).\n\nYou can reach the maintainers of this project at:\n\n- Slack: [#sig-auth](https://kubernetes.slack.com/messages/sig-auth)\n- Mailing List: [kubernetes-sig-auth](https://groups.google.com/forum/#!forum/kubernetes-sig-auth)\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n", "release_dates": []}, {"name": "publishing-bot", "description": "Code behind the robot to publish from staging to real repositories.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Publishing Bot\n\n[![sig-release-publishing-bot/build](https://testgrid.k8s.io/q/summary/sig-release-publishing-bot/build/tests_status?style=svg)](https://testgrid.k8s.io/sig-release-publishing-bot#build)\n[![](https://img.shields.io/uptimerobot/status/m779759348-04b1f4fd3bb5ce4a810670d2.svg?label=bot)](https://stats.uptimerobot.com/wm4Dyt8kY)\n[![](https://img.shields.io/uptimerobot/status/m779759340-0a6b2cb6fee352e75f58ba16.svg?label=last%20publishing%20run)](https://github.com/kubernetes/kubernetes/issues/56876)\n\n## Overview\n\nThe publishing bot publishes the code in `k8s.io/kubernetes/staging` to their own repositories. It guarantees that the master branches of the published repositories are compatible, i.e., if a user `go get` a published repository in a clean GOPATH, the repo is guaranteed to work.\n\nIt pulls the latest k8s.io/kubernetes changes and runs `git filter-branch` to distill the commits that affect a staging repo. Then it cherry-picks merged PRs with their feature branch commits to the target repo. It records the SHA1 of the last cherrypicked commits in `Kubernetes-sha: <sha>` lines in the commit messages.\n\nThe robot is also responsible to update the `go-mod` and the `vendor/` directory for the target repos.\n\n## Playbook\n\n### Publishing a new repo or a new branch\n\n* Adapt the rules in [config/kubernetes-rules-configmap.yaml](configs/kubernetes-rules-configmap.yaml)\n  * For Kubernetes, the configuration is located in the [kubernetes/kubernetes repository](https://github.com/kubernetes/kubernetes/blob/master/staging/publishing/rules.yaml)\n\n* For a new repo, add it to the repo list in [hack/repos.sh](hack/repos.sh)\n\n* [Test and deploy the changes](#testing-and-deploying-the-robot)\n\n### Updating rules\n\n#### Adapting rules for a new branch\n\nIf you're creating a new branch, you need to update the publishing-bot rules to reflect that. For Kubernetes, this means that you need to update the [`rules.yaml` file](https://github.com/kubernetes/kubernetes/blob/master/staging/publishing/rules.yaml) on the `master` branch.\n\nFor each repository, add a new branch to the `branches` stanza. If the branch is using the same Go version as the [default Go version](https://github.com/kubernetes/kubernetes/blob/489fb9bee3f626b3eeb120a5af89ad8c2b2f1c20/staging/publishing/rules.yaml#L10), you don't need to specify the Go version for the branch (otherwise you need to do that).\n\n#### Adapting rules for a Go update\n\nIf you're updating Go version for the master or release branches, you need to adapt the [`rules.yaml` file in kubernetes/kubernetes](https://github.com/kubernetes/kubernetes/blob/master/staging/publishing/rules.yaml) on the `master` branch.\n\n* If you're updating Go version for the master branch, you need to change the [default Go version](https://github.com/kubernetes/kubernetes/blob/489fb9bee3f626b3eeb120a5af89ad8c2b2f1c20/staging/publishing/rules.yaml#L10) to the new version.\n  * If release branches that depend on the default Go version use a different (e.g. old) Go version, you need to explicitly set Go version for those branches (e.g. [like here](https://github.com/kubernetes/kubernetes/blob/489fb9bee3f626b3eeb120a5af89ad8c2b2f1c20/staging/publishing/rules.yaml#L37))\n* If you're updating Go version for a previous release branch\n  * if it's the same version as the default Go version, you don't need to specify the Go version for that branch\n  * if it's **NOT** the same version as the default Go version, you need to explicitly specify the Go version for that branch (e.g. [like here](https://github.com/kubernetes/kubernetes/blob/489fb9bee3f626b3eeb120a5af89ad8c2b2f1c20/staging/publishing/rules.yaml#L37))\n    * Examples: https://github.com/kubernetes/kubernetes/pull/93998, https://github.com/kubernetes/kubernetes/pull/101232, https://github.com/kubernetes/kubernetes/pull/104226\n\n### Testing and deploying the robot\n\nCurrently we don't have tests for the bot. It relies on manual tests:\n\n* Fork the repos you are going the publish.\n* Run [hack/fetch-all-latest-and-push.sh](hack/fetch-all-latest-and-push.sh) from the bot root directory to update the branches of your repos. This will sync your forks with upstream. **CAUTION:** this might delete data in your forks.\n* Use [hack/create-repos.sh](hack/create-repos.sh) from the bot root directory to create any missing repos in the destination github org.\n\n* Create a config and a corresponding ConfigMap in [configs](configs),\n  - by copying [configs/example](configs/example) and [configs/example-configmap.yaml](configs/example-configmap.yaml),\n  - and by changing the Makefile constants in `configs/<yourconfig>`\n  - and the ConfigMap values in  `configs/<yourconfig>-configmap.yaml`.\n\n* Create a rule config and a corresponding ConfigMap in [configs](configs),\n  - by copying [configs/example-rules-configmap.yaml](configs/example-rules-configmap.yaml),\n  - and by changing the Makefile constants in `configs/<yourconfig>`\n  - and the ConfigMap values in  `configs/<yourconfig>-rules-configmap.yaml`.\n\n* Deploy the publishing bot by running make from the bot root directory, e.g.\n\n```shell\n$ make build-image push-image CONFIG=configs/<yourconfig>\n$ make run CONFIG=configs/<yourconfig> TOKEN=<github-token>\n```\n\n  for a fire-and-forget pod. Or use\n\n```shell\n$ make deploy CONFIG=configs/<yourconfig> TOKEN=<github-token>\n```\n\n  to run a ReplicaSet that publishes every 24h (you can change the `INTERVAL` config value for different intervals).\n\nThis will not push to your org, but runs in dry-run mode. To run with a push, add `DRYRUN=false` to your `make` command line.\n\n### Running in Production\n\n* Use one of the existing [configs](configs) and\n* launch `make deploy CONFIG=configs/kubernetes-nightly`\n\n**Caution:** Make sure that the bot github user CANNOT close arbitrary issues in the upstream repo. Otherwise, github will close, them triggered by `Fixes kubernetes/kubernetes#123` patterns in published commits.\n\n**Note:**: Details about running the publishing-bot for the Kubernetes project can be found in [production.md](production.md).\n\n\n### Update rules\n\nTo add new branch rules or update go version for configured destination repos, check [update-branch-rules](cmd/update-rules/README.md).\n\n## Contributing\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on how to contribute.\n\n## Known issues\n\n1. Testing: currently we rely on manual testing. We should set up CI for it.\n2. Automate release process (tracked at https://github.com/kubernetes/kubernetes/issues/49011): when kubernetes release, automatic update the configuration of the publishing robot. This probably means that the config must move into the Kubernetes repo, e.g. as a `.publishing.yaml` file.\n", "release_dates": []}, {"name": "registry.k8s.io", "description": "This project is the repo for registry.k8s.io, the production OCI registry service for Kubernetes' container image artifacts", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# registry.k8s.io\n\nThis project implements the backend for registry.k8s.io, Kubernetes's container\nimage registry.\n\nKnown user-facing issues will be pinned at the top of [our issue tracker][issues].\n\nFor details on the implementation see [cmd/archeio](./cmd/archeio/README.md)\n\nThe community deployment configs are documented at in the k8s.io repo with\nthe rest of the community infra deployments, but primarily \n[here][infra-configs].\n\nFor publishing to registry.k8s.io, refer to [the docs][publishing] at in k8s.io \nunder `registry.k8s.io/`.\n\n## Stability\n\nregistry.k8s.io is GA and we ask that all users migrate from k8s.gcr.io as\nsoon as possible.\n\nHowever, unequivocally: **DO NOT depend on the implementation details of this registry.**\n\n**Please note that there is NO uptime SLA as this is a free, volunteer managed\nservice**. We will however do our best to respond to issues and the system is\ndesigned to be reliable and low-maintenance. If you need higher uptime guarantees\nplease consider [mirroring] images to a location you control.\n\n**Other than `registry.k8s.io` serving an [OCI][distribution-spec] compliant registry:\nAPI endpoints, IP addresses, and backing services used \nare subject to change at _anytime_ as new resources become available or as otherwise\nnecessary.**\n\n**If you need to allow-list domains or IPs in your environment, we highly recommend\n[mirroring] images to a location you control instead.**\n\nThe Kubernetes project is currently sending traffic to GCP and AWS\nthanks to their donations but we hope to redirect traffic to more\nsponsors and their respective API endpoints in the future to keep the project\nsustainable.\n\nSee Also:\n- Pinned issues in our [our issue tracker][issues]\n- Our [debugging guide][debugging] for identifying and resolving or reporting issues\n- Our [mirroring guide][mirroring] for how to mirror and use mirrored Kubernetes images\n\n## Privacy\n\nThis project abides by the Linux Foundation privacy policy, as documented at\nhttps://registry.k8s.io/privacy\n\n## Background\n\nPreviously all of Kubernetes' image hosting has been out of gcr.io (\"Google Container Registry\").\n\nWe've incurred significant egress traffic costs from users on other cloud providers\nin particular in doing so, severely limiting our ability to use the \nGCP credits from Google for purposes other than hosting end-user downloads.\n\nWe're now moving to shift all traffic behind a community controlled domain, so\nwe can quickly implement cost-cutting measures like serving the bulk of the traffic\nfor AWS-users from AWS-local storage funded by Amazon, or potentially leveraging\nother providers in the future.\n\nFor additional context on why we did this and what we're changing about kubernetes images\nsee: https://kubernetes.io/blog/2022/11/28/registry-k8s-io-faster-cheaper-ga\n\nEssentially, this repo implements the backend sources for the steps outlined there.\n\nFor a talk with more details see: [\"Why We Moved the Kubernetes Image Registry\"](https://www.youtube.com/watch?v=9CdzisDQkjE)\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n- [Slack](http://slack.k8s.io/) in channel `#sig-k8s-infra`\n- [Mailing List](https://groups.google.com/forum/#!forum/kubernetes-sig-k8s-infra)\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n[owners]: https://git.k8s.io/community/contributors/guide/owners.md\n[Creative Commons 4.0]: https://git.k8s.io/website/LICENSE\n[distribution-spec]: https://github.com/opencontainers/distribution-spec\n[publishing]: https://git.k8s.io/k8s.io/registry.k8s.io#managing-kubernetes-container-registries\n[infra-configs]: https://github.com/kubernetes/k8s.io/tree/main/infra/gcp/terraform\n[mirroring]: ./docs/mirroring/README.md\n[debugging]: ./docs/debugging.md\n[issues]: https://github.com/kubernetes/registry.k8s.io/issues\n", "release_dates": []}, {"name": "release", "description": "Release infrastructure for Kubernetes and related components", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes Release Tooling\n\n[![PkgGoDev](https://pkg.go.dev/badge/k8s.io/release)](https://pkg.go.dev/k8s.io/release)\n[![Go Report Card](https://goreportcard.com/badge/k8s.io/release)](https://goreportcard.com/report/k8s.io/release)\n[![Slack](https://img.shields.io/badge/Slack-%23release--management-blueviolet)](https://kubernetes.slack.com/archives/C2C40FMNF)\n\nThis repo contains the tooling and infrastructure configurations for creating\nKubernetes releases from the [kubernetes/kubernetes] main repository.\n\nThere are several scripts and helpers in this repository a Release Manager will\nfind useful when managing all kinds of releases (alpha, beta, official, rc)\nacross branches.\n\nGolang-based tools can be built via the `compile-release-tools` script.\nIndividual tools can be installed via `go install k8s.io/release/cmd/$TOOL@latest`.\n\n- [Release Creation](#release-creation)\n- [Release Management](#release-management)\n  - [`krel`](#krel)\n  - [`schedule-builder`](#schedule-builder)\n- [Artifact Management](#artifact-management)\n  - [`kpromo`](#kpromo)\n- [End User](#end-user)\n  - [`bom`](#bom)\n  - [`release-notes`](#release-notes)\n  - [`gcbuilder`](#gcbuilder)\n  - [`publish-release`](#publish-release)\n- [Legacy](#legacy)\n  - [`push-build.sh`](#push-buildsh)\n- [Contributing](#contributing)\n\n**Each of the headings below links to a tool's location.**\n\n## Release Creation\n\nIf you create a new release for this repository, then the\n[goreleaser](https://github.com/goreleaser/goreleaser) GitHub action will attach\nall available binary artifacts to it automatically. To publish those artifacts\nto our [`k8s-artifacts-sig-release` GCS bucket](https://console.cloud.google.com/storage/browser/k8s-artifacts-sig-release),\nrun the following [kpromo](https://github.com/kubernetes-sigs/promo-tools)\ncommand for the new `$TAG`:\n\n```bash\nkpromo gh \\\n    --org kubernetes \\\n    --repo release \\\n    --bucket k8s-artifacts-sig-release \\\n    --tags $TAG\n```\n\nThe release notes can be generated by using the\n[release-notes](cmd/release-notes) tool from this repository, which is also\navailable as binary artifact:\n\n```bash\nrelease-notes \\\n    --org kubernetes \\\n    --repo release \\\n    --required-author \"\" \\\n    --start-rev $PREVIOUS_TAG \\\n    --end-rev $TAG \\\n    --output release-notes.md\n```\n\n## Release Management\n\n### [`krel`](/cmd/krel)\n\n**K**ubernetes **rel**ease Toolbox: tooling for releasing Kubernetes\n\nStatus: Feature Complete\n\nAudience: [Release Managers][release-managers]\n\nDetails: [Documentation](/docs/krel/README.md)\n\n### [`schedule-builder`](/cmd/schedule-builder)\n\nGenerate a Markdown schedule for Kubernetes releases.\n\nStatus: In Progress\n\nAudience: [Release Managers][release-managers]\n\nDetails: [Documentation](/cmd/schedule-builder/README.md)\n\n## Artifact Management\n\n### [`kpromo`](https://sigs.k8s.io/promo-tools/cmd/kpromo)\n\n**K**ubernetes artifact **promo**tion tooling: tooling for promoting artifacts\n\nStatus: In Progress\n\nAudience: [Release Managers][release-managers] and subproject maintainers\nresponsible for promoting file or container artifacts\n\nDetails: [Documentation](https://sigs.k8s.io/promo-tools/README.md#kpromo)\n\n## End User\n\n### [`bom`](https://sigs.k8s.io/bom)\n\nGenerate SPDX-compliant Bills of Materials for a software\nproject. Supports reading directories, images, files and more.\n\nDetails: [Documentation](https://sigs.k8s.io/bom/README.md)\n\n### [`release-notes`](/cmd/release-notes)\n\nScrape GitHub pull requests for release notes.\n\nStatus: Feature Complete\n\nDetails: [Documentation](/cmd/release-notes/README.md)\n\n### [`gcbuilder`](/cmd/gcbuilder)\n\nGeneral purpose tool for triggering Google Cloud Build (GCB) runs with\nsubstitutions.\n\nStatus: Unused\n\nDetails: [Documentation](/cmd/gcbuilder/README.md)\n\n### [`publish-release`](/cmd/publish-release)\n\nA tool to announce software releases. Currently supports updating the\nrelease page on GitHub based on templates and updating release artifacts.\n\nDetails: [Documentation](cmd/publish-release/README.md)\n\n## Legacy\n\n### [`push-build.sh`](push-build.sh)\n\nPush a CI build of Kubernetes to Google Cloud Storage (GCS).\n\nStatus: Deprecated (but still in use)\n\nAudience: [Release Managers][release-managers], Prowjobs\n\n## Contributing\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on how to contribute.\n\n[kubernetes/kubernetes]: https://git.k8s.io/kubernetes\n[Branch Manager Handbook]: https://git.k8s.io/sig-release/release-engineering/role-handbooks/branch-manager.md\n[release-managers]: https://git.k8s.io/website/content/en/releases/release-managers.md\n", "release_dates": ["2024-02-19T12:46:12Z", "2023-11-15T09:24:33Z", "2023-10-11T10:36:37Z", "2023-10-09T07:50:36Z", "2023-10-05T11:17:25Z", "2023-10-05T09:42:39Z", "2023-04-14T07:12:01Z", "2023-01-19T15:11:40Z", "2022-06-13T12:41:25Z", "2022-02-15T23:43:38Z", "2021-11-16T16:11:20Z", "2021-09-13T22:16:53Z", "2021-08-09T14:15:46Z", "2021-06-01T00:39:31Z", "2021-03-31T10:35:55Z", "2021-01-22T18:06:19Z", "2020-11-27T08:58:25Z", "2020-10-21T20:47:46Z", "2020-10-02T10:08:19Z", "2020-09-24T06:39:26Z", "2020-08-10T15:23:33Z", "2020-06-23T21:11:47Z", "2020-06-07T23:37:34Z", "2020-06-02T04:17:55Z", "2020-05-19T19:26:34Z", "2020-05-13T06:12:51Z", "2020-05-07T06:29:56Z", "2020-03-24T14:11:47Z", "2020-03-02T18:22:17Z"]}, {"name": "repo-infra", "description": "Kubernetes repository infrastucture tools", "language": "Starlark", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kubernetes repository infrastructure\n[![Build Status](https://travis-ci.org/kubernetes/repo-infra.svg?branch=master)](https://travis-ci.org/kubernetes/repo-infra)  [![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/repo-infra)](https://goreportcard.com/report/github.com/kubernetes/repo-infra)\n\nThis repository contains repository infrastructure tools for use in\n`kubernetes` and `kubernetes-incubator` repositories.  Examples:\n\n- Boilerplate verification\n- Go source code quality verification\n- Golang build infrastructure\n\n---\n\n## Using this repository\n\nThis repository can be used via some golang \"vendoring\" mechanism \n(such as glide), or it can be used via\n[git subtree](http://git.kernel.org/cgit/git/git.git/plain/contrib/subtree/git-subtree.txt).\n\n### Using \"vendoring\"\n\nThe exact mechanism to pull in this repository will vary depending on\nthe tool you use. However, unless you end up having this repository\nat the root of your project's repository you will probably need to \nmake sure you use the `--rootdir` command line parameter to let the\n`verify-boilerplate.sh` know its location, eg:\n\n    verify-boilerplate.sh --rootdir=/home/myrepo\n\n### Using `git subtree`\n\nWhen using the git subtree mechanism, this repository should be placed in the \ntop level of your project.\n\nTo add `repo-infra` to your repository, use the following commands from the \nroot directory of **your** repository.\n\nFirst, add a git remote for the `repo-infra` repository:\n\n```\n$ git remote add repo-infra git://github.com/kubernetes/repo-infra\n```\n\nThis is not strictly necessary, but reduces the typing required for subsequent\ncommands.\n\nNext, use `git subtree add` to create a new subtree in the `repo-infra`\ndirectory within your project:\n\n```\n$ git subtree add -P repo-infra repo-infra master --squash\n```\n\nAfter this command, you will have:\n\n1.  A `repo-infra` directory in your project containing the content of **this**\n    project\n2.  2 new commits in the active branch:\n    1.  A commit that squashes the git history of the `repo-infra` project\n    2.  A merge commit whose ancestors are:\n        1.  The `HEAD` of the branch prior to when you ran `git subtree add`\n        2.  The commit containing the squashed `repo-infra` commits\n\n### Contributing\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on how to contribute.\n", "release_dates": ["2022-01-28T09:02:11Z", "2022-01-26T15:18:34Z", "2021-11-21T15:27:23Z", "2021-08-07T11:20:58Z", "2021-07-14T09:56:37Z", "2021-06-10T08:44:27Z", "2021-05-07T16:49:51Z", "2021-04-15T00:57:21Z", "2021-04-10T00:05:22Z", "2021-03-18T16:09:47Z", "2021-02-26T22:27:17Z", "2021-02-15T08:42:11Z", "2021-01-07T21:49:27Z", "2020-11-13T10:54:11Z", "2020-10-21T21:36:25Z", "2020-09-10T13:11:48Z", "2020-09-02T23:43:33Z", "2020-08-12T16:42:50Z", "2020-08-09T04:38:40Z", "2020-07-24T22:55:26Z", "2020-07-23T23:55:28Z", "2020-07-17T18:22:48Z", "2020-07-15T03:43:39Z", "2020-06-22T21:25:29Z", "2020-05-20T21:01:57Z", "2020-04-17T23:39:31Z", "2020-03-24T18:11:07Z", "2020-02-12T00:17:49Z", "2020-01-17T00:55:10Z", "2019-10-21T00:06:08Z"]}, {"name": "sample-apiserver", "description": "Reference implementation of an apiserver for a custom Kubernetes API.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# sample-apiserver\n\nDemonstration of how to use the k8s.io/apiserver library to build a functional API server.\n\n**Note:** go-get or vendor this package as `k8s.io/sample-apiserver`.\n\n## Purpose\n\nYou may use this code if you want to build an Extension API Server to use with API Aggregation, or to build a stand-alone Kubernetes-style API server.\n\nHowever, consider two other options:\n  * **CRDs**:  if you just want to add a resource to your kubernetes cluster, then consider using Custom Resource Definition a.k.a CRDs.  They require less coding and rebasing.  Read about the differences between Custom Resource Definitions vs Extension API Servers [here](https://kubernetes.io/docs/concepts/api-extension/custom-resources).\n  * **Apiserver-builder**: If you want to build an Extension API server, consider using [apiserver-builder](https://github.com/kubernetes-incubator/apiserver-builder) instead of this repo.  The Apiserver-builder is a complete framework for generating the apiserver, client libraries, and the installation program.\n\nIf you do decide to use this repository, then the recommended pattern is to fork this repository, modify it to add your types, and then periodically rebase your changes on top of this repo, to pick up improvements and bug fixes to the apiserver.\n\n\n## Compatibility\n\nHEAD of this repo will match HEAD of k8s.io/apiserver, k8s.io/apimachinery, and k8s.io/client-go.\n\n## Where does it come from?\n\n`sample-apiserver` is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/sample-apiserver.\nCode changes are made in that location, merged into `k8s.io/kubernetes` and later synced here.\n\n## Fetch sample-apiserver and its dependencies\n\nIssue the following commands --- starting in whatever working directory you\nlike.\n\n```sh\ngit clone https://github.com/kubernetes/sample-apiserver\ncd sample-apiserver\n```\n\nNote, however, that if you intend to\n[generate code](#changes-to-the-types) then you will also need the\ncode-generator repo to exist in an old-style location.  One easy way\nto do this is to use the command `go mod vendor` to create and\npopulate the `vendor` directory.\n\n### A Note on kubernetes/kubernetes\n\nIf you are developing Kubernetes according to\nhttps://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md\nthen you already have a copy of this demo in\n`kubernetes/staging/src/k8s.io/sample-apiserver` and its dependencies\n--- including the code generator --- are in usable locations.\n\n\n## Normal Build and Deploy\n\n### Changes to the Types\n\nIf you change the API object type definitions in any of the\n`pkg/apis/.../types.go` files then you will need to update the files\ngenerated from the type definitions.  To do this, first\n[create the vendor directory if necessary](#when-using-go-111-modules)\nand then invoke `hack/update-codegen.sh` with `sample-apiserver` as\nyour current working directory; the script takes no arguments.\n\n### Authentication plugins\n\nThe normal build supports only a very spare selection of\nauthentication methods.  There is a much larger set available in\nhttps://github.com/kubernetes/client-go/tree/master/plugin/pkg/client/auth\n.  If you want your server to support one of those, such as `oidc`,\nthen add an import of the appropriate package to\n`sample-apiserver/main.go`.  Here is an example:\n\n``` go\nimport _ \"k8s.io/client-go/plugin/pkg/client/auth/oidc\"\n```\n\nAlternatively you could add support for all of them, with an import\nlike this:\n\n``` go\nimport _ \"k8s.io/client-go/plugin/pkg/client/auth\"\n```\n\n### Build the Binary\n\nWith `sample-apiserver` as your current working directory, issue the\nfollowing command:\n\n```\nCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -a -o artifacts/simple-image/kube-sample-apiserver\n```\n\n### Build the Container Image\n\nWith `sample-apiserver` as your current working directory, issue the\nfollowing commands with `MYPREFIX` and `MYTAG` replaced by something\nsuitable.\n\n```\ndocker build -t MYPREFIX/kube-sample-apiserver:MYTAG ./artifacts/simple-image\ndocker push MYPREFIX/kube-sample-apiserver:MYTAG\n```\n\n### Deploy into a Kubernetes Cluster\n\nEdit `artifacts/example/deployment.yaml`, updating the pod template's image\nreference to match what you pushed and setting the `imagePullPolicy`\nto something suitable.  Then call:\n\n```\nkubectl apply -f artifacts/example\n```\n\n## Running it stand-alone\n\nDuring development it is helpful to run sample-apiserver stand-alone, i.e. without\na Kubernetes API server for authn/authz and without aggregation. This is possible, but needs\na couple of flags, keys and certs as described below. You will still need some kubeconfig,\ne.g. `~/.kube/config`, but the Kubernetes cluster is not used for authn/z. A minikube or\nhack/local-up-cluster.sh cluster will work.\n\nInstead of trusting the aggregator inside kube-apiserver, the described setup uses local\nclient certificate based X.509 authentication and authorization. This means that the client\ncertificate is trusted by a CA and the passed certificate contains the group membership\nto the `system:masters` group. As we disable delegated authorization with `--authorization-skip-lookup`,\nonly this superuser group is authorized.\n\n1. First we need a CA to later sign the client certificate:\n\n   ``` shell\n   openssl req -nodes -new -x509 -keyout ca.key -out ca.crt\n   ```\n\n2. Then we create a client cert signed by this CA for the user `development` in the superuser group\n   `system:masters`:\n\n   ``` shell\n   openssl req -out client.csr -new -newkey rsa:4096 -nodes -keyout client.key -subj \"/CN=development/O=system:masters\"\n   openssl x509 -req -days 365 -in client.csr -CA ca.crt -CAkey ca.key -set_serial 01 -sha256 -out client.crt\n   ```\n\n3. As curl requires client certificates in p12 format with password, do the conversion:\n\n   ``` shell\n   openssl pkcs12 -export -in ./client.crt -inkey ./client.key -out client.p12 -passout pass:password\n   ```\n\n4. With these keys and certs in-place, we start the server:\n\n   ``` shell\n   etcd &\n   sample-apiserver --secure-port 8443 --etcd-servers http://127.0.0.1:2379 --v=7 \\\n      --client-ca-file ca.crt \\\n      --kubeconfig ~/.kube/config \\\n      --authentication-kubeconfig ~/.kube/config \\\n      --authorization-kubeconfig ~/.kube/config\n   ```\n\n   The first kubeconfig is used for the shared informers to access\n   Kubernetes resources. The second kubeconfig passed to\n   `--authentication-kubeconfig` is used to satisfy the delegated\n   authenticator. The third kubeconfig passed to\n   `--authorized-kubeconfig` is used to satisfy the delegated\n   authorizer. Neither the authenticator, nor the authorizer will\n   actually be used: due to `--client-ca-file`, our development X.509\n   certificate is accepted and authenticates us as `system:masters`\n   member. `system:masters` is the superuser group such that delegated\n   authorization is skipped.\n\n5. Use curl to access the server using the client certificate in p12 format for authentication:\n\n   ``` shell\n   curl -fv -k --cert-type P12 --cert client.p12:password \\\n      https://localhost:8443/apis/wardle.example.com/v1alpha1/namespaces/default/flunders\n   ```\n\n   Or use wget:\n   ``` shell\n   wget -O- --no-check-certificate \\\n      --certificate client.crt --private-key client.key \\\n      https://localhost:8443/apis/wardle.example.com/v1alpha1/namespaces/default/flunders\n   ```\n\n   Note: Recent OSX versions broke client certs with curl. On Mac try `brew install httpie` and then:\n\n   ``` shell\n   http --verify=no --cert client.crt --cert-key client.key \\\n      https://localhost:8443/apis/wardle.example.com/v1alpha1/namespaces/default/flunders\n   ```\n\n", "release_dates": []}, {"name": "sample-cli-plugin", "description": "Sample kubectl plugin", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# sample-cli-plugin\n\nThis repository implements a single kubectl plugin for switching the namespace\nthat the current KUBECONFIG context points to. In order to remain as indestructive\nas possible, no existing contexts are modified.\n\n**Note:** go-get or vendor this package as `k8s.io/sample-cli-plugin`.\n\nThis particular example demonstrates how to perform basic operations such as:\n\n* How to create a new custom command that follows kubectl patterns\n* How to obtain a user's KUBECONFIG settings and modify them\n* How to make general use of the provided \"cli-runtime\" set of helpers for kubectl and third-party plugins\n\nIt makes use of the genericclioptions in [k8s.io/cli-runtime](https://github.com/kubernetes/cli-runtime)\nto generate a set of configuration flags which are in turn used to generate a raw representation of\nthe user's KUBECONFIG, as well as to obtain configuration which can be used with RESTClients when sending\nrequests to a kubernetes api server.\n\n## Details\n\nThe sample cli plugin uses the [client-go library](https://github.com/kubernetes/client-go/tree/master/tools/clientcmd) to patch an existing KUBECONFIG file in a user's environment in order to update context information to point the client to a new or existing namespace.\n\nIn order to be as non-destructive as possible, no existing contexts are modified in any way. Rather, the current context is examined, and matched against existing contexts to find a context containing the same \"AuthInfo\" and \"Cluster\" information, but with the newly desired namespace requested by the user.\n\n## Purpose\n\nThis is an example of how to build a kubectl plugin using the same set of tools and helpers available to kubectl.\n\n## Running\n\n```sh\n# assumes you have a working KUBECONFIG\n$ go build cmd/kubectl-ns.go\n# place the built binary somewhere in your PATH\n$ cp ./kubectl-ns /usr/local/bin\n\n# you can now begin using this plugin as a regular kubectl command:\n# update your configuration to point to \"new-namespace\"\n$ kubectl ns new-namespace\n# any kubectl commands you perform from now on will use \"new-namespace\"\n$ kubectl get pod\nNAME                READY     STATUS    RESTARTS   AGE\nnew-namespace-pod   1/1       Running   0          1h\n\n# list all of the namespace in use by contexts in your KUBECONFIG\n$ kubectl ns --list\n\n# show the namespace that the currently set context in your KUBECONFIG points to\n$ kubectl ns\n```\n\n## Use Cases\n\nThis plugin can be used as a developer tool, in order to quickly view or change the current namespace\nthat kubectl points to.\n\nIt can also be used as a means of showcasing usage of the cli-runtime set of utilities to aid in\nthird-party plugin development.\n\n## Shell completion\n\nThis plugin supports shell completion when used through kubectl.  To enable shell completion for the plugin\nyou must copy the file `./kubectl_complete-ns` somewhere on `$PATH` and give it executable permissions.\n\nThe `./kubectl_complete-ns` script shows a hybrid approach to providing completions:\n1. it uses the builtin `__complete` command provided by [Cobra](https://github.com/spf13/cobra) for flags\n1. it calls `kubectl` to obtain the list of namespaces to complete arguments (note that a more elegant approach would be to have the `kubectl-ns` program itself provide completion of arguments by implementing Cobra's `ValidArgsFunction` to fetch the list of namespaces, but it would then be a less varied example)\n\nOne can then do things like:\n```\n$ kubectl ns <TAB>\ndefault          kube-node-lease  kube-public      kube-system\n\n$ kubectl ns --<TAB>\n--as                        -- Username to impersonate for the operation. User could be a regular user or a service account in a namespace.\n--as-group                  -- Group to impersonate for the operation, this flag can be repeated to specify multiple groups.\n--as-uid                    -- UID to impersonate for the operation.\n--cache-dir                 -- Default cache directory\n[...]\n```\n\nNote: kubectl v1.26 or higher is required for shell completion to work for plugins.\n## Cleanup\n\nYou can \"uninstall\" this plugin from kubectl by simply removing it from your PATH:\n\n    $ rm /usr/local/bin/kubectl-ns\n\n## Compatibility\n\nHEAD of this repository will match HEAD of k8s.io/apimachinery and\nk8s.io/client-go.\n\n## Where does it come from?\n\n`sample-cli-plugin` is synced from\nhttps://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/sample-cli-plugin.\nCode changes are made in that location, merged into k8s.io/kubernetes and\nlater synced here.\n\n", "release_dates": []}, {"name": "sample-controller", "description": "Repository for sample controller. Complements sample-apiserver", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# sample-controller\n\nThis repository implements a simple controller for watching Foo resources as\ndefined with a CustomResourceDefinition (CRD).\n\n**Note:** go-get or vendor this package as `k8s.io/sample-controller`.\n\nThis particular example demonstrates how to perform basic operations such as:\n\n* How to register a new custom resource (custom resource type) of type `Foo` using a CustomResourceDefinition.\n* How to create/get/list instances of your new resource type `Foo`.\n* How to setup a controller on resource handling create/update/delete events.\n\nIt makes use of the generators in [k8s.io/code-generator](https://github.com/kubernetes/code-generator)\nto generate a typed client, informers, listers and deep-copy functions. You can\ndo this yourself using the `./hack/update-codegen.sh` script.\n\nThe `update-codegen` script will automatically generate the following files &\ndirectories:\n\n* `pkg/apis/samplecontroller/v1alpha1/zz_generated.deepcopy.go`\n* `pkg/generated/`\n\nChanges should not be made to these files manually, and when creating your own\ncontroller based off of this implementation you should not copy these files and\ninstead run the `update-codegen` script to generate your own.\n\n## Details\n\nThe sample controller uses [client-go library](https://github.com/kubernetes/client-go/tree/master/tools/cache) extensively.\nThe details of interaction points of the sample controller with various mechanisms from this library are\nexplained [here](docs/controller-client-go.md).\n\n## Fetch sample-controller and its dependencies\n\nIssue the following commands --- starting in whatever working directory you\nlike.\n\n```sh\ngit clone https://github.com/kubernetes/sample-controller\ncd sample-controller\n```\n\nNote, however, that if you intend to\ngenerate code then you will also need the\ncode-generator repo to exist in an old-style location.  One easy way\nto do this is to use the command `go mod vendor` to create and\npopulate the `vendor` directory.\n\n### A Note on kubernetes/kubernetes\n\nIf you are developing Kubernetes according to\nhttps://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md\nthen you already have a copy of this demo in\n`kubernetes/staging/src/k8s.io/sample-controller` and its dependencies\n--- including the code generator --- are in usable locations\n(valid for all Go versions).\n\n## Purpose\n\nThis is an example of how to build a kube-like controller with a single type.\n\n## Running\n\n**Prerequisite**: Since the sample-controller uses `apps/v1` deployments, the Kubernetes cluster version should be greater than 1.9.\n\n```sh\n# assumes you have a working kubeconfig, not required if operating in-cluster\ngo build -o sample-controller .\n./sample-controller -kubeconfig=$HOME/.kube/config\n\n# create a CustomResourceDefinition\nkubectl create -f artifacts/examples/crd-status-subresource.yaml\n\n# create a custom resource of type Foo\nkubectl create -f artifacts/examples/example-foo.yaml\n\n# check deployments created through the custom resource\nkubectl get deployments\n```\n\n## Use Cases\n\nCustomResourceDefinitions can be used to implement custom resource types for your Kubernetes cluster.\nThese act like most other Resources in Kubernetes, and may be `kubectl apply`'d, etc.\n\nSome example use cases:\n\n* Provisioning/Management of external datastores/databases (eg. CloudSQL/RDS instances)\n* Higher level abstractions around Kubernetes primitives (eg. a single Resource to define an etcd cluster, backed by a Service and a ReplicationController)\n\n## Defining types\n\nEach instance of your custom resource has an attached Spec, which should be defined via a `struct{}` to provide data format validation.\nIn practice, this Spec is arbitrary key-value data that specifies the configuration/behavior of your Resource.\n\nFor example, if you were implementing a custom resource for a Database, you might provide a DatabaseSpec like the following:\n\n``` go\ntype DatabaseSpec struct {\n\tDatabases []string `json:\"databases\"`\n\tUsers     []User   `json:\"users\"`\n\tVersion   string   `json:\"version\"`\n}\n\ntype User struct {\n\tName     string `json:\"name\"`\n\tPassword string `json:\"password\"`\n}\n```\n\nNote, the JSON tag `json:` is required on all user facing fields within your type. Typically API types contain only user facing fields. When the JSON tag is omitted from the field, Kubernetes generators consider the field to be internal and will not expose the field in their generated external output. For example, this means that the field would not be included in a generated CRD schema.\n\n## Validation\n\nTo validate custom resources, use the [`CustomResourceValidation`](https://kubernetes.io/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/#validation) feature. Validation in the form of a [structured schema](https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#specifying-a-structural-schema) is mandatory to be provided for `apiextensions.k8s.io/v1`.\n\n### Example\n\nThe schema in [`crd.yaml`](./artifacts/examples/crd.yaml) applies the following validation on the custom resource:\n`spec.replicas` must be an integer and must have a minimum value of 1 and a maximum value of 10.\n\n## Subresources\n\nCustom Resources support `/status` and `/scale` [subresources](https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/#subresources). The `CustomResourceSubresources` feature is in GA from v1.16.\n\n### Example\n\nThe CRD in [`crd-status-subresource.yaml`](./artifacts/examples/crd-status-subresource.yaml) enables the `/status` subresource for custom resources.\nThis means that [`UpdateStatus`](./controller.go) can be used by the controller to update only the status part of the custom resource.\n\nTo understand why only the status part of the custom resource should be updated, please refer to the [Kubernetes API conventions](https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status).\n\nIn the above steps, use `crd-status-subresource.yaml` to create the CRD:\n\n```sh\n# create a CustomResourceDefinition supporting the status subresource\nkubectl create -f artifacts/examples/crd-status-subresource.yaml\n```\n\n## A Note on the API version\nThe [group](https://kubernetes.io/docs/reference/using-api/#api-groups) version of the custom resource in `crd.yaml` is `v1alpha`, this can be evolved to a stable API version, `v1`, using [CRD Versioning](https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/).\n\n## Cleanup\n\nYou can clean up the created CustomResourceDefinition with:\n```sh\nkubectl delete crd foos.samplecontroller.k8s.io\n```\n\n## Compatibility\n\nHEAD of this repository will match HEAD of k8s.io/apimachinery and\nk8s.io/client-go.\n\n## Where does it come from?\n\n`sample-controller` is synced from\nhttps://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/sample-controller.\nCode changes are made in that location, merged into k8s.io/kubernetes and\nlater synced here.\n\n", "release_dates": []}, {"name": "sig-release", "description": "Repo for SIG release", "language": "Shell", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# SIG Release\n\n## Charter\n\nThe [charter] defines the scope and governance of the Release Special Interest Group.\n\n## Join us!\n\nIf you are new to the Kubernetes community and would like to start contributing, you can check out the [\"Getting Started\"](https://www.kubernetes.dev/docs/guide/) guide for Kubernetes contributors. Below are some more links specifically to sig-release to get in touch with us.\n\n- [Slack](https://kubernetes.slack.com/messages/sig-release)\n- [Mailing list](https://groups.google.com/forum/#!forum/kubernetes-sig-release)\n- [Open Issues / PRs](https://github.com/search?q=org%3Akubernetes+org%3Akubernetes-client+org%3Akubernetes-csi+org%3Akubernetes-incubator+org%3Akubernetes-retired+org%3Akubernetes-sigs+is%3Aopen+label%3Asig%2Frelease)\n- [Meeting agenda and notes](https://docs.google.com/document/d/1Fu6HxXQu8wl6TwloGUEOXVzZ1rwZ72IAhglnaAMCPqA/edit)\n\n## Roadmap and Vision\n\nSIG Release maintains their own [Roadmap and Vision in a dedicated document](roadmap.md).\n\n## Release Team\n\nSeveral of the responsibilities of SIG Release are discharged by the Release Team, a subproject of SIG Release. Explicit details on each of the roles can be found in the [Release Team subproject directory][rt-directory].\n\n\n[charter]: https://git.k8s.io/community/sig-release/charter.md\n[rt-directory]: /release-team/README.md\n\n## Processes\n\nThe following high-level descriptions of SIG Release processes should provide a\ngeneral overview about the work we're doing:\n\n- [Release Notes](/release-engineering/release-notes.md)\n- [Versioning](/release-engineering/versioning.md)\n", "release_dates": []}, {"name": "sig-security", "description": "Process documentation, non-code deliverables, and miscellaneous artifacts of Kubernetes SIG Security", "language": "Python", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Security Special Interest Group\n\nCovers horizontal security initiatives for the Kubernetes project, including regular security audits, the vulnerability management process, cross-cutting security documentation, and security community management.\n\nThe [charter](https://github.com/kubernetes/community/blob/master/sig-security/charter.md) defines the scope and governance of the Security Special Interest Group.\n\n## Meetings\n*Joining the [mailing list](https://groups.google.com/forum/#!forum/kubernetes-sig-security) for the group will typically add invites for the following meetings to your calendar.*\n* Regular SIG Meeting: [Thursdays at 9:00 PT (Pacific Time)](https://zoom.us/j/9934z1184192?pwd=L25Tc0ZOL3FqU09KNERlTU12dFhTQT09) (biweekly). [Convert to your timezone](http://www.thetimezoneconverter.com/?t=9:00&tz=PT%20%28Pacific%20Time%29).\n  * [Meeting notes and Agenda](https://docs.google.com/document/d/1GgmmNYN88IZ2v2NBiO3gdU8Riomm0upge_XNVxEYXp0/edit?usp=sharing).\n  * [Meeting recordings](https://www.youtube.com/playlist?list=PL69nYSiGNLP1mXOLAc9ti0oX8s_ookQCi).\n\n## Leadership\n\n### Chairs\nThe Chairs of the SIG run operations and processes governing the SIG.\n\n* Ian Coldwater (**[@IanColdwater](https://github.com/IanColdwater)**), Twilio\n* Tabitha Sable (**[@tabbysable](https://github.com/tabbysable)**), Datadog\n\n## Contact\n- Slack: [#sig-security](https://kubernetes.slack.com/messages/sig-security)\n- [Mailing list](https://groups.google.com/forum/#!forum/kubernetes-sig-security)\n- [Open Community Issues/PRs](https://github.com/kubernetes/community/labels/sig%2Fsecurity)\n- [Sig Security Issues](https://github.com/kubernetes/sig-security/issues)\n- GitHub Teams:\n    - [@kubernetes/sig-security-leads](https://github.com/orgs/kubernetes/teams/sig-security-leads) - SIG Security Leads\n    - [@kubernetes/sig-security-pr-reviews](https://github.com/orgs/kubernetes/teams/sig-security-pr-reviews) - SIG Security PR review notifications\n- Steering Committee Liaison: Paris Pittman (**[@parispittman](https://github.com/parispittman)**)\n\n## Subprojects\n\nThe following [subprojects][subproject-definition] are owned by sig-security:\n### security-assessments\nInformation about Security Assessments\n- **Owners:**\n  - [@kubernetes/sig-security-assessments](https://github.com/kubernetes/sig-security/blob/main/sig-security-assessments/OWNERS)\n### security-audit\nThird Party Security Audit\n- **Owners:**\n  - [kubernetes/sig-security/sig-security-external-audit](https://github.com/kubernetes/sig-security/blob/main/sig-security-external-audit/OWNERS)\n### security-docs\nSecurity Documents and Documentation\n- **Owners:**\n  - [kubernetes/sig-security/sig-security-docs](https://github.com/kubernetes/sig-security/blob/main/sig-security-docs/OWNERS)\n- **Contact:**\n  - Slack: [#sig-security-docs](https://kubernetes.slack.com/messages/sig-security-docs)\n### security-tooling\nDevelopment and Enhancements of Security Tooling\n- **Owners:**\n  - [kubernetes/sig-security/sig-security-tooling](https://github.com/kubernetes/sig-security/blob/main/sig-security-tooling/OWNERS)\n- **Contact:**\n  - Slack: [#sig-security-tooling](https://kubernetes.slack.com/messages/sig-security-tooling)\n### sig-security\nSIG Security discussions, documents, processes and other artifacts\n- **Owners:**\n  - [kubernetes/sig-security](https://github.com/kubernetes/sig-security/blob/master/OWNERS)\n- **Contact:**\n  - Slack: [#sig-security](https://kubernetes.slack.com/messages/sig-security)\n\n[subproject-definition]: https://github.com/kubernetes/community/blob/master/governance.md#subprojects\n", "release_dates": []}, {"name": "sig-testing", "description": "Home for SIG Testing discussion and documents.", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# SIG Testing\n\nHome for [SIG Testing](https://github.com/kubernetes/community/tree/master/sig-testing) discussion and documents.\n\n## Join us!\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\n- [Slack](https://kubernetes.slack.com/messages/sig-testing)\n- [Mailing List](https://groups.google.com/forum/#!forum/kubernetes-sig-testing)\n- [Meeting agenda and notes](https://docs.google.com/document/d/1z8MQpr_jTwhmjLMUaqQyBk1EYG_Y_3D4y4YdMJ7V1Kk/edit)\n\n## Contribution\n\n- [Open Issues / PRs](https://github.com/search?q=org%3Akubernetes+org%3Akubernetes-client+org%3Akubernetes-csi+org%3Akubernetes-incubator+org%3Akubernetes-retired+org%3Akubernetes-sigs+is%3Aopen+label%3Asig%2Ftesting)\n- [sig-testing issues project (Kubernetes)](https://github.com/orgs/kubernetes/projects/52)\n- [sig-testing issues project (Kubernetes SIGs)](https://github.com/orgs/kubernetes-sigs/projects/11)\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n", "release_dates": []}, {"name": "steering", "description": "The Kubernetes Steering Committee", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Steering Committee\n\n## Members\n\nThe Steering Committee is a 7 member body, overseeing the governance of the\nKubernetes project. See the [Steering Committee Charter](charter.md) for\nspecific committee structure information.\n\n### Term ends in October 2025\n\n| Name | Profile | Affiliation |\n| ---- | ------- | ----------- |\n| Maciej Szulik | **[@soltysh](https://github.com/soltysh)** | Red Hat |\n| Paco Xu \u5f90\u4fca\u6770 | **[@pacoxu](https://github.com/pacoxu)** | DaoCloud |\n| Patrick Ohly | **[@pohly](https://github.com/pohly)** | Intel |\n| Stephen Augustus | **[@justaugustus](https://github.com/justaugustus)** | Cisco |\n\n### Term ends in October 2024\n\n| Name | Profile | Affiliation |\n| ---- | ------- | ----------- |\n| Benjamin Elder | **[@BenTheElder](https://github.com/bentheelder)** | Google |\n| Bob Killen | **[@mrbobbytables](https://github.com/mrbobbytables)** | Google |\n| Nabarun Pal | **[@palnabarun](https://github.com/palnabarun)** | VMware |\n\n### Emeritus\n\n| Name | Profile |\n| ---- | ------- |\n| Aaron Crickenberger | **[@spiffxp](https://github.com/spiffxp)** |\n| Brandon Philips | **[@philips](https://github.com/philips)** |\n| Brendan Burns | **[@brendandburns](https://github.com/brendandburns)** |\n| Brian Grant | **[@bgrant0607](https://github.com/bgrant0607)** |\n| Carlos Tadeu Panato Jr. | **[@cpanato](https://github.com/cpanato)** |\n| Christoph Blecker | **[@cblecker](https://github.com/cblecker)** |\n| Clayton Coleman | **[@smarterclayton](https://github.com/smarterclayton)** |\n| Davanum Srinivas | **[@dims](https://github.com/dims)** |\n| Derek Carr | **[@derekwaynecarr](https://github.com/derekwaynecarr)** |\n| Joe Beda | **[@jbeda](https://github.com/jbeda)** |\n| Jordan Liggitt | **[@liggitt](https://github.com/liggitt)** |\n| Lachlan Evenson | **[@lachie83](https://github.com/lachie83)** |\n| Michelle Dhanani | **[@michelleN](https://github.com/michelleN)** |\n| Nikhita Raghunath | **[@nikhita](https://github.com/nikhita)** |\n| Paris Pittman | **[@parispittman](https://github.com/parispittman)** |\n| Phillip Wittrock | **[@pwittrock](https://github.com/pwittrock)** |\n| Quinton Hoole | **[@quinton-hoole](https://github.com/quinton-hoole)** |\n| Sarah Novotny | **[@sarahnovotny](https://github.com/sarahnovotny)** |\n| Tim Hockin | **[@thockin](https://github.com/thockin)** |\n| Tim Pepper | **[@tpepper](https://github.com/tpepper)** |\n| Timothy St. Clair | **[@timothysc](https://github.com/timothysc)** |\n\n\n## Kubernetes CNCF Governing Board Representative\n\nThe Kubernetes Project is granted one of the two [Developer Representative]\nseats on the [CNCF Governing Board]. This seat may be held by current and\nformer Kubernetes Steering Members and is elected to a two year term.\n\n| Name | Profile | Term |\n| ---- | ------- | ---- |\n| Christoph Blecker | **[@cblecker](https://github.com/cblecker)** | 2025 |\n\n### Emeritus Kubernetes CNCF Governing Board Representatives\n\n| Name | Profile |\n| ---- | ------- |\n| Michelle Dhanani | **[@michelleN](https://github.com/michelleN)** |\n| Paris Pittman | **[@parispittman](https://github.com/parispittman)** |\n\n[Developer Representative]: https://github.com/cncf/foundation/blob/main/maintainers-election-policy.md#developer-representation-on-the-cncf-gb\n[CNCF Governing Board]: https://www.cncf.io/people/governing-board/\n\n## CNCF Representative\n\nThere are various cases when the Steering Committee may require interactions\nwith CNCF, so a dedicated person from the CNCF Staff acts a primary\ncommunication point between Steering and CNCF.\n\n| Name | Profile |\n| ---- | ------- |\n| Jeff Sica | **[@jeefy](https://github.com/jeefy)** |\n\nFor more details on the relationship between Steering and CNCF, please see a\ndedicated document [Relationship with the CNCF](operations/cncf-and-k8s.md).\n\n\n## Communication Channels\n\n- Public Slack: [#steering-committee](https://kubernetes.slack.com/messages/steering-committee)\n- Mailing List: steering@kubernetes.io ([archive](https://groups.google.com/a/kubernetes.io/forum/#!forum/steering))\n- Private Mailing List: steering-private@kubernetes.io\n- [Open Community Issues/PRs](https://github.com/kubernetes/community/labels/committee%2Fsteering)\n- GitHub Teams:\n  - [@kubernetes/steering-committee](https://github.com/orgs/kubernetes/teams/steering-committee) - General Discussion\n\n### Private Communication Channels\n\nThe Steering Committee often deals with sensitive topics and has several\nprivate slack channels to discuss and coordinate with our project representatives.\n\n- `#steering-private` - Private channel for Steering Members\n- `#steering-cncf-rep-private` - Private channel between Steering and the\n   current CNCF Representative.\n- `#steering-gb-rep-private` - Private channel between Steering and the current\n   Kubernetes CNCF Governing Board Representative.\n\n## Meetings\n\nWe have two meetings every month.\n\n- We hold an open and recorded online meeting where the community is welcome to join the first Wednesday at 8am PT of every month if there is [quorum](charter.md#quorum).\n- We have a closed and not recorded online meeting every 3rd Wednesday of the month at 8am PT if there is [quorum](charter.md#quorum).\n\n### Resources\n\n- [Recordings of our meetings](https://www.youtube.com/watch?v=YAzgJRQxsdc&list=PL69nYSiGNLP1yP1B_nd9-drjoxp0Q14qM) are publicly available on youtube\n- [Meeting notes](https://bit.ly/k8s-steering-wd) are available to members of the [kubernetes-dev mailing list](https://groups.google.com/forum/#!forum/kubernetes-dev)\n\n## Projects\n\n- [Charter](charter.md)\n- [Backlog](https://github.com/orgs/kubernetes/projects/40)\n\n\n### CNCF ServiceDesk access\n\nThe CNCF ServiceDesk policy for Kubernetes community is defined at [ServiceDesk](operations/service-desk.md).\n\n## Top-level Accounts\n\nThe steering committee delegates ownership of various Kubernetes community accounts like GitHub, domain names, etc to SIGs and sub-projects. However, the committee also reserves top-level account access for service governance in some cases.\n\n### Google Workspace\n\n| Account | Owner |\n| ------- | ----- |\n| sc1@kubernetes.io | Stephen Augustus |\n| sc2@kubernetes.io | Nabarun Pal |\n| sc3@kubernetes.io | Bob Killen |\n\n", "release_dates": []}, {"name": "system-validators", "description": "A set of system-oriented validators for kubeadm preflight checks.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# System Validators\n\nA set of system-oriented validators for kubeadm preflight checks.\n\n## Creating releases\n\nTo prepare a release of this library please follow this guide:\n- The main branch should always contain WIP commits planned for the upcoming release.\n- Always create a new branch for MAJOR and MINOR releases. This allows backporting changes.\n- Release branch names should be in the format `release-MAJOR.MINOR` (without a `v` prefix).\n- Only non-breaking bug fixes can be done in a PATCH release.\n- New features must not be added in PATCH releases.\n- Breaking changes must be added in a MAJOR release.\n- Pushing releases requires write access. To obtain that you must be part of\nthe [`system-validator-maintainers` team](http://git.k8s.io/org/config/kubernetes/sig-cluster-lifecycle/teams.yaml).\n\nFor vendoring the new release in kubernetes/kubernetes you can use its `pin-dependency.sh` script.\n\nExample:\n```bash\n./hack/pin-dependency.sh k8s.io/system-validators <NEW-TAG>\n```\n\nAnd then PR the changes.\n\n## Community, discussion, contribution, and support\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n- [Slack](https://kubernetes.slack.com/messages/sig-cluster-lifecycle)\n- [Mailing List](https://groups.google.com/forum/#!forum/kubernetes-sig-cluster-lifecycle)\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n", "release_dates": ["2022-08-25T07:31:11Z", "2022-03-24T16:56:10Z", "2021-11-10T20:18:25Z", "2021-06-25T15:32:45Z", "2021-03-02T18:33:24Z", "2020-11-09T15:56:10Z", "2020-09-09T19:54:49Z", "2020-04-08T17:37:37Z", "2020-04-06T19:54:45Z", "2020-04-06T16:54:07Z", "2019-11-12T00:02:56Z", "2019-11-11T20:34:33Z", "2019-11-07T19:48:10Z", "2019-11-05T18:30:16Z", "2019-11-04T16:54:36Z"]}, {"name": "test-infra", "description": "Test infrastructure for the Kubernetes project.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# test-infra\n\n[![GoDoc](https://godoc.org/k8s.io/test-infra?status.svg)](https://godoc.org/k8s.io/test-infra)\n[![Build status](https://prow.k8s.io/badge.svg?jobs=ci-test-infra-continuous-test)](https://testgrid.k8s.io/sig-testing-misc#continuous)\n\nThis repository contains tools and configuration files for the testing and\nautomation needs of the Kubernetes project.\n\nOur [architecture diagram](docs/architecture.svg) provides an (updated [#13063])\noverview of how the different tools and services interact.\n\n## CI Job Management\n\nKubernetes uses a [`prow`] instance at [prow.k8s.io] to handle CI and \nautomation for the entire project. Everyone can participate in a \nself-service PR-based workflow, where changes are automatically deployed\nafter they have been reviewed. All job configs are located in [`config/jobs`]\n\n- [Add or update job configs](/config/jobs/README.md#adding-or-updating-jobs)\n- [Delete job configs](/config/jobs/README.md#deleting-jobs)\n- [Test job configs locally](/config/jobs/README.md#testing-jobs-locally)\n- [Trigger jobs on PRs using bot commands](https://go.k8s.io/bot-commands)\n\n## Dashboards\n\n### Test Result Dashboards\n\n- [Testgrid](https://testgrid.k8s.io) shows historical test results over time ([`testgrid`])\n- [Triage](https://go.k8s.io/triage) shows clusters of similar test failures across all jobs ([`triage`](/triage))\n\n### Job and PR Dashboards\n\n- [Deck](https://prow.k8s.io) shows what jobs are running or have recently run in prow ([`prow/cmd/deck`])\n- [Gubernator's PR Dashboard](https://gubernator.k8s.io/pr) shows which PRs need your review ([`gubernator`])\n- [PR Status](https://prow.k8s.io/pr) shows what needs to be done to get PRs matching a GitHub Query to merge ([`prow/cmd/tide`])\n- [Tide History](https://prow.k8s.io/tide-history) shows what actions tide has taken over time to trigger tests and merge PRs ([`prow/cmd/tide`])\n- [Tide Status](https://prow.k8s.io/tide) shows what PRs are in tide pools to be tested and merged ([`prow/cmd/tide`])\n\n## Other Tools\n\n- [`boskos`](/boskos) manages pools of resources; our CI leases GCP projects from these pools\n- [`experiment`](/experiment) is a catchall directory for one-shot tools or scripts\n- [`gcsweb`](/gcsweb) is a UI we use to display test artifacts stored in public GCS buckets\n- [`ghproxy`](/ghproxy) is a GitHub-aware reverse proxy cache to help keep our GitHub API token usage within rate limits\n- [`gopherage`](/gopherage) is a tool for manipulating Go coverage files\n- [`greenhouse`](/greenhouse) is a shared bazel cache we use to ensure faster build and test presubmit jobs\n- [`label_sync`](/label_sync) creates, updates and migrates GitHub labels across orgs and repos based on `labels.yaml` file\n- [`kettle`](/kettle) extracts test results from GCS and puts them into bigquery\n- [`kubetest`](/kubetest) is how our CI creates and e2e tests kubernetes clusters\n- [`maintenance/migratestatus`](/maintenance/migratestatus) is used to migrate or retire GitHub status contexts on PRs across orgs and repos\n- [`metrics`](/metrics) runs queries against bigquery to generate metrics based on test results\n- [`robots/commenter`](/robots/commenter) is used by some of our jobs to comment on GitHub issues\n\n## Contributing\n\nPlease see [CONTRIBUTING.MD](CONTRIBUTING.md)\n\n[test-infra oncall]: https://go.k8s.io/oncall\n[@k8s-ci-robot]: (https://github.com/k8s-ci-robot)\n[#13063]: https://github.com/kubernetes/test-infra/issues/13063\n[prow.k8s.io]: https://prow.k8s.io\n[kubernetes/kubernetes]: https://github.com/kubernetes/kubernetes\n\n[bot commands]: https://go.k8s.io/bot-commands\n[`config/jobs`]: /config/jobs\n[`gubernator`]: /gubernator\n[`metrics`]: /metrics\n[`prow`]: /prow\n[`prow/cmd/tide`]: /prow/cmd/tide\n[`prow/cmd/deck`]: /prow/cmd/deck\n[`testgrid`]: /testgrid\n[testgrid.k8s.io]: https://testgrid.k8s.io\n[`triage`]: /triage\n", "release_dates": []}, {"name": "utils", "description": "Non-Kubernetes-specific utility libraries which are consumed by multiple projects.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Utils\n\n[![Build Status]](https://travis-ci.org/kubernetes/utils) [![GoDoc](https://godoc.org/k8s.io/utils?status.svg)](https://godoc.org/k8s.io/utils)\n\nA set of Go libraries that provide low-level, kubernetes-independent packages\nsupplementing the [Go standard libs].\n\n## Purpose\n\nAs Kubernetes grows and spins functionality out of its [core] and into\ncooperating repositories like [apiserver], [kubectl], [kubeadm], etc., the need\narises for leaf repositories to house shared code and avoid cycles in repository\nrelationships.\n\nThis repository is intended to hold shared utilities with _no Kubernetes\ndependencies_ that may be of interest to any Go project.  See these [instructions\nfor moving] an existing package to this repository.\n\n## Criteria for adding code here\n\n- Used by multiple Kubernetes repositories.\n\n- Complex enough to be worth vendoring, rather than copying (e.g. not 5 LOC).\n\n- Can be fully exercised by unit tests (e.g. no dependencies on kernels).\n\n- Has full unit test coverage.\n\n- Stable, or backward compatible, API, with complete godocs.\n\n- Go tools compliant (`go get`, `go test`, etc.).\n\n- Very few (ideally zero) external dependencies.\n\n- _No dependencies on any other Kubernetes repository_.\n\n[Build Status]: https://travis-ci.org/kubernetes/utils.svg?branch=master\n[Go standard libs]: https://pkg.go.dev/std#stdlib\n[api]: https://github.com/kubernetes/api\n[apiserver]: https://github.com/kubernetes/apiserver\n[core]: https://github.com/kubernetes/kubernetes\n[ingress]: https://github.com/kubernetes/ingress\n[kubeadm]: https://github.com/kubernetes/kubeadm\n[kubectl]: https://github.com/kubernetes/kubectl\n[instructions for moving]: ./HOWTOMOVE.md\n\n## Contributing\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on how to contribute.\n", "release_dates": []}, {"name": "website", "description": "Kubernetes website and documentation repo: ", "language": "HTML", "license": {"key": "cc-by-4.0", "name": "Creative Commons Attribution 4.0 International", "spdx_id": "CC-BY-4.0", "url": "https://api.github.com/licenses/cc-by-4.0", "node_id": "MDc6TGljZW5zZTI1"}, "readme": "# The Kubernetes documentation\n\n[![Netlify Status](https://api.netlify.com/api/v1/badges/be93b718-a6df-402a-b4a4-855ba186c97d/deploy-status)](https://app.netlify.com/sites/kubernetes-io-main-staging/deploys) [![GitHub release](https://img.shields.io/github/release/kubernetes/website.svg)](https://github.com/kubernetes/website/releases/latest)\n\nThis repository contains the assets required to build the [Kubernetes website and documentation](https://kubernetes.io/). We're glad that you want to contribute!\n\n- [Contributing to the docs](#contributing-to-the-docs)\n- [Localization READMEs](#localization-readmes)\n\n## Using this repository\n\nYou can run the website locally using [Hugo (Extended version)](https://gohugo.io/), or you can run it in a container runtime. We strongly recommend using the container runtime, as it gives deployment consistency with the live website.\n\n## Prerequisites\n\nTo use this repository, you need the following installed locally:\n\n- [npm](https://www.npmjs.com/)\n- [Go](https://go.dev/)\n- [Hugo (Extended version)](https://gohugo.io/)\n- A container runtime, like [Docker](https://www.docker.com/).\n\nBefore you start, install the dependencies. Clone the repository and navigate to the directory:\n\n```bash\ngit clone https://github.com/kubernetes/website.git\ncd website\n```\n\nThe Kubernetes website uses the [Docsy Hugo theme](https://github.com/google/docsy#readme). Even if you plan to run the website in a container, we strongly recommend pulling in the submodule and other development dependencies by running the following:\n\n### Windows\n```powershell\n# fetch submodule dependencies\ngit submodule update --init --recursive --depth 1\n```\n\n### Linux / other Unix\n```bash\n# fetch submodule dependencies\nmake module-init\n```\n\n## Running the website using a container\n\nTo build the site in a container, run the following:\n\n```bash\n# You can set $CONTAINER_ENGINE to the name of any Docker-like container tool\nmake container-serve\n```\n\nIf you see errors, it probably means that the hugo container did not have enough computing resources available. To solve it, increase the amount of allowed CPU and memory usage for Docker on your machine ([MacOS](https://docs.docker.com/desktop/settings/mac/) and [Windows](https://docs.docker.com/desktop/settings/windows/)).\n\nOpen up your browser to <http://localhost:1313> to view the website. As you make changes to the source files, Hugo updates the website and forces a browser refresh.\n\n## Running the website locally using Hugo\n\nMake sure to install the Hugo extended version specified by the `HUGO_VERSION` environment variable in the [`netlify.toml`](netlify.toml#L11) file.\n\nTo install dependencies, deploy and test the site locally, run:\n\n- For macOS and Linux\n  ```bash\n  npm ci\n  make serve\n  ```\n- For Windows (PowerShell)\n  ```powershell\n  npm ci\n  hugo.exe server --buildFuture --environment development\n  ```\n\nThis will start the local Hugo server on port 1313. Open up your browser to <http://localhost:1313> to view the website. As you make changes to the source files, Hugo updates the website and forces a browser refresh.\n\n## Building the API reference pages\n\nThe API reference pages located in `content/en/docs/reference/kubernetes-api` are built from the Swagger specification, also known as OpenAPI specification, using <https://github.com/kubernetes-sigs/reference-docs/tree/master/gen-resourcesdocs>.\n\nTo update the reference pages for a new Kubernetes release follow these steps:\n\n1. Pull in the `api-ref-generator` submodule:\n\n   ```bash\n   git submodule update --init --recursive --depth 1\n   ```\n\n2. Update the Swagger specification:\n\n   ```bash\n   curl 'https://raw.githubusercontent.com/kubernetes/kubernetes/master/api/openapi-spec/swagger.json' > api-ref-assets/api/swagger.json\n   ```\n\n3. In `api-ref-assets/config/`, adapt the files `toc.yaml` and `fields.yaml` to reflect the changes of the new release.\n\n4. Next, build the pages:\n\n   ```bash\n   make api-reference\n   ```\n\n   You can test the results locally by building and serving the site from a container:\n\n   ```bash\n   make container-serve\n   ```\n\n   In a web browser, go to <http://localhost:1313/docs/reference/kubernetes-api/> to view the API reference.\n\n5. When all changes of the new contract are reflected into the configuration files `toc.yaml` and `fields.yaml`, create a Pull Request with the newly generated API reference pages.\n\n## Troubleshooting\n\n### error: failed to transform resource: TOCSS: failed to transform \"scss/main.scss\" (text/x-scss): this feature is not available in your current Hugo version\n\nHugo is shipped in two set of binaries for technical reasons. The current website runs based on the **Hugo Extended** version only. In the [release page](https://github.com/gohugoio/hugo/releases) look for archives with `extended` in the name. To confirm, run `hugo version` and look for the word `extended`.\n\n### Troubleshooting macOS for too many open files\n\nIf you run `make serve` on macOS and receive the following error:\n\n```bash\nERROR 2020/08/01 19:09:18 Error: listen tcp 127.0.0.1:1313: socket: too many open files\nmake: *** [serve] Error 1\n```\n\nTry checking the current limit for open files:\n\n`launchctl limit maxfiles`\n\nThen run the following commands (adapted from <https://gist.github.com/tombigel/d503800a282fcadbee14b537735d202c>):\n\n```shell\n#!/bin/sh\n\n# These are the original gist links, linking to my gists now.\n# curl -O https://gist.githubusercontent.com/a2ikm/761c2ab02b7b3935679e55af5d81786a/raw/ab644cb92f216c019a2f032bbf25e258b01d87f9/limit.maxfiles.plist\n# curl -O https://gist.githubusercontent.com/a2ikm/761c2ab02b7b3935679e55af5d81786a/raw/ab644cb92f216c019a2f032bbf25e258b01d87f9/limit.maxproc.plist\n\ncurl -O https://gist.githubusercontent.com/tombigel/d503800a282fcadbee14b537735d202c/raw/ed73cacf82906fdde59976a0c8248cce8b44f906/limit.maxfiles.plist\ncurl -O https://gist.githubusercontent.com/tombigel/d503800a282fcadbee14b537735d202c/raw/ed73cacf82906fdde59976a0c8248cce8b44f906/limit.maxproc.plist\n\nsudo mv limit.maxfiles.plist /Library/LaunchDaemons\nsudo mv limit.maxproc.plist /Library/LaunchDaemons\n\nsudo chown root:wheel /Library/LaunchDaemons/limit.maxfiles.plist\nsudo chown root:wheel /Library/LaunchDaemons/limit.maxproc.plist\n\nsudo launchctl load -w /Library/LaunchDaemons/limit.maxfiles.plist\n```\n\nThis works for Catalina as well as Mojave macOS.\n\n## Get involved with SIG Docs\n\nLearn more about SIG Docs Kubernetes community and meetings on the [community page](https://github.com/kubernetes/community/tree/master/sig-docs#meetings).\n\nYou can also reach the maintainers of this project at:\n\n- [Slack](https://kubernetes.slack.com/messages/sig-docs)\n  - [Get an invite for this Slack](https://slack.k8s.io/)\n- [Mailing List](https://groups.google.com/forum/#!forum/kubernetes-sig-docs)\n\n## Contributing to the docs\n\nYou can click the **Fork** button in the upper-right area of the screen to create a copy of this repository in your GitHub account. This copy is called a _fork_. Make any changes you want in your fork, and when you are ready to send those changes to us, go to your fork and create a new pull request to let us know about it.\n\nOnce your pull request is created, a Kubernetes reviewer will take responsibility for providing clear, actionable feedback. As the owner of the pull request, **it is your responsibility to modify your pull request to address the feedback that has been provided to you by the Kubernetes reviewer.**\n\nAlso, note that you may end up having more than one Kubernetes reviewer provide you feedback or you may end up getting feedback from a Kubernetes reviewer that is different than the one initially assigned to provide you feedback.\n\nFurthermore, in some cases, one of your reviewers might ask for a technical review from a Kubernetes tech reviewer when needed. Reviewers will do their best to provide feedback in a timely fashion but response time can vary based on circumstances.\n\nFor more information about contributing to the Kubernetes documentation, see:\n\n- [Contribute to Kubernetes docs](https://kubernetes.io/docs/contribute/)\n- [Page Content Types](https://kubernetes.io/docs/contribute/style/page-content-types/)\n- [Documentation Style Guide](https://kubernetes.io/docs/contribute/style/style-guide/)\n- [Localizing Kubernetes Documentation](https://kubernetes.io/docs/contribute/localization/)\n- [Introduction to Kubernetes Docs](https://www.youtube.com/watch?v=pprMgmNzDcw)\n\n### New contributor ambassadors\n\nIf you need help at any point when contributing, the [New Contributor Ambassadors](https://kubernetes.io/docs/contribute/advanced/#serve-as-a-new-contributor-ambassador) are a good point of contact. These are SIG Docs approvers whose responsibilities include mentoring new contributors and helping them through their first few pull requests. The best place to contact the New Contributors Ambassadors would be on the [Kubernetes Slack](https://slack.k8s.io/). Current New Contributors Ambassadors for SIG Docs:\n\n| Name                       | Slack                      | GitHub                     |                   \n| -------------------------- | -------------------------- | -------------------------- |\n| Arsh Sharma                | @arsh                      | @RinkiyaKeDad              |\n\n## Localization READMEs\n\n| Language                   | Language                   |\n| -------------------------- | -------------------------- |\n| [Chinese](README-zh.md)    | [Korean](README-ko.md)     |\n| [French](README-fr.md)     | [Polish](README-pl.md)     |\n| [German](README-de.md)     | [Portuguese](README-pt.md) |\n| [Hindi](README-hi.md)      | [Russian](README-ru.md)    |\n| [Indonesian](README-id.md) | [Spanish](README-es.md)    |\n| [Italian](README-it.md)    | [Ukrainian](README-uk.md)  |\n| [Japanese](README-ja.md)   | [Vietnamese](README-vi.md) |\n\n## Code of conduct\n\nParticipation in the Kubernetes community is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/main/code-of-conduct.md).\n\n## Thank you\n\nKubernetes thrives on community participation, and we appreciate your contributions to our website and our documentation!\n", "release_dates": ["2023-12-13T17:12:25Z", "2023-08-15T19:46:57Z", "2023-04-12T00:34:54Z", "2022-12-10T02:15:26Z", "2022-08-24T17:12:57Z", "2022-05-03T23:47:12Z", "2021-12-07T23:48:36Z", "2021-08-04T22:50:27Z", "2021-04-08T19:03:31Z", "2020-12-08T22:03:19Z", "2020-08-26T23:42:07Z", "2020-03-31T10:22:28Z", "2019-12-11T00:56:25Z", "2019-09-18T23:30:19Z", "2019-06-20T21:17:51Z", "2019-04-02T19:15:57Z", "2018-12-04T21:07:02Z", "2018-09-27T23:50:29Z", "2018-09-27T19:26:38Z", "2018-04-16T21:20:41Z", "2017-12-15T23:48:51Z", "2017-12-15T20:41:31Z", "2017-09-29T05:02:55Z", "2017-09-29T05:06:28Z"]}]