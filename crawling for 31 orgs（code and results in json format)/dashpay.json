[{"name": ".github", "description": null, "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# .github", "release_dates": []}, {"name": "abscission", "description": "Error Framework for Platform", "language": "Rust", "license": null, "readme": "# abscission\n", "release_dates": []}, {"name": "adr", "description": "ADR's for Dash", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# ADR\n\nThis repository contains [architectural decision records](https://adr.github.io/) (ADRs) for Dash.\n\n## Contributing\n\nPRs accepted.\n\n## License\n\n[MIT](./LICENSE) \u00a9 Dash Core Group, Inc.\n", "release_dates": []}, {"name": "android-dashpay", "description": "JVM library for Platform and the DashPay contract", "language": "Kotlin", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# DashPay library for JVM\nThis library consists of two components\n- platform-core (similar to DashJS which handles identities, contracts, documents and names)\n- dashpay (handles the dashpay contract documents: profiles and contractRequests)\n\n# Building\nThis depends on the `android-dpp` and `dapi-client-android` libraries:\n```\ngit clone https://github.com/dashevo/android-dpp.git\ncd android-dpp\n./gradlew assemble\ncd ..\ngit clone https://github.com/dashevo/dapi-client-android.git\ncd dapi-client-android\n./gradlew assemble\ncd ..\n```\nFinally, build the library:\n```\ngit clone https://github.com/dashevo/android-dashpay.git`\ncd android-dashpay`\n./gradlew assemble`\n```\n- After building, it will be available on the local Maven repository.\n- To use it with gradle, add `mavenLocal()` to the `repositories` list in your `build.gradle` file and add `org.dashj.platform:dashpay:0.23-SNAPSHOT` and `org.dashj.platform:platform-core:0.21-SNAPSHOT` and as dependency. \n\n# Usage\n- Add mavenCentral() to your `repositories`\n- What to include in your build.gradle:\n```\ndependencies {\n    implementation \"org.dashj.platform:dpp:0.23-SNAPSHOT\"\n    implementation \"org.dashj.platform:dapi-client:0.23-SNAPSHOT\"\n    implementation \"org.dashj:dashj-core:0.19.1-SNAPSHOT\"\n    implementation \"org.dashj:dashj-bls:1.0.0\"\n    implementation \"org.dashj.platform:platform-core:0.23-SNAPSHOT\"\n    implementation \"org.dashj.platform:dashpay:0.23-SNAPSHOT\" # if dashpay contract is required\n}\n```\n# Tests\nRun tests with `gradle build test`\n\n# Publish to maven central\n```  \n./gradlew uploadArchives\n```\n\n", "release_dates": []}, {"name": "android-dpp", "description": "Dash Platform Protocol for JVM (Java, Kotlin, etc)", "language": "Kotlin", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Dash Platform Protocol (DPP) for JVM\n\n[![License](https://img.shields.io/github/license/dashevo/android-dpp)](https://github.com/dashevo/android-dpp/blob/master/LICENSE)\n[![dashevo/android-dpp](https://tokei.rs/b1/github/dashevo/android-dpp?category=code)](https://github.com/dashevo/android-dpp)\n\n| Branch | Tests                                                                                      | Coverage                                                                                                                             | Linting                                                                    |\n|--------|--------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------|\n| master | [![Tests](https://github.com/dashevo/android-dpp/workflows/CI/badge.svg?branch=master)](https://github.com/dashevo/android-dpp/actions) | [![codecov](https://codecov.io/gh/dashevo/android-dpp/branch/master/graph/badge.svg)](https://codecov.io/gh/dashevo/android-dpp) | ![Lint](https://github.com/dashevo/android-dpp/workflows/Kotlin%20Linter/badge.svg) |\n\n\n# Build and Publish to Local Repository\n```\ngit clone https://github.com/github/dashevo/android-dpp.git\ncd android-dpp\n./gradlew assemble\n```\n- After building, it will be available on the local Maven repository.\n- To use it with gradle, add `mavenLocal()` to the `repositories` list in your `build.gradle` file and add `org.dashj.platform:dpp:0.24-SNAPSHOT` as a dependency. \n\n# Usage\nAdd mavenCentral() to the `repositories` list in your `build.gradle`\n```groovy\n\ndependencies {\n    implementation 'org.dashj.platform:dpp:0.24-SNAPSHOT'\n}\n```\n\n# KtLint\nCheck using ktlint:\n```shell\n./gradlew ktlint\n```\nFormat using ktlint:\n```shell\n./gradlew ktlintFormat\n```\n\n# Tests\nRun tests with `./gradlew build test`\n\n# Debugging Tools\n- https://cbor.me\n\n# Publish to Maven Central\n```shell\n./gradlew uploadArchives\n```", "release_dates": []}, {"name": "bitcoin-tool", "description": "Tool for converting Bitcoin keys and addresses", "language": "C", "license": null, "readme": "Simple tool in C to convert Bitcoin keys to addresses, and various other\ntype conversions.\n\nDisclaimer: THIS CODE IS EXPERIMENTAL, IT IS PROBABLY BUGGY. PLEASE DO NOT\nTRUST YOUR BITCOINS WITH IT.  IT IS EASY TO MAKE AN IRREVERSIBLE MISTAKE AND\nSEND YOUR BITCOINS TO A ADDRESS WITH NO WAY OF GETTING THEM BACK.\n\nCompile with `make`.\n\nI created this because I couldn't find an offline tool or library able\nto create addresses from Bitcoin private keys, and as a learning exercise in\nBitcoin address formats and ECDSA.\n\nSome day I'd like to replace the dependancy on OpenSSL with my own\nimplementation of ECDSA.\n\nThe option names are a little verbose but I wanted to make it clear exactly what\neach one is referring to, especially when it is possible to make a costly\nmistake.\n\nI've tried to add as much sanity checking as possible, to remove the scope\nfor errors and misinterpretation of data.  This sometimes boreders on the\nannoying: if the file for --input-file contains more data than is expected,\nit'll tell you off about that.\n\n### Command-line options\n\n    --input-type : Input data type, can be one of :\n        mini-private-key : 30 character Casascius mini private key.\n        private-key      : 32 byte ECDSA private key\n        private-key-wif  : 37/38 byte ECDSA private key in wallet import format\n        public-key       : 33/65 byte ECDSA public key\n        public-key-sha   : 32 byte SHA256(public key) hash\n        public-key-rmd   : 20 byte RIPEMD160(SHA256(public key)) hash\n        address          : 21 byte Bitcoin address (prefix + hash)\n\n    --input-format : Input data format, can be one of :\n        raw             : raw binary data\n        hex             : hexadecimal encoded\n        base58          : Base58 encoded (almost never used in the wild)\n        base58check     : Base58Check encoded\n\n    --output-type   Output data type, can be any one of those used for\n                    --input-type, or additionally :\n        all             : all output types, as type:value pairs, most of which\n                          are never used, probably for good reason.\n\n    --output-format Output data format, can be any one of those used for\n                    --input-format\n\n    --input         Specify input data on command line\n    --input-file    Specify input file name.  File size must be exactly what\n                    is expected for the corresponding --input-type.\n\n    --network       Set network type of raw keys.  Can be one of :\n        bitcoin\n        bitcoin-testnet\n        litecoin\n        litecoin-testnet\n        feathercoin\n        feathercoin-testnet\n        dogecoin\n        dogecoin-testnet\n        quarkcoin\n        quarkcoin-testnet\n\n    --fix-base58check : Attempt to fix a Base58Check string by changing\n                        characters until the checksum matches.\n    --fix-base58check-change-chars : Maximum number of characters to change (default=3)\n\nThe `mini-private-key` input-type requires --input to be a 30 character ASCII\nstring in valid mini private key format and --input-format to be `raw`.\n\nIf raw keys are input and an address output is required, then the key type\nprefix must be specified via --network\n\n### Examples\n\n#### Manual address / key generation\n\nLet's manually generate a Bitcoin address and private key for the purpose of an offline wallet (cold storage).\n\nCreate private key:\n```\n$ openssl rand 32 > key.bin\n```\n\nInspect private key:\n```\n$ hexdump -e '32/1 \"%02X\" \"\\n\"' key.bin\n\n62A87AD3272B41E67108FEA10C57BA6ED609F2F7A2264A83B690CD45707090D1\n```\n\nConvert private key to WIF (Wallet Import Format).  Since it is a raw key, the\nnetwork type must be explicitally set (to bitcoin in this case) because it\ncannot be determined from the raw key :\n```\n$ ./bitcoin-tool \\\n    --network bitcoin \\\n    --input-type private-key \\\n    --input-format raw \\\n    --input-file key.bin \\\n    --output-type private-key-wif \\\n    --output-format base58check \\\n    --public-key-compression uncompressed\n\n5JZjfs5wJv1gNkJXCmYpyj6VxciqPkwmK4yHW8zMmPN1PW7Hk7F\n```\nSpecifying --public-key-compression is mandatory because the WIF output is\ndifferent depending on which public key compression type you choose, and there\nis no way to guess from a raw private key.\n\nSame again but compressed public key :\n```\n$ ./bitcoin-tool \\\n    --network bitcoin \\\n    --input-type private-key \\\n    --input-format raw \\\n    --input-file key.bin \\\n    --output-type private-key-wif \\\n    --output-format base58check \\\n    --public-key-compression compressed\n\nKzXVLY4ni4yznz8LJwdUmNoGpUfebSxiakXRqcGAeuhihzaVe3Rz\n```\n\nNote that the WIF private key is longer with public key compression on, because\nan extra byte flag is stored to indicate that the public key should be compressed\n(the private key is exactly the same).\n\nShow address for uncompressed WIF private key:\n```\n$ ./bitcoin-tool \\\n    --input-type private-key-wif \\\n    --input-format base58check \\\n    --input 5JZjfs5wJv1gNkJXCmYpyj6VxciqPkwmK4yHW8zMmPN1PW7Hk7F \\\n    --output-type address \\\n    --output-format base58check\n\n1KYv3U6gWcxS5UfbNzP25eDEjd5PHHB5Gh\n```\n\nShow address for compressed WIF private key:\n```\n$ ./bitcoin-tool \\\n    --input-type private-key-wif \\\n    --input-format base58check \\\n    --input KzXVLY4ni4yznz8LJwdUmNoGpUfebSxiakXRqcGAeuhihzaVe3Rz \\\n    --output-type address \\\n    --output-format base58check\n\n1Lm2DPqbhsutDkKoK9ZPPUkDKnGxQfpJLW\n```\nThis demonstrates why it is necessary to be careful when converting raw private\nkeys to addresses; the same private key will (almost definitely) result in two\nseperate addresses, one for each intermediate form of the public key.\n\nConvert the WIF private key to a QR code so we can print it and import it\neasily later:\n```\n$ qrencode -d 300 -s 3 -l H 5JZjfs5wJv1gNkJXCmYpyj6VxciqPkwmK4yHW8zMmPN1PW7Hk7F -o privkey.png\n```\n\nNow you can receive Bitcoins using the address above, but you will need to\nimport the private key into your wallet at a later time in order to spend them\n(`bitcoind importprivkey`, for the official client), or at least be able to\nsign transactions with that key (not necessarily online).\n\n#### Generate address from random private key\n```\n./bitcoin-tool \\\n    --network bitcoin \\\n    --input-type private-key \\\n    --input-format raw \\\n    --input-file <(openssl rand 32) \\\n    --output-type address \\\n    --output-format base58check \\\n    --public-key-compression compressed\n```\nThis outputs an address you can send Bitcoins to, if you want to loose them forever (because the private key is never output!).\n\n#### Poor-mans brainwallet\n\nHash a text phrase with SHA256, which is then used as the private key to generate an address from.\n\n**Never use this example for an actual wallet, it will be stolen almost immediately!** (I did a test with another dictionary word and it took all of 4 seconds for someone to steal it!)\n\nThis shows the `--output-type all` option, which spews out lots of unnecessary\ngarbage which I can't imagine would ever be useful, but it does so because it can.\nSo There.\n```\n./bitcoin-tool \\\n    --input-type private-key \\\n    --input-format raw \\\n    --input-file <(echo -n sausage|openssl dgst -sha256 -binary) \\\n    --public-key-compression uncompressed \\\n    --network bitcoin \\\n    --output-type all\n\naddress.hex:000511096ab078473911e0222fcbc3375314e2bab1\naddress.base58:156T6Af12SKCQGbjEWNeTkADhJNk\naddress.base58check:1TnnhMEgic5g4ttrCQyDopwqTs4hheuNZ\npublic-key-ripemd160.hex:0511096ab078473911e0222fcbc3375314e2bab1\npublic-key-ripemd160.base58:56T6Af12SKCQGbjEWNeTkADhJNk\npublic-key-ripemd160.base58check:TnnhMEgic5g4ttrCQyDopwqTs4k6XbAK\npublic-key-sha256.hex:b17978b7528353483429a758fb9ec833882a5ddbb27c1fc2bb4a66436f7e342f\npublic-key-sha256.base58:CwnbNMmu9yCkXE32543pfPAgVSynE2wjGYv9Mip4yrb8\npublic-key-sha256.base58check:2MAMBCve8eVyrbxxBzqn5HLNqqyc8CysKPdfaKPzA81mHxPvyu\npublic-key.hex:04a32ed011213146495f58d3ed83a6cc3fc0fd107d5fa2887bbc2fcea81e8bc84f650e81f4ddc84424daab546945f0d7d9dfd4dce39ce3776ee6b8ba78e6eddc7a\npublic-key.base58:QjfX2h4LdAA21NTa2K5dVcxcuQVTtvT3dL5JFLvxAMuCGKY3t8yCKNzJid8MHWbYmoHSRXAS9hggkhQUDiwaaGAV\npublic-key.base58check:3gKQTqtZhdBHDDe1echja7ac39tup3SnNSzwZSrnHb417QbL7T8JcTfW7GgEQsvhYrPqLsiraabne6xDrSGZ6bBB4S5YGM\nprivate-key-wif.hex:8030caae2fcb7c34ecadfddc45e0a27e9103bd7cfc87730d7818cc096b1266a683\nprivate-key-wif.base58:f5g1GA5uH4gsfEU6ANnGCzoe1VZvnZ1mYh3frnVSPR1nJ\nprivate-key-wif.base58check:5JBmuBc64pVrKLyDc8ktyXJmAeEwKQogn6jsk6taeq8zRMtGZrE\nprivate-key.hex:30caae2fcb7c34ecadfddc45e0a27e9103bd7cfc87730d7818cc096b1266a683\nprivate-key.base58:4HTpd7gVSeVJDurhJKYGEYyFWMZRCNjSnXaEcan9K6Gz\nprivate-key.base58check:NVKW9zzMvs4LawZwJztUZdx3R27Gwc4Hg6WvqqQxHMFkbn3Wz\n```\n", "release_dates": []}, {"name": "bls-signatures", "description": "BLS signatures in C++, using the relic toolkit", "language": "C", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# BLS Signatures implementation\n\n[![Build and Test C++, Javascript, and Python](https://github.com/Chia-Network/bls-signatures/actions/workflows/build-test.yaml/badge.svg)](https://github.com/Chia-Network/bls-signatures/actions/workflows/build-test.yaml)\n![PyPI](https://img.shields.io/pypi/v/blspy?logo=pypi)\n![PyPI - Format](https://img.shields.io/pypi/format/blspy?logo=pypi)\n![GitHub](https://img.shields.io/github/license/Chia-Network/bls-signatures?logo=Github)\n\n[![Total alerts](https://img.shields.io/lgtm/alerts/g/Chia-Network/bls-signatures.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/Chia-Network/bls-signatures/alerts/)\n[![Language grade: JavaScript](https://img.shields.io/lgtm/grade/javascript/g/Chia-Network/bls-signatures.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/Chia-Network/bls-signatures/context:javascript)\n[![Language grade: Python](https://img.shields.io/lgtm/grade/python/g/Chia-Network/bls-signatures.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/Chia-Network/bls-signatures/context:python)\n[![Language grade: C/C++](https://img.shields.io/lgtm/grade/cpp/g/Chia-Network/bls-signatures.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/Chia-Network/bls-signatures/context:cpp)\n\nNOTE: THIS LIBRARY IS NOT YET FORMALLY REVIEWED FOR SECURITY\n\nNOTE: THIS LIBRARY WAS SHIFTED TO THE IETF BLS SPECIFICATION ON 7/16/20\n\nImplements BLS signatures with aggregation using [relic toolkit](https://github.com/relic-toolkit/relic)\nfor cryptographic primitives (pairings, EC, hashing) according to the\n[IETF BLS RFC](https://datatracker.ietf.org/doc/draft-irtf-cfrg-bls-signature/)\nwith [these curve parameters](https://datatracker.ietf.org/doc/draft-irtf-cfrg-pairing-friendly-curves/)\nfor BLS12-381.\n\nFeatures:\n\n* Non-interactive signature aggregation following IETF specification\n* Works on Windows, Mac, Linux, BSD\n* Efficient verification using Proof of Posssesion (only one pairing per distinct message)\n* Aggregate public keys and private keys\n* [EIP-2333](https://eips.ethereum.org/EIPS/eip-2333) key derivation (including unhardened BIP-32-like keys)\n* Key and signature serialization\n* Batch verification\n* [Python bindings](https://github.com/Chia-Network/bls-signatures/tree/main/python-bindings)\n* [Pure python bls12-381 and signatures](https://github.com/Chia-Network/bls-signatures/tree/main/python-impl)\n* [JavaScript bindings](https://github.com/Chia-Network/bls-signatures/tree/main/js-bindings)\n\n## Before you start\n\nThis library uses minimum public key sizes (MPL). A G2Element is a signature (96 bytes), and a G1Element is a public key (48 bytes). A private key is a 32 byte integer. There are three schemes: Basic, Augmented, and ProofOfPossession. Augmented should be enough for most use cases, and ProofOfPossession can be used where verification must be fast.\n\n## Import the library\n\n```c++\n#include \"bls.hpp\"\nusing namespace bls;\n```\n\n## Creating keys and signatures\n\n```c++\n// Example seed, used to generate private key. Always use\n// a secure RNG with sufficient entropy to generate a seed (at least 32 bytes).\nvector<uint8_t> seed = {0,  50, 6,  244, 24,  199, 1,  25,  52,  88,  192,\n                        19, 18, 12, 89,  6,   220, 18, 102, 58,  209, 82,\n                        12, 62, 89, 110, 182, 9,   44, 20,  254, 22};\n\nPrivateKey sk = AugSchemeMPL().KeyGen(seed);\nG1Element pk = sk.GetG1Element();\n\nvector<uint8_t> message = {1, 2, 3, 4, 5};  // Message is passed in as a byte vector\nG2Element signature = AugSchemeMPL().Sign(sk, message);\n\n// Verify the signature\nbool ok = AugSchemeMPL().Verify(pk, message, signature);\n```\n\n## Serializing keys and signatures to bytes\n\n```c++\nvector<uint8_t> skBytes = sk.Serialize();\nvector<uint8_t> pkBytes = pk.Serialize();\nvector<uint8_t> signatureBytes = signature.Serialize();\n\ncout << Util::HexStr(skBytes) << endl;    // 32 bytes printed in hex\ncout << Util::HexStr(pkBytes) << endl;    // 48 bytes printed in hex\ncout << Util::HexStr(signatureBytes) << endl;  // 96 bytes printed in hex\n```\n\n## Loading keys and signatures from bytes\n\n```c++\n// Takes vector of 32 bytes\nPrivateKey skc = PrivateKey::FromByteVector(skBytes);\n\n// Takes vector of 48 bytes\npk = G1Element::FromByteVector(pkBytes);\n\n// Takes vector of 96 bytes\nsignature = G2Element::FromByteVector(signatureBytes);\n```\n\n## Create aggregate signatures\n\n```c++\n// Generate some more private keys\nseed[0] = 1;\nPrivateKey sk1 = AugSchemeMPL().KeyGen(seed);\nseed[0] = 2;\nPrivateKey sk2 = AugSchemeMPL().KeyGen(seed);\nvector<uint8_t> message2 = {1, 2, 3, 4, 5, 6, 7};\n\n// Generate first sig\nG1Element pk1 = sk1.GetG1Element();\nG2Element sig1 = AugSchemeMPL().Sign(sk1, message);\n\n// Generate second sig\nG1Element pk2 = sk2.GetG1Element();\nG2Element sig2 = AugSchemeMPL().Sign(sk2, message2);\n\n// Signatures can be non-interactively combined by anyone\nG2Element aggSig = AugSchemeMPL().Aggregate({sig1, sig2});\n\nok = AugSchemeMPL().AggregateVerify({pk1, pk2}, {message, message2}, aggSig);\n```\n\n## Arbitrary trees of aggregates\n\n```c++\nseed[0] = 3;\nPrivateKey sk3 = AugSchemeMPL().KeyGen(seed);\nG1Element pk3 = sk3.GetG1Element();\nvector<uint8_t> message3 = {100, 2, 254, 88, 90, 45, 23};\nG2Element sig3 = AugSchemeMPL().Sign(sk3, message3);\n\n\nG2Element aggSigFinal = AugSchemeMPL().Aggregate({aggSig, sig3});\nok = AugSchemeMPL().AggregateVerify({pk1, pk2, pk3}, {message, message2, message3}, aggSigFinal);\n\n```\n\n## Very fast verification with Proof of Possession scheme\n\n```c++\n// If the same message is signed, you can use Proof of Posession (PopScheme) for efficiency\n// A proof of possession MUST be passed around with the PK to ensure security.\n\nG2Element popSig1 = PopSchemeMPL().Sign(sk1, message);\nG2Element popSig2 = PopSchemeMPL().Sign(sk2, message);\nG2Element popSig3 = PopSchemeMPL().Sign(sk3, message);\nG2Element pop1 = PopSchemeMPL().PopProve(sk1);\nG2Element pop2 = PopSchemeMPL().PopProve(sk2);\nG2Element pop3 = PopSchemeMPL().PopProve(sk3);\n\nok = PopSchemeMPL().PopVerify(pk1, pop1);\nok = PopSchemeMPL().PopVerify(pk2, pop2);\nok = PopSchemeMPL().PopVerify(pk3, pop3);\nG2Element popSigAgg = PopSchemeMPL().Aggregate({popSig1, popSig2, popSig3});\n\nok = PopSchemeMPL().FastAggregateVerify({pk1, pk2, pk3}, message, popSigAgg);\n\n// Aggregate public key, indistinguishable from a single public key\nG1Element popAggPk = pk1 + pk2 + pk3;\nok = PopSchemeMPL().Verify(popAggPk, message, popSigAgg);\n\n// Aggregate private keys\nPrivateKey aggSk = PrivateKey::Aggregate({sk1, sk2, sk3});\nok = (PopSchemeMPL().Sign(aggSk, message) == popSigAgg);\n```\n\n## HD keys using [EIP-2333](https://github.com/ethereum/EIPs/pull/2333)\n\n```c++\n// You can derive 'child' keys from any key, to create arbitrary trees. 4 byte indeces are used.\n// Hardened (more secure, but no parent pk -> child pk)\nPrivateKey masterSk = AugSchemeMPL().KeyGen(seed);\nPrivateKey child = AugSchemeMPL().DeriveChildSk(masterSk, 152);\nPrivateKey grandChild = AugSchemeMPL().DeriveChildSk(child, 952)\n\n// Unhardened (less secure, but can go from parent pk -> child pk), BIP32 style\nG1Element masterPk = masterSk.GetG1Element();\nPrivateKey childU = AugSchemeMPL().DeriveChildSkUnhardened(masterSk, 22);\nPrivateKey grandchildU = AugSchemeMPL().DeriveChildSkUnhardened(childU, 0);\n\nG1Element childUPk = AugSchemeMPL().DeriveChildPkUnhardened(masterPk, 22);\nG1Element grandchildUPk = AugSchemeMPL().DeriveChildPkUnhardened(childUPk, 0);\n\nok = (grandchildUPk == grandchildU.GetG1Element();\n```\n\n## Build\n\nCmake 3.14+, a c++ compiler, and python3 (for bindings) are required for building.\n\n```bash\nmkdir build\ncd build\ncmake ../\ncmake --build . -- -j 6\n```\n\n### Run tests\n\n```bash\n./build/src/runtest\n```\n\n### Run benchmarks\n\n```bash\n./build/src/runbench\n```\n\nOn a 3.5 GHz i7 Mac, verification takes about 1.1ms per signature, and signing takes 1.3ms.\n\n### Link the library to use it\n\n```bash\ng++ -Wl,-no_pie -std=c++11  -Ibls-signatures/depends/relic/include -Ibls-signatures/build/depends/relic/include -Ibls-signatures/src -L./bls-signatures/build/ -l bls yourapp.cpp\n```\n\n## Notes on dependencies\n\nWe use Libsodium and have GMP as an optional dependency: libsodium gives secure memory\nallocation, and GMP speeds up the library by ~ 3x. MPIR is used on Windows via\nGitHub Actions instead. To install them, either download them from github and\nfollow the instructions for each repo, or use a package manager like APT or\nbrew. You can follow the recipe used to build python wheels for multiple\nplatforms in `.github/workflows/`.\n\n## Discussion\n\nDiscussion about this library and other Chia related development is in the #dev\nchannel of Chia's [public Keybase channels](https://keybase.io/team/chia_network.public).\n\n## Code style\n\n* Always use vector<uint8_t> for bytes\n* Use size_t for size variables\n* Uppercase method names\n* Prefer static constructors\n* Avoid using templates\n* Objects allocate and free their own memory\n* Use cpplint with default rules\n* Use SecAlloc and SecFree when handling secrets\n\n## ci Building\n\nThe primary build process for this repository is to use GitHub Actions to\nbuild binary wheels for MacOS, Linux (x64 and aarch64), and Windows and publish\nthem with a source wheel on PyPi. MacOS ARM64 is supported but not automated\ndue to a lack of M1 CI runners. See `.github/workflows/build.yml`. CMake uses\n[FetchContent](https://cmake.org/cmake/help/latest/module/FetchContent.html)\nto download [pybind11](https://github.com/pybind/pybind11) for the Python\nbindings and relic from a chia relic forked repository for Windows. Building\nis then managed by [cibuildwheel](https://github.com/joerick/cibuildwheel).\nFurther installation is then available via `pip install blspy` e.g. The ci\nbuilds include GMP and a statically linked libsodium.\n\n## Contributing and workflow\n\nContributions are welcome and more details are available in chia-blockchain's\n[CONTRIBUTING.md](https://github.com/Chia-Network/chia-blockchain/blob/main/CONTRIBUTING.md).\n\nThe main branch is usually the currently released latest version on PyPI.\nNote that at times bls-signatures/blspy will be ahead of the release version\nthat chia-blockchain requires in it's main/release version in preparation\nfor a new chia-blockchain release. Please branch or fork main and then create\na pull request to the main branch. Linear merging is enforced on main and\nmerging requires a completed review. PRs will kick off a GitHub actions ci\nbuild and analysis of bls-signatures at\n[lgtm.com](https://lgtm.com/projects/g/Chia-Network/bls-signatures/?mode=list).\nPlease make sure your build is passing and that it does not increase alerts\nat lgtm.\n\n## Specification and test vectors\n\nThe [IETF bls draft](https://datatracker.ietf.org/doc/draft-irtf-cfrg-hash-to-curve/)\nis followed. Test vectors can also be seen in the python and cpp test files.\n\n## Libsodium license\n\nThe libsodium static library is licensed under the ISC license which requires\nthe following copyright notice.\n\n>ISC License\n>\n>Copyright (c) 2013-2020\n>Frank Denis \\<j at pureftpd dot org\\>\n>\n>Permission to use, copy, modify, and/or distribute this software for any\n>purpose with or without fee is hereby granted, provided that the above\n>copyright notice and this permission notice appear in all copies.\n>\n>THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n>WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n>MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n>ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n>WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n>ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n>OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n## GMP license\n\nGMP is distributed under the\n[GNU LGPL v3 license](https://www.gnu.org/licenses/lgpl-3.0.html)\n\n## Relic license\n\nRelic is used with the\n[Apache 2.0 license](https://github.com/relic-toolkit/relic/blob/master/LICENSE.Apache-2.0)\n", "release_dates": ["2024-02-15T06:02:13Z"]}, {"name": "buildkit-cache-dance", "description": "Save `RUN --mount=type=cache` caches on GitHub Actions ( Forked from https://github.com/overmindtech/buildkit-cache-dance )", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# The BuildKit Cache Dance: save `RUN --mount=type=cache` caches on GitHub Actions\n\nThe BuildKit Cache Dance allows saving [`RUN --mount=type=cache`](https://docs.docker.com/build/guide/mounts/#add-a-cache-mount)\ncaches on GitHub Actions.\n\nUse cases:\n- apt-get (`/var/cache/apt`, `/var/lib/apt`)\n- Go (`/root/.cache/go-build`)\n- etc.\n\nThis [`reproducible-containers/buildkit-cache-dance`](https://github.com/reproducible-containers/buildkit-cache-dance) action was forked from\n[`overmindtech/buildkit-cache-dance`](https://github.com/overmindtech/buildkit-cache-dance/tree/306d31a77191f643c0c4a95083f36c6ddccb4a16)\n(archived on September 2023).\nThis action be used for \"non-reproducible\" containers too.\n\n## Examples\n### apt-get\nDockerfile:\n```dockerfile\nFROM ubuntu:22.04\nENV DEBIAN_FRONTEND=noninteractive\nRUN \\\n  --mount=type=cache,target=/var/cache/apt,sharing=locked \\\n  --mount=type=cache,target=/var/lib/apt,sharing=locked \\\n  rm -f /etc/apt/apt.conf.d/docker-clean && \\\n  echo 'Binary::apt::APT::Keep-Downloaded-Packages \"true\";' >/etc/apt/apt.conf.d/keep-cache && \\\n  apt-get update && \\\n  apt-get install -y gcc\n```\n\nAction:\n```yaml\n---\nname: Build\non: push\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v4\n      - uses: docker/setup-buildx-action@v3\n      - uses: docker/metadata-action@v5\n        id: meta\n        with:\n          images: YOUR_IMAGE\n      - name: Cache var-cache-apt\n        uses: actions/cache@v3\n        with:\n          path: var-cache-apt\n          key: var-cache-apt-${{ hashFiles('Dockerfile') }}\n      - name: Cache var-lib-apt\n        uses: actions/cache@v3\n        with:\n          path: var-lib-apt\n          key: var-lib-apt-${{ hashFiles('Dockerfile') }}\n      - name: inject var-cache-apt into docker\n        uses: reproducible-containers/buildkit-cache-dance@v2.1.3\n        with:\n          cache-source: var-cache-apt\n          cache-target: /var/cache/apt\n      - name: inject var-lib-apt into docker\n        uses: reproducible-containers/buildkit-cache-dance@v2.1.3\n        with:\n          cache-source: var-lib-apt\n          cache-target: /var/lib/apt\n      - name: Build and push\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n          file: Dockerfile\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n```\n\nReal-world examples:\n- <https://github.com/rootless-containers/slirp4netns/blob/v1.2.2/.github/workflows/release.yaml#L18-L36>\n- <https://github.com/containers/fuse-overlayfs/blob/40e0f3c/.github/workflows/release.yaml#L17-L36>\n\n## Releases\n### v1\nv1 follows the original design of [`overmindtech/buildkit-cache-dance`](https://github.com/overmindtech/buildkit-cache-dance/tree/306d31a77191f643c0c4a95083f36c6ddccb4a16).\n\nv1 is composed of two actions:\n- `reproducible-containers/buildkit-cache-dance/inject@v1.0.1`\n- `reproducible-containers/buildkit-cache-dance/extract@v1.0.1`\n\nSee the [`releases/v1`](https://github.com/reproducible-containers/buildkit-cache-dance/tree/releases/v1) branch.\n\n### v2\nv2 is composed of the single `reproducible-containers/buildkit-cache-dance` action.\n\n## Acknowledgement\n- Thanks to [Alexander Pravdin](https://github.com/speller) for the basic idea in [this comment](https://github.com/moby/buildkit/issues/1512).\n- Thanks to the authors of the original [`overmindtech/buildkit-cache-dance`](https://github.com/overmindtech/buildkit-cache-dance).\n", "release_dates": []}, {"name": "conventional-changelog-dash", "description": null, "language": "JavaScript", "license": {"key": "isc", "name": "ISC License", "spdx_id": "ISC", "url": "https://api.github.com/licenses/isc", "node_id": "MDc6TGljZW5zZTEw"}, "readme": "# [![Build Status][travis-image]][travis-url] [![Coverage Status][coveralls-image]][coveralls-url]\n\n## conventionalcommits.org convention\n\nA concrete implementation of the specification described at\n[conventionalcommits.org](https://conventionalcommits.org/) for automated\nCHANGELOG generation and version management.\n\n\n## Indirect Usage (as preset)\n\nUse the [Conventional Changelog CLI Quick Start](https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/conventional-changelog-cli#quick-start) with the `-p conventionalcommits` option.\n\n## Direct Usage (as a base preset so you can customize it)\n\nIf you want to use this package directly and pass options, you can use the [Conventional Changelog CLI Quick Start](https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/conventional-changelog-cli#quick-start) and with the `--config` or `-n` parameter, pass a js config that looks like this\n```\n'use strict'\nconst config = require('conventional-changelog-conventionalcommits')\n\nmodule.exports = config({\n    \"issuePrefixes\": [\"TEST-\"],\n    \"issueUrlFormat\": \"myBugTracker.com/{prefix}{id}\"\n})\n```\n\nor json config like that:\n```\n{\n    \"options\": {\n        \"preset\": {\n            \"name\": \"conventionalchangelog\",\n            \"issuePrefixes\": [\"TEST-\"],\n            \"issueUrlFormat\": \"myBugTracker.com/{prefix}{id}\"\n        }\n    }\n}\n```\nThis last json config way passes the `preset` object to the `conventional-changelog-preset-loader` package, that in turn, passes this same `preset` object as the config for the `conventional-changelog-conventionalcommits`.\n\n\n\nSee [conventional-changelog-config-spec](https://github.com/conventional-changelog/conventional-changelog-config-spec) for available\nconfiguration options.\n\n\n[travis-image]: https://travis-ci.org/conventional-changelog/conventional-changelog.svg?branch=master\n[travis-url]: https://travis-ci.org/conventional-changelog/conventional-changelog\n[coveralls-image]: https://coveralls.io/repos/conventional-changelog/conventional-changelog/badge.svg\n[coveralls-url]: https://coveralls.io/r/conventional-changelog/conventional-changelog\n", "release_dates": []}, {"name": "dapi-client-android", "description": "Dapi Client for Java/Android", "language": "Kotlin", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Dash DAPI Client for JVM\n\n[![License](https://img.shields.io/github/license/dashevo/dapi-client-android)](https://github.com/dashevo/dapi-client-android/blob/master/LICENSE)\n[![dashevo/android-dpp](https://tokei.rs/b1/github/dashevo/dapi-client-android?category=code)](https://github.com/dashevo/dapi-client-android)\n\n| Branch | Tests                                                                                      | Coverage                                                                                                                             | Linting                                                                    |\n|--------|--------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------|\n| master | [![Tests](https://github.com/dashevo/dapi-client-android/workflows/CI/badge.svg?branch=master)](https://github.com/dashevo/dapi-client-android/actions) | [![codecov](https://codecov.io/gh/dashevo/dapi-client-android/branch/master/graph/badge.svg)](https://codecov.io/gh/dashevo/dapi-client-android) | ![Lint](https://github.com/dashevo/dapi-client-android/workflows/Kotlin%20Linter/badge.svg) |\n\n\n\n# Build\nThis depends on the `android-dpp` library\n```\ngit clone https://github.com/github/dashevo/android-dpp.git\ncd android-dpp\n./gradlew assemble\n```\nBuild this library:\n```\ngit clone https://github.com/github/dashevo/dapi-client-android.git\ncd dapi-client-android\n./gradlew assemble\n```\n- After building, it will be available on the local Maven repository.\n- To use it with gradle, add `mavenLocal()` to the `repositories` list in your `build.gradle` file and add \n  `org.dashj.platform:dapi-client:0.23-SNAPSHOT` as dependency. \n\n# Usage\nAdd mavenCentral() to the `repositories` list in your `build.gradle`\n```groovy\ndependencies {\n    implementation 'org.dashj.platform:dpp:0.23-SNAPSHOT'\n}\n```\n\n# Tests\nRun tests with `gradle build test`\n\n# KtLint\nCheck using ktlint:\n```shell\n./gradlew ktlint\n```\nFormat using ktlint:\n```shell\n./gradlew ktlintFormat\n```\n\n# Updating DPP\nThe .proto files are located here: https://github.com/dashevo/dapi-grpc.git (`/protos` directory)\n\nIn this project, they are in the `/src/main/proto` directory\n\n# Publish to maven central\n```shell\n./gradlew uploadArchives\n```\n", "release_dates": []}, {"name": "darkcoin-sgminer", "description": null, "language": "C", "license": {"key": "gpl-3.0", "name": "GNU General Public License v3.0", "spdx_id": "GPL-3.0", "url": "https://api.github.com/licenses/gpl-3.0", "node_id": "MDc6TGljZW5zZTk="}, "readme": "# sgminer\n\n\n## Introduction\n\nThis is a multi-threaded multi-pool GPU miner with ATI GPU monitoring,\n(over)clocking and fanspeed support for scrypt-based coins. It is based on\ncgminer by Con Kolivas (ckolivas), which is in turn based on cpuminer by\nJeff Garzik (jgarzik).\n\n**releases**: https://github.com/veox/sgminer/releases\n\n**git tree**: https://github.com/veox/sgminer\n\n**issues**: https://github.com/veox/sgminer/issues\n\n**irc**: `#sgminer` on freenode\n\nLicense: GPLv3.  See `COPYING` for details.\n\n\n## Documentation\n\nDocumentation is available in directory `doc`. For details on several topics, see:\n\n* `API` for the RPC API specification;\n* `FAQ` for frequently asked questions;\n* `GPU` for semi-obsolete information on GPU configuration options and mining SHA256d-based coins;\n* `KERNEL.md` for OpenCL kernel-related information;\n* `MINING` for how to find the right balance in GPU configuration to mine Scrypt-based coins effectively;\n* `windows-build.txt` for information on how to build on Windows.\n\nNote that **most of the documentation is outdated**. If you want to contribute, fork this repository, update as needed, and submit a pull request.\n\n\n## Building\n\n### Dependencies\n\nMandatory:\n\n    curl dev library    http://curl.haxx.se/libcurl/\n    (libcurl4-openssl-dev)\n\n    pkg-config          http://www.freedesktop.org/wiki/Software/pkg-config\n    libtool             hhttp://www.gnu.org/software/libtool/\n\n    AMD APP SDK         http://developer.amd.com/tools-and-sdks/heterogeneous-computing/amd-accelerated-parallel-processing-app-sdk/downloads/\n\nOptional:\n\n    curses dev library\n    (libncurses5-dev or libpdcurses on WIN32 for text user interface)\n\n    AMD ADL SDK         http://developer.amd.com/tools-and-sdks/graphics-development/display-library-adl-sdk/\n    (Version 5 or 6, required for ATI GPU monitoring & clocking)\n\nIf building from git:\n\n    autoconf\n    automake\n\nsgminer-specific configuration options:\n\n    --disable-adl           Override detection and disable building with adl\n    --without-curses        Do not compile support for curses TUI\n\n### *nix build instructions\n\nIf needed, place include headers (`*.h` files) from `ADL_SDK_*<VERSION>*.zip` in `sgminer/ADL_SDK`.\n\nThen:\n\n    autoreconf -i\n    CFLAGS=\"-O2 -Wall -march=native\" ./configure <options>\n    make\n\nTo compile a debug version, replace `-O2` with `-ggdb`.\n\nSystemwide installation is optional. You may run `sgminer` from the build\ndirectory directly, or `make install` if you wish to install\n`sgminer` to a system location or a location you specified with `--prefix`.\n\n### Windows build instructions\n\nSee `doc/windows-build.txt` (might be outdated).\n\n\n## Basic Usage\n\n**WARNING**: documentation below this point has not been updated since the\nfork.\n\nAfter saving configuration from the menu, you do not need to give sgminer\nany arguments and it will load your configuration.\n\nAny configuration file may also contain a single\n\n    \"include\" : \"filename\"\n\nto recursively include another configuration file.\n\nWriting the configuration will save all settings from all files in the\noutput.\n\nSingle pool:\n\nsgminer -o http://pool:port -u username -p password\n\nMultiple pools:\n\nsgminer -o http://pool1:port -u pool1username -p pool1password -o http://pool2:port -u pool2usernmae -p pool2password\n\nSingle pool with a standard http proxy, regular desktop:\n\nsgminer -o \"http:proxy:port|http://pool:port\" -u username -p password\n\nSingle pool with a socks5 proxy, regular desktop:\n\nsgminer -o \"socks5:proxy:port|http://pool:port\" -u username -p password\n\nSingle pool with stratum protocol support:\n\nsgminer -o stratum+tcp://pool:port -u username -p password\n\nThe list of proxy types are:\n http:    standard http 1.1 proxy\n http0:   http 1.0 proxy\n socks4:  socks4 proxy\n socks5:  socks5 proxy\n socks4a: socks4a proxy\n socks5h: socks5 proxy using a hostname\n\nIf you compile sgminer with a version of CURL before 7.19.4 then some of\nthe above will not be available. All are available since CURL version\n7.19.4.\n\nIf you specify the --socks-proxy option to sgminer, it will only be\napplied to all pools that don't specify their own proxy setting like\nabove.\n\nFor more advanced usage , run `sgminer --help`.\n\nSee `doc/GPU` for more information regarding GPU mining and\n`doc/SCRYPT` for more information regarding Scrypt mining.\n\n\n## Runtime usage\n\nThe following options are available while running with a single keypress:\n\n[P]ool management [G]PU management [S]ettings [D]isplay options [Q]uit\n\nP gives you:\n\nCurrent pool management strategy: Failover\n[F]ailover only disabled\n[A]dd pool [R]emove pool [D]isable pool [E]nable pool\n[C]hange management strategy [S]witch pool [I]nformation\n\n\nS gives you:\n\n[Q]ueue: 1\n[S]cantime: 60\n[E]xpiry: 120\n[W]rite config file\n[C]gminer restart\n\n\nD gives you:\n\n[N]ormal [C]lear [S]ilent mode (disable all output)\n[D]ebug:off\n[P]er-device:off\n[Q]uiet:off\n[V]erbose:off\n[R]PC debug:off\n[W]orkTime details:off\nco[M]pact: off\n[L]og interval:5\n\n\nQ quits the application.\n\n\nG gives you something like:\n\nGPU 0: [124.2 / 191.3 Mh/s] [A:77  R:33  HW:0  U:1.73/m  WU 1.73/m]\nTemp: 67.0 C\nFan Speed: 35% (2500 RPM)\nEngine Clock: 960 MHz\nMemory Clock: 480 Mhz\nVddc: 1.200 V\nActivity: 93%\nPowertune: 0%\nLast initialised: [2011-09-06 12:03:56]\nThread 0: 62.4 Mh/s Enabled ALIVE\nThread 1: 60.2 Mh/s Enabled ALIVE\n\n[E]nable [D]isable [R]estart GPU [C]hange settings\nOr press any other key to continue\n\n\nThe running log shows output like this:\n\n [2012-10-12 18:02:20] Accepted f0c05469 Diff 1/1 GPU 0 pool 1\n [2012-10-12 18:02:22] Accepted 218ac982 Diff 7/1 GPU 1 pool 1\n [2012-10-12 18:02:23] Accepted d8300795 Diff 1/1 GPU 3 pool 1\n [2012-10-12 18:02:24] Accepted 122c1ff1 Diff 14/1 GPU 1 pool 1\n\nThe 8 byte hex value are the 2nd 8 bytes of the share being submitted to the\npool. The 2 diff values are the actual difficulty target that share reached\nfollowed by the difficulty target the pool is currently asking for.\n\nThe output line shows the following:\n(5s):1713.6 (avg):1707.8 Mh/s | A:729  R:8  HW:0  WU:22.53/m\n\nEach column is as follows:\n5s:  A 5 second exponentially decaying average hash rate\navg: An all time average hash rate\nA:  The total difficulty of Accepted shares\nR:  The total difficulty of Rejected shares\nHW:  The number of HardWare errors\nWU:  The Work Utility defined as the number of diff1 shares work / minute\n     (accepted or rejected).\n\n GPU 1: 73.5C 2551RPM | 427.3/443.0Mh/s | A:8 R:0 HW:0 WU:4.39/m\n\nEach column is as follows:\nTemperature (if supported)\nFanspeed (if supported)\nA 5 second exponentially decaying average hash rate\nAn all time average hash rate\nThe total difficulty of accepted shares\nThe total difficulty of rejected shares\nThe number of hardware erorrs\nThe work utility defined as the number of diff1 shares work / minute\n\nThe sgminer status line shows:\n ST: 1  SS: 0  NB: 1  LW: 8  GF: 1  RF: 1\n\nST is STaged work items (ready to use).\nSS is Stale Shares discarded (detected and not submitted so don't count as rejects)\nNB is New Blocks detected on the network\nLW is Locally generated Work items\nGF is Getwork Fail Occasions (server slow to provide work)\nRF is Remote Fail occasions (server slow to accept work)\n\nThe block display shows:\nBlock: 0074c5e482e34a506d2a051a...  Started: [17:17:22]  Best share: 2.71K\n\nThis shows a short stretch of the current block, when the new block started,\nand the all time best difficulty share you've found since starting sgminer\nthis time.\n\n\n## Multipool\n\n### Failover strategies\n\nA number of different strategies for dealing with multipool setups are\navailable. Each has their advantages and disadvantages so multiple strategies\nare available by user choice, as per the following list:\n\n#### Failover\n\nThe default strategy is failover. This means that if you input a number of\npools, it will try to use them as a priority list, moving away from the 1st\nto the 2nd, 2nd to 3rd and so on. If any of the earlier pools recover, it will\nmove back to the higher priority ones.\n\n#### Round robin\n\nThis strategy only moves from one pool to the next when the current one falls\nidle and makes no attempt to move otherwise.\n\n#### Rotate\n\nThis strategy moves at user-defined intervals from one active pool to the next,\nskipping pools that are idle.\n\n#### Load balance\n\nThis strategy sends work to all the pools on a quota basis. By default, all\npools are allocated equal quotas unless specified with --quota. This\napportioning of work is based on work handed out, not shares returned so is\nindependent of difficulty targets or rejected shares. While a pool is disabled\nor dead, its quota is dropped until it is re-enabled. Quotas are forward\nlooking, so if the quota is changed on the fly, it only affects future work.\nIf all pools are set to zero quota or all pools with quota are dead, it will\nfall back to a failover mode. See quota below for more information.\n\nThe failover-only flag has special meaning in combination with load-balance\nmode and it will distribute quota back to priority pool 0 from any pools that\nare unable to provide work for any reason so as to maintain quota ratios\nbetween the rest of the pools.\n\n#### Balance\n\nThis strategy monitors the amount of difficulty 1 shares solved for each pool\nand uses it to try to end up doing the same amount of work for all pools.\n\n\n### Quotas\n\nThe load-balance multipool strategy works off a quota based scheduler. The\nquotas handed out by default are equal, but the user is allowed to specify any\narbitrary ratio of quotas. For example, if all the quota values add up to 100,\neach quota value will be a percentage, but if 2 pools are specified and pool0\nis given a quota of 1 and pool1 is given a quota of 9, pool0 will get 10% of\nthe work and pool1 will get 90%. Quotas can be changed on the fly by the API,\nand do not act retrospectively. Setting a quota to zero will effectively\ndisable that pool unless all other pools are disabled or dead. In that\nscenario, load-balance falls back to regular failover priority-based strategy.\nWhile a pool is dead, it loses its quota and no attempt is made to catch up\nwhen it comes back to life.\n\nTo specify quotas on the command line, pools should be specified with a\nsemicolon separated --quota(or -U) entry instead of --url. Pools specified with\n--url are given a nominal quota value of 1 and entries can be mixed.\n\nFor example:\n--url poola:porta -u usernamea -p passa --quota \"2;poolb:portb\" -u usernameb -p passb\nWill give poola 1/3 of the work and poolb 2/3 of the work.\n\nWriting configuration files with quotas is likewise supported. To use\nthe above quotas in a configuration file they would be specified thus:\n\n    \"pools\" : [\n        {\n                \"url\" : \"poola:porta\",\n                \"user\" : \"usernamea\",\n                \"pass\" : \"passa\"\n        },\n        {\n                \"quota\" : \"2;poolb:portb\",\n                \"user\" : \"usernameb\",\n                \"pass\" : \"passb\"\n        }\n    ]\n\n\n### Extra File Configuration\n\nIf you want to store a number of pools in your configuration file, but\ndon't always want them automatically enabled at start up (or restart),\nthen the \"state\" option with a value of \"disabled\" can be used:\n\n    \"pools\" : [\n        {\n                \"url\" : \"poola:porta\",\n                \"user\" : \"usernamea\",\n                \"pass\" : \"passa\"\n        },\n        {\n                \"quota\" : \"2;poolb:portb\",\n                \"user\" : \"usernameb\",\n                \"pass\" : \"passb\",\n                \"state\" : \"disabled\"\n        }\n    ]\n\nIt is then trivial to change the \"state\" setting to \"enabled\" in the\nconfiguration file at anytime and then restart the miner (see below).\nYou can enable the pool whilst the miner is still running ('p' followed\nby 'e' followed by pool number) - but the pool will still be disabled on\nrestart if the config file is not changed.\n\n\"state\" can also be set to \"hidden\". This allows the json file to\ncontain a large number of pools, of which some could be automatically\nculled at start up. This makes it easy to swap pools in and out of the\nruntime selection, without having a large list of pools cluttering up\nthe display.\n\n    \"pools\" : [\n        {\n                \"poolname\" : \"Main Pool\",\n                \"url\" : \"poola:porta\",\n                \"user\" : \"usernamea\",\n                \"pass\" : \"passa\",\n                \"state\" : \"disabled\"\n        },\n        {\n                \"poolname\" : \"Joe's Weekend Pool\",\n                \"quota\" : \"2;poolb:portb\",\n                \"user\" : \"usernameb\",\n                \"pass\" : \"passb\",\n                \"state\" : \"hidden\"\n        }\n    ]\n\nThese options are considered experimental and therefore will NOT be\ncreated when the 'Write config file' option is used ('s' followed by\n'w').\n\nA restart of the miner ('s' followed by 'c') will reload the config\nfile and any changes that may have been made.\n\n\n## Logging\n\nsgminer will log to stderr if it detects stderr is being redirected to a\nfile. To enable logging simply append `2>logfile.txt` to your command line\nand `logfile.txt` will contain the logged output at the log level you\nspecify (normal, verbose, debug etc.)\n\nThere is also the -m option on Linux which will spawn a command of your choice\nand pipe the output directly to that command.\n\nThe WorkTime details 'debug' option adds details on the end of each line\ndisplayed for Accepted or Rejected work done. An example would be:\n\n <-00000059.ed4834a3 M:X D:1.0 G:17:02:38:0.405 C:1.855 (2.995) W:3.440 (0.000) S:0.461 R:17:02:47\n\nThe first 2 hex codes are the previous block hash, the rest are reported in\nseconds unless stated otherwise:\nThe previous hash is followed by the getwork mode used M:X where X is one of\nP:Pool, T:Test Pool, L:LP or B:Benchmark,\nthen D:d.ddd is the difficulty required to get a share from the work,\nthen G:hh:mm:ss:n.nnn, which is when the getwork or LP was sent to the pool and\nthe n.nnn is how long it took to reply,\nfollowed by 'O' on it's own if it is an original getwork, or 'C:n.nnn' if it was\na clone with n.nnn stating how long after the work was recieved that it was cloned,\n(m.mmm) is how long from when the original work was received until work started,\nW:n.nnn is how long the work took to process until it was ready to submit,\n(m.mmm) is how long from ready to submit to actually doing the submit, this is\nusually 0.000 unless there was a problem with submitting the work,\nS:n.nnn is how long it took to submit the completed work and await the reply,\nR:hh:mm:ss is the actual time the work submit reply was received\n\nIf you start sgminer with the --sharelog option, you can get detailed\ninformation for each share found. The argument to the option may be \"-\" for\nstandard output (not advisable with the ncurses UI), any valid positive number\nfor that file descriptor, or a filename.\n\nTo log share data to a file named \"share.log\", you can use either:\n./sgminer --sharelog 50 -o xxx -u yyy -p zzz 50>share.log\n./sgminer --sharelog share.log -o xxx -u yyy -p zzz\n\nFor every share found, data will be logged in a CSV (Comma Separated Value)\nformat:\n    timestamp,disposition,target,pool,dev,thr,sharehash,sharedata\nFor example (this is wrapped, but it's all on one line for real):\n    1335313090,reject,\n    ffffffffffffffffffffffffffffffffffffffffffffffffffffffff00000000,\n    http://localhost:8337,GPU0,0,\n    6f983c918f3299b58febf95ec4d0c7094ed634bc13754553ec34fc3800000000,\n    00000001a0980aff4ce4a96d53f4b89a2d5f0e765c978640fe24372a000001c5\n    000000004a4366808f81d44f26df3d69d7dc4b3473385930462d9ab707b50498\n    f681634a4f1f63d01a0cd43fb338000000000080000000000000000000000000\n    0000000000000000000000000000000000000000000000000000000080020000\n", "release_dates": []}, {"name": "dash", "description": "Dash - Reinventing Cryptocurrency", "language": "C++", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "Dash Core staging tree\n===========================\n\n|CI|master|develop|\n|-|-|-|\n|Gitlab|[![Build Status](https://gitlab.com/dashpay/dash/badges/master/pipeline.svg)](https://gitlab.com/dashpay/dash/-/tree/master)|[![Build Status](https://gitlab.com/dashpay/dash/badges/develop/pipeline.svg)](https://gitlab.com/dashpay/dash/-/tree/develop)|\n\nhttps://www.dash.org\n\nFor an immediately usable, binary version of the Dash Core software, see\nhttps://www.dash.org/downloads/.\n\nFurther information about Dash Core is available in the [doc folder](/doc).\n\nWhat is Dash?\n-------------\n\nDash is an experimental digital currency that enables instant, private\npayments to anyone, anywhere in the world. Dash uses peer-to-peer technology\nto operate with no central authority: managing transactions and issuing money\nare carried out collectively by the network. Dash Core is the name of the open\nsource software which enables the use of this currency.\n\n\nFor more information read the original Dash whitepaper.\n\nLicense\n-------\n\nDash Core is released under the terms of the MIT license. See [COPYING](COPYING) for more\ninformation or see https://opensource.org/licenses/MIT.\n\nDevelopment Process\n-------------------\n\nThe `master` branch is meant to be stable. Development is normally done in separate branches.\n[Tags](https://github.com/dashpay/dash/tags) are created to indicate new official,\nstable release versions of Dash Core.\n\nThe contribution workflow is described in [CONTRIBUTING.md](CONTRIBUTING.md)\nand useful hints for developers can be found in [doc/developer-notes.md](doc/developer-notes.md).\n\nTesting\n-------\n\nTesting and code review is the bottleneck for development; we get more pull\nrequests than we can review and test on short notice. Please be patient and help out by testing\nother people's pull requests, and remember this is a security-critical project where any mistake might cost people\nlots of money.\n\n### Automated Testing\n\nDevelopers are strongly encouraged to write [unit tests](src/test/README.md) for new code, and to\nsubmit new unit tests for old code. Unit tests can be compiled and run\n(assuming they weren't disabled in configure) with: `make check`. Further details on running\nand extending unit tests can be found in [/src/test/README.md](/src/test/README.md).\n\nThere are also [regression and integration tests](/test), written\nin Python.\nThese tests can be run (if the [test dependencies](/test) are installed) with: `test/functional/test_runner.py`\n\nThe Travis CI system makes sure that every pull request is built for Windows, Linux, and macOS, and that unit/sanity tests are run automatically.\n\n### Manual Quality Assurance (QA) Testing\n\nChanges should be tested by somebody other than the developer who wrote the\ncode. This is especially important for large or high-risk changes. It is useful\nto add a test plan to the pull request description if testing the changes is\nnot straightforward.\n\nTranslations\n------------\n\nChanges to translations as well as new translations can be submitted to\n[Dash Core's Transifex page](https://www.transifex.com/projects/p/dash/).\n\nTranslations are periodically pulled from Transifex and merged into the git repository. See the\n[translation process](doc/translation_process.md) for details on how this works.\n\n**Important**: We do not accept translation changes as GitHub pull requests because the next\npull from Transifex would automatically overwrite them again.\n", "release_dates": ["2024-02-26T17:01:17Z", "2024-02-21T18:53:57Z", "2024-01-13T19:28:31Z", "2023-12-27T16:56:07Z", "2023-12-06T03:31:59Z", "2023-11-18T19:38:08Z", "2023-11-15T16:28:00Z", "2023-11-08T01:22:17Z", "2023-10-31T09:18:57Z", "2023-10-24T17:29:42Z", "2023-10-20T20:49:24Z", "2023-10-20T16:52:58Z", "2023-10-19T11:21:33Z", "2023-10-09T19:13:48Z", "2023-09-28T02:37:26Z", "2023-09-05T20:02:09Z", "2023-07-31T16:40:58Z", "2023-06-19T17:16:00Z", "2023-06-14T15:58:00Z", "2023-05-22T17:31:55Z", "2023-04-14T17:32:55Z", "2023-04-06T21:19:59Z", "2023-04-02T05:03:30Z", "2023-03-23T16:14:48Z", "2023-03-21T04:57:15Z", "2023-03-21T15:39:22Z", "2023-03-13T17:56:23Z", "2023-03-02T18:52:48Z", "2023-03-02T02:56:23Z", "2023-02-23T00:36:16Z"]}, {"name": "dash-abe", "description": "Block explorer for Dash based on bitcoin-abe", "language": "Python", "license": {"key": "agpl-3.0", "name": "GNU Affero General Public License v3.0", "spdx_id": "AGPL-3.0", "url": "https://api.github.com/licenses/agpl-3.0", "node_id": "MDc6TGljZW5zZTE="}, "readme": "Abe: a free block chain browser for Bitcoin-based currencies.\r\nhttps://github.com/bitcoin-abe/bitcoin-abe\r\n\r\n    Copyright(C) 2011,2012,2013 by Abe developers.\r\n    License: GNU Affero General Public License, see the file LICENSE.txt.\r\n    Portions Copyright (c) 2010 Gavin Andresen, see bct-LICENSE.txt.\r\n\r\nWelcome to Abe!\r\n===============\r\n\r\nThis software reads the Bitcoin block file, transforms and loads the\r\ndata into a database, and presents a web interface similar to Bitcoin\r\nBlock Explorer, http://blockexplorer.com/.\r\n\r\nAbe draws inspiration from Bitcoin Block Explorer (BBE) and\r\nBlockChain.info and seeks some level of compatibility with them but\r\nuses a completely new implementation.\r\n\r\nInstallation\r\n------------\r\n\r\nIssue:\r\n\r\n    python setup.py install\r\n\r\nThis will install abe to your system. After you set up the config file and\r\ndatabase (see below and README-<DB>.txt) you can run:\r\n\r\n    python -m Abe.abe --config myconf.conf --commit-bytes 100000 --no-serve\r\n    \r\nThis will perform the initial data load and will take a long time.\r\nAfter it's fully synced, you can run the web server with: \r\n\r\n    python -m Abe.abe --config myconf.conf\r\n    \r\nTo really get everything right see the README file for your type of\r\ndatabase.\r\n\r\nAbe depends on Python 2.7 (or 2.6), the pycrypto package, and an SQL\r\ndatabase supporting ROLLBACK.  Abe runs on PostgreSQL, MySQL's InnoDB\r\nengine, and SQLite.  Other SQL databases may work with minor changes.\r\nAbe formerly ran on some ODBC configurations, Oracle, and IBM DB2, but\r\nwe have not tested to be sure it still works.  See the comments in\r\nabe.conf about dbtype for configuration examples.\r\n\r\nAbe works with files created by the original (Satoshi) Bitcoin client.\r\nYou will need a copy of the block files (blk0001.dat, blk0002.dat,\r\netc. in your Bitcoin directory or its blocks/ subdirectory).  You may\r\nlet Abe read the block files while Bitcoin runs, assuming Bitcoin only\r\nappends to the file.  Prior to Bitcoin v0.8, this assumption seemed\r\nsafe.  Abe may need some fixes to avoid skipping blocks while current\r\nand future Bitcoin versions run.\r\n\r\nNovaCoin and CryptoCash support depends on the ltc_scrypt module\r\navailable from https://github.com/CryptoManiac/bitcoin-abe (see\r\nREADME-SCRYPT.txt).\r\n\r\nHirocoin (and any other X11) support depends on the xcoin_hash module\r\navailable from https://github.com/evan82/xcoin-hash.\r\n\r\nBitleu (a Scrypt-Jane coin) depends on the yac_scrypt module.\r\n\r\nCopperlark (a Keccak coin) depends on the sha3 module available via\r\n\"easy_install pysha3\".\r\n\r\nLicense\r\n-------\r\n\r\nThe GNU Affero General Public License (LICENSE.txt) requires whoever\r\nmodifies this code and runs it on a server to make the modified code\r\navailable to users of the server.  You may do this by forking the\r\nGithub project (if you received this code from Github.com), keeping\r\nyour modifications in the new project, and linking to it in the page\r\ntemplate.  Or you may wish to satisfy the requirement by simply\r\npassing \"--auto-agpl\" to \"python -m Abe.abe\".  This option makes all\r\nfiles in the directory containing abe.py and its subdirectories\r\navailable to clients.  See the comments in abe.conf for more\r\ninformation.\r\n\r\nDatabase\r\n--------\r\n\r\nFor usage, run \"python -m Abe.abe --help\" and see the comments in\r\nabe.conf.\r\n\r\nYou will have to specify a database driver and connection arguments\r\n(dbtype and connect-args in abe.conf).  The dbtype is the name of a\r\nPython module that supports your database.  Known to work are psycopg2\r\n(for PostgreSQL) and sqlite3.  The value of connect-args depends on\r\nyour database configuration; consult the module's documentation of the\r\nconnect() method.\r\n\r\nYou may specify connect-args in any of the following forms:\r\n\r\n* omit connect-args to call connect() with no arguments\r\n\r\n* named arguments as a JSON object, e.g.:\r\n  connect-args = { \"database\": \"abe\", \"password\": \"b1tc0!n\" }\r\n\r\n* positional arguments as a JSON array, e.g.:\r\n  connect-args = [\"abe\", \"abe\", \"b1tc0!n\"]\r\n\r\n* a single string argument on one line, e.g.:\r\n  connect-args = /var/lib/abe/abe.sqlite\r\n\r\nFor JSON syntax, see http://www.json.org.\r\n\r\nSlow startup\r\n------------\r\n\r\nReading the block files takes much too long, several days or more for\r\nthe main BTC block chain as of 2013.  However, if you use a persistent\r\ndatabase, Abe remembers where it stopped reading and starts more\r\nquickly the second time.\r\n\r\nReplacing the Block File\r\n------------------------\r\n\r\nAbe does not currently handle block file changes gracefully.  If you\r\nreplace your copy of the block chain, you must rebuild Abe's database\r\nor (quicker) force a rescan.  To force a rescan of all data\r\ndirectories, run Abe once with the \"--rescan\" option.\r\n\r\nWeb server\r\n----------\r\n\r\nBy default, Abe expects to be run in a FastCGI environment.  For an\r\noverview of FastCGI setup, see README-FASTCGI.txt.\r\n\r\nTo run the built-in HTTP server instead of FastCGI, specify a TCP port\r\nand network interface in abe.conf, e.g.:\r\n\r\n    port 2750\r\n    host 127.0.0.1  # or a domain name\r\n\r\nInput\r\n-----\r\n\r\nTo display Namecoin, NovaCoin, or any block chain with data somewhere\r\nother than the default Bitcoin directory, specify \"datadir\" in\r\nabe.conf, e.g.:\r\n\r\n    datadir = /home/bitcoin/.namecoin\r\n\r\nThe datadir directive can include a new chain's basic configuration,\r\ne.g.:\r\n\r\n    datadir += [{\r\n            \"dirname\": \"/home/weeds/testnet\",\r\n            \"chain\":   \"Weeds\",\r\n            \"code3\":   \"WDS\",\r\n            \"address_version\": \"o\" }]\r\n\r\nNote that \"+=\" adds to the existing datadir configuration, while \"=\"\r\nreplaces it.  For help with address_version, please open doc/FAQ.html\r\nin a web browser.\r\n\r\nThe web interface is currently unaware of name transactions, but see\r\nnamecoin_dump.py in the tools directory.\r\n\r\nMore information\r\n----------------\r\n\r\nPlease see TODO.txt for a list of what is not yet implemented but\r\nwould like to be.\r\n\r\nForum thread: https://bitcointalk.org/index.php?topic=22785.0\r\nNewbies: https://bitcointalk.org/index.php?topic=51139.0\r\n\r\nDonations appreciated: 1PWC7PNHL1SgvZaN7xEtygenKjWobWsCuf (BTC)\r\nNJ3MSELK1cWnqUa6xhF2wUYAnz3RSrWXcK (NMC)\r\n", "release_dates": []}, {"name": "dash-binaries", "description": null, "language": "Shell", "license": null, "readme": null, "release_dates": []}, {"name": "dash-detached-sigs", "description": null, "language": null, "license": null, "readme": "# dash-detached-sigs", "release_dates": []}, {"name": "dash-dev-branches", "description": "DashCore branches which are not yet production-ready. Use at your own risk! For devnets only.", "language": "C++", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "Dash Core staging tree 18.0\n===========================\n\n|CI|master|develop|\n|-|-|-|\n|Gitlab|[![Build Status](https://gitlab.com/dashpay/dash/badges/master/pipeline.svg)](https://gitlab.com/dashpay/dash/-/tree/master)|[![Build Status](https://gitlab.com/dashpay/dash/badges/develop/pipeline.svg)](https://gitlab.com/dashpay/dash/-/tree/develop)|\n\nhttps://www.dash.org\n\n\nWhat is Dash?\n-------------\n\nDash is an experimental digital currency that enables instant, private\npayments to anyone, anywhere in the world. Dash uses peer-to-peer technology\nto operate with no central authority: managing transactions and issuing money\nare carried out collectively by the network. Dash Core is the name of the open\nsource software which enables the use of this currency.\n\nPre-Built Binary\n----------------\n\nFor more information, as well as an immediately usable, binary version of\nthe Dash Core software, see https://www.dash.org/downloads/.\n\nLicense\n-------\n\nDash Core is released under the terms of the MIT license. See [COPYING](COPYING) for more\ninformation or see https://opensource.org/licenses/MIT.\n\nDevelopment Process\n-------------------\n\nThe `master` branch is meant to be stable. Development is normally done in separate branches.\n[Tags](https://github.com/dashpay/dash/tags) are created to indicate new official,\nstable release versions of Dash Core.\n\nThe contribution workflow is described in [CONTRIBUTING.md](CONTRIBUTING.md)\nand useful hints for developers can be found in [doc/developer-notes.md](doc/developer-notes.md).\n\nTesting\n-------\n\nTesting and code review is the bottleneck for development; we get more pull\nrequests than we can review and test on short notice. Please be patient and help out by testing\nother people's pull requests, and remember this is a security-critical project where any mistake might cost people\nlots of money.\n\n### Automated Testing\n\nDevelopers are strongly encouraged to write [unit tests](src/test/README.md) for new code, and to\nsubmit new unit tests for old code. Unit tests can be compiled and run\n(assuming they weren't disabled in configure) with: `make check`. Further details on running\nand extending unit tests can be found in [/src/test/README.md](/src/test/README.md).\n\nThere are also [regression and integration tests](/test), written\nin Python, that are run automatically on the build server.\nThese tests can be run (if the [test dependencies](/test) are installed) with: `test/functional/test_runner.py`\n\nThe Travis CI system makes sure that every pull request is built for Windows, Linux, and macOS, and that unit/sanity tests are run automatically.\n\n### Manual Quality Assurance (QA) Testing\n\nChanges should be tested by somebody other than the developer who wrote the\ncode. This is especially important for large or high-risk changes. It is useful\nto add a test plan to the pull request description if testing the changes is\nnot straightforward.\n\nTranslations\n------------\n\nChanges to translations as well as new translations can be submitted to\n[Dash Core's Transifex page](https://www.transifex.com/projects/p/dash/).\n\nTranslations are periodically pulled from Transifex and merged into the git repository. See the\n[translation process](doc/translation_process.md) for details on how this works.\n\n**Important**: We do not accept translation changes as GitHub pull requests because the next\npull from Transifex would automatically overwrite them again.\n\nTranslators should also follow the [forum](https://www.dash.org/forum/topic/dash-worldwide-collaboration.88/).\n", "release_dates": ["2024-03-03T17:48:22Z", "2024-03-02T17:55:14Z", "2024-03-01T17:46:08Z", "2024-02-29T17:50:55Z", "2024-02-28T17:51:16Z", "2024-02-29T00:43:22Z", "2024-02-27T17:48:14Z", "2024-02-26T16:01:31Z", "2024-02-19T17:28:01Z", "2024-02-18T17:27:37Z", "2024-02-17T17:29:06Z", "2024-02-16T17:26:29Z", "2024-02-15T07:07:37Z", "2024-02-15T17:39:29Z", "2024-02-14T17:48:43Z", "2024-02-14T17:24:26Z", "2024-02-14T16:55:27Z", "2024-02-13T17:26:22Z", "2024-02-12T17:27:07Z", "2024-02-11T17:25:30Z", "2024-02-10T17:24:09Z", "2024-02-09T17:26:29Z", "2024-02-08T17:46:56Z", "2024-02-07T18:39:34Z", "2024-02-06T18:41:13Z", "2024-02-05T17:48:21Z", "2024-02-04T17:46:12Z", "2024-02-03T17:25:21Z", "2024-02-02T17:23:40Z", "2024-02-01T17:57:47Z"]}, {"name": "dash-network-ci", "description": null, "language": "Shell", "license": null, "readme": null, "release_dates": []}, {"name": "dash-network-deploy", "description": "Tools for Dash networks deployment and testing", "language": "HCL", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Dash Network Deployment Tool\n\n[![Latest Release](https://img.shields.io/github/v/release/dashevo/dash-network-deploy)](https://github.com/dashevo/dash-network-deploy/releases/latest)\n[![Build Status](https://github.com/dashevo/dash-network-deploy/actions/workflows/release.yml/badge.svg)](https://github.com/dashevo/dash-network-deploy/actions/workflows/release.yml)\n[![Release Date](https://img.shields.io/github/release-date/dashevo/dash-network-deploy)](https://img.shields.io/github/release-date/dashevo/dash-network-deploy)\n[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen)](https://github.com/RichardLitt/standard-readme)\n\n## Introduction\n\nThis tool assists in deploying and managing Dash networks.\n\nThere are two regular available networks: `testnet` and `mainnet`.\nAfter deployment your DashCore instances will join those networks.\n\n`regtest` and `devnet-*` networks are for testing purposes.\nDevnets are like regular Dash networks (`mainnet` and `testnet`)\nbut easier to bootstrap and with unique names. This supports maintaining multiple in parallel.\n\nThis is work in progress and in its initial state only meant to be used by\nDash Core developers to assist in Dash Platform development.\n\n## Installation\n\n1. [Install Docker](https://docs.docker.com/install/)\n2. Download tool:\n\n    Using `wget`:\n\n    ```bash\n    wget -P /usr/local/bin https://raw.github.com/dashpay/dash-network-deploy/master/bin/dash-network && \\\n    chmod +x /usr/local/bin/dash-network\n    ```\n\n    Using `curl`:\n\n    ```bash\n    curl -fsSL -o /usr/local/bin/dash-network https://raw.github.com/dashpay/dash-network-deploy/master/bin/dash-network && \\\n    chmod +x /usr/local/bin/dash-network\n    ```\n\n\n## Configuration\n\n### Networks definition\n\nYou can use the `generate` command to generate configs for your network:\n\n```bash\ndash-network generate <network_name> <masternodes_amd_count> <masternodes_arm_count> <hp_masternodes_amd_count> <hp_masternodes_arm_count>\n``` \n\nTerraform configuration is defined in the `*.tfvars` files.\nSee [variables.tf](https://github.com/dashpay/dash-network-deploy/blob/master/terraform/aws/variables.tf) for all available options.\n\nAnsible configuration is stored in the `*.yml` file. The \n[group_vars/all](https://github.com/dashpay/dash-network-deploy/blob/master/ansible/group_vars/all)\nfile contains the majority of playbook options.\nThe rest are defined in [ansible roles](https://github.com/dashpay/dash-network-deploy/tree/master/ansible/roles).\n\nConfigure your credentials in the `.env` file.\n\n### Using git\n\nPlease don't forget to include the following in your `.gitignore`:\n```\n.env\n*.inventory\n*.ovpn\n```\n\n## Deployment\n\nTo deploy a Dash Network, use the `deploy` command with a particular network name:\n\n```bash\ndash-network deploy <network_name>\n```\n\nYou may pass the `--only-infrastructure` or `--only-provisioning` option to target either infrastructure or software provisioning workflows.\n\nTo destroy an available Dash Network, use the `destroy` command:\n\n```bash\ndash-network destroy -t=<target> <network_name>\n```\n\nYou can use the `-t` flag to choose which logical network components you want to destroy. It takes one of three values:\n* all (infrastructure with software)\n* network (L2+L1)\n* platform (L2 only)\n\nDestroying only the network with `-t=network` allows you to redeploy the network in almost the same state by passing the `-p` option to the `deploy` command to skip infrastructure provisioning.\n\nDestroying only the L2 platform components with `-t=platform` means you must comment out everything except roles which target masternodes and seed nodes in the `deploy.yml` playbook, and run the deployment again with the `-p` option.\n\n## List network services\n\n```bash\ndash-network list <network_name>\n```\n\n## Testing\n\nTo test the network, run the `test` command with with particular network name:\n\n```bash\ndash-network test <network_name>\n```\n\nYou may pass the `--type` option to run only particular tests (`smoke`, `e2e`).\nIt is possible to specify several types using a comma delimiter.\n\n## Debugging\n\nThere are two commands that can be useful for debugging:\n\n- Show service logs: `dash-network logs <network_name> <host> [docker logs options] <service_name>`\n  - See [Docker log options](https://docs.docker.com/engine/reference/commandline/logs/) for details\n  - Example: `dash-network logs devnet-example node-1 --since 3h dashd`\n- Execute Dash Core RPC command: `dash-network dash-cli <network_name> <hostname> <rpc_command>`\n\n## Deploy Dash Platform\n\nIn order to deploy platform services, use the ansible variable:\n\n    ```yaml\n    evo_services: true\n    ```\n\n## Connect to private Dash Network services\n\nYou can use the OpenVPN config generated during deployment (`<network_name>.ovpn`) to connect to private services.\n\n## Manual installation\n\n1. Clone git repository:\n\n    ```bash\n    git clone https://github.com/dashpay/dash-network-deploy.git\n    ```\n\n2. Install Ansible (v2.11.4+) and Terraform (v1.4.4+) per instructions provided on the official websites:\n\n    * [Ansible](https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html)\n    * [Terraform](https://www.terraform.io/intro/getting-started/install.html)\n\n3. Ensure Python dependencies are installed locally\n\n    ```bash\n    pip install -U netaddr jmespath ansible-lint boto3 botocore\n    ```\n\n4. Install pre-requisite Ansible roles\n\n    ```bash\n    ansible-galaxy install -r ansible/requirements.yml\n    ```\n\n5. Install [AWS Command Line Interface](https://docs.aws.amazon.com/cli/latest/userguide/installing.html)\n\n\n6. Install [Node.JS](https://nodejs.org/en/download/) and dependencies:\n\n    ```bash\n    npm install\n    ```\n\n7. Install OpenVPN:\n\n    On Linux:\n    ```bash\n    apt-get install openvpn\n    ```\n\n    On Mac:\n    ```bash\n    brew install openvpn\n    ```\n\n## New AWS account setup\n\nIf you are running this tool for the first time in a new AWS account, some initial setup needs to be done one time:\n\nnote: Please ensure you have the correct REGION and PROFILE setup in your AWS CLI configuration (`aws configure`) or use the --region and --profile flags with the AWS commands below.\n\n1. Create Terraform state S3 bucket manually:\n\n```sh\naws s3 mb s3://bucket-name-here\n```\n\n2. Create Terraform state dynamodb lock table manually\n\n```sh\naws dynamodb create-table \\\n  --attribute-definitions AttributeName=LockID,AttributeType=S \\\n  --table-name tf-lock-table-test \\\n  --key-schema AttributeName=LockID,KeyType=HASH \\\n  --billing-mode PROVISIONED \\\n  --provisioned-throughput ReadCapacityUnits=2,WriteCapacityUnits=2 \\\n  --table-class STANDARD\n```\n\n3. Route53 domain creation / delegation\n\n```sh\naws route53 create-hosted-zone --name networks.domain.tld --caller-reference 1234567\n```\n\nPlease note the values of these, as they will be needed in the network config files.\n", "release_dates": ["2024-01-13T07:26:37Z", "2023-10-12T09:30:11Z", "2023-09-26T02:15:30Z", "2023-09-21T00:19:36Z", "2023-09-20T01:22:05Z", "2023-09-07T12:54:16Z", "2023-09-07T00:35:08Z", "2023-09-06T13:07:46Z", "2023-08-03T01:46:00Z", "2023-05-18T03:23:43Z", "2023-05-18T01:50:14Z", "2023-05-10T11:48:09Z", "2023-04-26T05:01:55Z", "2023-04-20T08:44:52Z", "2023-04-12T04:26:41Z", "2023-04-12T00:37:16Z", "2023-03-31T11:01:27Z", "2023-03-27T13:41:48Z", "2023-03-27T08:25:35Z", "2023-03-21T07:31:48Z", "2023-01-06T02:55:28Z", "2022-12-21T07:06:24Z", "2022-12-17T01:05:52Z", "2022-12-07T06:07:27Z", "2022-11-25T03:23:09Z", "2022-10-19T08:02:19Z", "2022-10-19T02:45:20Z", "2022-09-23T05:15:55Z", "2022-08-24T01:59:33Z", "2022-08-19T05:52:10Z"]}, {"name": "dash-network-monitor", "description": "A monitoring tool for the dash network written in rust", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# dash-network-monitor\nA monitoring tool for the dash network written in rust\n", "release_dates": []}, {"name": "dash-roadmap", "description": "Previous versions of Dash Core Group Roadmap for historical purposes", "language": null, "license": null, "readme": "# Official Roadmap - Dash Core Group, Inc.\n\nThe Official Dash Roadmap can be found at https://www.dash.org/roadmap/. Previous versions can be found in the [history of this Git repository](https://github.com/dashpay/dash-roadmap/commits/eb7f6bf4c0700fd2568a22b9a0b97881c55fe4da).\n\nThe most recent version in this repository (which is now superceded) can be found here: <https://github.com/dashpay/dash-roadmap/tree/eb7f6bf4c0700fd2568a22b9a0b97881c55fe4da>\n", "release_dates": []}, {"name": "dash-shared-core", "description": "DASH SPV core with bindings for different platforms (WiP)", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# DASH SPV core\nDash SPV core written in rust with bindings for different platforms (WORK IN PROGRESS)\n\n| Branch | Tests                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | Coverage |\n|--------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|\n| main | [![Tests](https://github.com/dashpay/dash-shared-core/workflows/Tests%20and%20XCode%20framework/badge.svg?branch=main)](https://github.com/dashpay/dash-shared-core/actions) | [![codecov](https://codecov.io/gh/dashpay/dash-shared-core/branch/main/graph/badge.svg?token=6Z6A6FT5HV)](https://codecov.io/gh/dashpay/dash-shared-core) |\n", "release_dates": ["2023-12-08T14:24:41Z", "2023-11-13T10:23:07Z", "2023-11-07T15:50:12Z", "2023-11-06T10:45:08Z", "2023-10-25T08:48:28Z", "2023-09-12T18:32:31Z", "2023-07-13T16:44:32Z", "2023-07-13T16:43:56Z", "2023-07-10T10:56:50Z", "2023-07-08T21:03:42Z", "2023-07-07T12:51:57Z", "2023-07-07T07:06:29Z", "2023-06-02T20:02:31Z"]}, {"name": "dash-stratum", "description": null, "language": "Python", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "[ ![Codeship Status for ahmedbodi/php-mpos](https://www.codeship.io/projects/b3003a70-61a3-0131-231e-26f75a0c690d/status?branch=master)](https://www.codeship.io/projects/12274)\n#Description\nStratum-mining is a pooled mining protocol. It is a replacement for *getwork* based pooling servers by allowing clients to generate work. The stratum protocol is described [here](http://mining.bitcoin.cz/stratum-mining) in full detail.\n\nThis is a implementation of stratum-mining for scrypt based coins. It is compatible with *MPOS* as it complies with the standards of *pushpool*. The end goal is to build on these standards to come up with a more stable solution.\n\nThe goal is to make a reliable stratum mining server for a wide range of coins unlike other forks where the code is limited to specific algorithm's. Over time I will develop this to be more feature rich and very stable. If you would like to see a feature please file a feature request. \n\n**NOTE:** This fork is still in development. Many features may be broken. Please report any broken features or issues.\n\n#Features\n\n* Stratum Mining Pool \n* Solved Block Confirmation\n* Job Based Vardiff support\n* Solution Block Hash Support\n* Log Rotation\n* Initial low difficulty share confirmation\n* Multiple *coind* wallets\n* On the fly addition of new *coind* wallets\n* MySQL/PostGres/SQLite database support\n* Adjustable database commit parameters\n* Bypass password check for workers\n* Proof Of Work and Proof of Stake Coin Support\n* Transaction Messaging Support\n\n#Donations \n* BTC:  18Xg4qP6RUvpeajanKPt5PDvvcqvU2pP6d\n* BTE:  8UJLskr8eDYATvYzmaCBw3vbRmeNweT3rW\n* DGC:  DSBb5KmGWYKMJjxk3rETtvpk9sPqgCCYAw\n* LTC:  Lg4kXMqPsmMHrGr81LLe8oHpbsMiWiuMSB\n* WDC:  WeVFgZQsKSKXGak7NJPp9SrcUexghzTPGJ\n* Doge: DLtBRYtNCzfiZfcpUeEr8KPvy5k1aR7jca\n* SRC:  sMP2wHN5H2ik7FQDPjhSzFZUWux75BYZGe\n* ARG:  AQvXPWVqGzcpH2j2XSRG7X5R9nA3y9D9aQ\n* Cryptsy Trade Key: ec13d183e304326ebd41258d6ae7188e303866fe\n\n\n#Requirements\n*stratum-mining* is built in python. I have been testing it with 2.7.3, but it should work with other versions. The requirements for running the software are below.\n* Python 2.7+\n* python-twisted\n* stratum\n* MySQL Server \n* SHA256 or Scrypt CoinDaemon\n\nOther coins have been known to work with this implementation. I have tested with the following coins, but there may be many others that work. \n\n* Orbitcoin.\n* FireFlyCoin.\n* ByteCoin\n* DigitalCoin\n* Worldcoin\n* Argentum\n* Netcoin\n* FlorinCoin\n* CHNCoin\n* Cubits v3\n* OpenSourceCoin\n* TekCoin\n* Franko\n* Quark\n* Securecoin\n\n#Installation\n\nThe installation of this *stratum-mining* can be found in the Repo Wiki. \n\n#Contact\nI am available in the #MPOS, #crypto-expert, #digitalcoin, and #worldcoin channels on freenode. \nAlthough i am willing to provide support through IRC please file issues on the repo.\nIssues as a direct result of stratum will be helped with as much as possible\nHowever issues related to a coin daemon's setup and other non stratum issues, \nPlease research and attempt to debug first.\n\n#Credits\n\n* Original version by Slush0 and ArtForz (original stratum code)\n* More Features added by GeneralFault, Wadee Womersley, Viperaus, TheSeven and Moopless\n* Multi Algo, Vardiff, DB and MPOS support done by Ahmed_Bodi, penner42 and Obigal\n\n#License\nThis software is provides AS-IS without any warranties of any kind. Please use at your own risk. \n\n", "release_dates": []}, {"name": "dash-wallet", "description": "Dash Wallet for Android", "language": "Kotlin", "license": null, "readme": "Welcome to _Dash Wallet_, a standalone Dash payment app for your Android device!\n\nThis project contains several sub-projects:\n\n * __wallet__:\n     The Android app itself. This is probably what you're searching for.\n * __common__:\n     Contains common components used by integrations.\n * __features__:\n     Contains features such as Explore Dash\n * __market__:\n     App description and promo material for the Google Play app store.\n * __integration-android__:\n      A tiny library for integrating Dash payments into your own Android app\n     (e.g. donations, in-app purchases).\n * __integrations__\n     Contains the various integrations: Crowdnode, Coinbase, Uphold,\n * __sample-integration-android__:\n     A minimal example app to demonstrate integration of digital payments into\n     your Android app.\n\nYou can build the production version using Gradle:\n\n`./gradlew assembleProdRelease`\n\nThe built apks will be in `wallet/build/outputs/apk`\n\n\n", "release_dates": ["2023-12-23T03:18:53Z", "2023-12-15T16:49:29Z", "2023-12-12T02:26:18Z", "2023-11-16T19:36:21Z", "2023-09-26T15:59:17Z", "2023-09-08T20:52:00Z", "2023-08-25T22:21:21Z", "2023-07-24T21:09:09Z", "2023-07-03T20:08:49Z", "2023-06-06T16:03:45Z", "2023-05-25T00:54:25Z", "2023-05-19T15:39:22Z", "2023-01-11T23:38:50Z", "2023-01-05T14:03:30Z", "2022-11-04T21:20:07Z", "2022-10-03T15:10:28Z", "2022-09-20T14:03:35Z", "2022-09-02T15:12:23Z", "2022-08-26T07:39:22Z", "2022-08-17T00:17:02Z", "2022-07-11T22:42:06Z", "2022-06-20T03:47:56Z", "2022-05-19T14:03:58Z", "2022-05-09T22:21:59Z", "2022-03-01T06:58:30Z", "2022-02-24T15:54:12Z", "2022-02-08T16:09:50Z", "2022-01-22T15:30:17Z", "2022-01-19T19:16:20Z", "2022-01-13T20:27:05Z"]}, {"name": "dash-website", "description": null, "language": "HTML", "license": null, "readme": "# Dash Website\n\n## Jekyll\nWe are using Jekyll to generate the static html files.\nhttps://jekyllrb.com\n\n### Requirements (macOS)\n* Ruby: `brew install ruby` (v2.3.3 works, v2.4.0 *does not*)\n* Ruby Gems: https://rubygems.org/pages/download\n* NodeJS: https://nodejs.org/en/ (Ideally >=4.5.0)\n* Python: `brew install python`\n* Bundler: `gem install bundler`\n\n### Dependencies\n(If you have nvm, do `nvm install && nvm use` first.)\n\nSimply run `npm install` to install all dependencies. This will also run `bundle install` on *postinstall* to install all ruby gems.\n\n**CI Note**: The Gems must also be installed on the CI server. \n\n**Mac Note**: Bundler will try to install the dependency `nokogiri`. If you are using a Mac, and run into issues related to `nokogiri` during `bundle install`, do the following:\n\n`xcode-select --install`\n\n`gem install nokogiri`\n\nThen run `bundle install`\n\n\n### Plugins\n* `jekyll-multiple-languages-plugin` installed as a gem. Documentation at https://github.com/perrywoodin/jekyll-multiple-languages-plugin. This is a modified fork that adds two new tags for outputting markdown `{% tmd key %}` or `{% translatemd key %}`\n\n(If you still have a `_plugins/jekyll-multiple-languages-plugin` directory in your root folder, you will need to remove it.)\n\n## Development\n`npm start` or `npm run watch` to build to the _site directory whenever a file is changed and serve via *localhost:3000*\n\n## Production Build\nProduction builds should be handled by CI.\n\n`npm run build` will build a fully minified, mangled, and compressed build to the _site directory.\n\n `npm run htmlproof` will run ImageCheck, ScriptCheck, and LinkCheck on the built \"_site\" folder \"*.html\" files. Travis CI will not deploy unless this command finishes successfully!\n\nmacOS\nxcode-select --install\ngem install nokogiri\n\n## i18n\nLanguage variables are set in `/_i18n/*.yml` files. The master language file is `/_i18n/en.yml`. All other languages should use that file as a base. \n\n### Writing Content\n\nAlmost all of the content is defined as a variable in the `/_i18n/*.yml` files. There will be a separate yml file for each language that is supported. The master\n\nContent should be written with little to no html. Do not wrap the content in `<p></p>` tags. If you need separate paragraphs, use two line breaks. For example:\n\n```\nParagraph one\n\n\nParagraph two\n```\n\nWill render as:\n```\n<p>Paragraph one</p>\n<p>Paragraph two</p>\n```\n\n### Displaying Content\n\n#### Strings\nTo output a variable to a template use:\n`{% t key %}`\nor\n`{% translate key %}`\n\n#### Markdown\nTo output a variable to a template as markdown use:\n`{% tmd key %}`\nor\n`{% translatemd key %}`\n\n#### Files\ni18n files can be saved in their corresponding directories under `/_i18n/`\n\nTo include a file use:\n`{% tf pagename/blockname.md %}`\nor\n`{% translate_file pagename/blockname.md %}`\n\n## Writing a Blog Post\nBlog posts can be written in MarkDown (*.md) or HTML (*.html).\n\nPosts need to be saved in the `_posts` directory and the filename must always start with YYYY-MM-DD-\n\nFor example: `2016-05-12-new-website.md`\n\n###Front matter\nThe top page of every post should contain the following (Example):\n```\nauthor: perry\nlayout: post\nimage: /assets/images/2016/05/Node40-banner.jpg\ntitle: New website for Node40\ndescription: Check out the new website for Node40\n```\n\n###Blog Post Images\nImage paths for blogs are currently relative to /assets/img/blog by default. If we replaced the image path from the front matter above with:\n```\n\timage: MyImage.jpg\n```\n... will look for `\"MyImage.jpg\"` in the `/assets/img/blog` folder. \n", "release_dates": []}, {"name": "dash-website-api", "description": null, "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": []}, {"name": "dashcontrol-android", "description": "Android version of Dash Control App.", "language": "Java", "license": null, "readme": null, "release_dates": []}, {"name": "dashcontrol-ios", "description": "The dash control project for ios.", "language": "Objective-C", "license": null, "readme": "# DashControl\n\n## Requirements\n\nDashControl uses both [CocoaPods](http://cocoapods.org) and [Carthage](https://github.com/Carthage/Carthage) to manage dependencies. To install them run in the command line:\n- `gem install cocoapods` or  `sudo gem install cocoapods` (if first command fails)\n- `brew update && brew install carthage`\n\nTo get started with the DashControl run the following commands after every \"git pull\":\n- `pod install`\n- `carthage bootstrap`\n\nUse **DashControl.xcworkspace** to open the project.\n\n## License\n\nDashControl is available under the MIT license.\n", "release_dates": []}, {"name": "dashcore-lib", "description": "A pure and powerful JavaScript Dash library.", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Dashcore Library\n\n[![NPM Version](https://img.shields.io/npm/v/@dashevo/dashcore-lib)](https://www.npmjs.com/package/@dashevo/dashcore-lib)\n[![Build Status](https://github.com/dashevo/dashcore-lib/actions/workflows/test_and_release.yml/badge.svg)](https://github.com/dashevo/dashcore-lib/actions/workflows/test_and_release.yml)\n[![Release Date](https://img.shields.io/github/release-date/dashevo/dashcore-lib)](https://github.com/dashevo/dashcore-lib/releases/latest)\n[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen)](https://github.com/RichardLitt/standard-readme)\n\nA pure and powerful JavaScript Dash library.\n\nDash is a powerful new peer-to-peer platform for the next generation of financial technology. The decentralized nature of the Dash network allows for highly resilient Dash infrastructure, and the developer community needs reliable, open-source tools to implement Dash apps and services.\n\n## Table of Contents\n\n- [Install](#install)\n- [Usage](#usage)\n- [Documentation](#documentation)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Install\n\n### NodeJS\n\n```\nnpm install @dashevo/dashcore-lib\n```\n\n### Browser\n\n#### CDN Standalone\n\n```html\n<script src=\"https://unpkg.com/@dashevo/dashcore-lib\"></script>\n<script>\n  const { PrivateKey } = dashcore;\n  const privateKey = new PrivateKey();\n  const address = privateKey.toAddress().toString();\n  ...\n</script>\n```\n\n#### Building the Browser Bundle\n\nTo build a dashcore-lib full bundle for the browser:\n\n```sh\nnpm run build\n```\n\nThis will generate a file named `dashcore-lib.min.js` in the `dist/` folder.\n\n## Usage\n\n### Browser\n\n```\n<script src='./dist/dashcore-lib.min.js' type=\"text/javascript\"></script>\n<script>\n  const PrivateKey = dashcore.PrivateKey;\n  const privateKey = new PrivateKey();\n  const address = privateKey.toAddress().toString();\n</script>\n```\n\n### Modules\n\nSome functionality is implemented as a module that can be installed separately:\n\n- [Payment Protocol Support](https://github.com/dashevo/dashcore-payment-protocol)\n- [Peer to Peer Networking](https://github.com/dashevo/dashcore-p2p)\n- [Dash Core JSON-RPC](https://github.com/dashevo/dashd-rpc)\n- [Mnemonics](https://github.com/dashevo/dashcore-mnemonic)\n- [Elliptical Curve Integrated Encryption Scheme](https://github.com/dashevo/bitcore-ecies-dash)\n- [Signed Messages](https://github.com/dashevo/bitcore-message-dash)\n\n### Development & Tests\n\n```sh\ngit clone https://github.com/dashevo/dashcore-lib\ncd dashcore-lib\nnpm install\n```\n\nRun all the tests:\n\n```sh\nnpm test\n```\n\nYou can also run just the Node.js tests with `npm run test:node`, just the browser tests with `npm run test:browser` or run a test coverage report with `npm run coverage`.\n\n## Documentation\n\n### Concepts\n\n- [Addresses](docs/core-concepts/address.md)\n- [Block](docs/core-concepts/block.md)\n- [Crypto](docs/core-concepts/crypto.md)\n- [Encoding](docs/core-concepts/encoding.md)\n- [Hierarchically-derived Private and Public Keys](docs/core-concepts/hierarchical.md)\n- [Mnemonic](docs/core-concepts/mnemonic.md)\n- [Networks](docs/core-concepts/networks.md)\n- [PrivateKey](docs/core-concepts/privatekey.md)\n- [PublicKey](docs/core-concepts/publickey.md)\n- [Script](docs/core-concepts/script.md)\n- [Transaction](docs/core-concepts/transaction.md)\n- [Using Different Units](docs/core-concepts/unit.md)\n- [Unspent Output](docs/core-concepts/unspentoutput.md)\n- [URI](docs/core-concepts/uri.md)\n- [Governance Object / Proposal](docs/core-concepts/govobject/govobject.md)\n\n### How To Use\n\n- [Addresses](docs/usage/address.md)\n- [Block](docs/usage/block.md)\n- [BlockHeader](docs/usage/blockheader.md)\n- [Hierarchically-derived Private Key](docs/usage/hdprivatekey.md)\n- [Hierarchically-derived Public Key](docs/usage/hdpublickey.md)\n- [Message](docs/usage/message.md)\n- [Mnemonic](docs/usage/mnemonic.md)\n- [Opcode](docs/usage/opcode.md)\n- [PrivateKey](docs/usage/privatekey.md)\n- [PublicKey](docs/usage/publickey.md)\n- [Script](docs/usage/script.md)\n- [Transaction](docs/usage/transaction.md)\n- [Transaction Input](docs/usage/transaction_input.md)\n- [Transaction Output](docs/usage/transaction_output.md)\n- [URI](docs/usage/uri.md)\n\n### Use Case Examples\n\nSome examples can be found [here](docs/examples.md), below is a list of direct links for some of them.\n\n- [Generate a random address](docs/examples.md#generate-a-random-address)\n- [Generate an address from a SHA256 hash](docs/examples.md#generate-an-address-from-a-sha256-hash)\n- [Import an address via WIF](docs/examples.md#import-an-address-via-wif)\n- [Create a Transaction](docs/examples.md#create-a-transaction)\n- [Sign a Dash message](docs/examples.md#sign-a-bitcoin-message)\n- [Verify a Dash message](docs/examples.md#verify-a-bitcoin-message)\n- [Create an OP RETURN transaction](docs/examples.md#create-an-op-return-transaction)\n- [Create a 2-of-3 multisig P2SH address](docs/examples.md#create-a-2-of-3-multisig-p2sh-address)\n- [Spend from a 2-of-2 multisig P2SH address](docs/examples.md#spend-from-a-2-of-2-multisig-p2sh-address)\n\n## Contributing\n\nPlease send pull requests for bug fixes, code optimization, and ideas for improvement. For more information on how to contribute, please refer to our [CONTRIBUTING](https://github.com/dashevo/dashcore-lib/blob/master/CONTRIBUTING.md) file.\n\n## License\n\nCode released under [the MIT license](LICENSE).\n\nCopyright 2013-2017 BitPay, Inc. Bitcore is a trademark maintained by BitPay, Inc.  \nCopyright 2016-2017 The Dash Foundation, Inc.  \nCopyright 2017-2020 Dash Core Group, Inc.\n", "release_dates": ["2024-01-31T18:32:33Z", "2023-10-30T12:02:13Z", "2023-10-19T12:04:11Z", "2023-06-22T12:50:19Z", "2023-06-08T10:10:08Z", "2023-06-06T17:57:05Z", "2023-05-05T14:15:21Z", "2023-05-03T08:29:56Z", "2023-05-01T07:08:28Z", "2023-04-18T10:56:07Z", "2023-04-17T10:16:11Z", "2023-03-25T06:04:45Z", "2023-03-20T17:09:31Z", "2022-09-22T12:03:56Z", "2022-09-20T15:53:34Z", "2022-09-18T14:56:13Z", "2022-08-22T09:46:35Z", "2022-06-28T08:45:43Z", "2022-06-17T02:36:34Z", "2022-05-25T16:27:03Z", "2022-05-24T10:37:36Z", "2022-05-17T07:33:38Z", "2022-05-02T15:35:46Z", "2022-05-02T04:40:41Z", "2022-04-29T16:47:37Z", "2022-04-29T06:52:01Z", "2022-04-21T07:17:24Z", "2022-02-04T09:37:48Z", "2022-01-14T10:09:42Z", "2021-11-24T15:09:34Z"]}, {"name": "dashcore-node", "description": "Full node with extended capabilities using Dashcore and Dash Core (dashd)", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "Dashcore Node\n============\n\nA Dash full node for building applications and services with Node.js. A node is extensible and can be configured to run additional services. At the minimum a node has an interface to [Dash Core (dashd) v0.13.0](https://github.com/dashpay/dash/tree/v0.13.0.x) for more advanced address queries. Additional services can be enabled to make a node more useful such as exposing new APIs, running a block explorer and wallet service.\n\n## Usages\n\n### As a standalone server\n\n```bash\ngit clone https://github.com/dashevo/dashcore-node\ncd dashcore-node\nnpm install\n./bin/dashcore-node start\n```\n\nWhen running the start command, it will seek for `.dashcore/dashcore-node.json` conf file in the working directory (see [/docs/services/dashd.md](/docs/services/dashd.md) for an example).\nIf it doesn't exist, it will create it, with basic task to connect to dashd.\n\nSome plugins are available :\n\n- Insight-API : `./bin/dashcore-node addservice @dashevo/insight-api`\n- Insight-UI : `./bin/dashcore-node addservice @dashevo/insight-ui`\n\nYou also might want to add these index to your dash.conf file :\n```\n-addressindex\n-timestampindex\n-spentindex\n```\n\n### As a library\n\n```bash\nnpm install @dashevo/dashcore-node\n```\n\n```javascript\nconst dashcore = require('@dashevo/dashcore-node');\nconst config = require('./dashcore-node.json');\n\nlet node = dashcore.scaffold.start({ path: \"\", config: config });\nnode.on('ready', function () {\n    console.log(\"Dash core started\");\n    \n    node.services.dashd.on('tx', function(txData) {\n        let tx = new dashcore.lib.Transaction(txData);\n        console.log(tx);\n    });\n});\n```\n\n## Prerequisites\n\n- Dash Core (dashd) (v0.13.0) with support for additional indexing *(see above)*\n- Node.js v8+\n- ZeroMQ *(libzmq3-dev for Ubuntu/Debian or zeromq on OSX)*\n- ~50GB of disk storage\n- ~1GB of RAM\n\n## Configuration\n\nDashcore includes a Command Line Interface (CLI) for managing, configuring and interfacing with your Dashcore Node.\n\n```bash\ndashcore-node create -d <dash-data-dir> mynode\ncd mynode\ndashcore-node install <service>\ndashcore-node install https://github.com/yourname/helloworld\ndashcore-node start\n```\n\nThis will create a directory with configuration files for your node and install the necessary dependencies.\n\nPlease note that [Dash Core](https://github.com/dashpay/dash/tree/master) needs to be installed first.\n\nFor more information about (and developing) services, please see the [Service Documentation](docs/services.md).\n\n## Add-on Services\n\nThere are several add-on services available to extend the functionality of Bitcore:\n\n- [Insight API](https://github.com/dashevo/insight-api/tree/master)\n- [Insight UI](https://github.com/dashevo/insight-ui/tree/master)\n- [Bitcore Wallet Service](https://github.com/dashevo/dashcore-wallet-service/tree/master)\n\n## Documentation\n\n- [Upgrade Notes](docs/upgrade.md)\n- [Services](docs/services.md)\n  - [Dashd](docs/services/dashd.md) - Interface to Dash Core\n  - [Web](docs/services/web.md) - Creates an express application over which services can expose their web/API content\n- [Development Environment](docs/development.md) - Guide for setting up a development environment\n- [Node](docs/node.md) - Details on the node constructor\n- [Bus](docs/bus.md) - Overview of the event bus constructor\n- [Release Process](docs/release.md) - Information about verifying a release and the release process.\n\n\n## Setting up dev environment (with Insight)\n\nPrerequisite : Having a dashd node already runing `dashd --daemon`.\n\nDashcore-node : `git clone https://github.com/dashevo/dashcore-node -b develop`\nInsight-api (optional) : `git clone https://github.com/dashevo/insight-api -b develop`\nInsight-UI (optional) : `git clone https://github.com/dashevo/insight-ui -b develop`\n\nInstall them :\n```\ncd dashcore-node && npm install \\\n && cd ../insight-ui && npm install \\\n && cd ../insight-api && npm install && cd ..\n```\n\nSymbolic linking in parent folder :\n```\nnpm link ../insight-api\nnpm link ../insight-ui\n```\n\nStart with `./bin/dashcore-node start` to first generate a ~/.dashcore/dashcore-node.json file.\nAppend this file with `\"@dashevo/insight-ui\"` and `\"@dashevo/insight-api\"` in the services array.\n\n## Contributing\n\nPlease send pull requests for bug fixes, code optimization, and ideas for improvement. For more information on how to contribute, please refer to our [CONTRIBUTING](https://github.com/dashevo/dashcore/blob/master/CONTRIBUTING.md) file.\n\n## License\n\nCode released under [the MIT license](https://github.com/dashevo/dashcore-node/blob/master/LICENSE).\n\nCopyright 2016-2018 Dash Core Group, Inc.\n\n- bitcoin: Copyright (c) 2009-2015 Bitcoin Core Developers (MIT License)\n", "release_dates": ["2023-07-13T11:41:23Z", "2023-03-25T09:56:33Z", "2023-03-24T02:07:01Z", "2022-10-11T21:18:01Z", "2022-09-19T12:36:04Z", "2021-08-20T09:29:32Z", "2021-03-02T03:20:24Z", "2021-01-29T09:45:29Z", "2020-12-15T12:35:56Z", "2020-12-15T07:22:30Z", "2020-10-22T03:02:23Z", "2019-06-21T16:32:29Z", "2019-01-28T18:35:37Z", "2019-01-21T17:10:10Z"]}, {"name": "dashcore-p2p", "description": "Interface to the dash P2P network for Dashcore", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "Dashcore P2P\n=======\n\n[![NPM Package](https://img.shields.io/npm/v/@dashevo/dashcore-p2p.svg?style=flat-square)](https://www.npmjs.org/package/@dashevo/dashcore-p2p)\n[![Build Status](https://github.com/dashevo/dashcore-p2p/actions/workflows/test_and_release.yml/badge.svg)](https://github.com/dashevo/dashcore-p2p/actions/workflows/test_and_release.yml)\n\n`dashcore-p2p` adds Dash protocol support for Dashcore.\n\nSee [the main dashcore-lib repo](https://github.com/dashevo/dashcore-lib) for more information.\n\n## Getting Started\n\n```sh\nnpm install @dashevo/dashcore-p2p\n```\nIn order to connect to the Dash network, you'll need to know the IP address of at least one node of the network, or use [Pool](/docs/pool.md) to discover peers using a DNS seed.\n\n```javascript\nvar Peer = require('@dashevo/dashcore-p2p').Peer;\n\nvar peer = new Peer({host: '127.0.0.1'});\n\npeer.on('ready', function() {\n  // peer info\n  console.log(peer.version, peer.subversion, peer.bestHeight);\n});\npeer.on('disconnect', function() {\n  console.log('connection closed');\n});\npeer.connect();\n```\n\nThen, you can get information from other peers by using:\n\n```javascript\n// handle events\npeer.on('inv', function(message) {\n  // message.inventory[]\n});\npeer.on('tx', function(message) {\n  // message.transaction\n});\n```\n\nTake a look at the [bitcore guide](http://bitcore.io/guide/peer.html) on the usage of the `Peer` class.\n\n## Contributing\n\nPlease send pull requests for bug fixes, code optimization, and ideas for improvement. For more information on how to contribute, please refer to our [CONTRIBUTING](https://github.com/dashevo/dashcore-p2p/blob/master/CONTRIBUTING.md) file.\n\n## License\n\nCode released under [the MIT license](https://github.com/dashevo/dashcore/blob/master/LICENSE).\n\nCopyright 2013-2017 BitPay, Inc. Bitcore is a trademark maintained by BitPay, Inc.  \nCopyright 2016-2017 The Dash Foundation, Inc.  \nCopyright 2017-2018 Dash Core Group, Inc.  \n", "release_dates": ["2021-08-19T17:53:00Z", "2021-03-02T03:29:10Z", "2019-07-01T15:19:17Z", "2019-01-21T09:39:39Z", "2019-01-18T19:00:59Z", "2018-12-31T17:03:24Z"]}, {"name": "dashd-go", "description": "An alternative full node bitcoin implementation written in Go (golang)", "language": "Go", "license": {"key": "isc", "name": "ISC License", "spdx_id": "ISC", "url": "https://api.github.com/licenses/isc", "node_id": "MDc6TGljZW5zZTEw"}, "readme": "dashd-go (in development - not working)\n====\n\n[![Build Status](https://github.com/btcsuite/btcd/workflows/Build%20and%20Test/badge.svg)](https://github.com/btcsuite/btcd/actions)\n[![Coverage Status](https://coveralls.io/repos/github/dashpay/dashd-go/badge.svg?branch=master)](https://coveralls.io/github/dashpay/dashd-go?branch=master)\n[![ISC License](https://img.shields.io/badge/license-ISC-blue.svg)](http://copyfree.org)\n[![GoDoc](https://img.shields.io/badge/godoc-reference-blue.svg)](https://pkg.go.dev/github.com/btcsuite/btcd)\n\ndashd-go is an alternative full node dash implementation written in Go (golang).\n\nThis project is currently not in active development, however the rpc-client it\ncontains is.  It is extremely stable and has been in production use since October 2013.\n\nIt properly downloads, validates, and serves the blockchain using the exact\nrules (including consensus bugs) for block acceptance as Bitcoin Core.  We have\ntaken great care to avoid btcd causing a fork to the blockchain.  It includes a\nfull block validation testing framework which contains all of the 'official'\nblock acceptance tests (and some additional ones) that is run on every pull\nrequest to help ensure it properly follows consensus.  Also, it passes all of\nthe JSON test data in the Bitcoin Core code.\n\nIt also properly relays newly mined blocks, maintains a transaction pool, and\nrelays individual transactions that have not yet made it into a block.  It\nensures all individual transactions admitted to the pool follow the rules\nrequired by the block chain and also includes more strict checks which filter\ntransactions based on miner requirements (\"standard\" transactions).\n\nOne key difference between dashd-go and Dash Core is that dashd-go does *NOT* include\nwallet functionality and this was a very intentional design decision.  See the\nblog entry [here](https://web.archive.org/web/20171125143919/https://blog.conformal.com/btcd-not-your-moms-bitcoin-daemon)\nfor more details.  This means you can't actually make or receive payments\ndirectly with dashd-go.\n\n## Requirements\n\n[Go](http://golang.org) 1.18 or newer.\n\n## Installation\n\n<https://github.com/btcsuite/btcd/releases>\n\n#### Linux/BSD/MacOSX/POSIX - Build from Source\n\n- Install Go according to the installation instructions here:\n  <http://golang.org/doc/install>\n\n- Ensure Go was installed properly and is a supported version:\n\n```bash\ngo version\ngo env GOROOT GOPATH\n```\n\nNOTE: The `GOROOT` and `GOPATH` above must not be the same path.  It is\nrecommended that `GOPATH` is set to a directory in your home directory such as\n`~/goprojects` to avoid write permission issues.  It is also recommended to add\n`$GOPATH/bin` to your `PATH` at this point.\n\n- Run the following commands to obtain btcd, all dependencies, and install it:\n\n```bash\ncd $GOPATH/src/github.com/btcsuite/btcd\nGO111MODULE=on go install -v . ./cmd/...\n```\n\n- dashd-go (and utilities) will now be installed in ```$GOPATH/bin```.  If you did\n  not already add the bin directory to your system path during Go installation,\n  we recommend you do so now.\n\n## Updating\n\n#### Linux/BSD/MacOSX/POSIX - Build from Source\n\n- Run the following commands to update btcd, all dependencies, and install it:\n\n```bash\ncd $GOPATH/src/github.com/btcsuite/btcd\ngit pull\nGO111MODULE=on go install -v . ./cmd/...\n```\n\n## Getting Started\n\nbtcd has several configuration options available to tweak how it runs, but all\nof the basic operations described in the intro section work with zero\nconfiguration.\n\n#### Linux/BSD/POSIX/Source\n\n```bash\n./btcd\n```\n\n## IRC\n\n- irc.libera.chat\n- channel #btcd\n- [webchat](https://web.libera.chat/gamja/?channels=btcd)\n\n## Issue Tracker\n\nThe [integrated github issue tracker](https://github.com/btcsuite/btcd/issues)\nis used for this project.\n\n## Documentation\n\nThe documentation is a work-in-progress.  It is located in the [docs](https://github.com/btcsuite/btcd/tree/master/docs) folder.\n\n## Release Verification\n\nPlease see our [documentation on the current build/verification\nprocess](https://github.com/btcsuite/btcd/tree/master/release) for all our\nreleases for information on how to verify the integrity of published releases\nusing our reproducible build system.\n\n## License\n\nbtcd is licensed under the [copyfree](http://copyfree.org) ISC License.\n", "release_dates": ["2023-07-14T14:05:46Z", "2023-04-04T07:58:37Z", "2023-02-22T10:01:58Z", "2022-04-21T10:00:08Z", "2022-03-03T13:34:48Z", "2022-03-03T13:35:06Z", "2022-03-03T13:35:25Z"]}, {"name": "dashd-rpc", "description": "Dash Client Library to connect to Dash Core (dashd) via RPC", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# dashd-rpc\n\n[![Build Status](https://github.com/dashevo/dashd-rpc/actions/workflows/test.yml/badge.svg)](https://github.com/dashevo/dashd-rpc/actions/workflows/test.yml)\n[![NPM Package](https://img.shields.io/npm/v/@dashevo/dashd-rpc.svg)](https://www.npmjs.org/package/@dashevo/dashd-rpc)\n\nDash Client Library to connect to Dash Core (dashd) via RPC\n\n## Install\n\ndashd-rpc runs on [node](http://nodejs.org/), and can be installed via [npm](https://npmjs.org/):\n\n```bash\nnpm install @dashevo/dashd-rpc\n```\n\n## Usage\n\n### RpcClient\n\nConfig parameters : \n\n\t- protocol : (string - optional) - (default: 'https') - Set the protocol to be used. Either `http` or `https`.\n\t- user : (string - optional) - (default: 'user') - Set the user credential.\n\t- pass : (string - optional) - (default: 'pass') - Set the password credential.\n\t- host : (string - optional) - (default: '127.0.0.1') - The host you want to connect with.\n\t- port : (integer - optional) - (default: 9998) - Set the port on which perform the RPC command.\n\nPromise vs callback based\n\n  - `require('@dashevo/dashd-rpc/promise')` to have promises returned\n  - `require('@dashevo/dashd-rpc')` to have callback functions returned\n\t\n### Examples\n\nConfig:\n\n```javascript\nvar config = {\n    protocol: 'http',\n    user: 'dash',\n    pass: 'local321',\n    host: '127.0.0.1',\n    port: 19998\n};\n```\n\nPromise based:\n\n```javascript\nvar RpcClient = require('@dashevo/dashd-rpc/promise');\nvar rpc = new RpcClient(config);\n\nrpc.getRawMemPool()\n    .then(ret => {\n        return Promise.all(ret.result.map(r => rpc.getRawTransaction(r)))\n    })\n    .then(rawTxs => {\n        rawTxs.forEach(rawTx => {\n            console.log(`RawTX: ${rawTx.result}`);\n        })\n    })\n    .catch(err => {\n        console.log(err)\n    })\n```\n\nCallback based (legacy):\n\n```javascript\nvar run = function() {\n  var bitcore = require('@dashevo/dashcore-lib');\n  var RpcClient = require('@dashevo/dashd-rpc');\n  var rpc = new RpcClient(config);\n\n  var txids = [];\n\n  function showNewTransactions() {\n    rpc.getRawMemPool(function (err, ret) {\n      if (err) {\n        console.error(err);\n        return setTimeout(showNewTransactions, 10000);\n      }\n\n      function batchCall() {\n        ret.result.forEach(function (txid) {\n          if (txids.indexOf(txid) === -1) {\n            rpc.getRawTransaction(txid);\n          }\n        });\n      }\n\n      rpc.batch(batchCall, function(err, rawtxs) {\n        if (err) {\n          console.error(err);\n          return setTimeout(showNewTransactions, 10000);\n        }\n\n        rawtxs.map(function (rawtx) {\n          var tx = new bitcore.Transaction(rawtx.result);\n          console.log('\\n\\n\\n' + tx.id + ':', tx.toObject());\n        });\n\n        txids = ret.result;\n        setTimeout(showNewTransactions, 2500);\n      });\n    });\n  }\n\n  showNewTransactions();\n};\n```\n\n### Help\n\nYou can dynamically access to the help of each method by doing\n\n```\nconst RpcClient = require('@dashevo/dashd-rpc');\nvar client = new RPCclient({\n    protocol:'http',\n    user: 'dash',\n    pass: 'local321', \n    host: '127.0.0.1', \n    port: 19998,\n    timeout: 1000\n});\n\nvar cb = function (err, data) {\n    console.log(data)\n};\n\n// Get full help\nclient.help(cb);\n\n// Get help of specific method\nclient.help('getinfo',cb);\n```\n\n## Contributing\n\nFeel free to dive in! [Open an issue](https://github.com/dashevo/dash-std-template/issues/new) or submit PRs.\n\n## License\n\n[MIT](LICENSE) &copy; Dash Core Group, Inc.\n", "release_dates": ["2022-12-30T08:53:12Z", "2022-10-27T16:27:08Z", "2022-09-22T08:57:28Z", "2022-09-22T08:27:48Z", "2022-09-16T14:51:43Z", "2022-07-06T04:36:40Z", "2022-06-30T11:39:41Z", "2022-01-13T09:34:40Z", "2021-09-26T11:15:42Z", "2021-04-28T15:20:35Z", "2021-03-02T09:22:21Z", "2021-02-01T23:10:40Z", "2020-10-05T06:19:50Z", "2020-02-26T11:48:51Z", "2019-03-21T11:16:02Z"]}, {"name": "dashj", "description": "Dash Java Library (X11, DGW, LLMQ, InstantSend, Chainlocks)", "language": "Java", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# dashj\n\n> A Java library for working with Dash\n> \n[![License](https://img.shields.io/github/license/dashevo/dashj)](https://github.com/dashevo/dashj/blob/master/COPYING)\n[![dashevo/dashj](https://tokei.rs/b1/github/dashevo/dashj?category=code)](https://github.com/dashevo/dashj)\n\n| Branch | Tests                                                                                                                                         | Coverage                                                                                                                              | Linting |\n|--------|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------|---------|\n| master | [![Tests](https://github.com/dashevo/dashj/workflows/Java%20CI/badge.svg?branch=master)](https://github.com/dashevo/dashj/actions) | [![codecov](https://codecov.io/gh/dashevo/dashj/branch/master/graph/badge.svg)](https://codecov.io/gh/dashevo/android-dpp) | N/A     |\n\n### Welcome to dashj\n\nThe dashj library is a Java implementation of the Dash protocol, which allows it to maintain a wallet and send/receive transactions without needing a local copy of Dash Core. It comes with full documentation and some example apps showing how to use it.\n\nThis branch is up to date with bitcoinj (https://github.com/bitcoinj/bitcoinj) 0.15.10.\n\n### Technologies\n\n* Java 8+ (needs Java 8 API or Android 6.0 API, compiles to Java 8 bytecode) and Gradle 4.4+ for the `core` module\n* Java 8+ and Gradle 5.6 for `tools` and `examples`\n* Java 11+ and Gradle 5.6 for the JavaFX-based `wallettemplate`\n* [Gradle](https://gradle.org/) - for building the project\n* [Google Protocol Buffers](https://github.com/google/protobuf) - for use with serialization and hardware communications\n\n### Getting started\n\nTo get started, it is best to have the latest JDK and Maven installed. The HEAD of the `master` branch contains the latest development code and various production releases are provided on feature branches.\n\n#### Building from the command line\nOfficial builds are currently using JDK 8. Our GitHub Actions build and test with JDK 8 and JDK 11.\n\nTo initialize the repo after cloning it (this will build the bls shared library): \n```shell\ngit submodule update  --init --recursive\ncd contrib/dashj-bls\nmvn package -DskipTests\ncd ../..\n```\nTo use the optional x11 native library:\n```shell\ncd contrib/x11\nmkdir build\ncd build\ncmake ..\ncmake --build .\ncd ../../..\n```\n\nTo perform a full build use (this includes the dashjbls shared library):\n\nTo perform a full build (*including* JavaDocs and unit/integration *tests*) use JDK 11+.\n```shell\n./gradlew clean build\n```\nIf you are using Gradle 4.10 or later, the build will automatically include the JavaFX-based `wallettemplate` module. The outputs are under the `build` directory.\n\nTo perform a full build *without* unit/integration *tests* use:\n```shell\n./gradlew clean build -x test\n```\n\nTo perform a full build and install it in the local maven repository:\n```shell\n./gradlew assemble\n```\n\nto generate a website with useful information like JavaDocs.\n\nThe outputs are under the `target` directory.\n\n#### Deployment\n\nTo deploy to the maven repository:\n```bash\n./gradlew publish\n```\n#### Building from an IDE\n\nAlternatively, just import the project using your IDE. [IntelliJ](http://www.jetbrains.com/idea/download/) has Gradle integration built-in and has a free Community Edition. Simply use `File | New | Project from Existing Sources` and locate the `build.gradle` in the root of the cloned project source tree.\n\nThe dashjbls library must still using the instructions above.\n\n### Example applications\n\nThese are found in the `examples` module.\n\n### Where next?\n\nNow you are ready to [follow the tutorial](https://bitcoinj.github.io/getting-started).  Though this is for bitcoinj, there is no equivalent site for dashj.\n\n### Building and Using the Wallet Tool\n\nThe **dashj** `tools` subproject includes a command-line Wallet Tool (`wallet-tool`) that can be used to create and manage **dashj**-based wallets (both the HD keychain and SPV blockchain state.) Using `wallet-tool` on Dash's test net is a great way to learn about Dash and **dashj**.\n\nTo build an executable shell script that runs the command-line Wallet Tool, use:\n```\ngradle dashj-tools:installDist\n```\n\nYou can now run the `wallet-tool` without parameters to get help on its operation:\n```\n./tools/build/install/wallet-tool/bin/wallet-tool\n```\n\nTo create a test net wallet file in `~/dashj/dashj-test.wallet`, you would use:\n```\nmkdir ~/dashj\n```\n```\n./tools/build/install/wallet-tool/bin/wallet-tool --net=TEST --wallet=$HOME/dashj/dashj-test.wallet create\n```\n\nTo sync the newly created wallet in `~/dashj/dashj-test.wallet` with the test net, you would use:\n```\n./tools/build/install/wallet-tool/bin/wallet-tool --net=TEST --wallet=$HOME/dashj/dashj-test.wallet sync\n```\n\nTo dump the state of the wallet in `~/dashj/dashj-test.wallet` with the test net, you would use:\n```\n./tools/build/install/wallet-tool/bin/wallet-tool --net=TEST --wallet=$HOME/dashj/dashj-test.wallet dump\n```\n\nNote: These instructions are for macOS/Linux, for Windows use the `tools/build/install/wallet-tool/bin/wallet-tool.bat` batch file with the equivalent Windows command-line commands and options.\n\n### Example applications\n\nThese are found in the `examples` module.\n\n### Where next?\n\nNow you are ready to [follow the tutorial](https://bitcoinj.github.io/getting-started).\n\n### Testing a SNAPSHOT build\n\nBuilding apps with official releases of **dashj** is covered in the [tutorial](https://bitcoinj.github.io/getting-started).\n\n", "release_dates": ["2023-12-23T03:16:49Z", "2023-12-08T15:58:53Z", "2023-09-08T20:44:12Z", "2023-08-24T14:14:00Z", "2023-07-03T18:21:54Z", "2023-07-03T18:21:23Z", "2023-07-03T18:20:55Z", "2023-05-19T15:28:54Z", "2022-09-01T15:19:01Z", "2022-08-09T15:33:35Z", "2022-05-18T01:22:05Z", "2022-05-01T05:31:12Z", "2021-10-26T18:27:55Z", "2021-09-28T21:04:24Z", "2021-09-28T21:10:20Z", "2021-05-25T13:24:17Z", "2020-10-10T01:01:45Z", "2020-04-10T15:44:45Z", "2020-02-19T01:49:30Z", "2020-02-05T16:20:55Z", "2019-09-10T18:18:36Z", "2019-08-03T14:34:01Z", "2019-05-12T04:45:50Z", "2019-04-17T07:33:53Z", "2019-03-14T05:09:11Z", "2019-02-27T02:09:33Z", "2017-08-02T02:35:36Z"]}, {"name": "dashj-android", "description": "Android JNI libraries for BLS, X11 and scrypt which are used by DashJ", "language": "C", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "DashJ BLS for Android\n\n```bash\ngit submodule update --init --recursive\n./gradlew build\n```\n\nPublish to Maven Local\n```\n./gradlew publishToMavenLocal\n```\nPublish to Maven Central\n```\n./gradlew publish\n```", "release_dates": []}, {"name": "dashj-bls", "description": "DashJ BLS library", "language": "C++", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# dashj-bls\n\n> A Java library for working with Dash\n\n[![Tests](https://github.com/dashevo/dashj-bls/workflows/Java%20CI/badge.svg?branch=master)](https://github.com/dashevo/dashj-bls/actions)\n![codecov](https://codecov.io/gh/dashevo/dashj-bls/branch/master/graph/badge.svg)\n### Welcome to dashj\n\nThe dashj-bls library is a Java implementation of the Dash BLS library.\n\n### Technologies\n\n* Java 11\n* [Maven 3+](http://maven.apache.org) - for building the project\n\n### Getting started\n\nTo get started, it is best to have the latest JDK and Maven installed. The HEAD of the `master` branch contains the latest development code and various production releases are provided on feature branches.\n\n#### Building from the command line\nTo initialize the repo after cloning it: \n```\ngit submodule update  --init --recursive\ngit apply catch_changes.patch\n```\nTo perform a full build use (this includes the dashjbls shared library):\n```\nmvn clean package -Dmaven.javadoc.skip=true\n```\nTo perform a full build without building the bls shared library and skip the test:\n```\n\nmvn clean package -Pno-build-bls -DskipTests -Dmaven.javadoc.skip=true\n```\nTo perform a full build and install it in the local maven repository:\n```\nmvn clean install\n```\nYou can also run\n```\nmvn site:site\n```\nto generate a website with useful information like JavaDocs.\n\nTo publish to maven central:\n```bash\nmvn deploy -DskipTests -Dmaven.javadoc.skip=true\n\n```\n\n\nThe outputs are under the `target` directory.\n\n#### Deployment\n\nTo deploy to the maven repository:\n\nmvn clean deploy -DskipTests -P release\n\n#### Building from an IDE\n\nAlternatively, just import the project using your IDE. [IntelliJ](http://www.jetbrains.com/idea/download/) has Maven integration built-in and has a free Community Edition. Simply use `File | Import Project` and locate the `pom.xml` in the root of the cloned project source tree.\n\nThe dashjbls library must still be built with `mvn`.\n", "release_dates": ["2022-11-09T03:17:30Z", "2022-11-02T04:00:19Z"]}, {"name": "dashj-merk", "description": "DashJ: Rust bindings for Merk", "language": "Kotlin", "license": null, "readme": "# Installing Build tools\n```shell\nrustup install nightly\n```\n\n# Build with Gradle\n```shell\n./gradlew assemble test\n```\n\n# Build with Gradle and Run Tests\n```shell\n./gradlew assemble test\n```\n# Build Rust Library Manually\n```shell\ncd src/main/rust\ncargo +nightly build --release\n```\n\n# Publish\n```shell\n./gradlew uploadArchives\n```\n\nTODO: Include dashj_merk builds", "release_dates": []}, {"name": "dashj-merk-android", "description": "Android Library for DashJ Merk", "language": "Rust", "license": null, "readme": "# DashJ Merk Library for Android\n\n##Build Instructions:\nThese commands do not work on Windows due to missing toolchains for Android.\n\n###Run once:\n```shell\nrustup install nightly\nrustup +nightly target add armv7-linux-androideabi   # for arm\nrustup +nightly target add i686-linux-android        # for x86\nrustup +nightly target add aarch64-linux-android     # for arm64\nrustup +nightly target add x86_64-linux-android      # for x86_64\n```\n###followed by:\n```shell\n./gradlew assemble\n```\n# Publishing to maven central\n```shell\n./gradlew uploadArchives\n```", "release_dates": []}, {"name": "dashsync-iOS", "description": "Blockchain Dash framework for iOS", "language": "Objective-C", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# DashSync - iOS\n\n![banner](Docs/github-dashsync-image.jpg)\n\n[![Version](https://img.shields.io/cocoapods/v/DashSyncPod.svg?style=flat)](http://cocoapods.org/pods/DashSyncPod)\n[![License](https://img.shields.io/github/license/dashpay/dashsync-iOS)](https://github.com/dashpay/dashsync-iOS/blob/master/LICENSE)\n[![dashpay/dashsync-iOS](https://tokei.rs/b1/github/dashpay/dashsync-iOS?category=lines)](https://github.com/dashpay/dashsync-iOS)\n![Platform](https://img.shields.io/badge/platform-iOS-lightgrey)\n\n| Branch | Tests                                                                                      | Coverage                                                                                                                             | Linting                                                                    |\n|--------|--------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------|\n| master | [![Tests](https://github.com/dashpay/dashsync-iOS/workflows/Tests/badge.svg?branch=master)](https://github.com/dashpay/dashsync-iOS/actions) | [![codecov](https://codecov.io/gh/dashevo/dashsync-iOS/branch/master/graph/badge.svg)](https://codecov.io/gh/dashevo/dashsync-iOS) | ![Lint](https://github.com/dashpay/dashsync-iOS/workflows/Lint/badge.svg) |\n\n## Example\n\n### Requirements\n\n- Install last version of rust:\n`curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`\n- Install protobuf and grpc:\n`brew install protobuf grpc`\n- Install cmake and make sure it is located in one of the following folders: `${PLATFORM_PATH}/Developer/usr/bin, ${DEVELOPER}/usr/bin:/usr/local/bin, /usr/bin, /bin, /usr/sbin, /sbin, /opt/homebrew/bin`\n\nTo run the example project, clone the repo, and run `pod install` from the Example directory first.\n\n## Installation\n\nDashSyncPod is available through [CocoaPods](http://cocoapods.org). To install\nit, simply add the following line to your Podfile:\n\n```ruby\npod 'DashSyncPod'\n```\n\n## Contributing\n\nPlease abide by the [Code of Conduct](CODE_OF_CONDUCT.md) in all interactions.\n\nBefore contributing to the project, please take a look at the [contributing guidelines](CONTRIBUTING.md)\nand the [style guide](STYLE_GUIDE.md).\n\nTo get more active, join the Dash developer community (recommended) at [Discord](https://discord.com/channels/484546513507188745/614505310593351735) or jump onto the [Forum](https://www.dash.org/forum/).\n\nLearn more by reading the code and our [specifications](https://dashcore.readme.io/docs) or go deeper by reading our [Dash Improvement Proposals](https://github.com/dashpay/dips).\n\n## Author\n\nquantumexplorer, quantum@dash.org\n\n## License\n\nDashSyncPod is available under the MIT license. See the LICENSE file for more info.\n", "release_dates": ["2023-12-08T14:23:04Z", "2023-11-24T07:21:02Z", "2023-09-21T06:00:21Z", "2023-07-21T14:20:14Z", "2023-07-18T10:48:18Z", "2023-07-17T10:25:59Z", "2023-07-12T09:09:14Z", "2023-07-11T18:57:52Z", "2023-07-10T12:21:47Z", "2023-07-09T13:53:53Z", "2023-07-07T06:07:03Z", "2023-05-18T06:29:05Z", "2023-05-17T12:23:55Z", "2023-05-16T15:46:45Z", "2023-01-17T11:44:30Z"]}, {"name": "dashwallet-ios", "description": "dashwallet - dash iPhone wallet", "language": "Objective-C", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Dash Wallet\n\n[![Build Status](https://travis-ci.com/dashevo/dashwallet-ios.svg?branch=master)](https://travis-ci.com/dashevo/dashwallet-ios) [![License](https://img.shields.io/badge/license-MIT-green)](https://github.com/dashevo/dashwallet-ios/blob/master/LICENSE) [![Platform](https://img.shields.io/badge/platform-iOS%20%7C%20watchOS-blue)](https://github.com/dashevo/dashwallet-ios)\n\n<p align=\"center\" >\n<img src=\"https://docs.dash.org/en/stable/_images/dash_logo.png\" alt=\"Dash Wallet logo\" title=\"Dash Wallet\" width=\"300\">\n</p>\n\n*Dash Wallet* (breadwallet fork) is a real standalone [Dash](https://dash.org) client. There is no server to get hacked or go down, so you can always access your money.\nUsing [SPV](https://en.bitcoin.it/wiki/Thin_Client_Security#Header-Only_Clients) mode, *Dash Wallet* connects directly to the Dash network with the fast performance you need on a mobile device.\n*Dash Wallet* is designed to protect you from malware, browser security holes, even physical theft. With AES hardware encryption, app sandboxing,\nkeychain and code signatures, *Dash Wallet* represents a significant security advantage over web and desktop wallets, and other mobile platforms.\nSimplicity is *Dash Wallet*\u2019s core design principle. A simple backup phrase is all you need to restore your wallet on another device if yours is ever lost or broken.\nBecause *Dash Wallet* is [deterministic](https://dashpay.atlassian.net/wiki/display/DOC/Whitepaper), your balance and transaction history can be recovered from just your backup phrase.\n\n## Features\n\n- [\"simplified payment verification\"](https://dashpay.atlassian.net/wiki/display/DOC/Official+Documentation) for fast mobile performance\n- no server to get hacked or go down\n- single backup phrase that works forever\n- private keys never leave your device\n- import [password protected](https://dashpay.atlassian.net/wiki/display/DOC/Official+Documentation) paper wallets\n- [\u201cpayment protocol\u201d](https://dashpay.atlassian.net/wiki/display/DOC/Official+Documentation) payee identity certification\n- [Uphold](https://uphold.com) integration\n\n## Download\n\n[![Download on the AppStore](https://linkmaker.itunes.apple.com/en-gb/badge-lrg.svg?releaseDate=2017-07-19&kind=iossoftware&bubble=ios_apps)](https://apps.apple.com/app/dash-wallet/id1206647026?mt=8)\n\n## Getting Started\n\nTo run *Dash Wallet* iOS app on your device or simulator clone the repo and make sure you installed needed [Requirements](#Requirements).\nThen run `pod install` in the cloned directory.\nOpen `DashWallet.xcworkspace` in Xcode and run the project.\n\n## Requirements\n\n- Xcode 11\n- Dependency manager [CocoaPods](https://cocoapods.org). Install via `gem install cocoapods`\n\n### DashPay Requirements\n\nCurrently, DashPay wallet is under active development so it requires a few additional steps to make it work.\n\n1. Clone [DashSync](https://github.com/dashevo/dashsync-iOS) and [dapi-grpc](https://github.com/dashevo/dapi-grpc) repositories:  \n`git clone https://github.com/dashevo/dashsync-iOS.git DashSync`  \n`git clone https://github.com/dashevo/dapi-grpc.git dapi-grpc`\n\nTo simplify developing process we use local podspec dependencies and it's important to preserve the following folder structure:\n```\n../DashSync/\n../dapi-grpc/\n../dashwallet-ios/\n```\n\n2. Install protobuf and grpc:\n`brew install protobuf grpc`\n\n3. Install last version of rust:\n`curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`\n\n4. Install cmake and make sure it is located in one of the following folders:\n`${PLATFORM_PATH}/Developer/usr/bin, ${DEVELOPER}/usr/bin:/usr/local/bin, /usr/bin, /bin, /usr/sbin, /sbin, /opt/homebrew/bin`\n\n5. Run `pod install` in the wallet directory.\n\n### Optional Requirements\n\n#### Objective-C Related\n- Formatting tools: [clang-format](https://clang.llvm.org/docs/ClangFormat.html). Install via `brew install clang-format`.\n\n#### Swift Related\n- [SwiftFormat](https://github.com/nicklockwood/SwiftFormat). Install via `brew install swiftformat`. \n- [SwiftLint](https://github.com/realm/SwiftLint).  Install via `brew install swiftlint`.\n\n#### Localization\n\n- Localized files helper tool [BartyCrouch](https://github.com/Flinesoft/BartyCrouch). Install via `brew install bartycrouch`.\n\n## Contribution Guidelines\n\nWe use Objective-C for developing iOS App and underlying [DashSync](https://github.com/dashevo/dashsync-iOS) library and Swift for the Watch App.\n\nGeneral information on developing conventions you can find at [Apple Developer Portal](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/ProgrammingWithObjectiveC/Conventions/Conventions.html).\nFor more specific Objective-C guidelines we stick with [NYTimes Objective-C Style Guide](https://github.com/nytimes/objective-c-style-guide).\n\nOur code style is enforced by [clang-format](#Objective-C-Related) and [SwiftFormat / SwiftLint](#Swift-Related).\n\n## Documentation\n\nOfficial Dash documentation is available [here](https://docs.dash.org).\n\n## URL Schemes\n\nFor more information follow this [documentation page](https://docs.dash.org/en/stable/wallets/ios/advanced-functions.html#url-scheme).\n\n## WARNING\n\nInstallation on jailbroken devices is strongly discouraged.\n\nAny jailbreak app can grant itself access to every other app's keychain data and rob you by self-signing as described [here](http://www.saurik.com/id/8) and including `<key>application-identifier</key><string>*</string>` in its .entitlements file.\n\n## License\n\n*Dash Wallet* is available under the MIT license. See the LICENSE file for more info.\n", "release_dates": ["2023-12-09T10:26:23Z", "2023-10-04T06:37:49Z", "2023-08-30T09:33:29Z", "2023-08-12T09:14:18Z", "2023-08-03T10:28:17Z", "2023-07-25T11:02:43Z", "2023-07-08T10:38:16Z", "2023-05-22T03:53:52Z", "2023-05-11T14:06:36Z", "2023-04-12T07:42:37Z", "2023-03-29T05:11:20Z", "2023-03-04T15:34:31Z", "2023-02-22T09:59:37Z", "2023-02-10T08:40:44Z", "2023-01-12T04:41:20Z", "2023-01-09T09:08:01Z", "2023-01-09T04:20:47Z", "2022-12-15T16:17:21Z", "2022-12-02T08:14:10Z"]}, {"name": "dash_hash", "description": null, "language": "C", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "dash_hash (python) v1.4.0\n===========================\n\nPython module for Dash's X11 hashing.\n\n\nInstall\n-------\n\nPython 3.5+ or 2.7+ and the associated development package (e.g., `python3-dev`) is required as well as a gcc.\n\n    $ pip3 install -r requirements.txt .\n\nTest\n-------\n\nAfter installation, test hash.\n\n    $ python3 test.py\n\nUninstall\n-------\n    $ pip3 uninstall dash_hash\n\nCredits\n-------\n\n* Module written by @chaeplin https://github.com/chaeplin/xcoin-hash\n* Module maintained by @eduffield https://github.com/darkcoinproject/xcoin-hash\n* Module maintained by @flare https://github.com/nightlydarkcoin/xcoin-hash\n* Module maintained by @vertoe https://github.com/vertoe/darkcoin_hash\n", "release_dates": []}, {"name": "data-contract-creator", "description": "Data contract creator for Dash Platform", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<p align=\"center\">\n    <img alt=\"babel\" src=\"https://upload.wikimedia.org/wikipedia/commons/b/bf/Dash_logo_2018_rgb_for_screens.png\" width=\"400\">\n</p>\n\n# Data Contract Creator\n\nThis is a web app, hosted at [dashpay.io](https://dashpay.io/), to help people intuitively create and edit Dash Platform data contracts. There are three options available for getting started. Users can:\n\n1. Use the ChatGPT widget to automatically generate a data contract based on the provided context.\n2. Manually fill out a dynamic form.\n3. Import an existing data contract and edit it.\n\nThe app also validates the data contracts against Dash Platform Protocol, so users can save time and money by validating before actually submitting data contracts to Dash Platform.\n\nIn the future, users will be able to register data contracts to Dash Platform directly from the web app. However, for now, they must use the [JavaScript SDK](https://dashplatform.readme.io/docs/tutorial-register-a-data-contract), where they can copy and paste the contracts generated from here.\n\nThis app is built in Rust using the Yew framework and WebAssembly.\n\n## Features\n\n- Use ChatGPT to generate and modify Platform-compliant (usually) data contracts\n- Dynamically create and modify data contracts using a web interface\n- Import existing data contract schemas for editing\n- Validate data contract schemas against Dash Platform Protocol rules\n\n## Usage\n\n### ChatGPT\n\n1. Paste your OpenAI API key into the field at the top left.\n2. Describe your app in a few words or sentences and press return.\n3. Have a look at the generated contract and note any changes you'd like to make.\n4. It's recommended to make changes manually using the dynamic form, but you may also describe changes to the AI.\n\n### Dynamic form\n\n1. Use the dynamic form on the left to add, edit, or remove document types, properties, and indexes manually.\n2. Once finished, click the \"Submit\" button.\n3. View the generated contract and potential validation errors with the right-side interface.\n\n### Import a Data Contract\n\n1. If the right-side text area is already populated, click the \"Clear\" button.\n2. Paste a data contract into the right-side text area.\n3. Click the \"Import\" button. The dynamic form should automatically populate.\n\n## Setup\n\nThis app is available to use at [dashpay.io](https://dashpay.io/), however, you can also run the code locally, following these steps:\n\nYew environment:\n\n1. Install WebAssembly target: `rustup target add wasm32-unknown-unknown`\n2. Install Trunk: `cargo install --locked trunk`\n\nApp:\n\n1. Clone the repository: `git clone https://github.com/dashpay/data-contract-creator.git`\n2. Change into the project directory: `cd data-contract-creator`\n3. **Mac users** may need to run the following commands if they have issues compiling certain libraries such as secp256k1-sys:\n```\nexport AR_PATH=$(command -v llvm-ar)\nexport CLANG_PATH=$(command -v clang)\nexport AR=${AR_PATH} CC=${CLANG_PATH} ${BUILD_COMMAND}\nexport AR=${AR_PATH} CC=${CLANG_PATH} ${BINDGEN_COMMAND}\n```\n4. Start the app `trunk serve --open`\n\n## Future work\n\nOnce a wallet capable of authentication is available for Dash Platform, this app should integrate a \"connect wallet\" button so the generated data contract can be directly registered on Dash Platform from [dashpay.io](https://dashpay.io/).\n\n## Contributing\n\nContributions are welcome! Please submit a pull request or open an issue if you encounter any problems or have suggestions for improvement.\n\n## License\n\nThis project is licensed under the [MIT License](https://opensource.org/licenses/MIT).\n", "release_dates": []}, {"name": "dips", "description": "Dash Improvement Proposals", "language": "Python", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Dash Improvement Proposals (DIPs)\n\nDIP stands for Dash Improvement Proposal. Similar to Bitcoin's [BIPs](https://github.com/bitcoin/bips/), a DIP is a design document providing information to the Dash community, or describing a new feature for Dash or its processes or environment. The DIP should provide a concise technical specification of the feature and a rationale for the feature.\n\nBecause Dash is forked from the Bitcoin codebase, many of the BIPs can be applied to Dash as well (a list of the BIPs updated to include Dash-specific details can be found [here](https://github.com/dashevo/bips)). The purpose of the DIPs is not to duplicate those which exist as BIPs, but to introduce protocol upgrades or feature specifications which are unique to Dash.\n\n## Contributions\n\nWe use the same general guidelines for introducing a new DIP as specified in [BIP 2](https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki), with a few differences. Specifically:\n\n* Instead of the BIP editor, initiate contact with the Dash Core development team and your request should be routed to the DIP editor(s). The DIP workflow mimics the BIP workflow.\n* Recommended licenses include the MIT license\n* Markdown format is the preferred format for DIPs\n* Following a discussion, the proposal should be submitted to the DIPs git repository as a pull request. This draft must be written in BIP/DIP style as described in [BIP 2](https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki), and named with an alias such as \"dip-johndoe-infinitedash\" until the editor has assigned it a DIP number (authors MUST NOT self-assign DIP numbers).\n\n## Dash Improvement Proposal Summary\n\nNumber | Layer | Title | Owner | Type | Status\n--- | --- | --- | --- | --- | ---\n[1](dip-0001.md) | Consensus | Initial Scaling of the Network | Darren Tapp | Standard | Final\n[2](dip-0002.md) | Consensus | Special Transactions | Samuel Westrich, Alexander Block, Andy Freer | Standard | Final\n[3](dip-0003.md) | Consensus | Deterministic Masternode Lists | Samuel Westrich, Alexander Block, Andy Freer, Darren Tapp, Timothy Flynn, Udjinm6, Will Wray | Standard | Final\n[4](dip-0004.md) | Consensus | Simplified Verification of Deterministic Masternode Lists | Alexander Block, Samuel Westrich, UdjinM6, Andy Freer | Standard | Final\n[5](dip-0005.md) | Consensus | Blockchain Users | Alexander Block, Cofresi, Andy Freer, Nathan Marley, Anton Suprunchuk, Darren Tapp, Thephez, Udjinm6, Alex Werner, Samuel Westrich | Standard | Withdrawn\n[6](dip-0006.md) | Consensus | Long-Living Masternode Quorums | Alexander Block | Standard | Final\n[7](dip-0007.md) | Consensus | LLMQ Signing Requests / Sessions | Alexander Block | Standard | Final\n[8](dip-0008.md) | Consensus | ChainLocks | Alexander Block | Standard | Final\n[9](dip-0009.md) | Applications | Feature Derivation Paths | Samuel Westrich | Informational | Proposed\n[10](dip-0010.md) | Consensus | LLMQ InstantSend | Alexander Block | Standard | Final\n[11](dip-0011.md) | Consensus | Identities | Ivan Shumkov, Anton Suprunchuk, Samuel Westrich, Cofresi | Standard | Proposed\n[12](dip-0012.md) | Consensus | Dash Platform Name Service | Ivan Shumkov, Anton Suprunchuk | Standard | Proposed\n[13](dip-0013.md) | Applications | Identities in Hierarchical Deterministic Wallets | Samuel Westrich | Informational | Proposed\n[14](dip-0014.md) | Applications | Extended Key Derivation using 256-Bit Unsigned Integers | Samuel Westrich | Informational | Proposed\n[15](dip-0015.md) | Applications | DashPay | Samuel Westrich, Eric Britten | Standard | Proposed\n[16](dip-0016.md) | Applications | Headers First Synchronization on Simple Payment Verification Wallets | Samuel Westrich | Informational | Proposed\n[20](dip-0020.md) | Consensus | Dash Opcode Updates | Mart Mangus | Standard | Final\n[21](dip-0021.md) | Consensus | LLMQ DKG Data Sharing | dustinface | Standard | Final\n[22](dip-0022.md) | Consensus | Making InstantSend Deterministic using Quorum Cycles | Samuel Westrich, UdjinM6 | Standard | Final\n[23](dip-0023.md) | Consensus | Enhanced Hard Fork Mechanism | Pasta | Standard | Proposed\n[24](dip-0024.md) | Consensus | Long-Living Masternode Quorum Distribution and Rotation | Samuel Westrich & Virgile Bartolo | Standard | Final\n[25](dip-0025.md) | Peer Services | Compressed Block Headers | gabriel-bjg, Thephez, UdjinM6 | Standard | Proposed\n[26](dip-0026.md) | Consensus | Multi-Party Payout | Timothy Munsell, UdjinM6 | Standard | Proposed\n27 |  |  |  |  | Reserved\n[28](dip-0028.md) | Consensus | Evolution Masternodes | Paul DeLucia, Odysseas Gabrielides, \u0141ukasz Klimek, Ivan Shumkov, Samuel Westrich | Standard | Final\n[29](dip-0029.md) | Consensus | Randomness Beacon For LLMQ Selection | Virgile Bartolo | Standard | Proposed\n\n## License\n\nUnless otherwise specified, Dash Improvement Proposals (DIPs) are released under the terms of the MIT license. See [LICENSE](LICENSE) for more information or see the [MIT License](https://opensource.org/licenses/MIT).\n", "release_dates": []}, {"name": "docker-compose", "description": "Manage Docker-Compose via Node.js", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "[![Conventional Commits](https://img.shields.io/badge/Conventional%20Commits-1.0.0-yellow.svg)](https://conventionalcommits.org) [![Join the chat at https://gitter.im/pdmlab/docker-compose](https://badges.gitter.im/pdmlab/docker-compose.svg)](https://gitter.im/pdmlab/docker-compose?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) <img src=\"https://img.shields.io/github/workflow/status/pdmlab/docker-compose/Node.js%20CI/master\" /> <img src=\"https://img.shields.io/npm/dm/docker-compose.svg\" />\n\n# Manage Docker-Compose via Node.js\n\n`docker-compose` is a small library that allows you to run [docker-compose](https://docs.docker.com/compose/)(which is still required) via Node.js. This is useful to bootstrap test environments.\n\n### This package only works with Docker Compose v2 syntax. \n\nLegacy `docker-compose` syntax is not supported in this repo.\n\n\n## Installation\n\n```bash\nyarn add --dev docker-compose\n```\n\n## Documentation\n\nThe documentation can be found [here](https://pdmlab.github.io/docker-compose/).\n\n## Example\n\nTo start service containers based on the `docker-compose.yml` file in your current directory, just call `compose.up` like this:\n\n```javascript\ncompose.upAll({ cwd: path.join(__dirname), log: true }).then(\n  () => {\n    console.log('done')\n  },\n  (err) => {\n    console.log('something went wrong:', err.message)\n  }\n)\n```\n\nTo execute command inside a running container\n\n```javascript\ncompose.exec('node', 'npm install', { cwd: path.join(__dirname) })\n```\n\n## Running the tests\n\nWhile `docker-compose` runs on Node.js 6+, running the tests requires you to use Node.js 8+ as they make use of `async/await`.\n\n```bash\nyarn test\n```\n\n## Want to help?\n\nThis project is just getting off the ground and could use some help with cleaning things up and refactoring.\n\nIf you want to contribute - we'd love it! Just open an issue to work against so you get full credit for your fork. You can open the issue first so we can discuss and you can work your fork as we go along.\n\nIf you see a bug, please be so kind as to show how it's failing, and we'll do our best to get it fixed quickly.\n\nBefore sending a PR, please [create an issue](https://github.com/PDMLab/docker-compose/issues/new) to introduce your idea and have a reference for your PR.\n\nWe're using [conventional commits](https://www.conventionalcommits.org), so please use it for your commits as well.\n\nAlso please add tests and make sure to run `yarn lint`.\n\n### Discussions\n\nIf you want to discuss an `docker-compose` issue or PR in more detail, feel free to [start a discussion](https://github.com/PDMLab/docker-compose/discussions).\n\n## License\n\nMIT License\n\nCopyright (c) 2017 - 2021 PDMLab\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n", "release_dates": ["2023-09-18T09:42:08Z", "2023-09-14T15:18:45Z", "2023-04-25T14:00:15Z", "2022-06-28T08:32:49Z", "2022-06-09T17:16:48Z"]}, {"name": "docker-dashd", "description": "Docker image that runs the Dash dashd node in a container for easy deployment", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "Dashd for Docker\n================\n\n[![Docker Stats](http://dockeri.co/image/dashpay/dashd)](https://hub.docker.com/r/dashpay/dashd/)\n\n[![Build Status](https://travis-ci.org/dashpay/docker-dashd.svg?branch=master)](https://travis-ci.org/dashpay/docker-dashd/)\n\n\nDocker image that runs the Dash dashd node in a container for easy deployment.\n\n\nRequirements\n------------\n\n* Physical machine, cloud instance, or VPS that supports Docker (i.e. Vultr, Digital Ocean, KVM or XEN based VMs) running Ubuntu 18.04 or later (*not OpenVZ containers!*)\n* At least 40 GB to store the block chain files\n* At least 2 GB RAM + 2 GB swap file\n\n\nReally Fast Quick Start\n-----------------------\n\nOne liner for Ubuntu 18.04 LTS machines with JSON-RPC enabled on localhost and adds upstart init script:\n\n    curl https://raw.githubusercontent.com/dashpay/docker-dashd/master/bootstrap-host.sh | sh -s bionic\n\n\nQuick Start\n-----------\n\n1. Create a `dashd-data` volume to persist the dashd blockchain data, should exit immediately.  The `dashd-data` container will store the blockchain when the node container is recreated (software upgrade, reboot, etc):\n\n        docker volume create --name=dashd-data\n        docker run -v dashd-data:/dash --name=dashd-node -d \\\n            -p 9999:9999 \\\n            -p 127.0.0.1:9998:9998 \\\n            dashpay/dashd\n\n2. Verify that the container is running and dashd node is downloading the blockchain\n\n        $ docker ps\n        CONTAINER ID        IMAGE                         COMMAND             CREATED             STATUS              PORTS                                              NAMES\n        d0e1076b2dca        dashpay/dashd:latest          \"dash_oneshot\"      2 seconds ago       Up 1 seconds        127.0.0.1:9998->9998/tcp, 0.0.0.0:9999->9999/tcp   dashd-node\n\n3. You can then access the daemon's output thanks to the [docker logs command]( https://docs.docker.com/reference/commandline/cli/#logs)\n\n        docker logs -f dashd-node\n\n4. Install optional init scripts for upstart and systemd are in the `init` directory.\n\n\nDocumentation\n-------------\n\n* To run in testnet, add environment variable `TESTNET=1` to `docker run` as such:\n\n        docker run -v dashd-data:/dash --name=dashd-node -d \\\n            --env TESTNET=1 \\\n            -p 9999:9999 \\\n            -p 127.0.0.1:9998:9998 \\\n            dashpay/dashd\n\n* Additional documentation in the [docs folder](docs).\n\nCredits\n-------\n\nOriginal work by Kyle Manna [https://github.com/kylemanna/docker-bitcoind](https://github.com/kylemanna/docker-bitcoind).\nModified to use Dash Core instead of Bitcoin Core.\n\n", "release_dates": []}, {"name": "docker-envoy", "description": null, "language": "Python", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": ["2023-07-19T01:11:19Z"]}, {"name": "docker-sentinel", "description": null, "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "- [Introduction](#introduction)\n    - [Changelog](CHANGELOG.md)\n- [Contributing](#contributing)\n- [Team](#team)\n- [Issues](#issues)\n- [Announcements](#announcements)\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Configuration](#configuration)\n- [Maintenance](#maintenance)\n- [Features](#features)\n- [References](#references)\n\n\n# Introduction\n\nDockerfile to build a [Dash Sentinel](https://github.com/dashpay/sentinel/) container image.\n\n# Contributing\n# Team\n# Issues\n# Announcements\n# Prerequisites\n# Installation\n# Quick-start\n# Configuration\n# Maintenance\n# Features\n# Feferences\n", "release_dates": []}, {"name": "docs", "description": "Dash User Documentation", "language": "Python", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Dash Docs\n\n[![Build status](https://img.shields.io/readthedocs/dash-docs/stable)](https://readthedocs.org/projects/dash-docs/builds/)\n[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen)](https://github.com/RichardLitt/standard-readme)\n\nDash User Documentation\n\nThe official Dash documentation is oriented towards the average user and serves to describe all aspects of the Dash ecosystem, ranging from information for new users through to guides on more difficult tasks such as maintaining a masternode. This user documentation is available at https://docs.dash.org, while developer documentation is maintained separately at https://docs.dash.org/core and https://dashplatform.readme.io/.\n\n## Contributing\n\nThis documentation is written in [reStructuredText](https://docutils.sourceforge.io/rst.html) and is designed to be built with [Sphinx](https://www.sphinx-doc.org/) and hosted by [Read the Docs](https://readthedocs.org/). Feel free to [open an issue](https://github.com/dashpay/docs/issues/new/choose) or submit PRs modifying the English source text in this repository. Contributions to translations of the source text are welcomed on [Transifex](https://www.transifex.com/dash/dash-docs/).\n\n## License\n\n[MIT](/LICENSE) \u00a9 Dash Core Group, Inc.\n", "release_dates": []}, {"name": "docs-core", "description": "Dash Core documentation", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Dash Core Docs\n\n[![Build status](https://img.shields.io/readthedocs/dash-docs-core/stable)](https://readthedocs.org/projects/dash-docs-core/builds/)\n[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen)](https://github.com/RichardLitt/standard-readme)\n\nDash Core Documentation\n\nWelcome to the Dash Core developer documentation. You\u2019ll find sections for\nreference information, API details, guides, examples and Dash Core wallet\ninformation to help you start working with Dash as quickly as possible. This\ncore developer documentation is available at\nhttps://docs.dash.org/projects/core, while user documentation is maintained at\nhttps://docs.dash.org/ and Platform developer documentation at\nhttps://docs.dash.org/projects/platform.\n\n## Contributing\n\nThis documentation is written in primarily in\n[markdown](https://www.markdownguide.org/) and uses the [myst-parser\nextension](https://myst-parser.readthedocs.io/en/latest/index.html) for\ncompatibility with [reStructuredText](https://docutils.sourceforge.io/rst.html).\nIt is designed to be built with [Sphinx](https://www.sphinx-doc.org/) and hosted\nby [Read the Docs](https://readthedocs.org/). Feel free to [open an\nissue](https://github.com/dashpay/docs-core/issues/new/choose) or submit PRs\nmodifying the English source text in this repository.\n\n## License\n\n[MIT](/LICENSE) \u00a9 Dash Core Group, Inc.\n", "release_dates": []}, {"name": "docs-platform", "description": "Dash Platform documentation", "language": "HTML", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Dash Platform Docs\n\n[![Build\nstatus](https://img.shields.io/readthedocs/dash-docs-platform/stable)](https://readthedocs.org/projects/dash-docs-platform/builds/)\n[![standard-readme\ncompliant](https://img.shields.io/badge/readme%20style-standard-brightgreen)](https://github.com/RichardLitt/standard-readme)\n\nDash Platform Documentation\n\nWelcome to the Dash Platform developer documentation. You\u2019ll find sections for reference\ninformation, API details, tutorials, and library information to help you start working with Dash as\nquickly as possible. This Platform developer documentation is available at\nhttps://docs.dash.org/projects/platform, while user documentation is maintained at\nhttps://docs.dash.org/ and Core developer documentation at https://docs.dash.org/projects/core.\n\n## Contributing\n\nThis documentation is written in primarily in [markdown](https://www.markdownguide.org/) and uses\nthe [myst-parser extension](https://myst-parser.readthedocs.io/en/latest/index.html) for\ncompatibility with [reStructuredText](https://docutils.sourceforge.io/rst.html). It is designed to\nbe built with [Sphinx](https://www.sphinx-doc.org/) and hosted by [Read the\nDocs](https://readthedocs.org/). Feel free to [open an\nissue](https://github.com/dashpay/docs-platform/issues/new/choose) or submit PRs modifying the\nEnglish source text in this repository.\n\n## License\n\n[MIT](/LICENSE) \u00a9 Dash Core Group, Inc.\n", "release_dates": []}, {"name": "electrum-dash", "description": "Electrum-DASH - a Dash thin client", "language": "Python", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": []}, {"name": "electrum-dash-old", "description": "Electrum-DASH - a Dash thin client", "language": "Python", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": ["2016-01-06T20:13:27Z", "2015-12-08T16:48:15Z", "2015-11-08T17:39:11Z"]}, {"name": "electrum-dash-server", "description": "Electrum DASH Server", "language": "Python", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "Electrum-dash-server for the Electrum Dash client\n=========================================\n\n  * Author: Thomas Voegtlin (ThomasV on the bitcointalk forum)\n  * Dash codebase port Authors: ELM4Ever, Propulsion\n  * Language: Python\n\nFeatures\n--------\n\n  * The server indexes UTXOs by address, in a Patricia tree structure\n    described by Alan Reiner (see the 'ultimate blockchain\n    compression' thread in the Bitcointalk forum)\n\n  * The server requires dashd, leveldb, x11_hash and plyvel\n\n  * The server code is open source. Anyone can run a server, removing\n    single points of failure concerns.\n\n  * The server knows which set of Bitcoin addresses belong to the same\n    wallet, which might raise concerns about anonymity. However, it\n    should be possible to write clients capable of using several\n    servers.\n\nInstallation\n------------\n\n  1. To install and run a server, see INSTALL. For greater\n     detail on the installation process, see HOWTO.md.\n\n  2. To start and stop the server, use the 'electrum-dash-server' script\n\n\n\nLicense\n-------\n\nElectrum-server is made available under the terms of the MIT License.\nSee the included `LICENSE` for more details.\n", "release_dates": []}, {"name": "enquirer", "description": "Stylish, intuitive and user-friendly prompts, for Node.js. Used by eslint, webpack, yarn, pm2, pnpm, RedwoodJS, FactorJS, salesforce, Cypress, Google Lighthouse, Generate, tencent cloudbase, lint-staged, gluegun, hygen, hardhat, AWS Amplify, GitHub Actions Toolkit, @airbnb/nimbus, and many others! Please follow Enquirer's author: https://github.com", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "<h1 align=\"center\">Enquirer</h1>\n\n<p align=\"center\">\n  <a href=\"https://npmjs.org/package/enquirer\">\n    <img src=\"https://img.shields.io/npm/v/enquirer.svg\" alt=\"version\">\n  </a>\n  <a href=\"https://travis-ci.org/enquirer/enquirer\">\n    <img src=\"https://img.shields.io/travis/enquirer/enquirer.svg\" alt=\"travis\">\n  </a>\n  <a href=\"https://npmjs.org/package/enquirer\">\n    <img src=\"https://img.shields.io/npm/dm/enquirer.svg\" alt=\"downloads\">\n  </a>\n</p>\n\n<br>\n<br>\n\n<p align=\"center\">\n  <b>Stylish CLI prompts that are user-friendly, intuitive and easy to create.</b><br>\n  <sub>>_ Prompts should be more like conversations than inquisitions\u258c</sub>\n</p>\n\n<br>\n\n<p align=\"center\">\n  <sub>(Example shows Enquirer's <a href=\"#survey-prompt\">Survey Prompt</a>)</a></sub>\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/survey-prompt.gif\" alt=\"Enquirer Survey Prompt\" width=\"750\"><br>\n  <sub>The terminal in all examples is <a href=\"https://hyper.is/\">Hyper</a>, theme is <a href=\"https://github.com/jonschlinkert/hyper-monokai-extended\">hyper-monokai-extended</a>.</sub><br><br>\n  <a href=\"#built-in-prompts\"><strong>See more prompt examples</strong></a>\n</p>\n\n<br>\n<br>\n\nCreated by [jonschlinkert][jon] and [doowb][brian], Enquirer is fast, easy to use, and lightweight enough for small projects, while also being powerful and customizable enough for the most advanced use cases.\n\n- **Fast** - [Loads in ~4ms](#-performance) (that's about _3-4 times faster than a [single frame of a HD movie](http://www.endmemo.com/sconvert/framespersecondframespermillisecond.php) at 60fps_)\n- **Lightweight** - Only one dependency, the excellent [ansi-colors](https://github.com/doowb/ansi-colors) by [Brian Woodward](https://github.com/doowb).\n- **Easy to implement** - Uses promises and async/await and sensible defaults to make prompts easy to create and implement.\n- **Easy to use** - Thrill your users with a better experience! Navigating around input and choices is a breeze. You can even create [quizzes](examples/fun/countdown.js), or [record](examples/fun/record.js) and [playback](examples/fun/play.js) key bindings to aid with tutorials and videos.\n- **Intuitive** - Keypress combos are available to simplify usage.\n- **Flexible** - All prompts can be used standalone or chained together.\n- **Stylish** - Easily override semantic styles and symbols for any part of the prompt.\n- **Extensible** - Easily create and use [custom prompts](#-custom-prompts) by extending Enquirer's built-in [prompts](#-prompts).\n- **Pluggable** - Add advanced features to Enquirer using plugins.\n- **Validation** - Optionally validate user input with any prompt.\n- **Well tested** - All prompts are well-tested, and tests are easy to create without having to use brittle, hacky solutions to spy on prompts or \"inject\" values.\n- **Examples** - There are numerous [examples](examples) available to help you get started.\n\nIf you like Enquirer, please consider starring or tweeting about this project to show your support. Thanks!\n\n[issue]: https://github.com/enquirer/enquirer/issues/new\n[pulls]: https://github.com/enquirer/enquirer/pulls\n[jon]: https://github.com/jonschlinkert\n[brian]: https://github.com/doowb\n\n<br>\n\n<p align=\"center\">\n  <b>>_ Ready to start making prompts your users will love? \u258c</b><br>\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/heartbeat.gif\" alt=\"Enquirer Select Prompt with heartbeat example\" width=\"750\">\n</p>\n\n<br>\n<br>\n\n## \u276f Getting started\n\nGet started with Enquirer, the most powerful and easy-to-use Node.js library for creating interactive CLI prompts. \n\n- [Install](#-install)\n- [Usage](#-usage)\n- [Enquirer](#-enquirer)\n- [Prompts](#-prompts)\n  * [Built-in Prompts](#-built-in-prompts)\n  * [Custom Prompts](#-custom-prompts)\n- [Key Bindings](#-key-bindings)\n- [Options](#-options)\n- [Release History](#-release-history)\n- [Performance](#-performance)\n- [About](#-about)\n\n<br>\n\n## \u276f Install\nInstall with [npm](https://www.npmjs.com/):\n\n```sh\n$ npm install enquirer --save\n```\nInstall with [yarn](https://yarnpkg.com/en/):\n\n```sh\n$ yarn add enquirer\n```\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/npm-install.gif\" alt=\"Install Enquirer with NPM\" width=\"750\">\n</p>\n\n_(Requires Node.js 8.6 or higher. Please let us know if you need support for an earlier version by creating an [issue](../../issues/new).)_\n\n<br>\n\n## \u276f Usage\n### Single prompt\n\nThe easiest way to get started with enquirer is to pass a [question object](#prompt-options) to the `prompt` method.\n\n```js\nconst { prompt } = require('enquirer');\n\nconst response = await prompt({\n  type: 'input',\n  name: 'username',\n  message: 'What is your username?'\n});\n\nconsole.log(response); // { username: 'jonschlinkert' }\n```\n\n_(Examples with `await` need to be run inside an `async` function)_\n\n### Multiple prompts\n\nPass an array of [\"question\" objects](#prompt-options) to run a series of prompts.\n\n```js\nconst response = await prompt([\n  {\n    type: 'input',\n    name: 'name',\n    message: 'What is your name?'\n  },\n  {\n    type: 'input',\n    name: 'username',\n    message: 'What is your username?'\n  }\n]);\n\nconsole.log(response); // { name: 'Edward Chan', username: 'edwardmchan' }\n```\n\n### Different ways to run enquirer\n\n#### 1. By importing the specific `built-in prompt`\n\n```js\nconst { Confirm } = require('enquirer');\n\nconst prompt = new Confirm({\n  name: 'question',\n  message: 'Did you like enquirer?'\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer));\n```\n\n#### 2. By passing the options to `prompt`\n\n```js\nconst { prompt } = require('enquirer');\n\nprompt({\n  type: 'confirm',\n  name: 'question',\n  message: 'Did you like enquirer?'\n})\n  .then(answer => console.log('Answer:', answer));\n```\n\n**Jump to**: [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts) \u00b7 [Options](#-options) \u00b7 [Key Bindings](#-key-bindings)\n\n<br>\n\n## \u276f Enquirer\n**Enquirer is a prompt runner**\n\nAdd Enquirer to your JavaScript project with following line of code.\n\n```js\nconst Enquirer = require('enquirer');\n```\n\nThe main export of this library is the `Enquirer` class, which has methods and features designed to simplify running prompts.\n\n```js\nconst { prompt } = require('enquirer');\nconst question = [\n  {\n    type: 'input',\n    name: 'username',\n    message: 'What is your username?'\n  },\n  {\n    type: 'password',\n    name: 'password',\n    message: 'What is your password?'\n  }\n];\n\nlet answers = await prompt(question);\nconsole.log(answers);\n```\n\n**Prompts control how values are rendered and returned**\n\nEach individual prompt is a class with special features and functionality for rendering the types of values you want to show users in the terminal, and subsequently returning the types of values you need to use in your application.\n\n**How can I customize prompts?**\n\nBelow in this guide you will find information about creating [custom prompts](#-custom-prompts). For now, we'll focus on how to customize an existing prompt.\n\nAll of the individual [prompt classes](#built-in-prompts) in this library are exposed as static properties on Enquirer. This allows them to be used directly without using `enquirer.prompt()`.\n\nUse this approach if you need to modify a prompt instance, or listen for events on the prompt.\n\n**Example**\n\n```js\nconst { Input } = require('enquirer');\nconst prompt = new Input({\n  name: 'username',\n  message: 'What is your username?'\n});\n\nprompt.run()\n  .then(answer => console.log('Username:', answer))\n  .catch(console.error);\n```\n\n### Enquirer API\n\n### [Enquirer](index.js#L20)\nCreate an instance of `Enquirer`.\n\n**Params**\n\n* `options` **{Object}**: (optional) Options to use with all prompts.    \n* `answers` **{Object}**: (optional) Answers object to initialize with.    \n\n**Example**\n\n```js\nconst Enquirer = require('enquirer');\nconst enquirer = new Enquirer();\n```\n\n### [register()](index.js#L42)\nRegister a custom prompt type.\n\n**Params**\n\n* `type` **{String}**    \n* `fn` **{Function|Prompt}**: `Prompt` class, or a function that returns a `Prompt` class.    \n* `returns` **{Object}**: Returns the Enquirer instance  \n\n**Example**\n\n```js\nconst Enquirer = require('enquirer');\nconst enquirer = new Enquirer();\nenquirer.register('customType', require('./custom-prompt'));\n```\n\n### [prompt()](index.js#L78)\nPrompt function that takes a \"question\" object or array of question objects, and returns an object with responses from the user.\n\n**Params**\n\n* `questions` **{Array|Object}**: Options objects for one or more prompts to run.    \n* `returns` **{Promise}**: Promise that returns an \"answers\" object with the user's responses.  \n\n**Example**\n\n```js\nconst Enquirer = require('enquirer');\nconst enquirer = new Enquirer();\n\nconst response = await enquirer.prompt({\n  type: 'input',\n  name: 'username',\n  message: 'What is your username?'\n});\nconsole.log(response);\n```\n\n### [use()](index.js#L160)\nUse an enquirer plugin.\n\n**Params**\n\n* `plugin` **{Function}**: Plugin function that takes an instance of Enquirer.    \n* `returns` **{Object}**: Returns the Enquirer instance.  \n\n**Example**\n\n```js\nconst Enquirer = require('enquirer');\nconst enquirer = new Enquirer();\nconst plugin = enquirer => {\n  // do stuff to enquire instance\n};\nenquirer.use(plugin);\n```\n\n### [Enquirer#prompt](index.js#L210)\nPrompt function that takes a \"question\" object or array of question objects, and returns an object with responses from the user.\n\n**Params**\n\n* `questions` **{Array|Object}**: Options objects for one or more prompts to run.    \n* `returns` **{Promise}**: Promise that returns an \"answers\" object with the user's responses.  \n\n**Example**\n\n```js\nconst { prompt } = require('enquirer');\nconst response = await prompt({\n  type: 'input',\n  name: 'username',\n  message: 'What is your username?'\n});\nconsole.log(response);\n```\n\n<br>\n\n## \u276f Prompts\nThis section is about Enquirer's prompts: what they look like, how they work, how to run them, available options, and how to customize the prompts or create your own prompt concept.\n\n**Getting started with Enquirer's prompts**\n\n- [Prompt](#prompt) - The base `Prompt` class used by other prompts\n  - [Prompt Options](#prompt-options)\n- [Built-in prompts](#-built-in-prompts)\n- [Prompt Types](#prompt-types) - The base `Prompt` class used by other prompts \n- [Custom Prompts](#-custom-prompts) - Enquirer 2.0 introduced the concept of prompt \"types\", with the goal of making custom prompts easier than ever to create and use.\n\n### Prompt\n\nThe base `Prompt` class is used to create all other prompts.\n\n```js\nconst { Prompt } = require('enquirer');\nclass MyCustomPrompt extends Prompt {}\n```\n\nSee the documentation for [creating custom prompts](#-custom-prompts) to learn more about how this works.\n\n#### Prompt Options\n\nEach prompt takes an options object (aka \"question\" object), that implements the following interface:\n\n```js\n{\n  // required\n  type: string | function,\n  name: string | function,\n  message: string | function | async function,\n\n  // optional\n  skip: boolean | function | async function,\n  initial: string | function | async function,\n  format: function | async function,\n  result: function | async function,\n  validate: function | async function,\n}\n```\nEach property of the options object is described below:\n\n| **Property** | **Required?** | **Type**           | **Description**                                                                                                                                                                         |\n| ------------ | ------------- | ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `type`       | yes           | `string\\|function`  | Enquirer uses this value to determine the type of prompt to run, but it's optional when prompts are run directly.                                                                       |\n| `name`       | yes           | `string\\|function`  | Used as the key for the answer on the returned values (answers) object.                                                                                                                 |\n| `message`    | yes           | `string\\|function`  | The message to display when the prompt is rendered in the terminal.                                                                                                                     |\n| `skip`       | no            | `boolean\\|function` | If `true` it will not ask that prompt.                                                                                                                                                  |\n| `initial`    | no            | `string\\|function`  | The default value to return if the user does not supply a value.                                                                                                                        |\n| `format`     | no            | `function`         | Function to format user input in the terminal.                                                                                                                                          |\n| `result`     | no            | `function`         | Function to format the final submitted value before it's returned.                                                                                                                      |\n| `validate`   | no            | `function`         | Function to validate the submitted value before it's returned. This function may return a boolean or a string. If a string is returned it will be used as the validation error message. |\n\n**Example usage**\n\n```js\nconst { prompt } = require('enquirer');\n\nconst question = {\n  type: 'input',\n  name: 'username',\n  message: 'What is your username?'\n};\n\nprompt(question)\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n```\n\n<br>\n\n## \u276f Built-in prompts\n\n- [AutoComplete Prompt](#autocomplete-prompt)\n- [BasicAuth Prompt](#basicauth-prompt)\n- [Confirm Prompt](#confirm-prompt)\n- [Form Prompt](#form-prompt)\n- [Input Prompt](#input-prompt)\n- [Invisible Prompt](#invisible-prompt)\n- [List Prompt](#list-prompt)\n- [MultiSelect Prompt](#multiselect-prompt)\n- [Numeral Prompt](#numeral-prompt)\n- [Password Prompt](#password-prompt)\n- [Quiz Prompt](#quiz-prompt)\n- [Survey Prompt](#survey-prompt)\n- [Scale Prompt](#scale-prompt)\n- [Select Prompt](#select-prompt)\n- [Sort Prompt](#sort-prompt)\n- [Snippet Prompt](#snippet-prompt)\n- [Toggle Prompt](#toggle-prompt)\n\n### AutoComplete Prompt\n\nPrompt that auto-completes as the user types, and returns the selected value as a string.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/autocomplete-prompt.gif\" alt=\"Enquirer AutoComplete Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { AutoComplete } = require('enquirer');\n\nconst prompt = new AutoComplete({\n  name: 'flavor',\n  message: 'Pick your favorite flavor',\n  limit: 10,\n  initial: 2,\n  choices: [\n    'Almond',\n    'Apple',\n    'Banana',\n    'Blackberry',\n    'Blueberry',\n    'Cherry',\n    'Chocolate',\n    'Cinnamon',\n    'Coconut',\n    'Cranberry',\n    'Grape',\n    'Nougat',\n    'Orange',\n    'Pear',\n    'Pineapple',\n    'Raspberry',\n    'Strawberry',\n    'Vanilla',\n    'Watermelon',\n    'Wintergreen'\n  ]\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n```\n\n**AutoComplete Options**\n\n| Option      | Type       | Default                                                             | Description                                                                                                  |\n| ----------- | ---------- | ------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ |\n| `highlight` | `function` | `dim` version of primary style                                      | The color to use when \"highlighting\" characters in the list that match user input.                           |\n| `multiple`  | `boolean`  | `false`                                                             | Allow multiple choices to be selected.                                                                       |\n| `suggest`   | `function` | Greedy match, returns true if choice message contains input string. | Function that filters choices. Takes user input and a choices array, and returns a list of matching choices. |\n| `initial`   | `number` | 0 | Preselected item in the list of choices. |\n| `footer`   | `function` | None | Function that displays [footer text](https://github.com/enquirer/enquirer/blob/6c2819518a1e2ed284242a99a685655fbaabfa28/examples/autocomplete/option-footer.js#L10) |\n\n**Related prompts**\n\n- [Select](#select-prompt)\n- [MultiSelect](#multiselect-prompt)\n- [Survey](#survey-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### BasicAuth Prompt\n\nPrompt that asks for username and password to authenticate the user. The default implementation of `authenticate` function in `BasicAuth` prompt is to compare the username and password with the values supplied while running the prompt. The implementer is expected to override the `authenticate` function with a custom logic such as making an API request to a server to authenticate the username and password entered and expect a token back.\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/13731210/61570485-7ffd9c00-aaaa-11e9-857a-d47dc7008284.gif\" alt=\"Enquirer BasicAuth Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { BasicAuth } = require('enquirer');\n\n const prompt = new BasicAuth({\n  name: 'password',\n  message: 'Please enter your password',\n  username: 'rajat-sr',\n  password: '123',\n  showPassword: true\n});\n\n prompt\n  .run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n```\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Confirm Prompt\n\nPrompt that returns `true` or `false`.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/confirm-prompt.gif\" alt=\"Enquirer Confirm Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { Confirm } = require('enquirer');\n\nconst prompt = new Confirm({\n  name: 'question',\n  message: 'Want to answer?'\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [Input](#input-prompt)\n- [Numeral](#numeral-prompt)\n- [Password](#password-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Form Prompt\n\nPrompt that allows the user to enter and submit multiple values on a single terminal screen.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/form-prompt.gif\" alt=\"Enquirer Form Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { Form } = require('enquirer');\n\nconst prompt = new Form({\n  name: 'user',\n  message: 'Please provide the following information:',\n  choices: [\n    { name: 'firstname', message: 'First Name', initial: 'Jon' },\n    { name: 'lastname', message: 'Last Name', initial: 'Schlinkert' },\n    { name: 'username', message: 'GitHub username', initial: 'jonschlinkert' }\n  ]\n});\n\nprompt.run()\n  .then(value => console.log('Answer:', value))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [Input](#input-prompt)\n- [Survey](#survey-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Input Prompt\n\nPrompt that takes user input and returns a string.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/input-prompt.gif\" alt=\"Enquirer Input Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { Input } = require('enquirer');\nconst prompt = new Input({\n  message: 'What is your username?',\n  initial: 'jonschlinkert'\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.log);\n```\n\nYou can use [data-store](https://github.com/jonschlinkert/data-store) to store [input history](https://github.com/enquirer/enquirer/blob/master/examples/input/option-history.js) that the user can cycle through (see [source](https://github.com/enquirer/enquirer/blob/8407dc3579123df5e6e20215078e33bb605b0c37/lib/prompts/input.js)).\n\n**Related prompts**\n\n- [Confirm](#confirm-prompt)\n- [Numeral](#numeral-prompt)\n- [Password](#password-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Invisible Prompt\n\nPrompt that takes user input, hides it from the terminal, and returns a string.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/invisible-prompt.gif\" alt=\"Enquirer Invisible Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { Invisible } = require('enquirer');\nconst prompt = new Invisible({\n  name: 'secret',\n  message: 'What is your secret?'\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', { secret: answer }))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [Password](#password-prompt)\n- [Input](#input-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### List Prompt\n\nPrompt that returns a list of values, created by splitting the user input. The default split character is `,` with optional trailing whitespace.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/list-prompt.gif\" alt=\"Enquirer List Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { List } = require('enquirer');\nconst prompt = new List({\n  name: 'keywords',\n  message: 'Type comma-separated keywords'\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [Sort](#sort-prompt)\n- [Select](#select-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### MultiSelect Prompt\n\nPrompt that allows the user to select multiple items from a list of options.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/multiselect-prompt.gif\" alt=\"Enquirer MultiSelect Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { MultiSelect } = require('enquirer');\n\nconst prompt = new MultiSelect({\n  name: 'value',\n  message: 'Pick your favorite colors',\n  limit: 7,\n  choices: [\n    { name: 'aqua', value: '#00ffff' },\n    { name: 'black', value: '#000000' },\n    { name: 'blue', value: '#0000ff' },\n    { name: 'fuchsia', value: '#ff00ff' },\n    { name: 'gray', value: '#808080' },\n    { name: 'green', value: '#008000' },\n    { name: 'lime', value: '#00ff00' },\n    { name: 'maroon', value: '#800000' },\n    { name: 'navy', value: '#000080' },\n    { name: 'olive', value: '#808000' },\n    { name: 'purple', value: '#800080' },\n    { name: 'red', value: '#ff0000' },\n    { name: 'silver', value: '#c0c0c0' },\n    { name: 'teal', value: '#008080' },\n    { name: 'white', value: '#ffffff' },\n    { name: 'yellow', value: '#ffff00' }\n  ]\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n\n// Answer: ['aqua', 'blue', 'fuchsia']\n```\n\n**Example key-value pairs**\n\nOptionally, pass a `result` function and use the `.map` method to return an object of key-value pairs of the selected names and values: [example](./examples/multiselect/option-result.js)\n\n```js\nconst { MultiSelect } = require('enquirer');\n\nconst prompt = new MultiSelect({\n  name: 'value',\n  message: 'Pick your favorite colors',\n  limit: 7,\n  choices: [\n    { name: 'aqua', value: '#00ffff' },\n    { name: 'black', value: '#000000' },\n    { name: 'blue', value: '#0000ff' },\n    { name: 'fuchsia', value: '#ff00ff' },\n    { name: 'gray', value: '#808080' },\n    { name: 'green', value: '#008000' },\n    { name: 'lime', value: '#00ff00' },\n    { name: 'maroon', value: '#800000' },\n    { name: 'navy', value: '#000080' },\n    { name: 'olive', value: '#808000' },\n    { name: 'purple', value: '#800080' },\n    { name: 'red', value: '#ff0000' },\n    { name: 'silver', value: '#c0c0c0' },\n    { name: 'teal', value: '#008080' },\n    { name: 'white', value: '#ffffff' },\n    { name: 'yellow', value: '#ffff00' }\n  ],\n  result(names) {\n   return this.map(names);\n  }\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n\n// Answer: { aqua: '#00ffff', blue: '#0000ff', fuchsia: '#ff00ff' }\n```\n\n**Related prompts**\n\n- [AutoComplete](#autocomplete-prompt)\n- [Select](#select-prompt)\n- [Survey](#survey-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Numeral Prompt\n\nPrompt that takes a number as input.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/numeral-prompt.gif\" alt=\"Enquirer Numeral Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { NumberPrompt } = require('enquirer');\n\nconst prompt = new NumberPrompt({\n  name: 'number',\n  message: 'Please enter a number'\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [Input](#input-prompt)\n- [Confirm](#confirm-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Password Prompt\n\nPrompt that takes user input and masks it in the terminal. Also see the [invisible prompt](#invisible-prompt)\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/password-prompt.gif\" alt=\"Enquirer Password Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { Password } = require('enquirer');\n\nconst prompt = new Password({\n  name: 'password',\n  message: 'What is your password?'\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [Input](#input-prompt)\n- [Invisible](#invisible-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Quiz Prompt\n\nPrompt that allows the user to play multiple-choice quiz questions.\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/13731210/61567561-891d4780-aa6f-11e9-9b09-3d504abd24ed.gif\" alt=\"Enquirer Quiz Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { Quiz } = require('enquirer');\n\n const prompt = new Quiz({\n  name: 'countries',\n  message: 'How many countries are there in the world?',\n  choices: ['165', '175', '185', '195', '205'],\n  correctChoice: 3\n});\n\n prompt\n  .run()\n  .then(answer => {\n    if (answer.correct) {\n      console.log('Correct!');\n    } else {\n      console.log(`Wrong! Correct answer is ${answer.correctAnswer}`);\n    }\n  })\n  .catch(console.error);\n```\n\n**Quiz Options**\n\n| Option         | Type        | Required    | Description                                                                                                  |\n| -----------    | ----------  | ----------  | ------------------------------------------------------------------------------------------------------------ |\n| `choices`      | `array`     | Yes         | The list of possible answers to the quiz question.                                                           |\n| `correctChoice`| `number`    | Yes         | Index of the correct choice from the `choices` array.                                                        |\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Survey Prompt\n\nPrompt that allows the user to provide feedback for a list of questions.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/survey-prompt.gif\" alt=\"Enquirer Survey Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { Survey } = require('enquirer');\n\nconst prompt = new Survey({\n  name: 'experience',\n  message: 'Please rate your experience',\n   scale: [\n    { name: '1', message: 'Strongly Disagree' },\n    { name: '2', message: 'Disagree' },\n    { name: '3', message: 'Neutral' },\n    { name: '4', message: 'Agree' },\n    { name: '5', message: 'Strongly Agree' }\n  ],\n  margin: [0, 0, 2, 1],\n  choices: [\n    {\n      name: 'interface',\n      message: 'The website has a friendly interface.'\n    },\n    {\n      name: 'navigation',\n      message: 'The website is easy to navigate.'\n    },\n    {\n      name: 'images',\n      message: 'The website usually has good images.'\n    },\n    {\n      name: 'upload',\n      message: 'The website makes it easy to upload images.'\n    },\n    {\n      name: 'colors',\n      message: 'The website has a pleasing color palette.'\n    }\n  ]\n});\n\nprompt.run()\n  .then(value => console.log('ANSWERS:', value))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [Scale](#scale-prompt)\n- [Snippet](#snippet-prompt)\n- [Select](#select-prompt)\n\n***\n\n### Scale Prompt\n\nA more compact version of the [Survey prompt](#survey-prompt), the Scale prompt allows the user to quickly provide feedback using a [Likert Scale](https://en.wikipedia.org/wiki/Likert_scale).\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/scale-prompt.gif\" alt=\"Enquirer Scale Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { Scale } = require('enquirer');\nconst prompt = new Scale({\n  name: 'experience',\n  message: 'Please rate your experience',\n  scale: [\n    { name: '1', message: 'Strongly Disagree' },\n    { name: '2', message: 'Disagree' },\n    { name: '3', message: 'Neutral' },\n    { name: '4', message: 'Agree' },\n    { name: '5', message: 'Strongly Agree' }\n  ],\n  margin: [0, 0, 2, 1],\n  choices: [\n    {\n      name: 'interface',\n      message: 'The website has a friendly interface.',\n      initial: 2\n    },\n    {\n      name: 'navigation',\n      message: 'The website is easy to navigate.',\n      initial: 2\n    },\n    {\n      name: 'images',\n      message: 'The website usually has good images.',\n      initial: 2\n    },\n    {\n      name: 'upload',\n      message: 'The website makes it easy to upload images.',\n      initial: 2\n    },\n    {\n      name: 'colors',\n      message: 'The website has a pleasing color palette.',\n      initial: 2\n    }\n  ]\n});\n\nprompt.run()\n  .then(value => console.log('ANSWERS:', value))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [AutoComplete](#autocomplete-prompt)\n- [Select](#select-prompt)\n- [Survey](#survey-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Select Prompt\n\nPrompt that allows the user to select from a list of options.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/select-prompt.gif\" alt=\"Enquirer Select Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { Select } = require('enquirer');\n\nconst prompt = new Select({\n  name: 'color',\n  message: 'Pick a flavor',\n  choices: ['apple', 'grape', 'watermelon', 'cherry', 'orange']\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [AutoComplete](#autocomplete-prompt)\n- [MultiSelect](#multiselect-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Sort Prompt\n\nPrompt that allows the user to sort items in a list.\n\n**Example**\n\nIn this [example](https://github.com/enquirer/enquirer/raw/master/examples/sort/prompt.js), custom styling is applied to the returned values to make it easier to see what's happening.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/sort-prompt.gif\" alt=\"Enquirer Sort Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst colors = require('ansi-colors');\nconst { Sort } = require('enquirer');\nconst prompt = new Sort({\n  name: 'colors',\n  message: 'Sort the colors in order of preference',\n  hint: 'Top is best, bottom is worst',\n  numbered: true,\n  choices: ['red', 'white', 'green', 'cyan', 'yellow'].map(n => ({\n    name: n,\n    message: colors[n](n)\n  }))\n});\n\nprompt.run()\n  .then(function(answer = []) {\n    console.log(answer);\n    console.log('Your preferred order of colors is:');\n    console.log(answer.map(key => colors[key](key)).join('\\n'));\n  })\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [List](#list-prompt)\n- [Select](#select-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Snippet Prompt\n\nPrompt that allows the user to replace placeholders in a snippet of code or text.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/snippet-prompt.gif\" alt=\"Prompts\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst semver = require('semver');\nconst { Snippet } = require('enquirer');\nconst prompt = new Snippet({\n  name: 'username',\n  message: 'Fill out the fields in package.json',\n  required: true,\n  fields: [\n    {\n      name: 'author_name',\n      message: 'Author Name'\n    },\n    {\n      name: 'version',\n      validate(value, state, item, index) {\n        if (item && item.name === 'version' && !semver.valid(value)) {\n          return prompt.styles.danger('version should be a valid semver value');\n        }\n        return true;\n      }\n    }\n  ],\n  template: `{\n  \"name\": \"\\${name}\",\n  \"description\": \"\\${description}\",\n  \"version\": \"\\${version}\",\n  \"homepage\": \"https://github.com/\\${username}/\\${name}\",\n  \"author\": \"\\${author_name} (https://github.com/\\${username})\",\n  \"repository\": \"\\${username}/\\${name}\",\n  \"license\": \"\\${license:ISC}\"\n}\n`\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer.result))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [Survey](#survey-prompt)\n- [AutoComplete](#autocomplete-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Toggle Prompt\n\nPrompt that allows the user to toggle between two values then returns `true` or `false`.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/enquirer/enquirer/master/media/toggle-prompt.gif\" alt=\"Enquirer Toggle Prompt\" width=\"750\">\n</p>\n\n**Example Usage**\n\n```js\nconst { Toggle } = require('enquirer');\n\nconst prompt = new Toggle({\n  message: 'Want to answer?',\n  enabled: 'Yep',\n  disabled: 'Nope'\n});\n\nprompt.run()\n  .then(answer => console.log('Answer:', answer))\n  .catch(console.error);\n```\n\n**Related prompts**\n\n- [Confirm](#confirm-prompt)\n- [Input](#input-prompt)\n- [Sort](#sort-prompt)\n\n**\u2191 back to:** [Getting Started](#-getting-started) \u00b7 [Prompts](#-prompts)\n\n***\n\n### Prompt Types\nThere are 5 (soon to be 6!) type classes:\n* [ArrayPrompt](#arrayprompt)\n    - [Options](#options)\n    - [Properties](#properties)\n    - [Methods](#methods)\n    - [Choices](#choices)\n    - [Defining choices](#defining-choices)\n    - [Choice properties](#choice-properties)\n    - [Related prompts](#related-prompts)\n* [AuthPrompt](#authprompt)\n* [BooleanPrompt](#booleanprompt)\n* DatePrompt (Coming Soon!)\n* [NumberPrompt](#numberprompt)\n* [StringPrompt](#stringprompt)\n\nEach type is a low-level class that may be used as a starting point for creating higher level prompts. Continue reading to learn how.\n\n### ArrayPrompt\n\nThe `ArrayPrompt` class is used for creating prompts that display a list of choices in the terminal. For example, Enquirer uses this class as the basis for the [Select](#select) and [Survey](#survey) prompts.\n\n#### Options\n\nIn addition to the [options](#options) available to all prompts, Array prompts also support the following options.\n\n| **Option**  | **Required?** | **Type**        | **Description**                                                                                                         |\n| ----------- | ------------- | --------------- | ----------------------------------------------------------------------------------------------------------------------- |\n| `autofocus` | `no`          | `string\\|number` | The index or name of the choice that should have focus when the prompt loads. Only one choice may have focus at a time. |  |\n| `stdin`     | `no`          | `stream`        | The input stream to use for emitting keypress events. Defaults to `process.stdin`.                                      |\n| `stdout`    | `no`          | `stream`        | The output stream to use for writing the prompt to the terminal. Defaults to `process.stdout`.                          |\n|             |\n\n#### Properties\n\nArray prompts have the following instance properties and getters.\n\n| **Property name** | **Type**                                                                          | **Description**                                                                                                                                                                                                                                                                                                                                    |\n| ----------------- | --------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `choices`         | `array`                                                                           | Array of choices that have been normalized from choices passed on the prompt options.                                                                                                                                                                                                                                                              |\n| `cursor`          | `number`                                                                          | Position of the cursor relative to the _user input (string)_.                                                                                                                                                                                                                                                                                      |\n| `enabled`         | `array`                                                                           | Returns an array of enabled choices.                                                                                                                                                                                                                                                                                                               |\n| `focused`         | `array`                                                                           | Returns the currently selected choice in the visible list of choices. This is similar to the concept of focus in HTML and CSS. Focused choices are always visible (on-screen). When a list of choices is longer than the list of visible choices, and an off-screen choice is _focused_, the list will scroll to the focused choice and re-render. |\n| `focused`         | Gets the currently selected choice. Equivalent to `prompt.choices[prompt.index]`. |\n| `index`           | `number`                                                                          | Position of the pointer in the _visible list (array) of choices_.                                                                                                                                                                                                                                                                                  |\n| `limit`           | `number`                                                                          | The number of choices to display on-screen.                                                                                                                                                                                                                                                                                                        |\n| `selected`        | `array`                                                                           | Either a list of enabled choices (when `options.multiple` is true) or the currently focused choice.                                                                                                                                                                                                                                                |\n| `visible`         | `string`                                                                          |                                                                                                                                                                                                                                                                                                                                                    |\n\n#### Methods\n\n| **Method**    | **Description**                                                                                                                                                                                |\n| ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `pointer()`   | Returns the visual symbol to use to identify the choice that currently has focus. The `\u276f` symbol is often used for this. The pointer is not always visible, as with the `autocomplete` prompt. |\n| `indicator()` | Returns the visual symbol that indicates whether or not a choice is checked/enabled.                                                                                                           |\n| `focus()`     | Sets focus on a choice, if it can be focused.                                                                                                                                                  |\n\n#### Choices\n\nArray prompts support the `choices` option, which is the array of choices users will be able to select from when rendered in the terminal. \n\n**Type**: `string|object`\n\n**Example**\n\n```js\nconst { prompt } = require('enquirer');\n\nconst questions = [{\n  type: 'select',\n  name: 'color',\n  message: 'Favorite color?',\n  initial: 1,\n  choices: [\n    { name: 'red',   message: 'Red',   value: '#ff0000' }, //<= choice object\n    { name: 'green', message: 'Green', value: '#00ff00' }, //<= choice object\n    { name: 'blue',  message: 'Blue',  value: '#0000ff' }  //<= choice object\n  ]\n}];\n\nlet answers = await prompt(questions);\nconsole.log('Answer:', answers.color);\n```\n\n#### Defining choices\n\nWhether defined as a string or object, choices are normalized to the following interface:\n\n```js\n{\n  name: string;\n  message: string | undefined;\n  value: string | undefined;\n  hint: string | undefined;\n  disabled: boolean | string | undefined;\n}\n```\n\n**Example**\n\n```js\nconst question = {\n  name: 'fruit',\n  message: 'Favorite fruit?',\n  choices: ['Apple', 'Orange', 'Raspberry']\n};\n```\n\nNormalizes to the following when the prompt is run:\n\n```js\nconst question = {\n  name: 'fruit',\n  message: 'Favorite fruit?',\n  choices: [\n    { name: 'Apple', message: 'Apple', value: 'Apple' },\n    { name: 'Orange', message: 'Orange', value: 'Orange' },\n    { name: 'Raspberry', message: 'Raspberry', value: 'Raspberry' }\n  ]\n};\n```\n\n#### Choice properties\n\nThe following properties are supported on `choice` objects.\n\n| **Option**  | **Type**          | **Description**                                                                                                                                                                                     |\n| ----------- | ----------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `name`      | `string`          | The unique key to identify a choice                                                                                                                                                                 |\n| `message`   | `string`          | The message to display in the terminal. `name` is used when this is undefined.                                                                                                                      |\n| `value`     | `string`          | Value to associate with the choice. Useful for creating key-value pairs from user choices. `name` is used when this is undefined.                                                                   |\n| `choices`   | `array`           | Array of \"child\" choices.                                                                                                                                                                           |\n| `hint`      | `string`          | Help message to display next to a choice.                                                                                                                                                           |\n| `role`      | `string`          | Determines how the choice will be displayed. Currently the only role supported is `separator`. Additional roles may be added in the future (like `heading`, etc). Please create a [feature request] |\n| `enabled`   | `boolean`         | Enabled a choice by default. This is only supported when `options.multiple` is true or on prompts that support multiple choices, like [MultiSelect](#-multiselect).                                 |\n| `disabled`  | `boolean\\|string`  | Disable a choice so that it cannot be selected. This value may either be `true`, `false`, or a message to display.                                                                                  |\n| `indicator` | `string\\|function` | Custom indicator to render for a choice (like a check or radio button).                                                                                                                             |\n\n#### Related prompts\n\n- [AutoComplete](#autocomplete-prompt)\n- [Form](#form-prompt)\n- [MultiSelect](#multiselect-prompt)\n- [Select](#select-prompt)\n- [Survey](#survey-prompt)\n\n***\n\n### AuthPrompt\n\nThe `AuthPrompt` is used to create prompts to log in user using any authentication method. For example, Enquirer uses this class as the basis for the [BasicAuth Prompt](#basicauth-prompt). You can also find prompt examples in `examples/auth/` folder that utilizes `AuthPrompt` to create OAuth based authentication prompt or a prompt that authenticates using time-based OTP, among others.\n\n`AuthPrompt` has a factory function that creates an instance of `AuthPrompt` class and it expects an `authenticate` function, as an argument, which overrides the `authenticate` function of the `AuthPrompt` class.\n\n#### Methods\n\n| **Method**         | **Description**                                                                                                                                                                                          |\n| -------------      | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `authenticate()`   | Contain all the authentication logic. This function should be overridden to implement custom authentication logic. The default `authenticate` function throws an error if no other function is provided. |\n\n#### Choices\n\nAuth prompt supports the `choices` option, which is the similar to the choices used in [Form Prompt](#form-prompt).\n\n**Example**\n\n```js\nconst { AuthPrompt } = require('enquirer');\n\nfunction authenticate(value, state) {\n  if (value.username === this.options.username && value.password === this.options.password) {\n    return true;\n  }\n  return false;\n}\n\nconst CustomAuthPrompt = AuthPrompt.create(authenticate);\n\nconst prompt = new CustomAuthPrompt({\n  name: 'password',\n  message: 'Please enter your password',\n  username: 'rajat-sr',\n  password: '1234567',\n  choices: [\n    { name: 'username', message: 'username' },\n    { name: 'password', message: 'password' }\n  ]\n});\n\nprompt\n  .run()\n  .then(answer => console.log('Authenticated?', answer))\n  .catch(console.error);\n```\n\n#### Related prompts\n\n- [BasicAuth Prompt](#basicauth-prompt)\n\n***\n\n### BooleanPrompt\n\nThe `BooleanPrompt` class is used for creating prompts that display and return a boolean value.\n\n```js\nconst { BooleanPrompt } = require('enquirer');\n\nconst  prompt = new  BooleanPrompt({\n  header:  '========================',\n  message:  'Do you love enquirer?',\n  footer:  '========================',\n});\n\nprompt.run()\n  .then(answer  =>  console.log('Selected:', answer))\n  .catch(console.error);\n```\n\n**Returns**: `boolean`\n\n*** \n\n### NumberPrompt\n\nThe `NumberPrompt` class is used for creating prompts that display and return a numerical value.\n\n```js\nconst { NumberPrompt } = require('enquirer');\n\nconst  prompt = new  NumberPrompt({\n  header:  '************************',\n  message:  'Input the Numbers:',\n  footer:  '************************',\n});\n\nprompt.run()\n  .then(answer  =>  console.log('Numbers are:', answer))\n  .catch(console.error);\n```\n\n**Returns**: `string|number` (number, or number formatted as a string)\n\n*** \n\n### StringPrompt\n\nThe `StringPrompt` class is used for creating prompts that display and return a string value.\n\n```js\nconst { StringPrompt } = require('enquirer');\n\nconst prompt = new StringPrompt({\n  header: '************************',\n  message: 'Input the String:',\n  footer: '************************'\n});\n\nprompt.run()\n  .then(answer => console.log('String is:', answer))\n  .catch(console.error);\n```\n\n**Returns**: `string`\n\n<br>\n\n## \u276f Custom prompts\nWith Enquirer 2.0, custom prompts are easier than ever to create and use.\n\n**How do I create a custom prompt?**\n\nCustom prompts are created by extending either:\n- Enquirer's `Prompt` class\n- one of the built-in [prompts](#-prompts), or \n- low-level [types](#-types).\n\n<!-- Example: HaiKarate Custom Prompt -->\n\n```js\nconst { Prompt } = require('enquirer');\n\nclass HaiKarate extends Prompt {\n  constructor(options = {}) {\n    super(options);\n    this.value = options.initial || 0;\n    this.cursorHide();\n  }\n  up() {\n    this.value++;\n    this.render();\n  }\n  down() {\n    this.value--;\n    this.render();\n  }\n  render() {\n    this.clear(); // clear previously rendered prompt from the terminal\n    this.write(`${this.state.message}: ${this.value}`);\n  }\n}\n\n// Use the prompt by creating an instance of your custom prompt class.\nconst prompt = new HaiKarate({\n  message: 'How many sprays do you want?',\n  initial: 10\n});\n\nprompt.run()\n  .then(answer => console.log('Sprays:', answer))\n  .catch(console.error);\n```\n\nIf you want to be able to specify your prompt by `type` so that it may be used alongside other prompts, you will need to first create an instance of `Enquirer`.\n\n```js\nconst Enquirer = require('enquirer');\nconst enquirer = new Enquirer();\n```\n\nThen use the `.register()` method to add your custom prompt.\n\n```js\nenquirer.register('haikarate', HaiKarate);\n```\n\nNow you can do the following when defining \"questions\".\n\n```js\nlet spritzer = require('cologne-drone');\nlet answers = await enquirer.prompt([\n  {\n    type: 'haikarate',\n    name: 'cologne',\n    message: 'How many sprays do you need?',\n    initial: 10,\n    async onSubmit(name, value) {\n      await spritzer.activate(value); //<= activate drone\n      return value;\n    }\n  }\n]);\n```\n\n<br>\n\n## \u276f Key Bindings\n### All prompts\n\nThese key combinations may be used with all prompts.\n\n| **command**                      | **description**                        |\n| -------------------------------- | -------------------------------------- |\n| <kbd>ctrl</kbd>  +  <kbd>c</kbd> | Cancel the prompt.                     |\n| <kbd>ctrl</kbd> + <kbd>g</kbd>   | Reset the prompt to its initial state. |\n\n<br>\n\n### Move cursor\n\nThese combinations may be used on prompts that support user input (eg. [input prompt](#input-prompt), [password prompt](#password-prompt), and [invisible prompt](#invisible-prompt)).\n\n| **command**                    | **description**                          |\n| ------------------------------ | ---------------------------------------- |\n| <kbd>left</kbd>                | Move the cursor back one character.      |\n| <kbd>right</kbd>               | Move the cursor forward one character.   |\n| <kbd>ctrl</kbd> + <kbd>a</kbd> | Move cursor to the start of the line     |\n| <kbd>ctrl</kbd> + <kbd>e</kbd> | Move cursor to the end of the line       |\n| <kbd>ctrl</kbd> + <kbd>b</kbd> | Move cursor back one character           |\n| <kbd>ctrl</kbd> + <kbd>f</kbd> | Move cursor forward one character        |\n| <kbd>ctrl</kbd> + <kbd>x</kbd> | Toggle between first and cursor position |\n\n<br>\n\n### Edit Input\n\nThese key combinations may be used on prompts that support user input (eg. [input prompt](#input-prompt), [password prompt](#password-prompt), and [invisible prompt](#invisible-prompt)).\n\n| **command**                    | **description**                          |\n| ------------------------------ | ---------------------------------------- |\n| <kbd>ctrl</kbd> + <kbd>a</kbd> | Move cursor to the start of the line     |\n| <kbd>ctrl</kbd> + <kbd>e</kbd> | Move cursor to the end of the line       |\n| <kbd>ctrl</kbd> + <kbd>b</kbd> | Move cursor back one character           |\n| <kbd>ctrl</kbd> + <kbd>f</kbd> | Move cursor forward one character        |\n| <kbd>ctrl</kbd> + <kbd>x</kbd> | Toggle between first and cursor position |\n\n<br>\n\n| **command (Mac)**                   | **command (Windows)**            | **description**                                                                                                                           |\n| ----------------------------------- | -------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |\n| <kbd>delete</kbd>                   | <kbd>backspace</kbd>             | Delete one character to the left.                                                                                                         |\n| <kbd>fn</kbd> + <kbd>delete</kbd>   | <kbd>delete</kbd>                | Delete one character to the right.                                                                                                        |\n| <kbd>option</kbd> + <kbd>up</kbd>   | <kbd>alt</kbd> + <kbd>up</kbd>   | Scroll to the previous item in history ([Input prompt](#input-prompt) only, when [history is enabled](examples/input/option-history.js)). |\n| <kbd>option</kbd> + <kbd>down</kbd> | <kbd>alt</kbd> + <kbd>down</kbd> | Scroll to the next item in history ([Input prompt](#input-prompt) only, when [history is enabled](examples/input/option-history.js)).     |\n\n### Select choices\n\nThese key combinations may be used on prompts that support _multiple_ choices, such as the [multiselect prompt](#multiselect-prompt), or the [select prompt](#select-prompt) when the `multiple` options is true.\n\n| **command**       | **description**                                                                                                      |\n| ----------------- | -------------------------------------------------------------------------------------------------------------------- |\n| <kbd>space</kbd>  | Toggle the currently selected choice when `options.multiple` is true.                                                |\n| <kbd>number</kbd> | Move the pointer to the choice at the given index. Also toggles the selected choice when `options.multiple` is true. |\n| <kbd>a</kbd>      | Toggle all choices to be enabled or disabled.                                                                        |\n| <kbd>i</kbd>      | Invert the current selection of choices.                                                                             |\n| <kbd>g</kbd>      | Toggle the current choice group.                                                                                     |\n\n<br>\n\n### Hide/show choices\n\n| **command**                     | **description**                                |\n| ------------------------------- | ---------------------------------------------- |\n| <kbd>fn</kbd> + <kbd>up</kbd>   | Decrease the number of visible choices by one. |\n| <kbd>fn</kbd> + <kbd>down</kbd> | Increase the number of visible choices by one. |\n\n<br>\n\n### Move/lock Pointer\n\n| **command**                        | **description**                                                                                                      |\n| ---------------------------------- | -------------------------------------------------------------------------------------------------------------------- |\n| <kbd>number</kbd>                  | Move the pointer to the choice at the given index. Also toggles the selected choice when `options.multiple` is true. |\n| <kbd>up</kbd>                      | Move the pointer up.                                                                                                 |\n| <kbd>down</kbd>                    | Move the pointer down.                                                                                               |\n| <kbd>ctrl</kbd> + <kbd>a</kbd>     | Move the pointer to the first _visible_ choice.                                                                      |\n| <kbd>ctrl</kbd> + <kbd>e</kbd>     | Move the pointer to the last _visible_ choice.                                                                       |\n| <kbd>shift</kbd> + <kbd>up</kbd>   | Scroll up one choice without changing pointer position (locks the pointer while scrolling).                          |\n| <kbd>shift</kbd> + <kbd>down</kbd> | Scroll down one choice without changing pointer position (locks the pointer while scrolling).                        |\n\n<br>\n\n| **command (Mac)**                | **command (Windows)** | **description**                                            |\n| -------------------------------- | --------------------- | ---------------------------------------------------------- |\n| <kbd>fn</kbd> + <kbd>left</kbd>  | <kbd>home</kbd>       | Move the pointer to the first choice in the choices array. |\n| <kbd>fn</kbd> + <kbd>right</kbd> | <kbd>end</kbd>        | Move the pointer to the last choice in the choices array.  |\n\n<br>\n\n## \u276f Release History\n\nPlease see [CHANGELOG.md](CHANGELOG.md).\n\n## \u276f Performance\n\n### System specs\n\nMacBook Pro, Intel Core i7, 2.5 GHz, 16 GB.\n\n### Load time\n\nTime it takes for the module to load the first time (average of 3 runs):\n\n```\nenquirer: 4.013ms\ninquirer: 286.717ms\n```\n\n<br>\n\n## \u276f About\n\n<details>\n<summary><strong>Contributing</strong></summary>\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](../../issues/new).\n\n### Todo\n\nWe're currently working on documentation for the following items. Please star and watch the repository for updates!\n* [ ] Customizing symbols\n* [ ] Customizing styles (palette)\n* [ ] Customizing rendered input\n* [ ] Customizing returned values\n* [ ] Customizing key bindings\n* [ ] Question validation\n* [ ] Choice validation\n* [ ] Skipping questions\n* [ ] Async choices\n* [ ] Async timers: loaders, spinners and other animations\n* [ ] Links to examples\n</details>\n\n<details>\n<summary><strong>Running Tests</strong></summary>\n\nRunning and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command:\n\n```sh\n$ npm install && npm test\n```\n```sh\n$ yarn && yarn test\n```\n\n</details>\n\n<details>\n<summary><strong>Building docs</strong></summary>\n\n_(This project's readme.md is generated by [verb](https://github.com/verbose/verb-generate-readme), please don't edit the readme directly. Any changes to the readme must be made in the [.verb.md](.verb.md) readme template.)_\n\nTo generate the readme, run the following command:\n\n```sh\n$ npm install -g verbose/verb#dev verb-generate-readme && verb\n```\n\n</details>\n\n#### Contributors\n| **Commits** | **Contributor** |  \n| --- | --- |  \n| 287 | [jonschlinkert](https://github.com/jonschlinkert) |  \n| 86  | [doowb](https://github.com/doowb) |  \n| 32  | [rajat-sr](https://github.com/rajat-sr) |  \n| 20  | [318097](https://github.com/318097) |  \n| 15  | [g-plane](https://github.com/g-plane) |  \n| 12  | [pixelass](https://github.com/pixelass) |  \n| 5   | [adityavyas611](https://github.com/adityavyas611) |  \n| 5   | [satotake](https://github.com/satotake) |  \n| 3   | [tunnckoCore](https://github.com/tunnckoCore) |  \n| 3   | [Ovyerus](https://github.com/Ovyerus) |  \n| 3   | [sw-yx](https://github.com/sw-yx) |  \n| 2   | [DanielRuf](https://github.com/DanielRuf) |  \n| 2   | [GabeL7r](https://github.com/GabeL7r) |  \n| 1   | [ahmadawais](https://github.com/ahmadawais) |  \n| 1   | [AlCalzone](https://github.com/AlCalzone) |  \n| 1   | [hipstersmoothie](https://github.com/hipstersmoothie) |  \n| 1   | [TrySound](https://github.com/TrySound) |  \n| 1   | [brentjanderson](https://github.com/brentjanderson) |  \n| 1   | [danieldelcore](https://github.com/danieldelcore) |  \n| 1   | [ImgBotApp](https://github.com/ImgBotApp) |  \n| 1   | [jsonkao](https://github.com/jsonkao) |  \n| 1   | [knpwrs](https://github.com/knpwrs) |  \n| 1   | [yeskunall](https://github.com/yeskunall) |  \n| 1   | [mischah](https://github.com/mischah) |  \n| 1   | [renarsvilnis](https://github.com/renarsvilnis) |  \n| 1   | [sbugert](https://github.com/sbugert) |  \n| 1   | [stephencweiss](https://github.com/stephencweiss) |  \n| 1   | [skellock](https://github.com/skellock) |  \n| 1   | [whxaxes](https://github.com/whxaxes) |  \n\n#### Author\n\n**Jon Schlinkert**\n\n* [GitHub Profile](https://github.com/jonschlinkert)\n* [Twitter Profile](https://twitter.com/jonschlinkert)\n* [LinkedIn Profile](https://linkedin.com/in/jonschlinkert)\n\n#### Credit\n\nThanks to [derhuerst](https://github.com/derhuerst), creator of prompt libraries such as [prompt-skeleton](https://github.com/derhuerst/prompt-skeleton), which influenced some of the concepts we used in our prompts.\n\n#### License\n\nCopyright \u00a9 2018-present, [Jon Schlinkert](https://github.com/jonschlinkert).\nReleased under the [MIT License](LICENSE).\n\n[issue]: https://github.com/enquirer/enquirer/issues/new\n[pulls]: https://github.com/enquirer/enquirer/pulls\n[jon]: https://github.com/jonschlinkert\n[brian]: https://github.com/doowb\n\n", "release_dates": []}, {"name": "explore-dash-sync", "description": null, "language": "Kotlin", "license": null, "readme": "# Explore Dash Sync\n\n## Build\n\n### Recommended environments\n\nUbuntu 20.04.3 LTS or higher\n  * Windows Subsystem for Linux\nIntelliJ IDEA Community 2020.3 or higher\n\n### Init\n\n```\ngit clone https://github.com/dashpay/explore-dash-sync.git\ncd explore-dash-sync\n```\n\n### Standalone app\n\n#### Build\n\nGenerate executable [fat JAR](https://github.com/johnrengelman/shadow) `./build/deploy/explore-dash-sync-app.jar`) which\ncan be launched locally\n\n```\n./gradlew buildApp\n```\n\n#### Run\n\n```\njava -jar ./build/deploy/explore-dash-sync-app.jar\n```\n\nThis command will generate `explore.dat` file in the current directory Supported arguments:\n\n- `-upload` - upload data to GC Storage\n- `-dev` - load data from dev servers\n- `-quiet` - quiet mode: no notifications are pushed to Slack\n\n### Google Cloud Function\n\n#### Build\n\nGenerate [fat JAR](https://github.com/johnrengelman/shadow) `./build/deploy/explore-dash-sync-fun.jar` which can be\ndeployed to Google Cloud Platform ([BackgroundFunction](https://cloud.google.com/functions/docs/writing/background))\n\n```\n./gradlew buildFun\n```\n\n#### Deploy function to Google Cloud Platform\n\nBase on [Deploying Cloud Functions](https://cloud.google.com/functions/docs/deploying)\n\n```\ngcloud functions deploy explore-dash-sync \\\n --runtime=java17 \\\n --entry-point=org.dash.mobile.explore.sync.Function \\\n --source=build/deploy \\ \n --trigger-topic explore-dash-sync-trigger \\\n --allow-unauthenticated --memory=1024MB --timeout=300s\n``` \n\nCan be deployed manually\nfrom https://console.cloud.google.com/functions/list?authuser=0&project=dash-wallet-firebase `CREATE FUNCTION`\n\n#### Trigger function\n\nFunction can be triggered by publishing `explore-dash-sync-trigger` PubSub topic\n\n```\ngcloud pubsub topics publish explore-dash-sync-trigger\n```\n\nOr for the testnet mode:\n\n```\ngcloud pubsub topics publish explore-dash-sync-trigger --attribute=\"mode=testnet\"\n```\n\n### Generating Protocol Buffer messages (`javalite`)\n\n- src: `./src/main/proto/`\n- dst: `./src/main/java/`\n\n```\n./gradlew generateProto\n```\n\n# Google API credentials (credentials.json) not found.\n\nGoogle Cloud Console -> (dash-explore-sync) -> Credentials -> Download OAuth client\nhttps://console.cloud.google.com/apis/credentials?project=dash-explore-sync\n\nsave file as src/main/resources/credentials.json\n\n# Editing the database\nSuppose new columns need to be added to the explore database.\n1. Use an SQLite DB Browser to edit the `merchant` or `atm` tables in `src/main/resources/explore-empty.db`\n2. Add new columns as necessary\n3. Add code in `MerchantData` or `AtmData` to support those new columns\n4. Depending on the data source, code must be added the `convert` methods\n5. Within `src/main/resources/explore-empty.db` edit the `room_master_table` table value for `identity_hash` must be updated to match that of the schema generated by Room in Dash Wallet\n    ```json\n    {\n      \"formatVersion\": 1,\n      \"database\": {\n      \"version\": 2,\n      \"identityHash\": \"34049b02193e63ef6d5042b150f355e6\",\n      \"entities\": [\n       \n      ]\n    }\n    ```\n   ![](doc/identity-hash.png)\n6. Within `src/main/resources/explore-empty.db`, the User Version must be increased and match the version of `ExploreDatabase`\n    ```kotlin\n    @Database(entities = [\n        Merchant::class,\n        MerchantFTS::class,\n        Atm::class,\n        AtmFTS::class\n    ], version = 2, exportSchema = true)\n    @TypeConverters(RoomConverters::class)\n    abstract class ExploreDatabase : RoomDatabase() {\n    ```\n    ![](doc/user-version.png)\n\nExample of adding new columns to `MerchantData`:\n```kotlin\ndata class MerchantData(\n    // ...\n    var minCardPurchase: Double? = 0.0,\n    var maxCardPurchase: Double? = 0.0,\n    \n    // add new column variables here...\n) {\n    companion object {\n        // Add a ? for each new column in this INSERT_STATEMENT constant  \n        const val INSERT_STATEMENT = \"INSERT INTO merchant values(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\"\n        \n        // ...\n        const val MIN_CARD_PURCHASE_COL = 26\n        const val MAX_CARD_PURCHASE_COL = 27\n\n        // add new column number constance here...\n    }\n\n    override fun transferInto(statement: PreparedStatement): PreparedStatement {\n        return statement.apply {\n            // ...\n            setDouble(MIN_CARD_PURCHASE_COL, minCardPurchase ?: 0.0)\n            setDouble(MAX_CARD_PURCHASE_COL, maxCardPurchase ?: 0.0)\n\n            // add new statements here to set the values of the new columns\n        }\n    }\n}\n```", "release_dates": []}, {"name": "FAQs", "description": "FAQs for various topics.", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# FAQs\nFAQs for various topics.\n", "release_dates": []}, {"name": "gitian-builder", "description": "Build packages in a secure deterministic fashion inside a VM", "language": "Python", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# MAINTENANCE MODE\n\nDue to the move of Bitcoin Core to [Guix](https://github.com/bitcoin/bitcoin/blob/master/doc/release-process.md#building), this repository is switching to maintenance mode.  Only serious bugs (including security issues) will be considered going forward.\n\n# Gitian\n\nRead about the project goals at the [project home page](https://gitian.org/).\n\nThis package can do a deterministic build of a package inside a VM.\n\n## Deterministic build inside a VM\n\nThis performs a build inside a VM, with deterministic inputs and outputs.  If the build script takes care of all sources of non-determinism (mostly caused by timestamps), the result will always be the same.  This allows multiple independent verifiers to sign a binary with the assurance that it really came from the source they reviewed.\n\n## Prerequisites:\n\n### Arch:\n\n    sudo pacman -S python2-cheetah qemu rsync\n    sudo pacman -S lxc libvirt bridge-utils # for lxc mode\n\nFrom AUR:\n\n* [apt-cacher-ng](https://aur.archlinux.org/packages/apt-cacher-ng/) (you may have to play with permissions (chown to apt-cacher-ng) on files to get apt-cacher-ng to start)\n* [debootstrap](https://aur.archlinux.org/packages/debootstrap-git/)\n* [dpkg](https://aur.archlinux.org/packages/dpkg/)\n* [gnupg1](https://aur.archlinux.org/packages/gnupg1/)\n* [multipath-tools](https://aur.archlinux.org/packages/multipath-tools/) (for kpartx)\n\nNon-AUR packages:\n\n* [debian-archive-keyring](https://packages.debian.org/jessie/debian-archive-keyring) (for making Debian guests)\n* [ubuntu-keyring](https://packages.ubuntu.com/search?keywords=ubuntu-keyring) (for making Ubuntu guests)\n\nFrom newroco on GitHub:\n\n* [vmbuilder](https://github.com/newroco/vmbuilder)\n\nAlso, I had to modify the default /etc/sudoers file to uncomment the `secure_path` line, because vmbuilder isn't found otherwise when the `env -i ... sudo vmbuilder ...` line is executed (because the i flag resets the environment variables including the PATH).\n\n### Gentoo:\n\n    layman -a luke-jr  # needed for vmbuilder\n    sudo emerge dev-vcs/git net-misc/apt-cacher-ng app-emulation/vmbuilder dev-lang/ruby\n    sudo emerge app-emulation/qemu\n    export KVM=qemu-system-x86_64\n\n### Ubuntu:\n\nThis pulls in all pre-requisites for KVM building on Ubuntu:\n\n    sudo apt-get install git apache2 apt-cacher-ng python-vm-builder ruby qemu-utils\n\nIf you'd like to use LXC mode instead, install it as follows:\n\n    sudo apt-get install lxc\n\nIf you'd like to use docker mode instead, install it as follows:\n\n    sudo apt-get install docker-ce\n\n### Debian:\n\nSee Ubuntu, and also run the following on Debian Jessie or newer:\n\n    sudo apt-get install ubuntu-archive-keyring\n\nOn Debian Wheezy you run the same command, but you must first add backports to your system, because the package is only available in wheezy-backports.\n\n### OSX with MacPorts:\n\n    sudo port install ruby coreutils\n    export PATH=$PATH:/opt/local/libexec/gnubin  # Needed for sha256sum\n    \n### OSX with Homebrew:\n\n    brew install ruby coreutils\n    export PATH=$PATH:/opt/local/libexec/gnubin    \n\n#### VirtualBox:\n\nInstall virtualbox from http://www.virtualbox.org, and make sure `VBoxManage` is in your `$PATH`.\n\n## Debian Guests\n\nGitian supports Debian guests in addition to Ubuntu guests. Note that this doesn't mean you can allow the builders to choose to use either Debian or Ubuntu guests. The person creating the Gitian descriptor will need to choose a particular distro and suite for the guest and all builders must use that particular distro and suite, otherwise the software won't reproduce for everyone.\n\nTo create a Debian guest:\n\n    bin/make-base-vm --distro debian --suite jessie\n\nThere is currently no support for LXC Debian guests. There is just KVM support. LXC support for Debian guests is planned to be added soon.\n\nOnly Debian Jessie guests have been tested with Gitian. If you have success (or trouble) with other versions of Debian, please let us know.\n\nIf you are creating a Gitian descriptor, you can now specify a distro. If no distro is provided, the default is to assume Ubuntu. Since Ubuntu is assumed, older Gitian descriptors that don't specify a distro will still work as they always have.\n\n## Create the base VM for use in further builds\n**NOTE:** requires `sudo`, please review the script\n\n### KVM\n\n    bin/make-base-vm\n    bin/make-base-vm --arch i386\n\n### LXC\n\n    bin/make-base-vm --lxc\n    bin/make-base-vm --lxc --arch i386\n\nSet the `USE_LXC` environment variable to use `LXC` instead of `KVM`:\n\n    export USE_LXC=1\n\n### Docker\n\n    bin/make-base-vm --docker\n    bin/make-base-vm --docker --arch i386\n\nSet the `USE_DOCKER` environment variable to use `DOCKER` instead of `KVM`:\n\n    export USE_DOCKER=1\n\n### VirtualBox\n\nCommand-line `VBoxManage` must be in your `$PATH`.\n\n#### Setup:\n\n`make-base-vm` cannot yet make VirtualBox virtual machines ( _patches welcome_, it should be possible to use `VBoxManage`, boot-from-network Linux images and PXE booting to do it). So you must either get or manually create VirtualBox machines that:\n\n1. Are named `Gitian-<suite>-<arch>` -- e.g. Gitian-xenial-i386 for a 32-bit, Ubuntu 16 machine.\n2. Have a booted-up snapshot named `Gitian-Clean` .  The build script resets the VM to that snapshot to get reproducible builds.\n3. Has the VM's NAT networking setup to forward port `localhost:2223` on the host machine to port `22` of the VM; e.g.:\n\n```\n    VBoxManage modifyvm Gitian-xenial-i386 --natpf1 \"guestssh,tcp,,2223,,22\"\n```\n\nThe final setup needed is to create an `ssh` key that will be used to login to the virtual machine:\n\n    ssh-keygen -t rsa -f var/id_rsa -N \"\"\n    ssh -p 2223 ubuntu@localhost 'mkdir -p .ssh && chmod 700 .ssh && cat >> .ssh/authorized_keys' < var/id_rsa.pub\n\nThen log into the vm and copy the `ssh` keys to root's `authorized_keys` file.\n\n    ssh -p 2223 ubuntu@localhost\n    # Now in the vm\n    sudo bash\n    mkdir -p .ssh && chmod 700 .ssh && cat ~ubuntu/.ssh/authorized_keys >> .ssh/authorized_keys\n\nSet the `USE_VBOX` environment variable to use `VBOX` instead of `KVM`:\n\n    export USE_VBOX=1\n\n## Sanity-testing\n\nIf you have everything set-up properly, you should be able to:\n\n    PATH=$PATH:$(pwd)/libexec\n    make-clean-vm --suite xenial --arch i386\n\n    # on-target needs $DISTRO to be set to debian if using a Debian guest\n    # (when running gbuild, $DISTRO is set based on the descriptor, so this line isn't needed)\n    DISTRO=debian\n\n    # For LXC:\n    LXC_ARCH=i386 LXC_SUITE=xenial on-target ls -la\n\n    # For KVM:\n    start-target 32 xenial-i386 &\n    # wait a few seconds for VM to start\n    on-target ls -la\n    stop-target\n\n## Building\n\nCopy any additional build inputs into a directory named _inputs_.\n\nThen execute the build using a `YAML` description file (can be run as non-root):\n\n    export USE_LXC=1 # LXC only\n    bin/gbuild <package>.yml\n\nor if you need to specify a commit for one of the git remotes:\n\n    bin/gbuild --commit <dir>=<hash> <package>.yml\n\nThe resulting report will appear in `result/<package>-res.yml`\n\nTo sign the result, perform:\n\n    bin/gsign --signer <signer> --release <release-name> <package>.yml\n\nWhere `<signer>` is your signing PGP key ID and `<release-name>` is the name for the current release.  This will put the result and signature in the `sigs/<package>/<release-name>`.  The `sigs/<package>` directory can be managed through git to coordinate multiple signers.\n\nAfter you've merged everybody's signatures, verify them:\n\n    bin/gverify --release <release-name> <package>.yml\n\n\n## Poking around\n\n* Log files are captured to the _var_ directory\n* You can run the utilities in libexec by running `PATH=\"libexec:$PATH\"`\n* To start the target VM run `start-target 32 xenial-i386` or `start-target 64 xenial-amd64`\n* To ssh into the target run `on-target` (after setting $DISTRO to debian if using a Debian guest) or `on-target -u root`\n* On the target, the _build_ directory contains the code as it is compiled and _install_ contains intermediate libraries\n* By convention, the script in `<package>.yml` starts with any environment setup you would need to manually compile things on the target\n\nTODO:\n- disable sudo in target, just in case of a hypervisor exploit\n- tar and other archive timestamp setter\n\n## LXC tips\n\n`bin/gbuild` runs `lxc-execute` or `lxc-start`, which may require root.  If you are in the admin group, you can add the following sudoers line to prevent asking for the password every time:\n\n    %admin ALL=NOPASSWD: /usr/bin/lxc-execute\n    %admin ALL=NOPASSWD: /usr/bin/lxc-start\n\nRight now `lxc-start` is the default, but you can force `lxc-execute` (useful for Ubuntu 14.04) with:\n\n    export LXC_EXECUTE=lxc-execute\n\nRecent distributions allow lxc-execute / lxc-start to be run by non-privileged users, so you might be able to rip-out the `sudo` calls in `libexec/*`.\n\nIf you have a runaway `lxc-start` command, just use `kill -9` on it.\n\nThe machine configuration requires access to br0 and assumes that the host address is `10.0.2.2`:\n\n    sudo brctl addbr br0\n    sudo ifconfig br0 10.0.2.2/24 up\n\n## Tests\n\nNot very extensive, currently.\n\n`python -m unittest discover test`\n", "release_dates": []}, {"name": "gitian.sigs", "description": "Gitian signatures and assertions for Dash", "language": "Python", "license": null, "readme": "# gitian.sigs\n\nDEPRECATED: We no longer use Gitian to produce deterministic binaries; we use [Guix](https://guix.gnu.org/) instead.\nYou can find corresponding signatures in the [guix.sigs repository](https://github.com/dashpay/guix.sigs).\n\nThis repository is for deterministic build results for Dash releases.\n\nSee the [release process](https://github.com/dashpay/dash/blob/master/doc/release-process.md)\nin the Dash repository for how to\ndeterministically build binaries and then pgp-sign them.\n\n[Instructions for setting up a virtual machine](https://github.com/dashpay/dash/blob/master/doc/gitian-building.md) in which you can\ngitian build as well as [public keys of developers and active contributors](https://github.com/dashpay/dash/tree/master/contrib/gitian-keys) can also be found there.\n\nYou can verify PGP signatures produced by a specific author (e.g. with a nickname `some_food`)\nfor a specific version (e.g. 0.9.9.9) via a simple bash script like this:\n``` bash\nexport VERSION=0.9.9.9 && export PR_AUTHOR=some_food \\\n  && gpg --status-fd 1 --verify-files $VERSION-{osx-*,win-*,linux}/$PR_AUTHOR/*.sig 2>/dev/null | grep -e GOODSIG \\\n  && gpg --status-fd 1 --verify-files $VERSION-{osx-*,win-*,linux}/$PR_AUTHOR/*.sig 2>/dev/null | grep -e BADSIG -B4 | grep -e BADSIG -e FILE_START\n```\n\nThis should produce a few lines like\n```\n[GNUPG:] GOODSIG 9999999999999999 some_food <some_food@some_plate.org>\n```\nor something like\n```\n[GNUPG:] FILE_START 1 0.9.9.9-win-signed/some_food/dash-win-signer-build.assert.sig\n[GNUPG:] BADSIG 9999999999999999 some_food <some_food@some_plate.org>\n```\nif there is a bad signature.\n", "release_dates": []}, {"name": "go-engineer-code-challenge", "description": "Go Engineer Code Challenge", "language": "Go", "license": null, "readme": "<p align=\"center\">\n\t<a href=\"https://git.io/col\">\n\t\t<img src=\"https://img.shields.io/badge/%E2%9C%93-collaborative_etiquette-brightgreen.svg\" alt=\"Collaborative Etiquette\">\n\t</a>\n\t<a href=\"https://twitter.com/intent/follow?screen_name=dashpay\">\n\t\t<img src=\"https://img.shields.io/twitter/follow/dashpay.svg?style=social&logo=twitter\" alt=\"follow on Twitter\">\n\t</a>\n\t<a href=\"#\">\n\t\t<img src=\"https://travis-ci.com/dashevo/go-engineer-code-challenge.svg?branch=main\" alt=\"travis-ci\">\n\t</a>\n\t<a href=\"#\">\n\t\t<img src=\"https://img.shields.io/dub/l/vibe-d.svg\" alt=\"MIT\">\n\t</a>\n</p>\n\n<p>&nbsp;</p>\n\n<p align=\"center\">\n\t<a href=\"https://dash.org\">\n\t\t<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Dash_digital-cash_logo_2018_rgb_for_screens.svg/1600px-Dash_digital-cash_logo_2018_rgb_for_screens.svg.png\" width=\"600\">\n\t</a>\n</p>\n\n<p>&nbsp;</p>\n\n# Go Engineer Code Challenge\n\n> Code challenge for Dash Core Team candidates\n\nThe goal of this challenge is to create a backend application which receives,\nvalidates and displays data from users.\n\nThis repository is designed as a mono-repository for your application and external services. We've prepared an application skeleton for you and assume that your solution will be a light client and runs on remote untrusted hosts. In the provided skeleton, please implement [application logic](internal/app/usecase/service.go) which validates and persists [sample user data](assets/data.json) in external service(s), to which your application should connect. Your application should also be able to retrieve this data back and verify its integrity.\n\nYour solution must implement at least one of the following types of external services:\n\n  1. **Peer-to-peer service**: This service runs on remote untrusted hosts.\n     Networking and storage will be cheap for you - **0.0001 DASH per byte** - but you can\u2019t trust\n     this service because a malicious operator may spoof (modify) your data, or a man-in-the-middle attack may occur.\n     Code for this service should be placed [here](internal/p2p) and the entrypoint of the service is [here](cmd/p2p/main.go).\n  2. **Self-hosted service**: This service runs on your server.\n     Networking and storage will be much more expensive for you - **0.001 DASH per byte** - but the data is\n     located on your server, so you can trust it.\n     Code for this service should be placed [here](internal/selfhosted) and the entrypoint of the service is [here](cmd/selfhosted/main.go).\n\nFor communication with your external service(s) we provide [two HTTP Client instances](https://github.com/dashevo/go-engineer-code-challenge/blob/main/internal/app/usecase/service.go#L10-L11).\nThey use middleware to calculate inbound and outbound traffic.\n\n## Your mission\n\n- Use this repository as a template for the solution.\n- Write a brief spec for your solution.\n- Implement as many external services as you need to store sample data from the application.\n- Implement [the store method](internal/app/usecase/service.go#L27). Validate and persist sample data\n   in the external service(s).\n- Implement [the fetch method](internal/app/usecase/service.go#L23). Fetch sample data back and ensure its\n   integrity. **When you fetch data back from the untrusted service, you should verify it for spoofing protection**.\n- Write beautiful code. Code design (SOLID, Clean Architecture, 12factor) is important to us.\n- Run the application and review the results. **Try to spend as little money as possible.** Cost depends on the size\n   of the request / response and elapsed time. The exact formula is found in\n   [the application skeleton code](internal/app/metric/calculator.go).\n- Share a link to your private solution repository with us or send us an archive containing your solution.\n\n## Requirements\n\n### External services\n\n- Services should be written in Go.\n- Services should be dockerized and started with [docker compose](docker-compose.yml) in the root directory.\n- Data should be permanently persisted (i.e. available after a service restart).\n\n### Application\n\n- You should validate sample data in the store method. Return an error if any data is invalid.\n- You should check data integrity in the fetch method to avoid spoofing. Keep in mind that the fetch method will not have access to the original input data provided to the store method.\n- Make sure the data returned by the fetch method matches the input data from the store action.\n- You should use `p2pClient` for sending / retrieving data from a P2P service.\n- You should use `selfHostedClient` for sending / retrieving data from a hosted service.\n- You cannot store any data on the application side, including cryptographic keys.\n\n### Sample data validation rules\n\nThe provided [sample data](assets/data.json) contains a collection of various objects.\nEach type of object has its own validation rules as defined below:\n\n#### User\n\n- `id`\n  - Format: `a-zA-Z0-9`\n  - Length: `64`\n  - Required\n- `type`\n  - Value: `user`\n  - Required\n- `userName`\n  - Format: `a-zA-Z0-9_.`\n  - Max length: `20`\n  - Required\n- `firstName`\n  - Max length: `100`\n- `lastName`\n  - Max length: `100`\n- `email`\n  - According to RFC\n\n#### Payment\n\n- `id`\n  - Format: `a-zA-Z0-9`\n  - Length: `64`\n  - Required\n- `type`\n  - Value: `payment`\n  - Required\n- `fromUserId`\n  - Format: `a-zA-Z0-9`\n  - Length: `64`\n  - Required\n- `toMerchantId` or `toUserId`\n  - Format: `a-zA-Z0-9`\n  - Length: `64`\n  - Required\n- `amount`\n  - Format: float number\n   Not equal or less than `0`\n  - Required\n- `createdAt`\n  - Format: Date ISO 8601\n  - Required\n\n#### Merchant\n\n- `id`\n  - Format: `a-zA-Z0-9`\n  - Length: `64`\n  - Required\n- `type`\n  - Value: `merchant`\n  - Required\n- `name`\n  - Format: `a-zA-Z0-9_.`\n  - Max length: `20`\n  - Required\n\n## Summary\n\nFollow the [challenge mission](#your-mission) according to the [provided requirements](#requirements) and do your\nbest. Good luck!\n\n## License\n\n[MIT](LICENSE) \u00a9 2021 Dash Core Team\n", "release_dates": []}, {"name": "godashutil", "description": "Provides Dash-specific convenience functions and types", "language": "Go", "license": {"key": "isc", "name": "ISC License", "spdx_id": "ISC", "url": "https://api.github.com/licenses/isc", "node_id": "MDc6TGljZW5zZTEw"}, "readme": "godashutil\n==========\n\n[![Build Status](http://img.shields.io/travis/dashpay/godashutil.svg)]\n(https://travis-ci.org/dashpay/godashutil) [![Coverage Status]\n(http://img.shields.io/coveralls/dashpay/godashutil.svg)]\n(https://coveralls.io/r/dashpay/godashutil?branch=master) [![ISC License]\n(http://img.shields.io/badge/license-ISC-blue.svg)](http://copyfree.org)\n[![GoDoc](http://img.shields.io/badge/godoc-reference-blue.svg)]\n(http://godoc.org/github.com/dashpay/godashutil)\n\nPackage godashutil provides bitcoin-specific convenience functions and types.\nA comprehensive suite of tests is provided to ensure proper functionality.  See\n`test_coverage.txt` for the gocov coverage report.  Alternatively, if you are\nrunning a POSIX OS, you can run the `cov_report.sh` script for a real-time\nreport.\n\nThis package was developed for btcd, an alternative full-node implementation of\nbitcoin which is under active development by Conformal.  Although it was\nprimarily written for btcd, this package has intentionally been designed so it\ncan be used as a standalone package for any projects needing the functionality\nprovided.\n\n## Installation and Updating\n\n```bash\n$ go get -u github.com/dashpay/godashutil\n```\n\n## GPG Verification Key\n\nAll official release tags are signed by Conformal so users can ensure the code\nhas not been tampered with and is coming from the btcsuite developers.  To\nverify the signature perform the following:\n\n- Download the public key from the Conformal website at\n  https://opensource.conformal.com/GIT-GPG-KEY-conformal.txt\n\n- Import the public key into your GPG keyring:\n  ```bash\n  gpg --import GIT-GPG-KEY-conformal.txt\n  ```\n\n- Verify the release tag with the following command where `TAG_NAME` is a\n  placeholder for the specific tag:\n  ```bash\n  git tag -v TAG_NAME\n  ```\n\n## License\n\nPackage godashutil is licensed under the [copyfree](http://copyfree.org) ISC\nLicense.\n\n## Credits\n\nOriginal work by The btcsuite developers [https://github.com/btcsuite/btcutil](https://github.com/btcsuite/btcutil).\nModified to work with Dash instead of Bitcoin.\n", "release_dates": []}, {"name": "grovedb", "description": "Storage solution with proofs and secondary indices.", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# GroveDB\n| Branch | Tests                                                                                                                           | Coverage |\n|--------|---------------------------------------------------------------------------------------------------------------------------------|------|\n| master | [![Tests](https://github.com/dashevo/grovedb/workflows/CI/badge.svg?branch=master)](https://github.com/dashevo/grovedb/actions) | [![codecov](https://codecov.io/gh/dashpay/grovedb/branch/master/graph/badge.svg?token=6Z6A6FT5HV)](https://codecov.io/gh/dashpay/grovedb) |\n\n\n*Hierarchical Authenticated Data Structure with Efficient Secondary Index Queries*\n\nGroveDB is a database system designed specifically for efficient secondary index queries, proofs, speed, and reliability. It was built for use within [Dash Platform](https://dashplatform.readme.io/docs/introduction-what-is-dash-platform), but can be easily integrated into other applications for similar use.  \n   \n## Motivation\n\nSecondary indices are crucial to any database management system. All previous solutions had certain tradeoffs depending on the problem they were trying to solve. \n\nConsider an authenticated data structure, like a Merkle tree built on a database of restaurants for example. Each restaurant has certain attributes, such as price and type:\n\n```\nstruct Restaurant{\n\tID uint32;\n\tname: String;\n\ttype: String;\n\tisVegan: bool;\n};\n```\n\nIf we have say four restaurants, we might normally commit them to a Merkle tree as follows:\n\n```mermaid\ngraph TD;\nroot-->A[\" \"];\nroot-->B[\" \"];\nA-->AA[\"id:0\"];\nA-->AB[\"id:1\"];\nB-->AC[\"id:2\"];\nB-->AD[\"id:3\"];\n```\n\n\nQuerying by primary key is easy and efficient. If we have a query such as  ```SELECT * WHERE ID <= 2; ```, we can return the appropriate elements as well as construct an efficient range proof. However, querying by a secondary index is not efficient at all; it's likely that you will have to iterate over the entire structure. Consider the query ``` SELECT * WHERE isVegan=true;```. When sorted by primary key, the vegan restaurant won't be contiguous. Not only will the proof be nontrivial, but so will the time required to find these elements. \n\nGroveDB is a classic time-space tradeoff. It enables efficient querying on secondary indices by precomputing and committing them. A subtree of each possible queryable secondary index (up to a cap) is built and committed to our authenticated data structure. A tree of subtrees; a grove. For the same data, part of the analogous GroveDB structure might look like this:\n\n```mermaid\ngraph TD;\nroot-->A[\"\\'Restaurant\\'\"];\nroot-->B[\"...\"];\nA-->Q[\"ID\"];\nA-->W[\"name\"];\nA-->E[\"kind\"];\nA-->R[\"isVegan\"];\nQ-->Z[\"...\"];\nW-->X[\"...\"];\nE-->C[\"...\"];\nR-->Y[\"id:2\"];\nR-->U[\"id:1\"];\nR-->I[\"id:0\"];\nR-->O[\"id:3\"];\n```\nFrom here, a query on the secondary index ```isVegan``` would traverse to the subtree built for this secondary index. The items are not necessarily replicated, but referenced to.\n## Features\n- **Efficient secondary index queries** - Built specifically for and tailored to secondary index queries.\n- **Proofs** - Supports proofs of membership, proofs of non-membership, and range proofs.\n- **Run anywhere** - Being written in Rust, it supports all compile targets. x86, Raspberry Pis (AArch64), and Wasm. There are Node.js bindings as well.\n\n## Architecture\nInsertion and deletion work as you might expect, updating the respective subtrees and returning appropriate proofs of membership/nonmembership.\n### Tree structure(s)\nInstead of disjoint authenticated data structures, we opt for a unified one; a hierarchical, authenticated data structure based off of [Database Outsourcing with Hierarchical Authenticated Data Structures](https://ia.cr/2015/351). Elements are the most atomic pieces and can be represented in a few ways. They can be items, item references, trees, trees with items, or even trees with item references. An element contains an item, a reference to an object, or a subtree.\n\n\nThe trees are based off of our fork of Merk, with custom patches applied for better use with GroveDB. Merk is unique in the fact that it's an AVL tree, so the intermediary nodes also contain a key/value pair. Each node contains a third hash, the ```kv_hash```, in addition to the hashes of its left and right children. The ```kv_hash``` is simply computed as ```kv_hash=H(key,value)```. The node hash is then computed as ```H(kv_hash,left_child_hash,right_child_hash)```. Merk uses Blake2B, and rs-merkle uses SHA256. \n\n### Storage\nRocksDB is a key-value store, forked from LevelDB and built out by Facebook. We chose it because of its high performance, maturity, and its compatibility with our stack. Merk itself is built on top of RocksDB.\n\nWe have three types of storage: auxiliary, metadata, and tree root storage. Auxiliary storage is used to store plain key-value data which is not used in consensus.  Metadata is used to store things outside of the GroveDB usage scope. Is has no prefixes, and therefore has no relation to subtrees. It lives at a higher level. Tree root storage is used to store subtrees.\n\nA database transaction in GroveDB is a wrapper around the ```OptimisticTransactionDB``` primitive from RocksDB. An optimistic transaction hopes on average there will be only a few conflicts, which are detected at the commit stage. This is as compared to the pessimistic model, which uses a lock. \n\n## Querying\nTo query GroveDB, a path and a query item have to be supplied.\nThe path specifies the subtree, and the query item determines which nodes are selected from the subtree.\n\nGroveDB currently supports 10 query item types:\n- Key(key_name)\n- Range(start..end)\n- RangeInclusive(start..=end)\n- RangeFull(..)\n- RangeFrom(start..)\n- RangeTo(..end)\n- RangeToInclusive(..=end)\n- RangeAfter(prev..)\n- RangeAfterTo(prev..end)\n- RangeAfterToInclusive(prev..=end)\n\nThis describes a basic query system: select a subtree then select nodes from that subtree. The need to create more complex queries or add restrictions to the result set may arise, which leads us to the **PathQuery**.\n\n### PathQuery\nThe ```PathQuery``` allows for more complex queries with optional restrictions on the result set, i.e. limits and offsets. \n```\n    PathQuery\n        path: [k1, k2, ..]\n        sized_query: SizedQuery\n            limit: Optional<number>\n            offset: Optional<number>\n            query: Query\n                items: [query_item_1, query_item_2, ...],\n                default_subquery_branch: SubqueryBranch\n                    subquery_path: Optional<key>\n                    subquery_value: Optional<Query>\n                conditional_subquery_branches: Map<QueryItem, SubqueryBranch>\n                        \n```\n\nA path is needed to define the starting context for the query.\n\n#### SizedQuery\nThe ```sized_query``` determines how the result set would be restricted. It holds optional limits and offset values. \nThe ```limit``` determines the maximum size of the result set and the ```offset``` specifies the number of elements to skip before adding to the result set. \n\n#### Query\nThe ```query``` object is a recursive structure - it specifies how to select nodes from the current subtree and has the option to recursively apply another query to the result set obtained from the previous query. \n\n#### Items\nThe ```items``` are a collection of query items that decide which nodes to select from the current context (this builds a result set).  \n\nBefore describing ```default_subquery_branch``` and ```conditional_subquery_branches```, we need to define their building blocks, subquery branches:\n\n#### Subquery Branches\n```\n    subquery_path: Optional<Key>\n    subquery_value: Optional<Query>\n```\n**Cases**  \n- ```subquery_path: true```, ```subquery_value: false```  \nThe node with the subquery path is selected and returned as the result set.\n\n- ```subquery_path: false```, ```subquery_value: true```  \nThe query held in subquery_value is applied directly to the subtree, and the result is returned as the result set.\n\n- ```subquery_path: true```, ```subquery_value: true``` \nFirst the node with the subquery path is selected and set as new context.  \nThen, the subquery value is applied to this new context, and the result is returned as the result set.\n\nThe subquery branch is used on a single node but can be applied to the result set of a previous query with the use of **default_subquery_branch** and **conditional_subquery_branches**:\n\n#### default_subquery_branch\nIf this exists, the specified subquery branch is applied to every node in the result set of the previous query.\n\n#### conditional_subquery_branch\nRather than applying a subquery branch to every node in the result set, you might want to apply it to a subset of the result set.  In such cases, we make use of a conditional subquery.  \n  \nThe conditional subquery holds a map QueryItem to SubqueryBranch.  \n```\n    Map<QueryItem, SubqueryBranch>\n```\nFor every node in the result set, we check if there is a query item that matches it. If there is, then the associated subquery branch is applied to that node.  Note that once a conditional subquery has been applied to a node, the default subquery does run on that node.\n\n## Merging Path Queries\nThis section describes how GroveDB deals with the merging of path queries.\n\nMergeable path queries allow for the combination of separate path queries that do different things into a single equivalent path query.  \n  \nA path query can be represented as a set of keys (path to a subtree), and a query to apply to that subtree (query can have unknown depth):  \n\np<sub>i</sub> = [k<sub>1</sub>, k<sub>2</sub>, .., k<sub>n</sub>, Query]\n\nSomething very important to show is that a path query chain can be compressed at any point, i.e. you can turn a sequence of keys into a single query.  \n\nConsider p<sub>1</sub> = [k<sub>1</sub>, k<sub>2</sub>, k<sub>3</sub>]. This reads as: \n- From the root tree, select node with key k1\n- Change the context to k1, then select the node with key k2\n- Change the context to k2 and finally select the node with key k3\n\nWe can create an equivalent query to represent this, which can look like this:\n```\n    Query\n        query k1\n        cond on k1\n            query k2\n            cond on k2\n                query k3\n                cond on k3\n```\n[k<sub>1</sub>, k<sub>2</sub>, k<sub>3</sub>] => [Q<sub>1</sub>],  where Q1 is equivalent to the path array.  \n\nThis can also be done at any point in the path array, so we can have:  \n\n[k<sub>1</sub>, k<sub>2</sub>, k<sub>3</sub>] => [k<sub>1</sub>, Q<sub>2</sub>]  \n[k<sub>1</sub>, k<sub>2</sub>, k<sub>3</sub>] => [K<sub>1</sub>, K<sub>2</sub> Q<sub>3</sub>]\n\nThe path merge algorithm becomes:\n- Find the common path across the path queries\n- Compress each path array to a query after the common path index\n- Merge the compressed query into a single query\n- Return new path query with common path as path and combined query as query\n\n**Example:**  \np<sub>1</sub> =  [k<sub>1</sub>, k<sub>2</sub>, k<sub>3</sub>, Q<sub>a</sub>]  \np<sub>2</sub> =  [k<sub>1</sub>, k<sub>2</sub>, k<sub>4</sub>, Q<sub>b</sub>]\n\nCommon path = [k1, k2]  \n\nCompress each path array after common path:  \np<sub>1</sub> = [k<sub>1</sub>, k<sub>2</sub>, Q<sub>c</sub>]  \np<sub>2</sub> = [k<sub>1</sub>, k<sub>2</sub>, Q<sub>d</sub>]  \n\nMerge compressed queries:  \nQ<sub>p</sub> = Q<sub>c</sub> + Q<sub>d</sub> \n\nReturn final PathQuery:  \np<sub>f</sub> = [k<sub>1</sub>, k<sub>2</sub>, Q<sub>p</sub>]\n\n\n## Usage\nGroveDB is built for use with Dash Platform, but can be easily integrated into other applications for similar use. See its use in [rs-drive](https://github.com/dashevo/rs-drive) ([example](https://github.com/dashevo/rs-drive-example)). \n\nWe currently also have bindings for Node.js. See [node-grove](https://github.com/dashevo/grovedb/tree/master/node-grove). \n\n## Building\nFirst, install [rustup](https://www.rust-lang.org/tools/install) using your preferred method. \n\nRust nightly is required to build, so ensure you are using the correct version.\n\n```rustup install nightly```\n\nClone the repo and navigate to the main directory:\n\n```git clone https://github.com/dashevo/grovedb.git && cd grovedb```\n\nFrom here we can build: \n\n```cargo build```\n\n\n## Performance\n\nrun with ```cargo test```\n|CPU | Time |\n|----|-----|\n|Raspberry Pi 4 | 2m58.491s|\n|R5 1600AF | 33.958s |\n|R5 3600 | 25.658s |\n\n", "release_dates": ["2023-06-26T23:42:03Z", "2023-04-07T15:45:07Z", "2023-02-14T08:35:01Z", "2023-02-12T05:02:33Z", "2023-01-30T10:58:55Z", "2023-01-27T09:52:53Z", "2023-01-18T11:16:09Z", "2023-01-09T10:54:53Z", "2023-01-05T20:24:12Z", "2023-01-05T18:18:39Z", "2022-12-29T22:54:42Z", "2022-12-21T22:53:51Z", "2022-12-21T15:59:56Z", "2022-12-19T13:38:19Z", "2022-12-13T12:11:09Z", "2022-12-12T12:48:08Z", "2022-12-08T11:12:54Z", "2022-11-29T15:03:31Z", "2022-11-20T03:53:02Z", "2022-11-08T02:11:40Z", "2022-11-07T18:36:42Z", "2022-06-27T23:45:13Z", "2022-02-01T11:20:53Z", "2022-02-01T06:50:13Z", "2022-01-27T09:53:38Z"]}, {"name": "guix.sigs", "description": null, "language": null, "license": null, "readme": "# guix.sigs\nThis repository contains Guix attestations for releases of Dash Core.\n\nSee the [release process](https://github.com/dashpay/dash/blob/master/doc/release-process.md)\nin the Dash repository for how to\nbuild the release with Guix and create an attestation.\n\nYou can verify PGP signatures produced by a specific author (e.g. with a nickname `some_food`)\nfor a specific version (e.g. 0.9.9.9) via a simple bash script like this:\n``` bash\nexport VERSION=0.9.9.9 && export PR_AUTHOR=some_food \\\n  && gpg --status-fd 1 --verify-files $VERSION-{osx-*,win-*,linux}/$PR_AUTHOR/*.sig 2>/dev/null | grep -e GOODSIG \\\n  && gpg --status-fd 1 --verify-files $VERSION-{osx-*,win-*,linux}/$PR_AUTHOR/*.sig 2>/dev/null | grep -e BADSIG -B4 | grep -e BADSIG -e FILE_START\n```\n\nThis should produce a few lines like\n```\n[GNUPG:] GOODSIG 9999999999999999 some_food <some_food@some_plate.org>\n```\nor something like\n```\n[GNUPG:] FILE_START 1 0.9.9.9-win-signed/some_food/dash-win-signer-build.assert.sig\n[GNUPG:] BADSIG 9999999999999999 some_food <some_food@some_plate.org>\n```\nif there is a bad signature.\n", "release_dates": []}, {"name": "insight-api", "description": "A Dash blockchain REST and WebSocket API Service", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Insight-API\n\n[![Build Status](https://github.com/dashevo/insight-api/actions/workflows/test_and_release.yml/badge.svg)](https://github.com/dashevo/insight-api/actions/workflows/test_and_release.yml)\n[![NPM version](https://img.shields.io/npm/v/@dashevo/insight-api.svg)](https://npmjs.org/package/@dashevo/insight-api)\n[![API stability](https://img.shields.io/badge/stability-stable-green.svg)](https://nodejs.org/api/documentation.html#documentation_stability_index)\n\nA Dash blockchain REST and WebSocket API Service\n\nThis is a backend-only service. If you're looking for the web frontend application, take a look at https://github.com/dashevo/insight-ui.\n\n## Table of Content\n- [Install](#install)\n    - [Prerequisites](#prerequisites)\n    - [Query Rate Limit](#query-rate-limit)\n- [Usage](#usage)\n- [API HTTP Endpoints](#api-http-endpoints)\n    - [Block](#block)\n    - [Block Index](#block-index)\n    - [Raw Block](#raw-block)\n    - [Block Summaries](#block-summaries)\n    - [Transaction](#transaction)\n    - [Address](#address)\n    - [Address Properties](#address-properties)\n    - [Unspent Outputs](#unspent-outputs)\n    - [Unspent Outputs for Multiple Addresses](#unspent-outputs-for-multiple-addresses)\n    - [InstantSend Transactions](#instantsend-transactions)\n    - [Transactions by Block](#transactions-by-block)\n    - [Transactions by Address](#transactions-by-address)\n    - [Transactions for Multiple Addresses](#transactions-for-multiple-addresses)\n    - [Transaction Broadcasting](#transaction-broadcasting)\n    - [Sporks List](#sporks-list)\n    - [Proposals Informations](#proposals-informations)\n    - [Proposals Count](#proposals-count)\n    - [Budget Proposal List](#budget-proposal-list)\n    - [Budget Triggers List](#budget-triggers-list)\n    - [Budget Proposal Detail](#budget-proposal-detail)\n    - [Proposal Check](#proposal-check)\n    - [Proposal Deserialization](#proposal-deserialization)\n    - [Proposal Current Votes](#proposal-current-votes)\n    - [Governance Budget](#governance-budget)\n    - [Masternodes List](#masternodes-list)\n    - [Historic Blockchain Data Sync Status](#historic-blockchain-data-sync-status)\n    - [Live Network P2P Data Sync Status](#live-network-p2p-data-sync-status)\n    - [Status of the Dash Network](#status-of-the-dash-network)\n    - [Utility Methods](#utility-methods)\n- [Web Socket Api](#web-socket-api)\n    - [Example Usage](#example-usage)\n- [Notes on Upgrading from v0.3](#notes-on-upgrading-from-v03)\n- [Notes on Upgrading from v0.2](#notes-on-upgrading-from-v02)\n- [Resources](#resources)\n- [License](#license)\n\n## Install\n\n```bash\nnpm install -g @dashevo/dashcore-node\ndashcore-node create mynode\ncd mynode\ndashcore-node install @dashevo/insight-api\ndashcore-node start  # to also start the service\n```\n\nThe API endpoints will be available by default at: `http://localhost:3001/insight-api/`\n\n### Prerequisites\n\n- [Dashcore Node Dash 6.x](https://github.com/dashevo/dashcore-node)\n\n**Note:** You can use an existing Dash data directory, however `txindex`, `addressindex`, `timestampindex` and `spentindex` need to be enabled in `dash.conf`, as well as a few other additional fields.\n\n### Query Rate Limit\n\nTo protect the server, insight-api has a built-in query rate limiter. It can be configurable in `dashcore-node.json` with:\n\n```json /*eslint-disable */\n\n\"servicesConfig\": {\n  \"insight-api\": {\n    \"rateLimiterOptions\": {\n      \"whitelist\": [\"::ffff:127.0.0.1\"]\n    }\n  }\n}\n```\n\nWith all the configuration options available: https://github.com/dashevo/insight-api/blob/master/lib/ratelimiter.js#L10-17\n\nOr disabled entirely with:\n\n```json /*eslint-disable */\n\"servicesConfig\": {\n  \"insight-api\": {\n    \"disableRateLimiter\": true\n  }\n}\n```\n\n## Usage\n\nFollow the install instructions above, and ...\n\n```bash\ndashcore-node start\n```\n\nThis will start the Insight-API listening on default port 3001.\n\n## API HTTP Endpoints\n\n### Block\n\n```\n  /insight-api/block/[:hash]\n  /insight-api/block/0000000006e7b38e8ab2d351239019c01de9a148b5baef58cfe52dfd9917cedc\n```\n\n### Block Index\n\nGet block hash by height\n\n```\n  /insight-api/block-index/[:height]\n  /insight-api/block-index/0\n```\n\nThis would return:\n\n```\n{\n  \"blockHash\":\"00000bafbc94add76cb75e2ec92894837288a481e5c005f6563d91623bf8bc2c\"\n}\n```\n\nwhich is the hash of the TestNet Genesis block (0 height)\n\n### Raw Block\n\n```\n  /insight-api/rawblock/[:blockHash]\n```\n\nThis would return:\n\n```\n{\n  \"rawblock\":\"blockhexstring...\"\n}\n```\n\n### Block Summaries\n\nGet block summaries by date:\n\n```\n  /insight-api/blocks?limit=3&blockDate=2017-04-22\n```\n\nExample response:\n\n```\n{\n  \"blocks\": [\n    {\n      \"height\": 188928,\n      \"size\": 312,\n      \"hash\": \"00000000ee9a976cf459240c2add1147137ca6126b7906fa13ce3d80b5cadcc7\",\n      \"time\": 1492905418,\n      \"txlength\": 1,\n      \"poolInfo\": {\n        \"poolName\": \"BTCC Pool\",\n        \"url\": \"https://pool.btcc.com/\"\n      }\n    },{...},{...}\n  ],\n  \"length\": 3,\n  \"pagination\": {\n    \"next\":\"2017-04-23\",\n    \"prev\":\"2017-04-21\",\n    \"currentTs\":1492905599,\n    \"current\":\"2017-04-22\",\n    \"isToday\":false,\n    \"more\":true,\n    \"moreTs\":1492905600\n  }\n}\n```\n\n### Transaction\n\n```\n  /insight-api/tx/[:txid]\n  /insight-api/tx/ebdca263fe1c75c8609ce8fe3d82a320a0b3ca840f4df995883f5dab1b9ff8d9\n\n  /insight-api/rawtx/[:rawid]\n  /insight-api/rawtx/ebdca263fe1c75c8609ce8fe3d82a320a0b3ca840f4df995883f5dab1b9ff8d9\n```\n\n### Address\n\n```\n  /insight-api/addr/[:addr][?noTxList=1][&from=&to=]\n  /insight-api/addr/ybi3gej7Ea1MysEYLR7UMs3rMuLJH5aVsW?noTxList=1\n  /insight-api/addr/yPv7h2i8v3dJjfSH4L3x91JSJszjdbsJJA?from=1000&to=2000\n\n  /insight-api/addrs/[:addrs][?noTxList=1][&from=&to=]\n  /insight-api/addrs/ygwNQgE5f15Ygopbs2KPRYMS4TcffqBpsz,ygw5yCtVkx3hREke4L8qDqQtnNoAiPKTSx\n  /insight-api/addrs/ygwNQgE5f15Ygopbs2KPRYMS4TcffqBpsz,ygw5yCtVkx3hREke4L8qDqQtnNoAiPKTSx?from=1000&to=2000\n```\n\n### Address Properties\n\n```\n  /insight-api/addr/[:addr]/balance\n  /insight-api/addr/[:addr]/totalReceived\n  /insight-api/addr/[:addr]/totalSent\n  /insight-api/addr/[:addr]/unconfirmedBalance\n\n  /insight-api/addrs/[:addrs]/balance\n  /insight-api/addrs/[:addrs]/totalReceived\n  /insight-api/addrs/[:addrs]/totalSent\n  /insight-api/addrs/[:addrs]/unconfirmedBalance\n```\n\nThe response contains the value in Satoshis.\n\n### Unspent Outputs\n\n```\n  /insight-api/addr/[:addr]/utxo\n```\n\nSample return:\n\n```\n[\n  {\n    \"address\":\"ygwNQgE5f15Ygopbs2KPRYMS4TcffqBpsz\",\n    \"txid\":\"05d70bc1c4cf1c3afefc3250480d733b5666b19cb1f629901ded82cb2d6263d1\",\n    \"vout\":0,\n    \"scriptPubKey\":\"76a914e22dc8acf5bb5624f4beef22fb2238f8479e183f88ac\",\n    \"amount\":0.01194595,\n    \"satoshis\":1194595,\n    \"height\":142204,\n    \"confirmations\":124317\n  },{...}\n]\n```\n\n### Unspent Outputs for Multiple Addresses\n\nGET method:\n\n```\n  /insight-api/addrs/[:addrs]/utxo\n  /insight-api/addrs/ygwNQgE5f15Ygopbs2KPRYMS4TcffqBpsz,ygw5yCtVkx3hREke4L8qDqQtnNoAiPKTSx/utxo\n```\n\nPOST method:\n\n```\n  /insight-api/addrs/utxo\n```\n\nPOST params:\n\n```\naddrs: ygwNQgE5f15Ygopbs2KPRYMS4TcffqBpsz,ygw5yCtVkx3hREke4L8qDqQtnNoAiPKTSx\n```\n\n### InstantSend Transactions\n\nIf a Transaction Lock has been observed by Insight API a 'txlock' value of true will be included in the Transaction Object.\n\nSample output:\n\n```\n{\n\t\"txid\": \"b7ef92d1dce458276f1189e06bf532eff78f9c504101d3d4c0dfdcd9ebbf3879\",\n\t\"version\": 1,\n\t\"locktime\": 133366,\n\t\"vin\": [{ ... }],\n\t\"vout\": [{ ... }],\n\t\"blockhash\": \"0000001ab9a138339fe4505a299525ace8cda3b9bcb258a2e5d93ed7a320bf21\",\n\t\"blockheight\": 133367,\n\t\"confirmations\": 37,\n\t\"time\": 1483985187,\n\t\"blocktime\": 1483985187,\n\t\"valueOut\": 8.998,\n\t\"size\": 226,\n\t\"valueIn\": 8.999,\n\t\"fees\": 0.001,\n\t\"txlock\": true\n}\n```\n\n### Transactions by Block\n\n```\n  /insight-api/txs/?block=HASH\n  /insight-api/txs/?block=000000000814dd7cf470bd835334ea6624ebf0291ea857a5ab37c65592726375\n```\n\n### Transactions by Address\n\n```\n  /insight-api/txs/?address=ADDR\n  /insight-api/txs/?address=yWFfdp9nLUjy1kJczFhRuBMUjtTkTTiyMv\n```\n\n### Transactions for Multiple Addresses\n\nGET method:\n\n```\n  /insight-api/addrs/[:addrs]/txs[?from=&to=]\n  /insight-api/addrs/ygwNQgE5f15Ygopbs2KPRYMS4TcffqBpsz,ygw5yCtVkx3hREke4L8qDqQtnNoAiPKTSx/txs?from=0&to=20\n```\n\nPOST method:\n\n```\n  /insight-api/addrs/txs\n```\n\nPOST params:\n\n```\naddrs: ygwNQgE5f15Ygopbs2KPRYMS4TcffqBpsz,ygw5yCtVkx3hREke4L8qDqQtnNoAiPKTSx\nfrom (optional): 0\nto (optional): 20\nnoAsm (optional): 1 (will omit script asm from results)\nnoScriptSig (optional): 1 (will omit the scriptSig from all inputs)\nnoSpent (option): 1 (will omit spent information per output)\n```\n\nSample output:\n\n```\n{ totalItems: 100,\n  from: 0,\n  to: 20,\n  items:\n    [ { txid: '3e81723d069b12983b2ef694c9782d32fca26cc978de744acbc32c3d3496e915',\n       version: 1,\n       locktime: 0,\n       vin: [Object],\n       vout: [Object],\n       blockhash: '00000000011a135e5277f5493c52c66829792392632b8b65429cf07ad3c47a6c',\n       confirmations: 109367,\n       time: 1393659685,\n       blocktime: 1393659685,\n       valueOut: 0.3453,\n       size: 225,\n       firstSeenTs: undefined,\n       valueIn: 0.3454,\n       fees: 0.0001,\n       txlock: false },\n      { ... },\n      { ... },\n      ...\n      { ... }\n    ]\n}\n```\n\nNote: if pagination params are not specified, the result is an array of transactions.\n\n### Transaction Broadcasting\n\n#### Standard transaction\n\nPOST method:\n\n```\n  /insight-api/tx/send\n```\n\nPOST params:\n\n```\n  rawtx: \"signed transaction as hex string\"\n\n  eg\n\n  rawtx: 01000000017b1eabe0209b1fe794124575ef807057c77ada2138ae4fa8d6c4de0398a14f3f00000000494830450221008949f0cb400094ad2b5eb399d59d01c14d73d8fe6e96df1a7150deb388ab8935022079656090d7f6bac4c9a94e0aad311a4268e082a725f8aeae0573fb12ff866a5f01ffffffff01f0ca052a010000001976a914cbc20a7664f2f69e5355aa427045bc15e7c6c77288ac00000000\n```\n\nPOST response:\n\n```\n  {\n      txid: [:txid]\n  }\n\n  eg\n\n  {\n      txid: \"c7736a0a0046d5a8cc61c8c3c2821d4d7517f5de2bc66a966011aaa79965ffba\"\n  }\n```\n\n#### InstantSend transaction\n\nConditions :\n* Every inputs should have 6 confirmations.\n* Fee are 0.001 per input.\n* Transaction value should be below SPORK_5_INSTANTSEND_MAX_VALUE (see spork route)\n\nPOST method:\n\n```\n  /insight-api/tx/sendix\n```\n\nPOST params:\n\n```\n  rawtx: \"signed transaction as hex string\"\n```\n\nPOST response:\n\n```\n  {\n      txid: [:txid]\n  }\n```\n\n### Sporks List\n\nGET method:\n\n```\n  /insight-api/sporks\n```\n\nSample output:\n\n```\n{\n  \"sporks\": {\n    \"SPORK_2_INSTANTSEND_ENABLED\":0,\n    \"SPORK_3_INSTANTSEND_BLOCK_FILTERING\":0,\n    \"SPORK_5_INSTANTSEND_MAX_VALUE\":2000,\n    \"SPORK_8_MASTERNODE_PAYMENT_ENFORCEMENT\":0,\n    \"SPORK_9_SUPERBLOCKS_ENABLED\":0,\n    \"SPORK_10_MASTERNODE_PAY_UPDATED_NODES\":0,\n    \"SPORK_12_RECONSIDER_BLOCKS\":0,\n    \"SPORK_13_OLD_SUPERBLOCK_FLAG\":4070908800,\n    \"SPORK_14_REQUIRE_SENTINEL_FLAG\":4070908800\n  }\n}\n```\n\n### Proposals Informations\n\nGET method:\n\n```\n  /insight-api/gobject/info\n```\n\nSample output:\n\n```\n{\n  \"result\":{\n    \"governanceminquorum\":1,\n    \"masternodewatchdogmaxseconds\":7200,\n    \"proposalfee\":5,\n    \"superblockcycle\":24,\n    \"lastsuperblock\":79800,\n    \"nextsuperblock\":79824,\n    \"maxgovobjdatasize\":16384\n  },\n  \"error\":null,\n  \"id\":68537\n}\n```\n\n### Proposals Count\n\nGET method:\n\n```\n  /insight-api/gobject/count\n```\n\nSample output:\n\n```\n{\n  \"result\":\"Governance Objects: 47 (Proposals: 7, Triggers: 40, Watchdogs: 0/0, Other: 0; Erased: 0), Votes: 1883\",\n  \"error\":null,\n  \"id\":47025\n}\n```\n\n### Budget Proposal List\n\nGET method:\n\n```\n  /insight-api/gobject/list/proposal (or /insight-api/gobject/list)\n```\n\nSample output:\n\n```\n[\n  {\n    Hash: 'b6af3e70c686f660541a77bc035df2e5e46841020699ce3ec8fad786f7d1aa35',\n    DataObject: {\n      end_epoch: 1513555200,\n      name: 'flare03',\n      payment_address: 'yViyoK3NwfH5GXRo7e4DEYkzzhBjDNQaQG',\n      payment_amount: 5,\n      start_epoch: 1482105600,\n      type: 1,\n      url: 'https://www.dash.org'\n    },\n    AbsoluteYesCount: 40,\n    YesCount: 40,\n    NoCount: 0,\n    AbstainCount: 0\n  }\n]\n```\n\n### Budget Triggers List\n\nGET method:\n\n```\n  /insight-api/gobject/list/trigger\n```\n\nSample output:\n\n```\n[\n  {\n    \"Hash\":\"fa2a7505c52438b2ca3d14def1c2cdcb59d7ccca417920182f04fcb9be968f00\",\n    \"DataObject\":{\"type\":2},\n    \"AbsoluteYesCount\":53,\n    \"YesCount\":53,\n    \"NoCount\":0,\n    \"AbstainCount\":0\n  }\n]\n```\n\n### Budget Proposal Detail\n\nGET method:\n\n```\n  /insight-api/gobject/get/[:hash]\n  /insight-api/gobject/get/b6af3e70c686f660541a77bc035df2e5e46841020699ce3ec8fad786f7d1aa35\n```\n\nSample output:\n\n```\n    [ { Hash: 'b6af3e70c686f660541a77bc035df2e5e46841020699ce3ec8fad786f7d1aa35',\n        CollateralHash: '24a71d8f221659717560365d2914bc7a00f82ffb8f8c68e7fffce5f35aa23b90',\n       \tDataHex: '5b5b2270726f706f73616c222c7b22656e645f65706f6368223a313531333535353230302c226e616d65223a22666c6172653033222c227061796d656e745f61646472657373223a22795669796f4b334e776648354758526f3765344445596b7a7a68426a444e51615147222c227061796d656e745f616d6f756e74223a352c2273746172745f65706f6368223a313438323130353630302c2274797065223a312c2275726c223a2268747470733a2f2f64617368646f742e696f2f702f666c6172653033227d5d5d',\n        DataObject: {\n          end_epoch: 1513555200,\n          name: 'flare03',\n          payment_address: 'yViyoK3NwfH5GXRo7e4DEYkzzhBjDNQaQG',\n          payment_amount: 5,\n          start_epoch: 1482105600,\n          type: 1,\n          url: 'https://www.dash.org'\n        },\n        CreationTime: 1482223714,\n        FundingResult: {\n            AbsoluteYesCount: 40,\n            YesCount: 40,\n            NoCount: 0,\n            AbstainCount: 0\n        },\n        ValidResult: {\n            AbsoluteYesCount: 74,\n            YesCount: 74,\n            NoCount: 0,\n            AbstainCount: 0\n        },\n        DeleteResult: {\n            AbsoluteYesCount: 0,\n            YesCount: 0,\n            NoCount: 0,\n            AbstainCount: 0\n        },\n        EndorsedResult: {\n            AbsoluteYesCount: 0,\n            YesCount: 0,\n            NoCount: 0,\n            AbstainCount: 0\n        } } ]\n```\n\n### Proposal Check\n\nGET method:\n\n```\n  /insight-api/gobject/check/[:hexData]\n  /insight-api/gobject/check/5b5b2270726f706f736[..]\n```\n\nSample output:\n\n```\n    {\"Object status\":\"OK\"}\n```\n\n### Proposal Deserialization\n\nGET method:\n\n```\n  /insight-api/gobject/deserialize/[:hexData]\n  /insight-api/gobject/deserialize/5b5b2270726f706f736[..]\n```\n\nSample output:\n\n```\n{\n  \"result\":\"[[\\\"proposal\\\",{\\\"end_epoch\\\":1519848619,\\\"name\\\":\\\"ghijklmnopqrstuvwxyz01234567891519097947\\\",\\\"payment_address\\\":\\\"yik5HAgVAgjH1oZKjcDfvcf22bwBNbSYzB\\\",\\\"payment_amount\\\":10,\\\"start_epoch\\\":1519097947,\\\"type\\\":1,\\\"url\\\":\\\"https://www.dashcentral.org/p/test_proposal_1519097947\\\"}]]\",\n  \"error\":null,\n  \"id\":78637\n}\n```\n\n### Proposal Current Votes\n\nGET method:\n\n```\n  /insight-api/gobject/votes/current/[:hash]\n  /insight-api/gobject/votes/current/fbda8cdc1f48917f53b7d63fbce81c85d6dedd3d0e476e979926dfd154b84034\n```\n\nSample output:\n\n```\n{\n  \"result\":\"[[\\\"proposal\\\",{\\\"end_epoch\\\":1519848619,\\\"name\\\":\\\"ghijklmnopqrstuvwxyz01234567891519097947\\\",\\\"payment_address\\\":\\\"yik5HAgVAgjH1oZKjcDfvcf22bwBNbSYzB\\\",\\\"payment_amount\\\":10,\\\"start_epoch\\\":1519097947,\\\"type\\\":1,\\\"url\\\":\\\"https://www.dashcentral.org/p/test_proposal_1519097947\\\"}]]\",\n  \"error\":null,\n  \"id\":78637\n}\n```\n\n### Governance Budget\n\nGET method:\n\n```\n  /insight-api/governance/budget/[:blockIndex]\n  /insight-api/governance/budget/79872\n```\n\nSample output:\n\n```\n{\n    \"result\":\"60.00\",\n    \"error\":null,\n    \"id\":75619\n}\n```\n\n### Submit Proposal\n\nPOST method:\n\n```\n  /insight-api/gobject/submit\n```\n\nExample input:\n\n```\n{\n  \"parentHash\":\"abc\",\n  \"revision\":1,\n  \"time\":10009,\n  \"dataHex\":\"abc\",\n  \"feeTxId\":\"abc\"\n}\n```\n\nSample output:\n\n```\n{\n    \"result\":\"60.00\",\n    \"error\":null,\n    \"id\":75619\n}\n```\n\n### Masternodes List\n\n```\n  deprecated until full support for v0.13 deterministic masternode list\n```\n\n### Validate Masternode\n\n```\n  deprecated until full support for v0.13 deterministic masternode list\n```\n\n### Historic Blockchain Data Sync Status\n\n```\n  /insight-api/sync\n```\n\n### Live Network P2P Data Sync Status\n\n```\n  /insight-api/peer\n```\n\n### Status of the Dash Network\n\n```\n  /insight-api/status?q=xxx\n```\n\nWhere \"xxx\" can be:\n\n * getInfo\n * getDifficulty\n * getBestBlockHash\n * getBestChainLock\n * getLastBlockHash\n\n### Utility Methods\n\n```\n  /insight-api/utils/estimatefee[?nbBlocks=2]\n```\n\n## Web Socket API\n\nThe web socket API is served using [socket.io](http://socket.io).\n\nThe following are the events published by Insight:\n\n`tx`: new transaction received from network, txlock boolean is set true if a matching txlock event has been observed. This event is published in the 'inv' room. Data will be a app/models/Transaction object.\n\nSample output:\n\n```\n{\n  \"txid\":\"00c1b1acb310b87085c7deaaeba478cef5dc9519fab87a4d943ecbb39bd5b053\",\n  \"txlock\": false,\n  \"processed\":false\n  ...\n}\n```\n\n`txlock`: InstantSend transaction received from network, this event is published alongside the 'tx' event when a transaction lock event occurs. Data will be a app/models/Transaction object.\nSample output:\n\n```\n{\n  \"txid\":\"00c1b1acb310b87085c7deaaeba478cef5dc9519fab87a4d943ecbb39bd5b053\",\n  \"processed\":false\n  ...\n}\n```\n\n`block`: new block received from network. This event is published in the `inv` room. Data will be a app/models/Block object.\nSample output:\n\n```\n{\n  \"hash\":\"000000004a3d187c430cd6a5e988aca3b19e1f1d1727a50dead6c8ac26899b96\",\n  \"time\":1389789343,\n  ...\n}\n```\n\n`<dashAddress>`: new transaction concerning <dashAddress> received from network. This event is published in the `<dashAddress>` room.\n\n`status`: every 1% increment on the sync task, this event will be triggered. This event is published in the `sync` room.\n\nSample output:\n\n```\n{\n  blocksToSync: 164141,\n  syncedBlocks: 475,\n  upToExisting: true,\n  scanningBackward: true,\n  isEndGenesis: true,\n  end: \"000000000933ea01ad0ee984209779baaec3ced90fa3f408719526f8d77f4943\",\n  isStartGenesis: false,\n  start: \"000000009f929800556a8f3cfdbe57c187f2f679e351b12f7011bfc276c41b6d\"\n}\n```\n\n### Example Usage\n\nThe following html page connects to the socket.io insight API and listens for new transactions.\n\n```html\n<html>\n<body>\n  <script src=\"http://<insight-server>:<port>/socket.io/socket.io.js\"></script>\n  <script>\n    eventToListenTo = 'tx'\n    room = 'inv'\n\n    var socket = io(\"http://<insight-server>:<port>/\");\n    socket.on('connect', function() {\n      // Join the room.\n      socket.emit('subscribe', room);\n    })\n    socket.on(eventToListenTo, function(data) {\n      if (data.txlock) {\n        console.log(\"New InstantSend transaction received: \" + data.txid)\n      } else {\n        console.log(\"New transaction received: \" + data.txid)\n      }\n    })\n  </script>\n</body>\n</html>\n```\n\n## Notes on Upgrading from v0.3\n\nThe unspent outputs format now has `satoshis` and `height`:\n\n```\n[\n  {\n    \"address\":\"mo9ncXisMeAoXwqcV5EWuyncbmCcQN4rVs\",\n    \"txid\":\"d5f8a96faccf79d4c087fa217627bb1120e83f8ea1a7d84b1de4277ead9bbac1\",\n    \"vout\":0,\n    \"scriptPubKey\":\"76a91453c0307d6851aa0ce7825ba883c6bd9ad242b48688ac\",\n    \"amount\":0.000006,\n    \"satoshis\":600,\n    \"confirmations\":0,\n    \"ts\":1461349425\n  },\n  {\n    \"address\": \"mo9ncXisMeAoXwqcV5EWuyncbmCcQN4rVs\",\n    \"txid\": \"bc9df3b92120feaee4edc80963d8ed59d6a78ea0defef3ec3cb374f2015bfc6e\",\n    \"vout\": 1,\n    \"scriptPubKey\": \"76a91453c0307d6851aa0ce7825ba883c6bd9ad242b48688ac\",\n    \"amount\": 0.12345678,\n    \"satoshis: 12345678,\n    \"confirmations\": 1,\n    \"height\": 300001\n  }\n]\n```\n\nThe `timestamp` property will only be set for unconfirmed transactions and `height` can be used for determining block order. The `confirmationsFromCache` is nolonger set or necessary, confirmation count is only cached for the time between blocks.\n\nThere is a new `GET` endpoint or raw blocks at `/rawblock/<blockHash>`:\n\nResponse format:\n\n```\n{\n  \"rawblock\": \"blockhexstring...\"\n}\n```\n\nThere are a few changes to the `GET` endpoint for `/addr/[:address]`:\n\n- The list of txids in an address summary does not include orphaned transactions\n- The txids will be sorted in block order\n- The list of txids will be limited at 1000 txids\n- There are two new query options \"from\" and \"to\" for pagination of the txids (e.g. `/addr/[:address]?from=1000&to=2000`)\n\nSome additional general notes:\n- The transaction history for an address will be sorted in block order\n- The response for the `/sync` endpoint does not include `startTs` and `endTs` as the sync is no longer relevant as indexes are built in dashd.\n- The endpoint for `/peer` is no longer relevant connection to dashd is via ZMQ.\n- `/tx` endpoint results will now include block height, and spentTx related fields will be set to `null` if unspent.\n- `/block` endpoint results does not include `confirmations` and will include `poolInfo`.\n\n## Notes on Upgrading from v0.2\n\nSome of the fields and methods are not supported:\n\nThe `/tx/<txid>` endpoint JSON response will not include the following fields on the \"vin\"\nobject:\n- `doubleSpentTxId` // double spends are not currently tracked\n- `isConfirmed` // confirmation of the previous output\n- `confirmations` // confirmations of the previous output\n- `unconfirmedInput`\n\nThe `/tx/<txid>` endpoint JSON response will not include the following fields on the \"vout\"\nobject.\n- `spentTs`\n\nThe `/status?q=getTxOutSetInfo` method has also been removed due to the query being very slow and locking dashd.\n\nPlug-in support for Insight API is also no longer available, as well as the endpoints:\n- `/email/retrieve`\n- `/rates/:code`\n\nCaching support has not yet been added in the v0.3 upgrade.\n\n## Resources\n\n- (Medium)[How to setup a Dash Instant-Send Transaction using Insight API - The comprehensive way](https://medium.com/@obusco/setup-instant-send-transaction-the-comprehensive-way-a80a8a0572e)\n\n## Contributing\n\nFeel free to dive in! [Open an issue](https://github.com/dashevo/insight-api/issues/new) or submit PRs.\n\n## License\n\n[MIT](LICENSE) &copy; Dash Core Group, Inc.\n", "release_dates": ["2023-08-14T09:58:11Z", "2023-08-14T07:43:55Z", "2023-07-12T18:03:15Z", "2023-03-26T06:07:45Z", "2023-03-24T04:21:52Z", "2022-10-11T21:22:45Z", "2022-09-20T07:27:59Z", "2022-09-19T14:28:44Z", "2021-06-30T09:31:51Z", "2020-12-15T12:44:02Z", "2020-12-15T08:17:11Z", "2020-10-22T03:11:25Z", "2019-03-25T13:26:43Z", "2019-01-28T10:02:51Z", "2019-01-21T16:11:41Z"]}, {"name": "insight-ui", "description": "A Dash blockchain web browser user interface", "language": "JavaScript", "license": null, "readme": "# Insight UI\n\nA Dash blockchain explorer web application service for [Dashcore Node](https://github.com/dashevo/dashcore-node) using [Insight API](https://github.com/dashevo/insight-api).\n\n## Quick Start\n\nPlease see the guide at [https://bitcore.io/guides/full-node](https://bitcore.io/guides/full-node) for information about getting a block explorer running. This is only the front-end component of the block explorer, and is packaged together with all of the necessary components in [Dashcore](https://github.com/dashevo/dashcore).\n\n## Getting Started\n\nTo manually install all of the necessary components, you can run these commands:\n\n```bash\nnpm install -g @dashevo/dashcore-node\ndashcore-node create mynode\ncd mynode\ndashcore-node install @dashevo/insight-api\ndashcore-node install @dashevo/insight-ui\ndashcore-node start\n```\n\nOpen a web browser to `http://localhost:3001/insight/`\n\n## Development\n\nTo run Insight UI Dash locally in development mode:\n\nInstall dependencies:\n\n```\n$ npm install\n```\n\nTo download bower dependencies, compile and minify the web application's assets:\n\n```\n$ npm run build\n```\n\nThere is a convenient Gruntfile.js for automation during editing the code\n\n```\n$ npm run watch\n```\n\n## Multilanguage support\n\nInsight UI Dash uses [angular-gettext](http://angular-gettext.rocketeer.be) for multilanguage support.\n\nTo enable a text to be translated, add the ***translate*** directive to html tags. See more details [here](http://angular-gettext.rocketeer.be/dev-guide/annotate/). Then, run:\n\n```\nnpm run build\n```\n\nThis action will create a template.pot file in ***po/*** folder. You can open it with some PO editor ([Poedit](http://poedit.net)). Read this [guide](http://angular-gettext.rocketeer.be/dev-guide/translate/) to learn how to edit/update/import PO files from a generated POT file. PO file will be generated inside po/ folder.\n\nIf you make new changes, simply run **grunt compile** again to generate a new .pot template and the angular javascript ***js/translations.js***. Then (if use Poedit), open .po file and choose ***update from POT File*** from **Catalog** menu.\n\nFinally changes your default language from ***public/src/js/config***\n\n```\ngettextCatalog.currentLanguage = 'es';\n```\n\nThis line will take a look at any *.po files inside ***po/*** folder, e.g.\n**po/es.po**, **po/nl.po**. After any change do not forget to run ***grunt\ncompile***.\n\n\n## Note\n\nFor more details about the [Insight API](https://github.com/dashevo/insight-api) configuration and end-points, go to [Insight API GitHub repository](https://github.com/dashevo/insight-api).\n\n## Contribute\n\nContributions and suggestions are welcomed at the [Insight UI Dash GitHub repository](https://github.com/dashevo/insight-ui).\n\n\n## License\n(The MIT License)\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n'Software'), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n", "release_dates": ["2023-08-14T10:28:46Z", "2023-08-14T08:05:53Z", "2023-07-13T08:19:10Z", "2023-03-27T05:20:30Z", "2023-03-24T05:14:17Z", "2022-10-11T21:25:35Z", "2022-09-21T14:19:15Z", "2022-09-21T13:04:34Z", "2021-08-23T17:08:53Z", "2021-05-31T11:48:15Z", "2020-12-15T08:59:44Z", "2020-10-26T12:04:06Z", "2020-05-11T14:19:59Z", "2019-01-29T13:45:14Z"]}, {"name": "js-abci", "description": "Javascript ABCI libraries", "language": "JavaScript", "license": null, "readme": "# js-abci\n\nABCI server for Node.js. Supports Tenderdash 0.34+\n\n## Usage\n\n`npm install @dashevo/abci`\n\nRequires Node.js v10.9+\n\n```js\nlet createServer = require('abci')\n\nlet server = createServer({\n  info (request) {\n    console.log('got info request', request)\n    return { ... }\n  }\n\n  // implement any ABCI method handlers here\n})\n\nprocess.on('SIGTERM', async () => {\n  await server.close();\n\n  // Gracefull shutdown\n\n  process.exit(0);\n});\n\nserver.on('connection', (socket) => {\n  console.log(`Accepted new ABCI connection #${socket.connection.id} from ${socket.remoteAddress}:${socket.remotePort}`);\n\n  socket.on('error', (e) => {\n    console.error(`ABCI connection #${socket.connection.id} error`);\n  });\n\n  socket.once('close', (hasError) => {\n    let message = `ABCI connection #${socket.connection.id} is closed`;\n    if (hasError) {\n      message += ' with error';\n    }\n\n    console.log(message);\n  });\n});\n\nserver.once('close', () => {\n  console.log('ABCI server is closed');\n});\n\nserver.on('error', async (e) => {\n  console.error(e);\n  \n  // Graceful shutdown\n  \n  process.exit(1);\n});\n\nserver.on('listening', () => {\n  console.log(`ABCI server is waiting for connections`);\n});\n\nserver.listen(26658)\n\n```\n\n### `let server = createServer(app)`\n\nReturns a [`net.Server`](https://nodejs.org/api/net.html#net_class_net_server) that accepts ABCI connections from a Tendermint node.\n\n`app` should be an object with ABCI method handler functions. Each handler receives one `request` argument, and can return the response value or a `Promise` which resolves to the response value. `cb` responds to the ABCI request with either the error or `response` value.\n\nSupported ABCI methods are:\n\n```\necho\nflush\ninfo\nsetOption\ninitChain\nquery\nbeginBlock\ncheckTx\ndeliverTx\nendBlock\ncommit\n```\n", "release_dates": ["2022-07-18T12:59:44Z", "2022-05-17T13:27:52Z", "2021-10-14T11:07:38Z", "2021-09-26T10:31:34Z", "2021-08-17T12:53:58Z", "2021-07-14T16:58:14Z", "2021-06-08T15:47:10Z", "2021-02-16T10:09:59Z", "2021-02-16T04:41:37Z", "2021-02-16T02:49:25Z", "2021-02-15T16:55:07Z", "2021-02-15T16:44:16Z", "2021-02-04T15:10:35Z", "2020-12-30T07:59:45Z", "2020-12-21T11:44:35Z", "2020-12-14T08:15:48Z"]}, {"name": "js-dashd-zmq", "description": "JS implementation of a ZMQClient for dashd", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Dashd ZMQ\n\n[![NPM Version](https://img.shields.io/npm/v/@dashevo/dashd-zmq)](https://www.npmjs.com/package/@dashevo/dashd-zmq)\n[![Build Status](https://github.com/dashevo/dashd-zmq/actions/workflows/test_and_release.yml/badge.svg)](https://github.com/dashevo/dashd-zmq/actions/workflows/test_and_release.yml)\n[![Release Date](https://img.shields.io/github/release-date/dashevo/js-dashd-zmq)](https://github.com/dashevo/js-dashd-zmq/releases/latest)\n[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen)](https://github.com/RichardLitt/standard-readme)\n\nDash Client Library to connect and subscribe to Dash Core (dashd)'s ZMQ topics\n\n## Table of Contents\n\n- [Install](#install)\n- [Usage](#usage)\n- [Maintainers](#maintainers)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Install\n\n```sh\nnpm install @dashevo/dashd-zmq\n```\n\n## Usage\n\n```sh\nnpm start\n```\n\n## Documentation\n\nYou can see some [Examples here](https://dashevo.github.io/js-dashd-zmq/#/usage/examples).\n\nMore [extensive documentation is available here](https://dashevo.github.io/js-dashd-zmq).\n\n## Maintainers\n\nWallet-Lib is maintained by the [Dash Core Developers](https://www.github.com/dashevo).\nWe want to thank all members of the community that have submitted suggestions, issues and pull requests.\n\n## Contributing\n\nFeel free to dive in! [Open an issue](https://github.com/dashevo/js-dashd-zmq/issues/new) or submit PRs.\n\n## License\n\n[MIT](LICENSE) &copy; Dash Core Group, Inc.\n", "release_dates": ["2021-09-26T10:43:36Z", "2020-12-15T12:12:09Z", "2020-12-10T15:34:47Z", "2020-09-30T21:41:52Z"]}, {"name": "js-dp-services-ctl", "description": "Control Dash Platform services using JavaScript and Docker", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Dash Platform services ctl\n\n[![Build Status](https://travis-ci.com/dashevo/js-dp-services-ctl.svg?branch=master)](https://travis-ci.com/dashevo/js-dp-services-ctl)\n[![NPM version](https://img.shields.io/npm/v/@dashevo/dp-services-ctl.svg)](https://npmjs.org/package/@dashevo/dp-services-ctl)\n\n> Control Dash Platform services using JavaScript and Docker\n\nThe tool provides a convenient JavaScript interface for configuration and interaction with Dash Platform services. Services are started in Docker containers.\n\n## Table of Contents\n\n- [Installation](#installation)\n- [Usage](#usage)\n    - [Available DP services](#available-dp-services)\n    - [Services configuration](#services-configuration)\n    - [Integration with Mocha](#integration-with-mocha)\n- [Maintainers](#maintainers)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Installation\n\n1. [Install Docker](https://docs.docker.com/install/)\n2. Install NPM package:\n\n    ```sh\n    npm install @dashevo/dp-services-ctl\n    ```\n\n## Usage\n\n### Available DP services\n\n#### Drive\n\n[Drive](https://github.com/dashevo/drive) service starts a bunch of related services:\n- DriveAbci\n    - [Methods](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/drive/abci/DriveAbci.js)\n    - [Options](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/drive/abci/DriveAbciOptions.js)\n- [MongoDB](#mongodb)\n- [Dash Core](#dash-core)\n\n#### DAPI\n\n[DAPI](https://github.com/dashevo/dapi) service starts all DP services:\n- DAPI Core\n    - [Methods](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/dapi/core/DapiCore.js)\n    - [Options](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/dapi/core/DapiCoreOptions.js)\n- DAPI TxFilterStream\n    - [Methods](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/dapi/txFilterStream/DapiTxFilterStream.js)\n    - [Options](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/dapi/txFilterStream/DapiTxFilterStreamOptions.js)\n- [Drive](#drive)\n- [MongoDB](#mongodb)\n- [DashCore](#dash-core)\n- [Insight](#insight)\n- [Tendermint Core](#tendermint-core)\n\n#### Dash Core\n\n- [Dash Core](https://github.com/dashpay/dash) service\n    - [Methods](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/dashCore/DashCore.js)\n    - [Options](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/dashCore/DashCoreOptions.js)\n\n#### Tendermint Core\n\n- [Tendermint Core](https://tendermint.com) service\n    - [Methods](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/tendermintCore/TendermintCore.js)\n    - [Options](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/tendermintCore/TendermintCoreOptions.js)\n\n#### Insight API\n\n- [Insight API](https://github.com/dashevo/insight-api) service\n    - [Methods](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/insightApi/InsightApi.js)\n    - [Options](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/insightApi/InsightApiOptions.js)\n\n#### MongoDB\n\n- [MongoDB](https://www.mongodb.com/) service\n    - [Methods](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/mongoDb/MongoDb.js)\n    - [Options](https://github.com/dashevo/js-dp-services-ctl/blob/master/lib/services/mongoDb/MongoDbOptions.js)\n\n### Starting a service\n\n```js\n// Export service(s)\nconst { startMongoDb } = require('@dashevo/dp-services-ctl');\n// This is optional. Default options listed in options class\nconst options = {\n  port: 27017, // mongoDB port\n};\n\n// Start service\nconst mongo = await startMongoDb(options);\n\n// Get mongo client\nconst client = await mongo.getClient();\n\n// Stop mongoDB\nawait mongo.remove();\n```\n\nUse `many` method to start several instances:\n\n```js\nconst { startMongoDb } = require('@dashevo/dp-services-ctl');\n\n// This is optional. Default options listed in options class\nconst options = {\n  port: 27017, // mongoDB port\n};\n\n// Start two services\nconst mongoNodes = await startMongoDb.many(2,options);\n\n// Get peer IDs\nconst [client1, client2] = await Promise.all(\n  mongoNodes.map(mongo => mongo.getClient()),\n);\n\n// Stop mongoDB nodes\nawait Promise.all(\n  mongoNodes.map(mongo => mongo.remove()),\n);\n```\n\n### Services configuration\n\nEach service has default options which can be overwritten in three ways:\n1. Pass options as plain JS object to `start[service]` or `create[service]` methods\n2. Pass instance of options class to `start[service]` or `create[service]` methods\n3. Pass default options as plain JS object to `setDefaultCustomOptions` method of options class\n\n### Integration with Mocha\n\nServices [Mocha](https://mochajs.org/) hooks provide automation for your mocha tests:\n- Removing obsolete related Docker containers (`before`)\n- Cleaning a service state between tests (`beforeEach`, `afterEach`)\n- Stopping service after tests (`after`)\n\n```js\n// Export service(s) with mocha hooks\nconst { mocha: { startMongoDb } } = require('@dashevo/dp-services-ctl');\n\ndescribe('Test suite', () => {\n  let mongoClient;\n\n  startMongoDb().then(mongo => () => {\n    mongoClient = mongo.getClient();\n  });\n\n  it('should do something', async () => {\n    const collection = mongoClient.db('test').collection('syncState');\n    const count = await collection.countDocuments({});\n\n    expect(count).to.equal(0);\n  });\n});\n```\n\n## Maintainers\n\n[@shumkov](https://github.com/shumkov)\n\n[@jawid-h](https://github.com/jawid-h)\n\n[@abvgedeika](https://github.com/abvgedeika)\n\n## Contributing\n\nFeel free to dive in! [Open an issue](https://github.com/dashevo/js-dp-services-ctl/issues/new) or submit PRs.\n\n## License\n\n[MIT](LICENSE) &copy; Dash Core Group, Inc.\n", "release_dates": ["2023-07-13T05:21:25Z", "2022-09-21T11:29:11Z", "2021-03-23T09:40:18Z", "2020-07-23T13:01:03Z", "2020-06-09T16:37:40Z", "2020-06-09T08:01:52Z", "2020-06-08T19:58:21Z", "2020-04-20T14:05:53Z", "2020-04-02T17:02:44Z", "2020-03-12T21:22:18Z", "2020-02-14T07:57:05Z", "2020-02-13T15:37:04Z"]}, {"name": "JSONSchemaValidation", "description": "JSON Schema draft 4, 6 and 7 parsing and validation library written in Objective-C.", "language": "Objective-C", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# DSJSONSchemaValidation\n\n**JSON Schema draft 4, draft 6 and draft 7 parsing and validation library written in Objective-C.**\n\n[![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage) [![CocoaPods](https://img.shields.io/cocoapods/v/DSJSONSchemaValidation.svg?maxAge=604800)]() [![CocoaPods](https://img.shields.io/cocoapods/p/DSJSONSchemaValidation.svg?maxAge=2592000)]() [![CocoaPods](https://img.shields.io/cocoapods/l/DSJSONSchemaValidation.svg?maxAge=2592000)]()\n\n`DSJSONSchemaValidation` is a library that provides a set of classes for parsing [JSON Schema](http://json-schema.org/documentation.html) documents into native Objective-C objects and subsequently using them to validate JSON documents.\n\nThe main feature of the library is an ability to \"compile\" the schema into a network of objects that describe that schema, so that it could be cached and reused for validation of multiple JSON documents in a performant manner, similar to the way `NSRegularExpression` and `NSDateFormatter` classes are used. One of the possible use cases of this library could be early validation of JSON response received from a web service, based on expectations described within the app in a form of JSON Schema.\n\n`DSJSONSchemaValidation` supports all validation keywords of JSON Schema draft 4, 6 and 7. It is also possible to extend the functionality of the library by defining custom keywords to be used with specific metaschema URIs and custom formats for the `format` validation keyword. Note that JSON Schema draft 3 is not supported at the moment. There are also a few important limitations, including usage of external schema references, listed under [Caveats and limitations](#caveats-and-limitations).\n\nBased on https://github.com/vlas-voloshin/JSONSchemaValidation\n\n## Requirements\n\n`DSJSONSchemaValidation` currently supports building in Xcode 7.0 or later with ARC enabled. Minimum supported target platform versions are iOS 7.0, tvOS 9.0 and OS X 10.9. Library can be linked to Objective-C and Swift targets.\n\n## Installation\n\n### Carthage\n\n1. Add the following line to your `Cartfile`:\n\n    ```\n    github \"dashevo/JSONSchemaValidation\"\n    ```\n    \n2. Follow the instructions outlined in [Carthage documentation](https://github.com/Carthage/Carthage/blob/master/README.md) to build and integrate the library into your app.\n3. Import library header in your source files:\n\t* Objective-C: `#import <DSJSONSchemaValidation/DSJSONSchemaValidation.h>`\n\t* Swift: `import DSJSONSchemaValidation`\n\n### CocoaPods\n\n1. Add the following line to your `Podfile`:\n\n\t```\n\tpod 'DSJSONSchemaValidation'\n\t```\n\t\n2. Import library header in your source files:\n\t* Objective-C: `#import <DSJSONSchemaValidation/DSJSONSchema.h>`\n\t* Swift: `import DSJSONSchemaValidation`\n\n### Framework (iOS 8.0+, tvOS and OS X)\n\n1. Download and copy the repository source files into your project, or add it as a submodule to your git repository.\n2. Drag&drop `DSJSONSchemaValidation.xcodeproj` into your project or workspace in Xcode.\n3. In \"General\" tab of Project Settings \u2192 `Your Target`, you might find that Xcode has added a missing framework item in \"Embedded Binaries\". Delete it for now.\n4. Still in \"General\" tab, add `DSJSONSchemaValidation.framework` from `DSJSONSchemaValidation-iOS`, `DSJSONSchemaValidation-tvOS` or `DSJSONSchemaValidation-OSX` target (depending on your target platform) to \"Embedded Binaries\". This should also add it to \"Linked Frameworks and Libraries\". \n5. Import library header in your source files:\n\t* Objective-C: `#import <DSJSONSchemaValidation/DSJSONSchemaValidation.h>`\n\t* Swift: `import DSJSONSchemaValidation`\n\n### Static library (iOS)\n\n1. Download and copy the repository source files into your project, or add it as a submodule to your git repository.\n2. Drag&drop `DSJSONSchemaValidation.xcodeproj` into your project or workspace in Xcode.\n3. In \"General\" section of Project Settings \u2192 `Your Target`, you might find that Xcode has added a missing framework item in \"Embedded Binaries\". Delete it for now.\n4. Still in \"General\" tab, add `libDSJSONSchemaValidation.a` to \"Linked Frameworks and Libraries\".\n5. Add project path to `Your Target` \u2192 Build Settings \u2192 Header Search Paths (e.g. `\"$(SRCROOT)/MyAwesomeProject/Vendor/DSJSONSchemaValidation/\"`).\n6. Add `-ObjC` flag to `Your Target` \u2192 Build Settings \u2192 Other Linker Flags to ensure that categories defined in the static library are loaded.\n7. Import library header in your source files:\n\t* Objective-C: `#import <DSJSONSchemaValidation/DSJSONSchema.h>`\n\t* Swift: `import DSJSONSchemaValidation`\n\n### Source files\n\n1. Download and copy the repository source files into your project, or add it as a submodule to your git repository.\n2. Add the contents of `DSJSONSchemaValidation` directory into your project in Xcode.\n3. Import library header: `#import \"DSJSONSchema.h\"`.\n\n## Usage\n\nAfter importing the library header/module, use `DSJSONSchema` class to construct schema objects from `NSData` instances:\n\n``` objective-c\nNSData *schemaData = [NSData dataWithContentsOfURL:mySchemaURL];\nNSError *error = nil;\nDSJSONSchema *schema = [DSJSONSchema schemaWithData:schemaData baseURI:nil referenceStorage:nil specification:[DSJSONSchemaSpecification draft4] error:&error];\n```\n``` swift\nif let schemaData = NSData(contentsOfURL: mySchemaURL) {\n    let schema = try? DSJSONSchema(data: schemaData, baseURI: nil, referenceStorage: nil, specification:DSJSONSchemaSpecification.draft4())\n}\n```\n\nor from parsed JSON instances:\n\n``` objective-c\nNSData *schemaData = [NSData dataWithContentsOfURL:mySchemaURL];\n// note that this object might be not an NSDictionary if schema JSON is invalid\nNSDictionary *schemaJSON = [NSJSONSerialization JSONObjectWithData:schemaData options:0 error:NULL];\nNSError *error = nil;\nDSJSONSchema *schema = [DSJSONSchema schemaWithObject:schemaJSON baseURI:nil referenceStorage:nil specification:[DSJSONSchemaSpecification draft4] error:&error];\n```\n``` swift\nif let schemaData = NSData(contentsOfURL: mySchemaURL),\n    schemaJSON = try? NSJSONSerialization.JSONObjectWithData(schemaData, options: [ ]),\n    schemaDictionary = schemaJSON as? [String : AnyObject] {\n    let schema = try? DSJSONSchema(object: schemaDictionary, baseURI: nil, referenceStorage: nil, specification: DSJSONSchemaSpecification.draft4())\n}\n```\n\nOptional `baseURI` parameter specifies the base scope resolution URI of the constructed schema. Default scope resolution URI is empty.\nOptional `referenceStorage` parameter specifies a `DSJSONSchemaStorage` object that should contain \"remote\" schemas referenced in the instantiated schema. See [Schema storage and external references](#schema-storage-and-external-references) for more details.\n\nAfter constructing a schema object, you can use it to validate JSON instances. Again, these instances could be provided either as `NSData` objects:\n\n``` objective-c\nNSData *jsonData = [NSData dataWithContentsOfURL:myJSONURL];\nNSError *validationError = nil;\nBOOL success = [schema validateObjectWithData:jsonData error:&validationError];\n```\n``` swift\nif let jsonData = NSData(contentsOfURL: myJSONURL) {\n    do {\n        try schema.validateObjectWithData(jsonData)\n        // Success\n    } catch let validationError as NSError {\n        // Failure\n    }\n}\n```\n\nor parsed JSON instances:\n\n``` objective-c\nNSData *jsonData = [NSData dataWithContentsOfURL:myJSONURL];\nid json = [NSJSONSerialization JSONObjectWithData:jsonData options:0 error:NULL];\nNSError *validationError = nil;\nBOOL success = [schema validateObject:json error:&validationError];\n```\n``` swift\nif let jsonData = NSData(contentsOfURL: myJSONURL),\n    json = try? NSJSONSerialization.JSONObjectWithData(jsonData, options: [ ]) {\n    do {\n        try schema.validateObject(json)\n        // Success\n    } catch let validationError as NSError {\n        // Failure\n    }\n}\n```\nIn case of a validation failure, the `NSError` object will contain the following keys in its `userInfo` dictionary:\n\n* `DSJSONSchemaErrorFailingObjectKey` (`object`) \u2013 contains a JSON representation of the object which failed validation.\n* `DSJSONSchemaErrorFailingValidatorKey` (`validator`) \u2013 references the failed validator object. Its description contains its class and validation parameters.\n* `DSJSONSchemaErrorFailingObjectPathKey` (`path`) \u2013 contains the full path to the failed object in a form of JSON Pointer. An empty path means that the root-level object failed validation.\n\n### Schema storage and external references\n\nResolving external schema references from network locations is deliberately not supported by `DSJSONSchema`. However, these external references can be provided using `DSJSONSchemaStorage` class. For example, if Schema A references Schema B at `http://awesome.org/myHandySchema.json`, the latter can be downloaded in advance and provided during instantiation of Schema A:\n\n``` objective-c\n// obviously, in a real application, data from a website must not be loaded synchronously like this\nNSURL *schemaBURL = [NSURL URLWithString:@\"http://awesome.org/myHandySchema.json\"];\nNSData *schemaBData = [NSData dataWithContentsOfURL:schemaBURL];\nDSJSONSchema *schemaB = [DSJSONSchema schemaWithData:schemaBData baseURI:schemaBURL referenceStorage:nil specification:[DSJSONSchemaSpecification draft4] error:NULL];\nDSJSONSchemaStorage *referenceStorage = [DSJSONSchemaStorage storageWithSchema:schemaB];\n\n// ... retrieve schemaAData ...\n\nDSJSONSchema *schemaA = [DSJSONSchema schemaWithData:schemaAData baseURI:nil referenceStorage:referenceStorage specification:[DSJSONSchemaSpecification draft4] error:NULL];\n```\n\n`DSJSONSchemaStorage` objects can also be used in general to store schemas and retrieve them by their scope URI. Please refer to the documentation of that class in the source code for more information.\n\n## Performance\n\nNote that constructing a `DSJSONSchema` object from a JSON representation incurs some computational cost in case of complex schemas. For this reason, if a single schema is expected to be used for validation multiple times, make sure you cache and reuse the corresponding `DSJSONSchema` object.\n\nOn iPhone 5s, `DSJSONSchema` shows the following performance when instantiating and validating against a medium-complexity schema (see [advanced-example.json](DSJSONSchemaValidationTests/JSON/advanced-example.json)):\n\n| Operation                  | Minimum | Average | Maximum |\n|----------------------------|---------|---------|---------|\n| Instantiation + validation | 4 ms    | 15 ms   | 24 ms   |\n| Instantiation only         | 3 ms    | 12 ms   | 20 ms   |\n| Validation only            | 1.2 ms  | 3.5 ms  | 5.8 ms  |\n\nProject uses a major part of [JSON Schema Test Suite](https://github.com/json-schema/JSON-Schema-Test-Suite) to test its functionality. Running this suite on 2.3 GHz Intel Core i7 processor shows the following performance:\n\n| Operation                   | Time    |\n|-----------------------------|---------|\n| Single suite instantiation  | 16.2 ms |\n| Average suite instantiation | 10.9 ms |\n| First suite validation      | 3.69 ms |\n| Average suite validation    | 3.44 ms |\n\n## Extending\n\nUsing `+[DSJSONSchema registerValidatorClass:forMetaschemaURI:withError:]` method, custom JSON Schema keywords can be registered for the specified custom metaschema URI that must be present in the `$schema` property of the instantiated root schemas. Schema keywords are validated using objects conforming to `DSJSONSchemaValidator` protocol. Please refer to `DSJSONSchema` class documentation in the source code for more information.\n\nUsing `+[DSJSONSchemaFormatValidator registerFormat:withRegularExpression:error:]` and `+[DSJSONSchemaFormatValidator registerFormat:withBlock:error:]` methods, custom format names can be registered to be used in the built-in `format` keyword validator class to validate custom formats without the need to modify library code. Please refer to `DSJSONSchemaFormatValidator` class documentation in the source code for more information.\n\n## Thread safety\n\n`DSJSONSchema` and all objects it is composed of are immutable after being constructed and thus thread-safe, so a single schema can be used to validate multiple JSON documents in parallel threads. It is also possible to construct multiple `DSJSONSchema` instances in separate threads, as long as no thread attempts to register additional schema keywords in the process.\n\n## Caveats and limitations\n\n- Regular expression patterns are validated using `NSRegularExpression`, which uses ICU implementation, not ECMA 262. Thus, some features like look-behind are not supported.\n- Loading schema references from external locations is not supported. See [Schema storage and external references](#schema-storage-and-external-references) for more details.\n- Schema keywords defined inside a schema reference (object with \"$ref\" property) are ignored as per [JSON Reference specification draft](https://tools.ietf.org/html/draft-pbryan-zyp-json-ref-03).\n- Validation of following formats is not supported: `\"uri-template\"`, `\"json-pointer\"`, `\"idn-email\"`, `\"idn-hostname\"`, `\"iri\"`, `\"iri-reference\"`, `\"relative-json-pointer\"`. But they can be used as described in [Extending](##Extending) section\n\n## License\n\n`DSJSONSchemaValidation` is available under the MIT license. See the LICENSE file for more info.\n", "release_dates": []}, {"name": "keepkey-firmware", "description": "KeepKey Device Firmware", "language": "C", "license": null, "readme": "## KeepKey Build Procedure for Ubuntu 14.04\n\n### Toolchain Installation\n\nUpdate \"apt-get\"\n```\n$ sudo apt-get update\n```\nRemove gdb package. It causes error during gdb-arm-none-eabi toolchain installation\n```\n$ sudo apt-get remove gdb\n```\nInstall supporting packages for build\n```\n$ sudo apt-get install git scons gcc-arm-none-eabi python-protobuf protobuf-compiler fabric exuberant-ctags gdb-arm-none-eabi default-jre\n```\n\nDownload firmware source code from KeepKey respository (https://github.com/keepkey/keepkey-firmware.git)\n```\n$ git clone git@github.com:keepkey/keepkey-firmware.git\n```\n\n### command line build\n\nFirst build libopencm3. Change to firmware directory and start make\n```\n$ pushd libopencm3 && make && popd\n```\nBuild final bootloader image. Change to firmware directory and run following command\n```\n$ ./b -b bldr -mp\n```\n\nBuild final application image. Change to firmware directory and run following command\n```\n$ ./b -b app \n```\nThe resultant binaries will be located in ./build/arm-none-gnu-eabi/release/bin directory.\n", "release_dates": []}, {"name": "keyhunter", "description": "A tool to recover lost bitcoin private keys from dead harddrives.", "language": null, "license": null, "readme": "keyhunter\n=========\n\nA tool to recover lost bitcoin private keys from dead harddrives.\n\nchmod +x keyhunter.py\n\n./keyhunter.py /dev/sdc\n\noutput should list found private keys in base58 key import format.\n\nbitcoind importprivkey 5K????????????? yay\n\nbitcoind getbalance\n\nDONATIONS --> 1YAyBtCwvZqNF9umZTUmfQ6vvLQRTG9qG\n", "release_dates": []}, {"name": "key_finder", "description": "Scalpel config and ruby script to recover bitcoins and others", "language": "Ruby", "license": null, "readme": "Recover Private Keys From Deleted Wallet Files\n====================\n\nIn this guide we will use scalpel and a custom ruby script and gem to recover lost private keys from deleted wallet files. The first step when deciding to attempt to recover private keys from a lost wallet file is to determine which public addresses holds the coins you are interested in recovering. Once you determine this you can then attempt to extract all the private keys on a drive iterate through each private key, compute the public key and determine it if is the key you are looking for.\n\nInstall And Setup Scalpel\n---------------------\n\nInstall scalpel via your package manager and open the config file:\n\n    vim /etc/scalpel/scalpel.conf\n\nBy analyzing the wallet.dat files of Darkcoin I was able to determine that private keys are always surrounded by the following hex values. I only have found Darkcoin and Bitcoin, if you end up adding more please issue a pull request as it could be helpful for others.\n\nAdding this line to your scalpel config will allow us to extract private keys from the drive:\n\nBITCOIN\n\n    key     y       128  \\x01\\x01\\x04\\x20                   \\xa0\\x81\\x85\\x30\\x81\\x82\\x02\\x01                 \n\nDARKCOIN\n\n    key     y       128  \\xd7\\x00\\x01\\xd6\\x30\\x81\\xd3\\x02\\x01\\x01\\x04\\x20                   \\xa0\\x81\\x85\\x30\\x81\\x82\\x02\\x01\\x01\\x30\\x2c\\x06\\x07\\x2a\\x86\\x48\n\nUncomment this line while leaving all the other options commented out. \n\nDetermine which drive you lost the keys \n\n    df -h \n\nFind the drive your wallet was stored on. My primary partition is /dev/sdb1, so I will run the scalpel against that drive. Use the -o (output) flag to specify your output directory.\n\n    mkdir ~/keys && scalpel /dev/sdb1 -o output ~/keys\n\nTar these files and scp them to a separate computer for analysis\n\n    tar -cvf keys.tar.gz ~/potential_keys/\n    scp keys.tar.gz user@otherserver\n\nAnalysis Of Scalpel Output\n---------------------\n\nTo make the process easier I had cuztomed the bitcoin-ruby gem for a friend and added support for Darkcoin. I also modified it to allow easy output for compressed keys (the common version of the key). Add this to your gemfile:\n\n    gem \"bitcoin-ruby\", :git => \"https://github.com/chemicalfire/bitcoin-ruby.git\"\n\nFirst the provided script will extract the keys from the scalpel output to make it easier to analyze. By default it expects the folder for the scalpel output to be named \"output\" but you can modify the constant DIR at the top of the file to specify your own folder name. \n\n    DIR = \"keys\"\n\nThen you will also want to set your public key you determined is holding the funds you are interested in looking for\n\n    PUBKEY = \"1NB6BCRctsjneowskMQM7Djx5GAkC9yBmy\"\n\nThen finally if you are searching darkcoins change this option to darkcoin otherwise leave it as bitcoin.\n\n    COIN = \"bitcoin\"\n\nOnce all these settings are defined you can then run the key_finder.rb script and see if your private key was found by scalpel:\n\n    bundle exec ruby key_finder.rb\n\nIf the script runs successfully, you will see it parse each key and it will end with the number of keys available readied for testing:\n\n\t\t\"Potential keys to test: 9943\"\n\nIt will then begin to load each private key and determine both the uncompressed and compressed versions of the key. \n\nIf it succeeds in locating the key it will give you both a hex and base58 version of the key otherwise you will be prompted that the key was not found. \n\nDonations\n---------------------\n\nI created this to help others and I believe in free open source code so I don't expect to be paid, but if you are able to recover funds and are feeling generous, I accept donations. \n\nI lost 0.24 bitcoins and unfortunately was not able to recover them, and my significant other 20 lost I gifted to them in aencrypted wallet. \n\nI was able to recover 10,000 lost Darkcoins using this method though and was grateful it worked and wanted to share my methods with others. \n\n1NFk9ukkUw6w5oQ7JtaPPr2MpyQ7RkiQXC\n\n", "release_dates": []}, {"name": "masternode-diff-processor", "description": "Library for processing masternode diff messages", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# masternode-diff-message-processor\n\nLibrary for processing masternode diff messages.\n\nAlso it incorporates all the crypto neccessary for spv (x11-hash, ecdsa, bls, ed25519 etc.)\n\n| main | [![Tests](https://github.com/dashpay/masternode-diff-processor/workflows/Tests/badge.svg?branch=main)](https://github.com/dashpay/masternode-diff-processor/actions) | [![codecov](https://codecov.io/gh/dashpay/masternode-diff-processor/branch/main/graph/badge.svg)](https://codecov.io/gh/dashpay/masternode-diff-processor) | ![Lint](https://github.com/dashpay/masternode-diff-processor/workflows/Lint/badge.svg) |\n\nRun tests: \ncargo test --package dash-spv-masternode-processor --lib tests\nRun c test-like functions:\n\n./build.sh && clang c/main.c target/universal/release/libdash_spv_masternode_processor_macos.a -o test && ./test\n\nFor fast local testing:\nIn 'dash-shared-core'\n1) Create custom branch\n2) Modify DashSharedCore.podspec so 'source' points to branch from previous step\n3) Modify Cargo.toml so needed dependency points to desired branch\n\nIn 'masternodes-diff-processor':\n1) Don't forget to push the changes into the branch that 'dash-shared-core' is looking at\n\nIn 'DashSync' when building example app:\n1) In Podfile put 'DashSharedCore' pod which is 'dash-shared-core' looking at right above 'DashSync' pod import\n2) Perform 'pod cache clean DashSharedCore' if neccessary \n3) Run 'pod update'\n\n\n", "release_dates": []}, {"name": "mtime-cache-test", "description": "Repo for testing cargo caching behaviour", "language": "Shell", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# mtime-cache-test\nRepo for testing cargo caching behaviour\n", "release_dates": []}, {"name": "multifaucet", "description": "Easy to setup crypto currency faucet that supports multiple currencies", "language": "PHP", "license": {"key": "bsd-2-clause", "name": "BSD 2-Clause \"Simplified\" License", "spdx_id": "BSD-2-Clause", "url": "https://api.github.com/licenses/bsd-2-clause", "node_id": "MDc6TGljZW5zZTQ="}, "readme": "MultiFaucet v0.9.2\n==================\nCopyright 2014 by The Daniel Morante Company, Inc.\nhttp://www.unibia.net/crypto-faucet\n\nEasy to setup crypto currency faucet that supports multiple currencies.  \nIt was loosely derived from the Simple Faucet script by Dogenes.  This faucet\nis built using the Enchilada Frame Work 3.0 and Enchilada Libraries 2.0 (http://www.buenapp.com/).\n\nIt's current features include:\n\n- Web installer that makes it easy to setup, just extract and go.\n- Automatic locale and translation into any language.\n- Support for either Hot or Cold crypto wallets.\n- Themes.\n- Simple Captcha, re-CAPTCHA, or Solve Media.\n- SpammerSlapper* Anti-Proxy Abuse\n- Remote Management via JSON-RPC.\n- Muti-site capable (premium add-on).\n\nA live example can be seen at: http://faucet.securepayment.cc\n\nRequirements\n-----------\n\n- MySQL 5.1 or later\n- PHP 5.3 or later\n- PHP JSON extension must be enabled\n- PHP MySQLi extension must be enabled\n- Crypto currency wallet with RPC access (can be on a seprate server)\n\nInstallation\n-------------\n\n1) Create a MySQL database and user that will be used for the faucet.\n\n2) Download the archive and extract into any folder or root folder on your web server.  \n\n3) Allow write permissions to the \"config\" folder\n\n4) Open the website in your browser to start the web based installer or visit \n\thttp://webserver/<upload_folder>/install.php.\n\t\n5) Delete or rename install.php\n\nIf you want to re-configure any settings in the future simply (restore install.php if needed) \nand re-run the installation script or manually edit the config files.\n\nIf you are using the cold wallet it's recommended that you place the data file outside your web directory.\n\nUsage\n-----\n\nOnce the faucet has enough funds, visitors only need to enter a valid wallet address to obtain coins. \nthey will also need to solve a CAPTCHA if enabled. Depending on the anti-abuse features to enabled. \nThe user may be rewarded or told to come back later.\n\nThe promo codes feature (if enabled) awards an extra amount of coins to the visitor.  At the moment the\ncodes and rewards will need to be manually entered into the database table \"PRFX_promo_codes\".\n\nIf you are using the hot wallet, payments will be sent immediately.  If using the cold wallet the funds need\nto be sent manually or by a script.  The faucet's RPC interface can aid with this process.  A sample PHP \nscript that interacts with the faucet's RPC interface to send payments and re-fill the faucet along with\ndetailed usage can be found at:\n\nhttp://www.unibia.net/crypto-faucet\n\nDocker\n------\n\nA `docker-compose.yml` file is provided with an appropriate database service provided. Dash Core is expected\nto be available on the host system. Configure settings by renaming `.env.example` to `.env` and modifying as\nnecessary. Then run `docker compose up -d`. The faucet should be available at `localhost`.\n\nRestrictions\n------------\n\nAll installations must preserve the HTML in \"powered by\" section in the default theme.  Custom themes \nmust also produce the same HTML code unless written permission is granted by the MultiFaucet author.\n\nIf you found this program useful please show your appreciation by sending me some:\n\nBTC: 1B6eyXVRPxdEitW5vWrUnzzXUy6o38P9wN\nZET: ZK6kdE5H5q7H6QRNRAuqLF6RrVD4cFbiNX\n\nDonators will be allowed to remove the \"powered by\" link.\n", "release_dates": ["2023-02-28T10:46:18Z", "2023-01-31T12:29:17Z", "2023-01-25T09:44:55Z", "2022-11-23T05:13:52Z", "2022-11-18T06:03:09Z", "2022-11-18T05:09:38Z", "2022-11-17T04:19:55Z"]}, {"name": "node-open-mining-portal", "description": "An extremely efficient, highly scalable, all-in-one, easy to setup cryptocurrency mining pool and portal written entirely in Node.js.", "language": "JavaScript", "license": {"key": "gpl-2.0", "name": "GNU General Public License v2.0", "spdx_id": "GPL-2.0", "url": "https://api.github.com/licenses/gpl-2.0", "node_id": "MDc6TGljZW5zZTg="}, "readme": "# NOMP ![NOMP Logo](http://zone117x.github.io/node-open-mining-portal/logo.svg \"NOMP Logo\")\n#### Node Open Mining Portal\n\nThis portal is an extremely efficient, highly scalable, all-in-one, easy to setup cryptocurrency mining pool written\nentirely in Node.js. It contains a stratum poolserver; reward/payment/share processor; and a (*not yet completed*)\nresponsive user-friendly front-end website featuring mining instructions, in-depth live statistics, and an admin center.\n\n#### Production Usage Notice\nThis is beta software. All of the following are things that can change and break an existing NOMP setup: functionality of any feature, structure of configuration files and structure of redis data. If you use this software in production then *DO NOT* pull new code straight into production usage because it can and often will break your setup and require you to tweak things like config files or redis data.\n\n#### Paid Solution\nUsage of this software requires abilities with sysadmin, database admin, coin daemons, and sometimes a bit of programming. Running a production pool can literally be more work than a full-time job. \n\n\n**Coin switching & auto-exchanging for payouts in BTC/LTC** to miners is a feature that very likely will not be included in this project. \n\n\n#### Table of Contents\n* [Features](#features)\n  * [Attack Mitigation](#attack-mitigation)\n  * [Security](#security)\n  * [Planned Features](#planned-features)\n* [Community Support](#community--support)\n* [Usage](#usage)\n  * [Requirements](#requirements)\n  * [Setting Up Coin Daemon](#0-setting-up-coin-daemon)\n  * [Downloading & Installing](#1-downloading--installing)\n  * [Configuration](#2-configuration)\n    * [Portal Config](#portal-config)\n    * [Coin Config](#coin-config)\n    * [Pool Config](#pool-config)\n    * [Setting Up Blocknotify](#optional-recommended-setting-up-blocknotify)\n  * [Starting the Portal](#3-start-the-portal)\n  * [Upgrading NOMP](#upgrading-nomp)\n* [Donations](#donations)\n* [Credits](#credits)\n* [License](#license)\n\n\n\n\n### Features\n\n* For the pool server it uses the highly efficient [node-stratum-pool](//github.com/zone117x/node-stratum-pool) module which\nsupports vardiff, POW & POS, transaction messages, anti-DDoS, IP banning, [several hashing algorithms](//github.com/zone117x/node-stratum-pool#hashing-algorithms-supported).\n\n* The portal has an [MPOS](//github.com/MPOS/php-mpos) compatibility mode so that the it can\nfunction as a drop-in-replacement for [python-stratum-mining](//github.com/Crypto-Expert/stratum-mining). This\nmode can be enabled in the configuration and will insert shares into a MySQL database in the format which MPOS expects.\nFor a direct tutorial see the wiki page [Setting up NOMP for MPOS usage](//github.com/zone117x/node-open-mining-portal/wiki/Setting-up-NOMP-for-MPOS-usage).\n\n* Multi-pool ability - this software was built from the ground up to run with multiple coins simultaneously (which can\nhave different properties and hashing algorithms). It can be used to create a pool for a single coin or for multiple\ncoins at once. The pools use clustering to load balance across multiple CPU cores.\n\n* For reward/payment processing, shares are inserted into Redis (a fast NoSQL key/value store). The PROP (proportional)\nreward system is used with [Redis Transactions](http://redis.io/topics/transactions) for secure and super speedy payouts.\nThere is zero risk to the pool operator. Shares from rounds resulting in orphaned blocks will be merged into share in the\ncurrent round so that each and every share will be rewarded\n\n* This portal does not have user accounts/logins/registrations. Instead, miners simply use their coin address for stratum\nauthentication. A minimalistic HTML5 front-end connects to the portals statistics API to display stats from from each\npool such as connected miners, network/pool difficulty/hash rate, etc.\n\n* Coin-switching ports using coin-networks and crypto-exchange APIs to detect profitability. Miner's connect to these ports\nwith their public key which NOMP uses to derive an address for any coin needed to be paid out.\n\n\n#### Attack Mitigation\n* Detects and thwarts socket flooding (garbage data sent over socket in order to consume system resources).\n* Detects and thwarts zombie miners (botnet infected computers connecting to your server to use up sockets but not sending any shares).\n* Detects and thwarts invalid share attacks:\n   * NOMP is not vulnerable to the low difficulty share exploits happening to other pool servers. Other pool server\n   software has hardcoded guesstimated max difficulties for new hashing algorithms while NOMP dynamically generates the\n   max difficulty for each algorithm based on values founds in coin source code.\n   * IP banning feature which on a configurable threshold will ban an IP for a configurable amount of time if the miner\n   submits over a configurable threshold of invalid shares.\n* NOMP is written in Node.js which uses a single thread (async) to handle connections rather than the overhead of one\nthread per connection, and clustering is also implemented so all CPU cores are taken advantage of.\n\n\n#### Security\nNOMP has some implicit security advantages for pool operators and miners:\n* Without a registration/login system, non-security-oriented miners reusing passwords across pools is no longer a concern.\n* Automated payouts by default and pool profits are sent to another address so pool wallets aren't plump with coins -\ngiving hackers little reward and keeping your pool from being a target.\n* Miners can notice lack of automated payments as a possible early warning sign that an operator is about to run off with their coins.\n\n\n#### Planned Features\n\n* NOMP API - Used by the website to display stats and information about the pool(s) on the portal's front-end website,\nand by the NOMP Desktop app to retrieve a list of available coins (and version-bytes for local wallet/address generation).\n\n* To reduce variance for pools just starting out which have little to no hashing power a feature is planned which will\nallow your own pool to connect upstream to a larger pool server. It will request work from the larger pool then\nredistribute the work to our own connected miners.\n\n\n### Community / Support\nIRC\n* Support / general discussion join #nomp: https://webchat.freenode.net/?channels=#nomp\n* Development discussion join #nomp-dev: https://webchat.freenode.net/?channels=#nomp-dev\n\nJoin our subreddit [/r/nomp](http://reddit.com/r/nomp)!\n\n*Having problems getting the portal running due to some module dependency error?* It's probably because you\ndidn't follow the instructions in this README. Please __read the usage instructions__ including [requirements](#requirements) and [downloading/installing](#1-downloading--installing). If you've followed the instructions completely and are still having problems then open an issue here on github or join our #nomp IRC channel and explain your problem :).\n\nIf your pool uses NOMP let us know and we will list your website here.\n\n##### Some pools using NOMP or node-stratum-module:\n* http://clevermining.com\n* http://suchpool.pw\n* http://hashfaster.com\n* http://miningpoolhub.com\n* http://kryptochaos.com\n* http://miningpools.tk\n* http://umine.co.uk\n\nUsage\n=====\n\n\n#### Requirements\n* Coin daemon(s) (find the coin's repo and build latest version from source)\n* [Node.js](http://nodejs.org/) v0.10+ ([follow these installation instructions](https://github.com/joyent/node/wiki/Installing-Node.js-via-package-manager))\n* [Redis](http://redis.io/) key-value store v2.6+ ([follow these instructions](http://redis.io/topics/quickstart))\n\n##### Seriously\nThose are legitimate requirements. If you use old versions of Node.js or Redis that may come with your system package manager then you will have problems. Follow the linked instructions to get the last stable versions.\n\n\n[**Redis security warning**](http://redis.io/topics/security): be sure firewall access to redis - an easy way is to\ninclude `bind 127.0.0.1` in your `redis.conf` file. Also it's a good idea to learn about and understand software that\nyou are using - a good place to start with redis is [data persistence](http://redis.io/topics/persistence).\n\n\n#### 0) Setting up coin daemon\nFollow the build/install instructions for your coin daemon. Your coin.conf file should end up looking something like this:\n```\ndaemon=1\nrpcuser=litecoinrpc\nrpcpassword=securepassword\nrpcport=19332\n```\nFor redundancy, its recommended to have at least two daemon instances running in case one drops out-of-sync or offline,\nall instances will be polled for block/transaction updates and be used for submitting blocks. Creating a backup daemon\ninvolves spawning a daemon using the `-datadir=/backup` command-line argument which creates a new daemon instance with\nit's own config directory and coin.conf file. Learn about the daemon, how to use it and how it works if you want to be\na good pool operator. For starters be sure to read:\n   * https://en.bitcoin.it/wiki/Running_bitcoind\n   * https://en.bitcoin.it/wiki/Data_directory\n   * https://en.bitcoin.it/wiki/Original_Bitcoin_client/API_Calls_list\n   * https://en.bitcoin.it/wiki/Difficulty\n\n#### 1) Downloading & Installing\n\nClone the repository and run `npm update` for all the dependencies to be installed:\n\n```bash\ngit clone https://github.com/zone117x/node-open-mining-portal.git nomp\ncd nomp\nnpm update\n```\n\n#### 2) Configuration\n\n##### Portal config\nInside the `config_example.json` file, ensure the default configuration will work for your environment, then copy the file to `config.json`.\n\nExplanation for each field:\n````javascript\n{\n    /* Specifies the level of log output verbosity. Anything more severe than the level specified\n       will also be logged. */\n    \"logLevel\": \"debug\", //or \"warning\", \"error\"\n    \n    /* By default NOMP logs to console and gives pretty colors. If you direct that output to a\n       log file then disable this feature to avoid nasty characters in your log file. */\n    \"logColors\": true, \n\n\n    /* The NOMP CLI (command-line interface) will listen for commands on this port. For example,\n       blocknotify messages are sent to NOMP through this. */\n    \"cliPort\": 17117,\n\n    /* By default 'forks' is set to \"auto\" which will spawn one process/fork/worker for each CPU\n       core in your system. Each of these workers will run a separate instance of your pool(s),\n       and the kernel will load balance miners using these forks. Optionally, the 'forks' field\n       can be a number for how many forks will be spawned. */\n    \"clustering\": {\n        \"enabled\": true,\n        \"forks\": \"auto\"\n    },\n    \n    /* Pool config file will inherit these default values if they are not set. */\n    \"defaultPoolConfigs\": {\n    \n        /* Poll RPC daemons for new blocks every this many milliseconds. */\n        \"blockRefreshInterval\": 1000,\n        \n        /* If no new blocks are available for this many seconds update and rebroadcast job. */\n        \"jobRebroadcastTimeout\": 55,\n        \n        /* Disconnect workers that haven't submitted shares for this many seconds. */\n        \"connectionTimeout\": 600,\n        \n        /* (For MPOS mode) Store the block hashes for shares that aren't block candidates. */\n        \"emitInvalidBlockHashes\": false,\n        \n        /* This option will only authenticate miners using an address or mining key. */\n        \"validateWorkerUsername\": true,\n        \n        /* Enable for client IP addresses to be detected when using a load balancer with TCP\n           proxy protocol enabled, such as HAProxy with 'send-proxy' param:\n           http://haproxy.1wt.eu/download/1.5/doc/configuration.txt */\n        \"tcpProxyProtocol\": false,\n        \n        /* If under low-diff share attack we can ban their IP to reduce system/network load. If\n           running behind HAProxy be sure to enable 'tcpProxyProtocol', otherwise you'll end up\n           banning your own IP address (and therefore all workers). */\n        \"banning\": {\n            \"enabled\": true,\n            \"time\": 600, //How many seconds to ban worker for\n            \"invalidPercent\": 50, //What percent of invalid shares triggers ban\n            \"checkThreshold\": 500, //Perform check when this many shares have been submitted\n            \"purgeInterval\": 300 //Every this many seconds clear out the list of old bans\n        },\n        \n        /* Used for storing share and block submission data and payment processing. */\n        \"redis\": {\n            \"host\": \"127.0.0.1\",\n            \"port\": 6379\n        }\n    },\n\n    /* This is the front-end. Its not finished. When it is finished, this comment will say so. */\n    \"website\": {\n        \"enabled\": true,\n        /* If you are using a reverse-proxy like nginx to display the website then set this to\n           127.0.0.1 to not expose the port. */\n        \"host\": \"0.0.0.0\",\n        \"port\": 80,\n        /* Used for displaying stratum connection data on the Getting Started page. */\n        \"stratumHost\": \"cryppit.com\",\n        \"stats\": {\n            /* Gather stats to broadcast to page viewers and store in redis for historical stats\n               every this many seconds. */\n            \"updateInterval\": 15,\n            /* How many seconds to hold onto historical stats. Currently set to 24 hours. */\n            \"historicalRetention\": 43200,\n            /* How many seconds worth of shares should be gathered to generate hashrate. */\n            \"hashrateWindow\": 300\n        },\n        /* Not done yet. */\n        \"adminCenter\": {\n            \"enabled\": true,\n            \"password\": \"password\"\n        }\n    },\n\n    /* Redis instance of where to store global portal data such as historical stats, proxy states,\n       ect.. */\n    \"redis\": {\n        \"host\": \"127.0.0.1\",\n        \"port\": 6379\n    },\n\n\n    /* With this switching configuration, you can setup ports that accept miners for work based on\n       a specific algorithm instead of a specific coin. Miners that connect to these ports are\n       automatically switched a coin determined by the server. The default coin is the first\n       configured pool for each algorithm and coin switching can be triggered using the\n       cli.js script in the scripts folder.\n\n       Miners connecting to these switching ports must use their public key in the format of\n       RIPEMD160(SHA256(public-key)). An address for each type of coin is derived from the miner's\n       public key, and payments are sent to that address. */\n    \"switching\": {\n        \"switch1\": {\n            \"enabled\": false,\n            \"algorithm\": \"sha256\",\n            \"ports\": {\n                \"3333\": {\n                    \"diff\": 10,\n                    \"varDiff\": {\n                        \"minDiff\": 16,\n                        \"maxDiff\": 512,\n                        \"targetTime\": 15,\n                        \"retargetTime\": 90,\n                        \"variancePercent\": 30\n                    }\n                }\n            }\n        },\n        \"switch2\": {\n            \"enabled\": false,\n            \"algorithm\": \"scrypt\",\n            \"ports\": {\n                \"4444\": {\n                    \"diff\": 10,\n                    \"varDiff\": {\n                        \"minDiff\": 16,\n                        \"maxDiff\": 512,\n                        \"targetTime\": 15,\n                        \"retargetTime\": 90,\n                        \"variancePercent\": 30\n                    }\n                }\n            }\n        },\n        \"switch3\": {\n            \"enabled\": false,\n            \"algorithm\": \"x11\",\n            \"ports\": {\n                \"5555\": {\n                    \"diff\": 0.001\n                }\n            }\n        }\n    },\n\n    \"profitSwitch\": {\n        \"enabled\": false,\n        \"updateInterval\": 600,\n        \"depth\": 0.90,\n        \"usePoloniex\": true,\n        \"useCryptsy\": true,\n        \"useMintpal\": true\n    }\n}\n````\n\n\n##### Coin config\nInside the `coins` directory, ensure a json file exists for your coin. If it does not you will have to create it.\nHere is an example of the required fields:\n````javascript\n{\n    \"name\": \"Litecoin\",\n    \"symbol\": \"ltc\",\n    \"algorithm\": \"scrypt\",\n\n    /* Magic value only required for setting up p2p block notifications. It is found in the daemon\n       source code as the pchMessageStart variable.\n       For example, litecoin mainnet magic: http://git.io/Bi8YFw\n       And for litecoin testnet magic: http://git.io/NXBYJA */\n    \"peerMagic\": \"fbc0b6db\", //optional\n    \"peerMagicTestnet\": \"fcc1b7dc\" //optional\n\n    //\"txMessages\": false, //options - defaults to false\n\n    //\"mposDiffMultiplier\": 256, //options - only for x11 coins in mpos mode\n}\n````\n\nFor additional documentation how to configure coins and their different algorithms\nsee [these instructions](//github.com/zone117x/node-stratum-pool#module-usage).\n\n\n##### Pool config\nTake a look at the example json file inside the `pool_configs` directory. Rename it to `yourcoin.json` and change the\nexample fields to fit your setup.\n\nDescription of options:\n\n````javascript\n{\n    \"enabled\": true, //Set this to false and a pool will not be created from this config file\n    \"coin\": \"litecoin.json\", //Reference to coin config file in 'coins' directory\n\n    \"address\": \"mi4iBXbBsydtcc5yFmsff2zCFVX4XG7qJc\", //Address to where block rewards are given\n\n    /* Block rewards go to the configured pool wallet address to later be paid out to miners,\n       except for a percentage that can go to, for examples, pool operator(s) as pool fees or\n       or to donations address. Addresses or hashed public keys can be used. Here is an example\n       of rewards going to the main pool op, a pool co-owner, and NOMP donation. */\n    \"rewardRecipients\": {\n        \"n37vuNFkXfk15uFnGoVyHZ6PYQxppD3QqK\": 1.5, //1.5% goes to pool op\n        \"mirj3LtZxbSTharhtXvotqtJXUY7ki5qfx\": 0.5, //0.5% goes to a pool co-owner\n\n        /* 0.1% donation to NOMP. This pubkey can accept any type of coin, please leave this in\n           your config to help support NOMP development. */\n        \"22851477d63a085dbc2398c8430af1c09e7343f6\": 0.1\n    },\n\n    \"paymentProcessing\": {\n        \"enabled\": true,\n\n        /* Every this many seconds get submitted blocks from redis, use daemon RPC to check\n           their confirmation status, if confirmed then get shares from redis that contributed\n           to block and send out payments. */\n        \"paymentInterval\": 30,\n\n        /* Minimum number of coins that a miner must earn before sending payment. Typically,\n           a higher minimum means less transactions fees (you profit more) but miners see\n           payments less frequently (they dislike). Opposite for a lower minimum payment. */\n        \"minimumPayment\": 0.01,\n\n        /* This daemon is used to send out payments. It MUST be for the daemon that owns the\n           configured 'address' that receives the block rewards, otherwise the daemon will not\n           be able to confirm blocks or send out payments. */\n        \"daemon\": {\n            \"host\": \"127.0.0.1\",\n            \"port\": 19332,\n            \"user\": \"testuser\",\n            \"password\": \"testpass\"\n        }\n    },\n\n    /* Each pool can have as many ports for your miners to connect to as you wish. Each port can\n       be configured to use its own pool difficulty and variable difficulty settings. varDiff is\n       optional and will only be used for the ports you configure it for. */\n    \"ports\": {\n        \"3032\": { //A port for your miners to connect to\n            \"diff\": 32, //the pool difficulty for this port\n\n            /* Variable difficulty is a feature that will automatically adjust difficulty for\n               individual miners based on their hashrate in order to lower networking overhead */\n            \"varDiff\": {\n                \"minDiff\": 8, //Minimum difficulty\n                \"maxDiff\": 512, //Network difficulty will be used if it is lower than this\n                \"targetTime\": 15, //Try to get 1 share per this many seconds\n                \"retargetTime\": 90, //Check to see if we should retarget every this many seconds\n                \"variancePercent\": 30 //Allow time to very this % from target without retargeting\n            }\n        },\n        \"3256\": { //Another port for your miners to connect to, this port does not use varDiff\n            \"diff\": 256 //The pool difficulty\n        }\n    },\n\n    /* More than one daemon instances can be setup in case one drops out-of-sync or dies. */\n    \"daemons\": [\n        {   //Main daemon instance\n            \"host\": \"127.0.0.1\",\n            \"port\": 19332,\n            \"user\": \"testuser\",\n            \"password\": \"testpass\"\n        }\n    ],\n\n    /* This allows the pool to connect to the daemon as a node peer to receive block updates.\n       It may be the most efficient way to get block updates (faster than polling, less\n       intensive than blocknotify script). It requires the additional field \"peerMagic\" in\n       the coin config. */\n    \"p2p\": {\n        \"enabled\": false,\n\n        /* Host for daemon */\n        \"host\": \"127.0.0.1\",\n\n        /* Port configured for daemon (this is the actual peer port not RPC port) */\n        \"port\": 19333,\n\n        /* If your coin daemon is new enough (i.e. not a shitcoin) then it will support a p2p\n           feature that prevents the daemon from spamming our peer node with unnecessary\n           transaction data. Assume its supported but if you have problems try disabling it. */\n        \"disableTransactions\": true\n    },\n    \n    /* Enabled this mode and shares will be inserted into in a MySQL database. You may also want\n       to use the \"emitInvalidBlockHashes\" option below if you require it. The config options\n       \"redis\" and \"paymentProcessing\" will be ignored/unused if this is enabled. */\n    \"mposMode\": {\n        \"enabled\": false,\n        \"host\": \"127.0.0.1\", //MySQL db host\n        \"port\": 3306, //MySQL db port\n        \"user\": \"me\", //MySQL db user\n        \"password\": \"mypass\", //MySQL db password\n        \"database\": \"ltc\", //MySQL db database name\n\n        /* Checks for valid password in database when miners connect. */\n        \"checkPassword\": true,\n\n        /* Unregistered workers can automatically be registered (added to database) on stratum\n           worker authentication if this is true. */\n        \"autoCreateWorker\": false\n    }\n}\n\n````\n\nYou can create as many of these pool config files as you want (such as one pool per coin you which to operate).\nIf you are creating multiple pools, ensure that they have unique stratum ports.\n\nFor more information on these configuration options see the [pool module documentation](https://github.com/zone117x/node-stratum-pool#module-usage)\n\n\n\n##### [Optional, recommended] Setting up blocknotify\n1. In `config.json` set the port and password for `blockNotifyListener`\n2. In your daemon conf file set the `blocknotify` command to use:\n```\nnode [path to cli.js] [coin name in config] [block hash symbol]\n```\nExample: inside `dogecoin.conf` add the line\n```\nblocknotify=node /home/nomp/scripts/cli.js blocknotify dogecoin %s\n```\n\nAlternatively, you can use a more efficient block notify script written in pure C. Build and usage instructions\nare commented in [scripts/blocknotify.c](scripts/blocknotify.c).\n\n\n#### 3) Start the portal\n\n```bash\nnode init.js\n```\n\n###### Optional enhancements for your awesome new mining pool server setup:\n* Use something like [forever](https://github.com/nodejitsu/forever) to keep the node script running\nin case the master process crashes. \n* Use something like [redis-commander](https://github.com/joeferner/redis-commander) to have a nice GUI\nfor exploring your redis database.\n* Use something like [logrotator](http://www.thegeekstuff.com/2010/07/logrotate-examples/) to rotate log \noutput from NOMP.\n* Use [New Relic](http://newrelic.com/) to monitor your NOMP instance and server performance.\n\n\n#### Upgrading NOMP\nWhen updating NOMP to the latest code its important to not only `git pull` the latest from this repo, but to also update\nthe `node-stratum-pool` and `node-multi-hashing` modules, and any config files that may have been changed.\n* Inside your NOMP directory (where the init.js script is) do `git pull` to get the latest NOMP code.\n* Remove the dependenices by deleting the `node_modules` directory with `rm -r node_modules`.\n* Run `npm update` to force updating/reinstalling of the dependencies.\n* Compare your `config.json` and `pool_configs/coin.json` configurations to the latest example ones in this repo or the ones in the setup instructions where each config field is explained. You may need to modify or add any new changes.\n\nDonations\n---------\nTo support development of this project feel free to donate :)\n\n* BTC: `1KRotMnQpxu3sePQnsVLRy3EraRFYfJQFR`\n* LTC: `LKfavSDJmwiFdcgaP1bbu46hhyiWw5oFhE`\n* VTC: `VgW4uFTZcimMSvcnE4cwS3bjJ6P8bcTykN`\n* MAX: `mWexUXRCX5PWBmfh34p11wzS5WX2VWvTRT`\n* QRK: `QehPDAhzVQWPwDPQvmn7iT3PoFUGT7o8bC`\n* DRK: `XcQmhp8ANR7okWAuArcNFZ2bHSB81jpapQ`\n* DOGE: `DBGGVtwAAit1NPZpRm5Nz9VUFErcvVvHYW`\n* Cryptsy Trade Key: `254ca13444be14937b36c44ba29160bd8f02ff76`\n\nCredits\n-------\n* [Jerry Brady / mintyfresh68](https://github.com/bluecircle) - got coin-switching fully working and developed proxy-per-algo feature\n* [Tony Dobbs](http://anthonydobbs.com) - designs for front-end and created the NOMP logo\n* [LucasJones](//github.com/LucasJones) - got p2p block notify working and implemented additional hashing algos\n* [vekexasia](//github.com/vekexasia) - co-developer & great tester\n* [TheSeven](//github.com/TheSeven) - answering an absurd amount of my questions and being a very helpful gentleman\n* [UdjinM6](//github.com/UdjinM6) - helped implement fee withdrawal in payment processing\n* [Alex Petrov / sysmanalex](https://github.com/sysmanalex) - contributed the pure C block notify script\n* [svirusxxx](//github.com/svirusxxx) - sponsored development of MPOS mode\n* [icecube45](//github.com/icecube45) - helping out with the repo wiki\n* [Fcases](//github.com/Fcases) - ordered me a pizza <3\n* Those that contributed to [node-stratum-pool](//github.com/zone117x/node-stratum-pool#credits)\n\n\nLicense\n-------\nReleased under the GNU General Public License v2\n\nhttp://www.gnu.org/licenses/gpl-2.0.html\n", "release_dates": []}, {"name": "node-stratum-pool", "description": "High performance Stratum poolserver in Node.js", "language": "JavaScript", "license": {"key": "gpl-2.0", "name": "GNU General Public License v2.0", "spdx_id": "GPL-2.0", "url": "https://api.github.com/licenses/gpl-2.0", "node_id": "MDc6TGljZW5zZTg="}, "readme": "High performance Stratum poolserver in Node.js. One instance of this software can startup and manage multiple coin\npools, each with their own daemon and stratum port :)\n\n#### Notice\nThis is a module for Node.js that will do nothing on its own. Unless you're a Node.js developer who would like to\nhandle stratum authentication and raw share data then this module will not be of use to you. For a full featured portal\nthat uses this module, see [NOMP (Node Open Mining Portal)](https://github.com/zone117x/node-open-mining-portal). It\nhandles payments, website front-end, database layer, mutli-coin/pool support, auto-switching miners between coins/pools,\netc.. The portal also has an [MPOS](https://github.com/MPOS/php-mpos) compatibility mode so that the it can function as\na drop-in-replacement for [python-stratum-mining](https://github.com/Crypto-Expert/stratum-mining).\n\n\n[![Build Status](https://travis-ci.org/zone117x/node-stratum-pool.png?branch=master)](https://travis-ci.org/zone117x/node-stratum-pool)\n\n[![NPM](https://nodei.co/npm/stratum-pool.png?downloads=true&stars=true)](https://nodei.co/npm/stratum-pool/)\n\n#### Why\nThis server was built to be more efficient and easier to setup, maintain and scale than existing stratum poolservers\nwhich are written in python. Compared to the spaghetti state of the latest\n[stratum-mining python server](https://github.com/Crypto-Expert/stratum-mining/), this software should also have a\nlower barrier to entry for other developers to fork and add features or fix bugs.\n\n\nFeatures\n----------------------------------\n* Daemon RPC interface\n* Stratum TCP socket server\n* Block template / job manager\n* P2P to get block notifications as peer node\n* Optimized generation transaction building\n* Connecting to multiple daemons for redundancy\n* Process share submissions\n* Session managing for purging DDoS/flood initiated zombie workers\n* Auto ban IPs that are flooding with invalid shares\n* __POW__ (proof-of-work) & __POS__ (proof-of-stake) support\n* Transaction messages support\n* Vardiff (variable difficulty / share limiter)\n* When started with a coin deamon that hasn't finished syncing to the network it shows the blockchain download progress and initializes once synced\n\n#### Hashing algorithms supported:\n* \u2713 __SHA256__ (Bitcoin, Freicoin, Peercoin/PPCoin, Terracoin, etc..)\n* \u2713 __Scrypt__ (Litecoin, Dogecoin, Feathercoin, etc..)\n* \u2713 __Scrypt-Jane__ (YaCoin, CopperBars, Pennies, Tickets, etc..)\n* \u2713 __Scrypt-N__ (Vertcoin [VTC])\n* \u2713 __Quark__ (Quarkcoin [QRK])\n* \u2713 __X11__ (Darkcoin [DRK], Hirocoin, Limecoin)\n* \u2713 __X13__ (MaruCoin, BoostCoin)\n* \u2713 __Keccak__ (Maxcoin [MAX], HelixCoin, CryptoMeth, Galleon, 365coin, Slothcoin, BitcointalkCoin)\n* \u2713 __Skein__ (Skeincoin [SKC])\n* \u2713 __Groestl__ (Groestlcoin [GRS])\n\nMay be working (needs additional testing):\n* ? *Blake* (Blakecoin [BLC])\n* ? *Fugue* (Fuguecoin [FC])\n* ? *Qubit* (Qubitcoin [Q2C], Myriadcoin [MYR])\n* ? *Hefty1* (Heavycoin [HVC])\n* ? *SHAvite-3* (INKcoin [INK])\n\nNot working currently:\n* *Groestl* - for Myriadcoin\n* *Keccak* - for eCoin & Copperlark\n\n\n\nRequirements\n------------\n* node v0.10+\n* coin daemon (preferably one with a relatively updated API and not some crapcoin :p)\n\n\nExample Usage\n-------------\n\n#### Install as a node module by cloning repository\n\n```bash\ngit clone https://github.com/zone117x/node-stratum-pool node_modules/stratum-pool\nnpm update\n```\n\n#### Module usage\n\nCreate the configuration for your coin:\n\nPossible options for `algorithm`: *sha256, scrypt, scrypt-jane, scrypt-n, quark, x11, keccak, blake,\nskein, groestl, fugue, shavite3, hefty1, or qubit*.\n\n```javascript\nvar myCoin = {\n    \"name\": \"Dogecoin\",\n    \"symbol\": \"DOGE\",\n    \"algorithm\": \"scrypt\",\n    \"nValue\": 1024, //optional - defaults to 1024\n    \"rValue\": 1, //optional - defaults to 1\n    \"txMessages\": false, //optional - defaults to false,\n\n    /* Magic value only required for setting up p2p block notifications. It is found in the daemon\n       source code as the pchMessageStart variable.\n       For example, litecoin mainnet magic: http://git.io/Bi8YFw\n       And for litecoin testnet magic: http://git.io/NXBYJA */\n     \"peerMagic\": \"fbc0b6db\" //optional\n     \"peerMagicTestnet\": \"fcc1b7dc\" //optional\n};\n```\n\nIf you are using the `scrypt-jane` algorithm there are additional configurations:\n\n```javascript\nvar myCoin = {\n    \"name\": \"Freecoin\",\n    \"symbol\": \"FEC\",\n    \"algorithm\": \"scrypt-jane\",\n    \"chainStartTime\": 1375801200, //defaults to 1367991200 (YACoin) if not used\n    \"nMin\": 6, //defaults to 4 if not used\n    \"nMax\": 32 //defaults to 30 if not used\n};\n```\n\nIf you are using the `scrypt-n` algorithm there is an additional configuration:\n```javascript\nvar myCoin = {\n    \"name\": \"Execoin\",\n    \"symbol\": \"EXE\",\n    \"algorithm\": \"scrypt-n\",\n    /* This defaults to Vertcoin's timetable if not used. It is required for scrypt-n coins that\n       have modified their N-factor timetable to be different than Vertcoin's. */\n    \"timeTable\": {\n        \"2048\": 1390959880,\n        \"4096\": 1438295269,\n        \"8192\": 1485630658,\n        \"16384\": 1532966047,\n        \"32768\": 1580301436,\n        \"65536\": 1627636825,\n        \"131072\": 1674972214,\n        \"262144\": 1722307603\n    }\n};\n```\n\nIf you are using the `keccak` algorithm there are additional configurations *(The rare `normalHashing` keccak coins\nsuch as Copperlark and eCoin don't appear to work yet - only the popular ones like Maxcoin are)*:\n```javascript\nvar myCoin = {\n    \"name\": \"eCoin\",\n    \"symbol\": \"ECN\",\n    \"algorithm\": \"keccak\",\n\n    /* This is not required and set to false by default. Some coins such as Copperlark and eCoin\n       require it to be set to true. Maxcoin and most others are false. */\n    \"normalHashing\": true\n};\n```\n\n\nCreate and start new pool with configuration options and authentication function\n\n```javascript\nvar Stratum = require('stratum-pool');\n\nvar pool = Stratum.createPool({\n\n    \"coin\": myCoin,\n\n    \"address\": \"mi4iBXbBsydtcc5yFmsff2zCFVX4XG7qJc\", //Address to where block rewards are given\n\n    /* Block rewards go to the configured pool wallet address to later be paid out to miners,\n       except for a percentage that can go to, for examples, pool operator(s) as pool fees or\n       or to donations address. Addresses or hashed public keys can be used. Here is an example\n       of rewards going to the main pool op, a pool co-owner, and NOMP donation. */\n    \"rewardRecipients\": {\n        \"n37vuNFkXfk15uFnGoVyHZ6PYQxppD3QqK\": 1.5, //1.5% goes to pool op\n        \"mirj3LtZxbSTharhtXvotqtJXUY7ki5qfx\": 0.5, //0.5% goes to a pool co-owner\n\n        /* 0.1% donation to NOMP. This pubkey can accept any type of coin, please leave this in\n           your config to help support NOMP development. */\n        \"22851477d63a085dbc2398c8430af1c09e7343f6\": 0.1\n    },\n\n    \"blockRefreshInterval\": 1000, //How often to poll RPC daemons for new blocks, in milliseconds\n\n\n    /* Some miner apps will consider the pool dead/offline if it doesn't receive anything new jobs\n       for around a minute, so every time we broadcast jobs, set a timeout to rebroadcast\n       in this many seconds unless we find a new job. Set to zero or remove to disable this. */\n    \"jobRebroadcastTimeout\": 55,\n\n    //instanceId: 37, //Recommend not using this because a crypto-random one will be generated\n\n    /* Some attackers will create thousands of workers that use up all available socket connections,\n       usually the workers are zombies and don't submit shares after connecting. This features\n       detects those and disconnects them. */\n    \"connectionTimeout\": 600, //Remove workers that haven't been in contact for this many seconds\n\n    /* Sometimes you want the block hashes even for shares that aren't block candidates. */\n    \"emitInvalidBlockHashes\": false,\n\n    /* Enable for client IP addresses to be detected when using a load balancer with TCP proxy\n       protocol enabled, such as HAProxy with 'send-proxy' param:\n       http://haproxy.1wt.eu/download/1.5/doc/configuration.txt */\n    \"tcpProxyProtocol\": false,\n\n    /* If a worker is submitting a high threshold of invalid shares we can temporarily ban their IP\n       to reduce system/network load. Also useful to fight against flooding attacks. If running\n       behind something like HAProxy be sure to enable 'tcpProxyProtocol', otherwise you'll end up\n       banning your own IP address (and therefore all workers). */\n    \"banning\": {\n        \"enabled\": true,\n        \"time\": 600, //How many seconds to ban worker for\n        \"invalidPercent\": 50, //What percent of invalid shares triggers ban\n        \"checkThreshold\": 500, //Check invalid percent when this many shares have been submitted\n        \"purgeInterval\": 300 //Every this many seconds clear out the list of old bans\n    },\n\n    /* Each pool can have as many ports for your miners to connect to as you wish. Each port can\n       be configured to use its own pool difficulty and variable difficulty settings. varDiff is\n       optional and will only be used for the ports you configure it for. */\n    \"ports\": {\n        \"3032\": { //A port for your miners to connect to\n            \"diff\": 32, //the pool difficulty for this port\n\n            /* Variable difficulty is a feature that will automatically adjust difficulty for\n               individual miners based on their hashrate in order to lower networking overhead */\n            \"varDiff\": {\n                \"minDiff\": 8, //Minimum difficulty\n                \"maxDiff\": 512, //Network difficulty will be used if it is lower than this\n                \"targetTime\": 15, //Try to get 1 share per this many seconds\n                \"retargetTime\": 90, //Check to see if we should retarget every this many seconds\n                \"variancePercent\": 30 //Allow time to very this % from target without retargeting\n            }\n        },\n        \"3256\": { //Another port for your miners to connect to, this port does not use varDiff\n            \"diff\": 256 //The pool difficulty\n        }\n    },\n\n    /* Recommended to have at least two daemon instances running in case one drops out-of-sync\n       or offline. For redundancy, all instances will be polled for block/transaction updates\n       and be used for submitting blocks. Creating a backup daemon involves spawning a daemon\n       using the \"-datadir=/backup\" argument which creates a new daemon instance with it's own\n       RPC config. For more info on this see:\n          - https://en.bitcoin.it/wiki/Data_directory\n          - https://en.bitcoin.it/wiki/Running_bitcoind */\n    \"daemons\": [\n        {   //Main daemon instance\n            \"host\": \"127.0.0.1\",\n            \"port\": 19332,\n            \"user\": \"litecoinrpc\",\n            \"password\": \"testnet\"\n        },\n        {   //Backup daemon instance\n            \"host\": \"127.0.0.1\",\n            \"port\": 19344,\n            \"user\": \"litecoinrpc\",\n            \"password\": \"testnet\"\n        }\n    ],\n\n\n    /* This allows the pool to connect to the daemon as a node peer to receive block updates.\n       It may be the most efficient way to get block updates (faster than polling, less\n       intensive than blocknotify script). It requires the additional field \"peerMagic\" in\n       the coin config. */\n    \"p2p\": {\n        \"enabled\": false,\n\n        /* Host for daemon */\n        \"host\": \"127.0.0.1\",\n\n        /* Port configured for daemon (this is the actual peer port not RPC port) */\n        \"port\": 19333,\n\n        /* If your coin daemon is new enough (i.e. not a shitcoin) then it will support a p2p\n           feature that prevents the daemon from spamming our peer node with unnecessary\n           transaction data. Assume its supported but if you have problems try disabling it. */\n        \"disableTransactions\": true\n\n    }\n\n}, function(ip, workerName, password, callback){ //stratum authorization function\n    console.log(\"Authorize \" + workerName + \":\" + password + \"@\" + ip);\n    callback({\n        error: null,\n        authorized: true,\n        disconnect: false\n    });\n});\n```\n\n\nListen to pool events\n```javascript\n/*\n\n'data' object contains:\n    job: 4, //stratum work job ID\n    ip: '71.33.19.37', //ip address of client\n    port: 3333, //port of the client\n    worker: 'matt.worker1', //stratum worker name\n    height: 443795, //block height\n    blockReward: 5000000000, //the number of satoshis received as payment for solving this block\n    difficulty: 64, //stratum worker difficulty\n    shareDiff: 78, //actual difficulty of the share\n    blockDiff: 3349, //block difficulty adjusted for share padding\n    blockDiffActual: 3349 //actual difficulty for this block\n\n\n    //AKA the block solution - set if block was found\n    blockHash: '110c0447171ad819dd181216d5d80f41e9218e25d833a2789cb8ba289a52eee4',\n\n    //Exists if \"emitInvalidBlockHashes\" is set to true\n    blockHashInvalid: '110c0447171ad819dd181216d5d80f41e9218e25d833a2789cb8ba289a52eee4'\n\n    //txHash is the coinbase transaction hash from the block\n    txHash: '41bb22d6cc409f9c0bae2c39cecd2b3e3e1be213754f23d12c5d6d2003d59b1d,\n\n    error: 'low share difficulty' //set if share is rejected for some reason\n*/\npool.on('share', function(isValidShare, isValidBlock, data){\n\n    if (isValidBlock)\n        console.log('Block found');\n    else if (isValidShare)\n        console.log('Valid share submitted');\n    else if (data.blockHash)\n        console.log('We thought a block was found but it was rejected by the daemon');\n    else\n        console.log('Invalid share submitted')\n\n    console.log('share data: ' + JSON.stringify(data));\n});\n\n\n\n/*\n'severity': can be 'debug', 'warning', 'error'\n'logKey':   can be 'system' or 'client' indicating if the error\n            was caused by our system or a stratum client\n*/\npool.on('log', function(severity, logKey, logText){\n    console.log(severity + ': ' + '[' + logKey + '] ' + logText);\n});\n```\n\nStart pool\n```javascript\npool.start();\n```\n\n\nCredits\n-------\n* [vekexasia](//github.com/vekexasia) - co-developer & great tester\n* [LucasJones](//github.com/LucasJones) - got p2p block notify working and implemented additional hashing algos\n* [TheSeven](//github.com/TheSeven) - answering an absurd amount of my questions, found the block 1-16 problem, provided example code for peer node functionality\n* [pronooob](https://dogehouse.org) - knowledgeable & helpful\n* [Slush0](//github.com/slush0/stratum-mining) - stratum protocol, documentation and original python code\n* [viperaus](//github.com/viperaus/stratum-mining) - scrypt adaptions to python code\n* [ahmedbodi](//github.com/ahmedbodi/stratum-mining) - more algo adaptions to python code\n* [steveshit](//github.com/steveshit) - ported X11 hashing algo from python to node module\n\n\nDonations\n---------\nTo support development of this project feel free to donate :)\n\n* BTC: `1KRotMnQpxu3sePQnsVLRy3EraRFYfJQFR`\n* LTC: `LKfavSDJmwiFdcgaP1bbu46hhyiWw5oFhE`\n* VTC: `VgW4uFTZcimMSvcnE4cwS3bjJ6P8bcTykN`\n* MAX: `mWexUXRCX5PWBmfh34p11wzS5WX2VWvTRT`\n* QRK: `QehPDAhzVQWPwDPQvmn7iT3PoFUGT7o8bC`\n* DRK: `XcQmhp8ANR7okWAuArcNFZ2bHSB81jpapQ`\n* DOGE: `DBGGVtwAAit1NPZpRm5Nz9VUFErcvVvHYW`\n* Cryptsy Trade Key: `254ca13444be14937b36c44ba29160bd8f02ff76`\n\nLicense\n-------\nReleased under the GNU General Public License v2\n\nhttp://www.gnu.org/licenses/gpl-2.0.html\n", "release_dates": []}, {"name": "node-x11-hash", "description": null, "language": "C", "license": null, "readme": "node-x11-hash\n===============\n\nX11 hashing function for node.js.\n\nUsage\n-----\n\nInstall\n\n    # install node, check updated script at https://github.com/nodesource/distributions\n    curl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash -\n    sudo apt-get install -y nodejs\n\n    # if you previously installed node-gyp via apt-get - remove it\n    # sudo apt-get remove node-gyp\n\n    # install proper version of node-gyp via npm\n    sudo npm i -g node-gyp\n\n    # install git and build tools\n    sudo apt-get install git python make g++\n\n    # clone this repo and go to that folder\n    # ...\n\n    # install dependencies\n    sudo npm i\n\n    # configure and build\n    sudo node-gyp configure\n    sudo node-gyp build\n\nTest\n\n    npm test\n\nSee test/test.js for usage example.\n\nCredits\n-------\n\n* Uses scrypt.c written by Colin Percival\n* [Neisklar](https://github.com/Neisklar/quarkcoin-hash-python) for the python module this is based off of\n", "release_dates": []}, {"name": "oclif", "description": "Node.js Open CLI Framework. Built by Salesforce.", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "\n<img src=\"https://user-images.githubusercontent.com/449385/38243295-e0a47d58-372e-11e8-9bc0-8c02a6f4d2ac.png\" width=\"260\" height=\"73\">\n\n\noclif: Node.JS Open CLI Framework\n=================================\n\n[![Version](https://img.shields.io/npm/v/oclif.svg)](https://npmjs.org/package/oclif)\n[![CircleCI](https://circleci.com/gh/oclif/oclif/tree/main.svg?style=shield)](https://circleci.com/gh/oclif/oclif/tree/main)\n[![Downloads/week](https://img.shields.io/npm/dw/@oclif/command.svg)](https://npmjs.org/package/@oclif/core)\n[![License](https://img.shields.io/npm/l/oclif.svg)](https://github.com/oclif/oclif/blob/main/package.json)\n\n<!-- toc -->\n* [\ud83d\uddd2 Description](#-description)\n* [\ud83d\ude80 Getting Started Tutorial](#-getting-started-tutorial)\n* [\u2728 Features](#-features)\n* [\ud83d\udccc Requirements](#-requirements)\n* [\ud83d\udccc Migrating from V1](#-migrating-from-v1)\n* [\ud83c\udfd7 Usage](#-usage)\n* [\ud83d\udcda Examples](#-examples)\n* [\ud83d\udd28 Commands](#-commands)\n* [\ud83c\udfed Related Repositories](#-related-repositories)\n* [\ud83e\udd94 Learn More](#-learn-more)\n* [\ud83d\udce3 Feedback](#-feedback)\n<!-- tocstop -->\n\n# \ud83d\uddd2 Description\n\nThis is a framework for building CLIs in Node.js. This framework was built out of the [Heroku CLI](https://cli.heroku.com) but generalized to build any custom CLI. It's designed both for single-file CLIs with a few flag options, or for very complex CLIs that have subcommands (like git or heroku).\n\n[See the docs for more information](http://oclif.io/docs/introduction).\n\n# \ud83d\ude80 Getting Started Tutorial\n\nThe [Getting Started tutorial](http://oclif.io/docs/introduction) is a step-by-step guide to introduce you to oclif. If you have not developed anything in a command line before, this tutorial is a great place to get started.\n\n# \u2728 Features\n\n* **Flag/Argument parsing** - No CLI framework would be complete without a flag parser. We've built a custom one from years of experimentation that we feel consistently handles user input flexible enough for the user to be able to use the CLI in ways they expect, but without compromising strictness guarantees to the developer.\n* **Super Speed** - The overhead for running an oclif CLI command is almost nothing. [It requires very few dependencies](https://www.npmjs.com/package/@oclif/command?activeTab=dependencies) (only 35 dependencies in a minimal setup\u2014including all transitive dependencies). Also, only the command to be executed will be required with node. So large CLIs with many commands will load equally as fast as a small one with a single command.\n* **CLI Generator** - Run a single command to scaffold out a fully functional CLI and get started quickly. See [Usage](#-usage) below.\n* **Testing Helpers** - We've put a lot of work into making commands easier to test and mock out stdout/stderr. The generator will automatically create [scaffolded tests](https://github.com/oclif/hello-world/blob/main/test/commands/hello.test.ts).\n* **Auto-documentation** - By default you can pass `--help` to the CLI to get help such as flag options and argument information. This information is also automatically placed in the README whenever the npm package of the CLI is published. See the [multi-command CLI example](https://github.com/oclif/example-multi-ts)\n* **Plugins** - Using [plugins](https://oclif.io/docs/plugins), users of the CLI can extend it with new functionality, a CLI can be split into modular components, and functionality can be shared amongst multiple CLIs. See [Building your own plugin](https://oclif.io/docs/plugins#building-your-own-plugin).\n* **Hooks** - Use lifecycle hooks to run functionality any time a CLI starts, or on custom triggers. Use this whenever custom functionality needs to be shared between various components of the CLI.\n* **TypeScript** - Everything in the core of oclif is written in TypeScript and the generator will build fully configured TypeScript CLIs. If you use plugins support, the CLI will automatically use `ts-node` to run the plugins enabling you to use TypeScript with minimal-to-no boilerplate needed for any oclif CLI.\n* **Auto-updating Installers** - oclif can package your CLI into [different installers](https://oclif.io/docs/releasing) that will not require the user to already have node installed on the machine. These can be made auto-updatable by using [plugin-update](https://github.com/oclif/plugin-update).\n* **Everything is Customizable** - Pretty much anything can be swapped out and replaced inside oclif if needed\u2014including the arg/flag parser.\n* **Autocomplete** - Automatically include autocomplete for your CLI. This includes not only command names and flag names, but flag values as well. For example, it's possible to configure the Heroku CLI to have completions for Heroku app names:\n\n```\n$ heroku info --app=<tab><tab> # will complete with all the Heroku apps a user has in their account\n```\n\n# \ud83d\udccc Requirements\n\nCurrently, Node 12+ is supported. We support the [LTS versions](https://nodejs.org/en/about/releases) of Node. You can add the [node](https://www.npmjs.com/package/node) package to your CLI to ensure users are running a specific version of Node.\n\n# \ud83d\udccc Migrating from V1\n\nIf you have been using version 1 of the [`oclif` CLI](https://github.com/oclif/oclif/tree/v1.18.4) there are some important differences to note when using the latest version.\n\n## Breaking Changes\n\n- `oclif multi`, `oclif plugin`, and `oclif single` have all been removed in favor of `oclif generate`, which generates an oclif based CLI using the [hello-world example repo](https://github.com/oclif/hello-world).\n  - The reason is that there's not enough of a meaningful difference between a \"multi command cli\", a \"single command cli\", and a \"plugin\" to justify the maintenance cost. The generated CLI can be easily used for any of those use cases.\n- `oclif hook` is now `oclif generate:hook`\n- `oclif command` is now `oclif generate:command`\n\n## New Commands\n\nVersion 2 now includes all the commands from the [`oclif-dev` CLI](https://github.com/oclif/dev-cli). This means that you can now use a single CLI for all your oclif needs. These commands include:\n- `oclif manifest`\n- `oclif pack`\n- `oclif pack:deb`\n- `oclif pack:macos`\n- `oclif pack:win`\n- `oclif upload` (formerly known as `oclif-dev publish`)\n- `oclif upload:deb` (formerly known as `oclif-dev publish:deb`)\n- `oclif upload:macos` (formerly known as `oclif-dev publish:macos`)\n- `oclif upload:win` (formerly known as `oclif-dev publish:win`)\n- `oclif readme`\n\n\n# \ud83c\udfd7 Usage\n\nCreating a CLI:\n\n```sh-session\n$ npx oclif generate mynewcli\n? npm package name (mynewcli): mynewcli\n$ cd mynewcli\n$ ./bin/run --version\nmynewcli/0.0.0 darwin-x64 node-v9.5.0\n$ ./bin/run --help\nUSAGE\n  $ mynewcli [COMMAND]\n\nCOMMANDS\n  hello\n  help   display help for mynewcli\n\n$ ./bin/run hello\nhello world from ./src/hello.js!\n```\n\n# \ud83d\udcda Examples\n\n* [Hello-World](https://github.com/oclif/hello-world)\n* [Salesforce CLI](https://github.com/salesforcecli/cli)\n* [Heroku CLI](https://github.com/heroku/cli)\n\n# \ud83d\udd28 Commands\n\n<!-- commands -->\n* [`oclif generate NAME`](#oclif-generate-name)\n* [`oclif generate command NAME`](#oclif-generate-command-name)\n* [`oclif generate hook NAME`](#oclif-generate-hook-name)\n* [`oclif help [COMMAND]`](#oclif-help-command)\n* [`oclif manifest [PATH]`](#oclif-manifest-path)\n* [`oclif pack deb`](#oclif-pack-deb)\n* [`oclif pack macos`](#oclif-pack-macos)\n* [`oclif pack tarballs`](#oclif-pack-tarballs)\n* [`oclif pack win`](#oclif-pack-win)\n* [`oclif promote`](#oclif-promote)\n* [`oclif readme`](#oclif-readme)\n* [`oclif upload deb`](#oclif-upload-deb)\n* [`oclif upload macos`](#oclif-upload-macos)\n* [`oclif upload tarballs`](#oclif-upload-tarballs)\n* [`oclif upload win`](#oclif-upload-win)\n\n## `oclif generate NAME`\n\ngenerate a new CLI\n\n```\nUSAGE\n  $ oclif generate [NAME]\n\nARGUMENTS\n  NAME  directory name of new project\n\nDESCRIPTION\n  generate a new CLI\n\n  This will clone the template repo 'oclif/hello-world' and update package properties\n```\n\n_See code: [src/commands/generate.ts](https://github.com/oclif/oclif/blob/v3.2.1/src/commands/generate.ts)_\n\n## `oclif generate command NAME`\n\nadd a command to an existing CLI or plugin\n\n```\nUSAGE\n  $ oclif generate command [NAME] [--force]\n\nARGUMENTS\n  NAME  name of command\n\nFLAGS\n  --force  overwrite existing files\n\nDESCRIPTION\n  add a command to an existing CLI or plugin\n```\n\n## `oclif generate hook NAME`\n\nadd a hook to an existing CLI or plugin\n\n```\nUSAGE\n  $ oclif generate hook [NAME] [--force] [--event <value>]\n\nARGUMENTS\n  NAME  name of hook (snake_case)\n\nFLAGS\n  --event=<value>  [default: init] event to run hook on\n  --force          overwrite existing files\n\nDESCRIPTION\n  add a hook to an existing CLI or plugin\n```\n\n## `oclif help [COMMAND]`\n\nDisplay help for oclif.\n\n```\nUSAGE\n  $ oclif help [COMMAND] [-n]\n\nARGUMENTS\n  COMMAND  Command to show help for.\n\nFLAGS\n  -n, --nested-commands  Include all nested commands in the output.\n\nDESCRIPTION\n  Display help for oclif.\n```\n\n_See code: [@oclif/plugin-help](https://github.com/oclif/plugin-help/blob/v5.1.12/src/commands/help.ts)_\n\n## `oclif manifest [PATH]`\n\ngenerates plugin manifest json\n\n```\nUSAGE\n  $ oclif manifest [PATH]\n\nARGUMENTS\n  PATH  [default: .] path to plugin\n\nDESCRIPTION\n  generates plugin manifest json\n```\n\n_See code: [src/commands/manifest.ts](https://github.com/oclif/oclif/blob/v3.2.1/src/commands/manifest.ts)_\n\n## `oclif pack deb`\n\npack CLI into debian package\n\n```\nUSAGE\n  $ oclif pack deb -r <value> [-t <value>]\n\nFLAGS\n  -r, --root=<value>     (required) [default: .] path to oclif CLI root\n  -t, --tarball=<value>  optionally specify a path to a tarball already generated by NPM\n\nDESCRIPTION\n  pack CLI into debian package\n```\n\n## `oclif pack macos`\n\npack CLI into macOS .pkg\n\n```\nUSAGE\n  $ oclif pack macos -r <value> [-t <value>]\n\nFLAGS\n  -r, --root=<value>     (required) [default: .] path to oclif CLI root\n  -t, --tarball=<value>  optionally specify a path to a tarball already generated by NPM\n\nDESCRIPTION\n  pack CLI into macOS .pkg\n```\n\n## `oclif pack tarballs`\n\npackages oclif CLI into tarballs\n\n```\nUSAGE\n  $ oclif pack tarballs -r <value> [-t <value>] [--xz] [--parallel] [-l <value>]\n\nFLAGS\n  -l, --tarball=<value>  optionally specify a path to a tarball already generated by NPM\n  -r, --root=<value>     (required) [default: .] path to oclif CLI root\n  -t, --targets=<value>  comma-separated targets to pack (e.g.: linux-arm,win32-x64)\n  --parallel             build tarballs in parallel\n  --[no-]xz              also build xz\n\nDESCRIPTION\n  packages oclif CLI into tarballs\n\n  This can be used to create oclif CLIs that use the system node or that come preloaded with a node binary.\n```\n\n## `oclif pack win`\n\ncreate windows installer from oclif CLI\n\n```\nUSAGE\n  $ oclif pack win -r <value> [-t <value>]\n\nFLAGS\n  -r, --root=<value>     (required) [default: .] path to oclif CLI root\n  -t, --tarball=<value>  optionally specify a path to a tarball already generated by NPM\n\nDESCRIPTION\n  create windows installer from oclif CLI\n\n  This command requires WINDOWS_SIGNING (prefixed with the name of your executable, e.g. OCLIF_WINDOWS_SIGNING_PASS) to\n  be set in the environment\n```\n\n## `oclif promote`\n\npromote CLI builds to a S3 release channel\n\n```\nUSAGE\n  $ oclif promote -r <value> --version <value> --sha <value> --channel <value> [-t <value>] [-d] [-m] [-w]\n    [-a <value>] [--xz] [--indexes]\n\nFLAGS\n  -a, --max-age=<value>  [default: 86400] cache control max-age in seconds\n  -d, --deb              promote debian artifacts\n  -m, --macos            promote macOS pkg\n  -r, --root=<value>     (required) [default: .] path to the oclif CLI project root\n  -t, --targets=<value>  comma-separated targets to promote (e.g.: linux-arm,win32-x64)\n  -w, --win              promote Windows exe\n  --channel=<value>      (required) [default: stable] which channel to promote to\n  --indexes              append the promoted urls into the index files\n  --sha=<value>          (required) 7-digit short git commit SHA of the CLI to promote\n  --version=<value>      (required) semantic version of the CLI to promote\n  --[no-]xz              also upload xz\n\nDESCRIPTION\n  promote CLI builds to a S3 release channel\n```\n\n_See code: [src/commands/promote.ts](https://github.com/oclif/oclif/blob/v3.2.1/src/commands/promote.ts)_\n\n## `oclif readme`\n\nadds commands to README.md in current directory\n\n```\nUSAGE\n  $ oclif readme --dir <value> [--multi] [--aliases]\n\nFLAGS\n  --[no-]aliases  include aliases in the command list\n  --dir=<value>   (required) [default: docs] output directory for multi docs\n  --multi         create a different markdown page for each topic\n\nDESCRIPTION\n  adds commands to README.md in current directory\n\n  The readme must have any of the following tags inside of it for it to be replaced or else it will do nothing:\n\n  # Usage\n\n  <!-- usage -->\n\n  # Commands\n\n  <!-- commands -->\n\n  Customize the code URL prefix by setting oclif.repositoryPrefix in package.json.\n```\n\n_See code: [src/commands/readme.ts](https://github.com/oclif/oclif/blob/v3.2.1/src/commands/readme.ts)_\n\n## `oclif upload deb`\n\nupload deb package built with pack:deb\n\n```\nUSAGE\n  $ oclif upload deb -r <value>\n\nFLAGS\n  -r, --root=<value>  (required) [default: .] path to oclif CLI root\n\nDESCRIPTION\n  upload deb package built with pack:deb\n```\n\n## `oclif upload macos`\n\nupload macos installers built with pack:macos\n\n```\nUSAGE\n  $ oclif upload macos -r <value>\n\nFLAGS\n  -r, --root=<value>  (required) [default: .] path to oclif CLI root\n\nDESCRIPTION\n  upload macos installers built with pack:macos\n```\n\n## `oclif upload tarballs`\n\nupload an oclif CLI to S3\n\n```\nUSAGE\n  $ oclif upload tarballs -r <value> [-t <value>] [--xz]\n\nFLAGS\n  -r, --root=<value>     (required) [default: .] path to oclif CLI root\n  -t, --targets=<value>  comma-separated targets to upload (e.g.: linux-arm,win32-x64)\n  --[no-]xz              also upload xz\n\nDESCRIPTION\n  upload an oclif CLI to S3\n\n  \"aws-sdk\" will need to be installed as a devDependency to upload.\n```\n\n## `oclif upload win`\n\nupload windows installers built with pack:win\n\n```\nUSAGE\n  $ oclif upload win -r <value>\n\nFLAGS\n  -r, --root=<value>  (required) [default: .] path to oclif CLI root\n\nDESCRIPTION\n  upload windows installers built with pack:win\n```\n<!-- commandsstop -->\n\n# \ud83c\udfed Related Repositories\n\n* [@oclif/core](https://github.com/oclif/core) - Base library for oclif. This can be used directly without the generator.\n* [@oclif/cli-ux](https://github.com/oclif/cli-ux) - Library for common CLI UI utilities.\n* [@oclif/test](https://github.com/oclif/test) - Test helper for oclif.\n\n# \ud83e\udd94 Learn More\n\n* [Salesforce Release Announcement](https://engineering.salesforce.com/open-sourcing-oclif-the-cli-framework-that-powers-our-clis-21fbda99d33a)\n* [Heroku Release Announcement](https://blog.heroku.com/open-cli-framework)\n\n# \ud83d\udce3 Feedback\n\nIf you have any suggestions or want to let us know what you think of oclif, send us a message at <alm-cli@salesforce.com>\n", "release_dates": []}, {"name": "p2pool-dash", "description": null, "language": "Python", "license": {"key": "gpl-3.0", "name": "GNU General Public License v3.0", "spdx_id": "GPL-3.0", "url": "https://api.github.com/licenses/gpl-3.0", "node_id": "MDc6TGljZW5zZTk="}, "readme": "Requirements:\n-------------------------\nGeneric:\n\n* Dashd >=0.18.0.0\n* Python >=2.7\n* Twisted >=13.0.0\n* Zope.interface >=3.8.0\n* pycrypto >= 2.6.1\n\nLinux:\n\n    sudo apt-get install python2 python2-dev python2-twisted python2-pip-whl python2-setuptools-whl\n    sudo apt-get install gcc g++\n\nInstall Python modules:\n-------------------------\nDownload the required submodules:\n\n    git submodule init\n    git submodule update\n\ndash_hash:\n\n    cd dash_hash\n    python setup.py install --user\n\nRunning P2Pool:\n-------------------------\nTo use P2Pool, you must be running your own local dashd. For standard\nconfigurations, using P2Pool should be as simple as:\n\n    python run_p2pool.py\n\nThen run your miner program, connecting to 127.0.0.1 on port 7903 with any\nusername and password.\n\nIf you are behind a NAT, you should enable TCP port forwarding on your\nrouter. Forward port 9998 to the host running P2Pool.\n\nRun for additional options.\n\n    python run_p2pool.py --help\n\nOfficial wiki :\n-------------------------\nhttps://en.bitcoin.it/wiki/P2Pool\n\nAlternate web front end :\n-------------------------\n* https://github.com/hardcpp/P2PoolExtendedFrontEnd\n* https://github.com/johndoe75/p2pool-node-status\n* https://github.com/justino/p2pool-ui-punchy\n\nSponsors:\n-------------------------\n\nThanks to:\n* The Bitcoin Foundation for its generous support of P2Pool\n* The Litecoin Project for its generous donations to P2Pool\n* The Vertcoin Community for its great contribution to P2Pool\n* jakehaas, vertoe, chaeplin, dstorm, poiuty, elbereth  and mr.slaveg from the Darkcoin/Dash Community\n", "release_dates": []}, {"name": "packster", "description": "A tool for working with dependency grapghs in a monorepository", "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Packster\n\n<a href='https://www.npmjs.com/package/packster' target='_blank'><img src='https://img.shields.io/npm/v/packster' alt='NPM Version' /></a>\n\nDescription\n\n### The key advantages of this library:\n\n- Some cool feature\n\n## Usage\n\n### Available commands\n\n#### list\n\nLists dependents of a certain package\n\n#### check\n\nChecks that all packages use local package as a dependency\n\nOptions:\n\n- `--all`: Check all packages in the repository\n- `--json`: Serialize output to json\n- `--error`: Exit process with status 1 instead of just printing version conflicts.\nUseful in CI\n- `--workspace`: Check dependents of a specific workspace. You can specify\n`--workspace` multiple times. Conflicts with `--all`\n\n#### fix\n\nMake all packages that do not use local package as a dependency to use it\n\nOptions:\n\n- `--all`: Fix versions for all packages in the repository\n- `--workspace`: Fix dependents of a specific workspace. You can specify\n  `--workspace` multiple times. Conflicts with `--all`\n- `--dedupe`: Run dedupe after fixing version conflicts\n\n#### run\n\nUsage: `packster run test`\n\nOptions: \n\n- `--workspace`: Run the command in a specific workspace. You can specify\n  `--workspace`: multiple times. Conflicts with `--all`\n- `--all`: Run the command in all workspaces\n- `--except`: Run the command in all workspaces except for specified packages. \nYou can specify `--except` multiple times. Conflicts with `--workspace`\n- `--interrupt`: Fail on the first encountered error \n\n#### workspaces\n\nList all packages in the repository\n\n#### \n\n## Contributing\n\nEveryone is welcome to contribute in any way or form! For the further details, please read [CONTRIBUTING.md](./CONTRIBUTING.md)\n\n## Authors\n- [Anton Suprunchuk](https://github.com/antouhou) - [Website](https://antouhou.com)\n\nSee also the list of contributors who participated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](./LICENSE.md) file for details\n", "release_dates": ["2021-11-02T10:34:27Z"]}, {"name": "paper.dash.org", "description": "JavaScript Client-Side Dash Wallet Generator", "language": "HTML", "license": null, "readme": "# paper.dash.org\nJavaScript Client-Side Dash Wallet Generator\n\nNow Dash addresses and their corresponding private key can be conveniently\ngenerated in a web browser.\n\n## Installation\n\n1. Install dependencies for compiling single page application:\n\n    ```bash\n    npm install\n    ```\n\n2. Build the single-page application:\n\n    ```bash\n    npm run build\n    ```\n\n\n## Attribution\n\nBased on bitaddress.org\nJavaScript Client-Side Bitcoin Wallet Generator\n\nThe bitaddress.org project provides an all-in-one HTML document with embedded\nJavaScript/Css/Images. The JavaScript is readable not minified and contains no\nXMLHttpRequest's (no AJAX). The benefit of this technique is you can load the\nJavaScript locally and trust that the JavaScript did not change after being\nloaded.\n\nHere is a link to the BitcoinTalk.org forum topic discussing original project:\nhttps://bitcointalk.org/index.php?topic=43496.0\n\n\nPlease send DONATIONS for original project to Bitcoin Address:\n1NiNja1bUmhSoTXozBRBEtR8LeF9TGbZBN\n\n\nEND USER NOTES:\n\n 1) For Bulk Wallet I recommended using Google Chrome, it's the fastest.\n\n 2) Requires IE9+, Firefox, Chrome or sufficient JavaScript support.\n\n 3) Mobile Safari only works with iPhone4 or newer devices.\n    Older devices timeout while executing JavaScript.\n\n 4) DO NOT use Opera Mini it renders JavaScript output server side, therefore\n    they might record the private key you generated.\n\n 5) BIP38 most likely will not work on mobile devices due to hardware limitations.\n\n\nNotice of Copyrights and Licenses:\n---------------------------------------\nThe paper.dash.org project, software and embedded resources are\ncopyright The Dash Developers.\n\nThe paper.dash.org name, Dash name and logo are not part of the open source\nlicense.\n\nThe bitaddress.org project, software and embedded resources are\ncopyright bitaddress.org.\n\nThe bitaddress.org name and logo are not part of the open source\nlicense.\n\nPortions of the all-in-one HTML document contain JavaScript codes that\nare the copyrights of others. The individual copyrights are included\nthroughout the document along with their licenses. Included JavaScript\nlibraries are separated with HTML script tags.\n\nSummary of JavaScript functions with a redistributable license:\n\nJavaScript function  | License\n-------------------  | --------------\nArray.prototype.map  | Public Domain\nwindow.Crypto        | BSD License\nwindow.SecureRandom  | BSD License\nwindow.EllipticCurve | BSD License\nwindow.BigInteger    | BSD License\nwindow.QRCode        | MIT License\nwindow.Bitcoin       | MIT License\n\nThe bitaddress.org software is available under The MIT License (MIT)\nCopyright (c) 2011-2013 bitaddress.org\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n", "release_dates": ["2016-04-08T07:40:42Z"]}, {"name": "platform", "description": "L2 solution for seriously fast decentralized applications for the Dash network ", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": ": <!-- markdownlint-disable MD033 MD041 -->\n<p align=\"center\">\n  <a href=\"https://dashplatform.readme.io/docs/introduction-what-is-dash-platform/\">\n    <img alt=\"babel\" src=\"https://media.dash.org/wp-content/uploads/dash_digital-cash_logo_2018_rgb_for_screens.png\" width=\"546\">\n  </a>\n</p>\n\n<p align=\"center\">\n  Seriously fast decentralized applications for the Dash network\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/dashpay/platform/actions/workflows/all-packages.yml\"><img alt=\"GitHub CI Status\" src=\"https://github.com/dashpay/platform/actions/workflows/all-packages.yml/badge.svg\"></a>\n  <a href=\"https://chat.dashdevs.org/\"><img alt=\"Devs Chat\" src=\"https://img.shields.io/badge/discord-Dev_chat-738adb\"></a>\n  <a href=\"https://discordapp.com/invite/PXbUxJB\"><img alt=\"General Chat\" src=\"https://img.shields.io/badge/discord-General_chat-738adb\"></a>\n  <a href=\"https://twitter.com/intent/follow?screen_name=Dashpay\"><img alt=\"Follow on Twitter\" src=\"https://img.shields.io/twitter/follow/Dashpay.svg?style=social&label=Follow\"></a>\n</p>\n\nDash Platform is a technology stack for building decentralized applications on\nthe Dash network. The two main architectural components, Drive and DAPI, turn\nthe Dash P2P network into a cloud that developers can integrate with their\napplications.\n\nIf you are looking for how to contribute to the project or need any help with\nbuilding an app on the Dash Platform - message us on the [Devs\nDiscord](https://chat.dashdevs.org/)!\n\n## Note: Dash Platform is currently available on the Dash Testnet only\n\n## Intro\n\nThis is a multi-package repository - sometimes also known as monorepository -\nthat contains all packages that comprise the Dash platform - for example, Drive,\nwhich is the storage component of Dash Platform, the JavaScript SDK, wallet-lib,\nDAPI, and others. Every individual package contains its own readme. Packages are\nlocated in the [packages](./packages) directory.\n\n### Supported networks\n\nDash Platform is currently undergoing testing and final development necessary to\nsupport its release on the Dash production network (mainnet). The packages in\nthis repository may be used on the following networks:\n\n- [x] **Development networks** ([**devnets**](https://dashplatform.readme.io/docs/reference-glossary#devnet))\n- [x] [**Testnet**](https://dashplatform.readme.io/docs/reference-glossary#testnet)\n- [ ] [Mainnet](https://dashplatform.readme.io/docs/reference-glossary#mainnet)\n\n## FAQ\n\n### How to build and set up a node from the code in this repo?\n\n- Clone the repo\n- Install prerequisites:\n  - [node.js](https://nodejs.org/) v20\n  - [docker](https://docs.docker.com/get-docker/) v20.10+\n  - [rust](https://www.rust-lang.org/tools/install) v1.73+, with wasm32 target (`rustup target add wasm32-unknown-unknown`)\n  - [protoc - protobuf compiler](https://github.com/protocolbuffers/protobuf/releases) v25.2+\n    - if needed, set PROTOC environment variable to location of `protoc` binary\n  - [wasm-bingen toolchain](https://rustwasm.github.io/wasm-bindgen/):\n    - **IMPORTANT (OSX only)**: built-in `llvm` on OSX does not work, needs to be installed from brew:\n      - `brew install llvm`\n      - LLVM installed from brew is keg only, and path to it must be provided in the profile file,\n        in terminal run `echo 'export PATH=\"/opt/homebrew/opt/llvm/bin:$PATH\"' >> ~/.zshrc` or `echo 'export PATH=\"/opt/homebrew/opt/llvm/bin:$PATH\"' >> ~/.bash_profile` depending on your default shell.\n        You can find your default shell with `echo $SHELL`\n      - Reload your shell with `source ~/.zshrc` or `source ~/.bash_profile`\n    - `cargo install wasm-bindgen-cli@0.2.85`\n      - *double-check that wasm-bindgen-cli version above matches wasm-bindgen version in Cargo.lock file*\n      - *Depending on system, additional packages may need to be installed as a prerequisite for wasm-bindgen-cli. If anything is missing, installation will error and prompt what packages are missing (i.e. clang, llvm, libssl-dev)*\n  - essential build tools - example for Debian/Ubuntu: `apt install -y build-essential libssl-dev pkg-config clang`\n- Run `corepack enable` to enable [corepack](https://nodejs.org/dist/latest/docs/api/corepack.html) and install yarn\n- Run `yarn setup` to install dependencies and configure and build all packages\n- Run `yarn start` to start the local dev environment built from the sources\n- Run `yarn test` to run the whole test suite (note that running tests requires a running node,\n so be sure to call `yarn start` first). Alternatively, you can run tests for a specific\n package by running `yarn workspace <package_name> test`, for example running\n `yarn workspace @dashevo/dapi-client test` will run tests for the JS DAPI client. To see\n all available packages, please see the [packages readme](./packages/README.md)\n- `yarn stop` will stop the local dev environment. Running a dev environment requires a non-trivial amount of system resources,\n so it is best to stop the local node when not in use\n- Run `yarn build` to rebuild the project after changes. If you have a local node\n running, you may need to restart it by running `yarn restart`\n- To completely reset all local data and builds, run `yarn reset`\n\n### Looking for support?\n\nFor questions and support, please join our [Devs\nDiscord](https://chat.dashdevs.org/)\n\n### Where are the docs?\n\nOur docs are hosted on\n[readme.io](https://dashplatform.readme.io/docs/introduction-what-is-dash-platform).\nYou can create issues and feature requests in the\n[issues](https://github.com/dashpay/platform/issues) for this repository.\n\n### Want to report a bug or request a feature?\n\nPlease read through our [CONTRIBUTING.md](CONTRIBUTING.md) and fill out the\nissue template at [platform/issues](https://github.com/dashpay/platform/issues)!\n\n### Want to contribute to Dash Platform?\n\nCheck out:\n\n- Our [Developers Discord](https://chat.dashdevs.org/)\n- Our [CONTRIBUTING.md](CONTRIBUTING.md) to get started with setting up the\n  repo.\n- Our [news](https://www.dash.org/news/) and [blog](https://www.dash.org/blog/) which contains release posts and\n  explanations.\n\n## License\n\n[MIT](LICENSE.md)\n", "release_dates": ["2024-02-27T19:08:29Z", "2024-02-27T10:26:15Z", "2024-02-27T02:27:29Z", "2024-02-21T13:12:35Z", "2024-02-20T15:36:48Z", "2024-02-16T09:55:46Z", "2024-02-15T12:47:10Z", "2024-02-14T16:48:22Z", "2024-02-13T14:00:31Z", "2024-02-12T10:57:09Z", "2024-02-07T11:45:08Z", "2024-01-27T19:06:32Z", "2024-01-27T10:14:22Z", "2024-01-27T02:22:35Z", "2024-01-27T02:07:12Z", "2024-01-27T01:09:19Z", "2024-01-26T16:56:42Z", "2024-01-25T21:49:12Z", "2024-01-24T21:34:16Z", "2024-01-24T20:24:04Z", "2024-01-24T20:08:14Z", "2024-01-19T11:36:39Z", "2024-01-16T16:35:43Z", "2024-01-12T17:02:50Z", "2024-01-11T05:02:58Z", "2023-12-28T16:51:03Z", "2023-12-21T12:26:02Z", "2023-12-19T17:05:38Z", "2023-12-12T12:16:46Z", "2023-12-11T17:12:45Z"]}, {"name": "platform-tutorials", "description": "Code for the tutorials found on https://docs.dash.org/platform", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# platform-readme-tutorials\n\n[![SDK Version](https://img.shields.io/github/package-json/dependency-version/dashpay/platform-readme-tutorials/dash)](https://github.com/dashpay/platform-readme-tutorials/blob/main/package.json)\n\nCode for the tutorials found on the\n[Platform documentation site](https://docs.dash.org/platform).\n\n## Install\n\nNote: [NodeJS](https://nodejs.org/en/download/) (v18+) must be installed to run\nthe tutorial code.\n\n### Clone this repository\n\n```shell\ngit clone https://github.com/dashpay/platform-readme-tutorials.git\n```\n\n### Install project dependencies\n\nDo a clean install of project dependencies:\n\n```shell\nnpm ci\n```\n\n## Usage\n\n1. Create an `.env` file (See [`.env.example`](./.env.example) for an example\n   `.env` file). Set `NETWORK` to the desired network type (normally 'testnet').\n1. Check connection: `node connect.js`\n1. Create wallet: `node create-wallet.js`\n1. Go to the [Testnet faucet](https://testnet-faucet.dash.org/) and add funds to\n   the address reported in the previous step\n1. Open the `.env` file (See [`.env.example`](./.env.example) for an example\n   `.env` file) and set `MNEMONIC` to the wallet mnemonic from step 3.\n\nProceed with the tutorials\n[Identities and Names tutorials](./1-Identities-and-Names/) first and the\n[Contracts And Documents tutorials](./2-Contracts-and-Documents/) next. They\nalign with the tutorials section found on the\n[documentation site](https://dashplatform.readme.io/docs/tutorials-introduction).\n\nAfter [creating an identity](./1-Identities-and-Names/identity-register.js), set\nthe `IDENTITY_ID` value in your `.env` file to your new identity ID. After\n[registering a data contract](./2-Contracts-and-Documents/contract-register-minimal.js),\nset the `CONTRACT_ID` value in your `.env` file to your new contract ID. To do\ncredit transfers between identities, create a second identity and set the\n`RECIPIENT_ID` value in your `.env` file to its ID.\n\n## Contributing\n\nPRs accepted.\n\n## License\n\n[MIT](LICENSE.md)\n", "release_dates": ["2024-02-22T18:37:56Z", "2024-02-22T18:37:30Z", "2023-12-12T21:19:22Z", "2023-12-12T21:17:37Z", "2023-07-20T13:58:41Z", "2023-05-17T14:41:54Z", "2022-12-20T15:29:57Z"]}, {"name": "proposal-generator", "description": "Dash Client-Side Governance Proposal Generator", "language": "JavaScript", "license": null, "readme": "# Dash Proposal Generator\n\n[![Build Status](https://travis-ci.org/dashevo/proposal-generator.svg?branch=master)](https://travis-ci.org/dashevo/proposal-generator)\n\n## Get Started\n\nBefore being able to use this repository, you will need to build the @dashevo/dashcore-lib for browser which is a required dependency. This can be done easily by running:\n\n```\nnpm install\nnpm run build\n```\n\nYou will find in the vendor folder the file index.js which index.html reference. This file handle a browserified version of @dashevo/dashcore-lib aswell as some inner logic that you can find in \"js/index.js\".\n\n## Dockerized\n\nA Dockerfile has been included in order to build the site deterministically, as well as a script to run the Docker site build, and place the resulting artifacts in the `dist/` directory. To run the full Dockerized build, run this script:\n\n```\nbash scripts/build.sh\n```\n", "release_dates": []}, {"name": "relic", "description": "Code", "language": "C", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "![](https://github.com/relic-toolkit/relic/blob/master/art/rlc_logo.png)\n=====\n\n[![Project stats](https://www.openhub.net/p/relic-toolkit/widgets/project_thin_badge.gif)](https://www.openhub.net/p/relic-toolkit)\n[![Build Status](https://travis-ci.org/relic-toolkit/relic.svg?branch=master)](https://travis-ci.org/relic-toolkit/relic)\n[![Code Quality: Cpp](https://img.shields.io/lgtm/grade/cpp/g/relic-toolkit/relic.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/relic-toolkit/relic/context:cpp)\n[![Total Alerts](https://img.shields.io/lgtm/alerts/g/relic-toolkit/relic.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/relic-toolkit/relic/alerts)\n\nRELIC is a modern cryptographic meta-toolkit with emphasis on efficiency and flexibility. RELIC can be used to build efficient and usable cryptographic toolkits tailored for specific security levels and algorithmic choices.\n\n### Goals\n\nRELIC is an ongoing project and features will be added on demand. The focus is to provide:\n\n * Ease of portability and inclusion of architecture-dependent code\n * Simple experimentation with alternative implementations\n * Tests and benchmarks for every implemented function\n * Flexible configuration\n * Maximum efficiency\n\n### Algorithms\n\nRELIC implements to date:\n\n * Multiple-precision integer arithmetic\n * Prime and Binary field arithmetic\n * Elliptic curves over prime and binary fields (NIST curves and pairing-friendly curves)\n * Bilinear maps and related extension fields\n * Cryptographic protocols (RSA, Rabin, ECDSA, ECMQV, ECSS (Schnorr), ECIES, Sakai-Ohgishi-Kasahara ID-based authenticated key agreement, Boneh-Lynn-Schacham and Boneh-Boyen short signatures, Paillier and Benaloh homomorphic encryption systems)\n\n### Citing\n\nIf you use RELIC, please cite using the template below:\n\n    @misc{relic-toolkit,\n        author = {D. F. Aranha and C. P. L. Gouv\u00eaa and T. Markmann and R. S. Wahby and K. Liao},        \n        title = {{RELIC is an Efficient LIbrary for Cryptography}},\n        howpublished = {\\url{https://github.com/relic-toolkit/relic}},\n    }\n\n### Build instructions\n\nInstructions for building the library can be found in the [Wiki](https://github.com/relic-toolkit/relic/wiki/Building).\n\n### Support\n\nYou can probably get some help over the official mailing list at `relic-discuss@googlegroups.com`\n\nIf you like the library, please consider supporting development through [Paypal](https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=R7D6ZE3BLMTF2&lc=BR&item_name=RELIC%20Development&currency_code=USD&bn=PP%2dDonationsBF%3abtn_donateCC_LG%2egif%3aNonHosted).\n\n### Licensing\n\nThis work is dual-licensed under Apache 2.0 and LGPL 2.1-or-above to encourage collaboration with other research groups and contributions from the industry. You can choose between one of them if you use this work.\n\n`SPDX-License-Identifier: Apache-2.0 OR LGPL-2.1`\n\nStarting from version 0.3.3, static linking and changes in the configuration or build system are explicitly exempted from representing derived works. Please refer to the LICENSE files for additional details.\n\n### Disclaimer\n\nRELIC is at most alpha-quality software. Implementations may not be correct or secure and may include patented algorithms. There are *many* configuration options which make the library horribly insecure. Backward API compatibility with early versions may not necessarily be maintained. Use at your own risk.\n", "release_dates": []}, {"name": "rs-bip37-bloom-filter", "description": "A bloom filter in rust that works as defined in BIP37. It will work for Bitcoin, Dash and most projects forked from Bitcoin.", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# rs-dashcore-bloom\nRust Bloom filter implementation for Dash\n", "release_dates": []}, {"name": "rs-drive-explorer", "description": "An explorer for rs-drive.", "language": "Rust", "license": null, "readme": null, "release_dates": []}, {"name": "rs-merk-verify-c-binding", "description": "Merk verification for C and iOS", "language": "Rust", "license": null, "readme": "# rs-merk-verify-c-binding\nMerk verification for C and iOS/MacOS\n\n###### Prerequisites:\n```\ncargo install cargo-lipo\nrustup target add aarch64-apple-ios\nrustup target add x86_64-apple-ios\n```\n\n###### Create universal binary (iOS): \n```\ncargo lipo --release\n```\n\n###### Create MacOS version:\n```\ncargo build --target=x86_64-apple-darwin --release\ncargo build --target=aarch64-apple-darwin --release\nlipo -create target/aarch64-apple-darwin/release/libmerk_ios.a target/x86_64-apple-darwin/release/libmerk_ios.a -output target/universal/release/libmerkMacOS.a\n```\n\nUse from Obj-C with NSData:\nAdd generated merk.h\n\n```obj-c    \nNSData *proofData = ...\n// proof data\nExecuteProofResult *result = execute_proof_c(proofData.bytes, proofData.length);\n// cleanup memory\ndestroy_proof_c(result);\n```\n", "release_dates": []}, {"name": "rs-platform", "description": "Dash Platform (rust components)", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": ["2022-11-24T08:27:55Z", "2022-11-21T15:15:35Z", "2022-11-17T00:59:42Z", "2022-11-16T19:00:19Z", "2022-11-16T22:11:19Z", "2022-11-15T19:11:14Z", "2022-11-14T07:41:08Z", "2022-11-13T19:29:46Z", "2022-11-12T11:55:15Z", "2022-11-11T19:37:42Z", "2022-11-10T21:28:25Z", "2022-11-10T20:35:54Z", "2022-11-10T14:16:04Z", "2022-10-26T13:47:47Z", "2022-10-18T09:26:38Z", "2022-08-08T16:24:29Z", "2022-08-05T12:26:27Z", "2022-07-26T16:24:12Z", "2022-07-26T13:56:49Z", "2022-07-07T15:32:27Z", "2022-07-06T14:59:17Z", "2022-07-06T12:06:41Z", "2022-07-06T08:11:11Z", "2022-06-28T14:02:04Z", "2022-06-27T11:07:38Z", "2022-06-21T14:52:24Z", "2022-06-17T04:43:38Z", "2022-06-16T14:29:53Z", "2022-06-15T01:33:55Z", "2022-06-01T09:43:28Z"]}, {"name": "rs-platform-explorer", "description": "An easy way to interact with Platform from the terminal", "language": "Rust", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": null, "release_dates": []}, {"name": "rs-tenderdash-abci", "description": "Application Blockchain Interface library written in Rust.", "language": "Rust", "license": null, "readme": null, "release_dates": ["2024-02-01T15:07:09Z", "2023-12-20T06:28:57Z", "2023-12-18T17:40:04Z", "2023-10-09T11:10:02Z", "2023-09-13T12:07:23Z", "2023-06-28T14:37:27Z"]}, {"name": "rust-dashcore", "description": "Rust Bitcoin library", "language": "Rust", "license": {"key": "cc0-1.0", "name": "Creative Commons Zero v1.0 Universal", "spdx_id": "CC0-1.0", "url": "https://api.github.com/licenses/cc0-1.0", "node_id": "MDc6TGljZW5zZTY="}, "readme": "<div align=\"center\">\n  <h1>Rust Dash</h1>\n\n  <img alt=\"Rust Dash logo by Rostislav Gorbachenko, UX engineer at Dash Core Group, see license and source files under /logo\" src=\"./logo/rust-dash-together.png\" width=\"300\" />\n\n  <p>Library with support for de/serialization, parsing and executing on data-structures\n    and network messages related to Dash Core payment chain.\n  </p>\n\n  <p>\n    <a href=\"https://crates.io/crates/dash\"><img alt=\"Crate Info\" src=\"https://img.shields.io/crates/v/dash.svg\"/></a>\n    <a href=\"https://github.com/dashevo/rust-dashcore/blob/master/LICENSE\"><img alt=\"MIT or Apache-2.0 Licensed\" src=\"https://img.shields.io/badge/license-MIT%2FApache--2.0-blue.svg\"/></a>\n    <a href=\"https://github.com/dashevo/rust-dashcore/actions?query=workflow%3AContinuous%20integration\"><img alt=\"CI Status\" src=\"https://github.com/dashevo/rust-dashcore/workflows/Continuous%20integration/badge.svg\"></a>\n    <a href=\"https://docs.rs/bitcoin\"><img alt=\"API Docs\" src=\"https://img.shields.io/badge/docs.rs-bitcoin-green\"/></a>\n    <a href=\"https://blog.rust-lang.org/2018/09/13/Rust-1.29.html\"><img alt=\"Rustc Version 1.29+\" src=\"https://img.shields.io/badge/rustc-1.29%2B-lightgrey.svg\"/></a>\n    <img alt=\"Lines of code\" src=\"https://img.shields.io/tokei/lines/github/dashevo/rust-dashcore\">\n  </p>\n</div>\n\n**Heads up for contributors: upcoming edition change**\n\n[Documentation](https://dashcore.readme.io/docs)\n\nSupports (or should support)\n\n* De/serialization of Dash protocol network messages\n* De/serialization of blocks and transactions\n* Script de/serialization\n* Private keys and address creation, de/serialization and validation (including full BIP32 support)\n* PSBT creation, manipulation, merging and finalization\n* Pay-to-contract support as in Appendix A of the [Blockstream sidechains whitepaper](https://www.blockstream.com/sidechains.pdf)\n\nFor JSONRPC interaction with Dash Core, it is recommended to use\n[rust-dashcore-rpc](https://github.com/dashevo/rust-dashcore-rpc).\n\n## Known limitations\n\n### Consensus\n\nThis library **must not** be used for consensus code (i.e. fully validating\nblockchain data). It technically supports doing this, but doing so is very\nill-advised because there are many deviations, known and unknown, between\nthis library and the Dash Core reference implementation. In a consensus\nbased cryptocurrency such as Dash it is critical that all parties are\nusing the same rules to validate data, and this library does not and might \nnever implement the same rules as Core.\n\nGiven the complexity of both C++ and Rust, it is unlikely that this will\never be fixed, and there are no plans to do so. Of course, patches to\nfix specific consensus incompatibilities are welcome.\n\n### Support for 16-bit pointer sizes\n\n16-bit pointer sizes are not supported and we can't promise they will be.\nIt will be dependent on rust-bitcoin implementing them first.\n\n## Documentation\n\nDocumentation can be found on [dashcore.readme.io/docs](https://dashcore.readme.io/docs).\n\n## Contributing\n\nContributions are generally welcome. If you intend to make larger changes please\ndiscuss them in an issue before PRing them to avoid duplicate work and\narchitectural mismatches.\n\n## Minimum Supported Rust Version (MSRV)\n\nThis library should always compile with any combination of features on **Rust 1.60**.\n\n## Installing Rust\n\nRust can be installed using your package manager of choice or\n[rustup.rs](https://rustup.rs). The former way is considered more secure since\nit typically doesn't involve trust in the CA system. But you should be aware\nthat the version of Rust shipped by your distribution might be out of date.\nGenerally this isn't a problem for `rust-bitcoin` since we support much older\nversions than the current stable one (see MSRV section).\n\n## Building\n\nThe library can be built and tested using [`cargo`](https://github.com/rust-lang/cargo/):\n\n```\ngit clone git@github.com:dashpay/rust-dashcore.git\ncd rust-bitcoin\ncargo build\n```\n\nYou can run tests with:\n\n```\ncargo test\n```\n\nPlease refer to the [`cargo` documentation](https://doc.rust-lang.org/stable/cargo/) for more detailed instructions.\n\n## Pull Requests\n\nEvery PR needs at least two reviews to get merged. During the review phase\nmaintainers and contributors are likely to leave comments and request changes.\nPlease try to address them, otherwise your PR might get closed without merging\nafter a longer time of inactivity. If your PR isn't ready for review yet please\nmark it by prefixing the title with `WIP: `.\n\n### CI Pipeline\n\nThe CI pipeline requires approval before being run on each MR.\n\nIn order to speed up the review process the CI pipeline can be run locally using\n[act](https://github.com/nektos/act). The `fuzz` and `Cross` jobs will be\nskipped when using `act` due to caching being unsupported at this time. We do\nnot *actively* support `act` but will merge PRs fixing `act` issues.\n\n\n## Release Notes\n\nSee [CHANGELOG.md](CHANGELOG.md).\n\n\n## Licensing\n\nThe code in this project is licensed under the [Creative Commons CC0 1.0\nUniversal license](LICENSE).\n", "release_dates": []}, {"name": "rust-dashcore-rpc", "description": "Rust RPC client library for the Dash Core JSON-RPC API.", "language": "Rust", "license": null, "readme": "[![Status](https://travis-ci.org/rust-dash/rust-dashcore-rpc.png?branch=master)](https://travis-ci.org/rust-dash/rust-dashcore-rpc)\n\n# Rust RPC client for Dash Core JSON-RPC \n\nThis is a Rust RPC client library for calling the Dash Core JSON-RPC API. It provides a layer of abstraction over \n[rust-jsonrpc](https://github.com/apoelstra/rust-jsonrpc) and makes it easier to talk to the Dash JSON-RPC interface \n\nThis git package compiles into two crates.\n1. [dashcore-rpc](https://crates.io/crates/dashcore-rpc) - contains an implementation of an rpc client that exposes \nthe Dash Core JSON-RPC APIs as rust functions.\n\n2. [dashcore-rpc-json](https://crates.io/crates/dashcore-rpc-json) -  contains rust data structures that represent \nthe json responses from the Dash Core JSON-RPC APIs. dashcore-rpc depends on this.\n\n# Usage\nGiven below is an example of how to connect to the Dash Core JSON-RPC for a Dash Core node running on `localhost`\nand print out the hash of the latest block.\n\nIt assumes that the node has password authentication setup, the RPC interface is enabled at port `8332` and the node\nis set up to accept RPC connections. \n\n```rust\nextern crate dashcore_rpc;\n\nuse dashcore_rpc::{Auth, Client, RpcApi};\n\nfn main() {\n\n    let rpc = Client::new(\n        \"localhost:19998\",\n                          Auth::UserPass(\"<FILL RPC USERNAME>\".to_string(),\n                                         \"<FILL RPC PASSWORD>\".to_string())).unwrap();\n    let best_block_hash = rpc.get_best_block_hash().unwrap();\n    println!(\"best block hash: {}\", best_block_hash);\n}\n```\n\nSee `client/examples/` for more usage examples. \n\n# Supported Dash Core Versions\nThe following versions are officially supported and automatically tested:\n* 0.18.0\n* 0.18.1\n* 0.19.0.1\n* 0.19.1\n* 0.20.0\n* 0.20.1\n* 0.21.0\n\n# Minimum Supported Rust Version (MSRV)\nThis library should always compile with any combination of features on **Rust 1.29**.\n\nBecause some dependencies have broken the build in minor/patch releases, to\ncompile with 1.29.0 you will need to run the following version-pinning command:\n```\ncargo update --package \"cc\" --precise \"1.0.41\"\ncargo update --package \"log:0.4.x\" --precise \"0.4.13\" # x being the highest patch version, currently 14\ncargo update --package \"cfg-if\" --precise \"0.1.9\"\ncargo update --package \"serde_json\" --precise \"1.0.39\"\ncargo update --package \"serde\" --precise \"1.0.98\"\ncargo update --package \"serde_derive\" --precise \"1.0.98\"\ncargo update --package \"byteorder\" --precise \"1.3.4\"\n```\n", "release_dates": ["2024-01-30T10:51:38Z", "2023-09-26T14:14:23Z"]}, {"name": "sentinel", "description": "DashCore Sentinel Engine", "language": "Python", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Dash Sentinel (DEPRECATED)\n\n[![Test Status](https://github.com/dashpay/sentinel/actions/workflows/test.yml/badge.svg)](https://github.com/dashpay/sentinel/actions/workflows/test.yml)\n\n> An automated governance helper for Dash Masternodes.\n\n**Note: Sentinel was [deprecated by Dash Core 20.0](https://github.com/dashpay/dash/blob/v20.0.0/doc/release-notes.md#sentinel-deprecation) which migrated all functionality directly into Dash Core.**\n\nSentinel is an autonomous agent for persisting, processing and automating Dash governance objects and tasks. It is a Python application which runs alongside the DashCore instance on each Dash Masternode.\n\n## Table of Contents\n- [Install](#install)\n  - [Dependencies](#dependencies)\n- [Usage](#usage)\n- [Configuration](#configuration)\n- [Troubleshooting](#troubleshooting)\n- [Maintainer](#maintainer)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Install\n\nThese instructions cover installing Sentinel on Ubuntu 18.04 / 20.04.\n\n### Dependencies\n\nUpdate system package list and install dependencies:\n\n    $ sudo apt-get update\n    $ sudo apt-get -y install git python3 virtualenv\n\nMake sure Python version 3.6.x or above is installed:\n\n    python3 --version\n\nMake sure the local DashCore daemon running is at least version 0.15.0.\n\n    $ dashd --version | head -n1\n\n### Install Sentinel\n\nClone the Sentinel repo and install Python dependencies.\n\n    $ git clone https://github.com/dashpay/sentinel.git && cd sentinel\n    $ virtualenv -p $(which python3) ./venv\n    $ ./venv/bin/pip install -r requirements.txt\n\n## Usage\n\nSentinel is \"used\" as a script called from cron every minute.\n\n### Set up Cron\n\nSet up a crontab entry to call Sentinel every minute:\n\n    $ crontab -e\n\nIn the crontab editor, add the lines below, replacing '/path/to/sentinel' to the path where you cloned sentinel to:\n\n    * * * * * cd /path/to/sentinel && ./venv/bin/python bin/sentinel.py >/dev/null 2>&1\n\n### Test Configuration\n\nTest the config by running tests:\n\n    $ ./venv/bin/py.test ./test\n\nWith all tests passing and crontab setup, Sentinel will stay in sync with dashd and the installation is complete\n\n## Configuration\n\nConfiguration is done via environment variables. Example:\n\n```sh\n$ RPCUSER=dash RPCPASSWORD=password RPCHOST=127.0.0.1 RPCPORT=19998 ./venv/bin/python bin/sentinel.py\n```\n\nA path to a `dash.conf` file can be specified in `sentinel.conf`:\n\n    # warning: deprecated\n    dash_conf=/path/to/dash.conf\n\nThis is now deprecated and will be removed in a future version. Users are encouraged to update their configurations to use environment variables instead.\n\n\n## Troubleshooting\n\nTo view debug output, set the `SENTINEL_DEBUG` environment variable to anything non-zero, then run the script manually:\n\n    $ SENTINEL_DEBUG=1 ./venv/bin/python bin/sentinel.py\n\n## Maintainer\n\n[@nmarley](https://github.com/nmarley)\n\n## Contributing\n\nPlease follow the [DashCore guidelines for contributing](https://github.com/dashpay/dash/blob/master/CONTRIBUTING.md).\n\nSpecifically:\n\n* [Contributor Workflow](https://github.com/dashpay/dash/blob/master/CONTRIBUTING.md#contributor-workflow)\n\n    To contribute a patch, the workflow is as follows:\n\n    * Fork repository\n    * Create topic branch\n    * Commit patches\n\n    In general commits should be atomic and diffs should be easy to read. For this reason do not mix any formatting fixes or code moves with actual code changes.\n\n    Commit messages should be verbose by default, consisting of a short subject line (50 chars max), a blank line and detailed explanatory text as separate paragraph(s); unless the title alone is self-explanatory (like \"Corrected typo in main.cpp\") then a single title line is sufficient. Commit messages should be helpful to people reading your code in the future, so explain the reasoning for your decisions. Further explanation [here](http://chris.beams.io/posts/git-commit/).\n\n### Code Style\n\nPlease use `black` to format code automatically before opening a PR:\n\n```sh\n./venv/bin/black .\n```\n\n## License\n\nReleased under the MIT license, under the same terms as DashCore itself. See [LICENSE](LICENSE) for more info.\n", "release_dates": ["2023-12-05T22:23:41Z", "2023-04-13T13:16:07Z", "2023-04-06T16:53:08Z", "2022-08-17T14:34:02Z", "2022-08-16T18:54:46Z", "2021-05-26T13:57:02Z", "2021-04-27T13:49:55Z"]}, {"name": "tenderdash", "description": "\u27c1 Tenderdash Core (SBFT Consensus) in Go", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Tendermint\n\n![banner](docs/tendermint-core-image.jpg)\n\n[Byzantine-Fault Tolerant](https://en.wikipedia.org/wiki/Byzantine_fault_tolerance)\n[State Machine Replication](https://en.wikipedia.org/wiki/State_machine_replication).\nOr [Blockchain](<https://en.wikipedia.org/wiki/Blockchain_(database)>), for short.\n\n[![version](https://img.shields.io/github/tag/tendermint/tendermint.svg)](https://github.com/dashevo/tenderdash/releases/latest)\n[![API Reference](https://camo.githubusercontent.com/915b7be44ada53c290eb157634330494ebe3e30a/68747470733a2f2f676f646f632e6f72672f6769746875622e636f6d2f676f6c616e672f6764646f3f7374617475732e737667)](https://pkg.go.dev/github.com/tendermint/tendermint)\n[![Go version](https://img.shields.io/badge/go-1.16-blue.svg)](https://github.com/moovweb/gvm)\n[![Discord chat](https://img.shields.io/discord/669268347736686612.svg)](https://discord.gg/AzefAFd)\n[![license](https://img.shields.io/github/license/tendermint/tendermint.svg)](https://github.com/tendermint/tendermint/blob/master/LICENSE)\n[![tendermint/tendermint](https://tokei.rs/b1/github/tendermint/tendermint?category=lines)](https://github.com/tendermint/tendermint)\n[![Sourcegraph](https://sourcegraph.com/github.com/tendermint/tendermint/-/badge.svg)](https://sourcegraph.com/github.com/tendermint/tendermint?badge)\n\n| Branch | Tests                                                                                      | Coverage                                                                                                                             | Linting                                                                    |\n|--------|--------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------|\n| master | ![Tests](https://github.com/tendermint/tendermint/workflows/Tests/badge.svg?branch=master) | [![codecov](https://codecov.io/gh/tendermint/tendermint/branch/master/graph/badge.svg)](https://codecov.io/gh/tendermint/tendermint) | ![Lint](https://github.com/tendermint/tendermint/workflows/Lint/badge.svg) |\n\nTendermint Core is a Byzantine Fault Tolerant (BFT) middleware that takes a state transition machine - written in any programming language - and securely replicates it on many machines.\n\nFor protocol details, refer to the [Tendermint Specification](./spec/README.md).\n\nFor detailed analysis of the consensus protocol, including safety and liveness proofs,\nread our paper, \"[The latest gossip on BFT consensus](https://arxiv.org/abs/1807.04938)\".\n\n## Documentation\n\nComplete documentation can be found on the [website](https://docs.tendermint.com/).\n\n## Releases\n\nPlease do not depend on master as your production branch. Use [releases](https://github.com/tendermint/tendermint/releases) instead.\n\nTendermint has been in the production of private and public environments, most notably the blockchains of the Cosmos Network. we haven't released v1.0 yet since we are making breaking changes to the protocol and the APIs.\nSee below for more details about [versioning](#versioning).\n\nIn any case, if you intend to run Tendermint in production, we're happy to help. You can\ncontact us [over email](mailto:hello@interchain.io) or [join the chat](https://discord.gg/cosmosnetwork).\n\nMore on how releases are conducted can be found [here](./RELEASES.md).\n\n## Security\n\nTo report a security vulnerability, see our [bug bounty\nprogram](https://hackerone.com/cosmos).\nFor examples of the kinds of bugs we're looking for, see [our security policy](SECURITY.md).\n\nWe also maintain a dedicated mailing list for security updates. We will only ever use this mailing list\nto notify you of vulnerabilities and fixes in Tendermint Core. You can subscribe [here](http://eepurl.com/gZ5hQD).\n\nWe also maintain a dedicated mailing list for security updates. We will only ever use this mailing list\nto notify you of vulnerabilities and fixes in Tendermint Core. You can subscribe [here](http://eepurl.com/gZ5hQD).\n\n## Minimum requirements\n\n| Requirement | Notes            |\n|-------------|------------------|\n| Go version  | Go1.22 or higher |\n\n### Install\n\nSee the [install instructions](./docs/introduction/install.md).\n\n### Quick Start\n\n- [Single node](./docs/introduction/quick-start.md)\n- [Local cluster using docker-compose](./docs/tools/docker-compose.md)\n- [Remote cluster using Terraform and Ansible](./docs/tools/terraform-and-ansible.md)\n\n## Contributing\n\nPlease abide by the [Code of Conduct](CODE_OF_CONDUCT.md) in all interactions.\n\nBefore contributing to the project, please take a look at the [contributing guidelines](CONTRIBUTING.md)\nand the [style guide](STYLE_GUIDE.md). You may also find it helpful to read the\n[specifications](./spec/README.md),\nand familiarize yourself with our\n[Architectural Decision Records (ADRs)](./docs/architecture/README.md) and [Request For Comments (RFCs)](./docs/rfc/README.md).\n\n## Versioning\n\n### Semantic Versioning\n\nTendermint uses [Semantic Versioning](http://semver.org/) to determine when and how the version changes.\nAccording to SemVer, anything in the public API can change at any time before version 1.0.0\n\nTo provide some stability to users of 0.X.X versions of Tendermint, the MINOR version is used\nto signal breaking changes across Tendermint's API. This API includes all\npublicly exposed types, functions, and methods in non-internal Go packages as well as\nthe types and methods accessible via the Tendermint RPC interface.\n\nBreaking changes to these public APIs will be documented in the CHANGELOG.\n\n### Upgrades\n\nIn an effort to avoid accumulating technical debt prior to 1.0.0,\nwe do not guarantee that breaking changes (ie. bumps in the MINOR version)\nwill work with existing Tendermint blockchains. In these cases you will\nhave to start a new blockchain, or write something custom to get the old\ndata into the new chain. However, any bump in the PATCH version should be\ncompatible with existing blockchain histories.\n\nFor more information on upgrading, see [UPGRADING.md](./UPGRADING.md).\n\n### Supported Versions\n\nBecause we are a small core team, we only ship patch updates, including security updates,\nto the most recent minor release and the second-most recent minor release. Consequently,\nwe strongly recommend keeping Tendermint up-to-date. Upgrading instructions can be found\nin [UPGRADING.md](./UPGRADING.md).\n\n## Resources\n\n### Roadmap\n\nWe keep a public up-to-date version of our roadmap [here](./docs/roadmap/roadmap.md)\n\n### Libraries\n\n- [Cosmos SDK](http://github.com/cosmos/cosmos-sdk); A framework for building applications in Golang\n- [Tendermint in Rust](https://github.com/informalsystems/tendermint-rs)\n- [ABCI Tower](https://github.com/penumbra-zone/tower-abci)\n\n### Applications\n\n- [Cosmos Hub](https://hub.cosmos.network/)\n- [Terra](https://www.terra.money/)\n- [Celestia](https://celestia.org/)\n- [Anoma](https://anoma.network/)\n- [Vocdoni](https://docs.vocdoni.io/)\n\n### Research\n\n- [The latest gossip on BFT consensus](https://arxiv.org/abs/1807.04938)\n- [Master's Thesis on Tendermint](https://atrium.lib.uoguelph.ca/xmlui/handle/10214/9769)\n- [Original Whitepaper: \"Tendermint: Consensus Without Mining\"](https://tendermint.com/static/docs/tendermint.pdf)\n- [Tendermint Core Blog](https://medium.com/tendermint/tagged/tendermint-core)\n- [Cosmos Blog](https://blog.cosmos.network/tendermint/home)\n\n## Join us\n\nTenderdash is maintained by [Dash Core Group](https://www.dash.org/dcg/).\nIf you'd like to work full-time on Tenderdash, [see our Jobs page](https://www.dash.org/dcg/jobs/).\n\nTendermint Core is maintained by [Interchain GmbH](https://interchain.berlin).\nIf you'd like to work full-time on Tendermint Core, [we're hiring](https://interchain-gmbh.breezy.hr/)!\n\nFunding for Tendermint Core development comes primarily from the [Interchain Foundation](https://interchain.io),\na Swiss non-profit. The Tendermint trademark is owned by [Tendermint Inc.](https://tendermint.com), the for-profit entity\n that also maintains [tendermint.com](https://tendermint.com).\n", "release_dates": ["2024-01-31T11:21:30Z", "2023-12-18T16:43:17Z", "2023-12-11T14:01:46Z", "2023-10-16T15:18:16Z", "2023-10-09T10:00:25Z", "2023-09-14T14:05:33Z", "2023-09-13T11:18:31Z", "2023-07-19T16:12:17Z", "2023-06-29T13:37:43Z", "2023-06-28T12:08:38Z", "2023-05-23T11:52:12Z", "2023-05-03T07:17:07Z", "2023-05-02T18:40:23Z", "2023-04-04T09:05:12Z", "2023-04-04T11:46:39Z", "2023-03-17T12:52:13Z", "2023-02-22T16:46:50Z", "2023-02-22T14:11:01Z", "2023-02-22T12:03:40Z", "2023-02-15T15:34:11Z", "2023-02-15T09:38:33Z", "2023-02-10T13:40:49Z", "2023-01-16T14:59:48Z", "2022-12-20T16:40:13Z", "2022-12-15T16:00:50Z", "2022-12-15T11:49:24Z", "2022-12-07T08:37:43Z", "2022-11-23T09:25:46Z", "2022-11-11T15:05:25Z", "2022-09-09T14:41:44Z"]}, {"name": "thumbor_dash", "description": "A Thumbor server extension for DASH", "language": null, "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# thumbor_dash\nA thumbor server extension for DASH\n\n\n## Setup\n\n#### Requirements\n\n- Python >= 3.9\n- Pip >= 21.1\n- Thumbor == 7.0.0a5\n\nSee the requirements for setting up `thumbor` in the [documentation](https://thumbor.readthedocs.io/en/latest/installing.html)\n\n#### 1. Install thumbor_dash\n\n`pip install thumbor_dash`\n\nNote: thumbor_dash, thumbor, and other required dependencies will be installed\n\n#### 2. Create a thumbor configuration file\n  \n`thumbor-config > thumbor.conf`\n\n#### 3. Add these lines to `thumbor.conf` file\n\n```python\n# Set allowed dimensions\nMIN_WIDTH = 1\nMIN_HEIGHT = 1\nMAX_WIDTH = 1200\nMAX_HEIGHT = 800\n\n# Set security key\nSECURITY_KEY = \"0\"\n\n# Use custom Url signing method (sha256)\nURL_SIGNER = 'thumbor_dash.url_signers.base64_hmac_sha256'\n\n# Allow only signed URL\nALLOW_UNSAFE_URL = False\n\n# Set user moderation rules\nREQUEST_TIME_LIMIT = 1 # time between requests in minutes\nUSAGE_VIOLATION_LIMIT = 5 # total number of times a requester can violate the time limit before ban\nBAN_DURATION = 10 # requester ban duration in minutes\n\n# Use custom error handling\nUSE_CUSTOM_ERROR_HANDLING = True\nERROR_HANDLER_MODULE = 'thumbor_dash.error_handlers.sentry'\n\n# Custom Handler Lists\nHANDLER_LISTS = [\n   'thumbor.handler_lists.healthcheck',\n   'thumbor_dash.handler_lists.upload',\n   'thumbor.handler_lists.blacklist',\n]\n\n```\n\n## Usage\n\n#### 1. Start thumbor_dash server\n\n   `thumbor_dash --conf=thumbor.conf`\n\n#### 2. Sign image URL\n\n   ```python\n\n   thumbor_dash-url --key=\"<SECURITY_KEY>\" --width=<width> --height=<height> --dashauth=\"requester(<requesterId>):contract(<contractId>):document(<documentType>):field(<avatarUrl>):owner(<ownerId>):updatedAt(<updatedAt>)\" --filters=\"<filters>\" <imageURL>\n\n   ```\n\n`output:`\n\n   ```python\n\n   /<signature>/<width>x<height>/dashauth:requester(<requesterId>):contract(<contractId>):document(<documentType>):field(<field>):owner(<ownerId>):updatedAt(<updatedAt>)/filters:format(<format>)/<encodedImageUrl>\n\n   ```\n\n#### 3. Thumbor_dash image retrieval URL\n\n   ```python\n   http://<thumbor_dash-server>/<signature>/<width>x<height>/dashauth:requester(<requesterId>):contract(<contractId>):document(<documentType>):field(<field>):owner(<ownerId>):updatedAt(<updatedAt>)/filters:format(<format>)/<encodedImageUrl>\n   \n   ```\n\n   Note: If running the server locally, `<thumbor_dash-server>` should be `localhost:8888`\n\n\n## Example\n\n This is a signed `thumbor_dash url`. Simply run `thumbor_dash` and paste this link in your browser.\n\n   ```python\n\n   http://localhost:8888/MXd8uDwHf1xqp6YG0RzlkrmtdBaq1ZyzznPLJft1rl4=/1200x800/dashauth:requester(26AxVi5bvYYaC94GmeTmqX21vzsSxar2a4imxSE8ULUQ):contract(D6tjxCZzZobDQztc4S1PK7EDwm4CegLARpiKZn6jQc1R):document(thumbnailField):field(avatarUrl):owner(26AxVi5bvYYaC94GmeTmqX21vzsSxar2a4imxSE8ULUQ):updatedAt(1627948894242)/filters:format(jpeg)/https%3A//github.com/thumbor/thumbor/raw/master/example.jpg\n\n\n   \n   ```\n\n# Running thumbor_dash in Docker\n\nThis is the fastest way to run `thumbor_dash`\n\n#### 1. Create a `thumbor.env.txt` file containing the environment variables\n\n```python\n\nMIN_WIDTH=1\nMIN_HEIGHT=1\nMAX_WIDTH=1200\nMAX_HEIGHT=800\nSECURITY_KEY=0\nREQUEST_TIME_LIMIT=1 \nUSAGE_VIOLATION_LIMIT=5\nBAN_DURATION=10\nUSE_CUSTOM_ERROR_HANDLING=True\nALLOW_UNSAFE_URL=False\nURL_SIGNER=thumbor_dash.url_signers.base64_hmac_sha256\nERROR_HANDLER_MODULE=thumbor_dash.error_handlers.sentry\nHANDLER_LISTS=[thumbor.handler_lists.healthcheck,thumbor_dash.handler_lists.upload,thumbor.handler_lists.blacklist]\n\n```\n\n#### 2. Start thumbor_dash server in Docker\n\n   `docker run -p 80:80 --env-file thumbor.env.txt mayoreee/thumbor_dash`\n\nNote: If running in Docker, `<thumbor_dash-server>` in the image request URL should be set to `localhost:80` instead of `localhost:8888`.\n   \n\n\n\n", "release_dates": []}, {"name": "trezor-mcu", "description": ":lock: Sources for TREZOR firmware", "language": "C", "license": {"key": "lgpl-3.0", "name": "GNU Lesser General Public License v3.0", "spdx_id": "LGPL-3.0", "url": "https://api.github.com/licenses/lgpl-3.0", "node_id": "MDc6TGljZW5zZTEy"}, "readme": "# TREZOR Firmware\n\n[![Build Status](https://travis-ci.org/trezor/trezor-mcu.svg?branch=master)](https://travis-ci.org/trezor/trezor-mcu) [![gitter](https://badges.gitter.im/trezor/community.svg)](https://gitter.im/trezor/community)\n\nhttps://trezor.io/\n\n## How to build TREZOR firmware?\n\n1. <a href=\"https://docs.docker.com/engine/installation/\">Install Docker</a>\n2. `git clone https://github.com/trezor/trezor-mcu.git`\n3. `cd trezor-mcu`\n4. `./firmware-docker-build.sh TAG` (where TAG is v1.3.2 for example, if left blank the script builds latest commit)\n\nThis creates file `output/trezor-TAG.bin` and prints its fingerprint at the last line of the build log.\n\n## How to build TREZOR bootloader?\n\n1. <a href=\"https://docs.docker.com/engine/installation/\">Install Docker</a>\n2. `git clone https://github.com/trezor/trezor-mcu.git`\n3. `cd trezor-mcu`\n4. `./bootloader-docker-build.sh`\n\nThis creates file `output/bootloader.bin` and prints its fingerprint and size at the last line of the build log.\n\n## How to get fingerprint of firmware signed and distributed by SatoshiLabs?\n\n1. Pick version of firmware binary listed on https://wallet.trezor.io/data/firmware/releases.json\n2. Download it: `wget -O trezor.signed.bin https://wallet.trezor.io/data/firmware/trezor-1.3.6.bin`\n3. `./firmware-fingerprint.sh trezor.signed.bin`\n\nStep 3 should produce the same sha256 fingerprint like your local build (for the same version tag).\n\nThe reasoning for `firmware-fingerprint.sh` script is that signed firmware has special header holding signatures themselves, which must be avoided while calculating the fingerprint.\n", "release_dates": []}, {"name": "wasm-re2", "description": null, "language": "TypeScript", "license": null, "readme": "# RE2\n\n## Getting Started\n\n### Installation\n\n``` bash\nnpm i wasm-re2\n```\n\n### Usage\n\n``` typescript\nimport { RE2 } from 'wasm-re2';\n\nconst regex = new RE2('(b|^a)', 'g');\n\nconst isFound = regex.test('aabc');\n// true\n\nconst matches = regex.exec('aabc');\n// [ ['a', 'a'], ['b', 'b'] ]\n```\n\n## API\n\n### `RE2.test(string)`\n\nExecutes a search for a match between a regular expression and a specified string.\n\nReturns true or false.\n\n### `RE2.exec(string)`\n\nReturns all matches of the regular expression against a string.\n\nWorks like non-iterable RegExp matchAll.\n\nExec returns all results in a 2D array where each result consists of [fullmatch, ...captureMathces].\n\nExample:\n\n```typescript\nconst regex = new RE2('(abc)\\\\d+(zxc)', 'g');\n\nregex.exec('123abc123zxc123abc123zxc123')\n// [ ['abc123zxc', 'abc', 'zxc'], ['abc123zxc', 'abc', 'zxc'] ]\n```\n\n### `RE2.replace(string, rewrite)`\n\nReturn a new string with some or all matches of a pattern replaced by a replacement.\n\n### `RE2.numberOfCaptureGroups()`\n\nReturns number of capture groups.\n\n## Working with Emscripten\n\n### For Mac\n\nIf you use mac proceed to [Pull submodule google-re2](#pull-submodule-google-re2).\nYou need node and python to be installed.\n\n### For Windows\n\nInstall Debian from Microsoft Store, then launch and create UNIX user.\n\n```\nEnter new UNIX username:\nNew password:\nRetype new password:\n```\n\nThen launch:\n\n```\nsudo apt-get update -y && sudo apt-get install nodejs npm git python -y\n```\n\nInstall Subsystem WSL using Setting on Windows 10:\n\n1. Open `Settings`.\n2. Click on `Apps`.\n3. Under the `Related settings` section, click the `Programs and Features` option.\n4. Click the `Turn Windows features on or off` option on the left pane.\n5. Check the `Windows Subsystem` for the Linux checkbox.\n6. Click the `OK` button.\n7. Then you need to reboot the PC.\n\nLaunch IDE with WSL, and do all next actions in WSL Terminal.\n\n### Pull submodule google-re2\n\n`git submodule update --init`\n\n### Clone emsdk in _your storage of repos_\n\n`git clone https://github.com/emscripten-core/emsdk.git`\n\n### Enter that directory\n\n`cd emsdk`\n\n### Fetch the latest version of the emsdk (not needed the first time you clone)\n\n`git pull`\n\n### Download and install the latest SDK tools\n\n`./emsdk install latest`\n\n### Make the \"latest\" SDK \"active\" for the current user. (writes ~/.emscripten file)\n\n`./emsdk activate latest`\n\n### Activate PATH and other environment variables in the current terminal\n\nfrom emsdk dir:\n`source ./emsdk_env.sh`\n\nfrom re2:\n`source ../emsdk/emsdk_env.sh`\n\n### Compile C code\n\n#### Install dependencies\n\n`npm i`\n\n#### Update/create foundation folder running\n\n`npm run foundation`\n\n##### Make sure you have permissions to execute the file `chmod +x ./compile.sh`\n\nRun script `npm run compile`\n\n#### Testing\n\n`npm test`\n\n### Updating re2 to latest\n\n#### If google-re2 module is updated\n\n```bash\ngit pull --recurse-submodules\n```\n\n#### Then run this script to update re2 package\n\n```bash\nnpm run build:update\n```\n\n### Rollup\n\nTo change rollup configuration read `Rollup_FAQ.md` in `yaml-core` package or visit <https://rollupjs.org/guide/en/>.\n", "release_dates": ["2023-07-31T11:55:23Z", "2023-07-27T07:35:03Z", "2023-07-26T19:37:39Z", "2023-07-26T18:21:19Z", "2023-07-25T19:17:57Z", "2022-03-16T14:11:09Z", "2022-03-16T11:07:57Z", "2022-03-16T10:06:03Z"]}, {"name": "wasm-x11-hash", "description": "WASM binding for X11 hashing algorithm", "language": "C", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# wasm-x11-hash\n[![NPM Version](https://img.shields.io/npm/v/wasm-x11-hash)](https://www.npmjs.com/package/wasm-x11-hash)\n[![Build Status](https://github.com/dashevo/wasm-x11-hash/actions/workflows/test_and_release.yml/badge.svg)](https://github.com/dashevo/wasm-x11-hash/actions/workflows/test_and_release.yml)\n[![Release Date](https://img.shields.io/github/release-date/dashevo/wasm-x11-hash)](https://github.com/dashevo/wasm-x11-hash/releases/latest)\n[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen)](https://github.com/RichardLitt/standard-readme)\n\nWASM binding for X11 hashing algorithm written in C\n\n## Installation and usage\n_[Buffer](https://github.com/feross/buffer) polyfill is required for usage in browsers_\n- `$ npm install wasm-x11-hash`\n\n```javascript\nconst X11 = require('wasm-x11-hash');\n\nX11().then(x11 => {\n  const hash = x11.digest('hello world')\n});\n```\n\n## Build and test\n_Docker v20+ is required_\n\n- `$ npm run build`\n- `$ npm run test`\n\n", "release_dates": ["2022-06-27T12:59:35Z", "2022-06-24T14:42:33Z"]}, {"name": "wp-dash-theme", "description": "Dash.org (2019 site) WordPress theme", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# WordPress Dash Theme 2019\n\n> WordPress theme for dash.org\n\n## Maintainer\n\n[@strophy](https://github.com/strophy)\n\n## License\n\n[MIT](LICENSE) &copy; Dash Core Group, Inc.\n", "release_dates": []}, {"name": "x11-hash-js", "description": "x11 javascript hashing algorithm in pure javascript", "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# x11-hash-js\n\n> Performs the [x11 hashing](https://docs.dash.org/en/latest/introduction/features.html#x11-hash-algorithm) algorithm used in the [Dash cryptocurrency](https://dash.org) in JavaScript.\n\n## Usage\n\nInstall the library as a Node module.\n\n```\n$ npm install --save @dashevo/x11-hash-js\n```\n\nReference the library within a Node module.\n\n```js\nvar x11 = require('x11-hash-js');\n\nconsole.log(x11.digest('The great experiment continues.'));\n// -> '4da3b7c5ff698c6546564ebc72204f31885cd87b75b2b3ca5a93b5d75db85b8c'\n```\n\nDownload the browserified library from the [dist](https://github.com/dashpay/x11-hash-js/tree/master/dist) folder and include it in your HTML.\n\n```html\n<html>\n<head>\n  <script src='./dist/x11-hash.min.js'></script>\n  <script>\n  let x11 = require('x11hash');\n  console.log(x11.digest('The great experiment continues.'));\n  // -> '4da3b7c5ff698c6546564ebc72204f31885cd87b75b2b3ca5a93b5d75db85b8c'\n  </script>\n</head>\n<body></body>\n</html>\n```\n\nCall individual hash functions within the x11 digest.\n\n```js\nconsole.log(x11.blake('The great experiment continues.'));\n// -> '8f257723af0741fb7d3d8c264a5ea86a57d4ae833557de04f5f78fad1ac17d6dfa1ae4a78a7564c08fc21d5d8cdd2793ca17d5500ecc2b43eb8aaf9c220d7b49'\n\nconsole.log(x11.bmw('The great experiment continues.'));\n// -> '7b30b4f1ccd83692bc6a01b1f7e374b59b81da6b21421679ae59d84c4f73afec5a0857565b6ebc1b9ddf9da5e75bf1ecd0ba6f5a75b7926ba9278385fb83533c'\n\nconsole.log(x11.cubehash('The great experiment continues.'));\n// -> '64394bcb9d7844070c8516480ea5f03f68386f33c3829e08bf38bea11f09eba5806aa7831cfbe8e515678b0cad7d4ac888ea2b9ea8f63f0cc918d5a6a76b7ae9'\n\nconsole.log(x11.echo('The great experiment continues.'));\n// -> 'b1db282b1672f3423c1e1bdf4496a8ddda0b6f483e92e9a8be2efbaab0ea230814f1f1485d919285deac13794dc215000eb39a47ac32bfc07299a0475049be2e'\n\nconsole.log(x11.groestl('The great experiment continues.'));\n// -> '6cea044acf31194eab7d1adb704712c34dd4f0b6a470b0f297832addab691faa459474c651efdbebddb138a2a9adb41705e0fb75741775314ddd8e5449ace986'\n\nconsole.log(x11.jh('The great experiment continues.'));\n// -> '90c7090e9d9a45bc79f476ae7fa3e7e4416d1c26b127d1d418ee9bd96b541933b0f144a0d4c6594944393e39fb6b98ceb54752af55198e00953d638183482521'\n\nconsole.log(x11.keccak('The great experiment continues.'));\n// -> '4c7e9c893fcdc87a2fd604574a4a5b9a0b6864665ed19057dedf24858314690ba45d6bbcfb86cd7182d1677e2d30dad9716ee99eb8ea267c6638f47ef20e0226'\n\nconsole.log(x11.luffa('The great experiment continues.'));\n// -> 'ea531ce38473fc4bd508c5396194dd6201699d47e25bd4d6b0c5dc7ab0627831e01ea027ebe33d80f608f139aa9fd0c6d923f32de9b5d714026300ed1c9a2f48'\n\nconsole.log(x11.shavite('The great experiment continues.'));\n// -> '6fbca2d53a26e22e6df1a8064230bdb98c0a612b64dad958f16757cf8ee8526862a0e4f56be69b98b07f0ea47db7211cf42352443fc806013374e819f26cb923'\n\nconsole.log(x11.simd('The great experiment continues.'));\n// -> '13ae2c08260f7d5abcfa791446800c1eaed8c5332ec437222428a28823aa2ba19a5907a2c860c12c0b894bdf9c0d64f807cb9512f1ed42980d15747ff4a26c1c'\n\nconsole.log(x11.skein('The great experiment continues.'));\n// -> '88a9dd727bb9b7cbd59612edbcd6b321427f473acc5673d7dffb16071dc71821d0cc1b94dccf7e5f71a0a94019a7e764d3315c3f4a40f73aee4ad98c75bcc2f7'\n\n```\n\n## API\n\n### x11.digest(str)\n\nReturns a `string` representation of the x11 hash of an input `string` ***str***.\n\n#### str\n\nType: `string`\n\nThe string to be hashed.\n\n### x11.digest(input, inputFormat, outputFormat)\n\nReturns the x11 hash of ***input*** with the input and output types variable between a `string`, 8 bit `array` or 32 bit `array`\n\n#### input\n\nType: `string` or `array`\n\nThe input data to be hashed.\n\n#### inputFormat\n\nType: `number`\n\nSpecifies the format and type of the ***input*** value:\n\n - **0**: `string`\n - **1**: 8 bit `array`\n - **2**: 32 bit `array`\n\n#### outputFormat\n\nType: `number`\n\nSpecifies the format and type of the return value:\n\n - **0**: `string`\n - **1**: 8 bit `array`\n - **2**: 32 bit `array`\n", "release_dates": []}]