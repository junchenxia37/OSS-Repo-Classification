[{"name": ".github", "description": null, "language": null, "license": null, "readme": "# Stellar Default Github Community Health Files\n\nThis repo contains Stellar's default community health file defaults on Github, such as:\n\n- CODE_OF_CONDUCT\n- CONTRIBUTING\n- ISSUE_TEMPLATE\n- Pull request templates\n- etc.\n\nFor more information, see\n[this Github help article](https://help.github.com/en/articles/creating-a-default-community-health-file-for-your-organization).\n", "release_dates": []}, {"name": "account-viewer-v2", "description": "A simple tool to view an account on the Stellar network and make transactions from it.", "language": "TypeScript", "license": null, "readme": "# Stellar Account Viewer 2.0\n\nA simple tool to view an account on the Stellar network and make transactions\nfrom it.\n\nThis app replaces the original Account Viewer with an updated framework and\ndesign.\n\n## Developing\n\nWe use `create-react-app` with yarn for dependencies.\n\n`yarn`\n\nTo start the app in development mode, which will watch for changes to files,\nrebuild, and reload the site automatically, run the start script.\n\n`yarn start`\n\n## Building for production\n\nBuilds the app for production to the `build` folder.\n\n`yarn build`\n\n## Change network\n\nYou can change Account Viewer\u2019s network by setting `testnet` query parameter to\neither `true` or `false`. For example, `localhost:3000/?testnet=false`. The red\nbanner at the top of the page will show that you're on a different network.\n\n![Red banner: You are using PUBLIC network in DEVELOPMENT](public/images/av-network-banner.png)\n", "release_dates": ["2023-04-18T19:44:47Z", "2022-01-18T18:06:16Z", "2021-10-14T20:25:30Z", "2021-09-01T21:44:29Z", "2021-08-06T19:01:57Z", "2021-07-29T20:11:45Z"]}, {"name": "actions", "description": "GitHub Actions for Stellar repositories.", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# stellar/actions\n\nThis repository contains GitHub Actions and GitHub Actions Workflows that are\nshared by [@stellar] repositories.\n\n## Usage\n\n### Actions\n\nTo use an action in this repository in another repository, specify the action in\nthis repo using the `uses` directive inside a step inside a job, and specify `stellar/actions/<action-directory>`. For example:\n\n```yml\njobs:\n  my_job:\n    steps:\n    - uses: stellar/actions/rust-cache@main\n```\n\n### Reusable Workflows\n\nTo use a reusable workflow in this repository in another repository, specify the\nreusable workflow in this repo using the `uses` directive inside a job, and\nspecify `stellar/actions/<path-to-reusable-workflow>`. The path used for the\nworkflow must be the `.github/workflows/` path. For example:\n\n```yml\njobs:\n  my_job:\n    uses: stellar/actions/.github/workflows/rust-set-rust-version.yml@main\n```\n\n## Actions and Workflows\n\n### Rust\n\n#### General\n\n| Name | Type | Description |\n| ---- | ---- | ----------- |\n| [rust-cache] | Action | Caches dependencies, install artifacts, and build artifacts in Rust projects. |\n| [rust-set-rust-version] | Workflow | Updates the rust-version in Rust crates to the latest stable version. |\n| [rust-check-git-rev-deps] | Workflow | Check that git rev dependencies do not reference revisions likely to be orphaned. |\n\n#### Releasing / Publishing\n\nSee [README-rust-release.md] for the release process supported by these\nworkflows.\n\n| Name | Type | Description |\n| ---- | ---- | ----------- |\n| [rust-bump-version] | Workflow | Updates the version in Rust crates to a input version. |\n| [rust-publish-dry-run] | Run a package verification on all crates in a workspace in their published form that automatically figures out the crate dependencies and order to publish (works only for repos without a binary). |\n| [rust-publish-dry-run-v2] | Run a package verification on all crates in a workspace in their published form that requires an explicit list of crates to publish (works with all repos). |\n| [rust-publish] | Workflow | Publish all crates in a workspace. |\n\n### Project Management\n\n| Name | Type | Description |\n| ---- | ---- | ----------- |\n| [update-completed-sprint-on-issue-closed] | Workflow | Updates the CompletedSprint project field when an issue/PR is closed. |\n\n[@stellar]: https://github.com/stellar\n\n[rust-cache]: ./rust-cache\n[rust-set-rust-version]: ./.github/workflows/rust-set-rust-version.yml\n[rust-bump-version]: ./.github/workflows/rust-bump-version.yml\n[rust-publish-dry-run]: ./.github/workflows/rust-publish-dry-run.yml\n[rust-publish-dry-run-v2]: ./.github/workflows/rust-publish-dry-run-v2.yml\n[rust-publish]: ./.github/workflows/rust-publish.yml\n[update-completed-sprint-on-issue-closed]: ./.github/workflows/update-completed-sprint-on-issue-closed.yml\n\n[README-rust-release.md]: README-rust-release.md\n", "release_dates": []}, {"name": "amm-reference-ui", "description": "A reference codebase to serve as a proof of concept for an AMM UI", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# AMM Reference IU\nThis project serves as a reference implementation for anyone who wants to explore setting up a UI for AMMs.\nThis is not a recomendation or perscribed way to set up a UI, nor does it endorse or advocate for any particular UI design or service. \nThis information should not be construed as professional advice of any kind -- including investment, financial, trading, tax, or legal advice.", "release_dates": ["2021-12-16T21:53:10Z", "2021-12-16T21:44:07Z", "2021-12-01T16:46:41Z"]}, {"name": "anchor-transfer-server-validator-ui", "description": null, "language": "JavaScript", "license": null, "readme": "# anchor-transfer-server-validator-ui\n\nThe GUI for running the automated test suites defined in [transfer-server-validator](https://github.com/stellar/transfer-server-validator).\n\n## Development\n\n```\nyarn install\nyarn start\n```\n\n## Live deployment\n\n[https://elated-lewin-aef0ce.netlify.com/](https://elated-lewin-aef0ce.netlify.com/)", "release_dates": []}, {"name": "anchor-transfer-utils", "description": "Utilities for anchors and wallets implementing SEP6 transfer protocol", "language": "TypeScript", "license": null, "readme": "# anchor-transfer-utils\n\nUtility functions for implementing the interactive SEP6 flow.  This helps implement the postMessage message handling involved in showing the interactive webapp.\n\n## Installation\n\n### Using NPM\n\n```\nnpm install --save @stellar/anchor-transfer-utils\n```\n\n### Standalone\n\n```\n<script src=\"https://unpkg.com/@stellar/anchor-transfer-utils@1.2.0/lib/index.js\" />\n```\n\n## Usage for Anchors\n\n### Withdrawal\n\nFor anchors using the interactive web flow, use the `finalizeTransaction` helper to communicate back to the wallet when a withdraw is ready for payment.\n\n```\nconst AnchorTransferUtils = require(\"@stellar/anchor-transfer-utils\")\nAnchorTransferUtils.finalizeWithdrawal({\n  id: \"id_representing_anchor_transaction\",\n  amount_in: \"80.12\",\n  withdraw_anchour_account: \"<Stellar public account id>\",\n  withdraw_memo: \"<Some unique identifier>\",\n  withdraw_memo_type: \"text\" | \"hash\" | \"id\"\n})\n```\n\n", "release_dates": []}, {"name": "anchor-ux-guidelines", "description": null, "language": null, "license": null, "readme": "# Anchor UX Guidelines #\n\n## This document describes guidelines for anchors in order to provide amazing UX to users. ##\n\nGood user experience (UX) is important: it creates obvious and seamless flows for users to follow which in turn reduces user error and increases trust in the product. The more high-quality your UX is, the more likely users will continue to use and have faith in your integration.\n\nAdditionally, wallets are protective of their users\u2019 experience for the same reason and will not want to offer your service unless the UX is up to their expectations. When we bring new anchors to a wallet, they do their own due diligence and evaluate your service, and submit feedback if they have any. This feedback will include UX suggestions if they see anything they\u2019d like changed. Once the issues are resolved, they'll integrate your service and your application will officially be launched to the public.\n\n### Guideline ###\n#### Loading States #### \nAll loading states should have a clear interface feedback, such as a loading bar or a spinner.\n\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/loader-do@2x.png\" width=\"355\" align=\"left\">\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/loader-dont@2x.png\" width=\"355\">\n\n#### Languages #### \nAll anchors should support both english and spanish in their interactive flow.\n\n#### Error Messages #### \nErrors messages should be easy to understand and describe what users should do next.\n\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/error-do@2x.png\" width=\"355\" align=\"left\">\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/error-dont@2x.png\" width=\"355\">\n\n#### Text Legibility ####\nAll text should have a minimum font size and a good contrast with the background.\n\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/legibility-do@2x.png\" width=\"355\" align=\"left\">\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/legibility-dont@2x.png\" width=\"355\">\n\n#### Clickable Areas ####\nAll fields, and buttons, should have a minimum clickable area.\n\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/click-area-do@2x.png\" width=\"355\" align=\"left\">\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/click-area-dont@2x.png\" width=\"355\">\n\n#### Brand ####\nMake it clear to users that they are interacting with your institution by showing the logo and the name on a first interaction and keeping the brand consistent throughout the process.\n\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/brand-do@2x.png\" width=\"355\" align=\"left\">\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/brand-dont@2x.png\" width=\"355\">\n\n#### Color Scheme ####\nThe colors used in the interactive flow should be aligned with their brand guidelines, but also not have a big contrast with Vega's colors.\n\n#### Response Time ####\nAll actions shouldn't take more than 15 seconds to be completed (considering a perfect network environment).\n\n#### Text Fields  ####\nAll text fields should have a minimum height, and not clip their content.\n\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/input-field-do@2x.png\" width=\"355\" align=\"left\">\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/input-field-dont@2x.png\" width=\"355\">\n\n#### Highlight Selected Fields  ####\nAll fields should have their highlighted states visible (e.g. with a colorful border), so users have a clear understanding of what's being edited.\n\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/field-highlight-do@2x.png\" width=\"355\" align=\"left\">\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/field-highlight-dont@2x.png\" width=\"355\">\n\n#### Back button ####\nIf you have multiple screens in a form, or flow, allow users to go back to previous screens with a back button.\n\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/back-do@2x.png\" width=\"355\" align=\"left\">\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/back-dont@2x.png\" width=\"355\">\n\n#### Responsive Layouts ####\nThe system will be used on different screen sizes, so make sure the layout works well on all different sizes.\n\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/responsive-do@2x.png\" width=\"355\" align=\"left\">\n<img src=\"https://github.com/stellar/anchor-ux-guidelines/raw/master/images/responsive-dont@2x.png\" width=\"355\">\n", "release_dates": []}, {"name": "atlantis", "description": "Terraform Pull Request Automation", "language": null, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Atlantis <!-- omit in toc -->\n\n[![Latest Release](https://img.shields.io/github/release/runatlantis/atlantis.svg)](https://github.com/runatlantis/atlantis/releases/latest)\n[![SuperDopeBadge](./runatlantis.io/.vuepress/public/hightower-super-dope.svg)](https://twitter.com/kelseyhightower/status/893260922222813184)\n[![Go Report Card](https://goreportcard.com/badge/github.com/runatlantis/atlantis)](https://goreportcard.com/report/github.com/runatlantis/atlantis)\n[![Go Reference](https://pkg.go.dev/badge/github.com/runatlantis/atlantis.svg)](https://pkg.go.dev/github.com/runatlantis/atlantis)\n[![codecov](https://codecov.io/gh/runatlantis/atlantis/branch/main/graph/badge.svg)](https://codecov.io/gh/runatlantis/atlantis)\n[![CircleCI](https://circleci.com/gh/runatlantis/atlantis/tree/main.svg?style=shield)](https://circleci.com/gh/runatlantis/atlantis/tree/main)\n[![Slack](https://img.shields.io/badge/Join-Atlantis%20Community%20Slack-red)](https://join.slack.com/t/atlantis-community/shared_invite/zt-1nt7yx7uq-AnVRc_JItF1CDwZtfqv_OA)\n\n<p align=\"center\">\n  <img src=\"./runatlantis.io/.vuepress/public/hero.png\" alt=\"Atlantis Logo\"/><br><br>\n  <b>Terraform Pull Request Automation</b>\n</p>\n\n- [Resources](#resources)\n- [What is Atlantis?](#what-is-atlantis)\n- [What does it do?](#what-does-it-do)\n- [Why should you use it?](#why-should-you-use-it)\n- [Stargazers over time](#stargazers-over-time)\n\n## Resources\n* How to get started: [www.runatlantis.io/guide](https://www.runatlantis.io/guide)\n* Full documentation: [www.runatlantis.io/docs](https://www.runatlantis.io/docs)\n* Download the latest release: [github.com/runatlantis/atlantis/releases/latest](https://github.com/runatlantis/atlantis/releases/latest)\n* Get help in our [Slack channel](https://join.slack.com/t/atlantis-community/shared_invite/zt-1nt7yx7uq-AnVRc_JItF1CDwZtfqv_OA)\n* Start Contributing: [CONTRIBUTING.md](CONTRIBUTING.md)\n\n## What is Atlantis?\nA self-hosted golang application that listens for Terraform pull request events via webhooks.\n\n## What does it do?\nRuns `terraform plan`, `import`, `apply` remotely and comments back on the pull request with the output.\n\n## Why should you use it?\n* Make Terraform changes visible to your whole team.\n* Enable non-operations engineers to collaborate on Terraform.\n* Standardize your Terraform workflows.\n\n## Stargazers over time\n\n[![Stargazers over time](https://starchart.cc/runatlantis/atlantis.svg)](https://starchart.cc/runatlantis/atlantis)\n", "release_dates": []}, {"name": "auth-required-tokens-manager", "description": "Web app to manage testnet auth required tokens and generate SEP7 QR Codes", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Auth Required Tokens Manager\n\nThis app is used to manage testnet auth required tokens and to generate\n[SEP-7](https://github.com/stellar/stellar-protocol/blob/master/ecosystem/sep-0007.md)\nQRCodes with payment and path payment operations.\n\n## Features\n\n* Configure token to be auth required.\n* Establish trustlines between accounts and token.\n* Make the market (create offers) between the token and XLM.\n* Send payments using the token.\n* Create SEP7 QRCode to send payments.\n* Send path payments with the path: `auth required token => XLM`.\n* Create SEP7 QRCode to send path payments with the path: `auth required token => XLM`.\n\n## Configuring Keys and Assets\n\nYou can check the pre-loaded keys and the asset name in the [.env](.env) file.\n\nIt's recommended to generate new keys in [Stellar Lab](https://laboratory.stellar.org/#?network=test)\nand populate [.env](.env) with them.\n\n## UI Sample\n\n![Alt text](UI_Screenshot.png?raw=true \"UI Sample\")\n\n## Available Scripts\n\nIn the project directory, you can run:\n\n### `yarn start`\n\nRuns the app in the development mode.<br /> Open\n[http://localhost:3000](http://localhost:3000) to view it in the browser.\n\nThe page will reload if you make edits.<br /> You will also see any lint errors\nin the console.\n\n### `yarn test`\n\nLaunches the test runner in the interactive watch mode.<br /> See the section\nabout\n[running tests](https://facebook.github.io/create-react-app/docs/running-tests)\nfor more information.\n\n### `yarn build`\n\nBuilds the app for production to the `build` folder.<br /> It correctly bundles\nReact in production mode and optimizes the build for the best performance.\n\nThe build is minified and the filenames include the hashes.<br /> Your app is\nready to be deployed!\n\nSee the section about\n[deployment](https://facebook.github.io/create-react-app/docs/deployment) for\nmore information.\n\n### `yarn eject`\n\n**Note: this is a one-way operation. Once you `eject`, you can\u2019t go back!**\n\nIf you aren\u2019t satisfied with the build tool and configuration choices, you can\n`eject` at any time. This command will remove the single build dependency from\nyour project.\n\nInstead, it will copy all the configuration files and the transitive\ndependencies (webpack, Babel, ESLint, etc) right into your project so you have\nfull control over them. All of the commands except `eject` will still work, but\nthey will point to the copied scripts so you can tweak them. At this point\nyou\u2019re on your own.\n\nYou don\u2019t have to ever use `eject`. The curated feature set is suitable for\nsmall and middle deployments, and you shouldn\u2019t feel obligated to use this\nfeature. However we understand that this tool wouldn\u2019t be useful if you couldn\u2019t\ncustomize it when you are ready for it.\n\n## Learn More\n\nYou can learn more in the\n[Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started).\n\nTo learn React, check out the [React documentation](https://reactjs.org/).\n", "release_dates": []}, {"name": "awesome-stellar", "description": "\ud83d\udc68\u200d\ud83d\ude80 A curated list of Stellar applications, blog posts, educational resources, tools, and more. ", "language": null, "license": null, "readme": "<div align=\"center\"><img width=\"50%\" align=\"center\" src=\"stellar_logo.png\"></div>\n<br>\n\n<h2 align=\"center\">  Stellar is an open network for storing and moving money. </h2>\n\n<p align=\"center\">Awesome Stellar is a curated list of Stellar applications, blog posts, educational resources, tools, and more.</p>\n\n<p align=\"center\">You can share this list using <a href=\"http://www.awesomestellar.com\">awesomestellar.com</a>.</p>\n\n<div align=\"center\"><a href=\"https://awesome.re\"><img src=\"https://awesome.re/badge-flat2.svg\"></a></div> \n\n## \ud83d\udc68\u200d\ud83d\ude80 Contents\n\n- [Official Channels](#official-channels)\n- [Community](#community)\n- [General Overview](#general-overview) \u2b50\n- [Blogs and Beginner Guides](#blogs-and-beginner-guides)\n- [Case Studies and Insights](#case-studies-and-insights)\n- [Network Statistics](#network-statistics)\n- [Developer Resources](#developer-resources)\n- [Developer Educational Resources](#developer-educational-resources)\n- [Understanding the Stellar Consensus Protocol](#understanding-the-stellar-consensus-protocol)\n- [Projects Building on Stellar](#projects-building-on-stellar)\n- [Stellar Asset Issuers (Anchors)](#stellar-asset-issuers-anchors)\n- [Store Your Stellar Assets](#store-your-stellar-assets)\n- [Use the Stellar Decentralized Exchange](#use-the-stellar-decentralized-exchange)\n- [Videos, Podcasts, and AMAs](#videos-podcasts-and-amas)\n\n\n## Official Channels\n- [Stellar Website](https://www.stellar.org/)\n- [Github](https://github.com/stellar)\n- [Twitter](https://twitter.com/StellarOrg)\n- [Keybase](https://keybase.io/team/stellar.public)\n- [SDF Blog](https://www.stellar.org/blog/) \n- [Stellar Community Blog](https://medium.com/stellar-community)\n- [Stellar Developers Blog](https://www.stellar.org/developers-blog)\n- [Reddit](https://www.reddit.com/r/Stellar/)\n- [YouTube](https://www.youtube.com/channel/UC4BrVpvKK0r2zP9xVFQcPSA)\n- [Stellar Podast YouTube](https://www.youtube.com/channel/UCHPQ8IGpoPftsid0s43wYpQ)\n- [Instagram](https://www.instagram.com/stellarorg/)\n- [Facebook](https://www.facebook.com/stellarfoundation) \n- [LinkedIn](https://www.linkedin.com/company/stellar-development-foundation/)\n\n\n## Community \n- [The Stellar Podcast](https://stellar-community-podcast.simplecast.com/) - A weekly podcast that discusses the news, applications, and developers building the future of finance on Stellar.\n\n- [Stellar discussions by Public Node](https://podcast.publicnode.org/) - Public Node community members discussing all aspects of the Stellar ecosystem - from brainstorming to developer interviews and everything in between.\n\n- [Galactic Talk](https://galactictalk.org/) - A community of Stellar users, developers and traders.\n\n- [Stellar Community Fund](https://www.stellar.org/community-fund?locale=en) - An exciting way for developers to flex their creative muscles and introduce new applications and use cases to the Stellar ecosystem, voted on by the community. \n  - [Round 1 Winners](https://medium.com/stellar-community/stellar-community-fund-round-1-winners-1957314d15cc)\n  - [Round 2 Winners](https://medium.com/stellar-community/stellar-community-fund-2-the-results-69b3f6a6040e) \n  - [Round 3 Winners](https://medium.com/stellar-community/stellar-community-fund-round-3-results-9d99e7cfec32)\n  - [Round 4 Winners](https://medium.com/stellar-community/stellar-community-fund-round-4-results-b3ed5f6acbe1)\n  \n- [Stellar Torch](http://stellartorch.com/) - A Stellar community experiment. The Stellar Torch is a transaction that is sent from person to person.\n  - [The Stellar Torch is Lit](https://www.reddit.com/r/Stellar/comments/c5r2z0/the_stellar_torch_is_lit/)\n  - [Stellar Torch featured on CoinDesk](https://www.coindesk.com/stellars-version-of-bitcoins-lightning-torch-has-been-burning-quietly-since-june)\n  \n- [Stellar Keybase Team](https://keybase.io/team/stellar.public) - A Keybase team to discuss all things Stellar. \n\n- [Stellar Global Keybase Team](https://keybase.io/team/stellar_global) - A community run Keybase team to discuss all things Stellar.\n\n- [Reddit](https://www.reddit.com/r/Stellar/) - Stellar Subreddit with 100,000+ members. \n\n- [Stellar StackExchange](https://stellar.stackexchange.com/) - Developer focused community and a place to ask dev related questions.\n\n\n## General Overview\n\nIf you're new to Stellar start here \ud83d\udc47\n\n- Quick Summaries \n  - [Learn how Stellar unites the world\u2019s financial infrastructure.](https://www.stellar.org/overview)\n  - [The Power of Stellar](https://www.stellar.org/learn/the-power-of-stellar) \n  - [Lumenauts - What is Stellar?](https://youtu.be/ixerXWJrDr0)\n  - [Lumenauts - Educational Twitter Moment](https://twitter.com/i/moments/1096909111734747138) \n  - [Coinbase Earn - What is Stellar?](https://www.coinbase.com/earn/stellar/lesson/1)\n  - [A Primer on the Stellar Network](https://snarky.ca/a-primer-on-stellar/)\n  \n- Intro to Stellar Assets & Anchors\n  - [What are Stellar Lumens?](https://www.stellar.org/lumens) \n  - [Stellar Assets and Anchors](https://youtu.be/Cf9CdFVse-w) \n  - [How banks, businesses, and people use Stellar](https://www.coinbase.com/earn/stellar/lesson/4)\n  \n- Intro to the Stellar Decentralized Exchange \n  - [How the Stellar Decentralized Exchange (DEX) Works](https://youtu.be/2L8-lrmzeWk)\n  - [How to Buy and Sell on the Stellar Decentralized Exchange](https://www.lumenauts.com/guides/how-to-buy-and-sell-on-the-stellar-decentralized-exchange)\n\n- Intro to the Stellar Consensus Protocol\n  - [How does Stellar protect digital assets?](https://www.coinbase.com/earn/stellar/lesson/5)\n  - [How the Stellar Consensus Protocol (Federated Byzantine Agreement) Works](https://youtu.be/X3Gj2nQZCNM)\n\n## Blogs and Beginner Guides \n\n- [Understanding Stellar Path Payments](https://medium.com/stellar-community/understanding-stellar-path-payments-5eefe55b071b)\n\n- [A Stellar 2019 \u2014 Year in Review](https://medium.com/stellar-community/a-stellar-2019-the-dev-digest-year-in-review-1ac4ac869ebd)\n\n- [SDF's Next Steps](https://www.stellar.org/blog/sdfs-next-steps/)\n\n- [SDF Joins the Blockchain Association](https://www.stellar.org/blog/sdf-joins-the-blockchain-association) \n\n- [The Future of Money](https://medium.com/stellar-community/the-future-of-money-a8fe27ee8f1)\n\n- [Help! I forgot my Stellar memo.](https://medium.com/stellar-community/help-i-forgot-my-stellar-memo-d62b3cc9c2f7)\n\n- [A Guide to Trustlines on Stellar](https://medium.com/stellar-community/a-guide-to-trustlines-on-stellar-8bc46091a86f) \n\n- [How Changes are Made to the Stellar Network](https://medium.com/stellar-community/how-changes-are-made-to-the-stellar-network-760abbb8d127) \n\n- [How to Stay Safe on Stellar](https://www.lumenauts.com/blog/how-to-stay-safe-on-stellar)\n\n- [Anatomy of a Stellar Scam](https://medium.com/@stellarguard/anatomy-of-a-stellar-scam-the-hard-fork-4ac89808fd38)\n\n- [How to Set Up a Mult-Sig Wallet](https://www.lumenauts.com/guides/how-to-set-up-a-multi-sig-wallet) \n\n- [Stellar - What's in your wallet?](https://medium.com/@stellarguard/stellar-whats-in-your-wallet-1b07b8f7123a)\n\n- [How to Use Lumens on the Ledger Nano S](https://www.lumenauts.com/guides/how-to-use-lumens-on-the-ledger-nano-s)\n\n- [How could Kelp bot help Stellar?](https://medium.com/stellar-community/how-could-kelp-bot-help-stellar-ba9bec513041)\n\n- [Stellar\u2019s Plan to Win Global Payments](https://www.coindesk.com/stellars-plan-to-win-global-payments-play-nice-with-the-finance-cops)\n\n\n## Case Studies and Insights\n\n- [How Tempo and Cowrie are Building on Stellar](https://stellar-org.webflow.io/case-studies/how-tempo-and-cowrie-are-building-on-stellar)\n\n- [Why IBM Built World Wire on Stellar](https://youtu.be/GtQY8Jfa4NA)\n\n- [Why IBM Built World Wire on Stellar: The Developer Experience](https://youtu.be/ksZAjFGGeRU)\n\n- [IBM Blockchain World Wire: How it Works](https://youtu.be/fXgwpfvDm5E) \n\n- [How SatoshiPay is Using Stellar to Transform Online Publishing](https://youtu.be/aaCc0s1bWAs)\n\n- [How Saldo is Using Stellar to Reimagine Cross-border Payments](https://youtu.be/y9FpIEv-TFw)\n\n- [Onboarding everyone - the StellarX Mission](https://youtu.be/HNRmJMAJ5rw)\n\n- [Central Bank Digital Currencies](http://thinktank.omfif.org/ibm)\n\n- [Charting the Evolution of Programmable Money](https://www.ibm.com/thought-leadership/institute-business-value/report/programmoneyevo)\n\n- [Paysend Group Launches Global Stablecoin on the Stellar Network](https://pressroom.journolink.com/paysend/release/paysend_group_launches_global_stablecoin_on_the_stellar_network_5007?)\n\n- [Keybase is now supported by the Stellar Development Foundation](https://keybase.io/blog/keybase-stellar)\n\n- [Why We Chose Stellar - BlockEQ](https://medium.com/@blockeq/why-we-chose-stellar-e5b9966c63b7) \n\n- [Stellar Network: Growth and Decentralization](https://medium.com/@SatoshiPay/stellar-network-growth-and-decentralisation-e99c52ade798)\n\n- [XLM launches on the back of a game-changing partnership (Wirex)](https://wirexapp.com/blog/post/xlm-launches-on-the-back-of-a-game-changing-partnership-0150)\n\n\n## Network Statistics \n\n- [Stellar Dashboard](https://dashboard.stellar.org/) - Monitors network status, ledger close times, fee stats, lumen distribution and more.\n\n- [Stellar Status Updates](https://status.stellar.org/) - Get status updates on the Stellar network, Horizon, the test network, and more.\n\n- [StellarExpert](https://stellar.expert/explorer/public/) - Block explorer and analytics platform for the Stellar network. \n\n- [Lumenscan](https://lumenscan.io/) - Block explorer and analytics platform for the Stellar network. \n\n- [Stellarbeat](https://stellarbeat.io/) - Information about nodes and validators on the network - includes a quorum monitor. \n\n- [Galactic Vision](http://galactic.vision) - A 3D network and quorum explorer. \n\n\n## Developer Resources \n\n- [Stellar Dev Digest](https://stellar.us9.list-manage.com/subscribe?u=c001d97369b7a10d224c23867&id=e1f435dc0a) - Weekly newsletter covering all things around the Stellar developer ecosystem. \n\n- [Stellar Github](https://github.com/Stellar) \n\n- [Stellar Core](https://github.com/stellar/stellar-core) - stellar-core is the backbone of the Stellar network. It maintains a local copy of the ledger, communicating and staying in sync with other instances of stellar-core on the network.\n\n- [Astrocore](https://github.com/astroband/astrocore) - Astrocore aims to become an alternative implementation of the stellar-core, the core component of the Stellar network.\n\n- [Stellar Protocol](https://github.com/stellar/stellar-protocol) - Developer discussion about possible changes to the protocol.\n   - [Stellar Ecosystem Proposals](https://github.com/stellar/stellar-protocol/blob/master/ecosystem/README.md) \n   - [Core Advancement Proposals](https://github.com/stellar/stellar-protocol/blob/master/core/README.md)\n\n- [Stellar Docs](https://developers.stellar.org/docs/) - Stellar documentation. \n\n- [Stellar Laboratory](https://www.stellar.org/laboratory/) - The Stellar Laboratory is a set of tools that enables people to try out and learn about the Stellar network.\n\n- Stellar SDKs \n  - [JavaScript SDK](https://www.stellar.org/developers/js-stellar-sdk/reference/) \n  - [Go SDK](https://www.stellar.org/developers/go/reference/)\n  - [Java SDK](https://github.com/stellar/java-stellar-sdk)\n  - [Kotlin SDK](https://github.com/Inbot/inbot-stellar-kotlin-wrapper)\n  - [Python SDK](https://github.com/StellarCN/py-stellar-base) \n  - [C# .NET Core 2.0 SDK](https://github.com/elucidsoft/dotnet-stellar-sdk) \n  - [Ruby SDK](https://github.com/astroband/ruby-stellar-sdk)\n  - [iOS and macOS SDK](https://github.com/Soneso/stellar-ios-mac-sdk)\n  - [Scala SDK](https://github.com/synesso/scala-stellar-sdk)\n  - [C++ SDK](https://github.com/bnogalm/StellarQtSDK)\n  - [Unity 3D SDK](https://github.com/Kirbyrawr/stellar-sdk-unity)\n  - [Flutter SDK](https://github.com/Soneso/stellar_flutter_sdk)\n  \n- Interact with the Stellar Network \n  - [Horizon API](https://horizon.stellar.org/) - Horizon allows you to submit transactions to the network, check the status of accounts, and subscribe to event streams. Servers hosted in the US. \n    - [Horizon Github Repo](https://github.com/stellar/go/tree/master/services/horizon) \n    \n  - [SatoshiPay's Horizon API](https://stellar-horizon.satoshipay.io/) - SatoshiPay's alternative to Stellar.org's Horizon API servers. Servers hosted in the US, Europe, and Asia. \n  \n  - [Astrograph](https://astrograph.io/) - A GraphQL interface to the Stellar network. \n    - [Astrograph Github Repo](https://github.com/astroband/astrograph) \n      \n  - [go-stellar-ipfs](https://github.com/aanupam23/go-stellar-ipfs) - A library that is a bridge between Stellar and IPFS. \n    - [go-stellar-ipfs Github Repo](https://github.com/aanupam23/go-stellar-ipfs)\n  \n  - [Stellar Ticker API](https://ticker.stellar.org/) - Provides the freshest data about Markets, Issuers and Assets on the Stellar Network.\n    - [GraphiQL for Stellar Ticker](https://ticker.stellar.org/graphiql) - an in-browser tool for writing, validating, and testing GraphQL queries.\n    - [Ticker API Documentation](https://github.com/stellar/go/blob/master/services/ticker/docs/API.md) \n    - [Assets Endpoint](https://ticker.stellar.org/assets.json) - Displays information about all assets available. \n    - [Markets Endpoint](https://ticker.stellar.org/markets.json) - Displays 24-hour, 7-day and orderbook information about markets that were active during these periods. \n \n - Useful Tools\n    - [Hack Stellar Boilerplate](https://github.com/tyvdh/hack-stellar) - This Hack Stellar app is a boilerplate collection of basic Stellar functions. You can either hack this Stencil project into whatever you're trying to build or just cut and paste out the functions from here into your own project.\n    - [StellarBurrito](https://github.com/stellarburrito/stellarburritojs) - An open-source wrapper for the JavaScript Stellar SDK. \n    - [Stellar Vanity Address Generator](https://github.com/robertDurst/stellar-vanity-address-generator) - A simple CLI tool to generate custom Stellar vanity addresses. \n    - [Stellar transaction signers inspector](https://github.com/stellar-expert/stellar-tx-signers-inspector) - Discover required signers, weights, and build optimal signature schema for Stellar transactions and accounts.\n    - [Cosmic.plus libraries](https://cosmic.plus/#libraries)\n      - cosmic-lib: implement CosmicLink & SEP-0007.\n      - ledger-wallet: Ledger Wallets support in two lines of code.\n      - loopcall: Limitless/advanced queries to horizon.\n      - oc-multisig: On-chain multisig account coordination.\n    - [Create Stellar Token (Testnet)](https://github.com/msfeldstein/create-stellar-token) - Script that creates a custom Stellar token on testnet. \n    - [Cosmic.link SEP-0007 debugger](https://cosmic.plus/js-cosmic-lib/web/demo) \n    - [Cosmic.plus applications](https://cosmic.plus/#applications)\n      - Equilibre.io: wallet-independent portfolio balancer for Stellar (first app to use delegated signing)\n      - Cosmic.link: CosmicLink protocol frontend.\n      - Stellar Authenticator: Security-oriented wallet. (+ useful dev tool)\n  - Validator Tools\n    - [Fast Stellar Core Catch Up](https://github.com/Lobstrco/stellar-core-parallel-catchup-py) - Starting a full stellar core validator from scratch takes a while, as the node needs to download and process a lot of data during the \"Catch up\" phase. The catching up phase usually takes more than a month. This script helps to make the process significantly shorter, as it allows to perform the catch up of multiple ledgers blocks in parallel.\n    - [Parallel Stellar Core Catchup](https://github.com/satoshipay/stellar-core-parallel-catchup) - Sync a full Stellar validator node (including full history) as fast as possible. Split the big ledger into small chunks of size CHUNK_SIZE. Run a catchup for the chunks in parallel with WORKERS worker processes. Stitch together the resulting database and history archive.\n    - [Stellar Parallel Catchup](https://github.com/astroband/stellar-parallel-catchup) - Catchup Stellar node history in background. \n\n## Developer Educational Resources \n  - [Developer Guides and Concepts](https://www.stellar.org/developers/guides/) - These guides are designed to help you learn more about the technical aspects of integrating Stellar into your application or service. \n      - [How and Why to Complete Your Stellar.toml](https://www.stellar.org/developers/guides/walkthroughs/how-to-complete-stellar-toml.html)\n      - [How to Connect Your Anchor Service to Stellar Wallets](https://www.stellar.org/developers/guides/walkthroughs/connect-to-wallets.html) \n      - [Creating Custom Assets on Stellar](https://www.stellar.org/developers/guides/walkthroughs/custom-assets.html) \n      \n  - [How Stellar.org Recovers From a Testnet Reset](https://www.stellar.org/developers/blog/how-stellar-org-recovers-from-a-testnet-reset)\n  \n  - [Get Started Building Stellar Applications: New York Blockchain Week Hackathon](https://youtu.be/kDzIpKXOdf0)\n  \n  - [Fee Bump Transactions Explained](https://medium.com/stellar-community/fee-bump-transactions-explained-9a6a365c0fb6) - A look at transactions on Stellar, the costs involved in submitting them,problems that could arise submitting transactions pre-Protocol 13, and how fee bump transactions solve them.\n  \n  - [Stellar Developer Workshop with Tomer Weller](https://youtu.be/80FKQeghK_4)\n  \n  - [Building your own Venmo with Stellar](https://blog.abuiles.com/building-your-own-venmo-with-stellar/) - This tutorial will show you how to create an anchor maintaining a Stellar account for each customer, hiding the implementation details. It will use the programming language JavaScript and the mobile wallet will be written using React Native.\n  \n  - [Explore Stellar Addresses and the Stellar DEX using Python](https://medium.com/@kolten/explore-stellar-addresses-and-the-stellar-dex-using-python-e72611822b48) - In this tutorial you'll be creating a script that takes in a Stellar address and returns the XLM balance. You will also convert that XLM balance to USD using the new ticker API for the Stellar DEX.\n  \n  - [Stream Ledger Data from the Stellar Network Using Python](https://medium.com/@kolten/stream-ledger-data-from-the-stellar-network-using-python-861af04c40ab) \n  \n  - [Stellar payments \u2014 thoughts on federation, QR Codes, URIs, and Point of Sale systems within the Stellar.org ecosystem](https://medium.com/lumenauts/stellar-payments-thoughts-on-federation-qr-codes-uris-and-point-of-sale-systems-within-the-2c6fcdc3fa4d)\n  \n  - [Sending Secret and Anonymous Memos with Stellar](https://medium.com/lumenauts/sending-secret-and-anonymous-memos-with-stellar-8914479e949b) \n  \n  - [Distributed Trustless Workers with Stellar](https://medium.com/lumenauts/distributed-trustless-workers-with-stellar-e197fd1b77f6) - An in-depth look at how Stellar\u2019s advanced features can be used to create a \u201csmart contract\u201d between a customer and an anonymous and untrusted worker.\n  \n  - [I Just Wrote a Stellar Smart Contract](https://medium.com/@robdurst/i-just-wrote-a-stellar-smart-contract-7f54a391f5e1) & [I Just Wrote a Stellar Smart Contract Pt. 2: Let\u2019s Dig a Little Deeper](https://medium.com/hackernoon/i-just-wrote-a-stellar-smart-contract-pt-2-lets-dive-a-little-deeper-a8dae19b9d0a) - Exploring Stellar 'smart contracts.' \n  \n  - [Hacking Stellar](https://github.com/0xfe/hacking-stellar) - This online book introduces you to Stellar with lots of practical examples using the command-line client, Lumen. Incomplete but useful nonetheless for understanding basic concepts. \n  \n  - [Understanding the Stellar Consensus Protocol](#understanding-the-stellar-consensus-protocol) - Useful information regarding SCP.\n\n  - [How to Create a Custom Token on Stellar in Python](https://medium.com/python-pandemonium/how-to-create-a-custom-token-on-stellar-network-in-python-abf8b2f7a6f8) \n  \n  - [StellarTxSignersInspector - Facilitating Multisig Discovery](https://stellar.expert/blog/stellar-tx-signers-inspector-facilitating-multisig-discovery) \n \n - Engineering Talk Series\n    - [Creating Usable Stellar Applications](https://youtu.be/hVGHMkYL15s)\n    - [Intuitive Stellar Consensus Protocol](https://youtu.be/fDt8Eh4T_lE)\n    - [Kelp GUI](https://youtu.be/zxBoERxZcQs) \n    - [Practical Path Payments](https://youtu.be/KzlSgSPStz8) \n    - [ZkVM: about the motocrab](https://youtu.be/1i-EJykVzag) \n    - [User-Friendly Key Management with SEP-30 Recoverysigner](https://youtu.be/W-n73Cuy7-0) \n    - [Turing Complete Contract proposal for Stellar](https://youtu.be/T7FlHKbew4U) \n\n## Understanding the Stellar Consensus Protocol\n\nThe Stellar Consensus Protocol (SCP) provides a way to reach consensus without relying on a closed system to accurately record financial transactions. SCP simultaneously enjoys four key properties: decentralized control, low latency, flexible trust, and asymptotic security.\n\n- [White Paper](https://www.stellar.org/papers/stellar-consensus-protocol.pdf) \n\n- [Fast and secure global payments with Stellar](https://www.scs.stanford.edu/~dm/home/papers/lokhava:stellar-core.pdf)\n\n- [Mathematical Analysis and Algorithms for Federated Byzantine Agreement Systems](https://arxiv.org/abs/1912.01365)\n\n- Blog Posts \n  - [Simplified SCP](http://www.scs.stanford.edu/~dm/blog/simplified-scp.html)\n  - [Understanding the Stellar Consensus Protocol](https://medium.com/interstellar/understanding-the-stellar-consensus-protocol-423409aad32e)\n  - [Why Quorums Matter and How Stellar Approaches Them](https://medium.com/stellar-developers-blog/why-quorums-matter-and-how-stellar-approaches-them-547336c1275)\n  - [Intuitive Stellar Consensus Protocol](https://medium.com/stellar-developers-blog/intuitive-stellar-consensus-protocol-d7fbf99a60ce)\n\n- Talks by David Mazi\u00e8res\n  - [ConsensusDay 1 // Stellar Consensus Protocol - David Mazieres](https://youtu.be/rLRPFsloyqk)\n  - [dotScale 2017 - David Mazi\u00e8res - Internet-level consensus is practical](https://youtu.be/zTI1HAWDHIg) \n  - [David Mazi\u00e8res: \"The Stellar Consensus Protocol\" | Talks at Google](https://youtu.be/vmwnhZmEZjc)\n  - [A Federated Model for Internet-level Consensus](https://youtu.be/hjRQLYF599w)\n  - [Fast and Secure Global Payments with Stellar](https://youtu.be/ZOtPlFvpGd8) \n  \n\n## Projects Building on Stellar \n\n- [Stellar Asset Issuers (Anchors)](#stellar-asset-issuers-anchors) - Financial institutions issuing assets on the Stellar network.\n\n- [Stellar.org Project Directory](https://proxy.stellar.org/ecosystem/projects) - Another project directory maintained on Stellar.org\n\n- [Keybase](https://keybase.io/) - Secure groups, files, and chat for everyone with a built in Stellar wallet. \n\n- [DSTOQ](https://dstoq.com/) - DSTOQ is on a mission to introduce micro investing to billions of people around the world. \n\n- [Money Clip](https://www.moneyclip.io/) - MoneyClip stores Canadian Dollars inside your phone. You can split bills, buy & sell online, and easily pay friends and family using digital cash. It\u2019s quick, secure, and easy to use.\n\n- [Nodle](https://nodle.io/) - Nodle is the world\u2019s largest ecosystem of connected devices, providing infrastructure, software and access to data for the Internet of Things.\n\n- [SatoshiPay](https://satoshipay.io/) - Global, fast and easy micropayment solutions. \n\n- [Settle Network](https://settlenetwork.com/) - Settle provides programmatic interoperability between traditional and digital assets, by leveraging our financial infrastructure in every country we operate. \n\n- [StellarAuth](https://stellarauth.com/) - StellarAuth increases user security and enables key management across applications and user actions with more grace and simplicity than any 2FA system out there.\n\n- [RealtyBits](https://www.realtybits.com/) - RealtyBits is the first blockchain based marketplace for buying and selling real estate assets with digital currencies from anywhere in the world.\n\n- [Kapilendo](https://www.kapilendo.de/) - Kapilendo is a banking platform for SMEs and issued its first blockchain-based digital bond on Stellar.\n\n- [DealBox](https://dlbx.io/) - A feature-rich digital securities issuance and investment platform connecting entrepreneurs and investors to enable the future of investing and capital formation.\n\n- [Tempo](https://tempo.eu.com/en) - Tempo is an international money transfer, money and crypto exchange company.  It offers online, offline and crypto remittances to nearly 100 countries.\n\n- [Wirex](https://wirexapp.com/business/stellar-partnership) - A U.K.-based payments platform and issuer of stablecoins on Stellar. \n\n- [COINQVEST](https://www.coinqvest.com) - Enterprise Cryptocurrrency Payment Processing on Stellar. Accept digital currencies, settle in USD, EUR, NGN.\n\n- [Velo](https://velo.org) - Velo is a Credit and Reserve Protocol enabling digital credit issuance and borderless asset transfer for businesses using a smart contract reserve system. \n\n- [SureRemit](https://sureremit.co/) - Nigeria-based global non-cash remittances company. \n\n- [Bitbond](https://www.bitbond.com/) - Bitbond is the issuer of Germany's first security token and makes business lending globally accessible.\n\n- [Blockdaemon](https://app.blockdaemon.com/marketplace/categories/-/stellar-horizon) - Spin up and deploy Stellar nodes within minutes. \n\n- [Public Node](https://publicnode.org/) - Stellar nodes funded by the community. \n\n- [Rehive](https://rehive.com/) - Rehive is a platform and toolkit for building fintech apps on Stellar. \n\n- [Stellar Battle](https://stellarbattle.com/) - Win community funded prizes. \n\n- [COINQVEST](https://www.coinqvest.com/) - COINQVEST helps online merchants and e-commerce shops programmatically accept and settle payments in new digital currencies while staying compliant, keeping their accountants and tax authorities happy.\n\n- [Litemint.io](https://litemint.io/) - PvP card battles (cards issued as NFTs on Stellar). \n\n- [Litemint.com](https://litemint.com/) - Built on Stellar, Litemint is a crypto wallet loaded with free instant games. Take on the daily live challenges, earn collectibles and rewards straight in your wallet.\n\n- [Tangem](https://tangem.com/) - An NFC card wallet that supports Stellar assets.\n\n- [Saldo.mx](https://smxwallet.com/) - A way for migrant workers to pay family members' bills across borders. \n\n- [Skyhitz](https://skyhitz.io/) - Skyhitz is a beats market for music creators built on Stellar. \n\n## Stellar Asset Issuers (Anchors)\n\n- [AnchorUSD](https://www.anchorusd.com/) - Redeemable and stable cryptocurrency anchored 1-for-1 to the US dollar. All deposits are secured in US-domiciled bank accounts.\n\n- [Tempo](https://tempo.eu.com/en) - Tempo's EURT is a stable coin, backed by on hand cash, 1 EURT = 1 EUR. \n\n- [StableCoin](https://stablecoin.group/) - Deposit BTC and ETH in exchange for a fully backed 1:1 asset on Stellar; Powered by Coinsquare. \n\n- [Apay (Papaya Anchor)](https://apay.io/in) - Papaya anchors multiple crypto assets to the network including BTC, LTC, and ETH.\n\n- [Bitbond](https://www.bitbond.com/) - Bitbond is the issuer of Germany's first security token and makes business lending globally accessible.\n\n- [Cowrie](https://cowrie.exchange/) - Cowrie anchors NGNT, an asset backed digital token pegged to the Nigerian Naira. \n\n- [Stellarport](https://stellarport.io) - Stellarport anchors assets such as BTC, ETH, and LTC. \n\n- [MINTX](https://mintx.co/) - MINTX supplies GOLD, SVLR, PLAT and PALL tokens priced to the physical metals global spot price +3%. \n\n- [Firefly](https://fchain.io/en/) - Firefly is a wallet provider and an issuer of the Chinese Yuan. \n  \n\n## Store Your Stellar Assets\n\n- [Keybase](https://keybase.io/blog/keybase-stellar-launch) - Keybase is an encrypted communication app with a built-in Stellar wallet available on most mobile and desktop devices.\n  \n- [Solar Wallet](https://solarwallet.io/) - Solar Wallet is an easy to-use wallet with multi-signature transactions. Available on most mobile and desktop devices. Allows users to withdraw stablecoins directly to their bank account. \n  \n- [Lobstr](https://lobstr.co/) - Lobstr is a custodial wallet with 2FA key recovery. This wallet allows you to store any Stellar-based asset and perform trades on the Stellar decentralized exchange.\n  \n- [Litemint](https://litemint.com/) - Litemint is an [open source](https://github.com/litemint/litemint), non-custodial wallet allowing you to store any Stellar asset and trade on the SDEX. It also offers an app and game ecosystem powered by decentralized cross-currency purchases through Stellar path payments.\n\n- [Tangem](https://tangem.com/) - An NFC card wallet that supports Stellar assets.\n\n## Use the Stellar Decentralized Exchange \n\n- User Interfaces for the DEX \n  - [StellarX](https://www.stellarx.com/)\n  - [Stellarport](https://stellarport.io/home)\n  - [StellarTerm](https://stellarterm.com/)\n  - [Interstellar.Exchange](https://interstellar.exchange/) \n  \n- Trading Bots\n  - [Kelp (free & open-source)](https://kelpbot.io/) - Kelp is a trading bot for the Stellar universal marketplace. \n  - [Rockfish (free & open-source)](https://github.com/Reidmcc/rockfish) - Rockfish is an arbitrage bot for the Stellar Decentralized Exchange (SDEX). \n\n  \n## Videos, Podcasts, and AMAs\n\n- Videos\n  - [Denelle Dixon shares the growth strategy for the Stellar network in 2020](https://youtu.be/-KQPlI1_cWI) \n  - [SFBW19 - Fireside Chat: Jed McCaleb & Denelle Dixon](https://youtu.be/K46cND9OjLE) \n  - [Crypto Assets: How are They Being Used to Make Payments on Blockchain?](https://youtu.be/geQD--3Ai6o)\n  - [What is IBM Blockchain World Wire?](https://youtu.be/IDq5MxmUSe8) \n  - [Jed McCaleb - Money 20/20 Interview](https://youtu.be/aTqWbfDT1NY) \n  - [Jed McCaleb, Stellar, and Jesse Lund, IBM, Announce World Wire](https://youtu.be/FAQ5DLxEhOs)\n  - [IBM's Jesse Lund and Stellar's Jed McCaleb answer audience questions at Blockchain West](https://youtu.be/82U3AZdA0qU)\n  - [CFCon USA 2018 / Jed McCaleb & Adam Ludwin / Issuing assets on blockchain](https://youtu.be/MAW1RApB_mE)\n  - [Stellar with Jed McCaleb at Distributed: Markets 2017](https://youtu.be/GIMOrsPxlZg)\n  - [Jed McCaleb: How Many Lumens Till Stellar (2017)](https://youtu.be/-0JrcV-Ozoc)\n  \n- Podcasts \n  - [Money 3.0: Denelle Dixon from the Stellar Development Foundation](https://www.abra.com/blog/money-3-0-denelle-dixon-stellar-development-foundation/)\n  - [Jed McCaleb: Stellar And The Vision Of An Open Financial System](https://youtu.be/dHkrrMg9RUw)\n  - [Making cross-border payments seamless | Blockchain Pulse Podcast S01E02](https://youtu.be/uwExNUOYEMQ)\n  - [Lisa Nestor on Digtal Assets Weekly](https://youtu.be/3OIXjr4kv4o)\n  - [Lisa Nestor podcast with Matt Case](https://www.spreaker.com/user/11246218/lisa-nestor-stellar_1)\n  - [Tempo Director Anthony Barker with Finance Magnates](https://soundcloud.com/finance-magnates/blockchain-podcast-66-tempo-director-anthony-barker)\n  \n- AMAs\n  - [Stellar Community Podcast - AMA with Kolten & Tyler](https://podcast.stellar.org/episodes/stellar-community-live-february-27th)\n  - [Blockchain Week NYC 2019 - Q&A with Jed McCaleb (Video)](https://youtu.be/OrpHfZcywJw) \n  - [Blockchain Week NYC 2019 - Q&A with Jed McCaleb (Transcript)](https://medium.com/stellar-community/transcript-q-a-with-jed-mccaleb-blockchain-week-nyc-2019-17862ba66a90)\n  - [AMA with Jed McCaleb and Denelle Dixon (6/5/19)](https://www.reddit.com/r/Stellar/comments/bwsprq/ama_with_stellar_development_foundation_jed/)\n  - [SDF Update & Mini AMA - Jed McCaleb (1/28/19)](https://www.reddit.com/r/Stellar/comments/akup8k/sdf_update/)\n\n\n## Contribute\n\nContributions welcome! Read the [contribution guidelines](CONTRIBUTING.md) first.\n\nSpell checking and checking for broken/incorrect links is also welcomed - let's keep the list clean!\n\n\n## License\n\n[![CC0](https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0)\n", "release_dates": []}, {"name": "basic-payment-app", "description": "An example payments application demonstrating integrations of various features and SEPs in a user-facing product.", "language": "Svelte", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# BasicPay <!-- omit in toc -->\n\n> The app that lets you pay, _basically_, anyone.\n\nAn example payments application demonstrating integrations of various Stellar\nfeatures and SEPs in a user-facing product.\n\n> :warning: **CAUTION:** Although BasicPay is a full-fledged application on\n> Stellar's Testnet, it has been built solely to showcase Stellar functionality\n> for the educational purposes of this tutorial, not to be copied, pasted, and\n> used on Mainnet.\n\n## Table of Contents <!-- omit in toc -->\n\n- [Companion App](#companion-app)\n- [Companion Tutorial](#companion-tutorial)\n- [Development Instructions](#development-instructions)\n- [Where to Start in this Repository?](#where-to-start-in-this-repository)\n  - [Stellar](#stellar)\n    - [SEPs](#seps)\n    - [Other Stellar Functionality](#other-stellar-functionality)\n  - [SvelteKit](#sveltekit)\n    - [Pages and Routes](#pages-and-routes)\n    - [Stores](#stores)\n\n\n## Companion App\n\nThis isn't just a codebase, it's a fully functioning testnet wallet! You can\ncheck it out and use it here: <https://basicpay.pages.dev>\n\n## Companion Tutorial\n\nThis application was built to coincide with a written tutorial, located in the\nStellar documentation. This tutorial is a \"nearly comprehensive\" guide to\nbuilding the features in this app. Following along with the tutorial and this\nsource code repository, you can get a solid understanding of building an\napplication on the Stellar network.\n\nFind the start the tutorial here:\n<https://developers.stellar.org/docs/building-apps/example-application-tutorial/overview>\n\n## Development Instructions\n\nClone the repository:\n\n```bash\ngit clone https://github.com/stellar/basic-payment-app.git\n```\n\nChange into the repository app:\n\n```bash\ncd basic-payment-app\n```\n\nInstall dependencies and start the development server.\n\n```bash\nyarn install\nyarn dev\n```\n\nYou can now visit the local development site in your browser at\n<http://localhost:5173>\n\n## Where to Start in this Repository?\n\nWe've worked to document everything in this repo, so start exploring wherever\nyou like. We'd suggest looking into the following areas:\n\n### Stellar\n\nThe heart and soul of this application is interacting with the Stellar network.\n\n#### SEPs\n\nMost of the Stellar interactions take place through the use of SEPs (Stellar\nEcosystem Proposals). These interactions are coded in the\n`/src/lib/stellar/sep*.js` files.\n\n#### Other Stellar Functionality\n\nMore generic Stellar functionality are located in the same directory:\n\n- `/src/lib/stellar/horizonQueries.js` for querying information from the network\n- `/src/lib/stellar/transactions.js` for building different kinds of Stelar\n  transactions\n\n### SvelteKit\n\nThis application is built using SvelteKit. We don't want to make this much of a\n\"SvelteKit Tutorial,\" but here's what you may want to explore:\n\n#### Pages and Routes\n\nWe primarily use SvelteKit for its routing capability. You can begin exploring\nthe SvelteKit components by reading the comments in the\n`/src/routes/dashboard/+page.svelte` file.\n\n#### Stores\n\nWe also have implemented a few custom stores to keep track of contact names and\naddresses, user KYC information, a list of anchor transfers, etc. A good place\nto start exploring these stores is the `/src/lib/stores/contactsStore.js` file.\n", "release_dates": []}, {"name": "binaries", "description": "Precompiled binaries for use in CI and other places.", "language": null, "license": null, "readme": "# binaries\n\nThis repository precompiles binaries and caches them in GitHub Releases for CI\njobs of the [@stellar] GitHub org.\n\n[@stellar]: https://github.com/stellar\n\n## Usage\n\n**Use of the binaries stored here are not recommended for general purpose use.\nThey're only intended for use supporting the [@stellar] CI jobs.**\n\nAdd the following to a workflow to install a binary here. The version must be\nspecified as a tag, as the tag also identifies which release to download the\nbinaries from.\n\n```yml\n- uses: stellar/binaries@v10\n  with:\n    name: cargo-set-rust-version\n    version: 0.5.0\n```\n", "release_dates": ["2024-01-09T00:32:33Z", "2023-11-30T22:46:10Z", "2023-06-23T21:31:16Z", "2023-06-21T03:59:15Z", "2023-04-11T16:58:16Z", "2022-12-01T23:17:26Z", "2022-10-28T22:53:37Z", "2022-10-28T20:18:50Z", "2022-10-28T18:30:02Z", "2022-10-28T18:17:44Z", "2022-10-28T06:26:37Z", "2022-10-28T06:05:09Z", "2022-10-28T01:14:46Z", "2022-10-27T22:45:47Z", "2022-10-27T07:50:43Z"]}, {"name": "bower-js-stellar-base", "description": null, "language": "JavaScript", "license": null, "readme": "# js-stellar-base for Bower\n\nPackaged version of [js-stellar-base](https://github.com/stellar/js-stellar-base) for front-end development.\n", "release_dates": []}, {"name": "bower-js-stellar-sdk", "description": null, "language": "JavaScript", "license": null, "readme": "# js-stellar-sdk for Bower\n\nPackaged version of [js-stellar-sdk](https://github.com/stellar/js-stellar-sdk) for front-end development.\n", "release_dates": []}, {"name": "bytes-lit", "description": "Creates byte arrays from literal values.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# bytes-lit\nCreates byte arrays from literal values.\n\nCurrently supports integer literals of unbounded size.\n\n## Example\n\nGet a byte array given an integer value. Leading zeros in hex (`0x`) and binary\n(`0b`) integer form are preserved.\n\n```rust\nlet bytes = bytes!(0x00ed3f55dec47250a52a8c0bb7038e72fa6ffaae33562f77cd2b629ef7fd424d);\nassert_eq!(bytes, [\n    0, 237, 63, 85, 222, 196, 114, 80, 165, 42, 140, 11, 183, 3, 142, 114,\n    250, 111, 250, 174, 51, 86, 47, 119, 205, 43, 98, 158, 247, 253, 66, 77,\n]);\n```\n\nGet the minimum sized byte array given an integer value to capture the value.\nLeading zeros are ignored.\n\n```rust\nlet bytes = bytesmin!(0x00ed3f55dec47250a52a8c0bb7038e72fa6ffaae33562f77cd2b629ef7fd424d);\nassert_eq!(bytes, [\n    237, 63, 85, 222, 196, 114, 80, 165, 42, 140, 11, 183, 3, 142, 114,\n    250, 111, 250, 174, 51, 86, 47, 119, 205, 43, 98, 158, 247, 253, 66, 77,\n]);\n```\n", "release_dates": ["2023-05-02T16:39:45Z", "2022-09-20T03:49:44Z", "2022-08-31T21:24:49Z", "2022-08-29T19:36:32Z", "2022-08-29T19:22:06Z"]}, {"name": "cargo-set-rust-version", "description": "Update Cargo.toml rust-version to latest.", "language": "Rust", "license": null, "readme": "# cargo-set-rust-version\n\nUpdate Cargo.toml rust-version to latest.\n\nIf the given manifest is a workspace, all members are updated.\n\n## Install\n\n```rust\ncargo install --locked cargo-set-rust-version\n```\n\n## Usage\n\nUpdate the `rust-version` to the latest stable version:\n\n```rust\ncargo set-rust-version\n```\n\nLicense: Apache-2.0\n", "release_dates": ["2022-10-24T18:20:32Z", "2022-08-11T15:45:36Z", "2022-08-11T07:09:00Z", "2022-08-10T15:50:00Z", "2022-08-10T15:05:38Z"]}, {"name": "convert-stellar-address", "description": null, "language": "JavaScript", "license": null, "readme": "# convert-stellar-address\n\nLittle CLI tool to convert new network address to the old network address.\n\n## Install\n\n```\nnpm install -g convert-stellar-address\n```\n\n## Usage\n\n```\nconvert-stellar-address GBC6LVJ4XQUINTJONMCAHKDIOFW5MBJFGGRMRN2OEI6ORNTAI6S62NPY\n```\n", "release_dates": []}, {"name": "core-node-admin-panel", "description": null, "language": "TypeScript", "license": null, "readme": "## Getting Started\n\nCopy `.env.example` to `.env` and ensure the values match your stellar-core instance.\n`npm run dev` To start the proxy server and the front-end.\n\n# core-node-admin-panel\n\n## Proposal\n\n- **Who**: For people running validation nodes\n- **Why**: It\u2019s difficult to set up and understand whether you have a robust node, or if it\u2019s fragile\n- **What**: A UI admin tool set to understand the health and risks of your node, along with hints on how to strengthen it.\n- **How**: Create views and analyses to help surface common detectable, but perhaps non obvious weak points.\n\n## Phase 1\n\n### Quorum halting analysis\n\nAdministrators need to choose a robust quorum slice, but it\u2019s hard to know how your selection will react to various network failures. After fetching the full transitive quorum, the application will run scenarios in which groups of 1-3 nodes die. Any runs in which that failure state causes our own node to die will be marked as a fatal case, and shown to the user, along with the paths creating the vulnerability\n\n### Expose API endpoints\n\nStart as a simple pull json api which can be converted to push mechanisms in the future if necessary. Should use the [json:api](<[https://jsonapi.org/](https://jsonapi.org/)>) format\n\n- **/nodes/flaky** Flaky nodes in quorum, in order to create easy alerting mechanisms\n- **/nodes/halting** Single nodes that, if they go down, would halt the current node\n\nImplementation Notes\n\n- Package it in the default docker\n- Use sqlite as the data store\n- NodeJS + Typescript\n\n## Phase 2\n\nAdd \u2018what if\u2019 scenarios: Visualize health of your node after making possible changes to you quorum set without having to actually make the change and revalidate\n\n- Add node X to my quorum set\n- Remove node Y from my quorum set\n- Stop depending on organization Z\n", "release_dates": []}, {"name": "crate-git-revision", "description": "Embed git revision into crates built and published.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# crate-git-revision\n\nEmbed the git revision of a crate in its build.\n\nSupports embedding the version from a local or remote git repository the build\nis occurring in, as well as when `cargo install` or depending on a crate\npublished to crates.io.\n\nIt extracts the git revision in two ways:\n- From the `.cargo_vcs_info.json` file embedded in published crates.\n- From the git repository the build is occurring from in unpublished crates.\n\nInjects an environment variable `GIT_REVISION` into the build that contains\nthe full git revision, with a `-dirty` suffix if the working directory is\ndirty.\n\nRequires the use of a build.rs build script. See [Build Scripts]() for more\ndetails on how Rust build scripts work.\n\n[Build Scripts]: https://doc.rust-lang.org/cargo/reference/build-scripts.html\n\n#### Examples\n\nAdd the following to the crate's `Cargo.toml` file:\n\n```toml\n[build_dependencies]\ncrate-git-revision = \"0.0.2\"\n```\n\nAdd the following to the crate's `build.rs` file:\n\n```rust\ncrate_git_revision::init();\n```\n\nAdd the following to the crate's `lib.rs` or `main.rs` file:\n\n```rust\npub const GIT_REVISION: &str = env!(\"GIT_REVISION\");\n```\n\nLicense: Apache-2.0\n", "release_dates": ["2023-02-17T00:38:05Z", "2023-01-03T18:14:17Z", "2022-12-05T04:01:22Z", "2022-11-28T21:14:59Z", "2022-10-19T23:28:00Z"]}, {"name": "create-stellar-token", "description": "Creates a custom stellar token on testnet", "language": null, "license": null, "readme": "# create-stellar-token\n\nCreate a custom Stellar token on Testnet.  You can specify keys for any of the accounts used.  If no seed is specified random accounts will be created for you.  All parameters are optional.\n\n`--issuer-seed=[seed]` Private key for the issuing account\n\n`--distribution-seed=[seed]` Private key for the distribution account\n\n`--client-seed=[seed]` Private key for a client account to receive a disbursement.\n\n`--asset=[code]` Asset name\n\n`--issue-amount=[number]` Amount of asset to issue\n\n`--client-amount=[number]` Amount of asset to send to client\n\n## Usage\n\n`npx create-stellar-token`\n\n`npx create-stellar-token --asset=MYUSD --issue-amount=100000 --client-amount=100`", "release_dates": []}, {"name": "dashboard", "description": null, "language": "JavaScript", "license": null, "readme": "# Dashboard\n\n## Dependencies\n\nTo build this project, you must have the following dependencies installed:\n\n- node 10.16.3\n- yarn\n\n## Installation\n\n```sh\nyarn\n```\n\n## Developing\n\n```sh\nyarn start\n```\n\n### If you wish to use backend server API, you need to have redis running locally on port 6379 (default for redis)\n\n(If you do not have redis installed) If on a mac, install redis using homebrew\n\n```sh\nbrew install redis\n```\n\n(Other install directions can be found here: https://redis.io/download)\n\nMake sure it's running\n\n```sh\nbrew services start redis\n```\n\nOnce you have redis installed, start this command\n\n```sh\nyarn run start:backend\n```\n\nIt will create a proxy to `browser-sync` server started by gulp at\n`http://localhost:5000`\n\n### Connecting to Big Query\nConnecting to Big Query is not required for running the backend (if you run with UPDATE_DATA=false), but is required for things like catching up ledger data in redis.\n\nThis project is pulling from SDF's `crypto-stellar` public data set, so no special credentials are required. However you will need a Google Cloud Platform project with a service account to be able to access Big Query.\n\nDirections for creating a service account [can be found here](https://cloud.google.com/docs/authentication/getting-started).\n\nOnce you've created a service account, add the service account key json file to the `gcloud` folder under the name `service-account.json`. An example json file shows what the file structure should look like.\n", "release_dates": []}, {"name": "developers", "description": "Stellar developer portal site generator.", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Stellar Developers\nStellar developer portal site generator.\n\nThis uses gulp and metalsmith (plus a heap of plugins) to generate the site.\n\n## Dependencies\n\nTo build this project, you must have the following dependencies installed:\n\n- node 10.16.3\n- npm\n- yarn\n\n## Installation\n```bash\ngit clone https://github.com/stellar/developers # or git@github.com:stellar/developers.git\nnpm install --no-shrinkwrap\nyarn install\n```\n\n(Note the `no-shrinkwrap` option is because of an issue in `metalsmith-concat`: https://github.com/aymericbeaumet/metalsmith-concat/issues/22)\n\n## Docs repository cloning\nThe developers site tool generates content pulled in from other repos. These repositories are configured in `repos.json` and stored in `repos/`. To clone all the required repositories, run:\n```\nnode_modules/.bin/gulp git:clone\n```\n\nKeeping these repositories up to date is the responsibility of the person using this tool. Here is a simple bash command you can use to do a `git pull` on all the repos.\n\n```\nfor dir in ./repos/*;\ndo\n  if [[ -d $dir ]]; then\n    ( echo; cd \"$dir\"; pwd; git pull );\n  fi;\ndone\n```\n\n## Development\nTo generate the static site, run the following inside your repo containing this folder:\n\n```bash\nnode_modules/.bin/gulp # or just `gulp` if you have it installed globally or have path set up\n```\n\nTo run a web server and view the site in a browser:\n\n```bash\nnode_modules/.bin/gulp watch serve\n```\n\nThis will also automatically rebuild the site when edits are made. (To serve without rebuilding, drop the `watch` argument.)\n\nBy default, the site is served under the developers/ subfolder. This is to reduce the amount of bugs when this site is deployed to https://www.stellar.org/developers/. This can be changed by passing a custom baseUrl to the gulp build task like so: `gulp --baseUrl=\"/\"` or `gulp build --baseUrl=\"/\"`.\n\nWhen working on the site, you can also use the `--debug` option to generate output that is easier to debug in the browser (it includes things like sourcemaps).\n\n\n### Browser JavaScript\nBrowser JavaScript files live in [`src/js`](/src/js/). `vendor.js` is generated from bower_components and not checked in to the repository.\n\nTo add a new browser JS file, add it to [`src/js`](/src/js/) and update the metalsmith concat step by adding your new file to the list. The list of JS files is order sensitive.\n\n## Development conventions\n- Use yaml especially for front matter since Github can nicely display markdown files with this\n- 2 spaces everywhere\n\n### Writing Examples\n\nThe developer portal for stellar includes a system for displaying code-samples alongside the documentation for horizon endpoints. To recognize and process these examples, you must write them in a particular way:\n\n1.  Any markdown (.md) file in a project that has a path prefix of `/docs/horizon-examples` will be considered to be an example file.\n2.  The example file must include a `language` attribute in it's front matter.  Valid values for this attribute are `curl`, `ruby`, `javascript`, and `go`\n3.  The file's basename must match the basename of the horizon endpoint to which it is associated.  For example `docs/horizon-examples/accounts-all.md` will be associated with the \"accounts-all\" horizon endpoint.\n\nBy following the rules above, your example file should get recognized by the build pipeline and slotted into the appropriate output file.\n\n## Client Data\nSometimes, we may want to pass frontmatter data to js scripts on the page. Documents can specify \"client data\" in front matter. The term client refers to the browser. The `clientData` key in the front matter of a document will be converted to JSON and put in the web page as a js variable `window.clientData`. The `clientData` must be an object in order to successfully appear in the html.\n\n## Troubleshooting\n\n### No handlebars file\n\n```sh\n[00:49:37] Error: ENOENT: no such file or directory, open '/app/layouts/plans.handlebars'\n```\n\nThis happens when you add a new directory in a `docs` folder in one of the repos that `stellar/developers` processes. If you don't want any of the docs in the directory to be included in the developers site, you can add your directory to the `excluded_dirs` in `gulp/enhance.js:addSection`.\n\n## Contributing\nPlease read the [contributing guide](CONTRIBUTING.md) to learn more about how to contribute to the developer portal. For contributions to docs, please put contributions in their respective repositories.\n\n## License\nThis project is licensed under Apache License Version 2.0. For more information, refer to the [LICENSE.txt](LICENSE.txt) file.\n", "release_dates": []}, {"name": "django-polaris", "description": "An extendable Django app for building modular Stellar services", "language": "Python", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": null, "release_dates": ["2023-10-12T16:35:55Z", "2023-10-12T16:38:26Z", "2023-10-11T17:12:49Z", "2023-10-11T17:20:56Z", "2023-08-21T18:53:15Z", "2023-03-14T17:29:47Z", "2023-01-19T22:43:08Z", "2022-11-23T00:32:22Z", "2022-09-16T17:01:48Z", "2022-08-17T15:41:15Z", "2022-07-19T21:36:23Z", "2022-06-09T17:57:09Z", "2022-05-13T19:39:06Z", "2022-04-04T17:10:25Z", "2022-03-04T21:49:52Z", "2021-12-01T20:50:41Z", "2021-11-12T19:59:03Z", "2021-11-11T03:10:35Z", "2021-11-09T18:43:49Z", "2021-10-28T18:03:53Z", "2021-10-19T00:14:04Z", "2021-10-06T19:57:44Z", "2021-10-06T20:15:03Z", "2021-09-13T21:25:14Z", "2021-09-09T23:06:38Z", "2021-09-02T22:54:06Z", "2021-09-02T21:28:53Z", "2021-09-02T22:58:12Z", "2021-08-30T16:17:59Z", "2021-08-25T22:36:40Z"]}, {"name": "django-polaris-circle", "description": "A reusable Django app for Circle USDC custody support in django-polaris deployments", "language": "Python", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": null, "release_dates": []}, {"name": "docs-wallet", "description": null, "language": "SCSS", "license": null, "readme": "![Built With Stencil](https://img.shields.io/badge/-Built%20With%20Stencil-16161d.svg?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjIuMSwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4IgoJIHZpZXdCb3g9IjAgMCA1MTIgNTEyIiBzdHlsZT0iZW5hYmxlLWJhY2tncm91bmQ6bmV3IDAgMCA1MTIgNTEyOyIgeG1sOnNwYWNlPSJwcmVzZXJ2ZSI%2BCjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI%2BCgkuc3Qwe2ZpbGw6I0ZGRkZGRjt9Cjwvc3R5bGU%2BCjxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik00MjQuNywzNzMuOWMwLDM3LjYtNTUuMSw2OC42LTkyLjcsNjguNkgxODAuNGMtMzcuOSwwLTkyLjctMzAuNy05Mi43LTY4LjZ2LTMuNmgzMzYuOVYzNzMuOXoiLz4KPHBhdGggY2xhc3M9InN0MCIgZD0iTTQyNC43LDI5Mi4xSDE4MC40Yy0zNy42LDAtOTIuNy0zMS05Mi43LTY4LjZ2LTMuNkgzMzJjMzcuNiwwLDkyLjcsMzEsOTIuNyw2OC42VjI5Mi4xeiIvPgo8cGF0aCBjbGFzcz0ic3QwIiBkPSJNNDI0LjcsMTQxLjdIODcuN3YtMy42YzAtMzcuNiw1NC44LTY4LjYsOTIuNy02OC42SDMzMmMzNy45LDAsOTIuNywzMC43LDkyLjcsNjguNlYxNDEuN3oiLz4KPC9zdmc%2BCg%3D%3D&colorA=16161d&style=flat-square)\n\n# Stencil Component Starter\n\nThis is a starter project for building a standalone Web Component using Stencil.\n\nStencil is also great for building entire apps. For that, use the [stencil-app-starter](https://github.com/ionic-team/stencil-app-starter) instead.\n\n# Stencil\n\nStencil is a compiler for building fast web apps using Web Components.\n\nStencil combines the best concepts of the most popular frontend frameworks into a compile-time rather than run-time tool.  Stencil takes TypeScript, JSX, a tiny virtual DOM layer, efficient one-way data binding, an asynchronous rendering pipeline (similar to React Fiber), and lazy-loading out of the box, and generates 100% standards-based Web Components that run in any browser supporting the Custom Elements v1 spec.\n\nStencil components are just Web Components, so they work in any major framework or with no framework at all.\n\n## Getting Started\n\nTo start building a new web component using Stencil, clone this repo to a new directory:\n\n```bash\ngit clone https://github.com/ionic-team/stencil-component-starter.git my-component\ncd my-component\ngit remote rm origin\n```\n\nand run:\n\n```bash\nnpm install\nnpm start\n```\n\nTo build the component for production, run:\n\n```bash\nnpm run build\n```\n\nTo run the unit tests for the components, run:\n\n```bash\nnpm test\n```\n\nNeed help? Check out our docs [here](https://stenciljs.com/docs/my-first-component).\n\n\n## Naming Components\n\nWhen creating new component tags, we recommend _not_ using `stencil` in the component name (ex: `<stencil-datepicker>`). This is because the generated component has little to nothing to do with Stencil; it's just a web component!\n\nInstead, use a prefix that fits your company or any name for a group of related components. For example, all of the Ionic generated web components use the prefix `ion`.\n\n\n## Using this component\n\n### Script tag\n\n- [Publish to NPM](https://docs.npmjs.com/getting-started/publishing-npm-packages)\n- Put a script tag similar to this `<script src='https://unpkg.com/my-component@0.0.1/dist/mycomponent.js'></script>` in the head of your index.html\n- Then you can use the element anywhere in your template, JSX, html etc\n\n### Node Modules\n- Run `npm install my-component --save`\n- Put a script tag similar to this `<script src='node_modules/my-component/dist/mycomponent.js'></script>` in the head of your index.html\n- Then you can use the element anywhere in your template, JSX, html etc\n\n### In a stencil-starter app\n- Run `npm install my-component --save`\n- Add an import to the npm packages `import my-component;`\n- Then you can use the element anywhere in your template, JSX, html etc\n", "release_dates": []}, {"name": "dotnet-stellar-sdk", "description": "Stellar API SDK for .NET Core 2.x and .NET Standard 2.0", "language": "C#", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<!-- PROJECT LOGO -->\n\n<br /><p align=\"center\"> <a href=\"https://github.com/elucidsoft/dotnet-stellar-sdk\"><img width=\"460\" height=\"300\" src=\"https://raw.githubusercontent.com/elucidsoft/dotnet-stellar-sdk/master/.github/images/logo.svg\"> </a> <!-- TITLE AND BADGES --> <h3 align=\"center\">dotnet-stellar-sdk</h3> <p align=\"center\"> Stellar API SDK for .NET Core 2.x and .NET Standard 2.0 <br /> <a href=\"https://ci.appveyor.com/project/elucidsoft/dotnet-stellar-sdk/branch/master\"> <img src=\"https://ci.appveyor.com/api/projects/status/n34q6l3wyar2rq5l/branch/master?svg=true\"></a> <a href=\"https://coveralls.io/github/elucidsoft/dotnet-stellar-sdk?branch=master\"> <img src=\"https://coveralls.io/repos/github/elucidsoft/dotnet-stellar-sdk/badge.svg?branch=master\"></a><a href=\"https://www.codefactor.io/repository/github/elucidsoft/dotnet-stellar-sdk\"> <img src=\"https://www.codefactor.io/repository/github/elucidsoft/dotnet-stellar-sdk/badge\"></a> <a href=\"https://www.nuget.org/packages/stellar-dotnet-sdk\"> <img src=\"https://buildstats.info/nuget/stellar-dotnet-sdk\"> </a><br /><br /><!-- USEFUL LINKS--><a href=\"https://elucidsoft.github.io/dotnet-stellar-sdk/\"><strong>Explore the docs \u00bb</strong></a> <br /> <br /> <a href=\"https://github.com/elucidsoft/dotnet-stellar-sdk/issues/new?template=Bug_report.md\">Report Bug</a> \u00b7 <a href=\"https://github.com/elucidsoft/dotnet-stellar-sdk/issues/new?template=Feature_request.md\">Request Feature</a> \u00b7 <a href=\"https://github.com/elucidsoft/dotnet-stellar-sdk/security/policy\">Report Security Vulnerability</a> </p></p>\n\n<!-- TABLE OF CONTENTS -->\n\n## Table of Contents\n\n-   [About the Project](#about-the-project)\n-   [Installation](#installation)\n    -   [Visual Studio](#visual-studio)\n    -   [JetBrains Rider](#jetbrains-rider)\n    -   [Other](#other)\n-   [Usage](#usage)\n-   [XDR](#xdr)\n-   [XDR Generation](#xdr-generation)\n-   [Contributors](#contributors)\n-   [License](#license)\n-   [Acknowledgements](#acknowledgements)\n\n<!-- ABOUT THE PROJECT -->\n\n## About The Project\n\n`dotnet-stellar-sdk` is a **Net Core/Standard** library for communicating with a [Stellar Horizon server](https://github.com/stellar/go/tree/master/services/horizon). It is used for building Stellar apps.\n\n_This project originated as a full port of the official [Java SDK API](https://github.com/stellar/java-stellar-sdk)_\n\n## Installation\n\nThe `stellar-dotnet-sdk` library is bundled in a NuGet Package.\n\n-   [NuGet Package](https://www.nuget.org/packages/stellar-dotnet-sdk)\n\n### Visual Studio\n\n-   Using the [console](https://docs.microsoft.com/en-us/nuget/consume-packages/install-use-packages-powershell)\n\n    -   Run `Install-Package stellar-dotnet-sdk` in the console.\n\n-   Using the [NuGet Package Manager](https://docs.microsoft.com/en-us/nuget/consume-packages/install-use-packages-visual-studio)\n\n    -   Search this package [NuGet Package](https://www.nuget.org/packages/stellar-dotnet-sdk) and install it.\n\n### JetBrains Rider\n\n-   <https://www.jetbrains.com/help/rider/Using_NuGet.html#>\n\n### Other\n\n-   <https://docs.microsoft.com/en-us/nuget/consume-packages/overview-and-workflow#ways-to-install-a-nuget-package>\n\n<!-- USAGE EXAMPLES -->\n\n## Usage\n\nCheck the [Tutorials](https://elucidsoft.github.io/dotnet-stellar-sdk/tutorials/index.html) page to get started.\n\n**In case of doubts or issues, you can ask for help here:**\n\n-   [Stellar Stack Exchange](https://stellar.stackexchange.com/)\n\n-   [Keybase Team](https://keybase.io/team/stellar_dotnet)\n\n## XDR\n\n[![NuGet Badge](https://buildstats.info/nuget/stellar-dotnet-sdk-xdr)](https://www.nuget.org/packages/stellar-dotnet-sdk-xdr/)\n\nIf you only need the XDR objects in a .NET Standard NuGet package, then you can get those here: <https://www.nuget.org/packages/stellar-dotnet-sdk-xdr/>\n\n## XDR Generation\n\nIn order to generate the XDR Files automatically in C# a custom XDR Generator must be used.\n\nYou can find the latest working generator here: <https://github.com/fracek/xdrgen/tree/csharp>\n\nYou can use that version of xdrgen to regenerate the XDR files from the .x files located from the [source](https://github.com/stellar/stellar-core/tree/master/src/xdr) of the original API SDK for Horizon.\n\n<!-- CONTRIBUTORS-->\n\n## Contributors\n\n-   Eric Malamisura (Twitter: [@EricDaCoder](https://twitter.com/EricDaCoder), Keybase: [elucidsoft](https://keybase.io/elucidsoft))\n-   Kirbyrawr (Keybase: [Kirbyrawr](https://keybase.io/Kirbyrawr))\n-   Michael Monte\n-   Francesco Ceccon\n\n<!-- LICENSE -->\n\n## License\n\n`dotnet-stellar-sdk` is licensed under an Apache-2.0 license. See the [LICENSE](https://github.com/elucidsoft/dotnet-stellar-sdk/blob/master/LICENSE.txt) file for details.\n\n<!-- ACKNOWLEDGEMENTS -->\n\n## Acknowledgements\n\n-   Stellar Development Foundation\n\n<!-- Disclaimer -->\n\n<!-- This readme is a modification of https://github.com/othneildrew/Best-README-Template that is licensed under MIT -->\n", "release_dates": []}, {"name": "dts-xdr", "description": "A library for generating TypeScript declarations (.d.ts) for js-xdr auto-generated files.", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# dts-xdr\n[![Stellar](https://circleci.com/gh/stellar/dts-xdr.svg?style=shield)](https://circleci.com/gh/stellar/dts-xdr)\n\n`dts-xdr` is a library for generating `TypeScript` declarations file (`.d.ts`) for [js-xdr](https://github.com/stellar/js-xdr) auto-generated files.\n\nThis library uses [jscodeshift](https://github.com/facebook/jscodeshift) to generate the definitions, follow the steps below to generate definitions.\n\n## Setup\n\n```sh\ngit clone https://github.com/stellar/dts-xdr.git\ncd dts-xdr\nyarn install\n```\n\n## Usage\n\nYou can use this library in two mode:\n\n### Source replacement\n\nThe first one is using inline replacement which is the default mode when you call `jscodeshift`. The following will replace the given file with the generated code:\n\n> npx jscodeshift -t src/transform.js sample/stellar-xdr_generated.js\n\nAfter you run the command above, `sample/stellar-xdr_generated.js` will have the type definitions.\n\n### Output mode\n\nThe second mode is specifying an output file, this mode won't change the source file. The following command will generate a new file called `stellar-xdr_generated.d.ts` with the `TypeScript` declarations:\n\n> OUT=stellar-xdr_generated.d.ts npx jscodeshift -t src/transform.js sample/stellar-xdr_generated.js\n", "release_dates": []}, {"name": "escape-bytes", "description": "Escapes bytes that are not printable ASCII characters.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# escape-bytes\n\nEscapes bytes that are not printable ASCII characters.\n\nThe exact rules are:\n- Nul is escaped as `\\0`.\n- Tab is escaped as `\\t`.\n- Line feed is escaped as `\\n`.\n- Carriage return is escaed as `\\r`.\n- Backslach is escaped as `\\\\`.\n- Any character in the printable ASCII range `0x20`..=`0x7e` is not escaped.\n- Any other character is hex escaped in the form `\\xNN`.\n\nIntended for use where byte sequences are not valid ASCII or UTF-8 but need\nto be stored in a semi-human readable form where only ASCII or UTF-8 are\npermitted.\n\n### Examples\n\n#### Escape\n\n```rust\nlet str = b\"hello\\xc3world\";\nlet escaped = escape_bytes::escape(str);\nassert_eq!(escaped, br\"hello\\xc3world\");\n```\n\n#### Unescape\n\n```rust\nlet escaped = br\"hello\\xc3world\";\nlet unescaped = escape_bytes::unescape(escaped)?;\nassert_eq!(unescaped, b\"hello\\xc3world\");\n```\n\nLicense: Apache-2.0\n", "release_dates": ["2023-12-01T18:30:23Z", "2023-12-01T09:56:24Z"]}, {"name": "fca00c-asteroids", "description": "Learn Soroban and compete for a top spot on the leaderboard in Fast, Cheap & Out of Control", "language": "Rust", "license": null, "readme": "# Asteroids <!-- omit in toc -->\n\nToday's game will set you on a spaceship in one of the darkest corners of the\nuniverse! It is your quest to explore this uncharted portion of the universe and\ndestroy 100 asteroids. Don't forget to re-fuel and upgrade your ship along the\nway.\n\n## TL;DR\n\nProvided here are the bullet points of what you will **absolutely need** to know\nto successfully play this game. This is _intentionally_ quite brief, and\neverything is explained in much greater detail further on down in this document.\n\n- Your goal is to earn `100 points` by shooting and destroying asteroids\n- You will need to navigate your ship through multiple `16x16` galaxy grids\n  - `6 asteroids` are contained within each galaxy\n  - `2 fuel pods` are contained within each galaxy\n- Use the `p_turn`, `p_move`, `p_shoot`, `p_harvest`, and `p_upgrade` functions\n  to control your ship\n- Turning, moving, and shooting all consume different amounts of fuel\n- Upgrade your ship to improve fuel efficiency\n- Upgrading consumes points\n\n## Table of Contents <!-- omit in toc -->\n\n<details>\n<summary>Expand Table of Contents</summary>\n\n- [TL;DR](#tldr)\n- [Competition Leaderboards and Schedule](#competition-leaderboards-and-schedule)\n- [Get Started with Soroban](#get-started-with-soroban)\n- [How to Play](#how-to-play)\n  - [Gather Your Materials](#gather-your-materials)\n  - [The Game Engine Contract](#the-game-engine-contract)\n  - [The Map](#the-map)\n  - [Controlling Your Ship](#controlling-your-ship)\n  - [Compile Your Contract](#compile-your-contract)\n  - [Submit Your Ship](#submit-your-ship)\n- [Useful Information](#useful-information)\n  - [`GameEngine` Initialization Parameters](#gameengine-initialization-parameters)\n  - [Diagonal Turns and Moves](#diagonal-turns-and-moves)\n  - [Helpful Game Engine Methods](#helpful-game-engine-methods)\n  - [Testing Your Contract](#testing-your-contract)\n- [Suggestions and Strategies](#suggestions-and-strategies)\n\n</details>\n\n## Competition Leaderboards and Schedule\n\n_Fast, Cheap, and 0ut 0f Control_ is a wild[,][,] experimental take on coding\ncompetitions. Your goal is to submit a working contract that solves a given\nproblem, or performs a given task. We will track results in the following three\n(3) leaderboards.\n\n- **Fastest Submission**: On this leaderboard, the top prizes go to the entrants\n  submitting a complete contract first, second, and so on. A good, old-fashioned\n  race!\n- **Smallest WASM**: We want to test the limits of how small these deployed\n  contracts can be. We're awarding prizes for valid contracts with the very\n  smallest compiled sizes.\n- **Lowest Resource Use**: We are measuring resource use as the number of CPU\n  instructions used during a contract's invocation. Top spots are given to\n  complete contracts with the least CPU utilization.\n\nEach time you submit a contract, it will be judged according to all leaderboards\ncurrently accepting entries. Your position in each leaderboard is determined by\nyour **best** submission to _that particular_ leaderboard.\n\n- **Yes!** You _can_ submit more than once. You probably should, if you want to\n  be competitive within each leaderboard.\n- **Yes!** You _can_ earn a prize from each leaderboard. Specific award amounts\n  can be found in the [official fca00c rules][rules].\n\nThis round of fca00c will run according to the following schedule:\n\n| Date       | Time (EST) | Unix Timestamp | What's Happening?                                                                    |\n| ---------- | ---------- | -------------- | ------------------------------------------------------------------------------------ |\n| 2023-02-15 | 7:00pm     | 1676505600     | fca00c-asteroids goes live! All leaderboards are open for entries.                   |\n| 2023-02-22 | 7:00pm     | 1677110400     | Submission deadline for _Smallest WASM_ leaderboard.                                 |\n| 2023-03-01 | 7:00pm     | 1677715200     | Submission deadline for _Fastest Submission_ and _Lowest Resource Use_ leaderboards. |\n\n## Get Started with Soroban\n\nAs a _very brief_ precursor before we get too deep into the weeds, here is a\nquick cheatsheet of references, links, and resources you might find useful if\nyou are confused by the words _Soroban_, _Stellar_, _Rust_, or anything else we\ndiscuss.\n\n- [Soroban Documentation][soroban-docs]: This is a great first step to learn\n  more about Stellar's smart contract platform.\n- [Soroban SDK Crate][soroban-sdk-crate]: The official Rust SDK for interacting\n  with the Soroban platform.\n- [The Rust Book][rust-book]: The definitive volume for learning the Rust\n  programming language.\n- [Rustlings][rustlings]: A more interactive method for learning Rust.\n- [Soroban Quest][series-5]: Soroban Quest is an interactive course all about\n  Soroban.\n  - \u26a0\ufe0f Due to Soroban's current alpha nature, this course may or may not be\n    fully up-to-date, but it will provide some valuable context.\n- [Stellar Quest][sq-learn]: Soroban lives on top of the Stellar network.\n  Writing smart contracts for Soroban doesn't _require_ an in-depth knowledge of\n  Stellar, but the context can be useful.\n\n[soroban-docs]: https://soroban.stellar.org/docs\n[soroban-sdk-crate]: https://docs.rs/soroban-sdk\n[rust-book]: https://doc.rust-lang.org/book/\n[rustlings]: https://github.com/rust-lang/rustlings\n[series-5]: https://quest.stellar.org/soroban\n[sq-learn]: https://quest.stellar.org/learn\n\n## How to Play\n\n### Gather Your Materials\n\nBefore you can begin writing your contract, you'll need some materials first.\n\n1. [Setup your Soroban development environment][soroban-setup] using this guide\n   from the Soroban documentation.\n2. Git clone the [`stellar/fca00c-asteroids` repo][repo]. This is the\n   _canonical_ source for information and materials used for this challenge.\n\nIf you are reading this document anywhere besides the [fca00c site][site] (in a\ncode editor, for example), you've probably already done everything above, so you\nget to skip right to the front of the line. Well done!\n\n> **Note:** The competition materials may be updated, changed, etc. from time to\n> time. If you've cloned the git repository, we recommend you `git pull` often.\n> If something seems to be broken, not working as expected, etc. checking for an\n> up-to-date repo is an excellent first step.\n\n### The Game Engine Contract\n\nWe have built a _Game Engine_ contract. Your task is to write a contract that\nwill interact with our game engine in the Soroban environment. This contract has\nbeen included in two formats:\n\n1. In the `contracts/_game-engine` directory, we've provided the source code for\n   the contract, broken into its various modules. This version of the contract\n   is **NOT** intended to be modified, or used in your contract. It's being\n   provided only as a resource and reference to aid in understanding and\n   problem-solving.\n2. As a compiled WASM binary: `contracts/game_engine.wasm`. This is the version\n   of the contract you'll want to build and test your solution with. The starter\n   tests we've provided in the `solution` directory will mimic our evaluation\n   environment as closely as possible.\n\nIf you want to investigate the compiled binary, the `soroban contract bindings`\ncommand will give you a pretty decent understanding. `soroban contract bindings`\nis intended to generate client bindings for a contract. This will give you great\ninsight into what functions exist in a given WASM file, and what arguments they\nare expecting. You can run the command like this:\n\n```bash\nsoroban contract bindings --wasm /path/to/game_engine.wasm --output rust\n```\n\n### The Map\n\nThe map in our asteroids game is an infinite cartesian plane (yes, this universe\nis \"flat,\" don't worry about it. You should be focusing on the game, anyway).\nThis plane is then divided into \"galaxies.\" Each galaxy is a `16x16` square.\nNote the difference between `16 squares` and `17 points` along either the `x` or\n`y` axis that makes up each galaxy. For example, your ship starts its journey in\nthe galaxy that has a center coordinate of `(8, 8)`, and it is comprised of all\npoints within the following coordinates:\n\n```text\nBottomLeft: (0, 0)\nBottomRight: (16, 0)\nTopRight: (16, 16)\nTopLeft: (0, 16)\n```\n\nEach galaxy will contain `6 asteroids` and `2 fuel pods`. You can only see or\nshoot asteroids that are inside your current galaxy. When the time comes to\nchange galaxies, you must move your ship outside the boundaries of your current\ngalaxy.\n\n> **Note:** It would be more technically correct to say, \"Each galaxy will\n> _usually_ contain `6 asteroids` and `2 fuel pods`.\" It is unlikely, but\n> _possible_ that our game engine contract will generate a set of colliding\n> coordinates for two elements (asteroids or fuel pods). In this improbable\n> circumstance, a fuel pod will take priority over an asteroid, and there will\n> be only one element left at this point (\"erasing\" the previous element). A\n> galaxy like this would contain fewer than 8 map elements.\n\n<details>\n<summary>Expand Map Visualizations</summary>\n\nBelow, a single galaxy is illustrated. After the game engine has been first\ninitialized, your ship is placed at `(8, 8)` within the first galaxy.\n\n![A single galaxy in the asteroids game][single-galaxy]\n\nEven though you can only _see_ one galaxy at a time, there are neighboring\ngalaxies that contain their own asteroids and fuel pods. These are only\naccessible to you once your ship has entered that next galaxy.\n\n![Multiple galaxies in the asteroids game][multi-galaxy]\n\n</details>\n\n### Controlling Your Ship\n\nYour vessel is outfitted with the most _bleeding-edge_ capabilities we could\ncram into a starship! Your ship is capable of performing all these actions:\n\n- **Turn**: Your ship can turn in any direction you choose. Turning does cost\n  fuel, though. It will cost you the same amount of fuel, no matter which\n  direction you are turning to.\n  - Use the game engine's `p_turn()` method to turn your ship in the desired\n    direction before you shoot or move. Each turn will cost `1 fuel`, no matter\n    how far you are turning (i.e., turning 45\u00b0 costs the same as turning 180\u00b0).\n  - You must supply a `Direction` argument to the `p_turn()` method, specifying\n    the new direction you'd like your ship to face:\n    `engine.p_turn(&Direction::Left)`.\n  - Remember, calling the `p_turn()` method consumes a flat cost of `1 fuel`,\n    even if you turn 315\u00b0.\n  - Read below for more details on [diagonal turns][diagon-alley].\n- **Move**: Your ship can move any number of spaces as long as you have enough\n  fuel to cover that cost. Each space you move costs fuel as well (twice as much\n  fuel as each turn, mind you).\n  - Use the game engine's `p_move()` method to move your ship. By default, your\n    ship will move `1 space` in the direction it is facing.\n  - You can (optionally) provide a number of spaces you'd like your ship to\n    move: `engine.p_move(Some(4))`.\n  - Remember that moving will cost `2 fuel` for every _space_ moved, no matter\n    how many times `p_move()` is called, or how many spaces you provide to it as\n    an argument. The calculation is **always** made on the number of spaces your\n    ship moves.\n- **Shoot Asteroids**: Your ship is capable of shooting asteroids to destroy\n  them and earn valuable points! For each asteroid destroyed, you will be\n  rewarded with `1 point`. Your ship's laser cannon has a range of `3 spaces`.\n  For example, if your ship is currently located at `(53, 72)`, you could shoot\n  and destroy asteroids located at `(53, 75)` or `(50, 75)`; however, an\n  asteroid located at `(49, 72)` would be out of range.\n  - Use the game engine's `p_shoot()` method to shoot your laser cannon in the\n    direction your ship is currently facing. Each time you fire the cannon will\n    cost `5 fuel`, whether you hit an asteroid or not.\n  - If your ship is facing in a diagonal direction, you can shoot asteroids\n    within range of that direction. This can save you fuel and execution costs\n    by minimizing the number of moves needed to get within range of an asteroid.\n  - You _can_ shoot asteroids sharing the same coordinates as your ship (i.e.,\n    an asteroid you're \"on top of\").\n  - You _can_ shoot multiple asteroids in one shot in the same direction,\n    provided they are all within range of your ship (i.e., you shoot in a\n    straight line, and any asteroids on that line will be destroyed).\n- **Harvest Fuel Pods**: The amount of fuel you begin with will not be enough to\n  complete this quest. Sorry! Fuel prices are quite high at the moment. So,\n  along the way, you will need to harvest fuel pods to recharge your ship.\n  - Use the game engine's `p_harvest()` method to harvest a fuel pod once you\n    have moved your ship to the fuel pod's coordinates. Each fuel pod harvested\n    will give your ship an additional `100 fuel`.\n- **Upgrade**: Your ship even comes with its own upgrade feature. You can\n  upgrade your ship **only once**, and you can do so at any point during your\n  quest (only you can determine when the time is right). You will have to give\n  up some of the points you've worked hard to earn, but after the upgrade is\n  complete your ship will use half the fuel for _turning_, _moving_, and\n  _shoooting_.\n  - Use the game engine's `p_upgrade()` method to upgrade your ship at any point\n    during your quest. Upgrading will cost `5 points`.\n\n### Compile Your Contract\n\nWhen you've written a working contract, you'll need to build a binary file that\nwill contain your contract's WASM byte-code. This executable file is what you\nare meant to submit as \"Your Ship\" on the [fca00c site][site].\n\nCompilation can be done many different ways, but we've provided a couple\ncommands in our `Makefile` to get you going. `make build` will produce a binary\ncompiled according to the \"release\" profile, while `make build-optimized` will\nwork to optimize that build and minimize the size of the `.wasm` file.\n\nYou can also choose from several different optimization strategies to produce an\nefficient contract binary. There is much more nuance here than we have space to\nget into fully. However, you can use the following links to get started learning\nmore.\n\n- [Optimizing Builds][soroban-optimizing]: This example shows how to use the\n  `soroban-cli` to optimize a compiled contract using some sensible defaults.\n- [The `wasm_opt` crate][wasm-opt-crate]: This can be used to further customize\n  and optimize your compiled contract.\n- [The `Binaryen` toolkit][binaryen]: Binaryen is a compiler and toolchain for\n  WebAssembly. This toolkit is used \"under the hood\" in the `wasm_opt` crate.\n\n[soroban-optimizing]:\n    https://soroban.stellar.org/docs/getting-started/hello-world#optimizing-builds\n[wasm-opt-crate]: https://docs.rs/wasm-opt/latest/wasm_opt/\n[binaryen]: https://github.com/WebAssembly/binaryen\n\n### Submit Your Ship\n\nYou're finished! Really!? Sweet!! You should be proud of yourself, just for\ngetting to this part!\n\nWhen you're ready to have your smart contract evaluated, your next step is to\n[upload your compiled WASM file on the fca00c site][upload-contract]. You'll\nhave the option to log in and select how your name will be displayed if you land\non the leaderboard, and you can choose the file you wish to upload. We'll take\ncare of everything else from there!\n\n> **Note:** The Soroban environment we run in our backend will limit your\n> contract invocation to 30 seconds of runtime, and `16_000_000_000` CPU cycles.\n> If your contract runs past these limits, your validation will fail.\n\n## Useful Information\n\n### `GameEngine` Initialization Parameters\n\nWhen we are testing your solution contract, we will run it against our game\nengine with a prescribed and consistent set of initialization values. These have\nbeen documented in the `test.rs` file, but we'll include our initialization\nvalues and some brief descriptions here, as well:\n\n- `move_step (1)`: The number of spaces your ship will `p_move()` by default\n- `laser_range (3)`: The maximum distance from which your ship's laser can\n  `p_shoot()` an asteroid\n- `seed (8891)`: The map's randomness is seeded with a known, consistent `u64`\n  value (this ensures everyone is playing on the same map)\n- `view_range (16)`: The size of each galaxy grid\n- `fuel: ()`: Soroban functions can only accept a maximum of 10 parameters, so\n  all the fuel parameters are collected here\n  - `player_fuel (50)`: The amount of fuel your ship contains at initialization\n  - `shoot_fuel (5)`: The amount of fuel consumed by the `p_shoot()` method\n  - `move_fuel (2)`: The amount of fuel consumed when you `p_move()` a single\n    space\n  - `turn_fuel (1)`: The amount of fuel consumed by the `p_turn()` method\n- `asteroid_reward (1)`: The number of points you are rewarded for destroying an\n  asteroid\n- `asteroid_density (6)`: The number of asteroids each galaxy will contain\n- `pod_density (2)`: The number of fuel pods each galaxy will contain\n\n### Diagonal Turns and Moves\n\nIf you take a look at the game engine's type definitions, you may notice the\n`Direction` type looks like this:\n\n```rust\npub enum Direction {\n    Up,\n    UpRight,\n    Right,\n    DownRight,\n    Down,\n    DownLeft,\n    Left,\n    UpLeft,\n}\n```\n\nFrom the presence of directions like `UpRight` and `DownLeft`, you could infer\n(correctly) that your ship is capable of turning and moving diagonally. You can\nboost your ship's efficiency by moving diagonally when that is called for.\n\nFor everyone's sake, we've simplified the calculations in the game contract. 1\nunit of diagonal movement is the same as 1 unit of horizontal or vertical\nmovement (We know, things can get weird out there in space).\n\nFor example, if your ship is currently pointing `Up` at `(0, 0)`, and you want\nto move your ship to `(3, 2)`, here's how this can help:\n\n```text\n# Fuel Use Without Diagonal Moves\np_move(2) + p_turn(Right) + p_move(3) = 4 + 1 + 6 = 11 fuel\n\n# Fuel Use With Diagonal Moves\np_turn(UpRight) + p_move(2) + p_turn(Right) + p_move(1) = 1 + 4 + 1 + 2 = 8 fuel\n```\n\nYou can also shoot asteroids in diagonal directions, as long as your ship is\nfacing that direction and they are within range. This is a very powerful\nfuel-saving technique!\n\n### Helpful Game Engine Methods\n\nThe game engine contract provides some helper methods so you can orient yourself\nin space and monitor the other vital information about your ship:\n\n- `p_pos()`: Returns the ship's position on the map, as a set of coordinates.\n- `p_dir()`: Returns the direction your ship is currently pointed in.\n- `p_fuel()`: Returns the ship's current fuel level.\n- `p_points()`: Returns the player's current score.\n- `get_map()`: Returns the current galaxy's map as `Map<Point, MapElement>`,\n  where `MapElement` will be either an asteroid or fuel pod.\n\n### Testing Your Contract\n\nWhile writing your contract, you'll likely want to incorporate some tests along\nthe way. The `src/test.rs` file is there for that. We've included two test\nfunctions to get you started.\n\n- The `fca00c_fast()` test will test against your written contract source code,\n  and is a much quicker way to iterate throughout the build process.\n- The `fca00c_budget()` test will test against a _compiled_ WASM contract\n  binary. Of course, for this to work, you will need a compiled contract in\n  place first. You can run `make build` or `make build-optimized` (or, you can\n  do it yourself with `cargo build`, provided you know how to use it).\n\nYou'll want to keep our original `fca00c_fast()` and `fca00c_budget()` functions\nintact, but you can most definitely write your own. In fact, many people may\nfind it _easier_ to write their initial solution inside a `test.rs` file before\nbuilding the final compiled WASM binary.\n\nInside the testing environment, you can access very useful things from the `std`\ncrate, such as the `println!` macro. If you want to output any data along your\ndevelopment road, it's likely that including it in a test will be the quickest\nand easiest way to go about it.\n\n> **Note:** Rust tests do not print by default. So, if you're using `println`,\n> you will need to run the test like: `cargo test -- --nocapture`. This will\n> send any test output to stdout.\n\nThen, after you've written a working solution, it's pretty easy to get it moved\ninto your `lib.rs` file. If you want to get some kind of output from your\n`lib.rs` file, you'll need to learn all about [logging][logging] and\n[debugging][debugging] in Soroban. There is a lot there, but it's useful\nknowledge that can help you get the information you need, right from where you\nneed it.\n\n## Suggestions and Strategies\n\nThere is absolutely no shortage of interesting and unique methods you could use\nto solve this problem. _Fast, Cheap, and 0ut 0f Control_ is designed to allow\nfor many various competitive strategies. When trying to compete for pure speed\nand get the contract written before others, you'll likely care far less about\noptimizing your contract's performance or execution cost. Similarly, when you're\naiming for the very cheapest execution cost, the final deployed contract size\n_may_ not be a primary concern of yours. Your chosen strategy will need to\nreflect the relevant competition leaderboard you're currently optimizing for.\n\nTo get you started, we are providing below some suggestions and possible\nstrategies you might consider using. Take them, leave them, adapt them based on\nyour competitive context: The choice is yours.\n\n- This game's universe is infinite! It might be _possible_ to move in one single\n  direction, blasting any asteroids that happen to be right in front of you, and\n  come out victorious. That's very unlikely to work out in a cost- or\n  time-efficient manner, but you're welcome to give it a shot.\n- The `get_map()` function does quite a bit of calculating, and even accesses a\n  few different contract storage entries. Perhaps (or, perhaps not...) it would\n  be more efficient to keep track of what is in your galaxy's map on your own,\n  rather than calling `get_map()` repeatedly for the same galaxy.\n- Perhaps more important than anything else in this game is to think through\n  carefully how you will approach navigating. How far in advance do you want to\n  know the layout of your galaxy (or multiple galaxies)? Which asteroid is the\n  best next target? How low is too low for your fuel before you start looking\n  for a refill? All these questions can only be answered by you, and your\n  answers will determine your level of success in this game.\n- Before navigating to harvest a fuel pod, you might want to shoot any nearby\n  asteroids first, or shoot any you pass along the way (provided you have enough\n  fuel, that is).\n- Once you've harvested all fuel pods and destroyed all the asteroids in a\n  galaxy, it is time to move on to the next one! However, _which_ galaxy to move\n  to is certainly not a trivial choice. Plan carefully how you want to navigate,\n  considering which neighboring galaxy provides the closest, cheapest, and/or\n  fastest path of entry.\n- When you set out for a fuel pod, make sure you're heading toward the _nearest_\n  one to your current location.\n\n[,]: https://en.wikipedia.org/wiki/Fast,_Cheap_%26_Out_of_Control\n[soroban-setup]: https://soroban.stellar.org/docs/getting-started/setup\n[repo]: http://www.github.com/stellar/fca00c-asteroids\n[site]: https://fastcheapandoutofcontrol.com\n[diagon-alley]: #diagonal-turns-and-moves\n[logging]:\n    https://soroban.stellar.org/docs/how-to-guides/logging#using-the-log-macro\n[debugging]: https://soroban.stellar.org/docs/learn/debugging\n[single-galaxy]:\n    https://user-images.githubusercontent.com/2024293/217354050-405451d6-e5c5-48a4-abc4-5cc2abe5b9a3.png\n[multi-galaxy]:\n    https://user-images.githubusercontent.com/4383610/217380430-b00376fa-624f-4f9e-81ec-2fff88e63e37.png\n[upload-contract]: https://fastcheapandoutofcontrol.com/game/asteroids/submit\n[rules]: https://fastcheapandoutofcontrol.com/rules\n", "release_dates": ["2023-05-31T18:51:17Z", "2023-05-03T19:46:58Z", "2023-02-21T14:22:57Z", "2023-02-19T12:17:05Z", "2023-02-17T18:16:37Z", "2023-02-17T16:08:57Z", "2023-02-16T21:58:56Z", "2023-02-16T21:15:41Z", "2023-02-16T14:01:52Z", "2023-02-16T01:03:48Z", "2023-02-16T00:23:23Z"]}, {"name": "freighter", "description": "Stellar chrome extension", "language": "TypeScript", "license": null, "readme": "# Freighter\n\nThis repo is constructed using yarn workspaces and consists of the 4 sections:\n\n- the browser extension (`/extension`)\n- the client-facing SDK (`/@stellar/freighter-api`)\n- the docs (`/docs`)\n- some shared files that the above use (`/@shared/*`)\n\n## Prerequisites\n\nYou will need\n\n- Node (>=18): https://nodejs.org/en/download/\n- Yarn (v1.22.5 or newer): https://classic.yarnpkg.com/en/docs/install\n\n## Build the extension\n\nTo simply build a production version of the extension, install the prerequisites then navigate to this root folder in your command line and run these 2 steps:\n\n```\nyarn setup\n```\n\nfollowed by\n\n```\nyarn build:extension:production\n```\n\nThis will generate the files that make up the extension in `extension/build`\n\n## Starting a dev environment\n\n```\nyarn setup\nyarn start\n```\n\nThis will start up multiple watching builds in parallel:\n\n- The `@stellar/freighter-api` npm module\n- The docs, serving on `localhost:3000`\n- A dev server with the webapp running in the extension, serving on\n  `localhost:9000`\n- The actual built extension, able to be installed in Chrome, in `build/`\n\nEach of these will build in response to editing their source.\n\nThese can be started individually with `yarn start:\\<workspace name\\>` where\n`\\<workspace name\\>` is one of:\n\n- `freighter-api`\n- `docs`\n- `extension`\n\n```\nyarn build\n```\n\nThis will produce final output for the docs, the `@stellar/freighter` npm module, and\nthe extension.\n\n`yarn build:\\<workspace name\\>`, like the equivalent start commands, will build\nan individual workspace.\n\n### Useful URLs:\n\n[The popup webapp](http://localhost:9000/#/)\n\n[The `getPublicKey` playground](http://localhost:3000/docs/playground/getPublicKey)\n[The `signTransaction` playground](http://localhost:3000/docs/playground/signTransaction)\n\nIt's important to note that these two won't interact with the _dev server_ popup\nUI on `localhost:9000` \u2014 you'll need to re-install the unpacked extension each\ntime you make a change.\n\n### Importing a workspace\n\nIn some cases, you will want to import a workspace into another. For example, in\n`extension` we need to import `@shared/constants`. To do this, simply add\n`@shared/constants` to the dependencies list in package.json in `extension`. Yarn\nsymlinks all the workspaces, so doing so will allow you to import files from the\n`@shared/constants` workspace as if it were a published npm package.\n\n### Dependencies\n\nMany dev dependencies (such as Typescript, linters, Webpack, etc.) have been moved to the root `package.json` to allow devs to upgrade these libraries all in one place.\n\n### Pushing to repo\n\nThis repo will run a pre-push hook before pushing. This hook will run the cmd `yarn build:extension:translations` to check if any strings in the extension need to be added to the translations JSON. If there is no need to update the translations JSON, the push will go through. If there is a need to update, the changes will be automatically committed to your branch and the push will be aborted. You will need to run `git push` again.\n\nNOTE: If you're using nvm and run into an error where the git hook is using an incompatible version of node, create a file `~/.huskryc` on your system and added the following:\n\n```\n# This loads nvm.sh, sets the correct PATH before running hook, and ensures the project version of Node\nexport NVM_DIR=\"$HOME/.nvm\"\n\n[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\"\n\n# If you have an .nvmrc file, we use the relevant node version\nif [[ -f \".nvmrc\" ]]; then\n  nvm use\nfi\n```\n\nThis will instruct the git hook to use the .nvmrc found in this repo.\n", "release_dates": ["2024-03-03T18:25:40Z", "2024-02-29T21:20:27Z", "2024-02-29T16:30:04Z", "2024-02-27T21:04:49Z", "2024-02-27T16:50:37Z", "2024-02-22T17:12:58Z", "2024-02-21T23:04:59Z", "2024-02-16T01:33:07Z", "2024-02-15T22:27:48Z", "2024-02-14T23:15:57Z", "2024-02-12T21:57:53Z", "2024-02-12T21:01:10Z", "2024-02-08T23:38:41Z", "2024-02-08T23:09:54Z", "2024-02-08T18:28:35Z", "2024-02-08T17:21:07Z", "2024-02-01T23:45:18Z", "2024-02-01T16:46:35Z", "2024-01-31T19:24:02Z", "2024-01-18T23:07:58Z", "2024-01-16T22:01:40Z", "2024-01-02T22:32:39Z", "2023-12-19T17:17:26Z", "2023-12-14T22:41:28Z", "2023-12-11T22:38:02Z", "2023-12-08T20:04:23Z", "2023-12-07T22:34:22Z", "2023-12-07T20:26:25Z", "2023-12-06T16:56:57Z", "2023-12-04T20:04:26Z"]}, {"name": "freighter-backend", "description": "Freighter's indexer integration layer and general backend", "language": "TypeScript", "license": null, "readme": "# Freighter-Backend\n\nFreighter's indexer integration layer and general backend\n\n## Prerequisites\n\nYou will need\n\n- Node (>=18.0): https://nodejs.org/en/download/\n- Yarn (>=v1.22.5): https://classic.yarnpkg.com/en/docs/install\n\n## Development\n\nThis application relies on a Redis instance when `MODE=production`, you can either run `docker compose up` to use docker to stand up a Redis or you can start one on the standard port manually. If you're running in development mode, it uses a memory store.\n\nTo start the server in development mode, run:\n`yarn i && yarn start`\n\n## Production build\n\n`yarn build:prod`\n\n## Mercury Details\n\nThis project integrates with Mercury, an indexer for Stellar/Soroban. You can find general developer documentation (in their repo docs)[https://github.com/xycloo/merury-developers-documentation/blob/main/src/SUMMARY.md].\n", "release_dates": []}, {"name": "frontend-helpers", "description": "Common functionality used across many frontend projects", "language": "TypeScript", "license": null, "readme": "# Frontend Helpers\n\nThis repo contains useful functionality that we often have to duplicate across\ndifferent projects.\n\nThe goal is to have fewer lines of codes that we have to maintain, so anything\nthat we do in more than one repo should live here.\n\n## Structure\n\nAll functions are organized under the `src/helpers` folder with colocated\nMarkdown files to explain usage.\n\n## Installation\n\n```\nyarn add @stellar/frontend-helpers\n```\n\n## Adding helpers\n\n- Create a directory with the name of the helper method.\n- Inside the directory:\n  - create `index.ts` for the main code of the method,\n  - if necessary, add `README.md` file with context and/or instructions.\n- Export newly created helper to `src/index.ts`.\n", "release_dates": ["2022-07-28T19:42:00Z", "2021-10-05T19:17:44Z", "2021-10-05T18:21:41Z", "2021-10-05T17:02:06Z", "2021-09-23T16:03:23Z", "2021-09-22T21:35:05Z", "2021-08-06T20:44:59Z"]}, {"name": "go", "description": "Stellar's public monorepo of go code", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<div align=\"center\">\n<a href=\"https://stellar.org\"><img alt=\"Stellar\" src=\"https://github.com/stellar/.github/raw/master/stellar-logo.png\" width=\"558\" /></a>\n<br/>\n<strong>Creating equitable access to the global financial system</strong>\n<h1>Stellar Go Monorepo</h1>\n</div>\n<p align=\"center\">\n \n<a href=\"https://github.com/stellar/go/actions/workflows/go.yml?query=branch%3Amaster+event%3Apush\">![master GitHub workflow](https://github.com/stellar/go/actions/workflows/go.yml/badge.svg)</a>\n<a href=\"https://godoc.org/github.com/stellar/go\"><img alt=\"GoDoc\" src=\"https://godoc.org/github.com/stellar/go?status.svg\" /></a>\n<a href=\"https://goreportcard.com/report/github.com/stellar/go\"><img alt=\"Go Report Card\" src=\"https://goreportcard.com/badge/github.com/stellar/go\" /></a>\n</p>\n\nThis repo is the home for all of the public Go code produced by the [Stellar Development Foundation].\n\nThis repo contains various tools and services that you can use and deploy, as well as the SDK you can use to develop applications that integrate with the Stellar network.\n\n## Package Index\n\n* [Horizon Server](services/horizon): Full-featured API server for Stellar network\n* [Go Horizon SDK - horizonclient](clients/horizonclient): Client for Horizon server (queries and transaction submission)\n* [Go Horizon SDK - txnbuild](txnbuild): Construct Stellar transactions and operations\n* [Ticker](services/ticker): An API server that provides statistics about assets and markets on the Stellar network\n* [Keystore](services/keystore): An API server that is used to store and manage encrypted keys for Stellar client applications\n* Servers for Anchors & Financial Institutions\n  * [Compliance Server](services/compliance): Allows financial institutions to exchange KYC information\n  * [Federation Server](services/federation): Allows organizations to provide addresses for users (`jane*examplebank.com`)\n\n## Dependencies\n\nThis repository is officially supported on the last two releases of Go.\n\nIt depends on a [number of external dependencies](./go.mod), and uses Go [Modules](https://github.com/golang/go/wiki/Modules) to manage them. Running any `go` command will automatically download dependencies required for that operation.\n\nYou can choose to checkout this repository into a [GOPATH](https://github.com/golang/go/wiki/GOPATH) or into any directory.\n\n## Directory Layout\n\nIn addition to the other top-level packages, there are a few special directories that contain specific types of packages:\n\n* **clients** contains packages that provide client packages to the various Stellar services.\n* **exp** contains experimental packages.  Use at your own risk.\n* **handlers** contains packages that provide pluggable implementors of `http.Handler` that make it easier to incorporate portions of the Stellar protocol into your own http server. \n* **support** contains packages that are not intended for consumption outside of Stellar's other packages.  Packages that provide common infrastructure for use in our services and tools should go here, such as `db` or `log`. \n* **support/scripts** contains single-file go programs and bash scripts used to support the development of this repo. \n* **services** contains packages that compile to applications that are long-running processes (such as API servers).\n* **tools** contains packages that compile to command line applications.\n\nEach of these directories have their own README file that explain further the nature of their contents.\n\n### Other packages\n\nIn addition to the packages described above, this repository contains various packages related to working with the Stellar network from a go program.  It's recommended that you use [godoc](https://godoc.org/github.com/stellar/go#pkg-subdirectories) to browse the documentation for each.\n\n\n## Package source layout\n\nWhile much of the code in individual packages is organized based upon different developers' personal preferences, many of the packages follow a simple convention for organizing the declarations inside of a package that aim to aid in your ability to find code.\n\nIn each package, there may be one or more of a set of common files:\n\n- *errors.go*: This file should contains declarations (both types and vars) for errors that are used by the package.\n- *example_test.go*: This file should contains example tests, as described at https://blog.golang.org/examples.\n- *main.go/internal.go* (**deprecated**): Older packages may have a `main.go` (public symbols) or `internal.go` (private symbols).  These files contain, respectively, the exported and unexported vars, consts, types and funcs for the package. New packages do not follow this pattern, and instead follow the standard Go convention to co-locate structs and their methods in the same files. \n- *main.go* (**new convention**): If present, this file contains a `main` function as part of an executable `main` package.\n\nIn addition to the above files, a package often has files that contains code that is specific to one declared type.  This file uses the snake case form of the type name (for example `loggly_hook.go` would correspond to the type `LogglyHook`).  This file should contain method declarations, interface implementation assertions and any other declarations that are tied solely to that type.\n\nEach non-test file can have a test counterpart like normal, whose name ends with `_test.go`.  The common files described above also have their own test counterparts... for example `internal_test.go` should contains tests that test unexported behavior and more commonly test helpers that are unexported.\n\nGenerally, file contents are sorted by exported/unexported, then declaration type  (ordered as consts, vars, types, then funcs), then finally alphabetically.\n\n### Test helpers\n\nOften, we provide test packages that aid in the creation of tests that interact with our other packages.  For example, the `support/db` package has the `support/db/dbtest` package underneath it that contains elements that make it easier to test code that accesses a SQL database.  We've found that this pattern of having a separate test package maximizes flexibility and simplifies package dependencies.\n\n### Contributing\n\nContributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for more details.\n\n### Developing\n\nSee [GUIDE_FOR_DEVELOPERS.md](/services/horizon/internal/docs/GUIDE_FOR_DEVELOPERS.md) for helpful instructions for getting started developing code in this repository.\n\n[Stellar Development Foundation]: https://stellar.org\n", "release_dates": ["2024-02-16T20:30:40Z", "2024-02-12T18:24:41Z", "2024-02-05T15:25:35Z", "2024-01-26T21:29:17Z", "2023-12-06T20:25:05Z", "2023-12-06T19:43:01Z", "2023-09-19T22:10:14Z", "2023-09-18T16:17:46Z", "2023-09-18T20:27:31Z", "2023-08-14T15:29:15Z", "2023-07-27T04:20:01Z", "2023-06-22T18:51:12Z", "2023-05-01T08:56:43Z", "2023-03-29T21:43:56Z", "2023-02-15T21:48:08Z", "2023-02-08T21:19:33Z", "2022-12-07T16:09:25Z", "2022-11-28T13:25:04Z", "2022-10-18T14:52:12Z", "2022-10-17T18:18:43Z", "2022-09-08T12:40:50Z", "2022-08-15T21:10:59Z", "2022-07-29T10:21:44Z", "2022-07-03T19:35:52Z", "2022-05-26T10:41:20Z", "2022-05-27T17:54:29Z", "2022-05-02T21:07:55Z", "2022-04-29T00:40:10Z", "2022-04-19T04:23:52Z", "2022-04-13T17:09:02Z"]}, {"name": "go-xdr", "description": "Implements the XDR standard as specified in RFC 4506 in pure Google Go (Golang)", "language": "Go", "license": {"key": "isc", "name": "ISC License", "spdx_id": "ISC", "url": "https://api.github.com/licenses/isc", "node_id": "MDc6TGljZW5zZTEw"}, "readme": "# go-xdr\n\n[![Build Status](https://github.com/stellar/go-xdr/workflows/Go/badge.svg)](https://github.com/stellar/go-xdr/actions)\n[![GoDoc](https://godoc.org/github.com/stellar/go-xdr/xdr3?status.png)](http://godoc.org/github.com/stellar/go-xdr/xdr3)\n\nGo-xdr implements the data representation portion of the External Data\nRepresentation (XDR) standard protocol as specified in RFC 4506 (obsoletes RFC\n1832 and RFC 1014) in Pure Go (Golang).\n\nVersion 1 and 2 of this package are available in the `xdr` and `xdr2` packages\nrespectively. The current version is in the `xdr3` package. Stellar exclusively\nuses the `xdr3` version in `stellar/go`.\n\n## Thanks\n\nThanks to @davecgh for developing the [original go-xdr]. This is a fork of @davecgh's\nmodule. This version diverged and adds a new `xdr3` package which was a copy of\n`xdr2` but has added optionals, automatic enum deciding, union decoding,\nchanges to pointer decoding, ability to constrain sizes and some fixes.\n\n## License\n\nLicensed under the ISC License.\n\n[original go-xdr]: https://github.com/davecgh/go-xdr\n", "release_dates": []}, {"name": "golistcmp", "description": "A tool for comparing the output of 'go list -m -json all' executions.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# golistcmp\n\n[![Build Status](https://github.com/stellar/golistcmp/workflows/Go/badge.svg)](https://github.com/stellar/golistcmp/actions)\n\nA tool for comparing the output of `go list -m -json` executions.\n\n## Install\n\n```\ngo get github.com/stellar/golistcmp\n```\n\n## Usage\n\n```\nUsage of golistcmp:\n  golistcmp <go list before> <go list after>\n\nExample (built dependency graph comparison):\n  git checkout master\n  go list -json -deps -test ./... | jq -s 'map(select(.Module != null) | .Module) | unique | .[]' > go.list.json.master\n  git checkout mybranchwithchanges\n  go list -json -deps -test ./... | jq -s 'map(select(.Module != null) | .Module) | unique | .[]' > go.list.json.mybranchwithchanges\n  golistcmp go.list.json.master go.list.json.mybranchwithchanges \n\nExample (full dependency graph comparison):\n  git checkout master\n  go list -m -json all > go.list.json.master\n  git checkout mybranchwithchanges\n  go list -m -json all > go.list.json.mybranchwithchanges\n  golistcmp go.list.json.master go.list.json.mybranchwithchanges\n\nFlags:\n  -help\n        print this help\n```\n", "release_dates": []}, {"name": "Hack-a-Soroban", "description": "Hack-a-Soroban: Internal SDF Hackathon", "language": null, "license": null, "readme": "# Hack-a-Soroban\nHack-a-Soroban: Internal SDF Hackathon\n", "release_dates": []}, {"name": "hack-stellar", "description": null, "language": "TypeScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Hack Stellar Boilerplate\n\nThis Hack Stellar app is a boilerplate collection of basic Stellar functions. You can either hack this [Stencil](https://stenciljs.com) project into whatever you're trying to build or just cut and paste out the functions from here into your own project.\n\n[View a demo](https://hack-stellar.now.sh)\n\n## Getting Started\n\nTo start building with this project clone this repo and install the deps:\n\n```bash\nnpm i\n```\n\nand run:\n\n```bash\nnpm start\n```\n\nTo build the app for production, run:\n\n```bash\nnpm run build\n```\n\n## [Stellar Functions](https://github.com/tyvdh/hack-stellar/blob/master/src/components/app-home/app-home.tsx#L48-L176) Featured in this Boilerplate\n\n```ts\nkeypairGenerate() {}\n```\nDead simple Stellar keypair generator method. There are lots of ways to generate valid Stellar keypairs but if all you're looking for is a quick random keypair this is the method for you.\n\n```ts\nasync accountFund() {}\n```\nWhile on testnet we have a fancy little friendbot server method we can call to pay ourselves 10,000 XLM. Once you're in a production environment you'll need to use an `accountPay` method in order to get accounts created and funded. This is just a quick way to boot up your testing environment.\n\n```ts\nasync accountUpdate() {}\n```\nOnce we have a funded account live on the ledger we can call that account and GET its current state. There's lots of data in an account object understandably so you'll likely want to [brush up on these fields](https://www.stellar.org/developers/guides/concepts/accounts.html).\n\n```ts\nasync accountCreate() {}\n```\nA core Stellar transaction operation is creating new accounts. It's just like a payment operation except it's always XLM and always funding new accounts which don't exist on the ledger.\n\n```ts\nasync accountPay() {}\n```\nAnother central operation of Stellar transactions is making payments. In this method we're paying 100 XLM to the account we just created with an intial 10 XLM. The next step would be to explore [custom assets](https://www.stellar.org/developers/guides/concepts/assets.html) so you can make and receive payments in assets other than the native XLM.\n\n---\n\n### Helpful links:\n#### Docs\n- [https://www.stellar.org/developers](https://www.stellar.org/developers)\n- [https://stellar.github.io/js-stellar-sdk](https://stellar.github.io/js-stellar-sdk/)\n- [https://github.com/stellar/js-stellar-sdk](https://github.com/stellar/js-stellar-sdk)\n#### Explore\n- [https://stellar.expert](https://stellar.expert/)\n- [https://stellarbeat.io](https://stellarbeat.io/)\n- [https://www.stellar.org/laboratory](https://www.stellar.org/laboratory/)\n#### Wallets\n- [https://solarwallet.io](https://solarwallet.io/)\n- [https://testnet.interstellar.exchange](https://testnet.interstellar.exchange/)\n- [https://stellarterm.com/testnet](https://stellarterm.com/testnet)\n", "release_dates": []}, {"name": "hackathon-get-started", "description": "\ud83d\udcbb All the resources you'll need to begin your Stellar project. ", "language": null, "license": null, "readme": "# \ud83d\udee0\ufe0f Build on Stellar \n\nHave questions? Find [Tyler](https://keybase.io/tyvdh) on Keybase. You can also join the [Stellar Keybase team](https://keybase.io/team/stellar.public) to bounce your ideas off of the community. \n\n## Get Started\n\n[**Intro to Stellar**](https://stellar.org/learn/intro-to-stellar) - Need a refresher on what Stellar is and what it's for? Check out this quick explainer.\n\n[**Stellar Lumens**](https://stellar.org/lumens) - You'll no doubt discover lumens while building on Stellar and you might even win some at the end of the hackathon. This should help you wrap your head around what they are.\n\n[**Stellar App Boilerplate**](https://github.com/tyvdh/hack-stellar) - Get up and running building Stellar apps faster than \u26a1\ufe0f Usain Bolt \u26a1\ufe0f\n\n## Developer Resources\n\n### Documentation \n\n[**Stellar Documentation**](https://developers.stellar.org/docs/) - Quickest way to get started. \n\n[**Horizon API Reference Overview**](https://developers.stellar.org/api) - You'll be using the Horizon API a lot. Here's an overview of Horizon endpoints and how to use them.\n  - Tip: You'll be using [https://horizon-testnet.stellar.org/](https://horizon-testnet.stellar.org/) \n  \nYou can also check out [Awesome Stellar](https://github.com/stellar/awesome-stellar): a curated list of Stellar applications, blog posts, educational resources, tools, and more. \n\n### Tools\n[**Stellar Laboratory**](https://www.stellar.org/laboratory/) - The Stellar Laboratory is a set of tools that enables people to try out and learn about the Stellar network. The laboratory can build transactions, sign them, and submit them to the network. It can also make requests to any of the Horizon endpoints.\n\n[**Stellar Expert**](https://stellar.expert/explorer/public) - Block explorer and analytics platform for Stellar Network. Find information about accounts you create, transaction you submit to the network, and more. \n\n[**JavaScript Stellar SDK**](https://github.com/stellar/js-stellar-sdk) - Here's the Github repo for the JS Stellar SDK. It contains some documentation and reference examples that should help you get started.\n\n[**Python Stellar SDK**](https://github.com/StellarCN/py-stellar-base) - Here's the Github repo for the Python Stellar SDK. It contains some documentation and reference examples that should help you get started.\n\n[**Create Stellar Token (JS)**](https://github.com/msfeldstein/create-stellar-token) - A script that allows you to quickly create a Stellar token on testnet.\n\n[**Create Stellar Token + Orderbook (Python)**](https://github.com/stellar/stellar-asset-issuer-script) - A script that allows you to quickly create a Stellar token and a market for your token on testnet. \n\n## Previous Hackathons & Stellar Community Fund\n\nFind the winners of the HackNYU 2020 Stellar prizes [here](https://hacknyu-2020.devpost.com/submissions/search?utf8=%E2%9C%93&prize_filter%5Bprizes%5D%5B%5D=35771). \n\nFind the winners of the Gitcoin NYBW Hackathon Stellar prizes [here](https://github.com/stellar/hackathon-get-started/issues/1#issuecomment-635503405).\n\n**Stellar Community Fund** - The Stellar Community Fund gives people all over the world a chance to kickstart their Stellar-based projects and connect to the thriving Stellar community. You can road test ideas, get real feedback from developers and potential users, and win funding to allow you to pursue your vision. It's a rare opportunity to win rewards \u2014 no strings attached \u2014 for dreaming big. [Find more info here.](https://communityfund.stellar.org/)\n", "release_dates": []}, {"name": "helm-charts", "description": "Helm charts for deploying SDF maintained software", "language": "Smarty", "license": null, "readme": "# Stellar Development Helm Charts\n\nThis repository contains the following Helm charts for deploying SDF maintained software:\n- Anchor Platform SEP Service\n- Horizon API server\n\nTo add the repo to your system run:\n```\nhelm repo add stellar https://helm.stellar.org/charts\n```\n\n# Anchor Platform SEP Service\nDocumentation\n* https://github.com/stellar/java-stellar-anchor-sdk/tree/main/docs\n* https://github.com/stellar/helm-charts/tree/main/charts/anchor-platform/sep-service\n\n## Install Anchor Platform Helm Chart\n```\n$ helm install -f myvalues.yaml sep-service ./charts/anchor-platform/sep-service\n```\n## Uninstall Anchor Platform Helm Chart\n```\n$ helm uninstall sep-service \n```\n\n# Horizon API server\n\nSee https://github.com/stellar/helm-charts/tree/main/charts/horizon\n\n# Stellar Disbursement Platform\n\nSee https://github.com/stellar/helm-charts/tree/main/charts/stellar-disbursement-platform", "release_dates": ["2023-08-09T16:32:16Z", "2023-08-08T04:01:42Z", "2023-08-04T20:57:51Z", "2023-02-14T17:16:49Z", "2023-01-19T18:53:22Z", "2022-11-15T18:58:15Z", "2022-10-12T17:56:19Z"]}, {"name": "homebrew-tap", "description": "Homebrew Tap for brew.sh for Stellar tools and releases.", "language": "Ruby", "license": null, "readme": "# homebrew-tap\nHomebrew Tap for brew.sh for Stellar tools and releases.\n\n**Note: This tap is new and experimental. Tools found in this tap are not yet an\nofficial distribution of any tool contained within.**\n\n**Note: This tap contains no official distributions of stellar-core. See the\n*homebrew-core tap for distributions of released stellar-core.**\n\n## Usage\n\nTo install a formula that is in the `Formula` folder:\n\n```console\nbrew install stellar/tap/<formula>\n```\n\nFor example:\n\n```console\nbrew install stellar/tap/stellar-xdr\n```\n", "release_dates": []}, {"name": "ingress-nginx", "description": "Ingress-NGINX Controller for Kubernetes", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Ingress NGINX Controller\n\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5691/badge)](https://bestpractices.coreinfrastructure.org/projects/5691)\n[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/ingress-nginx)](https://goreportcard.com/report/github.com/kubernetes/ingress-nginx)\n[![GitHub license](https://img.shields.io/github/license/kubernetes/ingress-nginx.svg)](https://github.com/kubernetes/ingress-nginx/blob/main/LICENSE)\n[![GitHub stars](https://img.shields.io/github/stars/kubernetes/ingress-nginx.svg)](https://github.com/kubernetes/ingress-nginx/stargazers)\n[![GitHub stars](https://img.shields.io/badge/contributions-welcome-orange.svg)](https://github.com/kubernetes/ingress-nginx/blob/main/CONTRIBUTING.md)\n\n### Community Update\n\nWe will discuss the results of our Community Survey, progress on the stabilization project, and ideas going\nforward with the project at [Kubecon NA 2022 in Detroit](https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/). Come join us and let us hear what you'd like to see in the\nfuture for ingress-nginx.\n\nhttps://kccncna2022.sched.com/event/18lgl?iframe=no\n\n## Overview\n\ningress-nginx is an Ingress controller for Kubernetes using [NGINX](https://www.nginx.org/) as a reverse proxy and load balancer.\n\n[Learn more about Ingress on the main Kubernetes documentation site](https://kubernetes.io/docs/concepts/services-networking/ingress/).\n\n## Get started\n\nSee the [Getting Started](https://kubernetes.github.io/ingress-nginx/deploy/) document.\n\n## Troubleshooting\n\nIf you encounter issues, review the [troubleshooting docs](docs/troubleshooting.md), [file an issue](https://github.com/kubernetes/ingress-nginx/issues), or talk to us on the [#ingress-nginx channel](https://kubernetes.slack.com/messages/ingress-nginx) on the Kubernetes Slack server.\n\n## Changelog\n\nSee [the list of releases](https://github.com/kubernetes/ingress-nginx/releases) to find out about feature changes.\nFor detailed changes for each release; please check the [Changelog.md](Changelog.md) file.\nFor detailed changes on the `ingress-nginx` helm chart, please check the following [CHANGELOG.md](charts/ingress-nginx/CHANGELOG.md) file.\n\n### Support Versions table \n\n| Ingress-NGINX version | k8s supported version        | Alpine Version | Nginx Version |\n|-----------------------|------------------------------|----------------|---------------|\n| v1.4.0                | 1.25, 1.24, 1.23, 1.22       | 3.16.2         | 1.19.10\u2020      |\n| v1.3.1                | 1.24, 1.23, 1.22, 1.21, 1.20 | 3.16.2         | 1.19.10\u2020      |\n| v1.3.0                | 1.24, 1.23, 1.22, 1.21, 1.20 | 3.16.0         | 1.19.10\u2020      |\n| v1.2.1                | 1.23, 1.22, 1.21, 1.20, 1.19 | 3.14.6         | 1.19.10\u2020      |\n| v1.1.3                | 1.23, 1.22, 1.21, 1.20, 1.19 | 3.14.4         | 1.19.10\u2020      |\n| v1.1.2                | 1.23, 1.22, 1.21, 1.20, 1.19 | 3.14.2         | 1.19.9\u2020       |\n| v1.1.1                | 1.23, 1.22, 1.21, 1.20, 1.19 | 3.14.2         | 1.19.9\u2020       |\n| v1.1.0                | 1.22, 1.21, 1.20, 1.19       | 3.14.2         | 1.19.9\u2020       |\n| v1.0.5                | 1.22, 1.21, 1.20, 1.19       | 3.14.2         | 1.19.9\u2020       |\n| v1.0.4                | 1.22, 1.21, 1.20, 1.19       | 3.14.2         | 1.19.9\u2020       |\n| v1.0.3                | 1.22, 1.21, 1.20, 1.19       | 3.14.2         | 1.19.9\u2020       |\n| v1.0.2                | 1.22, 1.21, 1.20, 1.19       | 3.14.2         | 1.19.9\u2020       |\n| v1.0.1                | 1.22, 1.21, 1.20, 1.19       | 3.14.2         | 1.19.9\u2020       |\n| v1.0.0                | 1.22, 1.21, 1.20, 1.19       | 3.13.5         | 1.20.1        |\n\n\n\u2020 _This build is [patched against CVE-2021-23017](https://github.com/openresty/openresty/commit/4b5ec7edd78616f544abc194308e0cf4b788725b#diff-42ef841dc27fe0b5aa2d06bd31308bb63a59cdcddcbcddd917248349d22020a3)._\n\nSee [this article](https://kubernetes.io/blog/2021/07/26/update-with-ingress-nginx/) if you want upgrade to the stable Ingress API. \n\n## Get Involved\n\nThanks for taking the time to join our community and start contributing!\n\n- This project adheres to the [Kubernetes Community Code of Conduct](https://git.k8s.io/community/code-of-conduct.md). By participating in this project, you agree to abide by its terms.\n\n- **Contributing**: Contributions of all kind are welcome!\n  \n  - Read [`CONTRIBUTING.md`](CONTRIBUTING.md) for information about setting up your environment, the workflow that we expect, and instructions on the developer certificate of origin that we require.\n\n  - Join our Kubernetes Slack channel for developer discussion : [#ingress-nginx-dev](https://kubernetes.slack.com/archives/C021E147ZA4).\n  \n  - Submit github issues for any feature enhancements, bugs or documentation problems. Please make sure to read the [Issue Reporting Checklist](https://github.com/kubernetes/ingress-nginx/blob/main/CONTRIBUTING.md#issue-reporting-guidelines) before opening an issue. Issues not conforming to the guidelines **may be closed immediately**.\n\n- **Support**: Join the [#ingress-nginx-users](https://kubernetes.slack.com/messages/CANQGM8BA/) channel inside the [Kubernetes Slack](http://slack.kubernetes.io/) to ask questions or get support from the maintainers and other users.\n  \n  - The [GitHub issues](https://github.com/kubernetes/ingress-nginx/issues) in the repository are **exclusively** for bug reports and feature requests.\n\n- **Discuss**: Tweet using the `#IngressNginx` hashtag.\n\n## License\n\n[Apache License 2.0](https://github.com/kubernetes/ingress-nginx/blob/main/LICENSE)\n", "release_dates": []}, {"name": "integration-tests", "description": null, "language": "JavaScript", "license": null, "readme": "[![Build Status](https://travis-ci.org/stellar/integration-tests.svg?branch=master)](https://travis-ci.org/stellar/integration-tests)\n\n# Stellar Integration Tests\n\nThis repository contains script responsible for performing integration tests of different components of the Stellar network.\n\n## Architecture\n\nThis section describes the architecture of integration tests.\n\n### Architecture Diagram\n![Diagram](diagram.png)\n\n### Components\n\n#### Monitor\n\nMonitor (`monitor.js`) is the main app run by travis. It's responsible for:\n* Starting tests when both FI server are online.\n* Checking the current status of tests and returning the correct exit code if tests succeed/fail/timeout.\n\n#### ngrok\n\n[ngrok](https://ngrok.com/) allows creating http/https tunnels to Docker containers. This allows us to expose `stellar.toml`, federation server and auth server to the internet so other FI can access them.\n\n#### FI Container\n\nFI Container is built from docker image that can be found in `container` directory. It consists of:\n* [Bridge](https://github.com/stellar/bridge-server/blob/master/readme_bridge.md) server,\n* [Compliance](https://github.com/stellar/bridge-server/blob/master/readme_compliance.md) server,\n* Custom FI server (`index.js`). It provides:\n  * Callbacks for `bridge` and `compliance` servers.\n  * Callbacks for `monitor` to start tests and check tests status.\n  * Proxy to `compliance` auth server (to allow creating a single tunnel to docker container).\n  * Tests code.\n\nServices are listening on the following ports within a docker container:\n\nService | Port | Exposed to docker host?\n--------|------|------------------------\nbridge | 8000 | No\ncompliance external | 8001 | No\ncompliance internal | 8002 | No\nFI server with proxy to `compliance` auth server | 8003 | **Yes**\n\n#### DB Container\n\nDocker container with a DB server that provides storage for `bridge` and `compliance` servers.\n\n## Configuration\n\nDocker cluster is defined in `docker-compose.yml` and can be started using `docker-compose` command.\n\n`docker-compose` is using environment variables defined in `container1.env`, `container2.env` and secret variables set in Travis. The list of environment variables can be found below:\n\nDescription | Scope | Name | Value\n------------|-------|------|-------\nNgrok Auth Token | Global | `NGROK_AUTH_TOKEN` | _secret_\nF1 Domain | Global | `FI1_DOMAIN` | _random_\nF2 Domain | Global | `FI2_DOMAIN` | _random_\nF1 Bridge version | Global | `FI1_BRIDGE_VERSION` | Defined in .travis.yml: `master` - master branch, other values define release version \nF2 Bridge version | Global | `FI2_BRIDGE_VERSION` | Defined in .travis.yml: `master` - master branch, other values define release version\nFI1 Receiving account | container1.env | `RECEIVING_ACCOUNT` | `GAAJKG3WQKHWZJ5RGVVZMVV6X3XYU7QUH2YVATQ2KBVR2ZJYLG35Z65A`\nFI1 Receiving secret | Global | `FI1_RECEIVING_SEED` | _secret_\nFI1 Signing account | container1.env | `SIGNING_ACCOUNT` | `GBAPTLS2A72RGEQIK6GQ4F74AIYFS2N7WIQ7LZOYKOJT4KD6MUQEHOEU`\nFI1 Signing secret | Global | `FI1_SIGNING_SEED` | _secret_\nFI2 Receiving account | container2.env | `RECEIVING_ACCOUNT` | `GCNP7JE6KR5CKHMVVFTZJUSP7ALAXWP62SK6IMIY4IF3JCHEZKBJKDZF`\nFI2 Receiving secret | Global | `FI2_RECEIVING_SEED` | _secret_\nFI2 Signing account | container2.env | `SIGNING_ACCOUNT` | `GD4SMSFNFASBHPMCOJAOVYH47OXQM5BGSHFLKHO5BGRGUK6ZOAVDG54B`\nFI2 Signing secret | Global | `FI2_SIGNING_SEED` | _secret_\nIssuing account | container*.env | `ISSUING_ACCOUNT` | `GDNFUWF2EO4OWXYLI4TDEH4DXUCN6PB24R6XQW4VATORK6WGMHGRXJVB`\n\n## Tests flow\n\nSee `script.sh`.\n\n1. Build `container` docker image using files in `container` directory.\n1. Generate random ngrok subdomains for FIs and start ngrok.\n1. Start a cluster by `docker-compose up`.\n1. Start `monitor` app.\n  1. Wait for **both** FIs to go online.\n  1. When **both** FIs are working start tests.\n  1. Monitor current status of tests.\n  1. Print results and exit with correct (error) code.\n\n## TODO\n\n* More test scenarios.\n* Use `docker-stellar-core-horizon` instead of SDF's instances.\n", "release_dates": []}, {"name": "java-stellar-anchor-sdk", "description": "Java SDK for the Stellar network anchor development.", "language": "Kotlin", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "[![License](https://badgen.net/badge/license/Apache%202/blue?icon=github&label=License)](https://github.com/stellar/java-stellar-anchor-sdk/blob/develop/LICENSE)\n[![GitHub Version](https://badgen.net/github/release/stellar/java-stellar-anchor-sdk?icon=github&label=Latest%20release)](https://github.com/stellar/java-stellar-anchor-sdk/releases)\n[![Docker](https://badgen.net/badge/Latest%20Release/v2.5.2/blue?icon=docker)](https://hub.docker.com/r/stellar/anchor-platform/tags?page=1&name=2.5.1)\n![Develop Branch](https://github.com/stellar/java-stellar-anchor-sdk/actions/workflows/wk_push_to_develop.yml/badge.svg?branch=develop)\n\n<div style=\"text-align: center\">\n<img alt=\"Stellar\" src=\"https://github.com/stellar/.github/raw/master/stellar-logo.png\" width=\"558\" />\n<br/>\n<strong>Creating equitable access to the global financial system</strong>\n</div>\n\n# Stellar Anchor Platform\n\nThe Anchor Platform is the easiest and fastest way to deploy\na [SEP-compatible](https://github.com/stellar/stellar-protocol/tree/master/ecosystem) anchor service.\n\nIt implements the majority of standardized API (`SEP`) endpoints that wallets, exchanges, and other applications use,\nand provides a set of backend HTTPS APIs & callbacks for the anchor to integrate with for specifying fees, exchange\nrates, and off-chain transaction status updates.\n\nThe goal of the Anchor Platform is to abstract all Stellar-specific functionality and requirements for running an\nanchor, allowing businesses to focus on the core business logic necessary to provide these services.\n\n## Getting Started\n\nTo get started, visit the [Anchor Platform documentation](https://developers.stellar.org/docs/category/anchor-platform).\nRelease notes can be found on the\nproject's [releases page](https://github.com/stellar/java-stellar-anchor-sdk/releases).\n\n## Contributing\n\nPlease refer to our [How to contribute](/docs/01%20-%20Contributing/README.md) guide for more information on how to\ncontribute to this project.\n\n## Directory Layout\n\n- __docs__: Contains the documentation for the Anchor Platform.\n- __api_schema__: Contains the Java classes and interfaces that represent the API schema.\n- __core__: Contains the core Anchor Platform implementation. Most of the SEP business logics are implemented here. No\n  infrastructures, such as database, configuration, queue, or logging implementations are assumed in this sub-project.\n- __platform__: Contains the Anchor Platform implementation that uses Spring Boot as the underlying framework. This\n  sub-project is responsible for providing the infrastructure implementations, such as database, configuration, queue,\n  and logging. The `sep-server`, `platform-server`, `custody-server`, `event-processor` and `stellar-observer` services\n  are also implemented here.\n- __kotlin_reference_server__: Contains the anchor's reference server implementation in Kotlin.\n- __wallet_reference_server__: Contains the wallet's reference server implementation in Kotlin.\n- __service_runner__: Contains the service runner implementation that runs services, such as SEP, platform, payment\n  observer, and reference servers, etc. It also contains the main entry point of the Anchor Platform.\n- __essential-tests__: Contains the essential integration tests and end-2-end tests for the Anchor Platform.\n- __extended-tests__: Contains the extended integration tests and end-2-end tests for the Anchor Platform.\n\n## Quickstart\n\nAnchor Platform can be run locally using Docker Compose. This will start an instance of the Anchor Platform and the\nKotlin reference server.\n\n```shell\ndocker-compose -f service-runner/src/main/resources/docker-compose.yaml up -d\n```\n\nThe [Stellar Demo Wallet](https://demo-wallet.stellar.org) can be used to interact with the Anchor Platform. To get\nstarted, create and fund a new account, then add a new asset with the following parameters.\n\n| Parameter          | Value                                                      |\n|--------------------|------------------------------------------------------------|\n| Asset Code         | `USDC`                                                     |\n| Anchor Home Domain | `localhost:8080`                                           |\n| Issuer Public Key  | `GDQOE23CFSUMSVQK4Y5JHPPYK73VYCNHZHA7ENKCV37P6SUEO6XQBKPP` |\n\nNow you can deposit and withdraw USDC using the Stellar Demo Wallet.\n\n## References\n\n[SEP-1](https://stellar.org/protocol/sep-6): Stellar Info File\n\n[SEP-6](https://stellar.org/protocol/sep-6): Deposit and Withdrawal API\n\n[SEP-10](https://stellar.org/protocol/sep-10): Stellar Web Authentication\n\n[SEP-12](https://stellar.org/protocol/sep-12): KYC API\n\n[SEP-24](https://stellar.org/protocol/sep-24): Hosted Deposit and Withdrawal\n\n[SEP-31](https://stellar.org/protocol/sep-31): Cross-Border Payments API\n\n[SEP-38](https://stellar.org/protocol/sep-38): Anchor RFQ API\n", "release_dates": ["2024-03-01T17:43:55Z", "2024-02-16T20:21:29Z", "2024-02-09T00:11:50Z", "2023-12-22T19:59:20Z", "2023-12-20T17:30:32Z", "2023-12-14T11:29:56Z", "2023-12-05T19:46:39Z", "2023-12-04T21:02:55Z", "2023-11-06T17:31:18Z", "2023-10-11T17:00:56Z", "2023-09-21T15:51:54Z", "2023-09-21T21:34:23Z", "2023-09-13T17:11:01Z", "2023-09-07T21:28:56Z", "2023-09-07T22:14:41Z", "2023-08-30T21:14:50Z", "2023-08-11T19:51:22Z", "2023-08-03T01:14:36Z", "2023-07-28T14:47:24Z", "2023-07-12T22:27:46Z", "2023-06-23T18:11:25Z", "2023-06-20T20:09:06Z", "2023-06-16T20:13:53Z", "2023-06-05T16:58:56Z", "2023-05-31T21:07:59Z", "2023-05-09T22:41:42Z", "2023-05-01T21:07:59Z", "2023-04-06T19:17:18Z", "2023-04-05T17:42:31Z", "2023-04-04T17:08:51Z"]}, {"name": "java-stellar-sdk", "description": null, "language": "Java", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# java-stellar-sdk\n\n[![Test and Deploy](https://github.com/stellar/java-stellar-sdk/actions/workflows/test-deploy.yml/badge.svg?branch=master)](https://github.com/stellar/java-stellar-sdk/actions/workflows/test-deploy.yml)\n[![](https://jitpack.io/v/stellar/java-stellar-sdk.svg)](https://jitpack.io/#stellar/java-stellar-sdk)\n\nThe Java Stellar Sdk library provides APIs to build transactions and connect to [Horizon](https://github.com/stellar/go/tree/master/services/horizon) and [Soroban-RPC Server](https://soroban.stellar.org/docs/reference/rpc).\n\n## Installation\n\n### Maven\n\nUse [jitpack.io](https://jitpack.io)'s Maven repository:\n\n```\nrepositories {\n    maven { url \"https://jitpack.io\" }\n}\n\ndependencies {\n    implementation 'com.github.stellar:java-stellar-sdk:{version}'\n}\n```\n\nThe list of versions to install can be found in the [Releases](https://github.com/stellar/java-stellar-sdk/releases) section. More information can be found in [jitpack.io docs](https://jitpack.io/docs/).\n\n### JAR\n\nDownload the latest jar from the GitHub repo's [releases tab](https://github.com/stellar/java-stellar-sdk/releases). Add the `jar` package to your project according to how your environment is set up.\n\n## Basic Usage\nFor some examples on how to use this library, take a look at the [Get Started docs in the developers site](https://developers.stellar.org/docs/tutorials/create-account/).\n\n## Documentation\nJavadoc is available at https://stellar.github.io/java-stellar-sdk\n\n## Integrate into Android project\nIf you want to integrate this SDK on Android platforms with API level 26 and above, you don't need any additional configuration. \nHowever, if you need to include it on lower platforms, you may also need to add the [Java Stellar SDK Android SPI](https://github.com/stellar/java-stellar-sdk-android-spi).\n\n## Contributing\nFor information on how to contribute, please refer to our [contribution guide](https://github.com/stellar/java-stellar-sdk/blob/master/CONTRIBUTING.md).\n\n## License\njava-stellar-sdk is licensed under an Apache-2.0 license. See the [LICENSE](https://github.com/stellar/java-stellar-sdk/blob/master/LICENSE) file for details.\n\n## xdr to jave code generation\nAll the java source files in `org.stellar.sdk.xdr` package are generated using the following command:\n```bash\nmake xdr-update\n```", "release_dates": ["2024-01-23T01:07:16Z", "2023-11-15T09:13:30Z", "2023-09-28T23:51:22Z", "2023-09-19T22:35:49Z", "2023-09-07T16:46:01Z", "2023-09-01T17:54:11Z", "2023-08-21T08:38:08Z", "2023-08-18T11:14:15Z", "2023-08-16T08:56:53Z", "2023-05-01T20:51:51Z", "2023-03-09T19:07:20Z", "2022-12-03T02:01:20Z", "2022-08-11T01:06:35Z", "2022-08-08T17:31:30Z", "2022-08-08T04:20:23Z", "2022-07-25T19:50:12Z", "2022-07-19T17:38:22Z", "2022-07-13T19:15:36Z", "2022-06-30T20:50:36Z", "2022-06-01T22:50:05Z", "2022-05-05T01:16:56Z", "2022-04-18T22:37:31Z", "2022-01-11T04:07:10Z", "2022-01-03T18:52:08Z", "2021-10-22T07:02:51Z", "2021-10-08T17:47:41Z", "2021-09-30T20:26:39Z", "2021-09-24T11:21:10Z", "2021-06-29T13:20:36Z", "2021-05-24T12:51:14Z"]}, {"name": "java-stellar-sdk-android-spi", "description": "Stellar java sdk SPI implementation for Android", "language": "Java", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# java-stellar-sdk-android-spi\n\n[![Test and Deploy](https://github.com/stellar/java-stellar-sdk-android-spi/actions/workflows/test-deploy.yml/badge.svg?branch=main)](https://github.com/stellar/java-stellar-sdk-android-spi/actions/workflows/test-deploy.yml)\n[![](https://jitpack.io/v/stellar/java-stellar-sdk-android-spi.svg)](https://jitpack.io/#stellar/java-stellar-sdk-android-spi)\n\nThe goal of this library is to enable users to conveniently integrate the Java Stellar SDK into lower versions of the Android platform. In this context, lower versions refer to Android API level 23 to 27. If your minSdk is set to 28 or higher, you do not need to include this library.\n\n## Installation\n\n### Maven\n\nUse [jitpack.io](https://jitpack.io)'s Maven repository:\n\n```\nrepositories {\n    maven { url \"https://jitpack.io\" }\n}\n\ndependencies {\n    implementation 'com.github.stellar:java-stellar-sdk:{version}'\n    implementation 'com.github.stellar:java-stellar-sdk-android-spi:{version}'\n}\n```\n\nThe versions of `java-stellar-sdk` and `java-stellar-sdk-android-spi` should be maintained at the same version.\n\nThe list of versions to install can be found in the [Releases](https://github.com/stellar/java-stellar-sdk-android-spi/releases) section. More information can be found in [jitpack.io docs](https://jitpack.io/docs/).\n\n### JAR\n\nDownload the latest jar from the GitHub repo's [releases tab](https://github.com/stellar/java-stellar-sdk-android-spi/releases). Add the `jar` package to your project according to how your environment is set up.\n", "release_dates": ["2024-01-23T01:26:20Z", "2023-11-15T22:50:02Z", "2023-09-29T01:36:31Z"]}, {"name": "js-soroban-client", "description": "Main Soroban client library for the Javascript language", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<div align=\"center\">\n  <img alt=\"Stellar\" src=\"https://github.com/stellar/.github/raw/master/stellar-logo.png\" width=\"558\" />\n  <br/>\n  <strong>Creating equitable access to the global financial system</strong>\n  <h1>js-soroban-client</h1>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://badge.fury.io/js/soroban-client\"><img src=\"https://badge.fury.io/js/soroban-client.svg\" alt=\"npm version\" height=\"18\"></a>\n  <a href=\"https://github.com/stellar/js-soroban-client/actions/workflows/tests.yml\"><img alt=\"Test Status\" src=\"https://github.com/stellar/js-soroban-client/actions/workflows/tests.yml/badge.svg\" /></a>\n  <a href=\"https://coveralls.io/github/stellar/js-soroban-client?branch=master\"><img alt=\"Coverage Status\" src=\"https://coveralls.io/repos/stellar/js-soroban-client/badge.svg?branch=master&service=github\" /></a>\n</p>\n\n# Deprecation Notice\n\n**This repository has been deprecated** in favor of the [`stellar-sdk`](https://github.com/stellar/js-stellar-sdk) package. Please read the [migration guide](https://gist.github.com/Shaptic/5ce4f16d9cce7118f391fbde398c2f30) for how to upgrade to that package. Future changes will only be made there.\n\n----------\n\njs-soroban-client is a JavaScript library for communicating with a\n[Soroban RPC server](https://soroban.stellar.org/api) and building Stellar apps. It provides:\n- a networking layer API for soroban-rpc methods.\n- facilities for building and signing transactions, for communicating with a\n  soroban-rpc instance, and for submitting transactions or querying network\n  state.\n\n<details>\n\n### soroban-client vs stellar-base\n\nsoroban-client is a high-level library that serves as client-side API for Horizon.\n[stellar-base](https://github.com/stellar/js-stellar-base) is lower-level\nlibrary for creating Stellar primitive constructs via XDR helpers and wrappers.\n\n**Most people will want soroban-client instead of stellar-base.** You should only\nuse stellar-base if you know what you're doing!\n\nIf you add `soroban-client` to a project, **do not add `stellar-base`!** Mis-matching\nversions could cause weird, hard-to-find bugs. `soroban-client` automatically\ninstalls `stellar-base` and exposes all of its exports in case you need them.\n\n> **Important!** The Node.js version of the `stellar-base` (`soroban-client` dependency) package\n> uses the [`sodium-native`](https://www.npmjs.com/package/sodium-native) package as\n> an [optional dependency](https://docs.npmjs.com/files/package.json#optionaldependencies). `sodium-native` is\n> a low level binding to [libsodium](https://github.com/jedisct1/libsodium),\n> (an implementation of [Ed25519](https://ed25519.cr.yp.to/) signatures).\n> If installation of `sodium-native` fails, or it is unavailable, `stellar-base` (and `soroban-client`) will\n> fallback to using the [`tweetnacl`](https://www.npmjs.com/package/tweetnacl) package implementation.\n>\n> If you are using `soroban-client`/`stellar-base` in a browser you can ignore\n> this. However, for production backend deployments you should be\n> using `sodium-native`. If `sodium-native` is successfully installed and working the\n> `SorobanClient.FastSigning` variable will return `true`.\n\n## Quick start\n\nUsing npm to include js-soroban-client in your own project:\n\n```shell\nnpm install --save soroban-client\n```\n\nAlternatively, you can use cdnjs in a browser:\n\n```html\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/soroban-client/{version}/soroban-client.js\"></script>\n````\n\n## Install\n\n### To use as a module in a Node.js project\n\n1. Install it using npm:\n\n```shell\nnpm install --save soroban-client\n```\n\n2. require/import it in your JavaScript:\n\n```js\nvar SorobanClient = require('soroban-client');\n```\n\n### To self host for use in the browser\n\n1. Install it using [bower](http://bower.io):\n\n```shell\nbower install soroban-client\n```\n\n2. Include it in the browser:\n\n```html\n<script src=\"./bower_components/soroban-client/soroban-client.js\"></script>\n<script>\n  console.log(SorobanClient);\n</script>\n```\n\nIf you don't want to use or install Bower, you can copy built JS files from the\n[bower-js-soroban-client\nrepo](https://github.com/stellar/bower-js-soroban-client).\n\n### To use the [cdnjs](https://cdnjs.com/libraries/soroban-client) hosted script in the browser\n\n1. Instruct the browser to fetch the library from\n   [cdnjs](https://cdnjs.com/libraries/soroban-client), a 3rd party service that\n   hosts js libraries:\n\n```html\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/soroban-client/{version}/soroban-client.js\"></script>\n<script>\n  console.log(SorobanClient);\n</script>\n```\n\nNote that this method relies using a third party to host the JS library. This\nmay not be entirely secure.\n\nMake sure that you are using the latest version number. They can be found on the\n[releases page in Github](https://github.com/stellar/js-soroban-client/releases).\n\n### To develop and test js-soroban-client itself\n\n1. Clone the repo:\n\n```shell\ngit clone https://github.com/stellar/js-soroban-client.git\n```\n\n2. Install dependencies inside js-soroban-client folder:\n\n```shell\ncd js-soroban-client\nyarn install\n```\n\n3. Install Node 16\n\nBecause we support the latest maintenance version of Node, please install and develop on Node 16 so you don't get surprised when your code works locally but breaks in CI.\n\nHere's how to install `nvm` if you haven't: https://github.com/creationix/nvm\n\n```shell\nnvm install\n\n# if you've never installed 16 before you'll want to re-install yarn\nyarn install -g yarn\n```\n\nIf you work on several projects that use different Node versions, you might it\nhelpful to install this automatic version manager:\nhttps://github.com/wbyoung/avn\n\n4. Observe the project's code style\n\nWhile you're making changes, make sure to run the linter-watcher to catch any\n   linting errors (in addition to making sure your text editor supports ESLint)\n\n```shell\nnode_modules/.bin/gulp watch\n````\n\n## Usage\n\nFor information on how to use js-soroban-client, take a look at [the\ndocumentation](https://stellar.github.io/js-soroban-client/), or [the\nexamples](https://github.com/stellar/js-soroban-client/tree/master/docs/reference).\n\n## Testing\n\nTo run all tests:\n\n```shell\ngulp test\n```\n\nTo run a specific set of tests:\n\n```shell\ngulp test:node\ngulp test:browser\n```\n\nTo generate and check the documentation site:\n\n```shell\n# install the `serve` command if you don't have it already\nyarn install -g serve\n\n# generate the docs files\nyarn docs\n\n# get these files working in a browser\ncd jsdoc && serve .\n\n# you'll be able to browse the docs at http://localhost:5000\n```\n\n## Documentation\n\nDocumentation for this repo lives in\n[Developers site](https://github.com/stellar/js-soroban-client/blob/master/docs/reference/readme.md).\n\n## Contributing\n\nFor information on how to contribute, please refer to our\n[contribution guide](https://github.com/stellar/js-soroban-client/blob/master/CONTRIBUTING.md).\n\n## Publishing to npm\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for the detailed release process. Once a new release is published and CI passes, a new package will be published to npm by GitHub actions.\n\n## License\n\njs-soroban-client is licensed under an Apache-2.0 license. See the\n[LICENSE](https://github.com/stellar/js-soroban-client/blob/master/LICENSE) file\nfor details.\n\n</details>\n", "release_dates": ["2024-01-03T18:22:53Z", "2023-12-08T00:35:45Z", "2023-11-03T19:42:15Z", "2023-10-13T17:53:30Z", "2023-09-14T19:52:42Z", "2023-09-13T23:45:51Z", "2023-09-13T18:06:41Z", "2023-09-01T22:19:30Z", "2023-08-24T17:53:31Z", "2023-08-21T18:42:49Z", "2023-08-07T22:30:08Z", "2023-08-04T22:08:25Z", "2023-07-17T23:43:10Z", "2023-07-12T14:28:46Z", "2023-07-11T18:43:21Z", "2023-06-14T20:01:39Z", "2023-06-01T14:07:52Z", "2023-05-25T23:04:33Z", "2023-05-25T22:21:08Z", "2023-05-23T21:07:56Z", "2023-05-18T23:09:33Z", "2023-05-18T20:04:22Z", "2023-04-28T17:30:58Z", "2023-03-31T16:07:24Z", "2023-03-31T15:56:34Z", "2023-02-15T14:11:02Z", "2023-01-05T21:59:59Z", "2022-12-08T19:44:44Z", "2022-12-05T21:55:18Z", "2022-11-08T15:04:23Z"]}, {"name": "js-stellar-base", "description": "The lowest-level stellar helper library. It consists of classes to read, write, hash, and sign Stellar xdr", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# JS Stellar Base\n\n[![Tests](https://github.com/stellar/js-stellar-base/actions/workflows/tests.yml/badge.svg)](https://github.com/stellar/js-stellar-base/actions/workflows/tests.yml)\n[![Code Climate](https://codeclimate.com/github/stellar/js-stellar-base/badges/gpa.svg)](https://codeclimate.com/github/stellar/js-stellar-base)\n[![Coverage Status](https://coveralls.io/repos/stellar/js-stellar-base/badge.svg?branch=master&service=github)](https://coveralls.io/github/stellar/js-stellar-base?branch=master)\n[![Dependency Status](https://david-dm.org/stellar/js-stellar-base.svg)](https://david-dm.org/stellar/js-stellar-base)\n\nThe stellar-base library is the lowest-level stellar helper library. It consists\nof classes to read, write, hash, and sign the xdr structures that are used in\n[stellar-core](https://github.com/stellar/stellar-core). This is an\nimplementation in JavaScript that can be used on either Node.js or web browsers.\n\n- **[API Reference](https://stellar.github.io/js-stellar-base/)**\n\n> **Warning!** The Node version of this package uses the [`sodium-native`](https://www.npmjs.com/package/sodium-native) package, a native implementation of [Ed25519](https://ed25519.cr.yp.to/) in Node.js, as an [optional dependency](https://docs.npmjs.com/files/package.json#optionaldependencies).\n> This means that if for any reason installation of this package fails, `stellar-base` will fallback to the much slower implementation contained in [`tweetnacl`](https://www.npmjs.com/package/tweetnacl).\n>\n> If you'd explicitly prefer **not** to install the `sodium-native` package, pass the appropriate flag to skip optional dependencies when installing this package (e.g. `--no-optional` if using `npm install` or `--without-optional` using `yarn install`).\n>\n> If you are using `stellar-base` in a browser you can ignore this. However, for production backend deployments you should most likely be using `sodium-native`.\n> If `sodium-native` is successfully installed and working,\n> `StellarBase.FastSigning` variable will be equal `true`. Otherwise it will be\n> `false`.\n\n## Quick start\n\nUsing yarn to include js-stellar-base in your own project:\n\n```shell\nyarn add @stellar/stellar-base\n```\n\nFor browsers, [use Bower to install it](#to-use-in-the-browser). It exports a\nvariable `StellarBase`. The example below assumes you have `stellar-base.js`\nrelative to your html file.\n\n```html\n<script src=\"stellar-base.js\"></script>\n<script>\n  console.log(StellarBase);\n</script>\n```\n\n## Install\n\n### To use as a module in a Node.js project\n\n1. Install it using yarn:\n\n```shell\nyarn add @stellar/stellar-base\n```\n\n2. require/import it in your JavaScript:\n\n```js\nvar StellarBase = require('@stellar/stellar-base');\n```\n\n### To self host for use in the browser\n\n1. Install it using [bower](http://bower.io):\n\n```shell\nbower install stellar-base\n```\n\n2. Include it in the browser:\n\n```html\n<script src=\"./bower_components/stellar-base/stellar-base.js\"></script>\n<script>\n  console.log(StellarBase);\n</script>\n```\n\nIf you don't want to use install Bower, you can copy built JS files from the\n[bower-js-stellar-base repo](https://github.com/stellar/bower-js-stellar-base).\n\n### To use the [cdnjs](https://cdnjs.com/libraries/stellar-base) hosted script in the browser\n\n1. Instruct the browser to fetch the library from\n   [cdnjs](https://cdnjs.com/libraries/stellar-base), a 3rd party service that\n   hosts js libraries:\n\n```html\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/stellar-base/{version}/stellar-base.js\"></script>\n<script>\n  console.log(StellarBase);\n</script>\n```\n\nNote that this method relies using a third party to host the JS library. This\nmay not be entirely secure.\n\nMake sure that you are using the latest version number. They can be found on the\n[releases page in Github](https://github.com/stellar/js-stellar-base/releases).\n\n### To develop and test js-stellar-base itself\n\n1. Install Node 18.x\n\nWe support the oldest LTS release of Node, which is [currently 18.x](https://nodejs.org/en/about/releases/). Please likewise install and develop on Node 16 so you don't get surprised when your code works locally but breaks in CI.\n\nIf you work on several projects that use different Node versions, you might find helpful to install a NodeJS version manager:\n\n  - https://github.com/creationix/nvm\n  - https://github.com/wbyoung/avn\n  - https://github.com/asdf-vm/asdf\n\n2. Install Yarn\n\nThis project uses [Yarn](https://yarnpkg.com/) to manages its dependencies. To install Yarn, follow the project instructions available at https://yarnpkg.com/en/docs/install.\n\n3. Clone the repo\n\n```shell\ngit clone https://github.com/stellar/js-stellar-base.git\n```\n\n4. Install dependencies inside js-stellar-base folder\n\n```shell\ncd js-stellar-base\nyarn\n```\n\n5. Observe the project's code style\n\nWhile you're making changes, make sure to regularly run the linter to catch any\nlinting errors (in addition to making sure your text editor supports ESLint)\n\n```shell\nyarn lint\n```\n\nas well as fixing any formatting errors with\n\n```shell\nyarn fmt\n```\n\nIf you're working on a file not in `src`, limit your code to Node 6.16 ES! See\nwhat's supported here: https://node.green/. (Our npm library must support\nearlier versions of Node, so the tests need to run on those versions.)\n\n#### Updating XDR definitions\n\n1. Make sure you have [Docker](https://www.docker.com/) installed and running.\n2. `make reset-xdr`\n\n## Usage\n\nFor information on how to use js-stellar-base, take a look at the docs in the\n[docs folder](./docs).\n\n## Testing\n\nTo run all tests:\n\n```shell\nyarn test\n```\n\nTo run a specific set of tests:\n\n```shell\nyarn test:node\nyarn test:browser\n```\n\nTests are also run automatically in Github Actions for every master commit and\npull request.\n\n## Documentation\n\nDocumentation for this repo lives inside the [docs folder](./docs).\n\n## Contributing\n\nPlease see the [CONTRIBUTING.md](./CONTRIBUTING.md) for details on how to\ncontribute to this project.\n\n## Publishing to npm\n\n```\nnpm version [<newversion> | major | minor | patch | premajor | preminor | prepatch | prerelease]\n```\n\nA new version will be published to npm **and** Bower by GitHub Actions.\n\nnpm >= 2.13.0 required. Read more about\n[npm version](https://docs.npmjs.com/cli/version).\n\n## License\n\njs-stellar-base is licensed under an Apache-2.0 license. See the\n[LICENSE](./LICENSE) file for details.\n", "release_dates": ["2024-02-12T20:18:52Z", "2024-01-23T01:23:53Z", "2023-12-15T22:02:35Z", "2023-12-07T20:03:35Z", "2023-11-03T19:22:45Z", "2023-10-09T22:33:54Z", "2023-09-22T20:25:01Z", "2023-09-13T23:15:30Z", "2023-09-12T16:57:13Z", "2023-06-13T21:56:19Z", "2023-06-13T00:03:43Z", "2023-05-08T22:48:36Z", "2023-04-21T20:15:03Z", "2023-04-20T20:27:45Z", "2022-12-13T21:55:49Z", "2022-10-04T18:48:53Z", "2022-09-07T17:56:32Z", "2022-08-18T18:18:23Z", "2022-05-17T21:18:31Z", "2022-04-18T18:13:16Z", "2022-04-12T22:38:43Z", "2022-01-11T21:30:12Z", "2021-11-16T20:53:47Z", "2021-10-23T00:10:48Z", "2021-10-07T22:27:44Z", "2021-09-14T20:39:38Z", "2021-09-13T18:27:42Z", "2021-08-26T22:22:37Z", "2021-08-26T20:23:03Z", "2021-08-04T17:14:54Z"]}, {"name": "js-stellar-elements", "description": "Styled basic components for Stellar projects", "language": "JavaScript", "license": null, "readme": "# Stellar Elements\n\nA small design system for Stellar.org user interfaces using\n[styleguidist](https://react-styleguidist.js.org/).\n\n# Contributing\n\n## Developing\n\nCode examples in Markdown use ES6+JSX syntax. You can use the current component\nwithout explicitly importing it:\n\n````jsx\n// ```jsx inside Button/Readme.md or Button.md\n<Button>Push Me</Button>\n````\n\nTo use other components, you need to explicity import them. Reference on\n[Writing code examples on styleguidist](https://react-styleguidist.js.org/docs/documenting.html#writing-code-examples)\n\n<!-- prettier-ignore -->\n````jsx\n// ```jsx inside Panel/Readme.md or Panel.md\nimport { all } from 'dog-names';\nimport { RandomButton } from '../RandomButton';\n<RandomButton variants={all} />\n````\n\n## Merging in changes\n\nMake a pull request if you want to contribute changes to the library. Make sure\nall tests pass! An @stellar employee will merge your PR into master if all looks\nokay.\n\n## Releasing\n\nBefore releasing, make a pull request changing the version number in\npackage.json to the version you're planning to release.\n\nOnce the library is ready for release, make a new\n[release tag](https://github.com/stellar/js-stellar-elements/releases). CircleCI\nwill automatically publish changes to NPM when it sees new releases starting\nwith `v`.\n", "release_dates": ["2019-05-07T15:15:26Z", "2019-04-25T18:00:44Z", "2019-04-23T21:03:27Z"]}, {"name": "js-stellar-sdk", "description": "Main Stellar client library for the JavaScript language.", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "\n<div align=\"center\">\n  <img alt=\"Stellar\" src=\"https://github.com/stellar/.github/raw/master/stellar-logo.png\" width=\"558\" />\n  <br/>\n  <strong>Creating equitable access to the global financial system</strong>\n  <h1>js-stellar-sdk</h1>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://badge.fury.io/js/stellar-sdk\"><img src=\"https://badge.fury.io/js/stellar-sdk.svg\" alt=\"npm version\" height=\"18\"></a>\n  <a href=\"https://www.npmjs.com/package/stellar-sdk\">\n    <img alt=\"Weekly Downloads\" src=\"https://img.shields.io/npm/dw/stellar-sdk\" />\n  </a>\n  <a href=\"https://github.com/stellar/js-stellar-sdk/actions/workflows/tests.yml\"><img alt=\"Test Status\" src=\"https://github.com/stellar/js-stellar-sdk/actions/workflows/tests.yml/badge.svg\" /></a>\n</p>\n\njs-stellar-sdk is a JavaScript library for communicating with a\n[Stellar Horizon server](https://github.com/stellar/go/tree/master/services/horizon) and [Soroban RPC](https://soroban.stellar.org/docs/reference/rpc).\nIt is used for building Stellar apps either on Node.js or in the browser, though it can be used in other environments with some tinkering.\n\nIt provides:\n\n- a networking layer API for Horizon endpoints (REST-based),\n- a networking layer for Soroban RPC (JSONRPC-based).\n- facilities for building and signing transactions, for communicating with a\n  Stellar Horizon instance, and for submitting transactions or querying network\n  history.\n\n**Jump to:**\n\n * [Installation](#installation): details on hitting the ground running\n * [Usage](#usage): links to documentation and a variety of workarounds for non-traditional JavaScript environments\n   - [...with React Native](#usage-with-react-native)\n   - [...with Expo](#usage-with-expo-managed-workflows)\n   - [...with CloudFlare Workers](#usage-with-cloudflare-workers)\n * [Developing](#developing): contribute to the project!\n * [Understanding `stellar-sdk` vs. `stellar-base`](#stellar-sdk-vs-stellar-base)\n * [License](#license)\n\n## Installation\n\nUsing npm or yarn to include `stellar-sdk` in your own project:\n\n```shell\nnpm install --save @stellar/stellar-sdk\n# or\nyarn add @stellar/stellar-sdk\n```\n\nThen, require or import it in your JavaScript code:\n\n```js\nvar StellarSdk = require('@stellar/stellar-sdk');\n// or\nimport * as StellarSdk from '@stellar/stellar-sdk';\n```\n\n(Preferably, you would only import the pieces you need to enable tree-shaking and lower your final bundle sizes.)\n\n### Browsers\n\nYou can use a CDN:\n\n```html\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/stellar-sdk/{version}/stellar-sdk.js\"></script>\n```\n\nNote that this method relies using a third party to host the JS library. This may not be entirely secure. You can self-host it via [Bower](http://bower.io):\n\n```shell\nbower install @stellar/stellar-sdk\n```\n\nand include it in the browser:\n\n```html\n<script src=\"./bower_components/stellar-sdk/stellar-sdk.js\"></script>\n<script>\n  console.log(StellarSdk);\n</script>\n```\n\nIf you don't want to use or install Bower, you can copy the packaged JS files from the [Bower repo](https://github.com/stellar/bower-js-stellar-sdk), or just build the package yourself locally (see [Developing :arrow_right: Building](#building)) and copy the bundle.\n\n| Always make sure that you are using the latest version number. They can be found on the [releases page](https://github.com/stellar/js-stellar-sdk/releases) in GitHub. |\n|----|\n\n## Usage\n\nThe usage documentation for this library lives in a handful of places:\n\n * across the [Stellar Developer Docs](), which includes tutorials and examples,\n * within [this repository itself](https://github.com/stellar/js-stellar-sdk/blob/master/docs/reference/readme.md), and\n * on the generated [API doc site](https://stellar.github.io/js-stellar-sdk/).\n\nYou can also refer to:\n\n * the [documentation](https://developers.stellar.org/api/introduction/) for the Horizon REST API (if using the `Horizon` module) and\n * the [documentation](https://soroban.stellar.org/docs/reference/rpc) for Soroban RPC's API (if using the `SorobanRpc` module)\n\n### Usage with React-Native\n\n1. Install `yarn add --dev rn-nodeify`\n2. Add the following postinstall script:\n```\nyarn rn-nodeify --install url,events,https,http,util,stream,crypto,vm,buffer --hack --yarn\n```\n3. Uncomment `require('crypto')` on shim.js\n4. `react-native link react-native-randombytes`\n5. Create file `rn-cli.config.js`\n```\nmodule.exports = {\n  resolver: {\n    extraNodeModules: require(\"node-libs-react-native\"),\n  },\n};\n```\n6. Add `import \"./shim\";` to the top of `index.js`\n7. `yarn add @stellar/stellar-sdk`\n\nThere is also a [sample](https://github.com/fnando/rn-stellar-sdk-sample) that you can follow.\n\n**Note**: Only the V8 compiler (on Android) and JSC (on iOS) have proper support for `Buffer` and `Uint8Array` as is needed by this library. Otherwise, you may see bizarre errors when doing XDR encoding/decoding such as `source not specified`.\n\n#### Usage with Expo managed workflows\n\n1. Install `yarn add --dev rn-nodeify`\n2. Add the following postinstall script:\n```\nyarn rn-nodeify --install process,url,events,https,http,util,stream,crypto,vm,buffer --hack --yarn\n```\n3. Add `import \"./shim\";` to the your app's entry point (by default `./App.js`)\n4. `yarn add @stellar/stellar-sdk`\n5. `expo install expo-random`\n\nAt this point, the Stellar SDK will work, except that `StellarSdk.Keypair.random()` will throw an error. To work around this, you can create your own method to generate a random keypair like this:\n\n```javascript\nimport * as Random from 'expo-random';\nimport { Keypair } from '@stellar/stellar-sdk';\n\nconst generateRandomKeypair = () => {\n  const randomBytes = Random.getRandomBytes(32);\n  return Keypair.fromRawEd25519Seed(Buffer.from(randomBytes));\n};\n```\n\n#### Usage with CloudFlare Workers\n\nBoth `eventsource` (needed for streaming) and `axios` (needed for making HTTP requests) are problematic dependencies in the CFW environment. The experimental branch [`make-eventsource-optional`](https://github.com/stellar/js-stellar-sdk/pull/901) is an attempt to resolve these issues.\n\nIt requires the following additional tweaks to your project:\n * the `axios-fetch-adapter` lets you use `axios` with `fetch` as a backend, which is available to CF workers\n * it only works with `axios@\"<= 1.0.0\"` versions, so we need to force an override into the underlying dependency\n * and this can be problematic with newer `yarn` versions, so we need to force the environment to use Yarn 1\n\nIn summary, the `package.json` tweaks look something like this:\n\n```jsonc\n\"dependencies\": {\n  // ...\n  \"@stellar/stellar-sdk\": \"git+https://github.com/stellar/js-stellar-sdk#make-eventsource-optional\",\n  \"@vespaiach/axios-fetch-adapter\": \"^0.3.1\",\n  \"axios\": \"^0.26.1\"\n},\n\"overrides\": {\n  \"@stellar/stellar-sdk\": {\n    \"axios\": \"$axios\"\n  }\n},\n\"packageManager\": \"yarn@1.22.19\"\n```\n\nThen, you need to override the adapter in your codebase:\n\n```typescript\nimport { Horizon } from '@stellar/stellar-sdk';\nimport fetchAdapter from '@vespaiach/axios-fetch-adapter';\n\nHorizon.AxiosClient.defaults.adapter = fetchAdapter as any;\n\n// then, the rest of your code...\n```\n\nAll HTTP calls will use `fetch`, now, meaning it should work in the CloudFlare Worker environment.\n\n## Developing\n\nSo you want to contribute to the library: welcome! Whether you're working on a fork or want to make an upstream request, the dev-test loop is pretty straightforward.\n\n1. Clone the repo:\n\n```shell\ngit clone https://github.com/stellar/js-stellar-sdk.git\n```\n\n2. Install dependencies inside js-stellar-sdk folder:\n\n```shell\ncd js-stellar-sdk\nyarn\n```\n\n3. Install Node 18\n\nBecause we support the oldest maintenance version of Node, please install and develop on Node 18 so you don't get surprised when your code works locally but breaks in CI.\n\nHere's how to install `nvm` if you haven't: https://github.com/creationix/nvm\n\n```shell\nnvm install 18\n\n# if you've never installed 18 before you'll want to re-install yarn\nnpm install -g yarn\n```\n\nIf you work on several projects that use different Node versions, you might it helpful to install this automatic version manager: https://github.com/wbyoung/avn\n\n4. Observe the project's code style\n\nWhile you're making changes, make sure to run the linter to catch any linting\nerrors (in addition to making sure your text editor supports ESLint) and conform to the project's code style.\n\n```shell\nyarn fmt\n```\n\n### Building\nYou can build the developer version (unoptimized, commented, with source maps, etc.) or the production bundles:\n\n```shell\nyarn build\n# or\nyarn build:prod\n```\n\n### Testing\n\nTo run all tests:\n\n```shell\nyarn test\n```\n\nTo run a specific set of tests:\n\n```shell\nyarn test:node\nyarn test:browser\nyarn test:integration\n```\n\nIn order to have a faster test loop, these suite-specific commands **do not** build the bundles first (unlike `yarn test`). If you make code changes, you will need to run `yarn build` (or a subset like `yarn build:node` corresponding to the test suite) before running the tests again to see your changes.\n\nTo generate and check the documentation site:\n\n```shell\n# install the `serve` command if you don't have it already\nnpm i -g serve\n\n# clone the base library for complete docs\ngit clone https://github.com/stellar/js-stellar-base\n\n# generate the docs files\nyarn docs\n\n# get these files working in a browser\ncd jsdoc && serve .\n\n# you'll be able to browse the docs at http://localhost:5000\n```\n\n### Publishing\n\nFor information on how to contribute or publish new versions of this software to `npm`, please refer to our [contribution guide](https://github.com/stellar/js-stellar-sdk/blob/master/CONTRIBUTING.md).\n\n## Miscellaneous\n\n### `stellar-sdk` vs `stellar-base`\n\n`stellar-sdk` is a high-level library that serves as client-side API for Horizon and Soroban RPC, while [`stellar-base](https://github.com/stellar/js-stellar-base) is lower-level library for creating Stellar primitive constructs via XDR helpers and wrappers.\n\n**Most people will want stellar-sdk instead of stellar-base.** You should only use stellar-base if you know what you're doing!\n\nIf you add `stellar-sdk` to a project, **do not add `stellar-base`!** Mismatching versions could cause weird, hard-to-find bugs. `stellar-sdk` automatically installs `stellar-base` and exposes all of its exports in case you need them.\n\n> **Important!** The Node.js version of the `stellar-base` (`stellar-sdk` dependency) package uses the [`sodium-native`](https://www.npmjs.com/package/sodium-native) package as an [optional dependency](https://docs.npmjs.com/files/package.json#optionaldependencies). `sodium-native` is a low level binding to [libsodium](https://github.com/jedisct1/libsodium), (an implementation of [Ed25519](https://ed25519.cr.yp.to/) signatures).\n> If installation of `sodium-native` fails, or it is unavailable, `stellar-base` (and `stellar-sdk`) will fallback to using the [`tweetnacl`](https://www.npmjs.com/package/tweetnacl) package implementation. If you are using them in a browser, you can ignore this. However, for production backend deployments, you should be using `sodium-native`.\n> If `sodium-native` is successfully installed and working the `StellarSdk.FastSigning` variable will return `true`.\n\n### License\n\njs-stellar-sdk is licensed under an Apache-2.0 license. See the\n[LICENSE](https://github.com/stellar/js-stellar-sdk/blob/master/LICENSE) file\nfor details.\n", "release_dates": ["2024-02-12T20:38:32Z", "2024-01-23T01:45:53Z", "2024-01-11T21:39:32Z", "2023-12-15T22:50:22Z", "2023-12-08T00:32:10Z", "2023-12-07T20:26:12Z", "2023-11-03T19:56:17Z", "2023-10-25T18:46:40Z", "2023-10-05T16:01:25Z", "2023-09-19T01:01:54Z", "2023-09-15T23:34:59Z", "2023-07-12T16:55:42Z", "2023-04-21T20:25:39Z", "2022-12-15T21:12:57Z", "2022-10-04T21:09:13Z", "2022-09-07T19:35:02Z", "2022-08-19T22:14:55Z", "2022-05-26T19:00:03Z", "2022-05-17T22:00:46Z", "2022-04-18T18:28:19Z", "2022-04-13T17:02:27Z", "2022-01-21T21:28:18Z", "2022-01-11T22:03:32Z", "2021-11-16T21:37:21Z", "2021-10-07T22:49:52Z", "2021-09-20T14:11:17Z", "2021-09-16T23:38:33Z", "2021-09-02T21:15:29Z", "2021-08-04T18:53:10Z", "2021-07-22T17:17:47Z"]}, {"name": "js-stellar-wallets", "description": "A library to make it easier to write wallets that interact with Stellar", "language": "TypeScript", "license": null, "readme": "# js-stellar-wallets\n\n> **Warning**\n>\n> This project has been deprecated in favor of\n> <https://github.com/stellar/typescript-wallet-sdk>.\n\nTo read the original README, please visit\n<https://github.com/stellar/js-stellar-wallets/blob/master/README_ORIGINAL.md>.\n", "release_dates": ["2024-01-15T14:52:40Z", "2024-01-10T21:07:03Z", "2023-12-11T19:43:33Z", "2023-09-19T21:29:20Z", "2023-05-02T16:58:52Z", "2023-02-22T16:56:18Z", "2022-12-01T18:53:14Z", "2022-05-20T14:47:47Z", "2022-05-06T18:39:18Z", "2022-05-06T18:38:23Z", "2022-05-06T18:37:12Z", "2021-07-06T19:30:46Z", "2021-05-25T18:21:31Z", "2021-05-21T14:25:49Z", "2021-02-25T20:56:25Z", "2021-02-25T20:22:17Z", "2021-02-23T17:03:26Z", "2020-11-24T21:03:46Z", "2020-10-30T20:12:02Z", "2020-10-28T14:00:25Z", "2020-09-30T15:00:53Z", "2020-09-22T19:02:45Z", "2020-08-13T15:40:14Z", "2020-08-13T13:46:59Z", "2020-08-10T17:22:10Z", "2020-08-05T16:54:52Z", "2020-08-03T18:25:24Z", "2020-08-03T14:35:01Z", "2020-07-16T21:48:27Z", "2020-07-16T21:05:37Z"]}, {"name": "js-xdr", "description": "Read/write XDR encoded data structures (RFC 4506)", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# XDR, for Javascript\n\nRead/write XDR encoded data structures (RFC 4506)\n\n[![Build Status](https://travis-ci.com/stellar/js-xdr.svg?branch=master)](https://travis-ci.com/stellar/js-xdr)\n[![Code Climate](https://codeclimate.com/github/stellar/js-xdr/badges/gpa.svg)](https://codeclimate.com/github/stellar/js-xdr)\n[![Dependency Status](https://david-dm.org/stellar/js-xdr.svg)](https://david-dm.org/stellar/js-xdr)\n[![devDependency Status](https://david-dm.org/stellar/js-xdr/dev-status.svg)](https://david-dm.org/stellar/js-xdr#info=devDependencies)\n\nXDR is an open data format, specified in\n[RFC 4506](http://tools.ietf.org/html/rfc4506.html). This library provides a way\nto read and write XDR data from javascript. It can read/write all of the\nprimitive XDR types and also provides facilities to define readers for the\ncompound XDR types (enums, structs and unions)\n\n## Installation\n\nvia npm:\n\n```shell\nnpm install --save @stellar/js-xdr\n```\n\n## Usage\n\nYou can find some [examples here](examples/).\n\nFirst, let's import the library:\n\n```javascript\nvar xdr = require('@stellar/js-xdr');\n// or\nimport xdr from '@stellar/js-xdr';\n```\n\nNow, let's look at how to decode some primitive types:\n\n```javascript\n// booleans\nxdr.Bool.fromXDR([0, 0, 0, 0]); // returns false\nxdr.Bool.fromXDR([0, 0, 0, 1]); // returns true\n\n// the inverse of `fromXDR` is `toXDR`, which returns a Buffer\nxdr.Bool.toXDR(true); // returns Buffer.from([0,0,0,1])\n\n// XDR ints and unsigned ints can be safely represented as\n// a javascript number\n\nxdr.Int.fromXDR([0xff, 0xff, 0xff, 0xff]); // returns -1\nxdr.UnsignedInt.fromXDR([0xff, 0xff, 0xff, 0xff]); // returns 4294967295\n\n// XDR Hypers, however, cannot be safely represented in the 53-bits\n// of precision we get with a JavaScript `Number`, so we allow creation from big-endian arrays of numbers, strings, or bigints.\nvar result = xdr.Hyper.fromXDR([0, 0, 0, 0, 0, 0, 0, 0]); // returns an instance of xdr.Hyper\nresult = new xdr.Hyper(0); // equivalent\n\n// convert the hyper to a string\nresult.toString(); // return '0'\n\n// math!\nvar ten = result.toBigInt() + 10;\nvar minusone = result.toBigInt() - 1;\n\n// construct a number from a string\nvar big = xdr.Hyper.fromString('1099511627776');\n\n// encode the hyper back into xdr\nbig.toXDR(); // <Buffer 00 00 01 00 00 00 00 00>\n```\n\n## Caveats\n\nThere are a couple of caveats to be aware of with this library:\n\n1.  We do not support quadruple precision floating point values. Attempting to\n    read or write these values will throw errors.\n2.  NaN is not handled perfectly for floats and doubles. There are several forms\n    of NaN as defined by IEEE754 and the browser polyfill for node's Buffer\n    class seems to handle them poorly.\n\n## Code generation\n\n`js-xdr` by itself does not have any ability to parse XDR IDL files and produce\na parser for your custom data types. Instead, that is the responsibility of\n[`xdrgen`](http://github.com/stellar/xdrgen). xdrgen will take your .x files\nand produce a javascript file that target this library to allow for your own\ncustom types.\n\nSee [`stellar-base`](http://github.com/stellar/js-stellar-base) for an example\n(check out the src/generated directory)\n\n## Contributing\n\nPlease [see CONTRIBUTING.md for details](CONTRIBUTING.md).\n\n### To develop and test js-xdr itself\n\n1. Clone the repo\n\n```shell\ngit clone https://github.com/stellar/js-xdr.git\n```\n\n2. Install dependencies inside js-xdr folder\n\n```shell\ncd js-xdr\nnpm i\n```\n\n3. Install Node 14\n\nBecause we support the oldest maintenance version of Node, please install and\ndevelop on Node 14 so you don't get surprised when your code works locally but\nbreaks in CI.\n\nHere's out to install `nvm` if you haven't: https://github.com/creationix/nvm\n\n```shell\nnvm install\n\n# if you've never installed 14.x before you'll want to re-install yarn\nnpm install -g yarn\n```\n\nIf you work on several projects that use different Node versions, you might it\nhelpful to install this automatic version manager:\nhttps://github.com/wbyoung/avn\n\n4. Observe the project's code style\n\nWhile you're making changes, make sure to run the linter periodically to catch any linting errors (in addition to making sure your text editor supports ESLint)\n\n```shell\nyarn fmt\n````\n\nIf you're working on a file not in `src`, limit your code to Node 14! See what's\nsupported here: https://node.green/ (The reason is that our npm library must\nsupport earlier versions of Node, so the tests need to run on those versions.)\n", "release_dates": ["2024-01-30T01:12:53Z", "2023-11-20T21:30:29Z", "2023-06-22T20:38:44Z", "2023-04-21T23:02:13Z", "2021-04-12T21:12:25Z", "2020-11-12T19:44:42Z", "2020-04-07T21:32:49Z", "2020-01-23T19:34:56Z", "2019-04-19T19:04:39Z", "2019-02-25T15:28:56Z", "2019-02-04T15:55:36Z", "2018-09-17T17:25:52Z", "2018-08-08T18:32:10Z", "2018-06-25T14:58:57Z", "2018-02-08T14:20:50Z", "2017-08-10T00:32:46Z", "2016-04-28T17:50:19Z"]}, {"name": "kelp", "description": "Kelp is a free and open-source trading bot for the Stellar DEX and 100+ centralized exchanges", "language": "Go", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Kelp\n\n![Kelp logo](resources/kelp-icon@1x.png)\n\n[![GitHub last commit](https://img.shields.io/github/last-commit/stellar/kelp.svg)][github-last-commit]\n[![Github All Releases](https://img.shields.io/github/downloads/stellar/kelp/total.svg)][github-releases]\n[![license](https://img.shields.io/badge/License-Apache%202.0-blue.svg?longCache=true)][license-apache]\n\n[![Godoc](https://godoc.org/github.com/stellar/kelp?status.svg)](https://godoc.org/github.com/stellar/kelp)\n[![Go Report Card](https://goreportcard.com/badge/github.com/stellar/kelp)](https://goreportcard.com/report/github.com/stellar/kelp)\n[![Build Status](https://circleci.com/gh/stellar/kelp.svg?style=shield)](https://circleci.com/gh/stellar/kelp)\n[![Contributors](https://img.shields.io/github/contributors/stellar/kelp.svg)](https://github.com/stellar/kelp/graphs/contributors)\n\nKelp is a free and open-source trading bot for the [Stellar universal marketplace][stellarx] and for centralized exchanges such as Binance, Kraken, CoinbasePro, etc.\n\nKelp includes several configurable trading strategies and exchange integrations. You can define your own parameters or use the sample configurations to quickly get up and running with a trading bot in a matter of minutes. The modular design allows you to easily create new trading strategies, exchange integrations, and assets to give you full control over the bot.\n\nKelp is built to:\n\n- Make spreads and make markets\n- Create liquidity and facilitate price-discovery for ICOs\n- Price and trade custom [stablecoins][stablecoin]\n- Mimic orderbooks from other exchanges\n\nTo learn more about the Stellar protocol check out [Stellar Videos on Coinbase Earn][stellar coinbase earn], or [this video about the Stellar DEX created by Lumenauts][sdex explainer video], or read more about it on the [Stellar Website][intro to stellar].\n\n## Be Smart and Go Slow\n\n**Important Disclaimer: Be Smart and Go Slow.** Whenever you trade on Stellar, you are trading with volatile assets, in volatile markets, and you risk losing money. Kelp is an experimental software that contains bugs. Use Kelp at your own risk. There is no guarantee you'll make a profit from using our bots or strategies. In fact, if you set bad parameters or market conditions change, Kelp might help you lose money very fast. So be smart and go slow.\n\nYour use of Kelp is governed by the Apache 2.0 open-source license. Please note that SDF\u2019s interactions with you are governed by the SDF [Terms of Service][tos] and [Privacy Policy][privacy-policy].\n\n![Kelp GUI screenshot](resources/screenshots/gui_screenshot.png)\n\n# Table of Contents\n\n* [Getting Started](#getting-started)\n   * [How To Get Kelp](#how-to-get-kelp)\n      * [Download Kelp Binary](#download-kelp-binary)\n      * [Run With Docker](#run-with-docker)\n      * [Compile from Source](#compile-from-source)\n   * [Running Kelp](#running-kelp)\n      * [Using CCXT](#using-ccxt)\n      * [Using Postgres](#using-postgres)\n      * [Using Auth0](#using-auth0)\n   * [Examples](#examples)\n      * [Walkthrough Guides](#walkthrough-guides)\n      * [Configuration Files](#configuration-files)\n      * [Winning Educational Content from StellarBattle](#winning-educational-content-from-stellarbattle)\n* [Components](#components)\n   * [Strategies](#strategies)\n   * [Price Feeds](#price-feeds)\n   * [Exchanges](#exchanges)\n   * [Plugins](#plugins)\n   * [Directory Structure](#directory-structure)\n   * [Accounting](#accounting)\n* [Community](#community)\n   * [Contributing](#contributing)\n   * [Changelog](#changelog)\n   * [Code of Conduct](#code-of-conduct)\n   * [Project Improvements](#project-improvements)\n* [Public Assets](#public-assets)\n\n# Getting Started\n\n## How To Get Kelp\n\nTo get started with Kelp, _either_ download the pre-compiled binary for your platform from the [Github Releases Page][github-releases] _or_ [compile Kelp from source](#compile-from-source).\n\nThere is **one** binary associated with this project: `kelp`. Once the binary is downloaded, run the bot by following the instructions in [Running Kelp](#running-kelp).\n\n### Download Kelp Binary\n\nYou can find the pre-compiled binary for your platform from the [Github Releases Page][github-releases].\n\n#### GUI\n\nHere is a list of binaries for the most recent release **v1.0.0-rc2 (v1.12.0)**:\n\n| Platform       | Architecture | Binary File Name |\n| -------------- | ------------ | ---------------- |\n| MacOS (Darwin) | 64-bit       | [kelp-v1.12.0-darwin-amd64.tar](https://github.com/stellar/kelp/releases/download/v1.12.0/KelpGUI__gui-v1.0.0-rc2__cli-v1.12.0__darwin-amd64.dmg) |\n| Windows        | 64-bit       | [kelp-v1.12.0-windows-amd64.tar](https://github.com/stellar/kelp/releases/download/v1.12.0/KelpGUI__gui-v1.0.0-rc2__cli-v1.12.0__windows-amd64.zip) |\n| Linux          | 64-bit       | [kelp-v1.12.0-linux-amd64.tar](https://github.com/stellar/kelp/releases/download/v1.12.0/KelpGUI__gui-v1.0.0-rc2__cli-v1.12.0__linux-amd64.zip) |\n\n#### CLI\n\nHere is a list of binaries for the most recent release **v1.12.0**:\n\n| Platform       | Architecture | Binary File Name |\n| -------------- | ------------ | ---------------- |\n| MacOS (Darwin) | 64-bit       | [kelp-v1.12.0-darwin-amd64.tar](https://github.com/stellar/kelp/releases/download/v1.12.0/kelp-v1.12.0-darwin-amd64.tar) |\n| Windows        | 64-bit       | [kelp-v1.12.0-windows-amd64.tar](https://github.com/stellar/kelp/releases/download/v1.12.0/kelp-v1.12.0-windows-amd64.tar) |\n| Linux          | 64-bit       | [kelp-v1.12.0-linux-amd64.tar](https://github.com/stellar/kelp/releases/download/v1.12.0/kelp-v1.12.0-linux-amd64.tar) |\n| Linux          | 64-bit arm   | [kelp-v1.12.0-linux-arm64.tar](https://github.com/stellar/kelp/releases/download/v1.12.0/kelp-v1.12.0-linux-arm64.tar) |\n| Linux          | 32-bit arm5  | [kelp-v1.12.0-linux-arm5.tar](https://github.com/stellar/kelp/releases/download/v1.12.0/kelp-v1.12.0-linux-arm5.tar) |\n| Linux          | 32-bit arm6  | [kelp-v1.12.0-linux-arm6.tar](https://github.com/stellar/kelp/releases/download/v1.12.0/kelp-v1.12.0-linux-arm6.tar) |\n| Linux          | 32-bit arm7  | [kelp-v1.12.0-linux-arm7.tar](https://github.com/stellar/kelp/releases/download/v1.12.0/kelp-v1.12.0-linux-arm7.tar) |\n\nAfter you _untar_ the downloaded file, change to the generated directory (`kelp-v1.12.0`) and invoke the `kelp` binary.\n\nHere's an example to get you started (replace `filename` with the name of the file that you download):\n\n    tar xvf filename\n    cd kelp-v1.12.0\n    ./kelp\n\nTo run the bot in simulation mode, try this command:\n\n    ./kelp trade -c sample_trader.cfg -s buysell -f sample_buysell.cfg --sim\n\n### Run With Docker\n\nThis docker image (`nikhilsaraf/kelp:latest`) points to the latest pre-compiled version of the kelp binary v1.12.0, which can be run like this:\n\n`docker run nikhilsaraf/kelp:latest version`\n`docker run nikhilsaraf/kelp:latest trade -c sample_trader.cfg -s buysell -f sample_buysell.cfg --sim`\n`docker run nikhilsaraf/kelp:latest exchanges`\n`docker run nikhilsaraf/kelp:latest strategies`\n\n### Compile from Source\n\n_Note for Windows Users: You should use a [Bash Shell][bash] to follow the steps below. This will give you a UNIX environment in which to run your commands and will enable the `./scripts/build.sh` bash script to work correctly._\n\nTo compile Kelp from source:\n\n1. [Download][golang-download] and [setup][golang-setup] Golang _v1.13 or later_\n   1. Set environment variable `export GOPROXY=https://goproxy.io,https://proxy.golang.org,https://goproxy.cn`\n2. Install [Yarn][yarn-install] and [NodeJs][nodejs-install] (Node v12.3.1 via [nvm][nvm]) to build the Kelp GUI\n3. Clone the kelp repository `git clone git@github.com:stellar/kelp.git`\n4. Install the [astilectron-bundler][astilectron-bundler] binary\n    * `go install github.com/asticode/go-astilectron-bundler/astilectron-bundler`\n5. Build the binaries using the provided build script (the _go install_ command will produce a faulty binary):\n    * `./scripts/build.sh` _(this must be invoked from root directory i.e. kelp)_\n6. Confirm one new binary file exists with version information. \n    * `./bin/kelp version`\n7. Set up CCXT to use an expanded set of priceFeeds and orderbooks (see the [Using CCXT](#using-ccxt) section for details)\n    * `sudo docker run -p 3000:3000 -d franzsee/ccxt-rest:v0.0.4`\n\n## Running Kelp\n\nKelp places orders on the [Stellar marketplace][stellarx] based on the selected strategy. Configuration files specify the Stellar account and strategy details.\n\nThese are the following commands available from the `kelp` binary:\n- `trade`: Trades with a specific strategy against the Stellar universal marketplace\n- `exchanges`: Lists the available exchange integrations along with capabilities\n- `strategies`: Lists the available strategies along with details\n- `version`: Version and build information\n- `help`: Help about any command\n\nThe `trade` command has three required parameters which are:\n\n- **botConf**: full path to the _.cfg_ file with the account details, [sample file here](examples/configs/trader/sample_trader.cfg).\n- **strategy**: the strategy you want to run (_sell_, _sell_twap_, _buysell_, _balanced_, _pendulum_, _mirror_, _delete_).\n- **stratConf**: full path to the _.cfg_ file specific to your chosen strategy, [sample files here](examples/configs/trader/).\n\nKelp sets the `X-App-Name` and `X-App-Version` headers on requests made to Horizon. These headers help us track overall Kelp usage, so that we can learn about general usage patterns and adapt Kelp to be more useful in the future. Kelp also uses Amplitude for metric tracking. These can be turned off using the `--no-headers` flag. See `kelp trade --help` for more information.\n\nHere's an example of how to start the trading bot with the _buysell_ strategy:\n\n`kelp trade --botConf ./path/trader.cfg --strategy buysell --stratConf ./path/buysell.cfg`\n\nIf you are ever stuck, just run `kelp help` to bring up the help section or type `kelp help [command]` for help with a specific command.\n\n### Using CCXT\n\nYou can use the [CCXT][ccxt] library via the [CCXT REST API Wrapper][ccxt-rest] to fetch prices and orderbooks from a larger number of exchanges. You will need to run the CCXT REST server on `localhost:3000` so Kelp can connect to it.\n\nThe CCXT-REST server **must** be running on port `3000` _before_ you start up the Kelp bot. You can list the exchanges (`./kelp exchanges`) to get the full list of supported exchanges via CCXT.\n\n_Note: this integration is still **experimental** and is also **incomplete**. Please use at your own risk._\n\nCCXT-rest can be run in any one of the following ways.\n\n#### Download CCXT Binary\n\nWe have compiled the ccxt-rest v0.0.4 server as a binary for all x86 platforms (linux, darwin, windows). This is the version that Kelp currently uses.\n\nYou can find these pre-compiled binaries of the CCXT-rest server in the [releases tab here](https://github.com/stellar/kelp/releases/tag/ccxt-rest_v0.0.4).\n\n#### Run CCXT using Docker\n\nInstall [docker][docker] (linux: `sudo apt install -y docker.io`) and run the CCXT-REST docker image configured to port `3000` (linux: `sudo docker run -p 3000:3000 -d franzsee/ccxt-rest:v0.0.4`).\nYou can find more details on the [CCXT_REST github page][ccxt-rest].\n\n### Using Postgres\n\n[Postgres][postgres] v12.1 or later must be installed for Kelp to automatically write trades to a sql database along with updating the trader config file.\n\n### Using Auth0\n\nA [auth0](https://auth0.com/) account is required. To use it, uncomment \\[AUTH0] section in [Sample GUI config file](examples/configs/trader/sample_GUI_config.cfg) and enter your auth0 crendentials in required fields.\nNote: AUTH0 is only applicable for Kelp GUI or Kaas Mode. Intructions of how to configure your auth0 account can be found [here](https://auth0.com/docs/quickstart/spa/react/01-login#configure-auth0)\n\n## Examples\n\nIt's easier to learn with examples! Take a look at the walkthrough guides and sample configuration files below.\n\n### Walkthrough Guides\n\n- [Setting up a trading account](examples/walkthroughs/trader/account_setup.md): This guide uses an example token, `COUPON`, to show you how to set up your account before deploying the bot.\n- [Market making for a stablecoin](examples/walkthroughs/trader/buysell.md): This guide uses the `buysell` strategy to provide liquidity for a stablecoin. \n- [ICO sale](examples/walkthroughs/trader/sell.md): This guide uses the `sell` strategy to make a market using sell offers for native tokens in a hypothetical ICO. \n- [TWAP sale](examples/walkthroughs/trader/sell_twap.md): This guide uses the `sell_twap` strategy to consistently sell tokens throughout the day. This can also be used for ICOs.\n- [Create liquidity AMM for a Stellar-based token](examples/walkthroughs/trader/balanced.md): This guide uses the `balanced` strategy to create liquidty for a token which only trades on the Stellar network. \n- [Create targeted liquidity AMM within a bounded price range](examples/walkthroughs/trader/pendulum.md): This guide uses the `pendulum` strategy to create liquidty for a token. \n\n### Configuration Files\n\nEach strategy you implement needs a configuration file. The format of the configuration file is specific to the selected strategy. You can use these files to customize parameters for your chosen strategy.\n\nThe following reference config files are in the [examples folder](examples/configs/trader):\n\n- [Sample Sell strategy config file](examples/configs/trader/sample_sell.cfg)\n- [Sample BuySell strategy config file](examples/configs/trader/sample_buysell.cfg)\n- [Sample Balanced strategy config file](examples/configs/trader/sample_balanced.cfg)\n- [Sample Pendulum strategy config file](examples/configs/trader/sample_pendulum.cfg)\n- [Sample Mirror strategy config file](examples/configs/trader/sample_mirror.cfg)\n- [Sample GUI(auth0 and other stuff) config file](examples/configs/trader/sample_GUI_config.cfg)\n\n### Winning Educational Content from StellarBattle\n\nSDF sponsored a [Kelp StellarBattle in August/September 2020][kelp-battle-1], here were the winning results ([announcement][kelp-battle-1-winners]):\n\n- [How To Create Liquidity With Kelp On The Stellar Dex (Winner)](https://medium.com/axons/how-to-create-liquidity-with-kelp-on-the-stellar-dex-5155928d4986)\n- [Make use of arbitrage opportunities with Kelp bot (Runner-Up)](https://stellarupdate.com/make-use-of-arbitrage-opportunities-with-kelp-bot-653/)\n- [Market Making in Stellar 101: Fundamentals & Kelp](https://rambling-ideas.salessandri.name/market-making-in-stellar-101-fundamentals-kelp/)\n- [Market Making on Stellar with Kelp Quickstart Guide](https://medium.com/@dexter0x8/market-making-on-stellar-101-with-kelp-trading-bot-5adbb05c3cb9)\n- [Kelp: Setup your first trading bot on the Stellar Network (using Windows)](https://edunode.org/blog/kelp)\n\n# Components\n\nKelp includes an assortment of strategies, price feeds, and plugins you can use to customize your bot. Kelp also enables you to create your own trading strategies.\n\n<details>\n    <summary>click to expand Components section</summary>\n\n## Strategies\n\nStrategies are at the core of Kelp. Without them it's just lazy, capable of nothing, thinking of nothing, doing nothing, like our friend [scooter][scooter video] here. The strategies give your bot purpose. Each approaches the market in a different way and is designed to achieve a particular goal.\n\nThe following strategies are available **out of the box** with Kelp:\n\n- sell ([source](plugins/sellStrategy.go)):\n\n    - **What:** creates sell offers based on a reference price with a pre-specified liquidity depth\n    - **Why:** To sell tokens at a fixed price or at a price that changes based on an external reference price\n    - **Who:** An issuer could use Sell to distribute tokens from an ICO pre-sale\n\n- sell_twap ([source](plugins/sellTwapStrategy.go)):\n\n    - **What:** creates sell offers based on a reference price spread over the day for a given daily sale amount\n    - **Why:** To sell tokens consistently using the time-weighted-average-price (TWAP) metric\n    - **Who:** An issuer could use SellTwap to distribute tokens from an ICO pre-sale in a consistent manner\n\n- buysell ([source](plugins/buysellStrategy.go)):\n\n    - **What:** creates buy and sell offers based on a specific reference price and a pre-specified liquidity depth while maintaining a [spread][spread].\n    - **Why:** To make the market for tokens based on a fixed or external reference price.\n    - **Who:** Anyone who wants to create liquidity for a stablecoin or [fiat][fiat] token\n\n- balanced ([source](plugins/balancedStrategy.go)):\n\n    - **What:** dynamically prices two tokens based on their relative demand (like AMMs). For example, if more traders buy token A _from_ the bot (the traders are therefore selling token B), the bot will automatically raise the price for token A and drop the price for token B. This strategy does not allow you to configure the order size but can run out of assets. This is a mean-reversion strategy.\n    - **Why:** To let the market surface the _true price_ for one token in terms of another.\n    - **Who:** Market makers and traders for tokens that have a neutral view on the market\n\n- pendulum ([source](plugins/pendulumStrategy.go)):\n\n    - **What:** dynamically prices two tokens based on their relative demand (like AMMs). For example, if more traders buy token A _from_ the bot (the traders are therefore selling token B), the bot will automatically raise the price for token A and drop the price for token B. This strategy allows you to configure the order size but runs the risk of running out of one of the two assets. This is a mean-reversion strategy.\n    - **Why:** To let the market surface the _true price_ for one token in terms of another.\n    - **Who:** Market makers and traders for tokens that have a neutral view on the market\n\n- mirror ([source](plugins/mirrorStrategy.go)):\n\n    - **What:** mirrors an orderbook from another exchange by placing the same orders on Stellar after including a [spread][spread].\n    - **Why:** To [hedge][hedge] your position on another exchange whenever a trade is executed to reduce inventory risk while keeping a spread\n    - **Who:** Anyone who wants to reduce inventory risk and also has the capacity to take on a higher operational overhead in maintaining the bot system.\n\n- delete ([source](plugins/deleteStrategy.go)):\n\n    - **What:** deletes your offers from both sides of the specified orderbook. _Note: does not need a strategy-specific config file_.\n    - **Why:** To kill the offers placed by the bot. _This is not a trading strategy but is used for operational purposes only_.\n    - **Who:** Anyone managing the operations of the bot who wants to stop all activity by the bot.\n\nRefer to this [Pull Request][pr-template-new-strategy] to see an example template of a new trading strategy.\n\n## Price Feeds\n\nPrice Feeds fetch the price of an asset from an external source. The following price feeds are available **out of the box** with Kelp:\n\n- `crypto`: fetches the price of tokens from [CoinMarketCap][cmc]\n- `fiat`: fetches the price of a [fiat][fiat] currency from the [CurrencyLayer API][currencylayer]\n- `exchange`: fetches the price from an exchange you specify, such as Kraken or Poloniex. You can also use the [CCXT][ccxt] integration to fetch prices from a wider range of exchanges (see the [Using CCXT](#using-ccxt) section for details)\n- `fixed`: sets the price to a constant\n- `function`: uses a pre-defined function to combine the above price feed types into a single feed. We currently support only two types\n    - `max` - `max(exchange/ccxt-binance/XLM/USDT/mid,exchange/ccxt-coinbasepro/XLM/USD/mid)`\n    - `invert` - `invert(exchange/ccxt-binance/XLM/USDT/mid)`\n\n## Exchanges\n\nExchange integrations provide data to trading strategies and allow you to [hedge][hedge] your positions on different exchanges. The following [exchange integrations](plugins) are available **out of the box** with Kelp:\n\n- sdex (_`\"sdex\"`_) ([source](plugins/sdex.go)): The [Stellar Decentralized Exchange][sdex]\n- kraken (_`\"kraken\"`_) ([source](plugins/krakenExchange.go)): [Kraken][kraken] - recommended to use `ccxt-kraken` instead\n- kraken (via CCXT) (_`\"ccxt-kraken\"`_) ([source](plugins/ccxtExchange.go)): Kraken via CCXT - full two-way integration (tested)\n- binance (via CCXT) (_`\"ccxt-binance\"`_) ([source](plugins/ccxtExchange.go)): Binance via CCXT - full two-way integration (tested)\n- coinbasepro (via CCXT) (_`\"ccxt-coinbasepro\"`_) ([source](plugins/ccxtExchange.go)): Coinbase Pro via CCXT - full two-way integration (tested)\n- poloniex (via CCXT) (_`\"ccxt-poloniex\"`_) ([source](plugins/ccxtExchange.go)): Poloniex via CCXT - only tested on priceFeeds and one-way mirroring\n- bittrex (via CCXT) (_`\"ccxt-bittrex\"`_) ([source](plugins/ccxtExchange.go)): Bittrex via CCXT - only tested on priceFeeds and onw-way mirroring\n\n## Plugins\n\nKelp can easily be extended because of its _modular plugin based architecture_.\nYou can create new flavors of the following components: Strategies, PriceFeeds, and Exchanges.\n\nThese interfaces make it easy to create plugins:\n- Strategy ([source](api/strategy.go)) - API for a strategy\n- PriceFeed ([source](api/priceFeed.go)) - API for price of an asset\n- Exchange ([source](api/exchange.go)) - API for crypto exchanges\n\n## Directory Structure\n\nThe folders are organized to make it easy to find code and streamline development flow.\nEach folder is its own package **without any sub-packages**.\n\n    github.com/stellar/kelp\n    \u251c\u2500\u2500 api/            # API interfaces live here (strategy, exchange, price feeds, etc.)\n    \u251c\u2500\u2500 cmd/            # Cobra commands (trade, exchanges, strategies, etc.)\n    \u251c\u2500\u2500 examples/       # Sample config files and walkthroughs\n    \u251c\u2500\u2500 model/          # Low-level structs (dates, orderbook, etc.)\n    \u251c\u2500\u2500 plugins/        # Implementations of API interfaces (sell strategy, kraken, etc.)\n    \u251c\u2500\u2500 support/        # Helper functions and utils\n    \u251c\u2500\u2500 trader/         # Trader bot logic; uses other top-level packages like api, plugins, etc.\n    \u251c\u2500\u2500 glide.yaml      # Glide dependencies\n    \u251c\u2500\u2500 main.go         # main function for our kelp binary\n    \u2514\u2500\u2500 ...\n\n## Accounting\n\nYou can use [**Stellar-Downloader**][stellar-downloader] to download trade and payment data from your Stellar account as a CSV file.\n\n</details>\n\n# Community\n\n- Ask questions on the [Stellar StackExchange][stackexchange] using the `kelp` tag\n- Announcements will be made on the [announcements distribution list][announcements-group]\n- Community discussions (outside of questions) can take place on the [user mailing list][discussions-group]\n\n<details>\n    <summary>click to expand Community section</summary>\n\n## Contributing\n\nSee the [Contribution Guide](CONTRIBUTING.md) and then please [sign the Contributor License Agreement][cla].\n\n## Changelog\n\nSee the [Changelog](CHANGELOG.md).\n\n## Code of Conduct\n\nSee the [Code of Conduct](CODE_OF_CONDUCT.md).\n\n## Project Improvements\n\n- [Submit a Bug Report][github-bug-report]\n- [Submit a Feature Request][github-feature-request]\n- [Raise an issue][github-new-issue] that is not a bug report or a feature request\n- [Contribute a PR][github-pulls]\n\n</details>\n\n# Public Assets\n\n<details>\n    <summary>click to expand Public Assets section</summary>\n\n`TEST1` and `TEST2` issued by the `GCL4KBYTRA3QYI4JTN4FWVYVYNI67W2M6XMDUB2V6ZLWFASIYHWEJPHU` account are test assets used to test Kelp on the production Stellar Network. **These assets have no value** and are marked as `auth_required` with the intent to close them off from the rest of the Stellar ecosystem. No trustlines will be accepted against these assets. As part of our testing process, you may observe a market and trades between these two tokens. It is not intended for any of these assets to represent any meaningful volume on the Stellar Network.\n\n</details>\n\n[github-last-commit]: https://github.com/stellar/kelp/commit/HEAD\n[github-releases]: https://github.com/stellar/kelp/releases\n[license-apache]: https://opensource.org/licenses/Apache-2.0\n[github-issues]: https://github.com/stellar/kelp/issues\n[github-issues-closed]: https://github.com/stellar/kelp/issues?q=is%3Aissue+is%3Aclosed\n[github-pulls]: https://github.com/stellar/kelp/pulls\n[github-pulls-closed]: https://github.com/stellar/kelp/pulls?q=is%3Apr+is%3Aclosed\n[stellarx]: https://www.stellarx.com\n[stablecoin]: https://en.wikipedia.org/wiki/Stablecoin\n[intro to stellar]: https://www.stellar.org/learn/intro-to-stellar\n[scooter video]: https://youtu.be/LStXAG5dwzA\n[sdex]: https://www.stellar.org/developers/guides/concepts/exchange.html\n[stellar coinbase earn]: https://www.coinbase.com/earn/stellar\n[sdex explainer video]: https://www.lumenauts.com/lessons/stellar-decentralized-exchange\n[bash]: https://en.wikipedia.org/wiki/Bash_(Unix_shell)\n[golang-download]: https://golang.org/dl/\n[golang-setup]: https://golang.org/doc/install#install\n[glide-install]: https://github.com/Masterminds/glide#install\n[yarn-install]: https://yarnpkg.com/lang/en/docs/install/\n[nodejs-install]: https://nodejs.org/en/download/\n[nvm]: https://github.com/nvm-sh/nvm\n[astilectron-bundler]: https://github.com/asticode/go-astilectron-bundler\n[spread]: https://en.wikipedia.org/wiki/Bid%E2%80%93ask_spread\n[hedge]: https://en.wikipedia.org/wiki/Hedge_(finance)\n[pr-template-new-strategy]: https://github.com/stellar/kelp/pull/494\n[cmc]: https://coinmarketcap.com/\n[fiat]: https://en.wikipedia.org/wiki/Fiat_money\n[currencylayer]: https://currencylayer.com/\n[ccxt]: https://github.com/ccxt/ccxt\n[ccxt-rest]: https://github.com/franz-see/ccxt-rest\n[docker]: https://www.docker.com/\n[postgres]: https://www.postgresql.org/\n[auth0]: https://auth0.com/\n[kelp-battle-1]: https://stellarbattle.com/kelp-overview-battle/\n[kelp-battle-1-winners]: https://medium.com/stellar-community/announcing-the-winners-of-the-first-kelpbot-stellarbattle-a6f28fef7776\n[kraken]: https://www.kraken.com/\n[stellar-downloader]: https://github.com/nikhilsaraf/stellar-downloader\n[stackexchange]: https://stellar.stackexchange.com/\n[cla]: https://forms.gle/9FBgjDnNYv1abnKD7\n[tos]: https://www.stellar.org/terms-of-service\n[privacy-policy]: https://www.stellar.org/privacy-policy\n[announcements-group]: https://groups.google.com/forum/#!forum/kelp-announce\n[discussions-group]: https://groups.google.com/forum/#!forum/kelp-talk\n[github-bug-report]: https://github.com/stellar/kelp/issues/new?template=bug_report.md\n[github-feature-request]: https://github.com/stellar/kelp/issues/new?template=feature_request.md\n[github-new-issue]: https://github.com/stellar/kelp/issues/new\n", "release_dates": ["2021-11-05T20:56:13Z", "2021-02-15T16:48:03Z", "2020-10-22T20:00:19Z", "2020-05-11T13:28:28Z", "2020-05-07T15:07:14Z", "2020-03-20T17:45:19Z", "2020-02-17T21:33:58Z", "2020-02-11T23:30:58Z", "2019-10-30T20:40:12Z", "2019-08-26T07:42:06Z", "2019-07-18T22:07:20Z", "2019-05-06T04:19:02Z", "2019-04-13T00:20:04Z", "2019-03-29T23:43:34Z", "2019-03-05T03:57:39Z", "2019-02-06T23:50:25Z", "2019-01-11T00:54:50Z", "2018-11-27T01:29:37Z", "2018-10-30T18:03:52Z", "2018-10-22T21:43:23Z", "2018-10-19T23:51:21Z", "2018-10-15T21:22:21Z", "2018-09-29T16:01:29Z", "2018-09-28T19:05:45Z", "2018-08-13T23:18:58Z"]}, {"name": "kotlin-wallet-sdk", "description": "Kotlin Wallet SDK to build Stellar wallets", "language": "Kotlin", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Kotlin Wallet SDK [![javadoc](https://javadoc.io/badge2/org.stellar/wallet-sdk/dokka.svg?logo=kotlin)](https://javadoc.io/doc/org.stellar/wallet-sdk) [![Maven Central](https://img.shields.io/maven-central/v/org.stellar/wallet-sdk?color=success&logo=apache-maven)](https://central.sonatype.com/search?q=pkg%253Amaven%252Forg.stellar%252Fwallet-sdk&namespace=org.stellar)\n\nKotlin Wallet SDK is a library that allows developers to build wallet applications on the Stellar network faster. It\nutilizes [Java Stellar SDK](https://github.com/stellar/java-stellar-sdk) to communicate with a Stellar Horizon server.\n\n## Dependency\n\nThe library is hosted on the [Maven Central](https://central.sonatype.com/search?q=pkg%253Amaven%252Forg.stellar%252Fwallet-sdk&namespace=org.stellar).\nTo import `wallet-sdk` library you need to add following dependencies to your code:\n\nMaven:\n\n```pom\n<dependency>\n  <groupId>org.stellar</groupId>\n  <artifactId>wallet-sdk</artifactId>\n  <version>1.1.0</version>\n</dependency>\n```\n\nGradle:\n\n```gradle\nimplementation(\"org.stellar:wallet-sdk:1.1.0\")\n```\n\n## Introduction\n\n<!--- INCLUDE .*readme.*\nimport org.stellar.walletsdk.*\n\nfun main() { \n-->\n<!--- SUFFIX .*readme.*\n  println(newKeyPair)\n}    \n-->\n\nHere's a small example creating main wallet class with default configuration connected to testnet network:\n\n```kotlin\n  val wallet = Wallet(StellarConfiguration.Testnet)\n```\n\nIt should later be re-used across the code, as it has access to various useful children classes. For example, new key pair can be\ncreated using it.\n\n```kotlin\n  val newKeyPair = wallet.stellar().account().createKeyPair()\n```\n\nRead [full wallet guide](https://developers.stellar.org/docs/category/build-a-wallet-with-the-wallet-sdk) for more info\n\nYou can find auto-generated documentation website on [javadoc.io](https://javadoc.io/doc/org.stellar/wallet-sdk) \n", "release_dates": ["2024-02-22T03:27:19Z", "2024-02-14T00:00:30Z", "2023-12-21T18:02:24Z", "2023-12-15T19:58:59Z", "2023-10-24T17:41:03Z", "2023-09-20T18:30:54Z", "2023-08-03T16:54:49Z", "2023-07-19T00:01:58Z", "2023-07-11T23:00:42Z", "2023-06-16T20:39:37Z", "2023-06-16T17:27:25Z", "2023-05-01T18:56:59Z", "2023-04-11T17:56:41Z", "2023-03-02T21:06:44Z", "2023-01-20T00:31:43Z", "2022-12-09T18:57:38Z"]}, {"name": "laboratory", "description": null, "language": "JavaScript", "license": null, "readme": "# laboratory\n\nThe Stellar Laboratory is a suite of tools to help one learn about exploring the\nStellar network. See it in action:\n[https://laboratory.stellar.org/](https://laboratory.stellar.org/).\n\n## Developing\n\n```sh\nyarn start\n```\n\nTesting hardware wallets requires an HTTPS connection to enable U2F. The\nrecommended way to do this is with [`ngrok`](https://ngrok.com/). Once\ndownloaded and authenticated, start ngrok, and tell the laboratory to start with\na public URL.\n\n```bash\n./ngrok http 3000\n# in a separate terminal\n# the subdomain will appear in ngrok's output\nyarn start --public randomsubdomain.ngrok.io\n```\n\n## Building for production\n\n```sh\nyarn build\n```\n\nTo build a production docker image using a clean docker build environment:\n\n```sh\nmake docker-build\n# or directly with docker\ndocker build -t lab:localbuild .\n```\n\nTo build and run production build locally:\n\n```sh\nyarn production\n# or\nyarn prod:build\nyarn prod:serve\n```\n\nProduction uses Amplitude to emit metrics, so to fully emulate a production build, you'll need to set an `AMPLITUDE_API_KEY` variable in `/public/settings/env-config.js` file.\n\n## Internal documentation\n\nThe [docs.md](./docs.md) file contains code documentation on the laboratory. The\ndocs.md is only relevant for developing the laboratory.\n", "release_dates": ["2023-12-19T17:00:42Z", "2023-12-18T23:04:40Z", "2023-12-18T23:06:13Z", "2023-10-17T20:41:06Z", "2023-09-20T22:29:16Z", "2023-09-20T18:57:55Z", "2023-09-20T18:11:04Z", "2023-09-18T18:30:27Z", "2023-07-18T01:44:13Z", "2023-05-30T21:52:02Z", "2023-05-26T12:09:42Z", "2023-04-18T17:44:40Z", "2023-02-16T21:32:37Z", "2022-01-13T21:32:04Z", "2021-12-20T21:08:00Z", "2021-10-14T19:56:07Z", "2021-08-31T16:58:26Z", "2021-08-30T22:42:16Z", "2021-08-30T20:37:29Z"]}, {"name": "libsodium", "description": "A modern and easy-to-use crypto library.", "language": "C", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": null, "release_dates": []}, {"name": "mddiffcheck", "description": "A tool for checking that diffs in markdown files apply.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# mddiffcheck\nA tool for checking that git diffs that have been in markdown files apply successfully to the repo they're intended.\n\nThis tool was created to verify that git diffs included in [stellar-protocol] Core Advancement Protocols (CAPs) are valid.\n\nThe tool runs `git` as a subprocess and requires it to be installed.\n\n[stellar-protocol]: https://github.com/stellar/stellar-protocol\n\n## Usage\n\n```\n$ go install github.com/stellar/mddiffcheck@latest\n```\n\n```\n$ mddiffcheck -help\nUsage of mddiffcheck:\n  mddiffcheck -repo=<repo> <markdown-file> [markdown-file] ...\n\nExample:\n  mddiffcheck -repo=https://github.com/user/repo doc1.md doc2.md\n\nFlags:\n  -help\n        print this help\n  -repo string\n        repository to verify diffs against\n```\n\nWhen adding diffs into markdown, use the following format:\n\n- Specify the code block is a diff with `diff` on the same line as the backticks.\n- Specify the base git reference the diff applies to, either a tag or a commit sha, using the `mddiffcheck.base=` parameter.\n- Or, specify the diff should be ignored and not checked, using the `mddiffcheck.ignore=true` parameter.\n\n````\n# Heading\n\n## Subheading\n\n```diff mddiffcheck.fetch=pull/3380/head mddiffcheck.base=v16.0.0\ndiff --git a/src/xdr/Stellar-ledger-entries.x b/src/xdr/Stellar-ledger-entries.x\nindex 0e7bc842..68c52758 100644\n--- a/src/xdr/Stellar-ledger-entries.x\n+++ b/src/xdr/Stellar-ledger-entries.x\n@@ -114,12 +114,15 @@ enum AccountFlags\n     // Trustlines are created with clawback enabled set to \"true\",\n     // and claimable balances created from those trustlines are created\n     // with clawback enabled set to \"true\"\n-    AUTH_CLAWBACK_ENABLED_FLAG = 0x8\n+    AUTH_CLAWBACK_ENABLED_FLAG = 0x8,\n+    // Trustlines are created with revocation disabled set to \"true\"\n+    AUTH_NOT_REVOCABLE_FLAG = 0x10\n };\n \n // mask for all valid flags\n\n```\n\n````\n", "release_dates": ["2022-06-03T23:35:16Z", "2022-05-04T19:10:12Z"]}, {"name": "medida", "description": "Simple metrics library for C++ programs", "language": "C++", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "Medida - Simple metrics for C++ programs\n========================================\n\n*NOTE: Work in progress and not for human consumption! Go away!*\n\nProject homepage and documentation: http://dln.github.com/medida/\n\nCreated out of envy of Coda Hale's awesome Metrics library for the JVM.\n\n\nCopyright\n---------\nCopyright (c) 2012 Daniel Lundin\n\nThis software is licensed under the Apache License, Version 2.0.\nPlease see LICENSE for details.\n", "release_dates": []}, {"name": "moneygram-access-wallet-mvp", "description": "An MVP wallet integrated with MoneyGram Access", "language": "Python", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# MoneyGram Access Wallet MVP\n\nThis project contains the minimum amount of code necessary to integrate with a [SEP-24](https://github.com/stellar/stellar-protocol/blob/master/ecosystem/sep-0024.md) server, specifically [MoneyGram Access](https://stellar.org/moneygram?locale=en).\n\n**THIS CODE SHOULD ONLY BE USED AS A REFERENCE. DO NOT USE THIS CODE IN PRODUCTION.**\n\n## Configuration\n\nThe `.env.example` file contains all the environment variables necessary to run the service. The values are configured\nfor MoneyGram's testing deployment. However, `FUNDS_SECRET_KEY` and `AUTH_SECRET_KEY` should be replaced by keypairs\nyou generate yourself, either using a Stellar SDK or [Stellar Lab](https://laboratory.stellar.org/#account-creator?network=test).\n\nCopy `.env.example` to `.env`\n\n```shell\n$ cp .env.example .env\n```\n\nTo access MoneyGram's test environment, you will need to contact MoneyGram and provide the public keys associated with `FUNDS_SECRET_KEY` and `AUTH_SECRET_KEY`. They will add these public keys to a list of known accounts.\n\n## Running\n\nThe project can be run locally using Docker Compose.\n\n```shell\n$ docker compose up\n```\n\nYou should be able to access the UI at http://localhost:5000. Adjusting the code should automatically restart the docker container.\n\n### Running Without Docker\n\nYou'll need to export the variables from the `.env` file to the environment running the web server. You can do this line-by-line, or try exporting all environment variables in the file. This [StackOverflow post](https://stackoverflow.com/questions/19331497/set-environment-variables-from-file-of-key-value-pairs) may be helpful. Then:\n\n```shell\n$ poetry install\n$ poetry run python wallet_server.py\n```\n", "release_dates": []}, {"name": "new-docs", "description": null, "language": "JavaScript", "license": {"key": "mit", "name": "MIT License", "spdx_id": "MIT", "url": "https://api.github.com/licenses/mit", "node_id": "MDc6TGljZW5zZTEz"}, "readme": "# Stellar [Documentation](https://developers.stellar.org/docs/) and [API Reference](https://developers.stellar.org/api/)\n\n### \u26a0\ufe0f These docs are depreciated in favor of https://github.com/stellar/stellar-docs \u26a0\ufe0f \n\n# Contents\n\n- [Stellar Documentation and API Reference](#stellar-documentation-and-api-reference)\n- [Contents](#contents)\n- [How to Run](#how-to-run)\n  - [Dependencies](#dependencies)\n  - [Local Development](#local-development)\n  - [Local Production Build](#local-production-build)\n- [Structure](#structure)\n  - [Page Metadata](#page-metadata)\n  - [Folder Metadata](#folder-metadata)\n- [Markdown](#markdown)\n  - [Basic Components](#basic-components)\n    - [Table](#table)\n    - [Unordered List](#unordered-list)\n    - [Ordered List](#ordered-list)\n    - [Images](#images)\n    - [Quote](#quote)\n    - [Paragraph and Headings](#paragraph-and-headings)\n  - [Custom Components](#custom-components)\n    - [AttributeTable](#attributetable)\n      - [Omitting Data Type](#omitting-data-type)\n    - [Alert](#alert)\n    - [CodeExample](#codeexample)\n    - [Endpoint](#endpoint)\n    - [EndpointsTable](#endpointstable)\n    - [Example (JSON) Response](#example-json-response)\n    - [MethodTable](#methodtable)\n    - [Diagrams (Mermaid)](#diagrams-mermaid)\n    - [Performance metrics](#performance-metrics)\n    - [Testing requests as a crawler](#testing-requests-as-a-crawler)\n\n# How to Run\n\n## Dependencies\n\nTo build this project, you must have the following dependencies installed:\n\n- A modern version of node. We recommend the current LTS.\n  - We have some binary dependencies, `sharp` for image processing and\n    `puppeteer` to render Mermaid charts, which are both somewhat flaky. It's\n    possible that one of these will ship a change that mandates a more modern\n    version in the future.\n- `yarn`\n- If your local build environment is arm64, such as on newer Apple M1 Macs, then\n  use brew to pre-install libvips which is a native `sharp` dependency and needs\n  to be the arm64 version, it wasn't getting resolved to correct arch/platform\n  version through yarn install alone: `brew install vips`\n\nSome of the dependencies are considered \"legacy\", so run\n`npm install --legacy-peer-deps` to bypass errors.\n\n## Local Development\n\n`yarn start` to start local development.\n\n## Local Production Build\n\nThe build has been dockerized so we can host with nginx on Kubernetes, which can\nbe compiled and run with `yarn` scripts. Make sure you have Docker set up on\nyour machine.\n\n```sh\nyarn production\n# or\nyarn prod:build\nyarn prod:serve\n```\n\nTo run a complete simulation of a production build, make sure to set an\n`AMPLITUDE_KEY` environment variable.\n\n# Structure\n\n- `/content` contains\n  - Documentation `/docs`\n    - Web assets `/docs/web-assets`\n  - API Reference `/api`\n  - Each page is authored as an `index.mdx` document.\n\n## Page Metadata\n\n- **Title** (og:title, page title): Pulled from front matter.\n- **Order** (order in which a page appears in the table of contents): Pulled\n  from front matter.\n- **URL slug**: Pulled from the folder or file name\n\n**All names must use dashes for spaces instead of spaces or underscores**\n\n```\n---\ntitle: Node Monitoring and Diagnostics\norder: 40\n---\n```\n\n## Folder Metadata\n\nEach folder must have a `metadata.json` file with 2 keys:\n\n- **Title** (section title in the table of contents): Pulled from a\n  `metadata.json` file in the folder\n- **Order** (order in which a section appears in the table of contents): Pulled\n  from a metadata.json file in the folder\n\n```json\n{\n  \"order\": 0,\n  \"title\": \"Introduction\"\n}\n```\n\nIf we want to sort pages in an alphabetical order, add `sortMethod` in that\nfolder's `metadata.json`.\n\nThe below example is for\n[/glossary](https://github.com/stellar/new-docs/blob/master/content/docs/glossary/metadata.json)\npage\n\n```json\n{\n  \"order\": 60,\n  \"title\": \"Glossary\",\n  \"sortMethod\": \"alphabetical\"\n}\n```\n\nFolders may be nested, which means that a final URL may be stitched together\nfrom multiple metadata files.\n\nCheck `/content` folder to see how its nested order is working\n\n```\ncontent/\n\u251c\u2500\u2500 api/\n\u2502    \u251c\u2500\u2500 metadata.json\n\u2502    \u2514\u2500\u2500 aggregations/\n\u2502        \u251c\u2500\u2500 metadata.json\n\u2502        \u251c\u2500\u2500 index.mdx\n\u2502        \u2514\u2500\u2500 fee-stats/\n\u2502          \u251c\u2500\u2500 index.mdx\n\u2502          \u251c\u2500\u2500 metadata.json\n\u2502          \u251c\u2500\u2500 object.mdx\n\u2502          \u2514\u2500\u2500 single.mdx\n\u2514\u2500\u2500 docs/\n    \u251c\u2500\u2500 metadata.json\n    \u251c\u2500\u2500 index.mdx\n    \u251c\u2500\u2500 web-assets/\n    \u2502    \u2514\u2500\u2500 img.png\n    \u2514\u2500\u2500 building-apps/\n      \u251c\u2500\u2500 basic-wallet.mdx\n      \u251c\u2500\u2500 custom-assets.mdx\n      \u251c\u2500\u2500 index.mdx\n      \u251c\u2500\u2500 metadata.json\n      \u2514\u2500\u2500 connect-to-anchors/\n        \u251c\u2500\u2500 deposit-anchored-assets.mdx\n        \u251c\u2500\u2500 index.mdx\n        \u251c\u2500\u2500 setup-for-anchored-assets.mdx\n        \u2514\u2500\u2500 metadata.json\n```\n\n# Markdown\n\n## Basic Components\n\n### Table\n\n<img src=\"./readme-imgs/table.png\" alt=\"Table\" width=\"600\"/>\n\n```\n| Field | Requirements | Description |\n| --- | --- | --- |\n| FEDERATION_SERVER | uses `https://` | The endpoint for clients to resolve stellar addresses for users on your domain via [SEP-2](https://github.com/stellar/stellar-protocol/tree/master/ecosystem/sep-0002.md) Federation Protocol |\n| AUTH_SERVER | uses `https://` | The endpoint used for [SEP-3](https://github.com/stellar/stellar-protocol/tree/master/ecosystem/sep-0003.md) Compliance Protocol |\n| TRANSFER_SERVER | uses `https://` | The server used for [SEP-6](https://github.com/stellar/stellar-protocol/tree/master/ecosystem/sep-0006.md) Anchor/Client interoperability |\n| KYC_SERVER | uses `https://` | The server used for [SEP-12](https://github.com/stellar/stellar-protocol/tree/master/ecosystem/sep-0012.md) Anchor/Client customer info transfer |\n| WEB_AUTH_ENDPOINT | uses `https://` | The endpoint used for [SEP-10 Web Authentication](https://github.com/stellar/stellar-protocol/tree/master/ecosystem/sep-0010.md) |\n| SIGNING_KEY | Stellar public key | The signing key is used for [SEP-3](https://github.com/stellar/stellar-protocol/tree/master/ecosystem/sep-0003.md) Compliance Protocol |\n| HORIZON_URL | url | Location of public-facing Horizon instance (if you offer one) |\n| ACCOUNTS | list of `G...` strings | A list of Stellar accounts that are controlled by this domain |\n| VERSION | string | The version of SEP-1 your `stellar.toml` adheres to. This helps parsers know which fields to expect. |\n| URI_REQUEST_SIGNING_KEY | Stellar public key | The signing key is used for [SEP-7](https://github.com/stellar/stellar-protocol/tree/master/ecosystem/sep-0007.md) delegated signing |\n```\n\n### Unordered List\n\n<img src=\"./readme-imgs/unordered-list.png\" alt=\"Unordered List\" width=\"400\"/>\n\n```\n- Unordered lists\n  - Unordered lists with nesting\n    - Unordered lists with second-level nesting\n    - Unordered lists with second-level nesting\n- Unordered lists #2\n  - Unordered lists with nesting #2\n- Unordered lists #3\n- Unordered lists #4\n  - Unordered lists with nesting #4\n  - Unordered lists with nesting #4\n```\n\n### Ordered List\n\n<img src=\"./readme-imgs/ordered-list.png\" alt=\"Ordered List\" width=\"500\"/>\n\n```\n1. [`Set Options`](../api/resources/operations/object/set-options.mdx) to set the flags on the issuing account to `0x1` to enable `AUTHORIZATION REQUIRED`. This is necessary because you cannot run the [`Allow Trust`](../api/resources/operations/object/allow-trust.mdx) operation without `AUTHORIZATION REQUIRED` being set on your issuing account.\n1. [`Allow Trust`](../api/resources/operations/object/allow-trust.mdx) on the existing user's account in order to authorize it. **Note:** You can actually place as many as `MAX OPERATIONS PER TRANSACTION - 2` (currently the [maximum is 100](concepts/transactions.md#list-of-operations)) `Allow Trust` operations for different accounts to minimize the number of transactions submitted to the network.\n1. [`Set Options`](../api/resources/operations/object/set-options.mdx) to set the flags on the issuing account to `0x0` to disable `AUTHORIZATION REQUIRED`.\n   1. If I had more points to make about `Set Options`, I'd start listing those here.\n   1. Another point\n      1. Nested point of Anoter point\n      1. Nested point of Anoter point\n      1. Nested point of Anoter point\n   1. Another point #2\n```\n\n### Images\n\nCurrently (April, 2020), only\n[Documentation](https://developers.stellar.org/docs/) uses images.\n\n1. Drop the images in the `content/docs/web-assets` folder\n2. Refer to the asset as `![image caption](web-assets/image-file-name.png)` in\n   the proper location in your file - make sure that `web-assets`' relative path\n   is correct\n3. Captions: Include alt text if you\u2019d like a caption:\n   `![This is the image caption](web-assets/image-file-name.png)` Leave the alt\n   text section blank if you do not want a caption:\n   `![](web-assets/image-file-name.png)`\n\n### Quote\n\n![Quote](./readme-imgs/quote.png)\n\n```\n> Here's a quote\n```\n\n### Paragraph and Headings\n\nBeyond defining title font sizes, line heights, and weights:\n\n- **H1** tags are reserved for the page\u2019s title and should not be used; that\n  said, if they are used, they will still show up on the front end as H1 tags\n- **H2** tags populate the ride-side page\n  [table of contents](https://developers.stellar.org/docs/anchoring-assets/enabling-deposit-and-withdrawal/setting-up-test-server/)\n  in Documentation\n\n## Custom Components\n\nCustom (React) components that are being used throughout Documentation and API\nReference.\n\n**Make sure that there is an empty line within the wrapper**\n\nFor example,\n\n```\n<Alert>\n<!-- EMPTY SPACE IS NEEDED BELOW FOR A COMPONENT TO RENDER PROPERLY -->\n\nNote: the testnet is reset every three months, so when building on it, make sure you have a plan to recreate necessary accounts and other data.  For more info, check out the [best practices for using the testnet](../glossary/testnet.mdx#best-practices-for-using-testnet).\n\n<!-- EMPTY SPACE IS NEEDED BELOW FOR A COMPONENT TO RENDER PROPERLY -->\n</Alert>\n```\n\n### AttributeTable\n\n<img src=\"./readme-imgs/attribute-table.png\" alt=\"AttributeTable Component\" width=\"500\"/>\n\n`<AttributeTable/>` explains each attribute or argument that is being used.\nNested table will turn into \"child attributes\" that are collapsed by default\n(See `prices_r` and its child attributes from the example above).\n\n- PropTypes\n  - `children` (required)\n\nFor example,\n[Api Reference > Resources > Operations > Object](https://developers.stellar.org/api/resources/operations/object/)\n\n```\nimport { AttributeTable } from \"components/AttributeTable\";\n\n<AttributeTable>\n\n- ATTRIBUTE\n  - DATA TYPE\n  - DESCRIPTION\n- amount\n  - string\n  - The amount of `selling_asset` that the account making this offer is willing to sell.\n- price\n  - string\n  - How many units of `selling_asset` it takes to get 1 unit of `buying_asset`. A number representing the decimal form of `price_r`.\n- price_r\n  - object\n  - A precise representation of the buy and sell price of the assets on offer.\n    - n\n      - number\n      - The numerator.\n    - d\n      - number\n      - The denominator.\n\n</AttributeTable>\n```\n\n#### Omitting Data Type\n\n`Data Type` is not required. If you want to skip it, simply add a text \"skip\" in\nit\n\n```\nimport { AttributeTable } from \"components/AttributeTable\";\n\n<AttributeTable>\n\n- TYPE\n  - skip\n  - OPERATION(S)\n- Account Created\n  - skip\n  - create_account\n- Account Removed\n  - skip\n  - merge_account\n\n  </AttributeTable>\n```\n\nExample: `<AttributeTable/>` without type specified on\n[API's Manage Data Object](https://developers.stellar.org/api/resources/operations/object/manage-data/).\n\n<img src=\"./readme-imgs/attributetable-with-type.png\" alt=\"AttributeTable with Type\" width=\"500\"/>\n\nExample: `<AttributeTable/>` with type specified on\n[API's Effect Types](https://developers.stellar.org/api/resources/effects/types/).\n\n<img src=\"./readme-imgs/attributetable-without-type.png\" alt=\"AttributeTable without Type\" width=\"500\"/>\n\n### Alert\n\n<img src=\"./readme-imgs/alert.png\" alt=\"Alert Component\" width=\"712\"/>\n\n`<Alert/>` is used to convey hints, warnings, and etc.\n\n- PropTypes\n  - `children` (required)\n\nFor example,\n[Setting Up Test Server](https://developers.stellar.org/docs/anchoring-assets/enabling-deposit-and-withdrawal/setting-up-test-server/)\n\n```\nimport { Alert } from \"components/Alert\";\n\n<Alert>\n\nNote: the testnet is reset every three months, so when building on it, make sure you have a plan to recreate necessary accounts and other data.  For more info, check out the [best practices for using the testnet](../glossary/testnet.mdx#best-practices-for-using-testnet).\n\n</Alert>\n```\n\n### CodeExample\n\n<img src=\"./readme-imgs/code-example.png\" alt=\"CodeExample Component\" width=\"389\"/>\n\n`<CodeExample/>` is a code snippet component. You can include snippets for more\nthan one language. See an example of including a snippet for `curl` and\n`JavaScript` below. It is using\n[Prism syntax highlighting library](https://prismjs.com/).\n\n- PropTypes\n  - `title` (optional)\n  - `children` (required)\n  - `href` (optional)\n\nFor example,\n[Setting Up Test Server](https://developers.stellar.org/docs/anchoring-assets/enabling-deposit-and-withdrawal/setting-up-test-server/)\nin Documentation and\n[Resources > Transaction > Retrieve a Transaction](https://developers.stellar.org/api/resources/transactions/single/)\nin API Reference.\n\n````\nimport { CodeExample } from \"components/CodeExample\";\n\n<CodeExample title=\"Example Request\">\n\n```curl\ncurl \"https://horizon.stellar.org/ledgers/27147222/transactions?limit=2\"\n```\n\n```js\nvar StellarSdk = require('stellar-sdk')\nvar server = new StellarSdk.Server('https://horizon.stellar.org')\n\nserver\n.transactions()\n.forLedger('27147222')\n.call()\n.then(function(resp) {\n  console.log(resp)\n})\n.catch(function(err) {\n  console.error(err)\n})\n```\n\n</CodeExample>\n````\n\nLanguages that are currently being used in Documentation and API Reference are\nbelow:\n\n```\n// https://github.com/stellar/new-docs/blob/master/src/components/CodeExample.js\n\nconst CODE_LANGS = {\n  bash: \"bash\",\n  cpp: \"C++\",\n  curl: \"cURL\",\n  go: \"Go\",\n  html: \"html\",\n  java: \"Java\",\n  js: \"JavaScript\",\n  json: \"json\",\n  python: \"Python\",\n  scss: \"SCSS\",\n  toml: \"TOML\",\n  ts: \"TypeScript\",\n  tsx: \"TSX\",\n  yaml: \"YAML\",\n};\n```\n\nIf you would like to add an additional language to this, visit\n[CodeExample.js](https://github.com/stellar/new-docs/blob/master/src/components/CodeExample.js)\nand add it to `CODE_LANGS`.\n\n### Endpoint\n\n<img src=\"./readme-imgs/endpoint.png\" alt=\"Endpoint Component\" width=\"500\"/>\n\n`<Endpoint/>` is currently used in API Reference.\n\n- PropTypes\n  - `children` (required)\n\nFor example,\n[Aggregations > Order Books > Retrieve an Order Book](https://developers.stellar.org/api/aggregations/order-books/single/).\n\n```\nimport { Endpoint } from \"components/Endpoint\";\n\n<Endpoint>\n\n|     |                              |\n| --- | ---------------------------- |\n| GET | /order_book?selling_asset_type={native,credit_alphanum4,credit_alphanum12}&selling_asset_issuer={:account_id}&selling_asset_code{:asset_code}&buying_asset_type={native,credit_alphanum4,credit_alphanum12}&buying_asset_issuer={:account_id}&buying_asset_code{:asset_code}&limit={1-200} |\n\n</Endpoint>\n```\n\n### EndpointsTable\n\n<img src=\"./readme-imgs/endpointstable.png\" alt=\"EndpointsTable Component\" width=\"389\"/>\n\n`<EndpointsTable/>` displays an endpoint and its\n[HTTP method](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Request_methods).\n\n- PropTypes\n  - `title` (required)\n  - `children` (required)\n\nFor example,\n[Resources > Transactions](https://developers.stellar.org/api/resources/transactions/).\n\n```\nimport { EndpointsTable } from \"components/EndpointsTable\";\n\n<EndpointsTable title=\"Endpoints\">\n\n|     |                                                               |\n| --- | ------------------------------------------------------------- |\n| GET | [/transactions/:transaction_id](./single.mdx)                 |\n| GET | [/transactions/:transaction_id/operations](./operations.mdx)  |\n| GET | [/transactions/:transaction_id/effects](./effects.mdx)        |\n| GET | [/transactions](./list.mdx)                                   |\n| POST | [/transactions](./post.mdx)                                  |\n\n</EndpointsTable>\n```\n\n### Example (JSON) Response\n\n<img src=\"./readme-imgs/exampleresponse.png\" alt=\"ExampleResponse Component\" width=\"389\"/>\n\n`<ExampleResponse/>` is **only** used in API Reference for JSON response. In\nDocumentation, we use `<CodeExample/>` for JSON response.\n\n- PropTypes\n  - `title` (optional)\n  - `children` (required)\n\nFor example,\n[Introduction > XDR](https://developers.stellar.org/api/introduction/xdr/).\n\n````\nimport { ExampleResponse } from \"components/ExampleResponse\";\n\n<ExampleResponse title=\"Example Transaction Response with XDR\">\n\n```json\n{\n  // Response truncated to highlight XDR-related attributes\n  \"envelope_xdr\": \"AAAAAPewD+/6X8o0bx3bp49Wf+mUhG3o+TUrcjcst717DWJVAAAAyAFvzscADTkNAAAAAAAAAAAAAAACAAAAAAAAAAYAAAACWE1BVEsAAAAAAAAAAAAAAAPvNOuztX4IjvV8pztsEc1/ZnTz0G3p5Cx4vcf04+xUAAONfqTGgAAAAAAAAAAABQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAAAD2NyeXB0b21hcmluZS5ldQAAAAAAAAAAAAAAAAF7DWJVAAAAQK3vfUCZ8mbjW3ssMd0n1tJTF9Fv6EbuJ6cWKkYXBqG5itqanPbFzIQoZEHbPS8nr2vo4dROvKI0uQzNcfExKwM=\",\n  \"result_xdr\": \"AAAAAAAAAMgAAAAAAAAAAgAAAAAAAAAGAAAAAAAAAAAAAAAFAAAAAAAAAAA=\",\n  \"result_meta_xdr\": \"AAAAAQAAAAIAAAADAZU3mQAAAAAAAAAA97AP7/pfyjRvHdunj1Z/6ZSEbej5NStyNyy3vXsNYlUAAAAABlxskAFvzscADTkMAAAAAgAAAAAAAAAAAAAAD2NyeXB0b21hcmluZS5ldQABAAAAAAAAAAAAAAAAAAAAAAAAAQGVN5kAAAAAAAAAAPewD+/6X8o0bx3bp49Wf+mUhG3o+TUrcjcst717DWJVAAAAAAZcbJABb87HAA05DQAAAAIAAAAAAAAAAAAAAA9jcnlwdG9tYXJpbmUuZXUAAQAAAAAAAAAAAAAAAAAAAAAAAAIAAAACAAAAAwGVN5gAAAABAAAAAPewD+/6X8o0bx3bp49Wf+mUhG3o+TUrcjcst717DWJVAAAAAlhNQVRLAAAAAAAAAAAAAAAD7zTrs7V+CI71fKc7bBHNf2Z089Bt6eQseL3H9OPsVAAATfBgJfPoAAONfqTGgAAAAAABAAAAAAAAAAAAAAABAZU3mQAAAAEAAAAA97AP7/pfyjRvHdunj1Z/6ZSEbej5NStyNyy3vXsNYlUAAAACWE1BVEsAAAAAAAAAAAAAAAPvNOuztX4IjvV8pztsEc1/ZnTz0G3p5Cx4vcf04+xUAABN8GAl8+gAA41+pMaAAAAAAAEAAAAAAAAAAAAAAAIAAAADAZU3mQAAAAAAAAAA97AP7/pfyjRvHdunj1Z/6ZSEbej5NStyNyy3vXsNYlUAAAAABlxskAFvzscADTkNAAAAAgAAAAAAAAAAAAAAD2NyeXB0b21hcmluZS5ldQABAAAAAAAAAAAAAAAAAAAAAAAAAQGVN5kAAAAAAAAAAPewD+/6X8o0bx3bp49Wf+mUhG3o+TUrcjcst717DWJVAAAAAAZcbJABb87HAA05DQAAAAIAAAAAAAAAAAAAAA9jcnlwdG9tYXJpbmUuZXUAAQAAAAAAAAAAAAAAAAAAAA==\",\n  \"fee_meta_xdr\": \"AAAAAgAAAAMBlTeXAAAAAAAAAAD3sA/v+l/KNG8d26ePVn/plIRt6Pk1K3I3LLe9ew1iVQAAAAAGXG1YAW/OxwANOQwAAAACAAAAAAAAAAAAAAAPY3J5cHRvbWFyaW5lLmV1AAEAAAAAAAAAAAAAAAAAAAAAAAABAZU3mQAAAAAAAAAA97AP7/pfyjRvHdunj1Z/6ZSEbej5NStyNyy3vXsNYlUAAAAABlxskAFvzscADTkMAAAAAgAAAAAAAAAAAAAAD2NyeXB0b21hcmluZS5ldQABAAAAAAAAAAAAAAAAAAAA\"\n  // Response truncated to highlight XDR-related attributes\n}\n```\n\n</ExampleResponse>\n````\n\n### MethodTable\n\n<img src=\"./readme-imgs/MethodTable.png\" alt=\"MethodTable Component\" width=\"389\"/>\n\n`<MethodTable/>` is used to display navigation sections and its description.\n\n- PropTypes\n  - `title` (required)\n  - `children` (required)\n\nFor example, [Introduction](https://developers.stellar.org/api/introduction/).\n\n```\nimport { MethodTable } from \"components/MethodTable\";\n\n<MethodTable title=\"API Reference Sections\">\n\n|  |  |\n| --- | --- |\n| [Introduction](../introduction/index.mdx) | How Horizon is structured. |\n| [Resources](../resources/index.mdx) | Descriptions of resources and their endpoints. |\n| [Aggregations](../aggregations/index.mdx) | Descriptions of specialized endpoints. |\n| [Errors](../errors/index.mdx) | Potential errors and what they mean. |\n\n</MethodTable>\n```\n\n### Diagrams (Mermaid)\n\n<img src=\"./readme-imgs/mermaid.png\" alt=\"Diagrams\" width=\"600\"/>\n\nWe're using [Mermaid](https://mermaidjs.github.io/#/) for diagrams.\n\n````\n```mermaid\nsequenceDiagram\n      participant W as Wallet\n      participant A as Anchor\n      participant S as Stellar\n      W->>A: [SEP6] /withdraw/params\n      A->>W: [SEP6] 403 - /kyc(...)\n      W->>A: [SEP10] GET /web_auth\n      A->>W: [SEP10] Challenge\n      W->>A: [SEP10] POST /web_auth\n      A->>W: [SEP10] JWT\n      W->>A: [SEP12] PUT /customer\n      Note over A: KYC Checks\n      A->>W: [SEP12] 200\n      W->>A: [SEP6] /withdraw/params\n      A->>W: [SEP6] 200\n      W->>S: [SEP10] POST /transaction\n      S->>W: [SEP10] 200\n      S->>A: [SEP10] TX120, memo\n      Note over A: Deposit\n```\n````\n\n### Performance metrics\n\nWe have support for simple, anonymous metrics, emitted to Amplitude via\n`helpers/metrics.js`.\n\nWe also have a simple performance tracking system, `helpers/performance.js`.\n`mark(string)` will begin measuring, and `measure(string)` will stop measuring\nand return timing information\u2014an object with a `duration` and\n`hasHighPrecision`. Some browsers don't expose the high-precision APIs, and we\ndefinitely want to know if they're used (especially if not usable). Make sure to\nuse a `constants/performanceMarks` constant, not just a raw string.\n\n### Testing requests as a crawler\n\nChrome allows you to\n[override the user agent](https://developers.google.com/web/tools/chrome-devtools/device-mode/override-user-agent)\nwith DevTools, which enables us to test how Google will see pages.\n", "release_dates": []}, {"name": "os-projects", "description": null, "language": null, "license": null, "readme": "# DEPRECATION NOTICE: We're no longer keeping this repository up to date.\nOver time we've realized that the os-projects repo is not the best way to highlight the projects in\nour ecosystem. Notably it's mostly hidden from the rest of the world, we're not differentiating\nwhich projects are actively supported and which ones need some love, and really showing these off\nwith the rest of Stellar's developer resources.\n\nOur goal is to turn a lot of these projects (after an audit) into a gallery on our website in early\n2019. For now, this is an existing repository of OSS projects for Stellar.\n\n## Stellar's Open Sourced Community Projects\n\n\u2b50 Welcome to the list of open sourced community projects! \u2b50\n\nProjects have been divided into nine unique categories:\n1. [Applications](Applications.md)\n2. [Trading](Trading.md)\n3. [Forums](Forums.md)\n4. [Ledger Explorers](LedgerExplorers.md)\n5. [Quorum Explorers](QuorumExplorers.md)\n6. [Libraries/APIs/Frameworks/Plug-ins](LibraryAPIsAndMore.md)\n7. [Remittance Applications](Remittance.md)\n8. [Tutorials and Documentation](TutorialsAndDocs.md)\n9. [Wallets](Wallets.md)\n\nProjects are listed in each category in no particular order.\n\n> Disclaimer: Stellar.org does not own, maintain or operate any of these projects. All projects listed in this repo are maintained by the Stellar Community.\n\n### \ud83d\ude80 How to get your project listed\nTo have your project listed in this collection please submit a PR of an edit of the appropriate category file. The edit should follow this format:\n\n    ### [Project name](link to live project if applicable) - [source](link to repository)\n    Description\n    &nbsp;\n\nDescriptions should be 40 words or less, and should be followed by two trailing spaces. Use the following format in your description / project name to prevent GitHub's autolinking feature:\n\n    link<span>.project\n\n### \ud83d\ude80 How to get your project unlisted\nTo have your project removed from the listing, please submit a PR of an edit, removing your project.\n", "release_dates": []}, {"name": "packages", "description": "SDF - Packages", "language": "Shell", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# SDF - packages\n\n## Package based installation\n\nIf you are using Ubuntu 16.04 LTS we provide the latest stable releases of [stellar-core](https://github.com/stellar/stellar-core) and [stellar-horizon](https://github.com/stellar/go/tree/master/services/horizon) in Debian binary package format.\n\nYou may choose to install these packages individually, this offers the greatest flexibility but will require **manual** creation of the relevant configuration files and the configuration of a **PostgreSQL** database.\n\nAlternatively you may choose to install the **stellar-quickstart** package which configures a **Testnet** `stellar-core` and `stellar-horizon` both backed by a local PostgreSQL database.\n\n#\n1.  [Adding the SDF stable repository to your system](docs/adding-the-sdf-stable-repository-to-your-system.md)\n2.  [Quickstart](docs/quickstart.md)\n3.  [Installing individual packages](docs/installing-individual-packages.md)\n4.  [Upgrading](docs/upgrading.md)\n5.  [Running Horizon in production](docs/running-horizon-in-production.md)\n6.  [Building Packages](docs/building-packages.md)\n7.  [Running a Full Validator](docs/running-a-full-validator.md)\n8.  [Publishing a History archive](docs/publishing-a-history-archive.md)\n9.  [Backfilling a History archive](docs/backfilling-a-history-archive.md)\n10. [Monitoring](docs/monitoring.md)\n11. [Testnet Reset](docs/testnet-reset.md)\n", "release_dates": []}, {"name": "paper-wallet", "description": null, "language": "HTML", "license": null, "readme": "Deprecated. More info: [https://stellar.github.io/paper-wallet/](https://stellar.github.io/paper-wallet/).\n", "release_dates": []}, {"name": "product-conventions", "description": "A layout of all conventions to be used by all Stellar frontend products", "language": "JavaScript", "license": null, "readme": "# Stellar Frontend Product Conventions\n\nThis is a repo of all conventions that the product team will use to build\nStellar's user interfaces.\n\n# Contents\n\n- [Goals](#goals)\n- [Scope](#scope)\n- [Ethos](#ethos)\n- [Tools](#tools)\n- [Process](#process)\n- [Code style](code-style)\n\n# Goals\n\n- Start with sane defaults\n- Learn once, write anywhere\n- Avoid bikeshedding\n- Spend less time and energy bootstrapping projects\n- Have an upgrade path for legacy projects\n\n# Scope\n\nAll frontend products created from now (May 3, 2019) should follow these\nconventions, unless there's a good reason not to. Every exception makes the\nrules harder to follow, so please avoid making them.\n\n# Ethos\n\n## Above all, write code for others to read\n\n- Prefer straightforward code that explains itself over clever code.\n- Be deliberate about variable, function, and component names.\n- Pick straightforward inputs and outputs for functions and components. They\n  should line up with the name.\n- If something will be used more than once, write unit tests and/or a story.\n\n## Don't ask for permission\n\n- Mistakes are okay. Iterating is good.\n- State your plans out loud.\n- For anything longer than a couple sentences, write a spec.\n- You don't need permission to merge, you have the privilege and responsibility\n  to merge.\n\n## Use the tools as much as possible\n\n- Prefer declarative over imperative.\n- Use React lifecycle methods sparingly, but prefer it over doing things outside\n  of React.\n- Don't be afraid to use Redux, especially if have a lot of pass-through params.\n- Try really, really, really hard to use an existing helper func, constant,\n  basic, component, or feature.\n  - Consider refactoring or abstracting (and adding any needed tests or other\n    supporting code) if there's something close, but not quite what you need\n\n# Process\n\nThis is intended as a baseline, a starting point that projects will evolve to\nsuit their needs\n\n- Pick the top card off the sprint backlog that you can do that's not assigned\n- Using checklists/subtasks, break the task down into half-day chunks\n- Ideally, after each chunk, the site will build and work; but don't agonize\n  over this\n- For each chunk:\n  - make a shared branch named `<initials>-taskname`, i.e. `mz-marketsrewrite`\n  - Do the thing\n  - If you start doing the thing and find unexpected complexity:\n    - Step back and come up with a plan\n    - Post your plan in the most relevant slack channel\n  - Make a PR for your change and post a link in `#product-frontend`\n    - See [writing a PR](#writing-a-pr)\n  - Address any feedback\n  - Merge it into master once all checks pass, and you're comfortable with it\n\n## Writing a task\n\nWhether an Asana task, GitHub issue, Trello card, or something else, a task\nshould have enough information that anyone reading it can understand what needs\nto happen. Spend a little extra time on them to add information. It won't be\nperfect, it should have information that anyone coming across it blind can\ngather more details on their own, without having to ask what a ticket is about.\n\n## Writing a PR\n\nReviewing code without context is difficult, so add as much context as you can\nwithout it being a burden, but avoid referencing private materials in\nopen-source PRs. Summarize the problem, describe the intent of the solution, and\npoint out any particularly interesting parts of the code. Try adding screenshots\n(even annotated!) or screen recordings if the issue is difficult to communicate\nwith words.\n\nPR titles are used as commit mesages, so make them concise and descriptive.\nThey're trimmed to 70 characters when displayed in GitHub.\n\n# Code style\n\nRead [our styleguide](./STYLEGUIDE.md) for more information.\n\n# Plans\n\nA plan is (1) a problem you're facing with (2) one or more approaches that solve\nthat problem. Thinking through and announcing your plan out loud is a better way\nof solving problems than diving in immediately:\n\n- You approach a problem _with intention_ instead of _blindly_\n- Posting your plan in a Slack channel informs others what you're doing and how\n  you're doing it\n- People have the opportunity to correct misconceptions, suggest alternatives,\n  or otherwise improve your plan before you've spent time implementing them\n\nThe effort to make a plan should be proportional to the effort to execute the\nplan.\n\n- If it takes longer to write a plan than execute it, Just Do It\n- If the project takes an hour or less, write a sentence or two\n- If the project is a couple days or more, consider writing it in a markdown\n  file\n\nMake sure you think hard about what your \\_actual problem is. Let's say your\ntask is to \"build a function that takes a number and outputs that number's\nLebowski coefficient.\" So you write a plan:\n\n```\nI'm working on the Lebowski coefficient, and my plan is to figure out what a\nLebowski coefficient is.\n```\n\nThat's not a very specific plan: it doesn't give you actionable steps to take,\nand it's not substantive enough for someone else to comment on.\n\nOne of the reasons is because it misattributes the problem at hand. It's not\nthat you find Lebowski coefficient; the problem is _you don't know what a\nLebowski coefficient is._\n\nThis is a much better plan:\n\n```\nI'm working on the Lebowski coefficient and I don't know what a\nLebowski coefficient is, so I'm going to Google around for definitions.\n```\n\nThat's a concrete plan! And maybe it's one for someone else to point out an NPM\nrepo that calculates them automatically, or that a blog has covered the topic\nsuccinctly, or that our project cut Lebowski coefficients last week.\n\nPlans about exploratory problems are some of the most useful to think out loud\nabout, because they have more ways to attack them, which generates better\ndiscussion than problems with obvious solutions.\n", "release_dates": []}, {"name": "project-viewer", "description": "Navigating projects on Stellar", "language": "Go", "license": null, "readme": "# project-viewer\n", "release_dates": []}, {"name": "quickstart", "description": "Home of the stellar/quickstart docker image for development and testing", "language": "Shell", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Stellar Quickstart Docker Image\n\nThis docker image provides a simple way to run stellar-core and horizon locally for development and testing.\n\n**Looking for instructions for how to run stellar-core or horizon in production? Take a look at the docs [here](https://developers.stellar.org/docs/run-core-node/).**\n\nThis image provides a default, non-validating, ephemeral configuration that should work for most developers.  By configuring a container using this image with a host-based volume (described below in the \"Usage\" section) an operator gains access to full configuration customization and persistence of data.\n\nThe image uses the following software:\n\n- Postgresql 12 is used for storing both stellar-core and horizon data\n- [stellar-core](https://github.com/stellar/stellar-core)\n- [horizon](https://github.com/stellar/go/tree/master/services/horizon)\n- [friendbot](https://github.com/stellar/go/tree/master/services/friendbot)\n- [soroban-rpc](https://github.com/stellar/soroban-tools/tree/main/cmd/soroban-rpc)\n- Supervisord is used from managing the processes of the services above\n\n## Usage\n\nTo use this project successfully, you should first decide a few things:\n\nFirst, decide whether you want your container to be part of the public, production Stellar network (referred to as the _pubnet_) or the test network (called testnet) that we recommend you use while developing software because you need not worry about losing money on the testnet. Alternatively, choose to run a local network (called local) which allows you to run your own acellerated private Stellar network for testing.\n\nNext, you must decide whether you will use a docker volume or not.  When not using a volume, we say that the container is in _ephemeral mode_, that is, nothing will be persisted between runs of the container. _Persistent mode_ is the alternative, which should be used in the case that you need to either customize your configuration (such as to add a validation seed) or would like avoid a slow catchup to the Stellar network in the case of a crash or server restart.  We recommend persistent mode for anything besides a development or test environment.\n\nFinally, you must decide what ports to expose.  The software in these images listen on 4 ports, each of which you may or may not want to expose to the network your host system is connected to.  A container that exposes no ports isn't very useful, so we recommend at a minimum you expose the horizon http port.  See the \"Ports\" section below for a more nuanced discussion regarding the decision about what ports to expose.\n\nAfter deciding on the questions above, you can setup your container.  Please refer to the appropriate section below based upon what mode you will run the container in.\n\n### Network Options\n\nProvide either `--pubnet`, `--testnet` or `--local` as a command line flag when starting the container to determine which network (and base configuration file) to use.\n\n#### `--pubnet`\n\nIn public network mode, the node will join the public, production Stellar network.\n\n_Note: In pubnet mode the node will consume more disk, memory, and CPU resources because of the size of the ledger and frequency of transactions. If disk space warnings occur and the image is being used on a Docker runtime that uses a VM, like that of macOS and Windows, the VM may need to have its disk space allocation increased._\n\n#### `--testnet`\n\nIn test network mode, the node will join the network that developers use while developing software. Use the [Stellar Laboratory](https://laboratory.stellar.org/#account-creator?network=test) to create an account on the test network.\n\n#### `--futurenet`\n\nIn futurenet network mode, the node will join the [Soroban] test network that developers use while developing smart contracts on Stellar.\n\n[Soroban]: https://soroban.stellar.org\n\n#### `--local`\n\nIn local network mode, you can optionally pass:\n\n- `--protocol-version {version}` to run a specific protocol version (defaults to latest version).\n\n- `--limits {limits}` to configure specific Soroban resource limits to one of:\n   - `default` leaves limits set extremely low which is stellar-core's default configuration\n   - `testnet` sets limits to match those used on testnet (the default quickstart configuration)\n   - `unlimited` sets limits to the maximum resources that can be configured\n\nThe network passphrase of the network defaults to:\n```\nStandalone Network ; February 2017\n```\n\nSet the network passphrase in the SDK or tool you're using. If an incorrect network passphrase is used in clients signing transactions, the transactions will fail with a bad authentication error.\n\nThe root account of the network is fixed to:\n```\nPublic Key: GBZXN7PIRZGNMHGA7MUUUF4GWPY5AYPV6LY4UV2GL6VJGIQRXFDNMADI\nSecret Key: SC5O7VZUXDJ6JBDSZ74DSERXL7W3Y5LTOAMRF7RQRL3TAGAPS7LUVG3L\n```\n\nThe root account is derived from the network passphrase and if the network passphrase is changed the root account will change. To find out the root account when changing the network passphrase view the logs for stellar-core on its first start. See [Viewing logs](#viewing-logs) for more details.\n\nIn local network mode a ledger occurs every one second and so transactions\nare finalized faster than on deployed networks.\n\n*Note*: The local network in this container is not suitable for any production use as it has a fixed root account. Any private network intended for production use would also required a unique network passphrase.\n\n### Service Options\n\nThe image runs all services available by default, but can be configured to run only certain services as needed. The option for configuring which services run is the `--enable` option.\n\nThe option takes a comma-separated list of service names to enable. To enable all services which is the default behavior, use:\n\n```\n--enable core,horizon,rpc\n```\n\nTo run only select services, simply specify only those services. For example, to enable the RPC, use:\n\n```\n--enable rpc\n```\n\n__Note: All services, and in addition friendbot, always run on a local network.__\n\n### Faucet (Friendbot)\n\nStellar development/test networks use friendbot as a faucet for the native asset.\n\nWhen running in local, testnet, and futurenet modes friendbot is available on `:8000/friendbot` and can be used to fund a new account.\n\nFor example:\n```\n$ curl http://localhost:8000/friendbot?addr=G...\n```\n\n_Note: In local mode a local friendbot is running. In testnet and futurenet modes requests to the local `:8000/friendbot` endpoint will be proxied to the friendbot deployments for the respective network._\n\n### Soroban Development\n\nThe RPC Server will be avaialble on port 8000 of the container, and the base URL path for Soroban RPC will be `http://<container_host>:8000/soroban/rpc`. This endpoint uses [JSON-RPC](https://www.jsonrpc.org/specification) protocol. Refer to example usages in [soroban-example-dapp](https://github.com/stellar/soroban-example-dapp).\n\nTo enable soroban rpc admin endpoint for access to metrics and [Go pprof (profiling)](https://pkg.go.dev/net/http/pprof), include the `--enable-soroban-rpc-admin-endpoint` flag, the HTTP endpoint will be listening on container port 6061, which can be exposed with standard docker port rule `-p \"6061:6061\"`, the published endpoints are:\n```\nhttp://<container_host>:6061/metrics\nhttp://<container_host>:6061/debug/pprof/\n```\n\n### Soroban Diagnostic Events\n\nSoroban diagnostic events contain logs about internal events that have occurred while a contract is executing. They're particularly useful for debugging why a contract trapped (panicked).\n\nTo enable Soroban diagnostic events provide the following command line flag when starting the container:\n`--enable-soroban-diagnostic-events`\n\nIn local network mode diagnostics are enabled by default and can be disabled with:\n`--disable-soroban-diagnostic-events`\n\n_Note: Diagnostic events are unmetered and their execution is not metered or contrained by network limits or transaction resource limits. This means the resources consumed by an instance with diagnostic events enabled may exceed resources typically required by a deployment with diagnostic events disabled._\n\n### Deploy to Digital Ocean\n\nYou can deploy the quickstart image to DigitalOcean by clicking the button below. It will by default create a container that can be used for development and testing, running the `latest` tag, in ephemeral mode, and on the `local` network.\n\n[![Deploy to DO](https://www.deploytodo.com/do-btn-blue.svg)](https://cloud.digitalocean.com/apps/new?repo=https://github.com/stellar/quickstart/tree/master)\n\nAfter clicking the button above, the deployment can be configured to deploy a different variant of the image, or join a different network such as `testnet` or `futurenet` by changing environment variables.\n\nSome example configurations that can be used are:\n- Local network matching pubnet:\n  `IMAGE`: `stellar/quickstart:latest`\n  `NETWORK`: `local`\n- Local network matching testnet:\n  `IMAGE`: `stellar/quickstart:testing`\n  `NETWORK`: `local`\n- Testnet node:\n  `IMAGE`: `stellar/quickstart:testnet`\n  `NETWORK`: `testnet`\n\n*Disclaimer*: The DigitalOcean server is publicly accessible on the Internet. Do not put sensitive information on the network that you would not want someone else to know. Anyone with access to the network will be able to use the root account above.\n\n### Building Custom Images\n\nTo build a quickstart image with custom or specific versions of stellar-core,\nhorizon, etc, use the `Makefile`. The following parameters can be specified to\ncustomize the version of each component, and for stellar-core the features it is\nbuilt with.\n\n- `TAG`: The docker tag to assign to the build. Default `dev`.\n- `CORE_REF`: The git reference of stellar-core to build.\n- `CORE_CONFIGURE_FLAGS`: The `CONFIGURE_FLAGS` to configure the stellar-core\nbuild with. Typically include `--disable-tests`, and to enable the next protocol\nversion that is still in development, add\n`--enable-next-protocol-version-unsafe-for-production`.\n- `CORE_SUPPORTS_ENABLE_SOROBAN_DIAGNOSTIC_EVENTS`: Flag for whether enabling Soroban diagnostic events is supported. Default `false`.\n- `HORIZON_REF`: The git reference of stellar-horizon to build.\n- `FRIENDBOT_REF`: The git reference of stellar-friendbot to build.\n- `SOROBAN_RPC_REF`: The git reference of soroban-rpc to build.\n\nFor example:\n```\nmake build \\\n  TAG=future \\\n  CORE_REF=... \\\n  CORE_CONFIGURE_FLAGS=... \\\n  HORIZON_REF=... \\\n  FRIENDBOT_REF=... \\\n  SOROBAN_RPC_REF=...\n```\n\n### Background vs. Interactive containers\n\nDocker containers can be run interactively (using the `-it` flags) or in a detached, background state (using the `-d` flag).  Many of the example commands below use the `-it` flags to aid in debugging but in many cases you will simply want to run a node in the background.  It's recommended that you use the use [the tutorials at docker](https://docs.docker.com/engine/tutorials/usingdocker/) to familiarize yourself with using docker.\n\n### Ephemeral mode\n\nEphermeral mode is provided to support development and testing environments.  Every time you start a container in ephemeral mode, the database starts empty and a default configuration file will be used for the appropriate network.\n\nStarting an ephemeral node is simple, just craft a `docker run` command to launch the appropriate image but *do not mount a volume*.  To craft your docker command, you need the network name you intend to run against and the flags to expose the ports your want available (See the section named \"Ports\" below to learn about exposing ports).  Thus, launching a testnet node while exposing horizon would be:\n\n```shell\n$ docker run --rm -it -p \"8000:8000\" --name stellar stellar/quickstart --testnet\n```\n\nAs part of launching, an ephemeral mode container will generate a random password for securing the postgresql service and will output it to standard out.  You may use this password (provided you have exposed the postgresql port) to access the running postgresql database (See the section \"Accessing Databases\" below).\n\n\n### Persistent mode\n\nIn comparison to ephemeral mode, persistent mode is more complicated to operate, but also more powerful.  Persistent mode uses a mounted host volume, a directory on the host machine that is exposed to the running docker container, to store all database data as well as the configuration files used for running services. This allows you to manage and modify these files from the host system.\n\nNote that there is no guarantee that the organization of the files of the volume will remain consistent between releases of the image, that occur on every commit to the stellar/quickstart repository. At anytime new files may be added, old files removed, or dependencies and references between them changed. For this reason persistent mode is primarily intended for running short lived test instances for development. If consistency is required over any period of time use [image digest references] to pin to a specific build.\n\n[image digest references]: https://docs.docker.com/engine/reference/run/#imagedigest\n\nStarting a persistent mode container is the same as the ephemeral mode with one exception:\n\n```shell\n$ docker run --rm -it -p \"8000:8000\" -v \"/home/scott/stellar:/opt/stellar\" --name stellar stellar/quickstart --testnet\n```\n\nThe `-v` option in the example above tells docker to mount the host directory `/home/scott/stellar` into the container at the `/opt/stellar` path.  You may customize the host directory to any location you like, simply make sure to use the same value every time you launch the container.  Also note: an absolute directory path is required.  The second portion of the volume mount (`/opt/stellar`) should never be changed.  This special directory is checked by the container to see if it is mounted from the host system which is used to see if we should launch in ephemeral or persistent mode.\n\nUpon launching a persistent mode container for the first time, the launch script will notice that the mounted volume is empty.  This will trigger an interactive initialization process to populate the initial configuration for the container.  This interactive initialization adds some complications to the setup process because in most cases you won't want to run the container interactively during normal operation, but rather in the background.  We recommend the following steps to setup a persistent mode node:\n\n1.  Run an interactive session of the container at first, ensuring that all services start and run correctly.\n2.  Shut down the interactive container (using Ctrl-C).\n3.  Start a new container using the same host directory in the background.\n\n## Regarding user accounts\n\nManaging UIDs between a docker container and a host volume can be complicated.  At present, this image simply tries to create a UID that does not conflict with the host system by using a preset UID:  10011001.  Currently there is no way to customize this value.  All data produced in the host volume be owned by 10011001.  If this UID value is inappropriate for your infrastructure we recommend you fork this project and do a find/replace operation to change UIDs.  We may improve this story in the future if enough users request it.\n\n## Ports\n\nThe image exposes one main port through which services provide their APIs:\n\n| Port  | Service                         | Description          |\n|-------|---------------------------------|----------------------|\n| 8000  | horizon, soroban-rpc, friendbot | main http port       |\n\nThe image also exposes a few other ports that most developers do not need, but area available:\n\n| Port  | Service                         | Description          |\n|-------|---------------------------------|----------------------|\n| 5432  | postgresql                      | database access port |\n| 6060  | horizon                         | admin port           |\n| 6061  | soroban-rpc                     | admin port           |\n| 11625 | stellar-core                    | peer node port       |\n| 11626 | stellar-core                    | main http port       |\n| 11725 | stellar-core (horizon)          | peer node port       |\n| 11726 | stellar-core (horizon)          | main http port       |\n| 11825 | stellar-core (soroban-rpc)      | peer node port       |\n| 11826 | stellar-core (soroban-rpc)      | main http port       |\n\n### Security Considerations\n\nExposing the network ports used by your running container comes with potential risks.  While many attacks are preventable due to the nature of the stellar network, it is extremely important that you maintain protected access to the postgresql server that runs within a quickstart container.  An attacker who gains write access to this DB will be able to corrupt your view of the stellar network, potentially inserting fake transactions, accounts, etc.\n\nIt is safe to open the horizon http port.  Horizon is designed to listen on an internet-facing interface and provides no privileged operations on the port. At the same time admin port should only be exposed to a trusted network, as it provides no security itself.\n\nThe HTTP port for stellar-core should only be exposed to a trusted network, as it provides no security itself.  An attacker that can make requests to the port will be able to perform administrative commands such as forcing a catchup or changing the logging level and more, many of which could be used to disrupt operations or deny service.\n\nThe peer port for stellar-core however can be exposed, and ideally would be routable from the internet.  This would allow external peers to initiate connections to your node, improving connectivity of the overlay network.  However, this is not required as your container will also establish outgoing connections to peers.\n\n## Accessing and debugging a running container\n\nThere will come a time when you want to inspect the running container, either to debug one of the services, to review logs, or perhaps some other administrative tasks.  We do this by starting a new interactive shell inside the running container:\n\n```\n$ docker exec -it stellar /bin/bash\n```\n\nThe command above assumes that you launched your container with the name `stellar`; Replace that name with whatever you chose if different.  When run, it will open an interactive shell running as root within the container.\n\n### Restarting services\n\nServices within the quickstart container are managed using [supervisord](http://supervisord.org/index.html) and we recommend you use supervisor's shell to interact with running services.  To launch the supervisor shell, open an interactive shell to the container and then run `supervisorctl`.  You should then see a command prompt that looks like:\n\n```shell\nhorizon                          RUNNING    pid 143, uptime 0:01:12\npostgresql                       RUNNING    pid 126, uptime 0:01:13\nstellar-core                     RUNNING    pid 125, uptime 0:01:13\nsupervisor>\n```\n\nFrom this prompt you can execute any of the supervisord commands:\n\n```shell\n# restart horizon\nsupervisor> restart horizon\n\n\n# stop stellar-core\nsupervisor> stop stellar-core\n```\n\nYou can learn more about what commands are available by using the `help` command.\n\n### Viewing logs\n\nLogs can be found within the container at the path `/var/log/supervisor/`.  A file is kept for both the stdout and stderr of the processes managed by supervisord.  Additionally, you can use the `tail` command provided by supervisorctl.\n\nAlternatively, to tail all logs into the container's output for all services, append the `--logs` option.\n\n### Accessing databases\n\nThe point of this project is to make running stellar's software within your own infrastructure easier, so that your software can more easily integrate with the stellar network.  In many cases, you can integrate with horizon's REST API, but often times you'll want direct access to the database either horizon or stellar-core provide.  This allows you to craft your own custom sql queries against the stellar network data.\n\nThis image manages two postgres databases:  `core` for stellar-core's data and `horizon` for horizon's data.  The username to use when connecting with your postgresql client or library is `stellar`. The password to use is dependent upon the mode your container is running in:  Persistent mode uses a password supplied by you and ephemeral mode generates a password and prints it to the console upon container startup.\n\n\n## Example launch commands\n\nBelow is a list of various ways you might want to launch the quickstart container annotated to illustrate what options are enabled.  It's also recommended that you should learn and get familiar with the docker command.\n\n*Launch an ephemeral local only dev/test network:*\n```\n$ docker run -d -p \"8000:8000\" --name stellar stellar/quickstart --local\n```\n\n*Launch an ephemeral testnet node in the foreground:*\n```\n$ docker run --rm -it \\\n    -p \"8000:8000\" \\\n    --name stellar \\\n    stellar/quickstart --testnet\n```\n\n*Setup a new persistent node using the host directory `/str`:*\n```\n$ docker run -it --rm \\\n    -p \"8000:8000\" \\\n    -v \"/str:/opt/stellar\" \\\n    --name stellar \\\n    stellar/quickstart --testnet\n```\n\n## Troubleshooting\n\nLet us know what you're having trouble with!  Open an issue or join us on our public slack channel.\n", "release_dates": []}, {"name": "react-starter", "description": "Stellar's starter kit for React projects.", "language": "TypeScript", "license": null, "readme": "# Stellar React Starter\n\n## First Step\n\nPlease upgrade all dependencies on this repo before using it in your project.\n\n## Available Scripts\n\nIn the project directory, you can run:\n\n### `yarn start`\n\nRuns the app in the development mode.<br /> Open\n[http://localhost:3000](http://localhost:3000) to view it in the browser.\n\nThe page will reload if you make edits.<br /> You will also see any lint errors\nin the console.\n\n### `yarn test`\n\nLaunches the test runner in the interactive watch mode.<br /> See the section\nabout\n[running tests](https://facebook.github.io/create-react-app/docs/running-tests)\nfor more information.\n\n### `yarn build`\n\nBuilds the app for production to the `build` folder.<br /> It correctly bundles\nReact in production mode and optimizes the build for the best performance.\n\nThe build is minified and the filenames include the hashes.<br /> Your app is\nready to be deployed!\n\nSee the section about\n[deployment](https://facebook.github.io/create-react-app/docs/deployment) for\nmore information.\n\n### `yarn eject`\n\n**Note: this is a one-way operation. Once you `eject`, you can\u2019t go back!**\n\nIf you aren\u2019t satisfied with the build tool and configuration choices, you can\n`eject` at any time. This command will remove the single build dependency from\nyour project.\n\nInstead, it will copy all the configuration files and the transitive\ndependencies (webpack, Babel, ESLint, etc) right into your project so you have\nfull control over them. All of the commands except `eject` will still work, but\nthey will point to the copied scripts so you can tweak them. At this point\nyou\u2019re on your own.\n\nYou don\u2019t have to ever use `eject`. The curated feature set is suitable for\nsmall and middle deployments, and you shouldn\u2019t feel obligated to use this\nfeature. However we understand that this tool wouldn\u2019t be useful if you couldn\u2019t\ncustomize it when you are ready for it.\n\n## Learn More\n\nYou can learn more in the\n[Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started).\n\nTo learn React, check out the [React documentation](https://reactjs.org/).\n", "release_dates": []}, {"name": "recoverysigner-demo-client", "description": "A limited feature demo client for a SEP-30 Recoverysigner server.", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# SEP-30 Recoverysigner Demo Client\n\nA limited feature demo client for a [SEP-30 Recoverysigner] server.\n\nImplements the basic endpoints required for registration and recovery of a Stellar account with one or more recoverysigner servers. Designed specifically for use with the [experimental implementation] that uses Firebase for email and phone number authentication.\n\n## Usage\n### Running\nThe demo client is HTML, JavaScript, and just a few lines of CSS. The files in this repository do not need compiling, just serve the files on localhost and you're good to go.\n\nYou can use `make run` to use Ruby to run a simple file web server of the directory, or any other method to host the files in this repository at a URL.\n\n### Using the UI\n1. Update the config with the URLs for the recoverysigners and their corresponding webauth servers.\n1. Create a new account by clicking `Create New Account`.\n1. Copy the seed generated in the logs into the `Register` panel to register it with the configured recoverysigners.\n1. Use the `Bump Sequence` panel to submit a transaction (it\u2019s the only transaction offered by the client).\n1. Take a look at the transactions, they\u2019re signed by a device key, not the master key.\n1. Copy the account `G` strkey into memory.\n1. Click `Clear` next to the account details.\n1. Click `Reset` next to the device key.\n1. Paste the account `G` strkey into the `Recover` panel and kick off recovery.\n\n[SEP-30 Recoverysigner]: https://github.com/stellar/stellar-protocol/blob/master/ecosystem/sep-0030.md\n[experimental implementation]: https://github.com/stellar/go/tree/master/exp/services/recoverysigner\n", "release_dates": []}, {"name": "recoverysigner-firebase-auth", "description": "A simple demo frontend web app for performing Firebase phone auth for use with recoverysigner.", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# recoverysigner-firebase-auth\n\n## Initial setup\n\n- Install [Node.js](https://nodejs.org)\n- Install [yarn](https://classic.yarnpkg.com/en/docs/install)\n- Run `git clone git@github.com:stellar/recoverysigner-firebase-auth.git`\n- Run `cd recoverysigner-firebase-auth && yarn install`\n- Create a file under `public/config/env-config.js` with the following code:\n  ```js\n  window.APP_ENV = {\n    FIREBASE_WEB_API_KEY: \"your firebase web api key\",\n    FIREBASE_PROJECT_ID: \"your firebase project id\",\n    TEXT_COLOR: \"#fff\",\n    BACKGROUND_START_COLOR: \"#6ececb\",\n    BACKGROUND_END_COLOR: \"#59a4ae\",\n    LOGO_URL: \"https://example.com/logo.svg\",\n  };\n  ```\n- Install the [Firebase CLI](https://firebase.google.com/docs/cli)\n- Run `firebase login` and follow the instructions\n- Run `firebase init`, and enable `Hosting`\n- Run `firebase use <project id>`\n\n## Hosting locally\n\nIf you're doing something like making UI changes, you can host the app locally.\nTo do this:\n\n- Run `yarn start`\n\n## Hosting with Firebase\n\nIf you have another app that communicates with this one, and you'd like to test\nthe interaction between the two during development, you can use Firebase to host\nthis project. To do this:\n\n- Run `yarn build`\n  - This exports the project with any code changes you've made, preparing it for\n    deploy.\n- Run `firebase deploy --public build`\n  - The output of this will contain a 'Hosting URL', where you can view the\n    project. To avoid browser caching issues, it's best to use a private\n    browsing window.\n\n## Trigger auth with phone\n\nRun the following script in your browser console:\n\n```js\nmain({ phoneNumber: \"+15551112222\" });\n```\n\nA 6-digit code will be sent to that phone number. To complete sign-in, input the\ncode on the next screen.\n\n## Trigger auth with email\n\nRun the following script in your browser console:\n\n```js\nmain({\n  email: \"jordyn@example.com\",\n  // These settings are used by Firebase to generate a dynamic sign-in link\n  dynamicLinkSettings: {\n    dynamicLinkDomain: \"example.page.link\",\n    url: \"https://example.page.link/auth-email\",\n    android: { installApp: true, packageName: \"io.example.app\" },\n    iOS: { bundleId: \"io.example.app\" },\n    handleCodeInApp: true,\n  },\n});\n```\n\nA link will be sent to that email. To complete sign-in, refresh the browser and\nrun:\n\n```js\nmain({\n  email: \"jordyn@example.com\",\n  // link from email\n  signInLink:\n    \"https://example.firebaseapp.com/__/auth/action?apiKey=[apiKey]&mode=signIn&oobCode=[oobCode]&continueUrl=https://sunship.page.link/email-auth&lang=en\",\n});\n```\n\n## Building production files\n\n- Run `yarn build`\n- Copy the config file to `build/config/env-config.js`\n- Serve the `build` directory\n", "release_dates": []}, {"name": "regulated-assets-poc", "description": null, "language": "JavaScript", "license": null, "readme": "# Regulated Assets Bridge Server\n\nAn express middleware adding SEP-8 compliance to your project by specifying your own ruleset.  For more information on how this works see the blog post [TBD].\n\n## Usage\n\nSee the [example](/example/index.js) project for a full implementation that implements a simple \"Transaction must be less than an amount of 50, and accounts can hold a maximum of 1000 tokens\" ruleset.\n\n### Env Vars\n\nAdd `ASSET_CODE` and `ISSUER_SECRET` environment variables so that the bridge can sign approval transactions.\n`BRIDGE_HOSTNAME` is required if you use the TOML middleware, and should contain the hostname the approval server will be located at.\n`HOME_DOMAIN` is required if you want to use the included scripts to set up your issuer account.  `HOME_DOMAIN` should be where your TOML is hosted, and doesn't necessarily need to be the same domain as the bridge.\n\n### Issuing an asset\n\nTo quickly set up an issuer account, use the `scripts/setup-issuer.js` script.  Ensure your env vars are set up and run:\n\n`$ node scripts/setup-issuer.js`\n\nThis will set up the issuer account with the proper flags.  To actually issue an asset, use the `scripts/issue-asset-to-address.js` script.  This can be used to either issue a batch amount to a distribution account, or ad-hoc issuance to clients.\n\n`$ node scripts/issue-asset-to-address.js <amount> <wallet address>`\n\n### Implementation\n\n```\nconst regulatedAssetBridge = require(\"regulated-assets\");\nconst app = express();\napp.use(regulatedAssetBridge(rules));\n// Optionally add the toml handler\napp.use(regulatedAssetBridge.toml);\napp.listen(PORT);\n```\n\nThe bridge can be used by providing a set of `rules`.  The rules should be an async function that takes in a [StellarSdk.Transaction](https://stellar.github.io/js-stellar-sdk/Transaction.html), and returns an object with an `allowed` boolean and optional `error` string message.  You can do whatever you need inside this rules function to validate whether the proposed transaction should be allowed, including querying the stellar ledger via horizon, external API calls to talk to another part of your service, or just a set of basic rules.\n\nOnce you return that a transaction is allowed, the bridge takes care of the rest of the communication with the new sandwiched transaction.\n\n### TOML\n\nThe bridge provides an optional `toml` route handler.  If you already have a toml file for your service you can just not use the toml middleware, but make sure that your currency has the `approval_server` and `approval_criteria` added.\n\n### Wallets\n\nCurrently there is a branch that adds support for regulated assets here: https://github.com/msfeldstein/stellar-demo-wallet/tree/AddRegAssets.  The features will be added to the main project shortly.\n\n### Notes\n\nControlling Asset Holders using AUTHORIZATION_REQUIRED: https://www.stellar.org/developers/guides/concepts/assets.html#controlling-asset-holders", "release_dates": []}, {"name": "rpciege-sveltekit", "description": null, "language": "Svelte", "license": null, "readme": "# create-svelte\n\nEverything you need to build a Svelte project, powered by [`create-svelte`](https://github.com/sveltejs/kit/tree/master/packages/create-svelte).\n\n## Creating a project\n\nIf you're seeing this, you've probably already done this step. Congrats!\n\n```bash\n# create a new project in the current directory\nnpm create svelte@latest\n\n# create a new project in my-app\nnpm create svelte@latest my-app\n```\n\n## Developing\n\nOnce you've created a project and installed dependencies with `npm install` (or `pnpm install` or `yarn`), start a development server:\n\n```bash\nnpm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n```\n\n## Building\n\nTo create a production version of your app:\n\n```bash\nnpm run build\n```\n\nYou can preview the production build with `npm run preview`.\n\n> To deploy your app, you may need to install an [adapter](https://kit.svelte.dev/docs/adapters) for your target environment.\n", "release_dates": []}, {"name": "rs-soroban-env", "description": "Rust environment for Soroban contracts.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# rs-soroban-env\n\nRust contract-environment interface and (optional) host implementation for Soroban.\n\nThe `soroban-env-common` crate contains elements of the shared environment-interface between smart contract guest and host: the `Env` trait that defines the set of available environment functions as well as the `Val` type that can pass back and forth through the WASM calling convention. Additionally small wrappers around subtypes of `Val` are included: `Object`, `Symbol`, `Error`, etc.\n\nThe `soroban-env-guest` crate contains the guest-side _stub implementation_ of the environment interface called `Guest` dependent on extern fns provided by the host implementation. This can be used in a WASM runtime that provides the extern fns.\n\nThe `soroban-env-host` crate contains the host-side _full implementation_ of the environment interface called `Host`. This can be used either in the real blockchain host, or for local testing in the SDK.\n", "release_dates": ["2024-02-13T10:25:10Z", "2024-02-05T23:59:48Z", "2024-02-02T01:46:14Z", "2024-01-24T05:24:52Z", "2024-01-09T00:57:30Z", "2023-12-20T02:56:44Z", "2023-12-18T23:01:59Z", "2023-12-04T19:41:54Z", "2023-09-18T22:52:12Z", "2023-09-12T03:26:06Z", "2023-06-27T00:03:28Z", "2023-05-04T20:45:35Z", "2023-03-22T18:28:42Z", "2023-02-14T17:29:42Z", "2023-02-07T20:33:29Z", "2023-01-03T22:51:36Z", "2022-12-08T18:13:41Z", "2022-12-01T22:46:17Z", "2022-11-03T04:10:30Z", "2022-11-03T00:36:23Z", "2022-11-02T23:43:38Z", "2022-10-06T17:55:31Z", "2022-09-09T05:34:23Z", "2022-08-31T23:48:30Z", "2022-07-29T23:45:26Z", "2022-07-29T22:48:27Z"]}, {"name": "rs-soroban-sdk", "description": "Rust SDK for Soroban contracts.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# rs-soroban-sdk\nRust SDK for writing contracts for [Soroban].\n\nSoroban: https://soroban.stellar.org\n\nDocs: https://docs.rs/soroban-sdk\n\n[Soroban]: https://soroban.stellar.org\n\n## Contributing\n\nContributing to the SDK? Read [CONTRIBUTING.md](CONTRIBUTING.md).\n", "release_dates": ["2024-03-02T00:44:33Z", "2024-02-14T01:04:09Z", "2024-02-06T15:41:46Z", "2024-02-02T23:40:32Z", "2024-01-19T08:12:32Z", "2024-01-09T03:15:40Z", "2023-12-20T04:40:11Z", "2023-12-19T01:42:28Z", "2023-12-19T00:13:41Z", "2023-12-04T21:24:13Z", "2023-12-03T02:20:43Z", "2023-12-03T02:00:08Z", "2023-09-19T01:46:53Z", "2023-09-12T19:30:31Z", "2023-07-11T22:06:47Z", "2023-06-28T17:02:24Z", "2023-06-27T19:17:22Z", "2023-06-16T17:31:53Z", "2023-06-14T20:03:32Z", "2023-06-12T22:59:40Z", "2023-05-18T23:55:42Z", "2023-05-18T16:36:08Z", "2023-05-18T06:45:03Z", "2023-05-15T19:25:07Z", "2023-05-04T23:11:54Z", "2023-03-22T19:27:50Z", "2023-02-14T18:08:53Z", "2023-02-07T21:22:13Z", "2023-01-09T20:40:31Z", "2023-01-06T18:38:07Z"]}, {"name": "rs-stellar-strkey", "description": "Rust lib for encode/decode of Stellar Strkeys.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# rs-stellar-strkey\n\nLibrary and CLI containing types and functionality for working with Stellar\nStrkeys.\n\n**This repository contains code that is in early development, incomplete,\nnot tested, and not recommended for use. The API is unstable, experimental,\nand is receiving breaking changes frequently.**\n\n### Usage\n\n#### Library\nTo use the library, include in your toml:\n\n```toml\nstellar-strkey = \"...\"\n```\n\n#### CLI\n\nTo use the CLI:\n\n```console\ncargo install --locked stellar-strkey --version ... --features cli\n```\n\n##### Examples\n\nDecode a `G` account/public-key strkey:\n```console\n$ stellar-strkey decode GAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWHF\nPublicKeyEd25519(PublicKey(0000000000000000000000000000000000000000000000000000000000000000))\n```\n\nDecode a `C` contract strkey:\n```console\n$ stellar-strkey decode CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABSC4\nContract(Contract(0000000000000000000000000000000000000000000000000000000000000000))\n```\n\nLicense: Apache-2.0\n", "release_dates": ["2023-01-03T19:15:04Z", "2022-10-05T18:21:26Z", "2022-09-09T05:05:38Z", "2022-09-02T04:09:34Z"]}, {"name": "rs-stellar-submit", "description": "Rust lib for submitting Stellar txs.", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# rs-stellar-submit\nRust lib for submitting Stellar txs.\n\n**This repository contains code that is in early development and not recommended for use. The API is unstable, experimental, and is receiving breaking changes frequently.**\n", "release_dates": []}, {"name": "rs-stellar-xdr", "description": "Rust lib for Stellar XDR.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# stellar-xdr\n\nLibrary and CLI containing types and functionality for working with Stellar\nXDR.\n\nTypes are generated from XDR definitions hosted at [stellar/stellar-xdr]\nusing [xdrgen].\n\n[stellar/stellar-xdr]: https://github.com/stellar/stellar-xdr\n[xdrgen]: https://github.com/stellar/xdrgen\n\n### Usage\n\n#### Library\nTo use the library, include in your toml:\n\n```toml\nstellar-xdr = { version = \"...\", default-features = true, features = [] }\n```\n\n##### Features\n\nThe crate has several features, tiers of functionality, ancillary\nfunctionality, and channels of XDR.\n\nDefault features: `std`, `curr`.\n\nTeirs of functionality:\n\n1. `std` \u2013 The std feature provides all functionality (types, encode,\ndecode), and is the default feature set.\n2. `alloc` \u2013 The alloc feature uses `Box` and `Vec` types for recursive\nreferences and arrays, and is automatically enabled if the std feature is\nenabled. The default global allocator is used. Support for a custom\nallocator will be added in [#39]. No encode or decode capability exists,\nonly types. Encode and decode capability will be added in [#46].\n3. If std or alloc are not enabled recursive and array types requires static\nlifetime values. No encode or decode capability exists. Encode and decode\ncapability will be added in [#47].\n\n[#39]: https://github.com/stellar/rs-stellar-xdr/issues/39\n[#46]: https://github.com/stellar/rs-stellar-xdr/issues/46\n[#47]: https://github.com/stellar/rs-stellar-xdr/issues/47\n\nAncillary functionality:\n\n1. `base64` \u2013 Enables support for base64 encoding and decoding.\n2. `serde` \u2013 Enables support for serializing and deserializing types with\nthe serde crate.\n3. `arbitrary` \u2013 Enables support for interop with the arbitrary crate.\n\nChannels of XDR:\n\n- `curr` \u2013 XDR types built from the `stellar/stellar-xdr` `curr` branch.\n- `next` \u2013 XDR types built from the `stellar/stellar-xdr` `next` branch.\n\nIf a single channel is enabled the types are available at the root of the\ncrate. If multiple channels are enabled they are available in modules at\nthe root of the crate.\n\n#### CLI\n\nTo use the CLI:\n\n```console\ncargo install --locked stellar-xdr --version ... --features cli\n```\n\n##### Examples\n\nParse a `TransactionEnvelope`:\n```console\nstellar-xdr decode --type TransactionEnvelope << -\nAAAAA...\n-\n```\n\nParse a `ScSpecEntry` stream from a contract:\n```console\nstellar-xdr +next decode --type ScSpecEntry --input stream-base64 --output json-formatted << -\nAAAAA...\n-\n```\n\nParse a `BucketEntry` framed stream from a bucket file:\n```console\nstellar-xdr decode --type BucketEntry --input stream-framed --output json-formatted bucket.xdr\n```\n\nLicense: Apache-2.0\n", "release_dates": ["2024-02-01T20:02:29Z", "2023-12-18T21:49:20Z", "2023-12-05T02:00:30Z", "2023-12-02T00:53:00Z", "2023-09-12T00:15:39Z", "2023-06-26T17:53:57Z", "2023-05-04T19:23:41Z", "2023-03-22T16:24:11Z", "2023-02-14T16:57:51Z", "2023-02-07T18:45:51Z", "2023-01-03T21:28:27Z", "2022-12-08T17:49:53Z", "2022-12-08T17:17:47Z", "2022-12-01T19:54:35Z", "2022-12-01T05:24:14Z", "2022-11-02T23:14:06Z", "2022-10-05T18:18:22Z", "2022-08-31T22:50:18Z", "2022-07-29T20:44:44Z"]}, {"name": "rs-xdr-types", "description": "Rust lib with types and traits for XDR serialization.", "language": null, "license": null, "readme": "# rs-xdr-types\nRust lib containing types and traits for XDR serialization.\n", "release_dates": []}, {"name": "scaffold-soroban", "description": "Soroban example dapps", "language": "JavaScript", "license": null, "readme": "# Soroban Example Dapps\n\nThis repository holds examples & patterns for building decentralized applications on Soroban.\n\nThe repo is organized using yarn workspaces, and git submodules:\n\n- `@modules/payment-react`: this is an example dapp for making a payment on Soroban ([soroban-react-payment](https://github.com/stellar/soroban-react-payment/))\n- `@modules/mint-token`: this is an example dapp for minting a standard token on Soroban (\n  [soroban-react-mint-token](https://github.com/stellar/soroban-react-mint-token/))\n- `@modules/atomic-swap-react`: this is an example dapp for swapping tokens atomically on Soroban (\n[soroban-react-atomic-swap](https://github.com/stellar/soroban-react-atomic-swap/))\n\n## Prerequisites\n\nYou will need:\n\n- Node (>=16.14.0 <17.0.0): https://nodejs.org/en/download/\n\n- Yarn (v1.22.5 or newer): https://classic.yarnpkg.com/en/docs/install\n\n- Freighter wallet: https://www.freighter.app/\n\n## Getting Started\n\n1. Clone and navigate into the\n   [Scaffold Soroban repository](https://github.com/stellar/scaffold-soroban/tree/main)\n\n   ```\n   git clone git@github.com:stellar/scaffold-soroban.git\n   cd scaffold-soroban\n   ```\n\n2. Pull the submodules in if this is your first time pulling the repo\n\n   ```\n   git submodule update --init --recursive\n   ```\n\n3. Install the dependencies by running the following:\n\n   ```\n   yarn\n   ```\n\n4. If you need to update the submodules to the latest, run:\n\n   ```\n   git submodule update --remote\n   ```\n\n## Build the Project\n\n```\nyarn && yarn build\n```\n\n## Starting a Dev Environment\n\n```\nyarn && yarn start\n```\n", "release_dates": []}, {"name": "scp-proofs", "description": "SCP proofs and models", "language": "Python", "license": null, "readme": "This is a repository containing formal proofs about the Stellar Consensus\nProtocol as described in the paper \"Fast and secure global payments with\nStellar\" (SOSP 2019).\n\nUsing Isabelle/HOL, we formalize the theory of Federated Byzantine Agreement\nSystems (FBAS) and we prove two main results: the cascade theorem and that the\nunion of two intact sets is intact.\n\nUsing Ivy, we formalize SCP in a high-level, non-executable specification, and\nwe prove that members of intertwined sets never disagree (SCP's main safety\nproperty) and some liveness properties.\n\nNOTE: For the old proofs, checkout [commit 803b345](https://github.com/stellar/scp-proofs/tree/803b345e3156f70eb1e24f522c50517161731cd0) . The repository at this\ncommit contains a full liveness proof. However, being written in Ivy 1.6, it\nhas a lot of hacks. The current, newer version of this repository contains\nproofs written in Ivy 1.7.\n\n# Isabelle/HOL proofs\n\nFBA.thy contains a formalization of the notion of intact set. Roughly speaking,\na set *I* is intact when (a) *I* is a quorum, and (b) even if all nodes outside\n*I* are faulty, any two quorums of members of *I* intersect.\n\nWe prove that:\n1. The cascade theorem holds: if `I` is an intact set, `Q` is a quorum of\n   a member of `I`, and `Q\u2286S`, then either `I\u2286S` or there is a member of `I\u2212S`\n   that is blocked by `S\u2229I`.\n2. The union of two intersecting intact sets is intact. This implies that\n   maximal intact sets are disjoint.\n\nNote that there two major differences compared to the treatment in the Stellar\nWhitepaper:\n1. We do not assume that the FBAS enjoys quorum intersection. Thus there may be\n   disjoint intact sets that diverge but nevertheless remain internally safe\n   and live. Point 2 above implies that maximal intact sets are disjoint, and\n   that an FBA system is a collection of disjoint maximal intact sets.\n2. We use a new, more abstract definition of quorum for the analysis. A quorum\n   is a set `Q` such that all well-behaved members of `Q` have a slice in `Q`.\n\nNote that the new definition of quorum only relies on the slices of\nwell-behaved nodes, which seems natural since faulty nodes can arbitrarily\nchange their slices, whereas the original definition of quorum used the slices\nof faulty nodes too.\n\nWe use this new definition of quorum only for the analysis of the system. In\nreality, nodes do not know who is faulty and thus cannot use this new\ndefinition of quorum, and instead just check for sets whose members all have\na slice inside the set. The abstraction we make here is safe because any set\nthat is deemed a quorum by a node in reality is also a quorum in the abstract\ndefinition that we use for our analysis. Moreover, the two definitions coincide\nexactly when we consider only well-behaved nodes.\n\nTo browse and check FBA.thy with Isabelle, use [Isabelle\n2019](https://isabelle.in.tum.de/). The file `output/document.pdf` is a PDF\nversion of FBA.thy.\n\nThere is also a maintained version of the theory of FBAS and more in the\nArchive of Formal Proofs:\n<https://devel.isa-afp.org/entries/Stellar_Quorums.html>.\n\n## Comments on the Isabelle/HOL proofs\n\nThe proofs do not follow the presentation of the Stellar Whitepaper. They are\nsimpler due to the reformulation of the notion of quorum.\n\nTo prove the cascade theorem, we assume by contradiction that `I` is not\na subset of `S` but no member of `S\u2212I` is blocked by `S\u2229I`. In this situation,\nwe note that `I\u2212S` is a quorum of a member of `I` in the projection of the\nsystem on `I`. Moreover, `Q` is also a quorum of a member of `I` in the\nprojection of the system on `I`. Thus, by the quorum intersection property of\n`I`, `Q` and `I\u2212S` must intersect. This is clearly impossible since `Q` is\na subset of `S`, and we have reached a contradiction.\n\nTo prove that the union of two intersecting intact set is intact, we reason as\nfollows. Take two intersecting intact sets `I\u2081` and `I\u2082`. First, note that\n`I\u2081\u222aI\u2082` is trivially a quorum, and thus we have quorum availability.\n\nIt remains to show that `I\u2081\u222aI\u2082` enjoys quorum intersection. Take a set `Q\u2081`\nthat is a quorum of a member of `I\u2081` in the system projected on `I\u2081\u222aI\u2082` and\na quorum `Q\u2082` that is a quorum of a member of `I\u2082` in the system projected on\n`I\u2081\u222aI\u2082`. We must show that `Q\u2081` and `Q\u2082` intersect in `I\u2081\u222aI\u2082`. First note that\n`I\u2082` is a quorum in the system projected on `I\u2081` and, by assumption,\n`I\u2081\u2229I\u2082\u2260{}`. Moreover, `Q\u2081` is a quorum in the system projected on `I\u2081` and `I\u2081`\nis intact. Thus, by the quorum intersection property of intact sets, (a) `I\u2082`\nand `Q\u2081` intersect. Moreover, (b) both `Q\u2081` and `Q\u2082` are quorums in the system\nprojected on `I\u2082`. Because `I\u2082` is intact, by the quorum intersection property,\nwe get from (a) and (b) that `Q\u2081` and `Q\u2082` intersect in `I\u2082`, and we are done.\n\n# Ivy proofs\n\nThis repository contains a proof of SCP's safety property in Ivy (isolate\nprotocol.intertwined_safety in SCP.ivy) and of some of SCP's liveness properties.\n\n## Running the proofs\n\nTo run the proof (that is, to have Ivy check them), run the following commands\n(on Linux) from the root of this repository:\n```\ndocker-compose build ivy-check\ndocker-compose run ivy-check\n```\n\n## Background material to understand the model and proofs\n\n* To understand the model and safety proofs:\n  * Padon, Oded, et al. *Paxos made EPR: decidable reasoning about distributed protocols.* Proceedings of the ACM on Programming Languages 1.OOPSLA (2017): 108. (available [on arXiv](https://arxiv.org/abs/1710.07191)).\n\n* To understand the liveness proofs:\n  * Padon, Oded, et al. *Temporal prophecy for proving temporal properties of infinite-state systems.* 2018 Formal Methods in Computer Aided Design (FMCAD). IEEE, 2018.\n  * Padon, O., Hoenicke, J., Losa, G., Podelski, A., Sagiv, M., & Shoham, S. (2017). *Reducing liveness to safety in first-order logic*. Proceedings of the ACM on Programming Languages, 2(POPL), 26.\n\n## What is proved with Ivy?\n\n### The model\n\nFirst, the proofs make statements about a model of SCP written in the Ivy\nlanguage, and not about SCP's implementation or SCP's description in the\nStellar Whitepaper. This model may not reflect what the reader think SCP is,\nand what SCP is may be open to interpretation since there is not agreed-upon\nformal specification. The model in `SCP.ivy` could in principle be taken as the\nformal specification of SCP.\n\n**Caveat 1**: Discrepancies between the SCP model and any other notion of what\nSCP is would imply that the statements proved with Ivy may not apply to that\nother notion of what SCP is.\n\nThe model consists of an initial state and a collection of actions, which are\natomic steps that update the global state of the system. Actions model what\nnodes do upon receiving messages or upon timers firing. Each action consists of\npreconditions (expressed using `require` statements) and state updates. An\nexecution of the model is a sequence of global states, starting with the\ninitial state, and such that each successive state is obtained from the\npreceding state by applying an action whose preconditions are satisfied. This\nis an instance of Lamport's Standard Model, used e.g. in TLA+, which Lamport\ndiscusses in his Turing Award lecture.\n\nPreconditions and state updates are specified using First-Order Logic formulas.\nNote that, by convention, all free upper-case variables are taken to be\nuniversally quantified. For more details about specifying protocols in Ivy (and\nproving their safety), see the [Ivy tutorial](https://microsoft.github.io/ivy/).\n\n**Caveat 2:** It is easy to write a model that does nothing, e.g. because the\npreconditions of the actions are too strong or even contradictory, and, in this\ncase, any proof is meaningless. One way to ensure that the model does do\nsomething is to prove liveness properties. For example, we might want to prove\nthat, in every eventually synchronous execution, every intact node eventually\nconfirms a value as committed. We discuss the liveness of SCP below.\n\n#### Abstractions\n\nThe SCP model abstracts over several aspects of SCP.\n\n#### Quorum slices\n\nThere is no notion of quorum slice in the model. Instead, we consider a\nset of nodes which each have a set of quorums and a notion of blocking set. We\nthen define intertwined and intact sets using the following axioms:\n1. The intersection of two quorums of intertwined nodes contains a well-behaved\n   node.\n2. The intersection of two quorums of intact nodes contains an intact node.\n3. The set of intact nodes is a quorum.\n4. If `Q` is a quorum of an intact node and if all members of `Q` have accepted\n   `(b,v)` as prepared, then either all intact nodes have accepted `(b,v)` as\n   prepared, or there is an intact node `n` such that `n` has not accepted\n   `(b,v)` as prepared and `n` is blocked by a set of intact nodes that have\n   all accepted `(b,v)` as prepared. This is an instance of the cascade\n   theorem.\n5. If an intact node is blocked by a set of nodes `S`, then `S` contains an\n   intact node. Properties 4 and 5 are proved in the Isabelle/HOL theory\n   `FBA.thy`.\n\n**Caveat 3**: If those axioms are inconsistent (i.e. lead to a contradiction\nwhen taken together), the proofs are meaningless. We verified 4 and 5 in\nIsabelle/HOL, but there is no mechanically-checked link between the Ivy axioms\nand the Isabelle/HOL theory. Thus there is still the possibility that of\na typo.\n\n**TODO**: It should be possible to use Ivy to check that the axioms have\na model, which would rule out any inconsistency.\n\nAbstracting slices away may see like a bold step. However, the model still\npreserves the most challenging algorithmic aspect of implementing consensus in\na federated Byzantine agreement system, i.e. the fact that the notion of quorum\nis different for each participant. What is not captured by the model includes\nthe fact that quorums are discovered dynamically (nodes know all their quorums\nupfront in the model) and that quorums might change during execution as nodes\nadjust their slices (quorums are fixed upfront in the model).\n\n#### Execution model\n\nThere is no notion of real-time in the model. Instead, messages are delivered\nat non-deterministically and an armed timer can fire non-deterministically at\nany point. Thus we cannot make any statements about the amount of time that it\ntakes to make certain things happen.\n\nHowever, in practice, liveness depends on having synchronized clocks and a\nnetwork delay commensurate with timer values. For the liveness proofs, since we\ncannot talk about real time, we instead make assumptions using Linear-Time Temporal\nLogic (LTL). For example, we assume that every message sent from an intact node\nto an intact node is eventually delivered. Moreover, for a full liveness proof,\nwe would need to assume that there exists a ballot `b` after which the system\nbecomes synchronous (i.e.every message sent by an intact node to an intact node\nis received in the same ballot) and no non-intact nodes take any steps.\n\n#### Nomination\n\nFinally, the model does not specify the nomination protocol. Instead, we assume\nthat nomination can produce arbitrary values, which is a sound\nover-approximation.\n\n### Safety\n\nWe prove that intertwined nodes never disagree by providing a collection of\ninvariants which, together with the safety property to prove, form an\ninductive invariant (i.e. they hold in the initial state and are preserved by\nevery action).\n\nThe key invariants are:\n1. A well-behaved node does not accept `(b,v)` as committed unless it confirmed\n   `(b,v)` as prepared.\n2. A well-behaved node does not accept contradictory statements (where `commit\n   (b,v)` and `prepare (b',v')` are contradictory when `b < b'` and `v \u2260 v'`.\n3. If an intertwined node confirms a statement, then there is a quorum of an\n   intertwined node whose well-behaved members accepted that statement.\n4. A well-behaved node does not accept different values as prepared in the same\n   ballot.\n\nGiven those invariants, suppose that `v` and `v'` are confirmed committed in\nballots `n` and `n'`, with `n < n'`. By Invariant 1 and Invariant 3, there is\na quorum `Q` of an intertwined node whose well-behaved members all accepted\n`(n',v')` as prepared. Thus, by Invariant 2, no well-behaved member of `Q` ever\naccepts `(n,v)` as committed. Thus, by Invariant 3 and Quorum Intersection, no\nintertwined node confirmed `(n,v)` as committed, which is a contradiction.\n\nUsing the auxiliary conjectures present in the `safety` isolate in\n`SCP-safety.ivy`, Ivy reaches the same conclusion automatically and\nsuccessfully validates that the safety property holds.\n\n### Liveness\n\nWe would like to prove that SCP guarantees that, under eventual synchrony,\nevery intact node eventually confirms a value as committed. Unfortunately, this\ndoes not hold, and SCP guarantees the following, weaker liveness property: if\nthe system is eventually synchronous and non-intact nodes eventually stop\ntaking steps, then every intact node eventually confirms a value as committed.\n\nMore precisely, let us now sketch a proof that, after two consecutive\nsynchronous ballots that are long enough, every intact node confirms a value as\ncommitted.\n\nThis liveness property follows from the following two sub-properties:\n* L1: by the end of a long-enough synchronous ballot in which non-intact nodes\n  do not take steps, every intact node agrees on the highest confirmed-prepared\n  value.\n* L2: if a quorum unanimously votes to prepare a value `v` during a long-enough\n  synchronous ballot, then every intact node confirms `v` as committed by the\n  end of the ballot.\n\nNow why do L1 and L2 imply the liveness property? Note that, if intact nodes\nagree that the highest confirmed-prepared value is `v`, then they all vote for\n`v`. Thus, once ballots become synchronous and Byzantine nodes stop taking\nstep, properties L1 and L2 together imply that all intact nodes decide.\n\nLet us know informally argue why properties L1 and L2 hold. In each cases, the\nmain obstacle to liveness is the fact that nodes do not accept contradictory\nvalues, and this could block progress. In both cases, we rule out progress\nbeing blocked in this way using additional invariants proved in the isolate\n`protocol.additional_safety`.\n\nTo see why property L1 holds, assume that an intact node has confirmed `(b,v)`\nprepared during a long-enough synchronous ballot. Then, as we prove in `inv2`\nin isolate `protocol.additional_safety`, no contradictory statement is ever\naccepted by intact nodes. Thus, other intact nodes are never prevented from\naccepting `(b,v)` as prepared, and the Cascade Theorem ensures that, given\nenough communication, every intact node confirms `(b,v)` as prepared. Thus, if\nballot `b` is long enough, evey intact node confirms `(b,v)` as prepared by the\nend of the ballot.\n\nTo see  why property L2 holds, assume that every intact node votes to prepare\nthe same value `v` during a long-enough synchronous ballot `b`. Then, as we\nprove in `inv1` in isolate `protocol.additional_safety`, no contradictory\nstatement is ever accepted by intact nodes. Thus, given enough communication,\nnothing prevents value `v` from being accepted prepared, then confirmed\nprepared, then accepted committed, and finally confirmed committed by all\nintact nodes. Thus, if ballot `b` is long enough, every intact node confirms\n`(b,v)` as committed by the end of the ballot.\n\n#### What liveness properties are proved in Ivy?\n\nAn old version of this repository (commit `803b345`) contains a full liveness\nproof. However, this old proof is written in Ivy 1.6 and contains many hacks.\nThe current repository uses Ivy 1.7 and contains cleaner liveness proofs.\nHowever, we have so far only ported the proof of the following statement: if an\nintact node confirms `(b,v)` as prepared, then eventually all intact nodes\nconfirm `(b,v)` as prepared. This implies property L1.\n\n#### Liveness in practice\n\nUnfortunately, Byzantine nodes can always interfere right before the end of\na ballot and cause disagreement on what is confirmed prepared among intact\nnodes and make L1 fail. More precisely, a Byzantine node can always withhold an\n\"accept prepare\" message right until the end of a ballot (either because it is\nfaulty or because it has bad timing) and complete a quorum just before the\nballot ends, and thereby cause some intact nodes to confirm the corresponding\nvalue as prepared while others do not.\n\nIn practice, to ensure that all intact nodes vote to prepare the same value in\nthe next ballot, intact nodes must adjust their slices to make sure that no\nfaulty or otherwise untimely node remain in any of their quorums.\n", "release_dates": []}, {"name": "sep24-reference-ui", "description": null, "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# SEP-24 Reference UI\n\n## Developing\n\nWe use `yarn` package manager.\n\n`yarn` or `yarn install`\n\nTo start the app in development mode, which will watch for changes to files,\nrebuild, and reload the site automatically, run the start script.\n\n`yarn start`\n\n## Building for production\n\nBuilds the app for production to the `build` folder.\n\n`yarn build`\n", "release_dates": []}, {"name": "sjcl-scrypt", "description": "An scrypt implementation in JavaScript, because that is not insane at all.", "language": "JavaScript", "license": null, "readme": "sjcl-scrypt\n===========\n\nAn scrypt implementation in JavaScript, because that is not insane at all.\n\nIt depends on the [Standford JavaScript Cryptography Library](http://crypto.stanford.edu/sjcl/)\nand shares its license (BSD).\n\nTo use, make sure you have `sjcl.js` available, then do this:\n\n    <script src=\"sjcl.js\"></script>\n    <script src=\"sjcl-scrypt.js\"></script>\n", "release_dates": []}, {"name": "slingshot", "description": " A new blockchain architecture under active development, with a strong focus on scalability, privacy and safety", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Project Slingshot\n\n_Accelerating trajectory into interstellar space._\n\nSlingshot is a new blockchain architecture under active development,\nwith a strong focus on scalability, privacy and safety.\n\nThe Slingshot project consists of the following components:\n\n### [Demo](demo)\n\nDemo node where one can create transactions and inspect the blockchain.\n\n* Visit a public instance: [zkvm-demo.stellar.org](https://zkvm-demo.stellar.org).\n* Run on your own machine: [see instructions](demo/README.md).\n\n### [ZkVM](zkvm)\n\nZkVM is a transaction format with **cloaked assets** and **zero-knowledge smart contracts**.\n\n* [README](zkvm/README.md)\n* [ZkVM whitepaper](zkvm/docs/zkvm-design.md)\n* [ZkVM specification](zkvm/docs/zkvm-spec.md)\n* [ZkVM API guide](zkvm/docs/zkvm-api.md)\n\n### [Blockchain](blockchain)\n\nAbstract blockchain state machine for the ZkVM transactions.\n\n* [README](zkvm/README.md)\n* [Blockchain specification](zkvm/docs/zkvm-blockchain.md)\n* [Stubnet specification](zkvm/docs/zkvm-stubnet.md)\n\n### [Spacesuit](spacesuit)\n\nInterstellar\u2019s implementation of _Cloak_, a confidential assets protocol\nbased on the [Bulletproofs](https://doc.dalek.rs/bulletproofs/index.html) zero-knowledge circuit proof system.\n\n* [Spacesuit README](spacesuit/README.md)\n* [Cloak specification](spacesuit/spec.md)\n\n### [Starsig](starsig)\n\nA pure Rust implementation of the Schnorr signature scheme based on [ristretto255](https://ristretto.group).\n\n* [Starsig specification](starsig/docs/spec.md)\n\n### [Musig](musig)\n\nA pure Rust implementation of the [Simple Schnorr Multi-Signatures](https://eprint.iacr.org/2018/068) by Maxwell, Poelstra, Seurin and Wuille.\n\n* [Musig specification](musig/docs/musig-spec.md)\n\n### [Keytree](keytree)\n\nA _key blinding scheme_ for deriving hierarchies of public keys for [Ristretto](https://ristretto.group)-based signatures.\n\n* [Keytree specification](keytree/keytree.md)\n\n### [Merkle](merkle)\n\nA Merkle tree API for computing Merkle roots, making and verifying Merkle proofs.\nUsed for ZkVM transaction IDs, Taproot implementation and Utreexo commitments.\n\nBased on [RFC 6962 Section 2.1](https://tools.ietf.org/html/rfc6962#section-2.1) and implemented using [Merlin](https://merlin.cool).\n\n### [Accounts](accounts)\n\nAPI for managing accounts and receivers. This is a building block for various payment protocols.\n\n### [P2P](p2p)\n\nSmall p2p networking library that implements peer management logic with pluggable application logic.\nImplements symmetric DH handshake with forward secrecy.\n\n### [Reader/Writer](readerwriter)\n\nSimple encoding/decoding and reading/writing traits and utilities for blockchain data structures.\n\n\n![](https://user-images.githubusercontent.com/698/57546709-2d696c00-7312-11e9-8430-51ed9b51e6c8.png)\n", "release_dates": []}, {"name": "solang", "description": "Solidity Compiler for Solana and Substrate", "language": null, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<img src=\"docs//hl_solang_horizontal-color.svg\" alt=\"Solang Logo\" width=\"75%\"/>\n\n# solang - Solidity Compiler for Solana and Substrate\n\n[![Discord](https://img.shields.io/discord/905194001349627914?logo=Hyperledger&style=plastic)](https://discord.gg/jhn4rkqNsT)\n[![CI](https://github.com/hyperledger/solang/workflows/test/badge.svg)](https://github.com/hyperledger/solang/actions)\n[![Documentation Status](https://readthedocs.org/projects/solang/badge/?version=latest)](https://solang.readthedocs.io/en/latest/?badge=latest)\n[![license](https://img.shields.io/github/license/hyperledger/solang.svg)](LICENSE)\n[![LoC](https://tokei.rs/b1/github/hyperledger/solang?category=lines)](https://github.com/hyperledger/solang)\n\nWelcome to Solang, a new Solidity compiler written in rust which uses\nllvm as the compiler backend. Solang can compile Solidity for Solana and\nSubstrate. Solang is source compatible with Solidity 0.8, with\nsome caveats due to differences in the underlying blockchain.\n\nSolang is under active development right now, and has\n[extensive documentation](https://solang.readthedocs.io/en/latest/).\n\n\n## Installation\n\nSolang is available as a Brew cask for MacOS, with the following command:\n\n```\nbrew install hyperledger/solang/solang\n```\n\nFor other operating systems, please check the [installation guide](https://solang.readthedocs.io/en/latest/installing.html).\n\n## Simple example\n\nAfter installing the compiler, write the following to flipper.sol:\n\n```solidity\ncontract flipper {\n\tbool private value;\n\n\tconstructor(bool initvalue) public {\n\t\tvalue = initvalue;\n\t}\n\n\tfunction flip() public {\n\t\tvalue = !value;\n\t}\n\n\tfunction get() public view returns (bool) {\n\t\treturn value;\n\t}\n}\n```\n\n## Build for Solana\n\nRun:\n\n```bash\nsolang compile --target solana flipper.sol\n```\n\nAlternatively if you want to use the solang container, run:\n\n```\ndocker run --rm -it -v $(pwd):/sources ghcr.io/hyperledger/solang compile -v -o /sources --target solana /sources/flipper.sol\n```\n\nA file called `flipper.abi` and `flipper.so`. Now install `@solana/solidity`:\n\n```\nnpm install @solana/solidity\n```\n\nSave the following to `flipper.js`:\n```javascript\nconst { Connection, LAMPORTS_PER_SOL, Keypair } = require('@solana/web3.js');\nconst { Contract, Program } = require('@solana/solidity');\nconst { readFileSync } = require('fs');\n\nconst FLIPPER_ABI = JSON.parse(readFileSync('./flipper.abi', 'utf8'));\nconst PROGRAM_SO = readFileSync('./flipper.so');\n\n(async function () {\n    console.log('Connecting to your local Solana node ...');\n    const connection = new Connection('http://localhost:8899', 'confirmed');\n\n    const payer = Keypair.generate();\n\n    console.log('Airdropping SOL to a new wallet ...');\n    const signature = await connection.requestAirdrop(payer.publicKey, LAMPORTS_PER_SOL);\n    await connection.confirmTransaction(signature, 'confirmed');\n\n    const program = Keypair.generate();\n    const storage = Keypair.generate();\n\n    const contract = new Contract(connection, program.publicKey, storage.publicKey, FLIPPER_ABI, payer);\n\n    await contract.load(program, PROGRAM_SO);\n\n    console.log('Program deployment finished, deploying the flipper contract ...');\n\n    await contract.deploy('flipper', [true], storage, 17);\n\n    const res = await contract.functions.get();\n    console.log('state: ' + res.result);\n\n    await contract.functions.flip();\n\n    const res2 = await contract.functions.get();\n    console.log('state: ' + res2.result);\n})();\n```\n\nAnd now run:\n```\nnode flipper.js\n```\n\n## Build for Substrate\n\nRun:\n\n```bash\nsolang compile --target substrate flipper.sol\n```\n\nAlternatively if you want to use the solang container, run:\n\n```\ndocker run --rm -it -v $(pwd):/sources ghcr.io/hyperledger/solang compile -v -o /sources --target substrate /sources/flipper.sol\n```\nYou will have a file called flipper.contract. You can use this directly in\nthe [Contracts UI](https://contracts-ui.substrate.io/),\nas if your smart contract was written using ink!.\n\n## Tentative roadmap\n\nSolang has a high level of compatibility with many blockchains. We are trying to ensure the compiler stays\nup to date with the newest Solidity syntax and features.  In addition, we focus on bringing new performance optimizations\nand improve developer experience.\nHere is a brief description of what we envision for the next versions.\n\n### V0.3\n\n| Milestone                                  | Status      |\n|--------------------------------------------|-------------|\n| Call Solana's Rust contracts from Solidity | Completed   |\n| Improvements in overflow checking          | Completed   |\n| Support Solana's Program Derived Addresses | Completed   |\n| Call Solidity from Solana's Rust contracts | Not started |\n| Improve developer experience for Substrate | Not started |\n| Tooling for calls between ink! <> solidity | Not started |\n| Support chain extensions for Substrate     | Not started |\n| Provide CLI for node interactions          | Not started |\n\n\n### V0.4\n\n| Milestone                                          | Status      |\n|----------------------------------------------------|-------------|\n| Improve management over optimization passes        | Not started |\n| Specify values as \"1 sol\" and \"1e9 lamports\"       | In progress |\n| Adopt single static assignment for code generation | Not started |\n| Support openzeppelin on Substrate target           | Not started |\n| Provide Solidity -> Substrate porting guide        | Not started |\n\n\n\n## License\n\n[Apache 2.0](LICENSE)\n", "release_dates": []}, {"name": "solar-stellarorg", "description": "Stellar.org's Solar CSS framework theme", "language": "CSS", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "solar-stellarorg\n--------------\n\nsolar-stellarorg is a [solar css framework](https://github.com/stellar/solar) theme. It themes solar to Stellar Development Foundation's branding by adding a [theme layer](https://github.com/stellar/solar/blob/master/docs/architecture.md#modules-and-themes) on solar.\n\nThe lib/_index.scss and styles/_index.scss files are loaded after each of their respective core modules. The solar-stellarorg/lib/_index.scss file is loaded before solar-css/styles/_index.scss so that this theme library can affect core styles with variables.\n\nThis theme is not limited to use in interstellar. It is also used on other Stellarorg projects. While anyone can use solar-stellarorg, development of solar-stellarorg is targeted for use by Stellarorg itself. Feel free to fork and develop into your own theme.\n\n## What lives in the stellarorg theme?\n- **variables**: theming variables that other css code uses (colors, padding, border-radius)\n- **typography**: overrides for scale, typography, and custom fonts\n- **organization global sprites/icons**: small sprites used globally throughout the Stellarorg brand, such as the Stellar rocket or [stroopy and friends](https://www.stellar.org/stories/adventures-in-galactic-consensus-chapter-1/)\n- **custom**: any other styles to be used across multiple Stellarorg projects\n", "release_dates": []}, {"name": "solar-stellarorg-pages", "description": null, "language": "CSS", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# solar-stellarorg-pages\nThis is a [solar css](https://github.com/stellar/solar) module that provides reusable css for web pages created by StellarOrg.\n\n## License\nThis project is licensed under Apache License Version 2.0. For more information, refer to the [LICENSE.txt](LICENSE.txt) file.\n", "release_dates": []}, {"name": "soroban-cli", "description": "CLI for Soroban contracts.", "language": "Rust", "license": null, "readme": "# soroban-tools\n\nThis repo is home to the [Soroban CLI](https://github.com/stellar/soroban-tools/tree/main/cmd/soroban-cli): The command-line multi-tool for running and deploying Soroban contracts.\n\nSoroban: https://soroban.stellar.org\n\n# Adding git hooks\n\nTo add git hooks for commits and pushes run:\n\n```\n./install_githooks.sh\n```\n\nwhich copies the git hooks found at `.cargo-husky/hooks` to `.git/hooks`.", "release_dates": ["2024-02-23T05:41:23Z", "2024-02-06T19:20:07Z", "2024-01-12T01:38:32Z", "2023-12-21T19:47:40Z", "2023-12-20T16:46:44Z", "2023-12-12T19:41:28Z", "2023-12-08T00:32:39Z", "2023-12-06T20:38:20Z", "2023-12-05T23:02:11Z", "2023-10-26T14:24:44Z", "2023-09-26T20:05:13Z", "2023-09-21T18:20:14Z", "2023-09-19T14:51:19Z", "2023-09-14T22:35:49Z", "2023-07-27T00:44:06Z", "2023-07-12T17:18:39Z", "2023-07-12T13:17:15Z", "2023-06-23T16:26:55Z", "2023-06-15T12:57:36Z", "2023-05-23T21:23:12Z", "2023-04-05T11:02:59Z", "2023-04-03T21:05:29Z", "2023-02-15T04:02:06Z", "2023-02-14T03:17:41Z", "2023-01-06T00:37:44Z", "2022-12-08T01:20:54Z", "2022-12-08T00:49:51Z", "2022-12-06T17:36:37Z", "2022-12-06T16:03:11Z", "2022-11-04T23:00:39Z"]}, {"name": "soroban-dapps-challenge", "description": "Dapps for the Soroban Dapps Challenge", "language": null, "license": null, "readme": "# Soroban Dapps Challenge\n\nWelcome to the [Soroban Dapps Challenge](https://soroban.stellar.org/dapps) repository! This dynamic course is designed for developers interested in building decentralized applications (Dapps) on the Soroban smart contracts platform. It is part challenge, part educational journey, and it aims to provide a practical and creative experience in blockchain development.\n\n## About the Soroban Dapps Challenge\n\nThe Soroban Dapps Challenge allows you to explore the potential of building Dapps on the Soroban platform. While the course specifically focuses on Soroban, the knowledge you gain can be applied to other transaction processors such as different blockchains, L2s, and permissioned ledgers. The skills you acquire are meant to be transferable and versatile.\n\nIn this challenge, you'll gain hands-on experience using Soroban's initial versions of the smart contracts environment, a Rust SDK, a CLI, and an RPC server. You'll learn how to write, test, and deploy smart contracts, and you'll get to see your code in action on our special test network, Futurenet.\n\nEach example dapp is stored in it's own branch. You can find the list of branches [here](https://github.com/stellar/soroban-dapps-challenge/branches). We recommend you start with the [first example](https://github.com/stellar/soroban-dapps-challenge/tree/crowdfund) and work your way through the list.\n\nTo switch to a different branch, run the following command:\n\n```bash\ngit checkout <branch-name>\n```\n\n## What to Expect\n\nWe've designed this course as a learning adventure for developers from the Stellar ecosystem and other blockchain communities to experiment, provide feedback, and contribute to the Soroban development process.\n\nAs you progress through the challenge, anticipate your code to break and updates to shift things. We invite you to experiment and build but also remind you that changes are afoot as we prepare for the production release.\n\n## Giving Your Feedback\n\nWe highly value your input and encourage you to share your feedback. Feel free to file issues in the Soroban repos or raise them in the [`soroban-help`](https://discord.com/channels/897514728459468821/1037073682599780494) channel in the Stellar Developer Discord.\n\n## Conclusion\n\nWe're excited to have you on board and look forward to seeing the incredible Dapps you create during this challenge!\n\n", "release_dates": []}, {"name": "soroban-docs", "description": "Documentation for Soroban", "language": "MDX", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Soroban Documentation and API Reference <!-- omit in toc -->\n\nWelcome to the official home repository for [Documentation] and [API Reference] for the [Soroban] smart contracts platform.\n\n## Table of Contents <!-- omit in toc -->\n\n- [Contributing](#contributing)\n- [Quick Start](#quick-start)\n- [Repository Structure](#repository-structure)\n- [Markdown Basics](#markdown-basics)\n\n## Contributing\n\nContributions are more than welcome! Thank you! \ud83c\udf89\n\nBefore diving in, please read our [Stellar Contribution Guide] for details on\ncontributing to Stellar's various repositories. Please take special note of the\n[code of conduct].\n\nOur documentation site is built using [Docusaurus]. The content is written in\n[MDX], which adds a lot of cool possibilities. Even if you're unfamiliar with\nplain markdown, do not fear! You can still contribute in a helpful and\nmeaningful way. markdown is super easy to learn, and will come quite naturally\nafter only a bit of practice. You can always help fix typos, spelling, and\nbroken links, too.\n\n## Quick Start\n\nTo begin development on the documentation, you will first need [yarn] installed\non your system. Once it is, you can run the following commands:\n\n```bash\ngit clone https://github.com/stellar/soroban-docs\ncd soroban-docs\nyarn install\nyarn start\n```\n\nThis will begin the development server, and open a browser window/tab pointing\nto `http://localhost:3000/docs/`. This development server will auto-reload when\nit detects changes to the repository.\n\nAfter you've made your changes, please use `prettier` to ensure consistent\nformatting throughout the repository:\n\n```bash\nyarn check:mdx # this will search for problems in the MDX files\nyarn format:mdx # this will fix any problems that were found\n```\n\n## Repository Structure\n\n- `/docs/` Contains all the documentation content. If you're contributing to the\n  actual documentation, rather than site functionality, this is likely where you\n  will want to be.\n  - `/docs/<subdirectory>/` Each subdirectory inside the `docs` directory\n    contains content documents relating to a common idea (tutorials, or\n    technical reference for example). There can also be subdirectories nested\n    even further, which will follow the same rules. The location of a document\n    within this directory structure will have a direct impact on the URL given\n    to the document on the site (unless there is metadata or front matter that\n    overrides these defaults.)\n  - `/docs/<subdirectory>/_category_.json` This file contains information that\n    determines the directory's location and position within the site's sidebar.\n  - `/docs/<subdirectory>/<filename>.mdx` The actual documents live in these\n    files (written in markdown), and also contains \"front matter\" which can\n    specify configuration parameter for the document's display, URL, etc. **All\n    filenames must use dashes for spaces instead of spaces or underscores**\n- `/api/` Contains the pages documenting the methods available through the\n  [Soroban RPC] service. The top-level files here are pretty bog-standard\n  markdown files. However, the documentation for each of the available methods\n  is generated from an [OpenRPC specification] file. **This file should not be\n  edited by hand! It's generated from a subset of schema documents. If you find\n  a problem with the specification document, please [create an issue] and we can\n  take care of it as quickly as we can.**\n- `/dapps/` Contains the pages for the [Dapps Challenge] set of exercises and\n  tutorials, as well as other information on tools and techniques for building\n  Dapps using Soroban. Many of these pages rely on several custom React\n  components.\n- `/src/` Contains non-documentation files like custom React components and\n  styling.\n- `/static/` Contains static assets. Anything in this directory will be copied\n  to the root of the final `build` directory.\n- `/nginx/` Contains configuration used to deploy and host the docs site. Unless\n  you're part of Stellar's IT Ops team, you probably don't need to do anything\n  with this. *Exception*:\n  - `/nginx/includes/redirects.conf` Contains redirect rules to avoid broken\n    links. If you find a broken link somewhere out in the wilds of the internet,\n    and there's no way for it to be changed, a redirect could be a useful tool.\n    (Note our aim isn't to *completely* avoid 404 pages for a user. That would\n    be impossible and impractical. These redirects are evaluated on a\n    case-by-case basis, and it may be determined that a redirect isn't the right\n    approach in some instances.)\n\n## Markdown Basics\n\nIf you're unfamiliar with markdown, there are **loads** of good tutorials and\ncheat sheets out there. Check out some of these resources to get a handle on the\nbasics:\n\n- [CommonMark cheat sheet and tutorial]\n- [Interactive markdown tutorial]\n- [The markdown guide]\n\n[Documentation]: https://soroban.stellar.org/docs\n[API Reference]: https://soroban.stellar.org/api\n[Soroban]: https://soroban.stellar.org\n[Stellar Contribution Guide]: https://github.com/stellar/.github/blob/master/CONTRIBUTING.md\n[code of conduct]: https://github.com/stellar/.github/blob/master/CODE_OF_CONDUCT.md\n[Docusaurus]: https://docusaurus.io\n[MDX]: https://mdxjs.com\n[yarn]: https://yarnpkg.com/\n[Soroban RPC]: https://github.com/stellar.org/soroban-rpc/cmd/soroban-rpc\n[OpenRPC specification]: https://github.com/stellar/soroban-docs/blob/main/static/openrpc.json\n[create an issue]: https://github.com/stellar/soroban-docs/issues\n[Dapps Challenge]: https://soroban.stellar.org/dapps\n[CommonMark cheat sheet and tutorial]: https://commonmark.org/help/\n[Interactive markdown tutorial]: https://www.markdowntutorial.com/\n[The markdown guide]: https://www.markdownguide.org/\n", "release_dates": ["2022-09-02T17:38:35Z"]}, {"name": "soroban-example-dapp", "description": "End-to-End Example Soroban Dapp", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "Soroban Crowdfunding Dapp Example\n=================================\n\n![Screenshot of the Example Dapp](screenshot.png)\n\nThis is a [Next.js](https://nextjs.org/) project, demoing how to build a dapp frontend\nbacked by smart contracts on Stellar.\n\nGetting Started\n===============\n\nInstall Dependencies\n--------------------\n1. `rustc` >= 1.71.0 with the `wasm32-unknown-unknown` target installed. See https://soroban.stellar.org/docs/getting-started/setup#install-rust . If you have already a lower version, the easiest way to upgrade is to uninstall (`rustup self uninstall`) and install it again.\n2. `soroban-cli`. See https://soroban.stellar.org/docs/getting-started/setup#install-the-soroban-cli, but instead of `cargo install soroban-cli`, run `cargo install_soroban`. This is an alias set up in [.cargo/config.toml](./.cargo/config.toml), which pins the local soroban-cli to a specific version. If you add `./target/bin/` [to your PATH](https://linuxize.com/post/how-to-add-directory-to-path-in-linux/), then you'll automatically use this version of `soroban-cli` when you're in this directory.\n3. If you want to run everything locally: `docker` (you can run both Standalone and Futurenet backends with it)\n4. Node.js v18\n5. [Freighter Wallet](https://www.freighter.app/) \u2265[v5.0.2](https://github.com/stellar/freighter/releases/tag/2.9.1). Or from the Firefox / Chrome extension store. Once installed, enable \"Experimental Mode\" in the settings (gear icon).\n6. If you want to skip step (1) and (2) and avoid installing specific `rustc` or `soroban-cli` versions, build the `soroban-preview` docker image:\n\n       make build-docker\n\n\n7. **NOTE** - Follow the instructions below for Futurenet or Standalone and ensure that you have funded your wallet address that you intend to use from browser, otherwise the dapp display will be blank and a 'Account not found' will be printed on browser's console only.    \n\nRun Backend\n-----------\n\nMake sure to start from a clean setup:\n```\nnpm run clean\n```\n\nYou have three options: 1. Deploy on [Futurenet](https://soroban.stellar.org/docs/getting-started/deploy-to-futurenet) using a remote [RPC](https://soroban.stellar.org/docs/getting-started/run-rpc) endpoint, 2. Run your own Futerenet RPC node with Docker and deploy to it, 3. run in [localnet/standalone](https://soroban.stellar.org/docs/getting-started/deploy-to-a-local-network) mode.\n\n### Option 1: Deploy on Futurenet\n\n0. Make sure you have soroban-cli installed, as explained above\n\n1. Deploy the contracts and initialize them\n\n       npm run setup\n\n   This runs `./initialize.sh futurenet` behind the scenes, which will create a `token-admin` identity for you (`soroban config identity create token-admin`) and deploy a Fungible Token contract as well as the [crowdfund contract](./contracts/crowdfund), with this account as admin.\n\n2. Select the Futurenet network in your Freighter browser extension\n\n### Option 2: Run your own Futurenet node\n\n1. Run the backend docker container with `./quickstart.sh futurenet`, and wait for it to start.\n\n   **Note:** This can take up to 5 minutes to start syncing. You can tell it is\n   working by visiting http://localhost:8000/, and look at the\n   `ingest_latest_ledger`, field. If it is `0`, the quickstart image is not ready yet. The quickstart container also prints console statements on start status, it will print `soroban rpc: waiting for ready state...` at first and then `soroban rpc: up and ready` when network sync has been reached.\n\n2. Load the contracts and initialize them\n\n   Use your own local soroban-cli:\n\n       ./initialize.sh futurenet http://localhost:8000\n\n   Or run it inside the soroban-preview docker container:\n\n       docker exec soroban-preview ./initialize.sh futurenet\n\n3. Add the Futurenet custom network in Freighter (Note, the out-of-the-box\n   \"Future Net\" network in Freighter will not work with a local quickstart\n   container, so we need to add our own):\n\n   |   |   |\n   |---|---|\n   | Name | Futurenet Local RPC|\n   | URL | http://localhost:8000/soroban/rpc |\n   | Passphrase | Test SDF Future Network ; October 2022 |\n   | Allow HTTP connection | Enabled |\n   | Switch to this network | Enabled |\n\n4. Add some Futurenet network lumens to your Freighter wallet.\n\n   Visit https://laboratory.stellar.org/#create-account, and follow the instructions to create your freighter account on Futurenet.\n\n### Option 3: Localnet/Standalone\n\n0. If you didn't yet, build the `soroban-preview` docker image, as described above:\n\n       make build-docker\n\n1. In one terminal, run the backend docker containers and wait for them to start:\n\n       ./quickstart.sh standalone\n\n   You know that it fully started if it goes into a loop publishing & syncing checkpoints.\n\n   You can stop this process with <kbd>ctrl</kbd><kbd>c</kbd>\n\n2. Keep that running, then deploy the contracts and initialize them:\n\n   You can use your own local soroban-cli:\n\n       NETWORK=standalone npm run setup\n\n   Or run it inside the soroban-preview docker container:\n\n       docker exec soroban-preview ./initialize.sh standalone\n\n   **Note:** this state will be lost if the quickstart docker container is removed, which will happen if you stop the `quickstart.sh` process. You will need to re-run `./initialize.sh` every time you restart the container.\n\n3. Add the Standalone custom network in Freighter\n\n   |   |   |\n   |---|---|\n   | Name | Standalone |\n   | URL | http://localhost:8000/soroban/rpc |\n   | Passphrase | Standalone Network ; February 2017 |\n   | Allow HTTP connection | Enabled |\n   | Switch to this network | Enabled |\n\n4. Add some Standalone network lumens to your Freighter wallet.\n\n   1. Copy the address for your freighter wallet.\n   2. Visit `http://localhost:8000/friendbot?addr=<your address>`\n\n\nFrontend\n--------\n\nNow that you're running the backend, you can run the development server:\n\n    npm run dev\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\n**Note:** Before you can \"Back this project\", you'll need to have some EXT (example\ntoken) in your freighter wallet. There is a \"Mint 100 EXT\" button, which will\ngift you 100 EXT tokens for that purpose.\n\nUser Workflows\n==============\n\nThe contract dev should be able to:\n\n- Clone the example repo (this one)\n- Choose their target amount and deadline\n- Deploy their contract to futurenet\n- Deploy a soroban rpc server somewhere (TBD)\n- Deploy the example web ui somewhere (e.g. netlify)\n\nThen via the web UI, users should be able to:\n\n- Connect their wallet (freighter for now)\n- See their current balance(s)\n- See the current fundraising status (total amount & time remaining)\n- See allowed assets (xlm-only for now?)\n- Deposit an allowed asset\n- See their deposit(s) appear on the page as the transactions are confirmed.\n- \"Live\"-Update the page with the total amount with the new amount\n", "release_dates": []}, {"name": "soroban-examples", "description": "Example Soroban Contracts", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# soroban-examples <!-- omit in toc -->\n\nExample contracts for Soroban.\n\nFollow along with [The Documentation](https://soroban.stellar.org/docs/).\n\nOpen a development environment on GitPod:\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/stellar/soroban-examples)\n\nWARNING: These implementations have not been tested or audited. They are likely\nto have significant errors and security vulnerabilities. They should not be\nrelied on for any purpose.\n\nJoin us In the [Stellar Developers Discord server](https://discord.gg/stellardev)\n", "release_dates": ["2024-01-19T23:07:46Z", "2023-12-08T00:58:44Z", "2023-09-19T16:17:35Z", "2023-07-13T18:24:04Z", "2023-05-24T19:34:03Z", "2023-05-18T16:07:58Z", "2023-04-03T23:51:10Z", "2023-02-15T17:54:51Z", "2023-01-09T17:12:28Z", "2023-01-06T17:28:50Z", "2022-12-08T19:41:13Z", "2022-12-06T22:44:04Z", "2022-11-11T04:09:37Z", "2022-10-28T04:25:07Z", "2022-10-11T15:19:03Z", "2022-09-02T16:28:07Z"]}, {"name": "soroban-name-service", "description": "Soroban name service", "language": "Rust", "license": null, "readme": "***This is an experimental project. It may contain bugs or security issues***\n\n## How to run\nRust is not required to be installed in the system. You will need [nix](https://nixos.org/download.html) installed.  \nTo run development shell simply run `nix develop`. Cargo and rust are available inside this shell.  \nTo make a build run `nix build`. It will create a release wasm file in `result/lib`.  \n### Using soroban-cli\nCurrently, soroban-cli is not accessible in dev shell by default. You will need to install it manually via running in dev shell\n`cargo install --locked --version 0.4.0 soroban-cli`. \nNote, that it won't be managed by nix (i.e. it's installed into ~/.cargo/bin/soroban). Adding soroban-cli into your home directory. \n### Using IDE\nWhen using IDE, it's recommended to run it from dev shell. Rust and cargo are in $PATH, so your IDE should be able to pick it up\nand work normally. If it doesn't, you can get location of rustc via `which rustc` command inside devshell.\n", "release_dates": []}, {"name": "soroban-quest", "description": "Soroban Quest is a gamified educational course where you\u2019ll learn Soroban and earn rewards!", "language": "Rust", "license": null, "readme": "# Soroban Quest <!-- omit in toc -->\n\n![Stellar-Quest-email][series-5-img]\n\n[![Open in Gitpod][gp-btn]][gitpod]\n\n## Table of Contents <!-- omit in toc -->\n\n- [Welcome](#welcome)\n- [Feeling Lost?](#feeling-lost)\n  - [Re-Visit the Pioneer Quest](#re-visit-the-pioneer-quest)\n- [Join us on Discord](#join-us-on-discord)\n\n## Welcome\n\nWelcome to our Soroban Quest! We are beyond excited you've joined us. We've\nworked hard to make this a productive, interesting, and above all fun learning\nexperience for you!\n\nSo let's have some fun!\n\n## Feeling Lost?\n\nThere's a lot going on here! If you're feeling confused, or you're not sure how\nthis whole thing is supposed to work, don't fret. We have a couple options for\nyou:\n\n### Re-Visit the Pioneer Quest\n\nplease checkout our [pioneer quest][pioneer]. It covers the basic structure of\nthis repository, all the tools you'll need, and the process of getting\neverything working together.\n\nIt's an important resource to keep handy during all these live quests. Some of\nthe most important bits you'll need to know from it:\n\n- Understanding what a \"Gitpod workspace\" even is, and how we've set it up for\n  you to successfully complete these quests.\n- Using the `sq` CLI to login to your Stellar Quest account, play quests, verify\n  them, and more.\n- Interacting with a Soroban sandbox, as well as the Futurenet, from within this\n  gitpod workspace.\n\nIf you feel lost on any of that, you could probably use a refresher. Go ahead,\n[be a pioneer][pioneer] once more. We don't judge!\n\n## Join us on Discord\n\nIn the [Stellar Developers Discord server][dev-discord], you will find a large,\nactive, and helpful community! We have recently announced a $100M Soroban\nAdoption Fund, which SDF created to support the growth and development of the\nSoroban ecosystem. We'll be sharing more about additional programs on the\nStellar Dev Discord in the not-too-distant future, so make sure to join today to\nbe the among the first to hear those announcements. This is yet another way for\nyou to **Tinker and Earn** XLM with Soroban! Many of the people who are\n_creating_ the Soroban platform are there, and willing to answer questions, too!\nTalk about \"straight from the horse's mouth\"!!\n\n[![Open in Gitpod][gp-btn]][gitpod]\n\n[series-5-img]: https://user-images.githubusercontent.com/4383610/200077219-de8e1f20-9878-4705-bec6-ced9a3904694.jpg\n[gp-btn]: https://gitpod.io/button/open-in-gitpod.svg\n[gitpod]: https://gitpod.io/#ENV=prod/https://github.com/stellar/soroban-quest\n[pioneer]: https://github.com/stellar/soroban-quest--pioneer\n[dev-discord]: https://discord.gg/stellardev\n", "release_dates": []}, {"name": "soroban-quest--pioneer", "description": "Soroban Quest is a gamified educational course where you\u2019ll learn Soroban and earn rewards!", "language": "TypeScript", "license": null, "readme": "# Soroban Pioneer Quest <!-- omit in toc -->\n\n![Stellar-Quest-email](https://user-images.githubusercontent.com/4383610/200077219-de8e1f20-9878-4705-bec6-ced9a3904694.jpg)\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)][gitpod]\n\n## Table of Contents <!-- omit in toc -->\n\n- [Welcome](#welcome)\n- [Video Walkthrough](#video-walkthrough)\n- [Gitpod](#gitpod)\n  - [VS Code](#vs-code)\n  - [Terminal and Ports](#terminal-and-ports)\n  - [Docker Container'd](#docker-containerd)\n  - [Gitpod CLI](#gitpod-cli)\n- [Stellar Quest CLI](#stellar-quest-cli)\n- [Rust Environment](#rust-environment)\n- [Soroban CLI](#soroban-cli)\n- [Testnet](#testnet)\n- [Good Luck](#good-luck)\n- [Join us on Discord](#join-us-on-discord)\n\n## Welcome\n\nWelcome to the Pioneer Quest for our upcoming Soroban Quest! We are beyond\nexcited you've joined us. These quests are going to be fun, exciting, and\n_interesting_ to be sure! There's a lot to go through so you are up to speed, so\nlet's jump in!\n\n## Video Walkthrough\n\nThe rest of this README is quite heavily skewed toward written information.\nThat's not everybody's primary way of learning, so we've created a video\nwalkthrough you can check out, as well. It doesn't contain everything in this\nREADME, but it's a start. If that kind of content sounds like it's more up your\nalley, you can [watch the video right here][video]!\n\n[![Soroban Pioneer Quest Walkthrough][thumbnail]][video]\n\n## Gitpod\n\nYou are reading this _from inside_ a Gitpod development environment. You heard\nright! A freshly baked, automated environment built just for you! A couple\nthings you should know about Gitpod:\n\n### VS Code\n\nGitpod is built around a fully-functional copy of the VS Code IDE. Entirely in\nyour browser! All the things you can do in the local version of VS Code, you can\ndo here. Just about any extension you have in your local copy you can install\nhere. You get the idea.\n\n### Terminal and Ports\n\nIn your Gitpod workspace, you'll notice a panel at the bottom that is open to a\nfew terminal shells. There are a few methods to show/hide this panel, but my\nfavorite is the ``Ctrl + ` `` keyboard shortcut. There is a lot of information\nin the [VS Code docs][vsc-docs] about how to use these integrated terminals.\n\nThis panel will actually be pretty important to your questing success, so let's\ntake a second to examine this a bit more in-depth.\n\n![Terminal Panel][terminals]\n\n#### **Terminals** <!-- omit in toc -->\n\nOn the right-hand side of this panel, you'll notice there are 4 (four) shells\nopen. Each of them is designed for a specific purpose:\n\n- `Albedo Signer` - A simple webapp that facilitates claiming rewards for\n  completed quests. (You won't be required to actually _do_ anything in this\n  shell.)\n- `Testnet: docker` - An instance of the Testnet node that is running inside\n  your Gitpod workspace. (You won't be required to actually _do_ anything in\n  this shell either.)\n- `CLI - Testnet` - This shell is designed for interacting with the Testnet\n  network. It has some environment variables customized for this purpose, and\n  will make it easier and quicker for you to work with the network. When we say\n  something like \"you need to deploy a contract to the Testnet,\" you'll want\n  to do that from this shell.\n\nAbove this list of terminals, you could use the **+** icon to open another\nterminal, if you closed one of yours.\n\n#### **Ports** <!-- omit in toc -->\n\nThere are also a couple open ports that can be useful during your quests. You\ncan see these ports by clicking on **Ports** in the top part of the terminal\npanel (see above screenshot). You could also click on **Ports: 8000, 3000** in\nthe lower-right-hand corner of the Gitpod workspace (see below screenshot).\n\n- **Port 3000** - You can ignore the **Albedo Signer** port. That's open so we\n  can use it along with the `sq` CLI to get your earned rewards to you.\n- **Port 8000** - On port 8000 of your Gitpod workspace lives various tools to\n  interact with the Testnet network. There is a running instance of JSON-RPC\n  (which you will need to use) and a Horizon API server (which can be _very_\n  useful).\n\nBoth of these ports are publicly available on the web, at the listed addresses.\nYou could even use this RPC endpoint to interact with the Testnet network from\nyour local computer!\n\n![Open Gitpod Ports][ports]\n\n### Docker Container'd\n\nThat's right, Gitpod is running on a Docker-ized container so that we can be\ncertain _your_ setup for these Soroban Quests is **exactly** the same as _our_\nsetup! We have a few tasks configured to run on your Gitpod's startup. They're\nbriefly explained below, but you can also read through `.gitpod.yml` and\n`.gitpod.Dockerfile` to get a sense of what is happening during the build\nprocess.\n\n### Gitpod CLI\n\nGitpod has its very own CLI that you can use to manage a running Gitpod\nworkspace. It's got loads of useful features, and tons of ways you can use it.\nPreat neat, huh!? You can [learn all about it here][gp-cli]!\n\n## Stellar Quest CLI\n\nWould you belive that we've made, specifically for our Soroban Quest, a Stellar\nQuest CLI?! No joke! It's _super awesome_, and **absolutely essential** for you\nto understand, if you want to succeed in this live series. It's (awesomely)\ncalled \"Squirtle\" but you'll become more familiar with invoking it as `sq`. The\ncode for it lives in the `_squirtle/` directory, but you won't need to bother\nwith anything in there.\n\nIt exists as a command line tool that can connect your Gitpod instance with the\nSQ backend. You can use it to:\n\n- login to your Stellar Quest account using Discord (or logout),\n- get information about the currently logged in user,\n- visit the Stellar Quest website,\n- fetch new quests when they become available,\n- generate a keypair to play a particular quest,\n- fund Quest Keypairs on the Testnet,\n- check and/or verify the quests you've completed,\n- get rewards for completing quests successfully\n\nYou can invoke `sq` from within any of the bash shells in this Gitpod workspace.\nThe output of `sq --help` is shown below, for your convenience. You can also\ninvoke `sq <command> --help` to get more information on how to use a particular\ncommand.\n\n```bash\n$ sq help\nsq\n\nCommands:\n  sq login          Connect your Stellar Quest account to Gitpod\n  sq logout         Disconnect your Stellar Quest account from Gitpod\n  sq user           Print out information about yourself           [aliases: me]\n  sq open           Open the Stellar Quest website\n  sq pull           Pull any new or missing Quests into the /quests directory\n  sq play [index]   Generate a Quest Keypair to play a Quest\n  sq fund [key]     Create and fund an account on the Testnet\n  sq check [index]  Check your Quest answer\n  sq submit [xdr]   Submit a signed reward XDR to the Stellar Quest backend\n  sq rpc            Check the status of your local RPC endpoint\n                                                              [aliases: horizon]\n  sq                                                                   [default]\n\nOptions:\n      --version  Show version number                                   [boolean]\n  -h, --help     Show help                                             [boolean]\n```\n\n## Rust Environment\n\nCrucially toward the goal of writing smart contracts for Soroban, your workspace\ncontains a fully configured, ready to go Rust development environment. We have\nall the tooling, compilers, build processes, and anything else you'll need to\nhit the ground running. This includes:\n\n- A specified version of the [Rust][rust] programming language\n- This pre-configured [VS Code][vscode] editor, with some essential extensions\n- The [Cargo][cargo] package manager for Rust crates\n- The `wasm32-unknown-unknown` target for compiling your contracts\n\nYou have enough pre-installed to write, debug, test, build, and deploy Soroban\nsmart contracts from right within this Gitpod workspace. We even have an example\ncontract ready for you to look through in the `quests/0-hello-world/` directory.\n\n## Soroban CLI\n\nYour workspace includes the Soroban CLI, as well. The Soroban CLI is an\nessential tool to interact with Soroban's JSON-RPC servers and execute smart\ncontracts on the network. You can always find the latest about the [Soroban CLI\nhere][soroban-cli]!\n\n## Testnet\n\nDid you know you have access to a Stellar network node right now!? Yeah, right\nhere in your browser, in this workspace there's a Stellar node connected to the\n\"Testnet\" testing network. We've taken care of all the work so you don't have\nto worry about docker images, starting the service, or anything besides learning\nto make contracts!\n\nThis will come in very handy when you are ready to deploy and share your\ncontracts.\n\n## Good Luck\n\nNow that you're (at least somewhat) familiar with the lay of the land, you're\nready to get questing! Open up that Gitpod, and get to work! Most importantly,\nhave fun!!\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)][gitpod]\n\n## Join us on Discord\n\nIn the [Stellar Developers Discord server][dev-discord], you will find a large,\nactive, and helpful community! We have recently announced a $100M Soroban\nAdoption Fund, which SDF created to support the growth and development of the\nSoroban ecosystem. We'll be sharing more about additional programs on the\nStellar Dev Discord in the not-too-distant future, so make sure to join today to\nbe the among the first to hear those announcements. This is yet another way for\nyou to **Tinker and Earn** XLM with Soroban! Many of the people who are\n_creating_ the Soroban platform are there, and willing to answer questions, too!\nTalk about \"straight from the horse's mouth\"!!\n\n[gitpod]: https://gitpod.io/#ENV=prod/https://github.com/stellar/soroban-quest--pioneer\n[gp-cli]: https://www.gitpod.io/docs/configure/workspaces/gitpod-cli\n[rust]: https://www.rust-lang.org/\n[cargo]: https://doc.rust-lang.org/cargo/\n[vscode]: https://code.visualstudio.com/\n[soroban-cli]: https://soroban.stellar.org/docs/reference/soroban-cli\n[video]: https://youtu.be/6_tgpth6U5Y\n[thumbnail]: https://user-images.githubusercontent.com/2024293/201189898-dd9ae16e-698c-4b2d-b442-fec7d7222f3f.jpg\n[terminals]: https://user-images.githubusercontent.com/2024293/201201300-f86bbc98-6c0a-4189-b92c-fe4145c95f0d.png\n[vsc-docs]: https://code.visualstudio.com/docs/terminal/basics\n[ports]: https://user-images.githubusercontent.com/2024293/201206484-f69f9123-3550-49be-97f2-f6f39fe9aa2f.png\n[dev-discord]: https://discord.gg/stellardev\n", "release_dates": []}, {"name": "soroban-react-atomic-swap", "description": "A react demo dapp for making an atomic swap on Soroban", "language": "TypeScript", "license": null, "readme": "# Soroban React Atomic Swap\n\nThe Atomic Swap DApp is a simplified demo of a dapp that performs an atomic\noperation to swap 2 potentially different amounts of 2 tokens between 2 separate\nparties, optionally signed and submitted by a third party.\n\n## Prerequisites\n\nThe Atomic Swap DApp relies on the following dependencies:\n\n- Node (>=16.14.0 <=18.0.0): https://nodejs.org/en/download/\n\n- Yarn (v1.22.5 or newer): https://classic.yarnpkg.com/en/docs/install\n\n- Freighter wallet(v5.0 or newer): https://www.freighter.app/\n\nYou need access to/funds from the following contracts - Atomic Swap:\nhttps://github.com/stellar/soroban-examples/tree/main/atomic_swap Token:\nhttps://github.com/stellar/soroban-examples/tree/main/token\n\nThis demo involves a minimum of 2 parties and 2 different tokens to swap between\nthe parties.\n\n## Features\n\nThe Atomic Swap DApp offers the following features:\n\n1. **Freighter Wallet Integration**: The Atomic Swap DApp seamlessly integrates\n   with Freighter/Albedo/XBull, allowing users to connect their wallet to access\n   Soroban token balances and utilize their signing capabilities for secure and\n   integrity-checked transactions.\n\n2. **Transaction Construction**: Leveraging the Soroban atomic swap contract\n   interface, the DApp constructs transactions that invoke the `swap` method of\n   the\n   [swap interface](https://github.com/stellar/soroban-examples/blob/main/atomic_swap/src/lib.rs#L16).\n   This method facilitates an atomic swap operation on the Soroban network.\n\n## Getting Started\n\nTo use the Atomic Swap DApp, follow these steps:\n\n1. Install and set up one of the supported wallets.\n\n- [Freighter wallet](https://www.freighter.app/)\n- [Albedo wallet](https://albedo.link/install-extension)\n- [XBull wallet](https://xbull.app/)\n\n2. Clone and navigate into the\n   [Atomic Swap DApp repository](https://github.com/stellar/soroban-react-atomic-swap/tree/main)\n   by running the following:\n\n   ```\n   git clone https://github.com/stellar/soroban-react-atomic-swap.git\n   cd soroban-react-atomic-swap\n   ```\n\n3. Install the dependencies by running the following:\n\n   ```\n   yarn\n   ```\n\n4. Deploy the Atomic Swap smart contracts.\n\nFor this step you will need to clone and deploy the\n[Atomic Swap smart contract](https://github.com/stellar/soroban-examples/blob/main/atomic_swap/src/lib.rs).\nThe Atomic Swap smart contract is a custom contract that will be used to\nfacilitate swaps in the Atomic Swap Dapp.\n\nIn a new terminal window, follow the steps below to build and deploy the smart\ncontracts:\n\n```bash\ngit clone https://github.com/stellar/soroban-examples.git\ncd soroban-examples/atomic_swap\nmake\n```\n\nThis will build the smart contracts and put them in the\n`atomic_swap/target/wasm32-unknown-unknown/release` directory.\n\nNext, you will need to deploy the smart contracts to Futurenet. To do this, open\na terminal in the `soroban-examples/atomic_swap` directory and follow the steps\nbelow:\n\n```bash\nsoroban contract deploy \\\n    --wasm target/wasm32-unknown-unknown/release/soroban_atomic_swap_contract.wasm \\\n    --source <ADMIN_ACCOUNT_SECRET_KEY> \\\n    --rpc-url https://rpc-futurenet.stellar.org:443 \\\n    --network-passphrase 'Test SDF Future Network ; October 2022'\n```\n\nThis will return a contract id that we will need to use later on.\n\n```bash\n# Example output used for ATOMIC_SWAP_CONTRACT_ID\nCCWXGZ6PCOORP7UKO2GVYS5PFYR4BND4XDYTQMO2B32SKXVX4DUKUUZ6\n```\n\n## Token Setup\n\nThere are two options for setting up tokens for the Atomic Swap Dapp:\n\n#### 1. Use the Token Minter Dapp\n\nThe Token Minter Dapp provides an easy-to-use interface for minting tokens on\nSoroban. For step-by-step guidance on how to use the dapp, you can watch the\nvideo tutorial available in the release notes for the Token Minter Dapp,\n[here](https://github.com/stellar/soroban-react-mint-token/releases/tag/v1.0.0).\n\n#### 2. Use the Soroban CLI.\n\nYou can also use the Soroban CLI to deploy and mint tokens. To do this, follow\nthe steps below:\n\nFor this step you will need to clone and deploy the\n[Soroban token smart contracts](https://github.com/stellar/soroban-examples/blob/main/token/src/contract.rs).\nThe Soroban tokens are custom tokens that will be swapped in the Atomic Swap\nDapp.\n\nOpen a new terminal window in the `soroban-examples` directory and follow the\nsteps below to build and deploy the smart contracts:\n\n```bash\ncd token\nmake\n```\n\nThis will build the smart contracts and put them in the\n`token/target/wasm32-unknown-unknown/release` directory.\n\nNext, you will need to deploy the smart contracts to Futurenet. To do this,\nfollow the steps below:\n\n```bash\nsoroban contract deploy \\\n    --wasm target/wasm32-unknown-unknown/release/soroban_token_contract.wasm \\\n    --source <ADMIN_ACCOUNT_SECRET_KEY> \\\n    --rpc-url https://rpc-futurenet.stellar.org:443 \\\n    --network-passphrase 'Test SDF Future Network ; October 2022'\n```\n\nThis will return a contract id that we will need to use later on.\n\n```bash\n# Example output used for TOKEN_A_CONTRACT_ID\nCCZZ763JDLSHEXUFUIHIKOVAAKYU2CUXSUH5MP4MH2HDZYGOYMM3RDD5\n```\n\n```bash\nsoroban contract invoke \\\n    --id <TOKEN_A_CONTRACT_ID> \\\n    --source-account <ADMIN_ACCOUNT_SECRET_KEY> \\\n    --rpc-url https://rpc-futurenet.stellar.org:443 \\\n    --network-passphrase 'Test SDF Future Network ; October 2022' \\\n    -- initialize \\\n    --admin <ADMIN_PUBLIC_KEY> \\\n    --decimal 7 \\\n    --name \"Demo Token A\" \\\n    --symbol \"DTA\"\n```\n\nNext we will need to mint some tokens to two user account. To do this, run the\nfollowing command:\n\n```bash\nsoroban contract invoke \\\n    --id <TOKEN_A_CONTRACT_ID> \\\n    --source-account <ADMIN_ACCOUNT_SECRET_KEY> \\\n    --rpc-url https://rpc-futurenet.stellar.org:443 \\\n    --network-passphrase 'Test SDF Future Network ; October 2022' \\\n    -- mint \\\n    --to <USER_A_OR_B_PUBLIC_KEY> \\\n    --amount 1000000000\n```\n\nRemember: You'll be deploying, initializing token contract twice, once for each\ntoken involved in the swap so make sure to store both Contract Ids. You will\nmint tokens to both users' accounts for each token contract.\n\nAfter deploying and minting the first token contract using the steps outlined\nabove, simply repeat the process for the second token.\n\n_See the example below for initializing and minting the second token contract_\n\n**_Initialize_**\n\n```bash\nsoroban contract invoke \\\n    --id <TOKEN_B_CONTRACT_ID> \\\n    --source-account <ADMIN_ACCOUNT_SECRET_KEY> \\\n    --rpc-url https://rpc-futurenet.stellar.org:443 \\\n    --network-passphrase 'Test SDF Future Network ; October 2022' \\\n    -- initialize \\\n    --admin <ADMIN_PUBLIC_KEY> \\\n    --decimal 7 \\\n    --name \"Demo Token B\" \\\n    --symbol \"DTB\"\n```\n\n**_Mint_**\n\n```bash\nsoroban contract invoke \\\n    --id <TOKEN_B_CONTRACT_ID> \\\n    --source-account <ADMIN_ACCOUNT_SECRET_KEY> \\\n    --rpc-url https://rpc-futurenet.stellar.org:443 \\\n    --network-passphrase 'Test SDF Future Network ; October 2022' \\\n    -- mint \\\n    --to <USER_A_OR_B_PUBLIC_KEY> \\\n    --amount 1000000000\n```\n\n## Run the Dapp\n\nOnce you have deployed the Atomic Swap and Token contracts, you can run the dapp\nlocally by following the steps below:\n\n1. [Enable and add Soroban Tokens](https://soroban.stellar.org/docs/reference/freighter#enable-soroban-tokens)\n   in Freighter.\n\n2. In the `soroban-react-atomic-swap` directory run the front end with\n   `yarn start` and navigate to http://localhost:9000/ in your browser.\n\n## Make a Swap\n\nNow that you have the Atomic Swap Dapp running locally, you can make a swap!\n\n1. Connect your wallet to the Atomic Swap Dapp by clicking the \"Connect Wallet\"\n   button. This will open a Freighter/Albedo/XBull window where you can select\n   your account to connect to the Dapp.\n\n<img src = \"public/img/1-connect-wallet-a.png\" width=\"40%\" height=\"40%\"/>\n\nYou should see your account address in the top right corner of the screen.\n\n<img src = \"public/img/2-show-address.png\" width=\"85%\" height=\"85%\"/>\n\n2. Enter the contract id for the Atomic Swap.\n\n<img src = \"public/img/3-swap-contract-id.png\" width=\"40%\" height=\"40%\"/>\n\n3. Enter the contract id and amount for Token A you want to swap.\n\n<img src = \"public/img/4-token-a.png\" width=\"40%\" height=\"40%\"/>\n\nIn this example we will swap 1 of Token A for 5 of Token B.\n\n4. Enter Swapper B's public key and the contract id and amount for Token B you\n   want to swap.\n\n<img src = \"public/img/5-token-b.png\" width=\"40%\" height=\"40%\"/>\n\nIn this example we will swap 5 of Token B for 1 of Token A.\n\n5. Click the \"Build Swap\" button to initiate the swap.\n\n<img src = \"public/img/6-build-swap.png\" width=\"40%\" height=\"40%\"/>\n\nThis will open a another window in your browser where you will be prompted to\nsign the transaction with user A's and user B's accounts.\n\n<img src = \"public/img/7-windows.png\" width=\"85%\" height=\"85%\"/>\n\n6. Click the \"Connect Wallet\" button in the new window to connect user A's\n   account to the Dapp.\n\n7. Click the \"Sign with Wallet\" button to sign the transaction with user A's\n   account.\n\n<img src = \"public/img/8-sign-with-a.png\" width=\"40%\" height=\"40%\"/>\n\n> **Note:** When using the address of the account that initiated the swap, you\n> may not see a window for signing the transaction. This is due to two options\n> for satisfying contract authentication when required by the contract:\n>\n> 1. The user can sign the authentication entry, or\n> 2. The user can use \"invoker auth\" by also being the user who signs the\n>    transaction itself.\n>\n> If the address required for signing contract authentication is also the source\n> account of the transaction in question, it implicitly allows the user to\n> bypass signing the authentication entry. In this case, the signature from the\n> transaction itself is used instead of the signature on the authentication\n> entry.\n\n8. Switch to user B's account in Freighter/Albedo/XBull and click the \"Connect\n   Wallet\" button in the new window to connect user B's account to the Dapp.\n\n9. Click the \"Sign with Wallet\" button to sign the transaction with user B's\n   account. This will authorize the swap and display a success message.\n\n<img src = \"public/img/11-authorized.png\" width=\"40%\" height=\"40%\"/>\n\n10. Switch back to previous tab and click the \"Sign with Wallet & Sumbit\" button\n    to submit the swap to the network.\n\n<img src = \"public/img/12-submit-tx.png\" width=\"40%\" height=\"40%\"/>\n\n11. You should see a \"Transaction Result\" message and the swap should be\n    complete!\n\n<img src = \"public/img/13-tx-result.png\" width=\"40%\" height=\"40%\"/>\n\nCongratulations! You have successfully completed an Atomic Swap using Soroban!\n\ud83c\udf89\n\nIf you have any questions or issues, please reach out to us on\n[discord](https://discord.com/channels/897514728459468821/1037073682599780494)\nor file an issue on github.\n", "release_dates": ["2023-09-25T21:00:13Z", "2023-08-07T18:19:40Z"]}, {"name": "soroban-react-mint-token", "description": "An example dapp for minting tokens on Soroban", "language": "TypeScript", "license": null, "readme": "# Soroban React Mint Token\n\nThis serves as a basic example of how a token administrator can mint more tokens\non Soroban.\n\nYou can explore this dapp at https://scaffold-soroban.stellar.org/ by choosing\nmint-token from the \"select demo\" dropdown.\n\n## Prerequisites\n\nThe Mint Token DApp relies on the following dependencies:\n\n- Node (>=16.14.0 <=18.0.0): https://nodejs.org/en/download/\n\n- Yarn (v1.22.5 or newer): https://classic.yarnpkg.com/en/docs/install\n\n- Freighter wallet(v5.0 or newer): https://www.freighter.app/\n\n## Features\n\nThe Mint Token DApp offers the following features:\n\n1. **Freighter Wallet Integration**: The Mint Token DApp seamlessly integrates\n   with Freighter/Albedo/XBull, allowing users to connect their wallet to access\n   Soroban token balances and utilize their signing capabilities for\n   secure and integrity-checked transactions.\n\n2. **Transaction Construction**: Leveraging the Soroban token's contract\n   interface, the DApp constructs transactions that invoke the `mint`\n   method. This method facilitates the minting of new tokens to an address.\n\n## Getting Started\n\nTo use the Mint Token DApp, follow these steps:\n\n1. Install and set up one of the supported wallets.\n\n- [Freighter wallet](https://www.freighter.app/)\n- [Albedo wallet](https://albedo.link/install-extension)\n- [XBull wallet](https://xbull.app/)\n\n2. Clone and navigate into the\n   [Mint Token DApp repository](https://github.com/stellar/soroban-react-mint-token/tree/main)\n   by trunning the following:\n\n   ```\n   git clone https://github.com/stellar/soroban-react-mint-token.git\n   cd soroban-react-mint-token\n   ```\n\n3. Install the dependencies by running the following:\n\n   ```\n   yarn\n   ```\n\n4. If you are using the Freighter wallet, ensure that experimental mode\n   is enabled. You can find this setting in Freighter wallet at:\n   _`Settings(\u2699\ufe0f)>Preferences>ENABLE EXPERIMENTAL MODE`_.\n\n<img src = \"./public/img/freighter_settings.png\" width=\"50%\" height=\"50%\"/>\n\n6. [Enable and add Soroban Tokens](https://soroban.stellar.org/docs/getting-started/connect-freighter-wallet#enable-soroban-tokens)\n   in Freighter.\n\n7. Connect the dapp to Freighter.\n\n<img src = \"./public/img/connect.png\" width=\"50%\" height=\"50%\"/>\n\n8. Add the public key for the account that will receive the newly minted tokens.\n\n<img src = \"./public/img/add-dest.png\" width=\"50%\" height=\"50%\"/>\n\n9. Add the contract ID for the token that you will be minting, and add the quantity of new tokens to mint.\n\n<img src = \"./public/img/add-token.png\" width=\"50%\" height=\"50%\"/>\n<br/>\n<img src = \"./public/img/set-quantity.png\" width=\"50%\" height=\"50%\"/>\n\n10. Set the desired transaction fee & memo.\n\n<img src = \"./public/img/set-fee-memo.png\" width=\"50%\" height=\"50%\"/>\n\n11. Confirm your transaction parameters, and submit it to the network.\n\n<img src = \"./public/img/confirm-tx.png\" width=\"50%\" height=\"50%\"/>\n<br/>\n<img src = \"./public/img/submit-tx.png\" width=\"50%\" height=\"50%\"/>\n\n12. View your transaction's result XDR and optionally start the mint flow over.\n\n<img src = \"./public/img/tx-result.png\" width=\"50%\" height=\"50%\"/>\n\n## Build the Project\n\n```\nyarn && yarn build\n```\n\n## Starting a Dev Environment\n\n```\nyarn && yarn start\n```\n\n## Contributions\n\nContributions to the Mint Token DApp are welcome. If you encounter any issues, have\nsuggestions for improvements, or would like to contribute to the codebase,\nplease submit an issue, pull request, or reach out to us on\n[Discord](https://discord.com/channels/897514728459468821/1037073682599780494).", "release_dates": ["2023-12-19T19:22:42Z", "2023-09-25T20:59:53Z", "2023-07-18T01:43:39Z", "2023-06-16T18:10:33Z"]}, {"name": "soroban-react-payment", "description": "Soroban example dapps", "language": "TypeScript", "license": null, "readme": "# Soroban React Payment\n\nThe Payment DApp is an easy to use application designed to mirror the Soroban\npayment flow currently found in Freighter.\n\nYou can explore this dapp at https://scaffold-soroban.stellar.org/ by choosing\npayment from the \"select demo\" dropdown.\n\n## Prerequisites\n\nThe Payment DApp relies on the following dependencies:\n\n- Node (>=16.14.0 <=18.0.0): https://nodejs.org/en/download/\n\n- Yarn (v1.22.5 or newer): https://classic.yarnpkg.com/en/docs/install\n\n- Freighter wallet(v5.0 or newer): https://www.freighter.app/\n\n## Features\n\nThe Payment DApp offers the following features:\n\n1. **Freighter Wallet Integration**: The Payment DApp seamlessly integrates with\n   Freighter/Albedo/XBull, allowing users to connect their wallet to access\n   Soroban token balances and utilize their signing capabilities for secure and\n   integrity-checked transactions.\n\n2. **Transaction Construction**: Leveraging the Soroban token's contract\n   interface, the DApp constructs transactions that invoke the `transfer` method\n   of the\n   [token interface](https://github.com/stellar/soroban-examples/blob/main/token/src/contract.rs#L27).\n   This method facilitates the transfer of Soroban tokens from one address to\n   another.\n\n## Getting Started\n\nTo use the Payment DApp, follow these steps:\n\n1. Install and set up one of the supported wallets.\n\n- [Freighter wallet](https://www.freighter.app/)\n- [Albedo wallet](https://albedo.link/install-extension)\n- [XBull wallet](https://xbull.app/)\n\n2. Clone and navigate into the\n   [Payment DApp repository](https://github.com/stellar/soroban-react-payment/tree/main)\n   by running the following:\n\n   ```\n   git clone https://github.com/stellar/soroban-react-payment.git\n   cd soroban-react-payment\n   ```\n\n3. Install the dependencies by running the following:\n\n   ```\n   yarn\n   ```\n\n4. If you are using the Freighter wallet, ensure that experimental mode is\n   enabled. You can find this setting in Freighter wallet at:\n   _`Settings(\u2699\ufe0f)>Preferences>ENABLE EXPERIMENTAL MODE`_.\n\n<img src = \"./public/img/freighter_settings.png\" width=\"50%\" height=\"50%\"/>\n\n6. [Enable and add Soroban Tokens](https://soroban.stellar.org/docs/getting-started/connect-freighter-wallet#enable-soroban-tokens)\n   in Freighter.\n\n7. Select the account that will be used to send Soroban tokens.\n\n<img src = \"./public/img/account_selection.png\" width=\"50%\" height=\"50%\"/>\n\n8. Provide the required transaction parameters, such as the token to send,amount\n   of tokens to transfer and the destination address.\n\n<img src = \"./public/img/token_select.png\" width=\"50%\" height=\"50%\"/>\n<br/>\n<img src = \"./public/img/send_amount.png\" width=\"50%\" height=\"50%\"/>\n<br/>\n<img src = \"./public/img/destination.png\" width=\"50%\" height=\"50%\"/>\n\n9. Review the transaction details to ensure accuracy and then click the \"Sign\n   with Freighter\" once . Freighter will prompt you to sign the transaction with\n   your wallet's private key.\n\n<img src = \"./public/img/confirm.png\" width=\"50%\" height=\"50%\"/>\n\n10. Once signed, the click the \"Submit payment\" button and the transaction will\n    be submitted to the network.\n\n<img src = \"./public/img/submit_tx.png\" width=\"50%\" height=\"50%\"/>\n\n11. The Payment DApp will show a confirmation message once the transaction has\n    been successfully submitted.\n\n<img src = \"./public/img/tx_success.png\" width=\"50%\" height=\"50%\"/>\n\n## Build the Project\n\n```\nyarn && yarn build\n```\n\n## Starting a Dev Environment\n\n```\nyarn && yarn start\n```\n\n## Contributions\n\nContributions to the Payment DApp are welcome. If you encounter any issues, have\nsuggestions for improvements, or would like to contribute to the codebase,\nplease submit an issue, pull request, or reach out to us on\n[Discord](https://discord.com/channels/897514728459468821/1037073682599780494).\n", "release_dates": ["2023-12-19T19:21:48Z", "2023-09-25T20:59:26Z", "2023-07-18T01:43:15Z", "2023-06-08T16:48:56Z"]}, {"name": "soroban-rpc", "description": "RPC server for Soroban contracts.", "language": "Go", "license": null, "readme": "# soroban-rpc\nRPC Server for Soroban Contracts.\n", "release_dates": ["2024-02-22T00:04:35Z", "2024-02-21T01:37:48Z", "2024-02-14T17:13:04Z"]}, {"name": "sorobanathon", "description": "Sorobanathon: First Light", "language": null, "license": null, "readme": "# Welcome to *Sorobanathon: First Light* \ud83d\udd2d \n## We are no longer accepting submissions, stay tuned for more Soroban adoption programs to come! \n\nBetween now and December 15, 2022, you can earn rewards for experimenting with Soroban, and sharing your experience by creating content of all kinds, big and small. This is your chance to be an early Soroban adopter, and to be a part of the first program funded by the $100M Soroban Adoption Fund. Many more programs will follow! To find out about them, make sure to [join the Stellar Dev Discord](https://discord.gg/sp8zfb4qH6), and keep an eye on the #soroban channel.\n\nThe goal right now is to get you started, to gather feedback to guide the continued development of Soroban, and to generate some content to help kickstart the Soroban ecosystem. So roll up your sleeves, experiment, and have some fun!\n\nFor each qualified submission you create, you can earn a reward of 250 - 3000 XLM. It's a fun, low-lift way to tinker with Soroban while you help shape its development, and help grow the ecosystem as a whole.\n\n## Here's the kind of submission we're looking for:\n\n-   Code examples (think [Solidity by Example](https://solidity-by-example.org/)) \n-   Practical tutorials (such as this [DAO tutorial](https://docs.near.org/develop/relevant-contracts/dao))    \n-   Fun dapp tutorials (such as this [adoption tracking system for a pet shop](https://trufflesuite.com/blog/learn-ethereum-the-fun-way-with-our-pet-shop-tutorial/))    \n-   Video walkthroughs (such as this one on [creating a simple smart contract using Solidity](https://www.youtube.com/watch?v=bNXJNeaYl8Q))   \n-   Soroban for X developer tutorials (X = another smart contracts platform, such as Ethereum, Near, or Solana)\n\nAlso, if you're trying to do something and it doesn't work, let us know! File a good issue and/or document your experience in some way, and turn that in! Soroban is still a work in progress, and info about issues, bugs, and blockers is super useful right now.\n\nYou can file new issues (and see existing issues) in the [Soroban CLI repo](https://github.com/stellar/soroban-cli/issues) or the [Soroban SDK repo.](https://github.com/stellar/rs-soroban-sdk/issues) If you do file an issue, make sure to link to it in your *Sorobanathon: First Light* submission. If you have questions, feel free to ask them in the [Stellar Dev Discord](https://discord.gg/sp8zfb4qH6) #soroban channel\n\n## Get Started\n\nIf you haven't already, check out the [Soroban docs](https://soroban.stellar.org/docs) to get oriented, get set up, and get your head around the Soroban fundamentals. When you're ready to create a submission\u2026\n\n-   Click the [\"Discussions\"](https://github.com/stellar/sorobanathon/discussions) tab at the top of the page    \n-   Create a \"New Discussion\"    \n-   Title your discussion thread\n-   Select the \u201cGeneral\u201d category to post your submission    \n-   Add your submission. Feel free to put it right in the box, or to link to an external resource.    \n-   Once you have posted, you're done!\n\nWe will review your submission within a week, and reply on your submission thread to let you know if your submission qualifies to earn a reward! If so, we will ask you to complete a form to collect info necessary to validate and deliver a reward.\n\nIf your submission did not qualify, we may provide you with feedback on what's missing, or on how you can improve your submission so it qualifies. Once you have made the requested revisions, we will re-review your submission, and let you know if your submission qualifies for a reward.\n\n## What makes a good submission\n\nThe Stellar Development Foundation (\u201cSDF\u201d) will review submissions as they come in, and all *Sorobanathon: First Light* rewards are contingent upon review and approval of the submission by SDF, in its sole discretion.\n\nYour submission should be coherent and easy to follow. If you are creating a tutorial, the audience needs to be able to follow along. If you are writing code, it should be clear what the code is supposed to do. Ideally, the code works, but if it doesn't, capture any errors you encounter. If you create an issue or make a feature request, make sure it's clear, complete, and helpful. Please document everything you can!\n\nThat said, we don't require submissions to be long, or involved, or super polished. You don't need to be a professional writer to participate, and we want to reward efforts big and small. If you have questions, feel free to reach out on the [Stellar Dev Discord](https://discord.gg/sp8zfb4qH6) in the #soroban channel.\n\nRewards will be based on the scope and complexity of the submission. That said, here is a rough idea of what certain types of submissions can earn.\n\n-   Code examples 250-750 XLM\n-   Issues and feature requests 250-500 XLM\n-   Long-form written tutorials (how-tos, explainers) 1000-3000 XLM    \n-   Long-form technical video tutorials 1000-3000 XLM\n    \nNote: SDF is under no obligation to make any rewards if there are no eligible submissions or Eligible Individuals (as defined below), or if Eligible Individuals do not successfully complete the compliance and tax obligations set forth below.\n\n## Tips for picking submission topics\n\n\ud83d\udca1 Choose a great hack idea.\n-   Picture yourself at a hackathon trying to solve a problem quickly. What would it be?    \n-   Think about your own life and your own interests. Is there something missing that you could build with Soroban?    \n-   In this case, you can go big, and build the whole house, or you can scope things down, and focus on a single brick. \n\n\ud83d\udd0e Look for inspiration\n-   You don't need a completely unique concept, and reviewing other approaches can jumpstart your thought process   \n-   So check out existing smart contract tutorials for inspiration.\n\n\ud83c\udf0e Connect with the community\n-   Be proactive, engage with other devs, and ask for feedback in the [Stellar Dev Discord](https://discord.gg/UxsRyqpyBn) #soroban channel.    \n-   Remember that this is a community we build together \ud83d\udcaa! Our code of conduct is [here](https://www.stellar.org/community/code-of-conduct).\n\n\ud83c\udf89 Remember to have fun!\n-   There are no wrong answers here. As long as you are experimenting with Soroban, documenting and sharing, you're on the right track.\n\n**Happy Soroban-ing!!**\n\n## Sorobanathon Eligibility Guidelines\n\n### Submission Guidelines\n\n -   All submission materials should be in English or, if not in English, include an English translation.    \n - Do not submit:\n\t- Articles that point to ongoing asset sales, ICOs, referral programs, or affiliate links.\n\t- Speculative articles, price or price prediction articles, or \u201cwhy X should buy Y\u201d articles.\n\t- Announcements of announcements, short update blogs, or substanceless marketing pieces.\n\t- Articles attacking others. Please adhere to the [SDF Code of Conduct](https://stellar.org/community/code-of-conduct).\n\t- Other people\u2019s work - no plagiarizing or infringing on a third party\u2019s rights.\n - All submissions must be original works and the author should own all right, title and interest in the submission or, if third party licensed content is included in a submission, all necessary rights must be fully sub-licensable to SDF. Submission should not include any content that is unlawful, breaches any third party rights, or is otherwise in violation of or contrary to applicable laws or regulations.\n    \n## Reward Eligibility Guidelines\n\nWhile anyone may make a submission, only Eligible Individuals will be considered for XLM rewards. For purposes of *Sorobanathon: First Light*, an \u201cEligible Individual'' is a natural person who:\n\n1.  Is the greater of: (i) 18 years of age, or (ii) the minimum age that is legally permitted to use and hold cryptocurrency and/or to participate in *Sorobanathon: First Light* in the jurisdiction where such person resides;    \n2.  Is not an individual on the U.S. Department of Treasury\u2019s Office of Foreign Assets Control (OFAC) Specially Designated Nationals and Blocked Persons List or otherwise under sanction by OFAC (or an immediate family member - spouses, parent, child, sibling, grandparent, and \u201cstep\u201d child - of such individual) or be employed by or affiliated with an entity sanctioned by OFAC;    \n3.  Is not a resident of any country, state, province or territory subject to comprehensive OFAC sanctions, including Cuba, Iran, North Korea, Syria or any Russian-controlled region of Ukraine; and   \n4.  Does not reside in a jurisdiction where the transfer and holding of cryptocurrency is illegal or would require a special license or authorization that the such person does not possess.    \n\nSDF reserves the right, in its absolute discretion, to disqualify any participant or submission, without warning, from *Sorobanathon: First Light*, and to ban them from future programs funded by the Soroban Adoption Fund if they act in a way that violates these guidelines, is inappropriate, or not in the best interests or spirit of the program.\n\n### License to Submissions\n\nBy posting a submission, you will be granting to SDF and its assigns, licensees, and successors a royalty-free, irrevocable, non-exclusive and unlimited right and permission to use your submission, name, picture, statements, project name, likeness, and voice, and any material based thereon or derived therefrom (collectively, the \u201cContent\u201d), in any form, media, or technology now known or later developed, and to use, edit, modify, duplicate, distribute, publish, publicize and/or create derivative works from the Content (or any portion thereof), throughout the world, in perpetuity, without limitation and without payment of any royalties or compensation, consideration, notice or permission, except where prohibited by law, for the purpose of creating educational, informational, and promotional materials or creative assets (any such materials or assets that feature the Content are referred to herein as \u201cAssets\u201d), including, without limitation, on social media, or on any website owned or affiliated with SDF. You will have no right of approval, no claim to any compensation, and no claim arising out of the use, alteration, or distortion or use in any composite form of the Content.\n\n### Legal Terms and Acknowledgements  \n\n*Sorobanathon: First Light* is governed by the SDF [Terms of Service](https://www.stellar.org/terms-of-service?locale=en) and the guidelines described herein (the \u201cSorobanathon Eligibility Guidelines\u201d). SDF may collect personal information from you in connection with your submission, and such information is subject to the SDF [Privacy Policy](https://www.stellar.org/privacy-policy?locale=en). SDF reserves the right, in its sole discretion, to cancel, suspend and/or modify all or any part of *Sorobanathon: First Light* at any time for any reason. The terms and conditions of *Sorobanathon: First Light* are subject to change at any time, including the rights or obligations of the Participants and SDF.\n\nXLM is a highly risky and volatile asset, and SDF does not provide any representations, warranties, or guarantees of its value. You will be required to provide certain information to facilitate receipt of any XLM reward, including completing and submitting any tax or other forms necessary for compliance with applicable withholding and reporting requirements. You are responsible for reporting the receipt of any XLM reward to relevant government departments or agencies, where applicable, and paying all applicable taxes in your jurisdiction of residence. SDF reserves the right to withhold a portion of any reward amount to comply with the tax laws of the United States or other relevant jurisdictions. You should inform yourself as to any legal and tax requirements or consequences applicable to you in respect of the acquisition, holding, and disposition of XLM. You are also responsible for complying with any applicable foreign exchange and banking regulations relating to any XLM reward received hereunder.  \n\nSDF\u2019s failure to enforce any of these terms or guidelines shall not constitute a waiver of that provision. Should any provision of these Sorobanathon Eligibility Guidelines be or become illegal or unenforceable in any jurisdiction whose laws or regulations may apply to a participant or submission, such illegality or unenforceability shall leave the remainder of these Sorobanathon Eligibility Guidelines to the fullest extent permitted by law, unaffected and valid. The illegal or unenforceable provision shall be replaced by a valid and enforceable provision that comes closest and best reflects the SDF\u2019s intention in a legal and enforceable manner with respect to the invalid or unenforceable provision.\n  \n**Remember that this is a community we build together \ud83d\udcaa! Our code of conduct is [here](https://www.stellar.org/community/code-of-conduct) and our Privacy Policy is [here](https://www.stellar.org/privacy-policy).**\n", "release_dates": []}, {"name": "sorobounties", "description": "The Soroban content bounty program", "language": null, "license": null, "readme": "# Welcome to Sorobounties!\ud83c\udf3f\n\nBetween November 15th and December 22nd at 7 p.m. Eastern, you can receive awards for building decentralized applications (dapps) with Soroban on the Stellar network\u2019s Testnet (Stellar Testnet) or Futurenet, accompanied by explanatory content (such as written tutorials, video walkthroughs, etc.). This program is part of the Stellar Development Foundation\u2019s $100M Soroban adoption fund and is similar to the previous [Sorobounty Spectacular](https://github.com/stellar/sorobounty-spectacular). \n\nThe goal of this program is to provide the structure for application developers to build with Soroban and provide the educational materials for other devs to get up and running quickly on the platform as we approach Mainnet launch. We\u2019re looking for any type of dapp \u2014 from basic cryptographic games to NFT projects.\n\nFor each qualified submission you create, you can may be eligible to receive an award of between $400 and $1,300 worth of XLM. \n\n## Need some inspiration?\n\nYou can create:\n\n- Practical dapps (such as this [Bitcoin price oracle](https://github.com/stellar/sorobounty-spectacular/discussions/29)) \n- Fun dapp tutorials (such as [Cowchain Farm](https://github.com/stellar/sorobounty-spectacular/discussions/14))\n- Video walkthroughs (such as this one on [regulated assets](https://www.youtube.com/playlist?list=PLJo7htkGqBrFIHg6keCRRYjf6AEB1m1wo))\n\nSoroban is currently live on Stellar Testnet and Futurenet. You may encounter some problems as you are using the platform and various tools. We encourage you to report any problems or bugs you find in our Stellar Developer Discord under the #soroban channels.\n\n## What makes a good submission\n\nThe Stellar Development Foundation (\u201cSDF\u201d) will review submissions as they come in, and all Sorobounties awards are contingent upon review and approval of the submission by SDF, in its sole discretion.\n\nYour submission should be coherent and easy to follow. If you are creating a tutorial, the audience needs to be able to follow along. If you are writing code, what it does should be clear. All content and contract code also need to be public (GitHub, dev.to, Medium, or YouTube).\n\nAwards will be based on the scope, complexity, and quality of the submission. That said, here is a rough idea of what certain types of submissions can receive.\nIf your submission is just dapp code and a demo, you are eligible to receive up to $400 worth of XLM. The award amount increases to up to $1,300 worth of XLM based on the accompanying content: from decent READMEs to published written tutorials on dev.to to video tutorials on YouTube. The more you include in your submission, the better!\n\n**Note:** SDF is under no obligation to make any awards if there are no eligible submissions or Eligible Individuals (as defined below), or if Eligible Individuals do not successfully complete the compliance and tax obligations set forth below.\n\n## Award guidelines\n\nAward amounts are determined based on submission components (ex: does the submission have an accompanying video tutorial?), quality (ex: are the submission\u2019s code and accompanying written tutorial well-written and understandable?), and accessibility (ex: are all components of the submission public?). \n\nHere is a breakdown of all content component options:  \n\n- Required: $400 worth of XLM for contract (dapp) code and a live (usable), interactive demo\n- Optional: Add on $150 worth of XLM if your submission includes well-documented code and a detailed README on how to build and run your dapp on Soroban\n- Optional: Add on $250 worth of XLM if your submission includes a tutorial on how to build your dapp on Soroban published on dev.to or Medium \n- Optional: Add on $500 worth of XLM if your submission includes a video tutorial on building and running your dapp with Soroban published on YouTube\n\nSubmissions must contain contract (dapp) code and a demo but award amounts can be increased by including any or all of the additional content components. \n\nSubmission examples are:\n\n1) contract (dapp) code and a demo ($400 worth of XLM) plus a published video tutorial ($500 worth of XLM) for a total of $900 worth of XLM; \n2) contract (dapp) code and a demo ($400 worth of XLM) plus a decent README, ($150 worth of XLM), and a published written tutorial ($250 worth of XLM) for a total of $800 worth of XLM. \n\nA submission is eligible to be awarded up to $1,300 if it contains all the above components.\n\n## Example dapp resources\n\nTo help you get started, here are some example dapp resources that you can use as references:\n\n- [The Soroban Dapps Challenge](https://soroban.stellar.org/dapps/): Complete dapp development milestones, resulting in a smart contract and UI/UX templates for future projects, along with an MVP to build upon. It offers developers practical experience and valuable resources to excel in your journey.\n- [Scaffold Soroban](https://github.com/stellar/scaffold-soroban): Take advantage of the examples, like soroban-react-payment and soroban-react-mint-token, to create robust dapps on Soroban, all while leveraging our powerful JavaScript SDKs.\n\n## Get Started\n\nIf you haven't already, check out the [Soroban docs](https://soroban.stellar.org/docs) to get oriented, get set up, and get your head around the Soroban fundamentals. When you're ready to create a submission:\n\n1. Click the \"Discussions\" tab at the top of the page\n2. Create a \"New Discussion\"\n3. Title your discussion thread\n4. Select the \u201cGeneral\u201d category\n5. Github Discussions requires you to search for similar discussion threads before creating a new thread.  It's a good idea!  That way, you can see submissions that have already been turned in.  Don't copy from any, but feel free to create something similar.\n6. When you're ready, check off \u201cI have done a search for similar discussions.\u201d\n7. Add your submission.  Feel free to put it right in the box, or to link to an external resource.\n8. Your submission should then be posted on the Discussions page\n\nWe will review your submission within three weeks (this is subject to be longer depending on the holidays) and reply on your submission thread to let you know if your submission qualifies to receive an award! If so, we will ask you to complete a form to collect the info necessary to validate and deliver an award.\n\nIf your submission did not qualify, we may provide you with feedback on what's missing or on how you can improve your submission so it qualifies. Once you have made the requested revisions, we will re-review your submission and let you know if your submission qualifies for an award.\n\n# Sorobounties Eligibility Guidelines\n\n## Submission Guidelines\n\n- All submission materials should be in English or, if not in English, include an English translation. \n- Do not submit:\n    - Articles that point to ongoing asset sales, ICOs, referral programs, or affiliate links.\n    - Speculative articles, price or price prediction articles, or \u201cwhy X should buy Y\u201d articles.\n    - Announcements of announcements, short update blogs, or substanceless marketing pieces.\n    - Articles attacking others. Please adhere to the SDF Code of Conduct.\n    - Other people\u2019s work - no plagiarizing or infringing on a third party\u2019s rights.\n- All submissions must be original works and the author should own all right, title and interest in the submission or, if third-party licensed content is included in a submission, all necessary rights must be fully sub-licensable to SDF. Submission should not include any content that is unlawful, breaches any third-party rights, or is otherwise in violation of or contrary to applicable laws or regulations. \n\n## Reward Eligibility Guidelines\n\nWhile anyone may make a submission, only Eligible Individuals will be considered for XLM awards. For purposes of Sorobounties, an \u201cEligible Individual'' is a natural person who:\n\n1. Is the greater of: (i) 18 years of age, or (ii) the minimum age that is legally permitted to use and hold cryptocurrency and/or to participate in Sorobounties in the jurisdiction where such person resides;\n2. Is not an individual on the U.S. Department of Treasury\u2019s Office of Foreign Assets Control (OFAC) Specially Designated Nationals and Blocked Persons List or otherwise under sanction by OFAC (or an immediate family member - spouses, parent, child, sibling, grandparent, and \u201cstep\u201d child - of such individual) or be employed by or affiliated with an entity sanctioned by OFAC; \n3. Is not a resident of any country, state, province or territory subject to comprehensive OFAC sanctions, including Cuba, Iran, North Korea, Syria or any Russian-controlled region of Ukraine; and\n4. Does not reside in a jurisdiction where the transfer and holding of cryptocurrency is illegal or would require a special license or authorization that the such person does not possess.\n\nSDF reserves the right, in its absolute discretion, to disqualify any participant or submission, without warning, from Sorobounties, and to ban them from future programs funded by the Soroban Adoption Fund if they act in a way that violates these guidelines, is inappropriate, or not in the best interests or spirit of the program.\n\n## License to Submissions\n\nBy posting a submission, you will be granting to SDF and its assigns, licensees, and successors a royalty-free, irrevocable, non-exclusive and unlimited right and permission to use your submission, name, picture, statements, project name, likeness, and voice, and any material based thereon or derived therefrom (collectively, the \u201cContent\u201d), in any form, media, or technology now known or later developed, and to use, edit, modify, duplicate, distribute, publish, publicize and/or create derivative works from the Content (or any portion thereof), throughout the world, in perpetuity, without limitation and without payment of any royalties or compensation, consideration, notice or permission, except where prohibited by law, for the purpose of creating educational, informational, and promotional materials or creative assets (any such materials or assets that feature the Content are referred to herein as \u201cAssets\u201d), including, without limitation, on social media, or on any website owned or affiliated with SDF. You will have no right of approval, no claim to any compensation, and no claim arising out of the use, alteration, or distortion or use in any composite form of the Content. \n\n## Legal Terms and Acknowledgements\n\nSorobounties is governed by the [SDF Terms of Service](https://www.stellar.org/terms-of-service?locale=en) and the guidelines described herein (the \u201cSorobanathon Eligibility Guidelines\u201d). SDF may collect personal information from you in connection with your submission, and such information is subject to the [SDF Privacy Policy](https://www.stellar.org/privacy-policy?locale=en).  SDF reserves the right, in its sole discretion, to cancel, suspend and/or modify all or any part of Sorobounties at any time for any reason. The terms and conditions of Sorobounties are subject to change at any time, including the rights or obligations of the Participants and SDF. \n\nXLM is a highly risky and volatile asset, and SDF does not provide any representations, warranties, or guarantees of its value. You will be required to provide certain information to facilitate receipt of any XLM award, including completing and submitting any tax or other forms necessary for compliance with applicable withholding and reporting requirements. You are responsible for reporting the receipt of any XLM award to relevant government departments or agencies, where applicable, and paying all applicable taxes in your jurisdiction of residence. SDF reserves the right to withhold a portion of any award amount to comply with the tax laws of the United States or other relevant jurisdictions. You should inform yourself as to any legal and tax requirements or consequences applicable to you in respect of the acquisition, holding, and disposition of XLM. You are also responsible for complying with any applicable foreign exchange and banking regulations relating to any XLM award received hereunder.\n\nSDF\u2019s failure to enforce any of these terms or guidelines shall not constitute a waiver of that provision. Should any provision of these Sorobanathon Eligibility Guidelines be or become illegal or unenforceable in any jurisdiction whose laws or regulations may apply to a participant or submission, such illegality or unenforceability shall leave the remainder of these Sorobanathon Eligibility Guidelines to the fullest extent permitted by law, unaffected and valid. The illegal or unenforceable provision shall be replaced by a valid and enforceable provision that comes closest and best reflects the SDF\u2019s intention in a legal and enforceable manner with respect to the invalid or unenforceable provision.\n\n**Remember that this is a community we build together \ud83d\udcaa! Our code of conduct is [here](https://www.stellar.org/community/code-of-conduct) and our Privacy Policy is [here](https://www.stellar.org/privacy-policy).**\n", "release_dates": []}, {"name": "sorobounty-spectacular", "description": "Sorobounty Spectacular", "language": null, "license": null, "readme": "# Welcome to Sorobounty Spectacular! \ud83c\udfa1\n\n**Submissions have now closed**, you can get awards for building decentralized applications (dApps) with Soroban on the Stellar network, accompanied by explanatory content (such as written tutorials, video walkthroughs, etc.). This program is part of the Stellar Development Foundation\u2019s $100M Soroban Adoption Fund and is a precursor to Sorobanathon: Road to Mainnet. \n\nThe goal of this program is to provide the structure for application developers to build with Soroban and provide the educational materials for other devs to get up and running quickly on the platform as we approach Mainnet launch. We\u2019re looking for any type of dApp \u2014 from [basic cryptographic games to NFT projects](./RFPs.md). Have some fun with it!\n\nFor each qualified submission you create, you can get an award of between $300 and $1,500 worth of XLM. \n\nHere are the kind of submissions we're looking for:\n\n* Practical tutorials (such as this [DAO tutorial](https://docs.near.org/develop/relevant-contracts/dao))\n* Fun dApp tutorials (such as this [adoption tracking system for a pet shop](https://trufflesuite.com/blog/learn-ethereum-the-fun-way-with-our-pet-shop-tutorial/))\n* Video walkthroughs (such as this one on creating a [simple smart contract using Solidity](https://www.youtube.com/watch?v=bNXJNeaYl8Q))\n\nSoroban is still in preview release and is live on Futurenet, a shared test network. You may encounter some problems as you are using the platform and various tools. We encourage you to report any problems or bugs you find in our [Stellar Developer Discord](https://discord.gg/stellardev) under the #soroban channels.\n\n## What makes a good submission\n\nThe Stellar Development Foundation (\u201cSDF\u201d) will review submissions as they come in, and all Sorobounty Spectacular awards are contingent upon review and approval of the submission by SDF, in its sole discretion.\n\nYour submission should be coherent and easy to follow. If you are creating a tutorial, the audience needs to be able to follow along. If you are writing code, what it does should be clear. All content and contract code also need to be public (GitHub, dev.to, Medium, or YouTube).\n\nAwards will be based on the scope, complexity, and quality of the submission. Here is a breakdown of all content component options:\n\n* Required: $300 worth of XLM for  contract (dApp) code\n* Optional: Add on $150 worth of XLM if your submission includes well-documented code, a decent README detailing how to build a dApp on Soroban, and a live interactive demo site\n* Optional: Add on $250 worth of XLM if your submission includes a tutorial on building a dApp with Soroban published on dev.to or Medium\n* Optional: Add on $800 worth of XLM if your submission includes a public video tutorial on building a dApp with Soroban on YouTube\n\nSubmissions must contain contract (dApp) code but award amounts can be increased by including any or all of the additional content components. A couple of submission examples are:\n\n1. Contract (dApp) code ($300 worth of XLM) plus a published video tutorial ($800 worth of XLM) for a total of $1,100 worth of XLM;\n2. Contract (dApp) code ($300 worth of XLM) plus a decent README and interactive demo site ($150 worth of XLM), and a published written tutorial ($250 worth of XLM) for a total of $700 worth of XLM.\n   \nA submission is eligible to be awarded up to $1,500 if it contains all components.\n\n**Note:** SDF is under no obligation to make any awards if there are no eligible submissions or Eligible Individuals (as defined below), or if Eligible Individuals do not successfully complete the compliance and tax obligations set forth below.\n\n## Example dapp resources \ud83d\udcda\n\nTo help you get started, here are some example dapp resources that you can use as references:\n\n[The Soroban Dapps Challenge](https://soroban.stellar.org/dapps/): Complete dapp development milestones, resulting in a smart contract and UI/UX templates for future projects, along with an MVP to build upon. It offers developers practical experience and valuable resources to excel in your journey.\n\n[Scaffold Soroban](https://github.com/stellar/scaffold-soroban): Take advantage of the examples, like soroban-react-payment and soroban-react-mint-token, to create robust dapps on Soroban, all while leveraging our powerful JavaScript SDKs.\n\n[Soroban Example Crowdfund Dapp](https://github.com/stellar/soroban-example-dapp): Explore an awesome end-to-end (E2E) dapp example utilizing Next.js. This project demonstrates the step-by-step process of building a dapp frontend seamlessly integrated with smart contracts in a sandbox environment.\n\n## Get started\n\nIf you haven't already, check out the [Soroban docs](https://soroban.stellar.org/docs) to get oriented, get set up, and get your head around the Soroban fundamentals. When you're ready to create a submission:\n\n* Click the \"Discussions\" tab at the top of the page\n* Create a \"New Discussion\"\n* Title your discussion thread\n* Select the \u201cGeneral\u201d category\n* Github Discussions requires you to search for similar discussion threads before creating a new thread.  It's a good idea!  That way, you can see submissions that have already been turned in.  Don't copy from any, but feel free to create something similar.\n* When you're ready, check off \u201cI have done a search for similar discussions.\u201d\n* Add your submission.  Feel free to put it right in the box, or to link to an external resource.\n* Once you have posted, you're done!\n\nWe will review your submission within a week, and reply on your submission thread to let you know if your submission qualifies to get an award! If so, we will ask you to complete a form to collect the info necessary to validate and deliver an award.\n\nIf your submission did not qualify, we may provide you with feedback on what's missing, or on how you can improve your submission so it qualifies. Once you have made the requested revisions, we will re-review your submission, and let you know if your submission qualifies for an award.\n\n## Tips for picking submission topics\n\n\ud83d\udca1 Choose an idea:\n\n* Picture yourself at a hackathon trying to solve a problem quickly.  What would it be? \n* Think about your own life and your own interests.  Is there something missing that you could build with Soroban? \n* In this case, you can go big, and build the whole house, or you can scope things down, and focus on a single brick.\n\n\ud83d\udd0e Look for inspiration:\nYou don't need a completely unique concept, and reviewing other approaches can jumpstart your thought process.\nSo check out existing smart contract tutorials for inspiration.\n\n\ud83c\udf0e Connect with the community:\n\n* Be proactive, engage with other devs, and ask for feedback in the [Stellar Dev Discord](https://discord.gg/stellardev)  #soroban channels.\n* Remember that this is a community we build together  \ud83d\udcaa! Our code of conduct is [here](https://www.stellar.org/community/code-of-conduct). \n\n\ud83c\udf89 Remember to have fun!\n\n* As long as your submission contains an end-to-end smart contract deployed on the Stellar blockchain and has an interactive interface, you\u2019re on the right track.\n\n## Sorobanathon eligibility guidelines\n\n### Submission guidelines\n\n* All submission materials should be in English or, if not in English, include an English translation. \n* Do not submit:\n  - Articles that point to ongoing asset sales, ICOs, referral programs, or affiliate links.\n  - Speculative articles, price or price prediction articles, or \u201cwhy X should buy Y\u201d articles.\n  - Announcements of announcements, short update blogs, or substanceless marketing pieces.\n  - Articles attacking others. Please adhere to the [SDF Code of Conduct](https://stellar.org/community/code-of-conduct).\n  - Other people\u2019s work - no plagiarizing or infringing on a third party\u2019s rights.\n* All submissions must be original works and the author should own all right, title and interest in the submission or, if third-party licensed content is included in a submission, all necessary rights must be fully sub-licensable to SDF. Submission should not include any content that is unlawful, breaches any third-party rights, or is otherwise in violation of or contrary to applicable laws or regulations. \n\n### Award eligibility guidelines\n\nWhile anyone may make a submission, only Eligible Individuals will be considered for XLM awards. For purposes of Sorobounty Spectacular, an \u201cEligible Individual'' is a natural person who:\n\n1. Is the greater of: (i) 18 years of age, or (ii) the minimum age that is legally permitted to use and hold cryptocurrency and/or to participate in Sorobounty Spectacular in the jurisdiction where such person resides;\n2. Is not an individual on the U.S. Department of Treasury\u2019s Office of Foreign Assets Control (OFAC) Specially Designated Nationals and Blocked Persons List or otherwise under sanction by OFAC (or an immediate family member - spouses, parent, child, sibling, grandparent, and \u201cstep\u201d child - of such individual) or be employed by or affiliated with an entity sanctioned by OFAC; \n3. Is not a resident of any country, state, province or territory subject to comprehensive OFAC sanctions, including Cuba, Iran, North Korea, Syria or any Russian-controlled region of Ukraine; and\n4. Does not reside in a jurisdiction where the transfer and holding of cryptocurrency is illegal or would require a special license or authorization that the such person does not possess.\n\nSDF reserves the right, in its absolute discretion, to disqualify any participant or submission, without warning, from Sorobounty Spectacular, and to ban them from future programs funded by the Soroban Adoption Fund if they act in a way that violates these guidelines, is inappropriate, or not in the best interests or spirit of the program.\n\n### License to submissions\n\nBy posting a submission, you will be granting to SDF and its assigns, licensees, and successors a royalty-free, irrevocable, non-exclusive and unlimited right and permission to use your submission, name, picture, statements, project name, likeness, and voice, and any material based thereon or derived therefrom (collectively, the **\u201cContent\u201d**), in any form, media, or technology now known or later developed, and to use, edit, modify, duplicate, distribute, publish, publicize and/or create derivative works from the Content (or any portion thereof), throughout the world, in perpetuity, without limitation and without payment of any royalties or compensation, consideration, notice or permission, except where prohibited by law, for the purpose of creating educational, informational, and promotional materials or creative assets (any such materials or assets that feature the Content are referred to herein as **\u201cAssets\u201d**), including, without limitation, on social media, or on any website owned or affiliated with SDF. You will have no right of approval, no claim to any compensation, and no claim arising out of the use, alteration, or distortion or use in any composite form of the Content. \n\n### Legal terms and acknowledgements\n\nSorobounty Spectacular is governed by the SDF [Terms of Service](https://www.stellar.org/terms-of-service?locale=en) and the guidelines described herein (the \u201cSorobanathon Eligibility Guidelines\u201d). SDF may collect personal information from you in connection with your submission, and such information is subject to the SDF [Privacy Policy](https://www.stellar.org/privacy-policy?locale=en).  SDF reserves the right, in its sole discretion, to cancel, suspend and/or modify all or any part of Sorobounty Spectacular at any time for any reason. The terms and conditions of Sorobounty Spectacular are subject to change at any time, including the rights or obligations of the Participants and SDF. \n\nXLM is a highly risky and volatile asset, and SDF does not provide any representations, warranties, or guarantees of its value. You will be required to provide certain information to facilitate receipt of any XLM award, including completing and submitting any tax or other forms necessary for compliance with applicable withholding and reporting requirements. You are responsible for reporting the receipt of any XLM award to relevant government departments or agencies, where applicable, and paying all applicable taxes in your jurisdiction of residence. SDF reserves the right to withhold a portion of any award amount to comply with the tax laws of the United States or other relevant jurisdictions. You should inform yourself as to any legal and tax requirements or consequences applicable to you in respect of the acquisition, holding, and disposition of XLM. You are also responsible for complying with any applicable foreign exchange and banking regulations relating to any XLM award received hereunder.\n\nSDF\u2019s failure to enforce any of these terms or guidelines shall not constitute a waiver of that provision. Should any provision of these Sorobanathon Eligibility Guidelines be or become illegal or unenforceable in any jurisdiction whose laws or regulations may apply to a participant or submission, such illegality or unenforceability shall leave the remainder of these Sorobanathon Eligibility Guidelines to the fullest extent permitted by law, unaffected and valid. The illegal or unenforceable provision shall be replaced by a valid and enforceable provision that comes closest and best reflects the SDF\u2019s intention in a legal and enforceable manner with respect to the invalid or unenforceable provision.\n\nRemember that this is a community we build together  \ud83d\udcaa! Our code of conduct is [here](https://www.stellar.org/community/code-of-conduct) and our Privacy Policy is [here](https://www.stellar.org/privacy-policy). \n", "release_dates": []}, {"name": "soroflare", "description": "The Soroban environment and vm running on a Cloudflare Worker. (a simplified version of the backend running fca00c.com)", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Soroflare\n> Careful:  \n> This repository is an early stage of development.   \n> It is not recommended to use this code in an production enviroment!\n\nThis repository contains the environment and virtual machine running as the backbone for the [FCA00C][fca00c] contest.  \n\n## Virtual Machine \nThe virtual machine contained in [soroflare-vm] is designed as a standalone rust crate.  \nThis allows an easy implementation of Soroban contract execution in arbitrary applications.\n\n## FCA00C backend\nA modified version of the actual [FCA00C][fca00c] backend is given in [soroflare-wrangler].  \nThe backend is built using the Cloudflare Wrangler stack and uses the [worker-rs] framework to compile to\nWebAssembly.  \nThe [soroflare-wrangler] can is as an exemplary implementation of the [soroflare-vm].\n\n\n[fca00c]: https://fca00c.com\n[soroflare-vm]: ./soroflare-vm/\n[soroflare-wrangler]: ./soroflare-wrangler/\n[worker-rs]: https://github.com/cloudflare/workers-rs\n\n\n# Usage\n\nIn the newly updated soroflare version, you have the possibility of setting up an API for running and testing webassembly modules (more specifically Soroban contracts) from your clients.\n\nSoroflare enables you to define every variable within your testing workflow, and can be specifically useful for testing contracts from your clients while being able to manipulate\nthe context in which your contracts get executed (for instance, test agains state expiration). At the current stage, you can build and populate the execution context of a contract call with all the\nentries the invocation you send to soroflare encompasses.\n\nTo make requests lighter and reduce overhead, you can also deploy your binaries to soroflare and then reference them within the snapshot you're sending.\n\n## API\n\n### Upload your binary\n\nPOST request to `/uploadwasm`, with the WASM binary as raw body.\n\n\n### Execute invocation with ledger snapshot\n\nPOST request to `/executesnapshot` with the snapshot as JSON body:\n\nFor example:\n\n```json\n{\n    \"contract_id\": [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n    \"fname\": \"hello\",\n    \"keys\": [\n        {\n            \"contract_data\": {\n                \"contract\": \"CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABSC4\",\n                \"durability\": \"persistent\",\n                \"key\": \"ledger_key_contract_instance\"\n            }\n        }\n    ],\n    \"ledger_sequence\": 500,\n    \"params\": [\n        {\n            \"symbol\": \"tdep\"\n        }\n    ],\n    \"vals\": [\n        {\n            \"entry\": {\n                \"data\": {\n                    \"contract_data\": {\n                        \"contract\": \"CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABSC4\",\n                        \"durability\": \"persistent\",\n                        \"ext\": \"v0\",\n                        \"key\": \"ledger_key_contract_instance\",\n                        \"val\": {\n                            \"contract_instance\": {\n                                \"executable\": {\n                                    \"wasm\": \"cb212e08157def179b96989e9178d8cae62ce7b2155497ade08b08156f1921e8\"\n                                },\n                                \"storage\": null\n                            }\n                        }\n                    }\n                },\n                \"ext\": \"v0\",\n                \"last_modified_ledger_seq\": 0\n            },\n            \"live_until\": 100\n        }\n    ]\n}\n```\n\n> Note: We're testing entry expiration here as we've set the snapshot's `ledger_sequence` to `500` and our contract instance entry's `live_until` to ledger `100`. This means that we'll receive an `Expired entries` error in the response along with the information about the expired entries.\n\n> Note: above we're not providing the `LedgerEntry::ContractCode` entry in the snapshot, that's because I've already installed in Soroflare the binaries used by the contracts we're invoking in the call (`cb212e08157def179b96989e9178d8cae62ce7b2155497ade08b08156f1921e8`).\n> If you try to run this without having installed the contract code in soroflare, you will receive an error about the module not being found.\n\n## Generating Snapshots\n\nThe snapshot format that soroflare accepts is the following:\n\n```rust\npub struct WithSnapshotInput {\n    ledger_sequence: u32,\n    keys: Vec<LedgerKey>,\n    vals: Vec<EntryWithLifetime>,\n    contract_id: [u8; 32],\n    fname: String,\n    params: Vec<ScVal>,\n}\n```\n\nWith `LedgerKey` and `ScVal` being Stellar XDR objects and `EntryWithLifetime` defined as follows:\n\n```rust\n#[derive(Serialize, Deserialize, Debug)]\npub struct EntryWithLifetime {\n    pub entry: LedgerEntry,\n    pub live_until: Option<u32>,\n}\n```\n\nTo build a correctly-formed JSON snapshot, you can either serialize to JSON a `WithSnapshotInput` struct (for example, with `serde_json`) or simply follow the objects structure. \n\nExamples of built Snapshots can be found in the `soroflare-wrangler/src/routes/generic.rs` `test` module.\n", "release_dates": []}, {"name": "starbridge", "description": "Software that facilitates bridge builders who are connecting the Stellar network to other blockchains.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<div align=\"center\">\n<a href=\"https://stellar.org\"><img alt=\"Stellar\" src=\"https://github.com/stellar/.github/raw/master/stellar-logo.png\" width=\"558\" /></a>\n<br/>\n<strong>Creating equitable access to the global financial system</strong>\n<h1>Starbridge</h1>\n</div>\n<p align=\"center\">\n</p>\n\nStarbridge is software that facilitates bridge builders who are connecting the Stellar network to other blockchains.\n\nStarbridge is in early development.\n\n## Get involved\n\n- [Docs](./docs)\n- [Discussions](https://github.com/stellar/starbridge/discussions)\n- More to come...\n", "release_dates": []}, {"name": "starlight", "description": "Layer 2 payment channel protocol for the Stellar network.", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "<div align=\"center\">\n<a href=\"https://stellar.org\"><img alt=\"Stellar\" src=\"https://github.com/stellar/.github/raw/master/stellar-logo.png\" width=\"558\" /></a>\n<br/>\n<strong>Creating equitable access to the global financial system</strong>\n<h1>Starlight Protocol</h1>\n</div>\n<p align=\"center\">\n<a href=\"https://github.com/stellar/starlight/actions/workflows/sdk.yml\"><img src=\"https://github.com/stellar/starlight/actions/workflows/sdk.yml/badge.svg\" />\n<a href=\"https://pkg.go.dev/github.com/stellar/starlight/sdk\"><img src=\"https://pkg.go.dev/badge/github.com/stellar/starlight/sdk.svg\" alt=\"Go Reference\"></a>\n<a href=\"https://github.com/stellar/starlight/discussions\"><img src=\"https://img.shields.io/github/discussions/stellar/starlight\" alt=\"Discussions\"></a>\n</p>\n\nStarlight is a prototype layer 2 payment channel protocol for the Stellar Network. Starlight has existed in a couple different forms. The previous version of Starlight lives at [interstellar/starlight](https://github.com/interstellar/starlight).\n  \n**Have a use case for payment channels on Stellar? Tell us about it [here](https://github.com/stellar/starlight/discussions/new?category=use-cases).**\n\nThis repository contains a experiments, prototypes, documents, and issues\nrelating to implementing the Starlight protocol on the Stellar network.\nProtoypes here are dependent on Protocol 19 and Core Advancement Protocols,\n[CAP-21] and [CAP-40]. You can experiment with the Starlight protocol by using\nthe testnet, or running a Stellar network in a docker container. To find out\nhow, see [Getting Started](Getting%20Started.md).\n\n![Diagram of two people opening a payment channel, transacting off-network, and closing the payment channel.](README-diagram.png)\n\nThe Starlight protocol, SDK, code in this repository, and any forks of other Stellar software referenced here, are **experimental** and **not recommended for use in production** systems. Please use the SDK to experiment with payment channels on Stellar, but it is not recommended for use with assets that hold real world value.\n\n## Try it out\n\nRun the example console application with testnet:\n\n```\ngit clone https://github.com/stellar/starlight\ncd examples/console\ngo run .\n>>> help\n```\n\nRun two copies of the example console application and connect them directly over\nTCP to open a payment channel between two participants.\nMore details in the [README](https://github.com/stellar/starlight/tree/main/examples/console).\n\n## Get involved\n\n- [Discord](https://discord.gg/xGWRjyNzQh)\n- [Discussions](https://github.com/stellar/starlight/discussions)\n- [Demos](https://github.com/stellar/starlight/discussions/categories/demos)\n- [Getting Started](Getting%20Started.md)\n- [Specifications](specifications/)\n- [Benchmarks](benchmarks/)\n\n## Build and experiment\n\n- [SDK](https://pkg.go.dev/github.com/stellar/starlight/sdk)\n- [Examples](examples/)\n\n## Discussions\n\n- Live chat is on the `#starlight` channel in [Discord](https://discord.gg/xGWRjyNzQh)\n- Discussions about Starlight are on [GitHub Discussions](https://github.com/stellar/starlight/discussions)\n\n## Protocol 19\n\nThe code in this repository is dependent on changes to the Stellar protocol coming in Protocol 19, specifically the changes described by [CAP-21] and [CAP-40]. Protocol 19 is released.\n\n[CAP-21]: https://stellar.org/protocol/cap-21\n[CAP-40]: https://stellar.org/protocol/cap-40\n", "release_dates": []}, {"name": "stellar-account-prometheus-exporter", "description": "Stellar Account Prometheus Exporter - Monitor Stellar Network Accounts", "language": "Python", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Overview\n\nThe Stellar Account Prometheus Exporter retrieves account(s)\nbalance and exposes it in prometheus format.\n\n# Configuration\n\nConfiguration file path must be provided using the --config option.\n\nThe config file is yaml formatted file:\n```\nnetworks:\n- name: pubnet                              # Human readable name\n  horizon_url: https://horizon.example.com  # Horizon URL\n  accounts:\n  - account_id: ABC123XYZ     # Account ID\n    account_name: Account one # Human readable description\n  - account_id: DEF456ABC\n    account_name: Account two\n- name: testnet\n  horizon_url: https://horizon-testnet.example.com\n  accounts:\n  - account_id: QWE789DEF\n    account_name: Testnet test account\n```\n\nBy default the exporter listens on port 9618. This can be changes using\n--port switch or \"PORT\" environment variable.\n\n# Exported data\n\nFor each account the following metrics are exported:\n * *stellar_account_balance*\n * *stellar_account_available_balance*\n * *stellar_account_buying_liabilities*\n * *stellar_account_selling_liabilities*\n * *stellar_account_num_sponsored*\n * *stellar_account_num_sponsoring*\n * *stellar_account_scrape_success*\n\nEach metric has the following labels:\n * *network* - network name from the configuration file\n * *account_id* - account ID from the configuration file\n * *account_name* - account name, as per configuration file\n * *asset_type* - asset type\n\n# Installing from pypi\n\nTo download/test package in pypi you can use venv:\n```\npython3 -m venv venv\n. venv/bin/activate\n```\n\nInstall:\n```\npython3 -m pip install stellar_account_prometheus_exporter\n```\n\nRun:\n```\n./venv/bin/stellar-account-prometheus-exporter --config /path/to/config.yaml\n```\n\n# Releasing new version\n\n* ensure you bumped version number in setup.py. PyPi does not allow version reuse\n* build new package:\n```\npython3 setup.py sdist bdist_wheel\n```\n* push to testpypi:\n```\npython3 -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*\n```\n* test by installing the package (see above). If all good release:\n```\npython3 -m twine upload dist/*\n```\n\n# Docker and K8s version\nThis app is now dockerized. The new Dockerfile has been validated and can be used like this:\n```\ndocker build --pull --no-cache -t <your tag>\n```\n", "release_dates": []}, {"name": "stellar-anchor-tests", "description": "A library and CLI tool for testing Stellar anchors.", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Stellar Anchor Tests Monorepo\n\nLive at [anchor-tests.stellar.org](https://anchor-tests.stellar.org)\n\nThis repository is a container for three applications.\n\n- [@stellar/anchor-tests](./@stellar/anchor-tests)\n\t- A library and CLI for testing stellar anchors. Will be published to npm.\n- [ui](./ui)\n\t- A [react-redux](https://react-redux.js.org/) web interface for running anchor tests. Connects to the server via websockets.\n- [server](./server)\n\t- A [socket.io](socket.io) server. Depends on `@stellar/anchor-tests`.\n\nSee each project for more information. To install and run all applications:\n\n```sh\ngit clone git@github.com:stellar/stellar-anchor-tests.git\ncd stellar-anchor-tests\nyarn install\nyarn build:all\nyarn start:all\n```", "release_dates": ["2024-01-25T19:15:32Z", "2023-11-02T21:07:24Z", "2023-11-02T20:26:39Z", "2023-10-26T13:53:19Z", "2023-10-17T20:16:47Z", "2023-10-17T18:44:42Z", "2023-10-13T20:59:49Z", "2023-10-05T18:45:03Z", "2023-08-01T14:36:20Z", "2023-07-25T00:49:05Z", "2023-06-19T13:34:00Z", "2023-06-15T18:37:47Z", "2023-06-15T17:05:42Z", "2023-02-07T22:56:35Z", "2022-12-20T00:47:11Z", "2022-11-11T17:50:10Z", "2022-10-04T21:09:48Z", "2022-08-17T17:46:10Z", "2022-08-17T16:40:36Z", "2022-07-29T19:59:51Z", "2022-06-28T21:27:15Z", "2022-06-10T19:42:04Z", "2022-04-15T17:27:10Z", "2022-04-13T16:55:03Z", "2022-03-30T14:53:17Z", "2021-11-12T00:50:46Z", "2021-08-05T20:37:28Z", "2021-07-30T17:15:36Z", "2021-07-26T22:38:06Z", "2021-07-26T21:21:51Z"]}, {"name": "stellar-asset-issuer-script", "description": "Python script that issues an asset on the Stellar testnet and creates a simple market for it.", "language": null, "license": null, "readme": "# stellar-asset-issuer-script\nPython script that issues an asset on the Stellar testnet and creates a simple market for it.\n", "release_dates": []}, {"name": "stellar-client", "description": " INACTIVE. Browser based client for stellard. This repository is inactive. It points to the stellard network, which is being replaced by stellar-core. Please refer to the replacement repository, interstellar-client, which points to the stellar-core network.", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Stellar Client\n\n\n[![Build Status](https://travis-ci.org/stellar/stellar-client.svg)](https://travis-ci.org/stellar/stellar-client)\n\nStatus: INACTIVE. This repository is not in active development. It points to the stellard network, which is being replaced by stellar-core. Please refer to the replacement repository, [interstellar-client](https://github.com/stellar/interstellar-client), which points to the [stellar-core](https://github.com/stellar/stellar-core) network.\n\nThe Stellar client is an AngularJS application that allows users to interact with the Stellar network from their browser.\nThis client allows users to register for an account, generate a wallet containing cryptographic keys, and submit transactions to the Stellar network.\n\nYou can see it in action here: https://launch.stellar.org\n\n## Security\n\nEncrypting secret data:\n - Secret keys are encrypted in the browser before storing them in a [stellar-wallet](https://github.com/stellar/stellar-wallet) server.\n - Wallets are encrypted using 256bit AES in GCM mode.\n - The key used to encrypt/decrypt a wallet is derived from a username and password using [scrypt](http://en.wikipedia.org/wiki/Scrypt).\n\nSigning transactions:\n - Transactions are signed using the [Ed25519 signature system](http://ed25519.cr.yp.to/) implemented in [tweetnacl](http://tweetnacl.cr.yp.to/).\n - Signing keys are generated randomly during registration.\n - Transactions are signed in the browser before submitting them to a [stellard](https://github.com/stellar/stellard) server.\n\n## Setting up your dev server\n\n```bash\n\n# Install bower and gulp\nnpm install -g bower\nnpm install -g gulp\n\n# Install dev dependencies\nnpm install\n\n# Install app dependencies\nbower install\n\n# (optional) Install phantomjs for automated testing\nbrew install phantomjs\n\n```\n\n## Starting your dev server\n\n```bash\ngulp develop\n```\n\nBy default, your client will be running against the `stg` environment, which is connected to the stellar testnet.\n\n## Testing against the production wallet and api services\n\nSwitching what service endpoints your client is talking too is as simple as running a gulp task and restarting your dev server.\n\n```bash\ngulp config-prd\ngulp develop\n```\n\n`gulp config-prd` will overwrite app/scripts/config.js with the values from config/prd.js, pointing you at the production apis.\n\n## Public Roadmap\n\nWe've created a [public roadmap](https://trello.com/b/Clb1VMP5/platform-roadmap) so that you can see what work is planned, what is in progress, and when features have been released.  You can see previews of designs, give feedback, and up-vote roadmap items.\n\n[![](https://trello.com/b/Clb1VMP5.png)](https://trello.com/b/Clb1VMP5/platform-roadmap)  \n\n## Contributing\n\n 1. [Fork this project](https://github.com/stellar/stellar-client/fork)\n 2. Create your feature branch (`git checkout -b my-new-feature`)\n 3. Commit your changes (`git commit -am 'Add some feature'`)\n 4. Push to the branch (`git push -u origin my-new-feature`)\n 5. Create a new Pull Request\n\nIf you are wanting to help and not sure what to work on look for issues with the [contribute label](https://github.com/stellar/stellar-client/issues?q=is%3Aopen+is%3Aissue+label%3Acontribute).\n\n## License\n\nStellar Client is open source and permissively licensed under the ISC license. See the LICENSE file for more details.\n", "release_dates": []}, {"name": "stellar-core", "description": "Reference implementation for the peer-to-peer agent that manages the Stellar network.", "language": "C", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "<div align=\"center\">\n<a href=\"https://stellar.org\"><img alt=\"Stellar\" src=\"https://github.com/stellar/.github/raw/master/stellar-logo.png\" width=\"558\" /></a>\n<br/>\n<strong>Creating equitable access to the global financial system</strong>\n<h1>Stellar Core</h1>\n</div>\n<p align=\"center\">\n<a href=\"https://github.com/stellar/stellar-core/actions\"><img alt=\"Build Status\" src=\"https://github.com/stellar/stellar-core/workflows/.github/workflows/build.yml/badge.svg?branch=auto\" /></a>\n</p>\n\nStellar-core is a replicated state machine that maintains a local copy of a cryptographic ledger and processes transactions against it, in consensus with a set of peers.\nIt implements the [Stellar Consensus Protocol](https://github.com/stellar/stellar-core/blob/master/src/scp/readme.md), a _federated_ consensus protocol.\nIt is written in C++14 and runs on Linux, OSX and Windows.\nLearn more by reading the [overview document](https://github.com/stellar/stellar-core/blob/master/docs/readme.md).\n\n# Documentation\n\nDocumentation of the code's layout and abstractions, as well as for the\nfunctionality available, can be found in\n[`./docs`](https://github.com/stellar/stellar-core/tree/master/docs).\n\n# Installation\n\nSee [Installation](./INSTALL.md)\n\n# Contributing\n\nSee [Contributing](./CONTRIBUTING.md)\n\n# Running tests\n\nSee [running tests](./CONTRIBUTING.md#running-tests)\n", "release_dates": ["2024-03-01T18:54:04Z", "2024-02-29T03:25:13Z", "2024-02-26T19:04:55Z", "2024-02-05T20:44:03Z", "2024-02-02T16:37:50Z", "2024-01-26T18:55:11Z", "2024-01-24T21:29:33Z", "2024-01-09T22:04:05Z", "2023-12-20T04:08:26Z", "2023-12-14T17:39:14Z", "2023-12-04T22:55:08Z", "2023-09-20T17:46:52Z", "2023-09-19T21:42:55Z", "2023-09-15T21:45:51Z", "2023-08-02T23:30:51Z", "2023-07-24T21:18:03Z", "2023-07-10T19:08:47Z", "2023-06-30T03:38:26Z", "2023-06-21T18:48:57Z", "2023-05-30T22:44:31Z", "2023-05-24T21:48:57Z", "2023-05-23T18:38:31Z", "2023-05-02T03:53:09Z", "2023-04-24T18:53:11Z", "2023-04-04T22:01:59Z", "2023-03-24T16:43:38Z", "2023-02-28T18:00:43Z", "2023-02-21T19:40:23Z", "2023-01-31T18:50:48Z", "2023-01-24T03:31:54Z"]}, {"name": "stellar-core-prometheus-exporter", "description": "Stellar Core Prometheus Exporter", "language": "Python", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Overview\n\nThe Stellar Core Prometheus Exporter reads metrics exposed by the\nstellar-core daemon and exposes them in prometheus format.\n\n# Configuration\n\nOptional config can be provided using CLI arguments or environment variables.\n\nSupported configuration options:\n* **--stellar-core-address** - address of monitored stellar-core. Defaults to `http://127.0.0.1:11626`. Can also be set using `STELLAR_CORE_ADDRESS` environment variable\n* **--port** - listening port. Defaults to `9473`. Can also be set using `PORT` environment variable\n\n# Grafana dashboard\n\nGrafana can be used to visualise data. Example dashboards are shipped with this code.\nLatest versions is also available on [grafana.com](https://grafana.com/orgs/stellar/dashboards)\n\nPlease refer to the [documentation](https://github.com/stellar/packages/blob/master/docs/monitoring.md)\nfor details.\n\n# Docker image\n\nIncluded Dockerfile uses apt package to deploy the exporter. Example build command:\n```\ndocker build -t stellar-core-prometheus-exporter:latest .\n```\n\n# Installing from pypi\n\nTo download/test package in pypi you can use venv:\n```\npython3 -m venv venv\n. venv/bin/activate\n```\n\nInstall:\n```\npython3 -m pip install stellar_core_prometheus_exporter\n```\n\nRun:\n```\n./venv/bin/stellar-core-prometheus-exporter\n```\n\n# Releasing new version\n\n* ensure you bumped version number in setup.py. PyPi does not allow version reuse\n* build new package:\n```\npython3 setup.py sdist bdist_wheel\n```\n* push to testpypi:\n```\npython3 -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*\n```\n* test by installing the package (see above). If all good release:\n```\npython3 -m twine upload dist/*\n```\n", "release_dates": []}, {"name": "stellar-dbt-public", "description": "Public DBT instance to aid in data transformation for analytics purposes", "language": null, "license": null, "readme": "# stellar-dbt-public\nPublic DBT instance to aid in data transformation for analytics purposes.\nIf you're interested in setting up your own dbt project, you can find detailed instructions in the [dbt documentation](https://docs.getdbt.com/docs/introduction).\n\n\n## Table of Contents\n- [dbt Overview](#dbt-overview)\n    - [Workflow](#workflow)\n    - [dbt Project Structure](#dbt-project-structure)\n    - [Tests](#tests)\n- [Getting Started](#getting-started)\n    - [Oauth connection](#oauth)\n- [dbt Setup](#dbt-setup)    \n- [Working with dbt](#working-with-dbt)\n    - [Running Models](#running-models)\n    - [Running Tests](#running-tests)\n- [Project Structure](#project-structure)\n    - [Development Folders](#development-folders)\n- [New Releases](#New-code-release)\n\n\n## dbt Overview \n\ndbt is composed of different moving parts working harmoniously. All of them are important to what dbt does \u2014 transforming data.  When you execute `dbt run`, you are running a model that will transform your data without that data ever leaving your warehouse.\n\n### Workflow\n\nThe top level of a dbt workflow is the project. A project is a directory of a `.yml` file (the project configuration) and either `.sql` or `.py` files (the models). The project file tells dbt the project context, and the models let dbt know how to build a specific data set. In the end, the purpose of these models is to simplify analytics by generating data mart tables.\n\nA model is a single file containing a final select statement, and a project can have multiple models, and models can even reference each other.\n\nIn dbt, you can configure the materialization of your models. Materializations are strategies for persisting dbt models in a warehouse. There are four types of materializations built into dbt. They are:\n1. Table (your model is rebuilt as a table on each run)\n2. View (your model is rebuilt as a view on each run)\n3. Incremental (allow dbt to insert or update records into a table since the last time that dbt was run.)\n4. Ephemeral (models are not directly built into the database. instead, dbt will interpolate the code from this model into dependent models as a common table expression.)\n\n### dbt Project Structure\n\n1. Staging (data preparation)\nThe purpose of the source layer is to receive the raw data from the source and define preparations for further analysis.\n\n  What to do on staging:\n\n  - Column selection\n  - Consistently renaming columns.\n  - Definition of data types (casting columns to String, Numeric...)\n  - Flattening of structured objects\n  - Initial filters\n  - Tests (source.yml)\n  - Basic cleanup, like replacing empty strings with NULL, for example\n\n  What is not done in the source:\n\n  - Joins\n  - Creating business rules\n\n2. Intermediate (data preparation)\nIn the intermediate layer, the preparation for directing the data to the marts takes place. Not every table in the staging layer will become an intermediate. In staging, it is possible to combine different tables to start assembling business rules.\n\n  What is done in the intermediate:\n\n  - Join between different source queries\n  - More complex functions that would not enter the staging layer\n  - Aggregations\n  - Creation of business metrics/rules\n\n  What not to do in intermediate:\n\n  - Ingestion of raw data\n  - Dimensional modeling (separation of facts, dimensions and marts)\n\n3. Marts (final transformations)\nIn the marts layer, data is organized for the dimensional model, as well as the configuration for incremental materialization of final tables. Each model will be accompanied by a `.yml` file with the same name. This file contains model and column descriptions and tests.\n\n  What is done at the marts:\n\n  - Organization of data in a dimensional model (star schema)\n  - Creation of sk keys\n  - Mart-specific tweaks\n  - Join between sources and/or stagings\n  - Documentation and testing\n\n  What not to do at marts:\n\n  - Data cleaning\n  - Opening of staging\n\nThe models are divided into:\n\n  - Dimension tables (dim_table): where the dimensions of the models will be defined and gather all the sources of the respective dimension;\n  - Fact tables (fct_table): where the final models of the business strategy to be analyzed will be located;\n  - Aggregate tables (agg_table): where are aggregations of fact tables by one dimension.\n\n### Tests\n\nTests are assertions you make about your models and other resources in your dbt project (e.g. sources, seeds and snapshots). When you run `dbt test`, dbt will tell you if each test in your project passes or fails. Like almost everything in dbt, tests are SQL queries. In particular, they are select statements that seek to grab \"failing\" records, ones that disprove your assertion. \n\nThere are two ways of defining tests in dbt:\n\n1. A singular test is testing in its simplest form: If you can write a SQL query that returns failing rows, you can save that query in a `.sql` file within your test directory.\n2. A generic test is a parameterized query that accepts arguments. The test query is defined in a special test block (like a macro). Once defined, you can reference the generic test by name throughout your `.yml` files\u2014define it on models, columns, sources, snapshots, and seeds.\n\n\n## Getting Started \n\nIn order to develop on this repository, we must first get dbt and follow the installation procedure. First of all, clone the git repository locally. Afterwards, you can follow best practices by setting up a virtual environment for dbt installation or installing it directly (In that case, you can skip to the [dbt setup](#setting-up-dbt)).\n\nAfter cloning, create a virtual environment for the installation. The recommended python version for dbt is 3.8 and any of its patches.\n\n1. Follow the guide and install the [virtualenv package](https://virtualenv.pypa.io/en/latest/installation.html) through any of the available methods.\n\n2. In order to create a virtual environment, run the command: ``` virtualenv {{env_name}} -p {{python-version}} ```, in case you wish for an specific python environment version, or simply run ``` virtualenv {{env_name}} ``` to install the system's python version on the current repository. More information can be obtained [here](https://virtualenv.pypa.io/en/latest/user_guide.html).\n\n3. Source the virtual environment through: ``` source ~/path/to/venv/bin/activate ``` on Linux and ```.\\venv\\Scripts\\activate.ps1``` on Windows. (It must be activated each time you open the project). Ensure that you are in the folder where the virtual environment was created. If it is activated correctly, the terminal will display a flag (venv). To deactivate the virtual environment, simply run the command: ```deactivate```\n\n3. By invoking dbt from the CLI, it should parse `dbt_project.yml` and, in case it doesn't already exist, create a `~/.dbt/profiles.yml`. This file exists outside of the project to avoid sensitive credentials in the version control code and it's not recommended to change it's location. **There exists a profile.yml file inside the project folder, but it is not used when developing locally, only for the CI/CD pipeline, and it must not contain any exposed access keys**.\n\n4. In order to connect to the bigquery project, there are a couple methods of authentication supported by BQ. The BigQuery account to be used must be your personal account. We recommend using Oauth to connect through gcloud CLI tools. Any extra information can be found on the official dbt-bigquery adapter [documentation](https://docs.getdbt.com/reference/warehouse-setups/bigquery-setup#).\n\n### Oauth\n5. Oauth - Follow the GCP CLI installation guide [here](https://cloud.google.com/sdk/docs/install). After the installation, run `gcloud init` and provide the requested account information in order to properly setup your Oauth GCP account. The account will be used to run the queries and access the database, so you should use your GCP personal account for that.\n\n6. Open the `profiles.yml` file and add the following configurations:\n``` YML\n{{my_dbt_project_name}}:\n  outputs:\n    development:\n      dataset: your_dbt_dataset ##the name of your dataset.\n      maximum_bytes_billed: 5500000000 ##this field limits the maximum number of processed bytes. it helps control processing costs, we recommend 5500000000.\n      job_execution_timeout_seconds: 300 ##the number of seconds dbt should wait for queries to complete, after being submitted successfully. we sugest 300 seconds. \n      job_retries: 1 ##the number of times that dbt will retry failing queries. the default is 1.\n      location: your-location ##your BQ dataset location\n      method: oauth\n      priority: interactive ##the priority for the BQ jobs that dbt executes.\n      project: your_bigquery_project_name ##your GCP project id\n      threads: 1 ##the number of threads represents the maximum number of paths through the graph dbt may work on at once. we recommed 1\n      type: bigquery\n  target: development\n```\nIn order to avoid any additional costs, the same location of your BigQuery dataset should be used.\n\nFor more information on `profiles.yml` setup, please refer to the dbt [documentation](https://docs.getdbt.com/reference/project-configs/profile).\n\n## dbt Setup\n\n1. Run ``` pip install -r requirements.txt ``` to install all the necessary packages.\n\n2. To verify if all libraries have been correctly installed, use the command ```pip list```.\n\n3. Run ``` dbt deps ``` to install the utils packages from dbt.\n\n3. Following best practices, a dbt project informs dbt about the contect of your project and how to transform your data. To do so, open the ```dbt_project.yml``` project configuration file on your dbt project folder.\n``` YML\nname: 'your_dbt_project_name' ##the name of a dbt project.\nversion: '1.0.0' ##version of your project.\nconfig-version: 2 ##specify your dbt_project.yml as using the v2 structure.\n\nprofile: 'your_profile' ##the profile dbt uses to connect to your data platform.\n\nmodel-paths: [\"models\"] ##specify a custom list of directories where models and sources are located.\nanalysis-paths: [\"analyses\"] ##specify a custom list of directories where analyses are located.\ntest-paths: [\"tests\"] ##directories to where your singular test files live.\nseed-paths: [\"seeds\"] ##specify a custom list of directories where seed files are located.\nmacro-paths: [\"macros\"] ##specify a custom list of directories where macros are located.\nsnapshot-paths: [\"snapshots\"] ##directories to where your snapshots live.\n\nmodels:\n  {{my_dbt_project_name}}:\n    staging:\n      +materialized: view ##how your stagings models will materialized.\n      +dataset: raw ##the subfolder that will be created within your dataset models where the stagings will be located.\n    intermediate:\n      +materialized: table ##how your intermediate models will materialized.\n      +dataset: conformed ##the subfolder that will be created within your dataset models where the intermediates will be located.\n    marts:\n      +materialized: table ##how your marts models will materialized.\n      +dataset: marts ##the subfolder that will be created within your dataset models where the marts will be located.\n      ledger_current_state:\n        +materialized: table  ##how your ledger current state model will materialized.\n        +tags: current_state ##tag used to resource selection syntax.\n```\n\n4. You can also execute the command `dbt debug` to ensure that all configurations are working correctly, and it is possible to initiate data loading and transformation.\n\n## Working with dbt\n\n### Running Models\n\nExecuting a dbt model is the same as executing a SQL script. There are many ways to run dbt models: \n\n1. Run the entire project through `dbt run`\n\n2. Run tagged models, paths or configs through `dbt run --select tag:tag_1 tag_2 tag_3`.\n\n3. Run specific models through `dbt run --select model_1 model_2 model_3`. **Note that this runs only the specified models, unless you follow said model(s) with execution method #4**\n\n4. Run downstream or upstream models by adding a '+' at the beginning(downstream), end(upstream) or both on the model name `dbt run --select +model_1+`\n\nOn top of that, dbt supports --excluding, --defer, --target and many other selection types. To see more, please refer to the [documentation](https://docs.getdbt.com/reference/node-selection/syntax).\n\n### Running Tests\n\nExecuting tests works the same way as executing runs, with the command `dbt test` accepting many of the same parameters. This will run both schema tests and unique tests, unless commanded otherwise. For more information on the syntax, consult the [documentation](https://docs.getdbt.com/reference/node-selection/syntax).\n\nIn dbt, tests come in two ways. Schema tests, which are pre-built macros and can be called in YML schema files, and unique tests, which are user-made and have their own .SQL files, stored in the `tests` folder. Both tests will be executed during a `dbt test`, unless further node selection is provided. A dbt test will fail when the underlying SQL selection returns a result row, being approved when no rows are returned. For further information on tests, please refer to the [documentation](https://docs.getdbt.com/reference/test-configs).\n\n## Project Structure\n\nThe Stellar-dbt project follows a staging/marts approach to modelling. The staging step focuses on transforming and preparing the tables for joining on the marts step. In order to diminish cost, all staging `.sql` files are materialized as ephemeral in the `dbt_project.yml`, allowing code modularity and decoupling while not raising storage costs. \n\nThe marts, on the other hand, are materialized as tables, in order to reduce querying time on the BI and other exposures. It is in this step that tables are joined together to obtain analytical results or rejoin needed information to facilitate date exploration.\n\n### Development Folders\n\n| Name | Description |\n|------|-------------|\n|Source| Stores the raw data that will be used as inputs for the dbt transformations. |\n|Staging| Stages the pre-processed or cleaned data before performing the transformations. |\n|Intermediate| Contains the transformed and processed data. |\n|Marts| Houses the final data models or data marts, which are the end results of the dbt project. |\n|Docs| Stores documentation related to your dbt project. |\n|Macros| Contains reusable SQL code snippets known as macros. |\n|Tests| Contains defining tests to validate the accuracy and correctness of the data transformations. |\n\n### New Releases\n\nIn order to enable other repositories to work with and build on top of this dbt repo, it was configured as a package. Due to this, commiting to the repository requires a few extra steps to ensure git tagging is consistent, so that changes will not break any code downstream. When commiting changes, there are 3 main version changes that can be applied to the repository, as follows:\n\n| Change | Description |\n|------|-------------|\n|Major| Version when making incompatible changes |\n|Minor| Version change when adding functionalities in a backward compatible manner |\n|Patch| Version change when making backward compatible bug fixes |\n\nIn order to apply git tagging properly, the last commit message from a repo must contain a hashtag(#) followed by the change type present in that commit. This will allow github to detect the type of change being pushed and increment the version accordingly. For example:\n\n```'Fix trade-agg bug #patch'```", "release_dates": []}, {"name": "stellar-demo-wallet", "description": "Provides a front-end interface to test SEP interoperability. Website at https://demo-wallet.stellar.org/ ", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Stellar Demo Wallet\n\nThe Stellar Demo Wallet is our newly rebuilt application for interactively\ntesting anchor services.\n\nIf you would like to automate testing of your anchor service, check out the\nSDF's [anchor tests suite](https://github.com/stellar/stellar-anchor-tests)\nviewable at\n[https://anchor-tests.stellar.org/](https://anchor-tests.stellar.org/).\n\nThis repository was originally created for the\n[Build a Stellar Wallet](https://developers.stellar.org/docs/building-apps/)\ntutorial series. (That project has since moved over\n[here](https://github.com/stellar/docs-wallet)).\n\nIf you want to use parts or all of the project to kickstart your own wallet,\nfeel free to clone or copy any pieces that may be helpful.\n\n## Mainnet vs. Testnet\n\nThis application defaults to using Stellar's testnet.\n\nThis application can be used on Stellar's mainnet by setting\n**HORIZON_PASSPHRASE** & **HORIZON_URL** on `window._env_` object (this project\nuses _packages/demo-wallet-client/public/settings/env-config.js_ file).\n\n```typescript\nwindow._env_ = {\n  HORIZON_PASSPHRASE: \"Public Global Stellar Network ; September 2015\",\n  HORIZON_URL: \"https://horizon.stellar.org\",\n};\n```\n\n**All accounts on mainnet that are used with this application should be\nconsidered compromised.** If you want to test services on mainnet with this\ntool, make sure to create a new account and fund it with the minimum assets\nrequired.\n\nNote, that dy default base fee is 100 stroops. That may not be enough for\nmainnet application, and base fee can be changed via `REACT_APP_BASE_FEE`\nenvironment variable\n\n## Getting A Test Account Up and Running\n\nYou can use the demo wallet to interact with the following anchor services:\n\n- Regulated Assets API ([SEP-8])\n- Hosted Deposit and Withdrawals ([SEP-24])\n- Deposit & Withdrawal API ([SEP-6])\n- Cross-Border Payments API ([SEP-31])\n\nYou can connect to any domain that has a Stellar Info File (also known as\n[SEP-1], or a stellar.toml file).\n\nThe instructions below are for demo-ing standard integrations supported by\nStellar test server, testanchor.stellar.org, or by the [SEP-8] reference server,\nsep8-server.dev.stellar.org. For these integrations, the logs to the right of\nthe screen will show every network call.\n\n### Demo-ing a Regulated Asset Payment ([SEP-8])\n\n1. Click \"Generate keypair\", and then click \"Create account\" - this will create\n   a balance of 10,000 XLM.\n2. Click \u201cAdd asset\u201d and add `MYASSET` with the anchor home domain\n   `sep8-server.dev.stellar.org`.\n3. Click \u201cAdd trustline\u201d - this will allow you to hold MYASSET.\n4. Click on the \"Copy\" link on the right of your public key and use that value\n   to get some unities of MYASSET using the link\n   `https://sep8-server.dev.stellar.org/friendbot?addr=<paste_your_address_here>`.\n   Refresh the [demo-wallet page](https://demo-wallet.stellar.org/) to see funds\n   in your account.\n5. Select \"SEP-8 Send\" from the dropdown of MYASSET and click \"Start\" in the\n   modal.\n6. In the \"destination\" field, input an address that also has a trustline to\n   MYASSET.\n7. The modal will display the approval criteria used by the SEP-8 server.\n   Depending on the conditions described there your payment can be automatically\n   approved or you may be required to undergo an additional KYC step.\n8. After your payment gets revised and signed by the SEP-8 reference server\n   you'll need to review the updated transaction before the demo wallet submits\n   the payment.\n9. If the payment has been successfully sent you'll see \"SEP-8 send payment\n   completed \ud83c\udf89\" in the logs.\n\n### Demo-ing a Deposit on Testnet with Hosted Deposit and Withdrawal ([SEP-24])\n\n1. Click \"Generate keypair\", and then click \"Create account\" - this will create\n   a balance of 10,000 XLM.\n2. Click \u201cAdd asset\u201d and add `SRT` (this stands for Stellar Reference Token,\n   it\u2019s our representation of XLM for the test server) with the anchor home\n   domain `testanchor.stellar.org`.\n3. Click \u201cAdd trustline\u201d - this will allow you to hold SRT.\n4. Select \u201cSEP-24 deposit\u201d from the dropdown for your SRT asset and click\n   \"Start\" in the modal.\n5. If your browser doesn't already, make sure it allows pop-ups - this is how\n   the demo wallet requests KYC info.\n6. Enter your name and email in the pop-up - this information doesn't need to be\n   real, but the interface will want a valid email.\n7. Click \u201cSkip confirmation\u201d - skipping it won't be possible in live\n   integrations but helps the process move ahead in the demo.\n8. Select the asset you would like to provide to the anchor. Note that there is\n   no real asset you actually need to provide off-chain, it's just for\n   demonstration.\n9. Enter a number into the amount and click \"Submit\".\n10. If you opted to provide \"USD\" in the previous form, you'll be asked to\n    confirm the exchange rate from USD to SRT. Select \"Confirm Transaction\" to\n    continue.\n11. Leave the pop-up window open while you wait to see the deposit of SRT made\n    to your account - you can close when you see \u201cStatus\u201d is complete and you\n    have SRT.\n\n### Demo-ing Cross-Border Payments ([SEP-31]) on Testnet\n\n_Note: specifically in the case of demo-ing SEP-31 in the Demo Wallet, notice\nthe public and secret keys don't represent the Sending Client but instead the\nSending Anchor's account. In SEP-31, the only Stellar transaction happening is\nbetween the Sending and the Receiving anchors._\n\n1. Follow the steps above in order to establish an amount of SRT to send.\n2. Select \u201cSEP-31 Send\u201d from the dropdown for your SRT asset and click \"Start\"\n   in the modal.\n3. Enter the requested information in the pop-up - none of the info has to be\n   real for this testanchor.stellar.org demo, this is only to show the fields\n   required. When testing another anchor you may need to adhere to their\n   validation requirements.\n4. If the payment has been successfully sent you'll see \"SEP-31 send payment\n   completed\" in the logs.\n\n### Hosting Anchor Services Locally\n\nYou can serve `stellar.toml` files from `localhost`. When using locally hosted\nstellar.toml files on demo-wallet.stellar.org, some browsers might block them\nfor security reasons if you\u2019re not using `https`. If you\u2019re running the demo\nwallet locally, this is not a problem.\n\n## Running the Demo Wallet Locally\n\nYou can run the demo wallet locally, either by installing the application on\nyour machine or by using Docker.\n\n### Local Installation\n\n```bash\nyarn install\n```\n\nAdd **CLIENT_DOMAIN** (where `stellar.toml` is hosted) and the wallet backend\n**WALLET_BACKEND_ENDPOINT** to the `window._env_` object in\n_packages/demo-wallet-client/public/settings/env-config.js_.\n\nNOTE: if using a locally running test anchor (in docker) use\n_docker.for.mac.host.internal_, this will allow the anchor that's running in a\ndocker container to access the host network where the client domain (server\nhosting the `stellar.toml`) is running. ex:\n\n```typescript\nwindow._env_ = {\n  CLIENT_DOMAIN: \"docker.for.mac.host.internal:7000\",\n  WALLET_BACKEND_ENDPOINT: \"http://demo-wallet-server.stellar.org\",\n};\n```\n\nBuild `shared` files that are consumed by both the client and server.\n\n```bash\nyarn build:shared\n```\n\nAnd run the client:\n\n```bash\nyarn start:client\n```\n\nTo build the client app for production, run:\n\n```bash\nyarn build:client\n```\n\nTo run the server locally:\n\n```bash\nyarn start:server\n```\n\nAnd build the server for production:\n\n```bash\nyarn build:server\n```\n\n### Docker\n\nIf you want to run the demo wallet on testnet, building the project is easy.\n\n```bash\ndocker compose build\n```\n\nThen, launch the containers.\n\n```bash\ndocker compose up\n```\n\nNote that the docker compose file defaults to using SDF's demo wallet server,\nbut you are free to edit the compose file to use a local instance of the server.\n\n---\n\n## Release Notes\n\n### v1.2\n\n- SEP-06 now supported\n- SEP-08 now supported\n- Fixed a [bug](https://github.com/stellar/stellar-demo-wallet/issues/188) when\n  overriding home domain\n- Fixed an [issue](https://github.com/stellar/stellar-demo-wallet/issues/196)\n  where balance amounts were being overwritten\n- Sending to Muxed Accounts is now supported\n\n### [v1.1](https://github.com/stellar/stellar-demo-wallet/releases/tag/v1.1.0)\n\n- Fix for local CORS issue\n- Updated Sentry to log exceptions\n\n### v1.0\n\n- Revamped UI\n- All SEPs are integrated into one tool\n  - SEP-24 and SEP-31 are now found in the Asset action drop-down menus\n- Ablity to download logs\n- Claimable Balances supported\n\n### Helpful links\n\n- [https://www.stellar.org/developers](https://www.stellar.org/developers)\n- [https://stellar.github.io/js-stellar-sdk/](https://stellar.github.io/js-stellar-sdk/)\n- [https://github.com/stellar/js-stellar-sdk](https://github.com/stellar/js-stellar-sdk)\n\n[sep-1]:\n  https://github.com/stellar/stellar-protocol/blob/master/ecosystem/sep-0001.md\n[sep-8]:\n  https://github.com/stellar/stellar-protocol/blob/master/ecosystem/sep-0008.md\n[sep-24]:\n  https://github.com/stellar/stellar-protocol/blob/master/ecosystem/sep-0024.md\n[sep-31]:\n  https://github.com/stellar/stellar-protocol/blob/master/ecosystem/sep-0031.md\n[sep-6]:\n  https://github.com/stellar/stellar-protocol/blob/master/ecosystem/sep-0006.md\n", "release_dates": ["2022-01-18T16:59:23Z", "2021-09-23T21:56:03Z", "2021-09-23T16:04:08Z", "2021-08-11T21:10:04Z", "2021-08-09T20:51:42Z", "2021-07-29T20:11:02Z", "2021-07-19T20:01:22Z"]}, {"name": "stellar-design-system", "description": "Components for Stellar\u2019s design system", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Stellar Design System\n\nComponents for Stellar Development Foundation\u2019s design system.\n\n## Usage\n\nInstall as a dependency:\n\n```bash\nyarn add @stellar/design-system\n```\n\nAdd the main CSS file to your project (for example, the main index file of your\nReact project).\n\n```javascript\nimport \"@stellar/design-system/build/styles.min.css\";\n```\n\nImport Stellar Design System components\n\n```javascript\nimport { Button, Input } from \"@stellar/design-system\";\n```\n\nAvailable components can be found\n[here](./@stellar/design-system/src/components).\n\n## Development\n\nThis repo has two parts to it:\n\n- [Stellar Design System repo](./@stellar/design-system/) - everything for the\n  design system,\n- [Stellar Design System website repo](./@stellar/design-system-website/) -\n  website for the design system.\n\nThis project is tested with\n[BrowserStack](https://email.browserstack.com/c/eJwlzE1uwyAURtHV1DOQMf8D1lIB7yNBcewaSNl-LXV8dS6CMNas0imrFwo6abJLDUbCaKE2CCPNt1RpS8KQLQlIq9LCb94W3ivhVS9WGq4PjsEKsZ-TPh2xD8HesR6SPRpwMO3JOefJs3yZPL_Uijvv_Kb9Segvns_38gxZSYKzSaikfIFdBbIUSWFD1NbFZQ9zTp7aOTtaHzH_yxbqL0a8v31g32PjZ3v8AQZ4Rr0).\n\n### Scripts\n\n`build:sds` build Stellar Design System (`sds`) project only\n\n`build:sds-web` build Stellar Design System Website (`sds-web`) project only\n\n`build` build both projects\n\n`start:sds` start `sds` project for local development\n\n`start:sds-web` start `sds-web` project for local development\n\n`clean` delete `node_modules` and `build` directories in the whole repo\n\n**Note** You need to run each `start` command in its own window or tab.\n", "release_dates": ["2024-01-05T19:24:38Z", "2023-12-21T19:01:45Z", "2023-11-29T15:29:48Z", "2023-11-02T18:46:27Z", "2023-10-23T17:14:41Z", "2022-07-28T20:33:41Z", "2022-03-10T19:19:41Z", "2022-02-28T17:20:21Z", "2022-01-26T21:05:31Z", "2022-01-11T15:23:00Z", "2021-11-09T20:22:54Z", "2021-11-05T13:06:18Z", "2021-10-05T20:08:32Z", "2021-08-09T19:02:32Z", "2021-07-23T18:21:06Z", "2021-07-22T20:24:39Z", "2021-07-21T18:03:18Z", "2021-07-08T19:03:08Z", "2021-06-28T14:19:20Z", "2021-06-04T18:34:56Z", "2021-01-06T20:31:03Z", "2020-12-16T16:55:59Z", "2020-12-15T20:21:27Z"]}, {"name": "stellar-disbursement-platform-backend", "description": "Stellar Disbursement Platform Backend", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Stellar Disbursement Platform Backend\n\n> Note: you can find a more thorough and user-friendly documentation of this project at [Stelar Docs](https://docs.stellar.org/category/use-the-stellar-disbursement-platform).\n\n## Table of Contents\n\n- [Introduction](#introduction)\n- [Install](#install)\n- [Quick Start](#quick-start)\n- [Architecture](#architecture)\n  - [Core](#core)\n  - [Transaction Submission Service](#transaction-submission-service)\n  - [Database](#database)\n- [Wallets](#wallets)\n- [Contributors](#contributors)\n  - [State Transitions](#state-transitions)\n\n## Introduction\n\nThe Stellar Disbursement Platform (SDP) enables organizations to disburse bulk payments to recipients using Stellar.\n\nThroughout this documentation, we'll define \"users\" as members of the organization using the SDP to make payments, while defining \"recipients\" as those receiving payments.\n\n## Install\n\nInstall golang and make sure `$GOPATH/bin` is in your `$PATH`. Then run the following.\n\n``` sh\ngit clone git@github.com:stellar/stellar-disbursement-platform-backend.git\ncd stellar-disbursement-platform-backend\nmake go-install\nstellar-disbursement-platform --help\n```\n\n## Quick Start\n\nTo quickly test the SDP using preconfigured values, see the [Quick Start Guide](./dev/README.md).\n\n## Secure Operation Manual\n\nThis manual outlines the security measures implemented in the Stellar Disbursement Platform (SDP) to protect the integrity of the platform and its users. By adhering to these guidelines, you can ensure that your use of the SDP is as secure as possible.\n\nSecurity is a critical aspect of the SDP. The measures outlined in this document are designed to mitigate risks and enhance the security of the platform. Users are strongly encouraged to follow these guidelines to protect their accounts and operations.\n\n### Implementation of reCAPTCHA\n\nGoogle's reCAPTCHA has been integrated into the SDP to prevent automated attacks and ensure that interactions are performed by humans, not bots.\n\nReCAPTCHA is enabled by default and can be disabled in the development environment by setting the `DISABLE_RECAPTCHA` environment variable to `true`.\n\n**Note:** Disabling reCAPTCHA is not supported for production environments due to security risks.\n\n### Enforcement of Multi-Factor Authentication\n\nMulti-Factor Authentication (MFA) provides an additional layer of security to user accounts. It is enforced by default on the SDP and it relies on OTPs sent to the account's email.\n\nMFA is enabled by default and can be disabled in the development environment by setting the `DISABLE_MFA` environment variable to `true`.\n\n**Note:** Disabling MFA is not supported for production environments due to security risks.\n\n### Best Practices for Wallet Management\n\nThe SDP wallet should be used primarily as a hot wallet with a limited amount of funds to minimize potential losses.\n\n#### Hot and Cold Wallets\n\n- A hot wallet is connected to the internet and allows for quick transactions.\n- A cold wallet is offline and used for storing funds securely.\n- Learn more about these concepts at [Investopedia](https://www.investopedia.com/hot-wallet-vs-cold-wallet-7098461).\n\n### Distribution of Disbursement Responsibilities\n\nTo enhance security, disbursement responsibilities should be distributed among multiple financial controller users.\n\n#### Recommended Configuration\n\n1. **Approval Flow**: Enable the approval flow on the organization page to require two users for the disbursement process. The owner can do that at *Profile > Organization > ... > Edit details > Approval flow > Confirm*.\n2. **Financial Controller Role**: Create two users with the *Financial Controller* role on the organization page to enforce separation of duties. The owner can do hat at *Settings > Team Members*.\n3. **Owner Account Management**: Use the Owner account solely for user management and organization configuration. Avoid using the Owner account for financial controller tasks to minimize the exposure of that account.\n\n## Architecture\n\n![high_level_architecture](./docs/images/high_level_architecture.png)\n\nThe [SDP Dashboard][sdp-dashboard] and [Anchor Platform] components are separate projects that must be installed and configured alongside the services included in this project.\n\nIn a future iteration of this project, the Transaction Submission Service (TSS) will also be moved to its own repository to be used as an independent service. At that point, this project will include the services contained in the Core module shown in the diagram above.\n\n### Core\n\nThe SDP Core service include several components started using a single command.\n\n```sh\nstellar-disbursement-platform serve --help\n```\n\n#### Dashboard API\n\nThe Dashboard API is the component responsible for enabling clients to interact with the SDP. The primary client is the [SDP Dashboard][sdp-dashboard], but other clients can use the API as well.\n\n##### Metrics\n\nThe Dashboard API component is also responsible for exporting system and application metrics. We only have support for `Prometheus` at the moment, but we can add new monitors clients in the future.\n\n#### Message Service\n\nThe Message Service sends messages to users and recipients for the following reasons:\n\n- Informing recipients they have an incoming disbursement and need to register\n- Providing one-time passcodes (OTPs) to recipients\n- Sending emails to users during account creation and account recovery flows\n\nNote that the Message Service requires that both SMS and email services are configured. For emails, AWS SES is supported. For SMS messages to recipients, Twilio is supported. AWS SNS support is not integrated yet.\n\nIf you're using the `AWS_EMAIL` sender type, you'll need to verify the email address you're using to send emails in order to prevent it from being flagged by email firewalls. You can do that by following the instructions in [this link](https://docs.aws.amazon.com/ses/latest/dg/email-authentication-methods.html).\n\n#### Wallet Registration UI\n\nThe Wallet Registration UI is also hosted by the Core server, and enables recipients to confirm their phone number and other information used to verify their identity. Once recipients have registered through this UI, the Transaction Submission Server (TSS) immediately makes the payment to the recipients registered Stellar account.\n\n#### Core + Anchor Platform Integration\n\nFor a full understanding on how the Core and Anchor Platform components interact, as well as the best security and configuration practices, please refer to the [Anchor Platform Integration Points](https://docs.stellar.org/stellar-disbursement-platform/anchor-platform-integration-points) section of the Stellar Docs.\n\n### Transaction Submission Service\n\nRefer to documentation [here](/internal/transactionsubmission/README.md).\n\n#### Core + TSS Integration\n\nCurrently, Core and Transaction Submission Service (TSS) interact at the database layer, sharing the `submitter_transactions` table to read and write state. The interaction is as follows:\n\n1. Core inserts rows into the `submitter_transactions` table, queuing payments\n2. The TSS polls the `submitter_transactions` table, detecting payments\n3. For each payment detected, the TSS creates and submits a transaction to the Stellar network, monitoring its state until it is confirmed to have been included in a ledger or failed with a nonrecoverable error\n4. Core's Dashboard API reads from the `submitter_transactions` table on demand to fetch the state of each payment\n\nIn future iterations of the project, the Transaction Submission Service will provide an API for clients such as the SDP to use for queuing and polling the state of transactions.\n\n### Database\n\nTo manage the migrations of the database, use the `db` subcommand.\n\n```sh\nstellar-disbursement-platform db --help\n```\n\nNote that there is an `auth` subcommand that has its own `migrate` sub-subcommand. Operators of the SDP will need to ensure migrations for both the core and auth components are run.\n\n```sh\nstellar-disbursement-platform db migrate up\nstellar-disbursement-platform db auth migrate up\n```\n\n#### Core Tables\n\nThe tables below are used to facilitate disbursements.\n\n![core schema](./docs/images/core_schema.png)\n\nThe tables below are used to manage user roles and organizational information.\n\n![admin schema](./docs/images/admin_schema.png)\n\n#### TSS Tables\n\nThe tables below are shared by the transaction submission service and core service.\n\n![tss schema](./docs/images/tss_schema.png)\n\nNote that the `submitter_transactions` table is used by the TSS and will be managed by the service when moved to its own project.\n\n## Wallets\n\nPlease check the [Making Your Wallet SDP-Ready](https://docs.stellar.org/stellar-disbursement-platform/making-your-wallet-sdp-ready) section of the Stellar Docs for more information on how to integrate your wallet with the SDP.\n\n## Contributors\n\nThis section is a work-in-progress.\n\n### State Transitions\n\nThe state transitions of a disbursement, payment, message, and wallet (i.e. recipient Stellar account) are described below.\n\n#### Disbursements\n\n```mermaid\nstateDiagram-v2\n    [*] --> Draft:Started creating the disbursement\n    Draft --> [*]:User deleted\\nthe draft\n    Draft --> Draft:File Ingestion failed\\n due to wrong data\n    Draft --> Ready:Upload\n    Ready --> Started:User Started Disbursement\\n in the Dashboard\n    Started --> Paused:Paused\n    Paused --> Started:Unpaused\n    Started --> Completed:All payments\\n went through\n```\n\n#### Payments\n\n```mermaid\nstateDiagram-v2\n    [*] --> Draft:Upload a disbursement CSV\n    Draft --> [*]:Disbursement deleted\n    Draft --> Ready:Disbursement started\n    Ready --> Paused:Paused\n    Paused --> Ready:Unpaused\n    Ready --> Pending:Payment gets submitted\\nif user is ready\n    Pending --> Success:Payment succeeds\n    Pending --> Failed:Payment fails\n    Failed --> Pending:Retry\n```\n\n#### Recipient Wallets\n\n```mermaid\nstateDiagram-v2\n    [*] --> Draft:Upload disbursement CSV\n    Draft --> [*]:disbursement deleted\n    Draft --> Ready: Disbursement started\n    Ready --> Registered: receiver signed up\n    Ready --> Flagged: flagged\n    Flagged --> Ready: unflagged\n    Registered --> Flagged: flagged\n    Flagged --> Registered: unflagged\n```\n\n#### Messages\n\n```mermaid\nstateDiagram-v2\n    [*] --> Pending: Message is queued\n    Pending --> Success:Message sender\\nAPI succeeds\n    Pending --> Failed:Message sender\\nAPI fails\n    Failed --> Pending:Retry\n```\n\n[sdp-dashboard]: https://github.com/stellar/stellar-disbursement-platform-frontend\n[Anchor Platform]: https://github.com/stellar/java-stellar-anchor-sdk\n", "release_dates": ["2024-02-22T22:27:55Z", "2024-02-09T21:07:27Z", "2024-02-06T06:15:51Z", "2024-02-06T01:16:25Z", "2024-02-01T22:23:04Z", "2023-12-15T20:34:05Z", "2023-10-19T17:14:18Z", "2023-08-31T16:03:21Z", "2023-08-14T23:51:24Z"]}, {"name": "stellar-disbursement-platform-frontend", "description": "Stellar Disbursement Platform Frontend", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Stellar Disbursement Platform Frontend\n\n## Introduction\n\nThe Stellar Disbursement Platform (SDP) enables organizations to disburse bulk\npayments to recipients using Stellar.\n\nThis repo contains the SDP dashboard UI, which is to be used with the\n[Stellar Disbursement Platform Backend](https://github.com/stellar/stellar-disbursement-platform-backend).\nFor more information on how to get started, see the Stellar\n[dev docs](https://developers.stellar.org/docs/category/use-the-stellar-disbursement-platform)\nand\n[API reference](https://developers.stellar.org/api/stellar-disbursement-platform).\n\nThe SDP's comprehensive dashboard includes the following pages:\n\n- Dashboard Home (Overview): Summary of recent disbursement activities and key\n  metrics, including successful payment rate, total successful/failed/remaining\n  payments, total disbursed, individuals, and wallets.\n- Disbursements Page (Management): Create, draft, search, filter, and export\n  disbursements. Detailed disbursement page includes names, total payments,\n  successes, failures, remaining, creation date, total amount, and disbursed\n  amount.\n- Receivers Page (Overview): List of individuals set to receive payments, with\n  wallet information and payment history. May also search, filter, and export\n  receiver data in CSV.\n- Payments Page (Overview): Summary of all payments, including search by payment\n  ID, filters, and export options. Payment details include Payment ID, wallet\n  address, disbursement name, completion time, amount, and status information.\n- Wallets Page (Management): View Distribution Account information including\n  public key, balance, adding funds, and more, and manage which assets you want\n  to use on the Stellar network.\n- Analytics Page (Overview): Provides insights into financial transactions,\n  including successful payment rate, total successful/failed/remaining payments,\n  total disbursed, average amount, total amount per asset, and individuals and\n  wallets involved.\n\nFeedback and contributions are welcome!\n\n## Environment Variables\n\nEnvironment variables can be set either on a global `window._env_` object or as\n`process.env` variables. All environment variables used in this repo are in\n`src/constants/envVariables.ts` file, including types.\n\n### `window`\n\nThe default location of the `window._env_` object is\n`public/settings/env-config.js` (not included in the repo). The path can be\nupdated in `src/constants/envVariables.ts` variable `WINDOW_ENV_PATH`.\n\nExample settings for local testing:\n\n```javascript\nwindow._env_ = {\n  API_URL: \"https://localhost:8000\",\n  STELLAR_EXPERT_URL: \"https://stellar.expert/explorer/testnet\",\n  HORIZON_URL: \"https://horizon-testnet.stellar.org\",\n  RECAPTCHA_SITE_KEY: \"6Lego1wmAAAAAJNwh6RoOrsHuWnsciCTIL3NN-bn\",\n};\n```\n\n### `process`\n\nThe `.env` file should be placed in the root directory of the repo. All\nvariables should be prefixed with `REACT_APP_`.\n\nSet the value to true to avoid fetching the file if the Window ENV is not used.\n\n<!-- prettier-ignore -->\n> [!NOTE]\n> Set `REACT_APP_DISABLE_WINDOW_ENV=true` to avoid fetching the\n> `public/settings/env-config.js` file if the `window._env_` is not used.\n\nFor example:\n\n```\nREACT_APP_DISABLE_WINDOW_ENV=true\nREACT_APP_API_URL=https://localhost:8000\nREACT_APP_STELLAR_EXPERT_URL=https://stellar.expert/explorer/testnet\nREACT_APP_HORIZON_URL=https://horizon-testnet.stellar.org\nREACT_APP_RECAPTCHA_SITE_KEY=6Lego1wmAAAAAJNwh6RoOrsHuWnsciCTIL3NN-bn\n```\n\n## Favicon\n\n[Favicon](https://developer.mozilla.org/en-US/docs/Glossary/Favicon) image files\nare located in `/public` directory. The files are:\n\n- `apple-touch-icon.png` - mostly used for shortcuts\n- `favicon.ico` - for legacy browsers and devices\n- `icon-192.png` and `icon-512.png` - fallback if SVG is not supported\n- `icon.svg` - modern browser support is very good (can be adjusted to match\n  operating system theme)\n\nHaving this set of favicons should cover all devices and browsers. They are set\nin `/src/index.html` and `/public/manifest.json` files.\n\n<figure>\n  <img\n  src=\"public/icon-192.png\"\n  alt=\"Stellar logo favicon\">\n  <figcaption>Default favicon</figcaption>\n</figure>\n", "release_dates": ["2024-02-09T19:44:16Z", "2024-02-05T18:56:11Z", "2023-10-19T20:33:47Z", "2023-08-31T21:45:13Z", "2023-08-14T23:54:08Z"]}, {"name": "stellar-docs", "description": "Documentation for Stellar", "language": "MDX", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Stellar Documentation and API Reference <!-- omit in toc -->\n\nWelcome to the official home repository for [Documentation][docs] and\n[API Reference][api] for the [Stellar Network][stellar].\n\n# Table of Contents <!-- omit in toc -->\n\n- [Contributing](#contributing)\n- [Quick Start](#quick-start)\n- [Repository Structure](#repository-structure)\n- [Using Markdown](#using-markdown)\n  - [Markdown Basics](#markdown-basics)\n  - [Custom Markdown](#custom-markdown)\n    - [Alert](#alert)\n    - [Code Example](#code-example)\n\n# Contributing\n\nContributions are more than welcome! Thank you! \ud83c\udf89\n\nBefore diving in, please read our [Stellar Contribution Guide][contrib] for\ndetails on contributing to Stellar's various repositories. Please take special\nnote of the [code of conduct][coc].\n\nOur documentation site is built using [Docusaurus][docusaurus]. The content is\nwritten in [MDX][mdx], which adds a lot of cool possibilities. Even if you're\nunfamiliar with plain markdown, do not fear! You can still contribute in a\nhelpful and meaningful way. Markdown is super easy to learn, and will come quite\nnaturally after only a bit of practice. You can always help fix typos, spelling,\nand broken links, too.\n\n# Quick Start\n[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)][codespaces]  \n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)][gitpod]\n\nTo begin development on the documentation, you will first need [yarn][yarn]\ninstalled on your system. Once it is, you can run the following commands:\n\n```bash\ngit clone https://github.com/stellar/stellar-docs\ncd stellar-docs\nyarn install\nnpx docusaurus start\n```\n\nThis will begin the development server, and open a browser window/tab pointing\nto `http://localhost:3000/docs/`. This development server will auto-reload when\nit detects changes to the repository.\n\nAfter you've made your changes, please use `prettier` to ensure consistent\nformatting throughout the repository:\n\n```bash\nnpm run check:mdx # this will search for problems in the MDX files\nnpm run format:mdx # this will fix any problems that were found\n```\n\n# Repository Structure\n\n- `/docs/` Contains all the documentation content. If you're contributing to the\n  actual documentation, rather than site functionality, this is likely where you\n  will want to be.\n  - `/docs/<subdirectory>/` Each subdirectory inside the `docs` directory\n    contains content documents relating to a common idea (asset issuance, or\n    running a validator node, for example). There can also be subdirectories\n    nested even further, which will follow the same rules. The location of a\n    document within this directory structure will have a direct impact on the\n    URL given to the document on the site (unless there is metadata or front\n    matter that overrides these defaults.)\n  - `/docs/<subdirectory>/_category_.json` This file contains information that\n    determines the directory's location and position within the site's sidebar.\n  - `/docs/<subdirectory>/<filename>.mdx` The actual documents live in these\n    files (written in Markdown), and also contains \"front matter\" which can\n    specify configuration parameter for the document's display, URL, etc. **All\n    filenames must use dashes for spaces instead of spaces or underscores**\n- `/src/` Contains non-documentation files like custom React components and\n  styling.\n- `/static/` Contains static assets. Anything in this directory will be copied\n  to the root of the final `build` directory.\n- `/nginx/` Contains configuration used to deploy and host the docs site. Unless\n  you're part of Stellar's IT Ops team, you probably don't need to do anything\n  with this. *Exception*:\n  - `/nginx/includes/redirects.conf` Contains redirect rules to avoid broken\n    links. If you find a broken link somewhere out in the wilds of the internet,\n    and there's no way for it to be changed, a redirect could be a useful tool.\n    (Note our aim isn't to *completely* avoid 404 pages for a user. That would\n    be impossible and impractical. These redirects are evaluated on a\n    case-by-case basis, and it may be determined that a redirect isn't the right\n    approach in some instances.)\n\n# Using Markdown\n\n## Markdown Basics\n\nIf you're unfamiliar with Markdown, there are **loads** of good tutorials and\ncheat sheets out there. Check out some of these resources to get a handle on the\nbasics:\n\n- [CommonMark cheat sheet and tutorial][commonmark]\n- [Interactive markdown tutorial][tutorial]\n- [The markdown guide][guide]\n\n## Custom Markdown\n\nOur repository uses some custom React components that can be used inside the\n`MDX` documents. Use them as follows:\n\n**Make sure that there is an empty line within the wrapper.** For example,\n\n```\n<Alert>\n<!-- EMPTY LINE AFTER THE COMPONENT'S OPENING TAG IS REQUIRED -->\n\nNote: the testnet is reset every three months, so when building on it, make sure you have a plan to recreate necessary accounts and other data. For more info, check out the [best practices for using the testnet](../../fundamentals-and-concepts/testnet-and-pubnet).\n\n<!-- EMPTY LINE BEFORE THE COMPONENT'S CLOSING TAG IS REQUIRED -->\n</Alert>\n```\n\n### Alert\n\n![Testnet reset alert](./readme-imgs/alert.png)\n\n`<Alert />` is used to convey hints, warnings, etc. For example,\n[Build a SEP-31 Anchor on Testnet][alert-example]\n\n```markdown\nimport { Alert } from \"@site/src/components/Alert\";\n\n<Alert>\n\nNote: the testnet is reset every three months, so when building on it, make sure you have a plan to recreate necessary accounts and other data. For more info, check out the [best practices for using the testnet](../../fundamentals-and-concepts/testnet-and-pubnet).\n\n</Alert>\n```\n\n### Code Example\n\n![Create account code example](./readme-imgs/code-example.png)\n\n`<CodeExample />` is a code snippet component. You can include snippets for more\nthan one language. See an example including a snippet for `JavaScript` and\n`Python` below. It is using [Prism React Renderer][prism] for syntax\nhighlighting.\n\n````markdown\nimport { CodeExample } from \"@site/src/components/CodeExample\";\n\n<CodeExample>\n\n```js\n// create a completely new and unique pair of keys\n// see more about KeyPair objects: https://stellar.github.io/js-stellar-sdk/Keypair.html\nconst pair = StellarSdk.Keypair.random();\n\npair.secret();\n// SAV76USXIJOBMEQXPANUOQM6F5LIOTLPDIDVRJBFFE2MDJXG24TAPUU7\npair.publicKey();\n// GCFXHS4GXL6BVUCXBWXGTITROWLVYXQKQLF4YH5O5JT3YZXCYPAFBJZB\n```\n\n```python\n# stellar-sdk >= 2.0.0 required\n# create a completely new and unique pair of keys\n# see more about KeyPair objects: https://stellar-sdk.readthedocs.io/en/latest/api.html#keypair\nfrom stellar_sdk import Keypair\n\npair = Keypair.random()\nprint(f\"Secret: {pair.secret}\")\n# Secret: SCMDRX7A7OVRPAGXLUVRNIYTWBLCS54OV7UH2TF5URSG4B4JQMUADCYU\nprint(f\"Public Key: {pair.public_key}\")\n# Public Key: GAG7SXULMNWCW6LX42JKZOZRA2JJXQT23LYY32OXA6XECUQG7RZTQJHO\n```\n\n</CodeExample>\n````\n\nLanguages that are currently being used in Documentation and API Reference are\nbelow:\n\n```js\n// https://github.com/stellar/stellar-docs/blob/main/src/components/CodeExample.js\n\nconst CODE_LANGS = {\n  bash: 'bash',\n  cpp: 'C++',\n  curl: 'cURL',\n  go: 'Go',\n  html: 'html',\n  java: 'Java',\n  javascript: 'JavaScript',\n  js: 'JavaScript',\n  json: 'JSON',\n  json5: 'JSON5',\n  python: 'Python',\n  scss: 'SCSS',\n  toml: 'TOML',\n  ts: 'TypeScript',\n  tsx: 'TSX',\n  typescript: 'TypeScript',\n  yaml: 'YAML',\n};\n```\n\n[docs]: https://developers.stellar.org/docs\n[api]: https://developers.stellar.org/api\n[stellar]: https://stellar.org\n[contrib]: https://github.com/stellar/.github/blob/master/CONTRIBUTING.md\n[coc]: https://github.com/stellar/.github/blob/master/CODE_OF_CONDUCT.md\n[docusaurus]: https://docusaurus.io\n[mdx]: https://mdxjs.com\n[yarn]: https://yarnpkg.com/\n[commonmark]: https://commonmark.org/help/\n[tutorial]: https://www.markdowntutorial.com/\n[guide]: https://www.markdownguide.org/\n[alert-example]: https://developers.stellar.org/docs/anchoring-assets/enabling-cross-border-payments/setting-up-test-server\n[prism]: https://github.com/FormidableLabs/prism-react-renderer\n[codespaces]: https://github.com/codespaces/new?hide_repo_select=true&ref=main&repo=521307729&machine=basicLinux32gb&devcontainer_path=.devcontainer%2Fdevcontainer.json&location=EastUs\n[gitpod]: https://gitpod.io/#https://github.com/stellar/stellar-docs\n", "release_dates": []}, {"name": "stellar-etl", "description": "Stellar ETL will enable real-time analytics on the Stellar network", "language": "Go", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "\n# Stellar ETL\nThe Stellar-ETL is a data pipeline that allows users to extract data from the history of the Stellar network.\n\n## **Table of Contents**\n\n- [Exporting the Ledger Chain](#exporting-the-ledger-chain)\n  - [Command Reference](#command-reference)\n\t- [Bucket List Commands](#bucket-list-commands)\n\t  - [export_accounts](#export_accounts)\n\t  - [export_offers](#export_offers)\n\t  - [export_trustlines](#export_trustlines)\n\t  - [export_claimable_balances](#export_claimable_balances)\n  \t  - [export_pools](#export_pools)\n  \t  - [export_signers](#export_signers)\n\t  - [export_contract_data (futurenet, testnet)](#export_contract_data)\n\t  - [export_contract_code (futurenet, testnet)](#export_contract_code)\n\t  - [export_config_settings (futurenet, testnet)](#export_config_settings)\n\t  - [export_ttl (futurenet, testnet)](#export_ttl)\n\t- [History Archive Commands](#history-archive-commands)\n\t  - [export_ledgers](#export_ledgers)\n\t  - [export_transactions](#export_transactions)\n\t  - [export_operations](#export_operations)\n\t  - [export_effects](#export_effects)\n      - [export_assets](#export_assets)\n      - [export_trades](#export_trades)\n\t  - [export_diagnostic_events (futurenet, testnet)](#export_diagnostic_events)\n\t- [Stellar Core Commands](#stellar-core-commands)\n\t  - [export_ledger_entry_changes](#export_ledger_entry_changes)\n      - [export_orderbooks (unsupported)](#export_orderbooks-unsupported)\n\t  - [Utility Commands](#utility-commands)\n\t  - [get_ledger_range_from_times](#get_ledger_range_from_times) \n- [Schemas](#schemas)\n- [Extensions](#extensions)\n  - [Adding New Commands](#adding-new-commands)\n<br>\n<br>\n\n\n# Exporting the Ledger Chain\n\n## **Docker**\n1. Download the latest version of docker [Docker](https://www.docker.com/get-started)\n2. Pull the stellar-etl Docker image: `docker pull stellar/stellar-etl`\n3. Run the Docker images with the desired stellar-etl command: `docker run stellar/stellar-etl stellar-etl [etl-command] [etl-command arguments]`\n\n## **Manual Installation**\n1. Install Golang v1.19.0 or later: https://golang.org/dl/\n\n2. Ensure that your Go bin has been added to the PATH env variable: `export PATH=$PATH:$(go env GOPATH)/bin`\n3. Download and install Stellar-Core v19.0.0 or later: https://github.com/stellar/stellar-core/blob/master/INSTALL.md\n\n4. Run `go get github.com/stellar/stellar-etl` to install the ETL\n\n5. Run export commands to export information about the legder\n\n## **Command Reference**\n- [Bucket List Commands](#bucket-list-commands)\n   - [export_accounts](#export_accounts)\n   - [export_offers](#export_offers)\n   - [export_trustlines](#export_trustlines)\n   - [export_claimable_balances](#export_claimable_balances)\n   - [export_pools](#export_pools)\n   - [export_signers](#export_signers)\n   - [export_contract_data](#export_contract_data)\n   - [export_contract_code](#export_contract_code)\n   - [export_config_settings](#export_config_settings)\n   - [export_ttl](#export_ttl)\n- [History Archive Commands](#history-archive-commands)\n   - [export_ledgers](#export_ledgers)\n   - [export_transactions](#export_transactions)\n   - [export_operations](#export_operations)\n   - [export_effects](#export_effects)\n   - [export_assets](#export_assets)\n   - [export_trades](#export_trades)\n   - [export_diagnostic_events](#export_diagnostic_events)\n - [Stellar Core Commands](#stellar-core-commands)\n   - [export_orderbooks (unsupported)](#export_orderbooks-unsupported)\n - [Utility Commands](#utility-commands)\n   - [get_ledger_range_from_times](#get_ledger_range_from_times)\n\nEvery command accepts a `-h` parameter, which provides a help screen containing information about the command, its usage, and its flags.\n\nCommands have the option to read from testnet with the `--testnet` flag, from futurenet with the `--futurenet` flag, and defaults to reading from mainnet without any flags.\n> *_NOTE:_* Adding both flags will default to testnet. Each stellar-etl command can only run from one network at a time.\n\n<br>\n\n***\n\n## **Bucket List Commands**\n\nThese commands use the bucket list in order to ingest large amounts of data from the history of the stellar ledger. If you are trying to read large amounts of information in order to catch up to the current state of the ledger, these commands provide a good way to catchup quickly. However, they don't allow for custom start-ledger values. For updating within a user-defined range, see the Stellar Core commands.\n\n> *_NOTE:_* In order to get information within a specified ledger range for bucket list commands, see the export_ledger_entry_changes command.\n\n<br>\n\n### **export_accounts**\n\n```bash\n> stellar-etl export_accounts --end-ledger 500000 --output exported_accounts.txt\n```\n\nExports historical account data from the genesis ledger to the provided end-ledger to an output file. The command reads from the bucket list, which includes the full history of the Stellar ledger. As a result, it should be used in an initial data dump. In order to get account information within a specified ledger range, see the export_ledger_entry_changes command.\n\n<br>\n\n### **export_offers**\n\n```bash\n> stellar-etl export_offers --end-ledger 500000 --output exported_offers.txt\n```\n\nExports historical offer data from the genesis ledger to the provided end-ledger to an output file. The command reads from the bucket list, which includes the full history of the Stellar ledger. As a result, it should be used in an initial data dump. In order to get offer information within a specified ledger range, see the export_ledger_entry_changes command.\n\n<br>\n\n### **export_trustlines**\n\n```bash\n> stellar-etl export_trustlines --end-ledger 500000 --output exported_trustlines.txt\n```\n\nExports historical trustline data from the genesis ledger to the provided end-ledger to an output file. The command reads from the bucket list, which includes the full history of the Stellar ledger. As a result, it should be used in an initial data dump. In order to get trustline information within a specified ledger range, see the export_ledger_entry_changes command.\n\n<br>\n\n### **export_claimable_balances**\n\n```bash\n> stellar-etl export_claimable_balances --end-ledger 500000 --output exported_claimable_balances.txt\n```\n\nExports claimable balances data from the genesis ledger to the provided end-ledger to an output file. The command reads from the bucket list, which includes the full history of the Stellar ledger. As a result, it should be used in an initial data dump. In order to get claimable balances information within a specified ledger range, see the export_ledger_entry_changes command.\n\n<br>\n\n### **export_pools**\n\n```bash\n> stellar-etl export_pools --end-ledger 500000 --output exported_pools.txt\n```\n\nExports historical liquidity pools data from the genesis ledger to the provided end-ledger to an output file. The command reads from the bucket list, which includes the full history of the Stellar ledger. As a result, it should be used in an initial data dump. In order to get liquidity pools information within a specified ledger range, see the export_ledger_entry_changes command.\n\n<br>\n\n### **export_signers**\n\n```bash\n> stellar-etl export_signers --end-ledger 500000 --output exported_signers.txt\n```\n\nExports historical account signers data from the genesis ledger to the provided end-ledger to an output file. The command reads from the bucket list, which includes the full history of the Stellar ledger. As a result, it should be used in an initial data dump. In order to get account signers information within a specified ledger range, see the export_ledger_entry_changes command.\n\n<br>\n\n### **export_contract_data**\n\n```bash\n> stellar-etl export_contract_data --end-ledger 500000 --output export_contract_data.txt\n```\n\nExports historical contract data data from the genesis ledger to the provided end-ledger to an output file. The command reads from the bucket list, which includes the full history of the Stellar ledger. As a result, it should be used in an initial data dump. In order to get contract data information within a specified ledger range, see the export_ledger_entry_changes command.\n\n<br>\n\n### **export_contract_code**\n\n```bash\n> stellar-etl export_contract_code --end-ledger 500000 --output export_contract_code.txt\n```\n\nExports historical contract code data from the genesis ledger to the provided end-ledger to an output file. The command reads from the bucket list, which includes the full history of the Stellar ledger. As a result, it should be used in an initial data dump. In order to get contract code information within a specified ledger range, see the export_ledger_entry_changes command.\n\n<br>\n\n### **export_config_settings**\n\n```bash\n> stellar-etl export_config_settings --end-ledger 500000 --output export_config_settings.txt\n```\n\nExports historical config settings data from the genesis ledger to the provided end-ledger to an output file. The command reads from the bucket list, which includes the full history of the Stellar ledger. As a result, it should be used in an initial data dump. In order to get config settings data information within a specified ledger range, see the export_ledger_entry_changes command.\n\n<br>\n\n### **export_ttl**\n\n```bash\n> stellar-etl export_ttl --end-ledger 500000 --output export_ttl.txt\n```\n\nExports historical expiration data from the genesis ledger to the provided end-ledger to an output file. The command reads from the bucket list, which includes the full history of the Stellar ledger. As a result, it should be used in an initial data dump. In order to get expiration information within a specified ledger range, see the export_ledger_entry_changes command.\n\n<br>\n\n***\n\n## **History Archive Commands**\n\nThese commands export information using the history archives. This allows users to provide a start and end ledger range. The commands in this category export a list of everything that occurred within the provided range. All of the ranges are inclusive.\n\n> *_NOTE:_* Commands except `export_ledgers` and `export_assets` also require Captive Core to export data.\n\n<br>\n\n### **export_ledgers**\n\n```bash\n> stellar-etl export_ledgers --start-ledger 1000 \\\n--end-ledger 500000 --output exported_ledgers.txt\n```\n\nThis command exports ledgers within the provided range. \n\n<br>\n\n### **export_transactions**\n\n```bash\n> stellar-etl export_transactions --start-ledger 1000 \\\n--end-ledger 500000 --output exported_transactions.txt\n```\n\nThis command exports transactions within the provided range.\n\n<br>\n\n### **export_operations**\n\n```bash\n> stellar-etl export_operations --start-ledger 1000 \\\n--end-ledger 500000 --output exported_operations.txt\n```\n\nThis command exports operations within the provided range.\n\n<br>\n\n### **export_effects**\n\n```bash\n> stellar-etl export_effects --start-ledger 1000 \\\n--end-ledger 500000 --output exported_effects.txt\n```\n\nThis command exports effects within the provided range.\n\n<br>\n\n### **export_assets**\n```bash\n> stellar-etl export_assets \\\n--start-ledger 1000 \\\n--end-ledger 500000 --output exported_assets.txt\n```\n\nExports the assets that are created from payment operations over a specified ledger range.\n\n<br>\n\n### **export_trades**\n```bash\n> stellar-etl export_trades \\\n--start-ledger 1000 \\\n--end-ledger 500000 --output exported_trades.txt\n```\n\nExports trade data within the specified range to an output file\n\n<br>\n\n### **export_diagnostic_events**\n```bash\n> stellar-etl export_diagnostic_events \\\n--start-ledger 1000 \\\n--end-ledger 500000 --output export_diagnostic_events.txt\n```\n\nExports diagnostic events data within the specified range to an output file\n\n<br>\n\n***\n\n## **Stellar Core Commands**\n\nThese commands require a Stellar Core instance that is v19.0.0 or later. The commands use the Core instance to retrieve information about changes from the ledger. These changes can be in the form of accounts, offers, trustlines, claimable balances, liquidity pools, or account signers.\n\nAs the Stellar network grows, the Stellar Core instance has to catch up on an increasingly large amount of information. This catch-up process can add some overhead to the commands in this category. In order to avoid this overhead, run prefer processing larger ranges instead of many small ones, or use unbounded mode.\n\n<br>\n\n### **export_ledger_entry_changes**\n\n```bash\n> stellar-etl export_ledger_entry_changes --start-ledger 1000 \\\n--end-ledger 500000 --output exported_changes_folder/\n```\n\nThis command exports ledger changes within the provided ledger range. Flags can filter which ledger entry types are exported. If no data type flags are set, then by default all types are exported. If any are set, it is assumed that the others should not be exported.\n\nChanges are exported in batches of a size defined by the `batch-size` flag. By default, the batch-size parameter is set to 64 ledgers, which corresponds to a five minute period of time. This batch size is convenient because checkpoint ledgers are created every 64 ledgers. Checkpoint ledgers act as anchoring points for the nodes on the network, so it is beneficial to export in multiples of 64.\n\nThis command has two modes: bounded and unbounded.\n\n#### **Bounded**\n If both a start and end ledger are provided, then the command runs in a bounded mode. This means that once all the ledgers in the range are processed and exported, the command shuts down.\n \n#### **Unbounded**\nIf only a start ledger is provided, then the command runs in an unbounded fashion starting from the provided ledger. In this mode, the Stellar Core connects to the Stellar network and processes new changes as they occur on the network. Since the changes are continually exported in batches, this process can be continually run in the background in order to avoid the overhead of closing and starting new Stellar Core instances.\n\n<br>\n\n### **export_orderbooks (unsupported)**\n\n```bash\n> stellar-etl export_orderbooks --start-ledger 1000 \\\n--end-ledger 500000 --output exported_orderbooks_folder/\n```\n\n> *_NOTE:_* This is an expermental feature and is currently unsupported.\n\nThis command exports orderbooks within the provided ledger range. Since exporting complete orderbooks at every single ledger would require an excessive amount of storage space, the output is normalized. Each batch that is exported contains multiple files, namely: `dimAccounts.txt`, `dimOffers.txt`, `dimMarkets.txt`, and `factEvents.txt`. The dim files relate a data structure to an ID. `dimMarkets`, for example, contains the buying and selling assets of a market, as well as the ID for that market. That ID is used in other places as a replacement for the full market information. This normalization process saves  a significant amount of space (roughly 90% in our benchmarks). The `factEvents` file connects ledger numbers to the offer IDs that were present at that ledger.\n\nOrderbooks are exported in batches of a size defined by the `batch-size` flag. By default, the batch-size parameter is set to 64 ledgers, which corresponds to a five minute period of time. This batch size is convenient because checkpoint ledgers are created every 64 ledgers. Checkpoint ledgers act as anchoring points in that once they are available, so are the previous 63 nodes. It is beneficial to export in multiples of 64.\n\nThis command has two modes: bounded and unbounded.\n\n#### **Bounded**\n If both a start and end ledger are provided, then the command runs in a bounded mode. This means that once all the ledgers in the range are processed and exported, the command shuts down.\n \n#### **Unbounded**\nIf only a start ledger is provided, then the command runs in an unbounded fashion starting from the provided ledger. In this mode, the Stellar Core connects to the Stellar network and processes new orderbooks as they occur on the network. Since the changes are continually exported in batches, this process can be continually run in the background in order to avoid the overhead of closing and starting new Stellar Core instances.\n\n<br>\n\n***\n\n## **Utility Commands**\n\n### **get_ledger_range_from_times**\n```bash\n> stellar-etl get_ledger_range_from_times \\\n--start-time 2019-09-13T23:00:00+00:00 \\\n--end-time 2019-09-14T13:35:10+00:00 --output exported_range.txt\n```\n\nThis command exports takes in a start and end time and converts it to a ledger range. The ledger range that is returned will be the smallest possible ledger range that completely covers the provided time period. \n\n<br>\n<br>\n\n# Schemas\n\nSee https://github.com/stellar/stellar-etl/blob/master/internal/transform/schema.go for the schemas of the data structures that are outputted by the ETL.\n\n<br>\n<br>\n\n# Extensions\nThis section covers some possible extensions or further work that can be done.\n\n## **Adding New Commands**\nIn general, in order to add new commands, you need to add these files:\n\n - `export_new_data_structure.go` in the `cmd` folder\n\t - This file can be generated with cobra by calling: `cobra add {command}`\n\t - This file will parse flags, create output files, get the transformed data from the input package, and then export the data.\n - `export_new_data_structure_test.go` in the `cmd` folder\n\t - This file will contain some tests for the newly added command. The `runCLI` function does most of the heavy lifting. All the tests need is the command arguments to test and the desired output.\n\t - Test data should be stored in the `testdata/new_data_structure` folder\n - `new_data_structure.go` in the `internal/input` folder\n\t - This file will contain the methods needed to extract the new data structure from wherever it is located. This may be the history archives, the bucket list, or a captive core instance. \n\t - This file should extract the data and transform it, and return the transformed data.\n\t - If working with captive core, the methods need to work in the background. There should be methods that export batches of data and send them to a channel. There should be other methods that read from the channel and transform the data so it can be exported.\n- `new_data_structure.go` in the `internal/transform` folder\n\t- This file will contain the methods needed to transform the extracted data into a form that is suitable for BigQuery.\n\t- The struct definition for the transformed object should be stored in `schemas.go` in the `internal/transform` folder.\n\nA good number of common methods are already written and stored in the `util` package.\n", "release_dates": ["2024-02-29T19:22:21Z"]}, {"name": "stellar-etl-airflow", "description": "Airflow DAGs for the Stellar ETL project", "language": "Python", "license": null, "readme": "# stellar-etl-airflow\n\nThis repository contains the Airflow DAGs for the [Stellar ETL](https://github.com/stellar/stellar-etl) project. These DAGs provide a workflow for exporting data from the Stellar network and uploading the data into BigQuery.\n\n## **Table of Contents**\n\n- [Installation and Setup](#installation-and-setup)\n  - [Google Cloud Platform](#google-cloud-platform)\n  - [Cloud Composer](#cloud-composer)\n  - [Airflow Variables Explanation](#airflow-variables-explanation)\n    - [Normal Variables](#normal-variables)\n    - [Kubernetes Specific Variables](#kubernetes-specific-variables)\n- [Execution Procedures](#execution-procedures)\n  - [Starting Up](#starting-up)\n  - [Handling Failures](#handling-failures)\n    - [Clearing Failures](#clearing-failures)\n- [Understanding the Setup](#understanding-the-setup)\n  - [DAG Diagrams](#dag-diagrams)\n    - [History Archive with Captive Core DAG](#history-archive-with-captive-core-dag)\n    - [History Archive without Captive Core DAG](#history-archive-without-captive-core-dag)\n    - [State Table Export DAG](#state-table-export-dag)\n    - [Bucket List DAG (Unsupported)](#bucket-list-dag-unsupported)\n  - [Task Explanations](#task-explanations)\n    - [build_time_task](#build_time_task)\n    - [build_export_task](#build_export_task)\n    - [build_gcs_to_bq_task](#build_gcs_to_bq_task)\n    - [build_apply_gcs_changes_to_bq_task](#build_apply_gcs_changes_to_bq_task)\n    - [build_batch_stats](#build_batch_stats)\n    - [bq_insert_job_task](#bq_insert_job_task)\n    - [cross_dependency_task](#cross_dependency_task)\n    - [delete_data_task](#delete_data_task)\n- [Further Development](#further-development)\n  - [Extensions](#extensions)\n    - [Pre-commit Git hook scripts](#pre-commit-git-hook-scripts)\n    - [Adding New DAGs](#adding-new-dags)\n    - [Adding tasks to existing DAGs](#adding-tasks-to-existing-dags)\n    - [Adding New Tasks](#adding-new-tasks)\n  - [Testing Changes](#testing-changes)\n\n<br>\n\n# Installation and Setup\n\n- [Google Cloud Platform](#google-cloud-platform)\n- [Cloud Composer](#cloud-composer)\n- [Airflow Variables Explanation](#airflow-variables-explanation)\n  - [Normal Variables](#normal-variables)\n  - [Kubernetes Specific Variables](#kubernetes-specific-variables)\n\n<br>\n\n## **Google Cloud Platform**\n\nBelow are instructions to intialize the Google Cloud SDK and create the GCP project, dataset, and GCS bucket if needed.\n\n<br>\n\n### **Setup the Cloud SDK**\n\n- Download the [Google Cloud SDK](https://cloud.google.com/sdk/docs/quickstart#installing_the_latest_version).\n- [Initialize the Cloud SDK](https://cloud.google.com/sdk/docs/quickstart#initializing_the) and login to your Google account\n\n### **Create Google Project**\n\n- Login to the [Google Cloud Console](https://console.cloud.google.com/cloud-resource-manager)\n- Create a new [Google Project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#creating_a_project) or use an existing project\n  > **_NOTE:_** The project name you choose corresponds to the Airflow variable \"bq_project\".\n\n### **Create BigQuery Dataset**\n\n- Log in to Google [BigQuery](https://cloud.google.com/bigquery)\n- [Create](https://cloud.google.com/bigquery/docs/datasets#create-dataset) a new dataset with the desired name or use an existing dataset\n  > **_NOTE:_** The dataset name you choose corresponds to the Airflow variable \"bq_dataset\".\n\n### **Create Google Cloud Storage bucket**\n\n- Open the [Cloud Storage browser](https://console.cloud.google.com/storage/browser)\n- [Create](https://cloud.google.com/storage/docs/creating-buckets) a new Google Storage bucket that will store exported files\n\n  > **_NOTE:_** Creating a new Cloud Composer environment will automatically create a new GCS bucket.\n\n  > **_NOTE:_** The dataset name you choose corresponds to the Airflow variable \"gcs_exported_data_bucket_name\".\n\n  > **_NOTE:_** Creating a new environment with Cloud Composer will create a new GCS bucket.\n\n> **_WARNING:_** Make sure that you adhere to the [location requirements](https://cloud.google.com/bigquery/docs/batch-loading-data#data-locations) for Cloud Storage buckets and BigQuery datasets. Otherwise, it will not be possible to upload data to BigQuery.\n\n<br>\n\n---\n\n## **Cloud Composer**\n\nCloud Composer is the preferred method of deployment. [Cloud Composer](https://cloud.google.com/composer) is a managed service used for Airflow deployment that provides much of the infrastructure required to host an Airflow instance. The steps for setting up a Cloud Composer environment are detailed below.\n\n<br>\n\n### **Create Google Cloud Composer environment**\n\nCreate a new Cloud Composer environment using the [UI](https://console.cloud.google.com/composer/environments/create) or by following the setup instructions in [Create Cloud Composer environments](https://cloud.google.com/composer/docs/how-to/managing/creating)\n\n> **_For AIRFLOW 2.x:_** Be wary of choosing \"autopilot\" for environment resource management. The ephemeral storage provided by autopilot-ed containers is [capped at 10GB](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-resource-requests#min-max-requests), which may not be enough for hefty tasks (such as `state_table_dag`'s `export_task`), or any task that runs captive core.\n> You can add a second node pool to your Composer 1 environment, and configure it to be managed by autopilot if desired.\n> Composer 2 environments use autopilot exclusively for resource management.\n\n> **_Note_**: If no service account is provided, GCP will use the default GKE service account. For quick setup this is an easy option.\n> Remember to adjust the disk size, machine type, and node count to fit your needs. The python version must be 3, and the image must be `composer-1.16.11-airflow-1.10.14` or later. GCP deprecates support for older versions of composer and airflow. It is recommended that you select a stable, latest version to avoid an environment upgrade. See [the command reference page](https://cloud.google.com/sdk/gcloud/reference/composer/environments/create) for a detailed list of parameters.\n\n> **_TROUBLESHOOTING:_** If the environment creation fails because the \"Composer Backend timed out\" try disabling and enabling the Cloud Composer API. If the creation fails again, try creating a service account with Owner permissions and use it to create the Composer environment.\n\nCloud Composer may take a while to setup the environment. Once the process is finished, you can view the environment by going to the [Composer section of the Cloud Console](https://console.cloud.google.com/composer/environments).\n\n> **_NOTE:_** Creating an environment will also create a new Google Cloud Storage bucket. You can check this bucket's name by clicking on the DAGs folder link in the Composer section of the Cloud Console.\n\n<br>\n\n### **Upload DAGs and Schemas to Cloud Composer**\n\nAfter the environment is created, select the environment and navigate to the environment configuration tab. Look for the value under **DAGs folder**. It will be of the form `gs://airflow_bucket/dags`. The `airflow_bucket` value will be used in this step and the next. Run the command below in order to upload the DAGs and schemas to your Airflow bucket.\n\n```bash\n> bash upload_static_to_gcs.sh <airflow_bucket>\n```\n\nAfterwards, you can navigate to the Airflow UI for your Cloud Composer environment. To do so, navigate to the [Composer section of the Cloud Console](https://console.cloud.google.com/composer/environments), and click the link under `Airflow webserver`. Then, pause the DAGs by clicking the on/off toggle to the left of their names. DAGs should remain paused until you have finished setting up the environment. Some DAGs may not show up due to errors that will be fixed as the following steps are completed.\n\n<br>\n\n### **Add Service Account Key**\n\nThe Airflow DAGs require service account keys to perform their operations. Generate a [service account key](https://cloud.google.com/iam/docs/creating-managing-service-account-keys#creating_service_account_keys) for a service account that has access to BigQuery and Google Cloud Storage. Then, add this key file to the data folder in your `airflow_bucket`.\n\n> **_NOTE:_** The name of the key file corresponds to the Airflow variable \"api_key_path\". The data folder in Cloud Storage corresponds to the path \"/home/airflow/gcs/data/\", but ensure that the variable has the correct filename.\n\n<br>\n\n### **Add private docker registry auth secrets**\n\nIf you want to pull an image from a private docker registry to use in KubernetesPodOperator in airflow you will need to add auth json credentials to kubernetes and the service account. [Kubernetes docs](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/#registry-secret-existing-credentials)\n\n- Create the kubernetes secret from auth json\n\n```\nkubectl create secret generic <secret name> \\\n    --from-file=.dockerconfigjson=<path/to/.docker/config.json> \\\n    --type=kubernetes.io/dockerconfigjson\n```\n\n- Add secret to service account that will create the kubernetes pod\n\n```\nkubectl patch serviceaccount <serviceaccount name> -p '{\"imagePullSecrets\": [{\"name\": \"<secret-name>\"}]}' --namespace=<namespace>\n```\n\n<br>\n\n### **Add Kubernetes Node Pool**\n\nIf the Kubernetes pods contain long-running or resource intensive operations, it is best to create a separate node pool for task execution. Executing the tasks on the same node pool as the `airflow-scheduler` will contribute to resource starvation and transient failures in the DAG.\n\nFind the Kubernetes cluster name that is used by your Cloud Composer environment. To do so, select the environment, navigate to the `ENVIRONMENT CONFIGURATION` tab, and look for the value of `GKE cluster`. The cluster name is the final part of this path.\n\nThen, run the command:\n\n```bash\ngcloud container node-pools create <pool_name> --cluster <cluster_name> \\\n--zone <composer_zone> --project <project_id>\n```\n\nAlternatively, node pools can be created through the UI with the `ADD NODE POOL` button. Select the environment, navigate to the `ENVIRONMENT CONFIGURATION` tab, and look for the value under `GKE cluster`\n\nSecurity can only be applied upon pool creation, so ensure that your security account and scopes are correct. If they need to be updated, you will need to delete the node pool and recreate it.\n\n> **_NOTE:_** The name of the pool will be used in the Airflow variable \"affinity\".\n>\n> A sample affinity configuration is below, as well as defined in the `airflow_variables.txt`. The user must supply the node pool name in `values`.\n\n```\n\"affinity\": {\n        \"nodeAffinity\": {\n            \"requiredDuringSchedulingIgnoredDuringExecution\": {\n                \"nodeSelectorTerms\": [{\n                    \"matchExpressions\": [{\n                        \"key\": \"cloud.google.com/gke-nodepool\",\n                        \"operator\": \"In\",\n                        \"values\": [<node-pool-1>,\n\t\t\t\t\t\t           <node-pool-2>,]\n                        }]\n                    }]\n                }\n            }\n        },\n```\n\n### **Create Namespace for ETL Tasks (Optional)**\n\nOpen the Google [Cloud Shell](https://cloud.google.com/shell). Run these commands:\n\n```bash\ngcloud container clusters get-credentials <cluster_name> --region=<composer_region>\n\nkubectl create ns <namespace_name>\n\nkubectl create clusterrolebinding default-admin --clusterrole cluster-admin \\\n--serviceaccount=<service_account> --namespace <namespace_name>\n```\n\nThe first command acquires credentials, allowing you to execute the next commands. The second command creates the new namespace, and the third allows the service account that executes tasks to act in the new namespace.\n\nTo find the value of `<airflow_worker_namespace>`, select your Cloud Composer environment, navigate to the `ENVIRONMENT CONFIGURATION` tab, and look for the value of `GKE cluster`. Click on the link that says `view cluster workloads`.\n\nA new page will open with a list of Kubernetes workflows. Click on `airflow-worker` in order to go to the details page for that Deployment. Look for the value of `Namespace`.\n\n> **_NOTE:_** The name of the newly created namespace corresponds to the Airflow variable \"namespace\".\n\n<br>\n\n### **Authenticating Tasks in an Autopilot-Managed Environment**\n\nThere are a few extra hoops to jump through to configure Workload Identity, so that `export` tasks have permissions to upload files to GCS.\nYou will be creating a Kubernetes service account, and bind it to a Google service account that your task is authenticated as.\nSteps taken from this [doc](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity#authenticating_to).\n\n- Create a namespace in the k8s cluster where the Composer env is running:\n\n  ```bash\n  kubectl create namespace <namespace_name>\n  ```\n\n- Create a k8s service account:\n\n  ```bash\n  kubectl create serviceaccount <service_account_name> \\\n      --namespace <namespace_name>\n  ```\n\n- Create a Google service account, if one doesn't already exist:\n\n  ```bash\n  gcloud iam service-accounts create <service_account_name> \\\n      --project=<project_id>\n  ```\n\n- Grant the Google service account that you're using `storage.objectAdmin` permissions, it doesn't already have it.\n\n  ```bash\n  gcloud projects add-iam-policy-binding hubble-261722 \\\n    --member \"<Google service account>\" \\\n    --role \"roles/storage.objectAdmin\"\n  ```\n\n- Associate the Google and k8s service accounts:\n\n  ```bash\n  gcloud iam service-accounts add-iam-policy-binding <Google service account email> \\\n    --role roles/iam.workloadIdentityUser \\\n    --member \"<k8s service account>\"\n  ```\n\n- Annotate the k8s service account with the Google service account:\n\n  ```bash\n  kubectl annotate serviceaccount <k8s service account> \\\n      --namespace <namespace_name> \\\n      iam.gke.io/gcp-service-account=<Google service account>\n  ```\n\n- Set the corresponding airflow variables (`k8s_namespace` and `k8s_service_account`) for tasks running on `KubernetesPodOperator`.\n\n<br>\n\n### **Modify Kubernetes Config for Airflow Workers**\n\nFind the Kubernetes cluster workloads that are used by your Cloud Composer environment. To do so, select the environment, navigate to the `ENVIRONMENT CONFIGURATION` tab, and look for the `GKE cluster` section. Click on the link that says `view cluster workloads`.\n\nA new page will open with a list of Kubernetes workflows. Click on `airflow-worker` in order to go to the details page for that Deployment. Click the `edit` button. This will take you to a tab with a Kubernetes configuration. In subsequent steps, you will edit this file. For an example of a finalized config file, see this [example file](example_airflow_worker_config.yaml).\n\n> **_WARNING:_** You shouldn't copy the example file directly because it has environment variables and config values that are set up for a different project.\n\n> **_NOTE:_** This deployment file contains two separate containers: airflow-worker and gcs-syncd. Only the airflow-worker container should be edited.\n\n<details>\n<summary>Mount Docker on Airflow Workers</summary>\nIn this step, mount the Docker.sock and Docker. In addition, edit the security config so that the container runs as privileged, allowing it to access Docker. See [this commit](https://github.com/marc-chan/cloud_composer_examples/commit/f3e6a202ef0bfd2214385def7e36be33db191df6#diff-fc2e428a07c8d60059e54e5154f0c540) for an example of how to make these changes.\n</details>\n\n<details>\n<summary>Add Volume for Local Files to Airflow Workers</summary>\nIn this step, add another volumeMount to airflow-workers. This local path will be used for temporary storage of exported files. In addition, make sure that you add the corresponding volume with the type DirectoryOrCreate.\n\nHere is an example of what your volumeMounts and volumes should look like at the end of this step:\n\n```\n...\n\nvolumeMounts:\n- mountPath: /etc/airflow/airflow_cfg\nname: airflow-config\n\n- mountPath: /home/airflow/gcs\nname: gcsdir\n\n- mountPath: /var/run/docker.sock\nname: docker-host\n\n- mountPath: /bin/docker\nname: docker-app\n\n- mountPath: /home/airflow/etlData\nname: etl-data\n...\n\nvolumes:\n- configMap:\ndefaultMode: 420\nname: airflow-configmap\n\nname: airflow-config\n- emptyDir: {}\nname: gcsdir\n\n- hostPath:\npath: /var/run/docker.sock\ntype: \"\"\nname: docker-host\n\n- hostPath:\npath: /usr/bin/docker\ntype: \"\"\nname: docker-app\n\n- hostPath:\npath: /home/airflow/etlData\ntype: DirectoryOrCreate\nname: etl-data\n\n```\n\n> **_NOTE:_** The mount path chosen corresponds to the Airflow variable `local_output_path`.\n\n</details>\n\n<details>\n<summary>Add Poststart Script to Airflow Workers</summary>\nFind the namespace name in the airflow-worker config file. It should be near the top of the file, and may look like `composer-1-12-0-airflow-1-10-10-2fca78f7`. This value will be used in later commands.\n\nNext, open the cloud shell. Keep your airflow-worker configuration file open, or save it. In the cloud shell, create a text file called `poststart.sh` by running the command: `nano poststart.sh`. Then, copy the text from the `poststart.sh` file in this repository into the newly opened file.\n\n- If you changed the path for the local folder in the previous step, make sure that you edit line 13:\n\n  ```\n  for file in /home/airflow/etlData/*\n  ```\n\n- It should reflect the path changes you made. Once the file is finalized, run these commands:\n\n  ```bash\n  gcloud container clusters get-credentials <cluster_name> --region=<composer_region>\n\n  kubectl create configmap start-config --from-file poststart.sh -n <namespace_name>\n  ```\n\n- Return to the airflow-worker config file. Add a new volumeMount to /etc/scripts.\n\n  ```\n  ...\n\n  volumeMounts:\n  ...\n  - mountPath: /etc/scripts\n  name: config-volume\n  ...\n\n  ```\n\n- Then, add a new Volume that links to the configMap you created.\n\n  ```\n  ...\n  volumes:\n  ...\n  - configMap:\n  \tdefaultMode: 511\n  \tname: start-config\n  \tname: config-volume\n  ...\n  ```\n\n- This will make the script available to the Airflow workers. In order for them to call it automatically, add a postStart hook to airflow-worker above the existing preStop hook.\n\n  ```\n  ...\n  lifecycle:\n  \tpostStart:\n  \t\texec:\n  \t\t\tcommand:\n  \t\t\t\t- /bin/bash\n  \t\t\t\t- /etc/scripts/poststart.sh\n  preStop:\n  \texec:\n  \t\tcommand:\n  \t\t\t- bash\n  \t\t\t- -c\n  \t\t\t- pkill -f \"MainProcess\"\n  ...\n  ```\n\n<details>\n<summary>Click here if you are interested in knowing what the script does.</summary>\n\nThe export tasks in the etl use Docker images with their own filesystems. Mounting a folder to the Docker image allows us to connect the airflow-worker filesystem to the Docker image filesystem. However, there are multiple airflow-worker instances, and tasks are distributed between them. This means that an export task may occur on one worker, and the subsequent task that needs that file could occur on a different worker instance. There needs to be some way to pool all the data from all the worker instances.\n\nFortunately, Cloud Composer provides a folder at /home/airflow/gcs/data. This folder is described in detail [here](https://cloud.google.com/composer/docs/concepts/cloud-storage). Essentially, the folder is synchronized between all the workers, and it also is linked to the data folder in the environment's Cloud Storage bucket. This means that data stored here will be available to all workers, solving the problem. Unfortunately, since this folder is already connected to a Cloud Storage bucket, it cannot also connect to a Docker image.\n\nInstead, we connect a local folder defined in the previous step. The `poststart.sh` script runs constantly in the background. It moves files from the local folder to the gcs/data folder. The script is more complicated than a simple move command because it needs to ensure that no programs are writing to the files before they are moved.\n\n</details>\n</details>\n\n<br>\n\n### **Add Airflow Variables and Connections**\n\nIn order to add the Airflow variables and connections, navigate to the Airflow web server. To do so, navigate to the [Composer section of the Cloud Console](https://console.cloud.google.com/composer/environments), and click the link under `Airflow Webserver`.\n\nClick the Admin tab, then Connections. Click create, then:\n\n- Set the `Conn Id` field to `google_cloud_platform_connection`.\n- Set the `Conn Type` to `Google Cloud Platform`.\n- Set the `Project Id` to your project id\n- Set the `Keyfile Path` to `<api_key_path>`.\n- The `<api_key_path>` should be the same as the Airflow variable `api_key_path`.\n\nNext, add the Airflow variables. Click the Admin tab, then Variables. Click the `Choose file` button, select your variables file, and click import variables.\n\nThe `airflow_variables.txt` file provides a set of default values for variables.\n\n<br>\n\n---\n\n## **Airflow Variables Explanation**\n\n### **Normal Variables**\n\n| Variable name                 | Description                                                                                                                                         | Should be changed?                                                    |\n| ----------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| affinity                      | JSON object that represents the pod's [affinity](https://cloud.google.com/composer/docs/how-to/using/using-kubernetes-pod-operator#affinity-config) | Yes, if you followed the optional step and made a new node pool.      |\n| api_key_path                  | path to the Google Cloud Platform [API key](https://cloud.google.com/docs/authentication/api-keys?authuser=1)                                       | No, unless your filename is different.                                |\n| bq_dataset                    | name of the BigQuery [dataset](https://cloud.google.com/bigquery/docs/datasets)                                                                     | Yes. Change to your dataset name.                                     |\n| bq_project                    | name of the BigQuery [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#console)                                   | Yes. Change to your project name.                                     |\n| gcs_exported_data_bucket_name | name of the Google Cloud Storage [bucket](https://cloud.google.com/storage/docs/creating-buckets) that will store exported data                     | Yes. Change to the name of the bucket you made.                       |\n| image_name                    | name of the ETL's Docker image                                                                                                                      | No, unless you need a specific image version.                         |\n| image_output_path             | local output path within the ETL image                                                                                                              | No.                                                                   |\n| image_pull_policy             | Specifies how image pull behavior. Valid values are: `Always`, `IfNotPresent`, or `Never`                                                           | No, unless you handle image updates manually.                         |\n| local_output_path             | local output path within the airflow-worker that is used for temporary storage                                                                      | No, unless you changed the path when modifying the Kubernetes config. |\n| namespace                     | namespace name for ETL tasks that generate Kubernetes pods                                                                                          | Yes, if you followed the optional step and made a new namespace       |\n| output_file_names             | JSON object. Each key should be a data structure, and the value should be the name of the output file for that data structure                       | Yes, if desired. Make sure each type has a different filename.        |\n| output_path                   | shared output path for exported data                                                                                                                | No, unless you have a different shared storage solution.              |\n| owner                         | the name of the owner of the Airflow DAGs                                                                                                           | Yes.                                                                  |\n| schema_filepath               | file path to schema folder                                                                                                                          | No, unless schemas are in a different location                        |\n| table_ids                     | JSON object. Each key should be a data structure, and the value should be the name of the BigQuery table                                            | Yes, if desired. Make sure each type has a different table name.      |\n| cluster_fields                | JSON object. Each key should be a BigQuery table, and the value is a list of columns that the table is clustered by                                 | Yes, if desired for tables that want clustering                       |\n| partition_fields              | JSON object. Each key should be a BigQuery table, and the value is a JSON object of type and field to partition by                                  | Yes, if desired for tables that want partitioning                     |\n| gcs_exported_object_prefix    | String to prefix run_id export task output path with                                                                                                | Yes, if desired to prefix run_id                                      |\n| sentry_dsn                    | Sentry Data Source Name to tell where Sentry SDK should send events                                                                                 | Yes                                                                   |\n| sentry_environment            | Environment that sentry alerts will fire                                                                                                            | Yes                                                                   |\n| use_testnet                   | Flag to use testnet data instead of mainnet                                                                                                         | Yes, if desired to use testnet data                                   |\n| task_timeout                  | JSON object. Each key should be the airflow util task name, and the value is the timeout in seconds                                                 | Yes, if desired to give tasks timeout                                 |\n\n### **Kubernetes-Specific Variables**\n\n| Variable name            | Description                                                                                                                                                                                                                                                                                 | Should be changed?                                                                                     |\n| ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |\n| resources                | Resources to request and allocate to Kubernetes Pods.                                                                                                                                                                                                                                       | No, unless pods need more resources                                                                    |\n| kube_config_location     | Location of the kubernetes config file. See [here](https://www.astronomer.io/docs/cloud/stable/develop/kubepodoperator-local#get-your-kube-config) for a guide on finding the Kube config file. If you are running the pods in the same cluster as Airflow, you can leave this value blank. | No, unless the pods are in a different cluster than Airflow.                                           |\n| kubernetes_sidecar_image | Image used for xcom sidecar                                                                                                                                                                                                                                                                 | No, unless you want to pull a different alpine-based image.                                            |\n| k8s_namespace            | Namespace to run the task in                                                                                                                                                                                                                                                                | No, unless the pods are moved into a new namespace                                                     |\n| k8s_service_account      | K8s service account the task runs as                                                                                                                                                                                                                                                        | No, unless k8s authentication is modified, and is likely linked to the associated GCP service account. |\n| volume_config            | JSON objects representing the configuration for your Kubernetes volume.                                                                                                                                                                                                                     | Yes. Change configs to match your volume (see below for example configs)                               |\n| volume_name              | Name of the persistent ReadWriteMany volume associated with the claim.                                                                                                                                                                                                                      | Yes. Change to your volume name.                                                                       |\n\nHere are some example `volume_config` values. Note that a ReadWriteMany volume is required when tasks run in parallel.\n\n- For a an NFS volume set `volume_config={\"nfs\": {\"path\": \"/\", \"server\": \"my-server.provider.cloud\"}}`.\n- In order to set up a persistent volume claim, set `volume_config={\"persistentVolumeClaim\":{\"claimName\": <claim>}`\n- In order to set up a host path volume, set `volume_config=\"hostPath\":{\"path\": <path>, \"type\": \"DirectoryOrCreate\"}}`\n\n<br>\n\n# Execution Procedures\n\n- [Starting Up](#starting-up)\n- [Handling Failiures](#handling-failures)\n  - [Clearing Failures](#clearing-failures)\n\n## **Starting Up**\n\n> **_NOTE:_** Google Cloud Composer instance of airflow has limited CLI support.\n> [Supported Airflow CLI commands](https://cloud.google.com/composer/docs/composer-2/access-airflow-cli#supported-commands)\n\nFirst, this image has a shows the Airflow web UI components for pausing and triggering DAGs:\n![Airflow UI](documentation/images/AirflowUI.png)\n\n- Ensure that the Airflow scheduler is running: `airflow scheduler`\n- Ensure that the Airflow web server is running: `airflow webserver -p <port>`\n- Enable the DAGs\n  - Use the command `airflow unpause <DAG name>` or use the Airflow UI\n\n## **Handling Failures**\n\n### **Clearing Failures**\n\nYou can clear failed tasks in the [task-instance context menu](https://airflow.apache.org/docs/apache-airflow/1.10.14/ui.html#task-instance-context-menu) in the Airflow UI. Clearing failed tasks gives them a chance to run again without requiring you to run the entire DAG again.\n\n<br>\n\n# Understanding the Setup\n\nThis section contains information about the Airflow setup. It includes our DAG diagrams and explanations of tasks. For general Airflow knowledge, check out the Airflow [concepts overview](https://airflow.apache.org/docs/apache-airflow/stable/concepts.html) or the Airflow [tutorial](https://airflow.apache.org/docs/apache-airflow/stable/tutorial.html).\n\n- [DAG Diagrams](#dag-diagrams)\n  - [History Archive with Captive Core DAG](#history-archive-with-captive-core-dag)\n  - [History Archive without Captive Core DAG](#history-archive-without-captive-core-dag)\n  - [State Table Export DAG](#state-table-export-dag)\n  - [Bucket List DAG (Unsupported)](#bucket-list-dag-nsupported)\n- [Task Explanations](#task-explanations)\n  - [build_time_task](#build_time_task)\n  - [build_export_task](#build_export_task)\n  - [build_gcs_to_bq_task](#build_gcs_to_bq_task)\n  - [build_apply_gcs_changes_to_bq_task](#build_apply_gcs_changes_to_bq_task)\n  - [build_batch_stats](#build_batch_stats)\n  - [bq_insert_job_task](#bq_insert_job_task)\n  - [cross_dependency_task](#cross_dependency_task)\n  - [delete_data_task](#delete_data_task)\n\n## **DAG Diagrams**\n\n### **History Archive with Captive Core DAG**\n\n[This DAG](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/history_archive_with_captive_core_dag.py):\n\n- exports transactions, operations, trades, and effects from Stellar using CaptiveCore\n- inserts into BigQuery\n  > _*NOTE:*_ SDF writes to both a private dataset and public dataset. Non-SDF instances will probably only need to write to a single private dataset.\n\n![History Archive with Captive Core Dag](documentation/images/history_archive_with_captive_core.png)\n\n### **History Archive without Captive Core DAG**\n\n[This DAG](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/history_archive_without_captive_core_dag.py):\n\n- exports assets and ledgers from Stellar's history archives\n- inserts into BigQuery\n  > _*NOTE:*_ SDF writes to both a private dataset and public dataset. Non-SDF instances will probably only need to write to a single private dataset.\n\n![History Archive Dag](documentation/images/history_archive_without_captive_core.png)\n\n### **State Table Export DAG**\n\n[This DAG](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/state_table_dag.py)\n\n- exports accounts, account_signers, offers, claimable_balances, liquidity pools, and trustlines\n- inserts into BigQuery\n\n![Bucket List DAG](documentation/images/state_table_export.png)\n\n### **Bucket List DAG (Unsupported)**\n\n> _*NOTE:*_ Bucket List DAG is unsupported.\n\n[This DAG](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/bucket_list_dag.py):\n\n- exports from Stellar's bucket list, which contains data on accounts, offers, trustlines, account signers, liqudity pools, and claimable balances\n- inserts into BigQuery\n\n![Bucket List DAG](documentation/images/bucket_list_export.png)\n\n### **Sandbox update DAG**\n\n[This DAG](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/sandbox_update_dag.py)\n\n- This DAG update the Canvas sandbox dataset with transactions tables, state tables with history once a month.\n\n![sandbox update DAG](documentation/images/sandbox_update_dag.png)\n\n### **Cleanup metadata DAG**\n\n[This DAG](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/cleanup_metadata_dag.py)\n\n- A maintenance workflow that you can deploy into Airflow to periodically clean\n  out the DagRun, TaskInstance, Log, XCom, Job DB and SlaMiss entries to avoid\n  having too much data in your Airflow MetaStore.\n\n![Cleanup metadata DAG](documentation/images/cleanup_metadata_dag.png)\n\n<br>\n\n## **Task Explanations**\n\n### **build_time_task**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_time_task.py) contains methods for creating time tasks. Time tasks call the get_ledger_range_from_times function in the stellar-etl Docker image. The tasks receive the execution time of the current DAG run and the expected execution time of the next run. They convert this time range into a ledger range that can be passed to the export tasks.\n\n### **build_export_task**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_export_task.py) contains methods for creating export tasks. Export tasks call export functions in the stellar-etl Docker image with a ledger range determined by the upstream time task. The data is exported in a newline-delimited JSON text file with a file name in the format `[start ledger]-[end ledger]-[data type].txt`.\n\n### **build_gcs_to_bq_task**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_gcs_to_bq_task.py) contains methods for creating tasks that appends information from a Google Cloud Storage file to a BigQuery table. These tasks will create a new table if one does not exist. These tasks are used for history archive data structures, as Stellar wants to keep a complete record of the ledger's entire history.\n\n### **build_apply_gcs_changes_to_bq_task**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_apply_gcs_changes_to_bq_task.py) contains methods for creating apply tasks. Apply tasks are used to merge a file from Google Cloud Storage into a BigQuery table. Apply tasks differ from the other task that appends in that they apply changes. This means that they update, delete, and insert rows. These tasks are used for accounts, offers, and trustlines, as the BigQuery table represents the point in time state of these data structures. This means that, for example, a merge task could alter the account balance field in the table if a user performed a transaction, delete a row in the table if a user deleted their account, or add a new row if a new account was created.\n\nApply tasks can also be used to insert unique values only. This behavior is used for orderbook and history archive data structures. Instead of performing a merge operation, which would update or delete existing rows, the task will simply insert new rows if they don't already exist. This helps prevent duplicated data in a scenario where rows shouldn't change or be deleted. Essentially, this task replicates the behavior of a primary key in a database when used for orderbooks.\n\n### **build_batch_stats**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_batch_stats.py) pulls and inserts batch stats into BigQuery.\nData is inserted into `history_archives_dag_runs`.\n\n### **bq_insert_job_task**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_bq_insert_job_task.py) contains methods for creating BigQuery insert job tasks.\nThe task will read the query from the specified sql file and will return a BigQuery job operator configured to the GCP project and datasets defined.\n\n### **cross_dependency_task**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_cross_dependency_task.py) creates an ExternalTaskSensor that triggers on specified DAG tasks's success.\n\n### **build_delete_data_task**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_delete_data_task.py) deletes data from a specified BigQuery `project.dataset.table` according to the batch interval.\n\n> _*NOTE:*_ If the batch interval is changed, the deleted data might not align with the prior batch intervals.\n\n### **build_copy_table_task**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_copy_table_task.py) copies a table from an specified BigQuery `project.dataset.table` to its destination inside of an specific project and dataset.\n\n### **build_coingecko_api_to_gcs_task**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_coingecko_api_to_gcs_task.py) creates a CSV file from the CoinGecko API and uploads it to Google Cloud Storage, inside of a bucket.\nThe file is named after the destination_blob_name parameter and the columns parameter is used to create the CSV file with the specified columns.\n\n### **build_check_execution_date_task**\n\n[This file](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_check_execution_date_task.py) checks if the current date is in the list of dates that are set to reset the DAG.\nIf the current date is in the list, the DAG will continue to run the tasks that are set to run on the reset date. If the current date is not in the list, the DAG will stop running the tasks that are set to run on the reset date.\n\n<br>\n\n# Further Development\n\nThis section details further areas of development. It covers a basic guide on how to add new features and test changes to existing features. It also contains a list of project TODOs (check the GitHub [issues page](https://github.com/stellar/stellar-etl-airflow/issues) for more!)\n\n## **Extensions**\n\nThis section covers some possible extensions or further work that can be done.\n\n- [Pre-commit Git hook scripts](#pre-commit-git-hook-scripts)\n- [Adding New DAGs](#adding-new-dags)\n- [Adding tasks to existing DAGs](#adding-tasks-to-existing-dags)\n- [Adding New Tasks](#adding-new-tasks)\n\n<br>\n\n### **Pre-commit Git hook scripts**\n\nGit can run special scripts at various places in the Git workflow (which the system calls \u201chooks\u201d).\nThese scripts can do whatever you want and, in theory, can help a team with their development flow.\n\n`pre-commit` makes hook scripts extremely accessible to teams.\n\n- Install `pre-commit`\n\n  ```bash\n  # using pip\n  $ pip install pre-commit==3.2.1\n  ```\n\n- Set up the Git hook scripts\n\n  ```bash\n  $ pre-commit install\n  pre-commit installed at .git/hooks/pre-commit\n  ```\n\nThat's it. Now `pre-commit` will run automatically on `git commit`!\n\n<br>\n\n### **Adding New DAGs**\n\nAdding new DAGs is a fairly straightforward process. Create a new python file in the `dags` folder. Create your dag object using the code below:\n\n```\ndag = DAG(\n\t'dag_id',\n\tdefault_args=get_default_dag_args(),\n\tdescription='DAG description.',\n\tschedule_interval=None,\n)\n```\n\nThe `get_default_dag_args()` is defined in the [dags/stellar-etl-airflow/default.py](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/default.py) file.\n\nFeel free to add more arguments or customize the existing ones. The documentation for a DAG is available [here](https://airflow.apache.org/docs/stable/_api/airflow/models/dag/index.html).\n\n<br>\n\n### **Adding tasks to existing DAGs**\n\nIf you have created a new DAG, or wish to extend an existing DAG, you can add tasks to it by calling the various `create_X_task` functions that are in the repository. See [here](https://airflow.apache.org/docs/stable/concepts.html#relations-between-tasks) for details on how to create dependencies between tasks.\n\n<br>\n\n### **Adding New Tasks**\n\nAdding new tasks is a more involved process. You likely need to add a new python file in the `dags/stellar_etl_airflow` folder. This file should include a function that creates and returns the new task, as well as any auxiliary functions related to the task.\n\nAirflow has a variety of operators. The ones that are most likely to be used are:\n\n- [DockerOperator](https://airflow.apache.org/docs/apache-airflow-providers-docker/stable/_api/airflow/providers/docker/operators/docker/index.html#airflow.providers.docker.operators.docker.DockerOperator), which can be used to execute commands within a docker container\n- [KubernetesPodOperator](https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/operators.html), which can start new Kubernetes Pods\n- [PythonOperator](https://airflow.apache.org/docs/stable/howto/operator/python.html), which can run Python functions\n\nYou may also find this list of [Google-related operators](https://airflow.apache.org/docs/stable/howto/operator/gcp/index.html) useful for interacting with Google Cloud Storage or BigQuery.\n\nAn example of a simple task is the [time task](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/stellar_etl_airflow/build_time_task.py). This task converts a time into a ledger range using a stellar-etl command. Since it needs to use the stellar-etl, we need a KubernetesPodOperator. We provide the operator with the command, the task_id, the parent DAG, and some parameters specific to KubernetesPodOperator.\n\nMore complex tasks might require a good amount of extra code to set up variables, authenticate, or check for errors. However, keep in mind that tasks should be idempotent. This means that tasks should produce the same output even if they are run multiple times. The same input should always produce the same output.\n\nYou may find that you need to pass small amounts of information, like filenames or numbers, from one task to another. You can do so with Airflow's [XCOM system](https://airflow.apache.org/docs/stable/concepts.html?highlight=xcom#xcoms).\n\n<br>\n\n## **Testing Changes**\n\nOnce you make a change, you can test it using the Airflow command line interface. Here's a quick outline of how to test changes:\n\n- Run `kubectl get pods --all-namespaces`. Look for a pod that starts with `airflow-worker`.\n- Run `kubectl -n <pod_namespace> exec -it airflow-worker-<rest_of_pod_name> -c airflow-worker -- /bin/bash` to get inside the worker\n- Run `airflow task test history_archive_export <task_id> <test_date>`. Note that if the task you changed has dependencies, you need to run `airflow test` on those upstream tasks for the exact same date.\n- Run `airflow task test` on the tasks that depend on the the task you just changed. Ensure that they still perform as expected.\n\nThis guide can also be useful for testing deployment in a new environment. Follow this testing process for all the taks in your DAGs to ensure that they work end-to-end.\n\nAn alternative to the testing flow above is to `trigger` the task in the Airflow UI. From there you are able to view the task status, log, and task details.\n", "release_dates": []}, {"name": "stellar-protocol", "description": "Developer discussion about possible changes to the protocol.", "language": "RPC", "license": null, "readme": "<div align=\"center\">\n<img alt=\"Stellar\" src=\"https://github.com/stellar/.github/raw/master/stellar-logo.png\" width=\"558\" />\n<br/>\n<strong>Creating equitable access to the global financial system</strong>\n<h1>Stellar Protocol</h1>\n</div>\n<p align=\"center\">\n<a href=\"./core/README.md\"><img alt=\"Docs: CAPs\" src=\"https://img.shields.io/badge/docs-CAPs-blue\" /></a>\n<a href=\"./ecosystem/README.md\"><img alt=\"Docs: SEPs\" src=\"https://img.shields.io/badge/docs-SEPs-blue\" /></a>\n</p>\n\nThis repository is home to **Core Advancement Proposals** (CAPs) and **Stellar Ecosystem Proposals**\n(SEPs).\n\nSimilar to [BIPs](https://github.com/bitcoin/bips) and [EIPs](https://github.com/ethereum/EIPs),\nCAPs and SEPs are the proposals of standards to improve the Stellar protocol and related client APIs.\n\nCAPs deal with changes to the core protocol of the Stellar network. Please see [the process for CAPs](core/README.md).\n\nSEPs deal with changes to the standards, protocols, and methods used in the ecosystem built on top\nof the Stellar network. Please see [the process for SEPs](ecosystem/README.md).\n\n## Repository structure\n\nThe root directory of this repository contains:\n\n* Templates for creating your own CAP or SEP\n* `contents` directory with `[cap | sep]-xxxx` subdirectories that contain all media/script files for a given CAP or SEP document.\n* core directory which contains accepted CAPs (`cap-xxxx.md` where `xxxx` is a CAP number with leading zeros, ex. `cap-0051.md`)\n* ecosystem directory which contains accepted SEPs (`sep-xxxx.md` where `xxxx` is a SEP number with leading zeros, ex. `sep-0051.md`)\n\nExample repository structure:\n```\n\u251c\u2500\u2500 CONTRIBUTING.md\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 cap-template.md\n\u251c\u2500\u2500 contents\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 cap-0003\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 get_offer_stats.sql\n\u251c\u2500\u2500 core\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cap-0001.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cap-0002.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cap-0003.md\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u251c\u2500\u2500 ecosystem\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 README.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sep-0001.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sep-0002.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sep-0003.md\n\u2514\u2500\u2500 sep-template.md\n```\n\n## Contributing\n\nSee [CONTRIBUTING](CONTRIBUTING.md) to learn how to contribute.\n\n[Stellar Development Foundation]: https://stellar.org\n", "release_dates": []}, {"name": "stellar-turrets", "description": "Reference implementation of the Stellar Turrets protocol", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Stellar Turrets Reference Implementation\n\nThis Stellar Turrets reference implementation employs two serverless services. Cloudflare workers and an AWS lambda function. The reason for this is that txFunctions are by their nature unsafe arbitrary Javascript functions. Cloudflare doesn't allow the execution of such functions thus we're splitting the workload between the much more performant and affordable Cloudflare workers and an AWS lambda function which will serve as our txFunction execution environment.\n\nSee below for specific instructions for setting up and running both services.\n\n\n## Installation Guide\n\nThere are two apps you need to deploy one in [`/serverless](#AWS-serverless) and one in [/wrangler](#CloudFlare-Workers-setup-wrangler).\n  \n\n### CloudFlare Workers setup wrangler\n\n - If you haven't already go ahead and [signup for Cloudflare workers](https://dash.cloudflare.com/). You can attempt to run on their free tier but I highly suggest just biting the very affordable bullet and upgrading to their $5/mo plan which will allow you to scale much more nicely.\n - After you've signed up for cloudflare workers, go ahead and create a new service for your turret or two if you want to run on testnet and livenet.\n - Now back at your console there are a few prerequisites. First you should have NodeJS 16 or newer installed along with npm. You should have access to the commands `npm` and `npx` from your console. You will also need to have CloudFlare wrangler installed. \n\n`npm install -g @cloudflare/wrangler` (you don't need a global install, but i find it convenient.)\n\nrun `wrangler login` \n\nFor the next step you will need to have a number of values from your CloudFlare account. Some basic info on obtaining these values is below.\n\n#### Setting Up Your Environment (`.env` and `wrangler.toml`)\n\nGenerate the `.env` and `wrangler.toml` files from their templates.\n```sh\ncd wrangler\nnpm install\nnpm run init\n```\n**Notes:**\n\n - The `init` script will ask for the values mentioned above, which\n   you'll need at hand in order to successfully finish the init step, to\n   get them for the first time you may need to run the script multiple\n   times. TODO: update init to be compatible with win32\n - Setup your `WRANGLER_ACCOUNT_ID` first, because you because\n   `wrangler-cli` requires it in order to create the `kv_namespaces`\n   below. \n - Create the key value store namespaces that go into the\n   `kv_namespaces` on your CloudFlare project.\n - You can rerun the init script as many times as you find necessary, so\n   if you don't have the value at hand just hit enter.\n - Variables in `.env` that already have values assigned won't be updated again by\n   this step, so you may need to update them manually if they need\n   changed.\n\n** **\n| env variables | explanations: | Default:\n| -- | -- | -- |\n| `WRANGLER_ACCOUNT_ID` | For the `account_id` go to the workers page on [dash.cloudflare.com](https://dash.cloudflare.com) and copy your`Account ID`. | \n| [TESTNET_HORIZON_URL](#horizon-url)  | The testnet horizon to use.| `https://horizon-testnet.stellar.org` \n| [TESTNET_TURRET_ADDRESS](#turret-address) | The testnet address of your turret. | |\n| [TESTNET_TURRET_FUNCTION_RUNNER_URL](#turret-run-url) | the endpoint for your function runner [turret-run-url](#turret-run-url) | null |\n| [TESTNET_WRANGLER_WORKER_NAME](#worker-name) | The name of your testnet service on CloudFlare Workers | |\n| [TESTNET_WRANGLER_META](#generating-kv-namespaces) | The kv store for your stellar.toml metadata file[see generating kv namespaces](#generating-kv-namespaces) | |\n| [TESTNET_WRANGLER_TX_FUNCTIONS](#generating-kv-namespaces)  |  [see generating kv namespaces](#generating-kv-namespaces) | |\n| [TESTNET_WRANGLER_XLM_FEE_MIN](#fees) | the minimum fee to run a function in xlm | 1 |\n| [TESTNET_WRANGLER_XLM_FEE_MAX](#fees) | | 10 |\n| [TESTNET_WRANGLER_UPLOAD_DIVISOR](#fees) | | 1000 |\n| [TESTNET_WRANGLER_RUN_DIVISOR](#fees) | | 1000000 |\n| [PUBLIC_HORIZON_URL](#horizon-url) | mainnet horizon url | `https://horizon.stellar.org` |\n| [PUBLIC_TURRET_ADDRESS](#turret-address) | mainnet turret account pubkey | |\n| [PUBLIC_TURRET_FUNCTION_RUNNER_URL](#turret-run-url) | the endpoint for your function runner [turret-run-url](#turret-run-url) | null |\n| [PUBLIC_WRANGLER_WORKER_NAME](#worker-name) | mainnet worker name | tss |\n| [PUBLIC_WRANGLER_META](#generating-kv-namespaces)  |[see generating kv namespaces](#generating-kv-namespaces) | |\n| [PUBLIC_WRANGLER_TX_FUNCTIONS](#generating-kv-namespaces)  | | |\n| [PUBLIC_WRANGLER_ALLOWED](#generating-kv-namespaces)  | The KV store for allowed  [see generating kv namespaces](#generating-kv-namespaces) | |\n| [PUBLIC_WRANGLER_XLM_FEE_MIN](#fees) | the minimum fee to run a function in xlm | 1 |\n| [PUBLIC_WRANGLER_XLM_FEE_MAX](#fees) | | 10 |\n| [PUBLIC_WRANGLER_UPLOAD_DIVISOR](#fees) | | 1000 |\n| [PUBLIC_WRANGLER_RUN_DIVISOR](#fees) | | 1000000 |\n\n### Generating KV Namespaces\n\nCreate the testnet kv stores:\n```sh\n$ npx wrangler kv:namespace create \"META\"\n$ npx wrangler kv:namespace create \"TX_FUNCTIONS\"\n```\n\nCreate the mainnet kvs:\n```sh\n$ npx wrangler kv:namespace create \"META\" --env public\n$ npx wrangler kv:namespace create \"TX_FUNCTIONS\" --env public\n$ npx wrangler kv:namespace create \"ALLOWED\" --env public\n```\n\nEach of those commands will spit out the string to provide in the init-step.\n\n- Run `npm run init` again and provide the kv id's in the appropriate places.\n\n##### HORIZON_URL\n -  For `HORIZON_URL` place in the url for the horizon service your Turret will consume. This should match with either the Test or Public network.\n##### TURRET_ADDRESS\n -  For `TURRET_ADDRESS` just use any valid, funded, Stellar account you privately own. This is the account into which fees will be paid as txFunctions are uploaded and run on your Turret.\n##### TURRET_RUN_URL\n - Set `TURRET_RUN_URL` to `null` for now until we've got the Serverless AWS lambda setup with it's endpoint, at which point you'll update this value to that url.\n##### Fees\n - Finally set the `XLM_FEE_MIN`, `XLM_FEE_MAX`, `UPLOAD_DIVISOR`, and `RUN_DIVISOR` values. The defaults are considered reasonable but you can raise or lower them if you wish; however remember simple supply and demand in doing so.\n##### Worker Name\n - The name of your service on CloudFlare workers\n#### Todos\n - use a single env set instead of defaulting to testnet and public.\n - add local install instructions.\n - make win32 compatable.\n - automate above process substantially.\n\n### Setting up your stellar.toml file\nNow that the `wrangler.toml` file has been created let's move to the `stellar.toml` file. This file is served as your Turret's `stellar.toml` file. Particularly note the `[TSS].TURRETS` array; this will be an array of other Turret addresses that you trust to cohost txFunctions with in the case of txFunction healing. For now just make sure to include your own `TURRET_ADDRESS` which should be the first entry. There are already a few other turrets in the file as well. You can add or remove those entries to your liking/trust.\nOnce you've got that go ahead and upload it to the `META` kv store you instantiated earlier.\n```sh\n$ npx wrangler kv:key put --binding=META \"STELLAR_TOML\" ./stellar.toml --path\n```\nMake sure to run these wrangler commands from the `./wrangler` directory\n\n### DEPLOY TO RUN!\n - From within the `./wrangler` directory:\n```sh\n$ npm i\n$ wrangler publish --new-class TxFees\n```\n - You may have to work through a few errors to get logged into your Cloudflare account but the wrangler cli errors are typically quite helpful. Feel free to update this README with more clear instructions.\n##### TURRET_SIGNER\n - Once you've successfully got your project created and running upload a `TURRET_SIGNER` Stellar secret key to your Cloudflare worker.\n```sh\n$ npx wrangler secret put TURRET_SIGNER\n```\n - When the dialog asks your for a value paste in a valid Stellar **secret key**. Most often this will be the secret key counterpart to your `TURRET_ADDRESS` but this isn't a requirement. This key is used to authenticate requests between your Cloudflare and Serverless services, nothing else.\n - This connection is what secures and protects access between the Cloudflare and Serverless APIs. Remember Cloudflare gets the **private key** and Serverless gets the **public key**.\n##### Re-deploy\n - Whenever you need to redeploy the project in the future either run\n```sh\n$ npm run deploy\nor\n$ wrangler publish\n```\n- The `--new-class TxFees` you included in the first deploy was just an initializer argument for the `TxFees` Durable Object. Once you've successfully deployed do not include it again.\n```\n  ***\n\n## Serverless (AWS)\n\n - Next we have the Serverless lambda endpoint which is hosted with AWS but deployed using the far more sane [serverless.com](https://serverless.com) cli tool.\n - If you haven't go create both an [AWS console account](https://www.amazon.com/) and a [serverless.com account](https://www.serverless.com/dashboard/). \n - Once you have those setup ensure you've got the [serverless cli installed](https://github.coserm/serverless/components#quick-start).\n\nNow it'll be the fun task of getting:\n\n```sh\n$ yarn\n$ npm run deploy\n```\nTo successfully run from within the `./serverless` directory.\nif you're going to deploy to mainnet:\n```sh\nnpx envdist public\nnpm run deploy:public\n```\nAfter you get it to build, you will be prompted for setting up your environmental variables for your .env:\n\n| Variable | Description | default |\n| -- | -- | -- |\n| SLS_ORG | The organization name in serverless | |\n| SLS_APP | The name of the serverless app to create | `stellar-turrets` |\n| SLS_SERVICE | The name of the serverless service | `stellar-turrets` |\n| SLS_TURRET_BASE_URL | The URL of your wrangler service | |\n| SLS_TURRET_SIGNER_ACCOUNT | The **public key** of [the secret used in deploying wrangler](#TURRET_SIGNER) | |\n| SLS_AWS_PLAN | Use paid or free aws plan | free |\n\nThis connection is what secures and protects access between the Cloudflare and Serverless APIs. Remember Cloudflare gets the **private key** and Serverless gets the **public key**.  \n\nFollow any errors carefully and you should be able to get successfully deployed pretty quickly.\nThe most probable issue will be you need to manually create an app in the [Serverless dashboard](https://app.serverless.com/) and attach some new IAM credentials to it manually. \n    - In serverless dashboard click \"Apps\" on the left sidebar, then click \"Create App\" at the top.\n    - select \"Serverless Framework\"\n    - name your app and service to match the name you've given it during deploy.\n    - Select the aws credentials you've setup \n    - now run `serverless deploy` for testnet or `serverless deploy --stage public` for pubnet\n    - make sure you check the case of all 3 variables your org, app, and service.  they ARE Case sensitive\n    - There's a helpful UI walk through they have so you should be able to sort it out. \n\nAgain feel free to update these docs with more clear instructions as you sort out the nuances of setting the Serverless service up.\n\n\n*If* you are going to use the github action to deploy serverless, you need to set the three variables from above as repo-secrets as well.  \n\nWhen you finally get success on this task you'll be rewarded with an endpoint where your function is hosted. Copy that base url and paste it as the value for the `TURRET_FUNCTION_RUNNER_URL`  `var` back in the `.env` file in the `./wrangler` directory and run `npm run init && npm run deploy` again to update the worker to point to your lambda.\n\n## Congrats!\n\nAssuming both `npm run deploy`'s are now firing off without a hitch you should have a fully functional Turret ready to participate in the Stellar Turrets network delivering decentralized smart contracting functionality to anyone and everyone who chooses to use your Turret. Nice!\n\n## CI (github actions)\n\nThere are GH actions defined to actually deploy the serverless and wrangler parts continously. For this to work add the following secrets to your (cloned) repo:\n\n  \n\n| VARIABLE | Description | Default |\n| --- | --- | --- |\n| *STELLAR_NETWORK* | testnet= TESTNET or pubnet = PUBLIC| **TESTNET** |\n| *HORIZON_URL* | URL of horizon server. | **https://horizon-testnet.stellar.org** |\n| TURRET_ADDRESS | Existing and funded stellar address to receive fees | |\n| TURRET_FUNCTION_RUNNER_URL | base URL of function runner (serverless part from above) | null |\n| WRANGLER_ACCOUNT_ID | ID of cloudflare account to deploy wrangler to | |\n| WRANGLER_API_TOKEN | Token for cloudflare API access | |\n| *WRANGLER_WORKER_NAME* | name of your worker inside cloudflare | **tss-wrangler** |\n| WRANGLER_META | KV namesapace for worker's META information | |\n| WRANGLER_TX_FUNCTIONS | KV namespace for worker's functions | |\n| *WRANGLER_XLM_FEE_MIN* | The minimum claimable fee balance allowed. See [turret_info] | **1** |\n| *WRANGLER_XLM_FEE_MAX* | The maximum claimable fee balance allowed. See [turret_info] | **10** |\n| *WRANGLER_UPLOAD_DIVISOR* | The divisor used in fee calculations for uploading functions. See [turret_info] | **1000** |\n| *WRANGLER_RUN_DIVISOR* | The divisor used in fee calculations for running functions. See [turret_info] | **100000** |\n| SLS_ORG | The serverless organization to deploy to | |\n| SLS_TURRET_BASE_URL | Base URL of turret (wrangler URL) | |\n| SLS_TURRET_SIGNER_ACCOUNT | Public key of function signer (counterpart to turret's **private** signer key) | |\n| *SLS_AWS_PLAN* | Indicate if you are using a free or paid plan | **free** |\n| SERVERLESS_ACCESS_KEY | Token for SLS API access | |\n  \noptional values are *italic* (i.e. will be using defaults if not set)\n\n## [API Docs](https://tyvdh.github.io/stellar-turrets/)\n\n## Disclaimer\n\nThis is public software representing a reference implementation for the [Stellar Turrets protocol](https://tss.stellar.org/).\n\nFor this reason I strongly suggest either:\n\n  A) Leaving your `STELLAR_NETWORK` set to `TESTNET`\n\n  B) Encouraging users to leave themselves as a majority signer on any controlled account they're attaching Turret signers to\n", "release_dates": []}, {"name": "stellar-turrets-docs", "description": "Docs repo for the Stellar Turrets protocol", "language": null, "license": null, "readme": "---\ndescription: Where you can learn about turrets.\n---\n\n# Stellar Turrets Docs\n\n## Welcome!\n\nStellar Turrets introduce a new way for applications to create decentralized, permissionless applications on the Stellar blockchain. This tool adds a layer 2 solution for decentralizing turing complete smart contracting for Stellar transactions, as well as adding a permissionless system for users to run smart contracts on.\n\n### What you'll find here\n\nDetails on the foundations of Stellar Turrets including what they are, how they work, and why they exist.\n\n[Overview](overview/basics.md)\n\nInformation on how to utilize Stellar Turrets for an application or smart contract.\n\n[Developers](developers/getting-started.md)\n\nResources on what it means to be a Stellar Turrets Host, and how to support the Turret Network.\n\n[Turret-Hosts](turret-hosts/getting-started.md)\n\n### Resources\n\nLinks to external resources\n\n* [JavaScript Reference Implementation](https://github.com/stellar/stellar-turrets)\n* [Discord Group](https://discord.com/invite/d5RPb5gDrK)\n* [Turret Explorer](https://app.turrets.dev)\n* [TSS Admin](https://github.com/Answap-io/tss-admin)\n\n### Projects\n\nLinks to projects built on Stellar Turrets\n\n* [Smart NFTs](https://nft.kalepail.com)\n* [YieldBlox](https://yieldblox.finance)\n* [Task.io](https://task.io)\n", "release_dates": []}, {"name": "stellar-tutorials", "description": "This repository holds tools and tutorials to help developers build on Stellar.", "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "Various tutorials for building on Stellar\n\nNetwork Explorer has been moved to [https://github.com/stellar/network-explorer](https://github.com/stellar/network-explorer).\n", "release_dates": []}, {"name": "stellar-upgrade", "description": null, "language": "Go", "license": null, "readme": "# stellar-upgrade\n\nTool to upgrade your account from STR to XLM on the much improved network.\n\nWeb version available here: https://stellar.github.io/stellar-upgrade-web/\n\n## Downloading the tool\n[Prebuilt binaries](https://github.com/stellar/stellar-upgrade/releases) of the upgrade tool are available are on the [releases page](https://github.com/stellar/stellar-upgrade/releases).\n\n| Platform       | Binary file name                                                                         |\n|----------------|------------------------------------------------------------------------------------------|\n| Mac OSX 32 bit | [stellar-upgrade-darwin-386](https://github.com/stellar/stellar-upgrade/releases)        |\n| Mac OSX 64 bit | [stellar-upgrade-darwin-amd64](https://github.com/stellar/stellar-upgrade/releases)      |\n| Linux 32 bit   | [stellar-upgrade-linux-386](https://github.com/stellar/stellar-upgrade/releases)         |\n| Linux 64 bit   | [stellar-upgrade-linux-amd64](https://github.com/stellar/stellar-upgrade/releases)       |\n| Windows 32 bit | [stellar-upgrade-windows-386.exe](https://github.com/stellar/stellar-upgrade/releases)   |\n| Windows 64 bit | [stellar-upgrade-windows-amd64.exe](https://github.com/stellar/stellar-upgrade/releases) |\n\nAlternatively, you can build the binary yourself. [gb](http://getgb.io) is used for building this upgrade tool.\n\n## Usage\nRemember to make sure that you have the correct name of the binary.\n\n### Upgrade an account\n```shell\n./stellar-upgrade-[binary-suffix] upgrade\n```\n\n`upgrade` is the only argument needed when starting the tool in the command line.\nThe tool will ask you for the old secret key once you've started the tool.\n\n### Check the upgrade status of an account\n```shell\n./stellar-upgrade-[binary-suffix] status gYourOldNetworkAddresszpwrG5QVUXqM\n```\n\n### Troubleshooting\nIf you get a \"Permission denied\" error similar to this:\n```shell\n-bash: ./stellar-upgrade-[binary-suffix]: Permission denied\n```\n\nUse the following command to grant permission to run the file.\n```shell\nchmod +x stellar-upgrade-[binary-suffix]\n```\n\n### Command line help message\n```shell\nstellar-upgrade upgrades your old network account\n\nUsage:\n  stellar-upgrade [command]\n\nAvailable Commands:\n  upgrade     Upgrade account on old network\n  status      Displays your account upgrade status\n  help        Help about any command\n\nFlags:\n  -h, --help=false: help for stellar-upgrade\n\n\nUse \"stellar-upgrade help [command]\" for more information about a command.\n```\n", "release_dates": ["2015-11-06T22:02:16Z", "2015-11-03T21:11:42Z", "2015-11-02T19:42:43Z", "2015-10-30T18:51:20Z"]}, {"name": "stellar-upgrade-web", "description": null, "language": "JavaScript", "license": null, "readme": null, "release_dates": []}, {"name": "stellar-wallet", "description": "Holds encrypted data. Used by stellar-client to store the user's key in a secure way. ", "language": "JavaScript", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Stellar Wallet\n[![Build Status](https://travis-ci.org/stellar/stellar-wallet.svg?branch=master)](https://travis-ci.org/stellar/stellar-wallet)\n[![Coverage Status](https://coveralls.io/repos/stellar/stellar-wallet/badge.png)](https://coveralls.io/r/stellar/stellar-wallet)\n[![Code Climate](https://codeclimate.com/github/stellar/stellar-wallet/badges/gpa.svg)](https://codeclimate.com/github/stellar/stellar-wallet)\n\nStores encrypted data. The wallet server can't decrypt the data. Used by https://github.com/stellar/stellar-client to save the user's secret keys. \n\n\n\n## Getting Started\n\n1. Get yourself a db: `gulp db:setup`\n1. Get yourself a running server: `stex www --watch`\n1. Start making requests against port 3000 (by default)\n\n## Connect directly to mysql\n\n`stex db-console`\n", "release_dates": []}, {"name": "stellar-xdr", "description": "Staging area for future version of Stellar XDR.", "language": "RPC", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# stellar-xdr\n\nXDR for the Stellar Network.\n", "release_dates": ["2024-02-01T03:09:08Z", "2023-12-01T22:57:37Z", "2022-11-18T18:09:48Z"]}, {"name": "stellarterm", "description": "Advanced web based trading client for the Stellar network. \ud83d\udcc8\ud83d\udcca\ud83d\udcb9\ud83d\udcb1", "language": "JavaScript", "license": null, "readme": "[![Travis CI status](https://travis-ci.org/irisli/stellarterm.svg?branch=master)](https://travis-ci.org/irisli/stellarterm)\n\n# StellarTerm ecosystem - [client](https://stellarterm.com/) | [api](https://github.com/irisli/stellarterm/tree/master/api) | [directory](https://github.com/irisli/stellarterm/blob/master/directory/)\nThis StellarTerm monorepo consists of multiple projects built for the [Stellar network](https://www.stellar.org/) including a [trading client](https://stellarterm.com/). The projects are in this monorepo to enable faster development speed.\n\n## Web Client\nStellarTerm is a web based trading client for use on the Stellar network. This client aims to make it easy and safe for users of any skill level to trade on the Stellar network by making a clear and secure user interface. Try it out at [https://stellarterm.com](https://stellarterm.com/)\n\n## API for developers (built on AWS Lambda)\nThe StellarTerm API contains information on the markets on the Stellar network. This information is useful for the StellarTerm client itself as well as other developers that want to use this data.\n\nThe API uses the [Serverless framework](https://serverless.com/) for deployment to [AWS Lambda](https://aws.amazon.com/lambda/). The API data is hosted on AWS S3 for high availability.\n\nIt is currently under active development and is not yet finished. See it in action here: [https://api.stellarterm.com/](https://api.stellarterm.com/)\n\n## [Directory](https://github.com/irisli/stellarterm/blob/master/directory/README.md)\nStellarTerm maintains a manually curated directory file with a listing of well known anchors and assets on the Stellar network. For more information, see the [directory README](https://github.com/irisli/stellarterm/blob/master/directory/README.md).\n\n-------------------------------------------------------------------------------\n\n## StellarTerm client custom network\n\n### Testnet\nTo use the testnet, simply add `#testnet` to the url to activate it. To exit, refresh the page where the url is not `#testnet`.\n\n### Custom horizon builds\nSome developers may want to use StellarTerm pointed to a custom horizon server or even a custom network. To do this, you must build StellarTerm locally.\n\nThe StellarTerm build process checks for the presence of relevant environment variables.\n\n```sh\nexport STELLARTERM_CUSTOM_HORIZON_URL=\"https://horizon-testnet.stellar.org\"\nexport STELLARTERM_CUSTOM_NETWORK_PASSPHRASE=\"Test SDF Network ; September 2015\"\n```\n\nOnce built, the configuration will be embedded into the StellarTerm output file (and the environment variable is no longer needed). To check this, look at the output of `index.html` and search for `stCustomConfig`.\n\n## StellarTerm client screenshots\n### A detailed user friendly orderbook\n![Orderbook](https://raw.githubusercontent.com/irisli/stellarterm/master/screenshots/orderbook.png)\n\n### Ability to add trust either from a curated list, manually, or via federation\n![Adding trust from directories](https://raw.githubusercontent.com/irisli/stellarterm/master/screenshots/adding-trust-from-directory.png)\n\n![Adding trust via federation](https://raw.githubusercontent.com/irisli/stellarterm/master/screenshots/adding-trust-via-federation.png)\n\n### Price history charts\n![Price history charts](https://raw.githubusercontent.com/irisli/stellarterm/master/screenshots/history-chart.png)\n\n### Ability to make offers in an intuitive manner\n![Offer maker](https://raw.githubusercontent.com/irisli/stellarterm/master/screenshots/offermaker.png)\n\n### A directory of the asset pairs traded on the Stellar network\n![Market directory](https://raw.githubusercontent.com/irisli/stellarterm/master/screenshots/marketdirectory.png)\n\n### Manage offers for an account\n![Manage offers](https://raw.githubusercontent.com/irisli/stellarterm/master/screenshots/manage-offers.png)\n\n### Shows listing of balances with secure asset cards\n![Detailed balances](https://raw.githubusercontent.com/irisli/stellarterm/master/screenshots/detailed-balances.png)\n\n### Compatible with accounts from any other client\n![Universal login](https://raw.githubusercontent.com/irisli/stellarterm/master/screenshots/universal-login.png)\n\n## Under the cover features\n- No external dependencies or trackers\n- All GitHub commits [securely signed with GPG](https://github.com/blog/2144-gpg-signature-verification)\n\n## Deployment\nThe project is hosted on GitHub pages in the [stellarterm/stellarterm.github.io](https://github.com/stellarterm/stellarterm.github.io/) repository. The client is wrapped into a single html file and it's sha 256 sum is recorded on each git commit.\n\n## Client development instructions\n### Prerequisites\nMake sure you have Node.js 7.4.0 or higher installed. If not, install it ([Node version manager](https://github.com/creationix/nvm) is recommended).\n\n```sh\n# Check your node version using this command\nnode --version\n```\n\n### Environment Setup\n```sh\n# Clone the project\ngit clone https://github.com/irisli/stellarterm.git\ncd stellarterm\n\n# Install the npm and bower dependencies\nnpm run setup\n```\n\n### Development mode\nThe build process has tools watches the code and rebuilds if something has changed. It will also serve the app locally (usually http://localhost:3000) and automatically refresh the page when changes are built.\n\n```sh\nnpm start\n```\n\n### Production build\nThis builds a single index.html file with assets inlined. The single file contains the whole app and can be hosted online. Output file is in `./dist/index.html`.\n```sh\nnpm run production\n```\n\n## License\nProducts in the StellarTerm ecosystem is open source software and is licensed under the [Apache-2.0 license](https://github.com/irisli/stellarterm/blob/master/LICENSE-2.0.txt). Please understand the license carefully before using StellarTerm.\n\n## Credits\n- Started the project using the super helpful [react-gulp-browserify yeoman generator](https://github.com/randylien/generator-react-gulp-browserify)\n", "release_dates": []}, {"name": "stories", "description": null, "language": "JavaScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "Stellar Stories\n===============\nStellar Stories is a collection of graphic explainers used to help people learn\nmore about Stellar and what it can do.\n\nCheck out the latest graphic novel: https://www.stellar.org/stories/adventures-in-galactic-consensus-chapter-1/\n\n\n## Getting started\n```bash\n#0. Install node.js and npm\n#1. Clone this repo\ngit clone https://www.github.com/stellar/stories/\n\n#2. Install gulp globally to use the `gulp` command\nnpm install --global gulp\n\n#3. Run npm install on both stories and storyteller.js\nnpm install\ncd storyteller\nnpm install\ncd ..\n\n#4. Use the gulp develop task to build, watch, and run a development server on [localhost:8000](http://localhost:8000)\ngulp develop\n```\n\n## License\nStory-app and storyteller.js is released under the [Apache License 2.0](LICENSE.txt). For more information, see the\n[LICENSE.txt](LICENSE.txt) file.\n\nImages and text inside `content` folder are copyright \u00a9 2015 Stellar Development Foundation All Rights Reserved.\n", "release_dates": []}, {"name": "supercluster", "description": "Stellar-core integration test automation tool", "language": "F#", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Stellar Supercluster\n\nStellar Supercluster (SSC) is package for automated integration testing of\n[stellar-core](https://github.com/stellar/stellar-core). It works by running\nmultiple containerized core nodes in self-contained simulated networks, and\nfeeding them traffic (and/or invoking their internal load-generation testing\nsubsystem). It is a second-generation tool, replacing the functionality of an\nolder and now-retired package called Stellar Core commander (SCC).\n\n## Why a new tool\n\nSSC Has the following differences from SCC:\n\n  - SCC used local processes and docker daemons. SSC uses Kubernetes for greater\n    scalability, automation and co-tenancy among users. See\n    [doc/kubernetes.md](doc/kubernetes.md) for some notes on Kubernetes.\n\n  - SCC was written in Ruby and was fairly slow, fragile and typo-prone. SSC is\n    written in F# for greater compile-time error checking, performance and IDE\n    support. See [doc/fsharp.md](doc/fsharp.md) for some notes on F#.\n\nSSC has been driving day-to-day integration testing and simulation experiments\nat [SDF](https://stellar.org) since late 2019, and is capable of testing much\nlarger and much more complex scenarios than SCC was, while being easier to\nmaintain and more robust to errors.\n\n## Getting started\n\nSee [doc/getting-started.md](doc/getting-started.md) for brief instructions on\nhow to use it.\n\n## Contributions and support\n\nSee [doc/contributing.md](doc/contributing.md). Support for uses outside of SDF\nwill be provided on a best-effort basis.\n\n## Supported Tests (\"Missions\")\n\nSee [doc/missions.md](doc/missions.md) for a list of supported tests.\n\n## Measuring transaction throughput\n\nSee [doc/measuring-transaction-throughput.md](doc/measuring-transaction-throughput.md) for instructions on load testing using supercluster. \n\n## License\n\n[Apache 2.0](COPYING)\n", "release_dates": []}, {"name": "system-test", "description": "Home of the stellar/stellar-system-test docker image for e2e system testing", "language": "Go", "license": null, "readme": "# System Test\n\n### Running system tests:\n  Identify the system-test image you want to use for running tests:\n  - Use a prebuilt system test image published as tags under `dockerhub.io/stellar/system-test`\n  - Build the system test docker image locally with specific versions of core, horizon, soroban rpc, rust toolchain, soroban cli, this will create a docker image named\n  `stellar/system-test:dev`.\n  All `GIT_REF` variables can refer to either a fully qualified local path to checked out git repo, or a fully qualified github remote repo url `https://github.com/repo#<ref>`\n  ```\n  make\n       QUICKSTART_GIT_REF=? \\\n       CORE_GIT_REF=? \\\n       CORE_COMPILE_CONFIGURE_FLAGS=? \\\n       SOROBAN_RPC_GIT_REF=? \\\n       SOROBAN_CLI_GIT_REF=? \\\n       GO_GIT_REF=? \\\n       RUST_TOOLCHAIN_VERSION=? \\\n       SOROBAN_CLI_CRATE_VERSION=? \\\n       JS_STELLAR_SDK_NPM_VERSION=? \\\n       NODE_VERSION=? \\\n       build\n  ```\n\n  example of build using specific git refs, mainline from repos in this example, or use tags, branches, etc:\n  ```\n  make CORE_GIT_REF=https://github.com/stellar/stellar-core.git#f1dc39f0f146815e5e3a94ed162e2f0639cb433f \\\n         CORE_COMPILE_CONFIGURE_FLAGS=\"--disable-tests --enable-next-protocol-version-unsafe-for-production\" \\\n         SOROBAN_RPC_GIT_REF=https://github.com/stellar/soroban-tools.git#main \\\n         RUST_TOOLCHAIN_VERSION=stable \\\n         SOROBAN_CLI_GIT_REF=https://github.com/stellar/soroban-tools.git#main \\\n         QUICKSTART_GIT_REF=https://github.com/stellar/quickstart.git#master \\\n         JS_STELLAR_SDK_NPM_VERSION=https://github.com/stellar/js-stellar-sdk.git#master \\\n         build\n  ```\n\n  example of build using an existing quickstart image, this can dramatically speed up the build time, as the existing quickstart image will provide the pre-compiled rpc, and core runtimes already:\n  ```\n  make QUICKSTART_IMAGE=stellar/quickstart:soroban-dev \\\n         RUST_TOOLCHAIN_VERSION=1.66.0 \\\n         SOROBAN_CLI_GIT_REF=/Users/user/soroban-tools build\n  ```\n\n  some settings have defaults pre-set, and optionally be overriden:\n  ```\n  SOROBAN_CLI_GIT_REF=https://github.com/stellar/soroban-tools.git#main\n  SOROBAN_RPC_GIT_REF=https://github.com/stellar/soroban-tools.git#main\n  RUST_TOOLCHAIN_VERSION=stable\n  QUICKSTART_GIT_REF=https://github.com/stellar/quickstart.git#master\n  # the GO_GIT_REF provides the reference on the stellar/go repo from which\n  # to build horizon\n  GO_GIT_REF=https://github.com/stellar/go.git#master\n  CORE_COMPILE_CONFIGURE_FLAGS=\"--disable-tests\"\n  CORE_GIT_REF=https://github.com/stellar/stellar-core.git#master\n  JS_STELLAR_SDK_NPM_VERSION=https://github.com/stellar/js-stellar-sdk.git#master\n  ```\n\n  optional to set:\n  ```\n  # this will override SOROBAN_CLI_GIT_REF, and install soroban cli from crates repo instead\n  SOROBAN_CLI_CRATE_VERSION=0.4.0\n\n  # this will override the default Node JS vm version used for running the JS code:\n  NODE_VERSION=16.20.2\n\n  # js sdk version can be set to a published npm version from https://www.npmjs.com/package/stellar-sdk\n  JS_STELLAR_SDK_NPM_VERSION=latest\n  # or it can be set to a github git ref of a js-stellar-sdk repo\n  JS_STELLAR_SDK_NPM_VERSION=https://github.com/stellar/js-stellar-sdk.git#master\n\n  # Image overrides.\n  # If using these, the image ref should provide a manifiest version for same\n  # platform arch as the build host is running on, i.e. linux/amd64 or linux/arm64.\n  # Otherwise, build will fail if image is not available for matching host platform.\n  #\n  # this will skip building from source for core(CORE_GIT_REF), rpc(SOROBAN_RPC_GIT_REF) and quickstart(QUICKSTART_GIT_REF), instead\n  # will use the versions already compiled in the existing quickstart docker image provided:\n  QUICKSTART_IMAGE=<docker registry>/<docker image name>:<docker tag>\n\n  # this will skip building core from CORE_GIT_REF and instead\n  # will use the bin already compiled at /usr/local/bin/stellar-core in the existing docker image provided:\n  CORE_IMAGE=<docker registry>/<docker image name>:<docker tag>\n\n  # this will skip building soroban-rpc from SOROBAN_RPC_GIT_REF and instead\n  # will use the bin already compiled at /bin/soroban-rpc in the existing docker image provided:\n  SOROBAN_RPC_IMAGE=<docker registry>/<docker image name>:<docker tag>\n\n  # this will skip building soroban-cli from SOROBAN_CLI_GIT_REF and instead\n  # will use the bin already compiled at /usr/local/cargo/bin/soroban in the existing docker image provided:\n  SOROBAN_CLI_IMAGE=<docker registry>/<docker image name>:<docker tag>\n\n  # this will skip building horizon from GO_GIT_REF and instead\n  # will use the bin already compiled at /go/bin/horizon in the existing docker image provided:\n  HORIZON_IMAGE=<docker registry>/<docker image name>:<docker tag>\n\n  # this will skip building friendbot from GO_GIT_REF and instead\n  # will use the bin already compiled at /app/friendbot in the existing docker image provided:\n  FRIENDBOT_IMAGE=<docker registry>/<docker image name>:<docker tag>\n  ```\n\nOptional parameters to pass when running system-test image, `stellar/system-test:<tag>`:\n\nTo specify git version of the smart contract source code used in soroban test fixtures.\n`--SorobanExamplesGitHash {branch, tag, git commit hash}`\n`--SorobanExamplesRepoURL \"https://github.com/stellar/soroban-examples.git\"`\n\nTo specify which system test feature/scenarios to run, it is a regex of the feature test name and a scenario defined within, each row in example data for a scenario outline is postfixed with '#01', '#02', examples:\n`--TestFilter \"^TestDappDevelop$/^DApp developer compiles, deploys and invokes a contract.*$\"`\nor\n`--TestFilter \"^TestDappDevelop$/^DApp developer compiles, deploys and invokes a contract#01$\"`\n\nThe default target network for system tests is a new/empty instance of local network hosted inside the docker container, tests will use the default root account already seeded into local network. Alternatively, can override the network settings for local and remote usages:\n- Tests will use an internally hosted core watcher node:\n`--TargetNetwork {standalone|futurenet|testnet}`\n- Tests will use an external rpc instance and the container will not run core, horizon, rpc services internally:\n`--TargetNetworkRPCURL {http://<rpc_host:rpc_port>/soroban/rpc}`\n- Tests use these settings in either target network mode, and these are by default set to work with local:\n`--TargetNetworkPassphrase \"{passphrase}\"`\n`--TargetNetworkTestAccountSecret \"{your test account key pair info}\"`\n`--TargetNetworkTestAccountPublic \"{your test account key pair info}\"`\n\nDebug mode, the docker container will exit with error code when any pre-setup or test fails to pass,\nyou can enable DEBUG_MODE flag, and the container will stay running, prompting you for enter key before shutting down, make sure you invoke docker with `-it` so the prompt will reach your command line. While container is kept running, you can shell into it via `docker exec -it <container id or name>` and view log files of services in the stack such as core, rpc located in container at `/var/log/supervisor`.\n`--DebugMode=true`\n\nThe docker run follows standard exit code conventions, so if all tests pass in the container run, exit code from command line execution will be 0, otherwise, if any failures in container or tests, then exit code will be greater than 0.\n\n#### Running Test Examples\n- Run tests against an instance of core and rpc on a local network all running in the test container:\n\n\n  ```\n  docker run --rm -t --name e2e_test stellar/system-test:<tag> \\\n  --VerboseOutput true\n  ```\n\n- Run tests against a remote instance of rpc configured for testnet, this will not run core or rpc instances locally in the test container. It requires you provide a key pair of an account that is funded with Lumens on the target network for the tests to use as source account on transactions it will submit to target network:\n\n\n  ```\n  docker run --rm -t --name e2e_test stellar/system-test:<tag> \\\n  --VerboseOutput true \\\n  --TargetNetworkRPCURL https://<rpc host url> \\\n  --TargetNetworkPassphrase \"Test SDF Network ; September 2015\" \\\n  --TargetNetworkTestAccountSecret <your test account key pair info> \\\n  --TargetNetworkTestAccountPublic <your test account key pair info> \\\n  --SorobanExamplesGitHash v20.0.0-rc2\n  ```\n\n\n### Development mode and running tests directly from checked out system-test repo.\nThis approach allows to run the tests from source code directly on host as go tests, no docker image is used.\n\n#### Prerequisites:\n\n 1. go 1.18 or above - https://go.dev/doc/install\n 2. rust toolchain(cargo and rustc), install the version per testing requirements or stable, - use rustup - https://www.rust-lang.org/tools/install\n 3. `soroban` cli, compile or install via cargo crate a version of soroban cli onto your machine and accessible from PATH.\n 4. target network stack for the tests to access soroban-rpc instance. You can use an existing/running instance if reachable or can use the quickstart image `stellar/quickstart:soroban-dev` from dockerhub to run the latest stable target network stack locally, or build quickstart with specific versions of core, horizon and soroban rpc first [following these instructions](https://github.com/stellar/quickstart#building-custom-images) and run `stellar/quickstart:dev` locally.\n     ```\n     docker run --rm -it -p 8000:8000 --name stellar stellar/quickstart:dev --standalone --enable-soroban-rpc\n     ```\n 5. locally checkout stellar/system-test GH repo and go into top folder - `git clone https://github.com/stellar/system-test.git;cd system-test`\n\n\n#### Running tests locally as go programs\n```\nsystem-test $ SorobanExamplesGitHash=\"main\" \\\nSorobanExamplesRepoURL=\"https://github.com/stellar/soroban-examples.git\" \\\nTargetNetworkPassPhrase=\"Standalone Network ; February 2017\" \\\nTargetNetworkSecretKey=\"SC5O7VZUXDJ6JBDSZ74DSERXL7W3Y5LTOAMRF7RQRL3TAGAPS7LUVG3L\" \\\nTargetNetworkPublicKey=\"GBZXN7PIRZGNMHGA7MUUUF4GWPY5AYPV6LY4UV2GL6VJGIQRXFDNMADI\" \\\nTargetNetworkRPCURL=\"http://localhost:8000/soroban/rpc\" \\\nVerboseOutput=false \\\ngo test -v --run \"^TestDappDevelop$/^DApp developer compiles, deploys and invokes a contract.*$\" ./features/dapp_develop/...\n```\n\nThis follows standard go test conventions, so if all tests pass, exit code from command line execution will be 0, otherwise, if any tests fail, then exit code will be greater than 0.\n\nThis example uses a feature/scenario filter also to limit which tests are run.\n\n* Tests will attempt to run `soroban` as the cli as provided from your operating system PATH.\n\n* the verbose output of BDD scenerio results for tests is dependent on go's testing verbose output rules, need to specify -v and a directory with single package, if multiple packages detected on directory location, then go won't print verbose output for each package, i.e. you wont see the BDD scenerio summaries printed, just the standard one liner for summary of package pass/fail status.\n\n#### Debugging tests\n\nA debug config [launch.json](.vscode/launch.json) is provided for example reference on how to run a test with the go/dlv debugger.\n", "release_dates": ["2023-07-17T23:30:04Z", "2023-07-12T18:50:44Z", "2023-07-12T14:55:23Z", "2023-07-11T23:55:51Z", "2023-06-01T16:51:03Z", "2023-05-24T13:25:50Z", "2023-05-23T20:39:35Z", "2023-04-20T18:47:53Z", "2023-04-18T18:03:38Z", "2023-03-24T18:16:30Z", "2023-03-17T17:53:45Z", "2023-03-13T13:44:05Z", "2023-03-01T05:20:29Z", "2023-02-22T15:04:09Z", "2023-02-13T22:09:00Z", "2023-02-10T17:43:48Z", "2023-02-07T05:52:14Z", "2023-01-18T00:17:40Z", "2023-01-12T18:59:09Z", "2023-01-17T19:35:31Z"]}, {"name": "throttled", "description": "Package throttled implements rate limiting access to resources such as HTTP endpoints.", "language": "Go", "license": {"key": "bsd-3-clause", "name": "BSD 3-Clause \"New\" or \"Revised\" License", "spdx_id": "BSD-3-Clause", "url": "https://api.github.com/licenses/bsd-3-clause", "node_id": "MDc6TGljZW5zZTU="}, "readme": "# Throttled [![build status](https://secure.travis-ci.org/throttled/throttled.svg)](https://travis-ci.org/throttled/throttled) [![GoDoc](https://godoc.org/github.com/throttled/throttled?status.svg)](https://godoc.org/github.com/throttled/throttled)\n\nPackage throttled implements rate limiting using the [generic cell rate\nalgorithm][gcra] to limit access to resources such as HTTP endpoints.\n\nThe 2.0.0 release made some major changes to the throttled API. If\nthis change broke your code in problematic ways or you wish a feature\nof the old API had been retained, please open an issue.  We don't\nguarantee any particular changes but would like to hear more about\nwhat our users need. Thanks!\n\n## Installation\n\n```sh\ngo get -u github.com/throttled/throttled\n```\n\n## Documentation\n\nAPI documentation is available on [godoc.org][doc]. The following\nexample demonstrates the usage of HTTPLimiter for rate-limiting access\nto an http.Handler to 20 requests per path per minute with bursts of\nup to 5 additional requests:\n\n```go\nstore, err := memstore.New(65536)\nif err != nil {\n\tlog.Fatal(err)\n}\n\nquota := throttled.RateQuota{throttled.PerMin(20), 5}\nrateLimiter, err := throttled.NewGCRARateLimiter(store, quota)\nif err != nil {\n\tlog.Fatal(err)\n}\n\nhttpRateLimiter := throttled.HTTPRateLimiter{\n\tRateLimiter: rateLimiter,\n\tVaryBy:      &throttled.VaryBy{Path: true},\n}\n\nhttp.ListenAndServe(\":8080\", httpRateLimiter.RateLimit(myHandler))\n```\n\n## Related Projects\n\nSee [throttled/gcra][throttled-gcra] for a list of other projects related to\nrate limiting and GCRA.\n\n## Release\n\n1. Update `CHANGELOG.md`. Please use semantic versioning and the existing\n   conventions established in the file. Commit the changes with a message like\n   `Bump version to 2.2.0`.\n2. Tag `master` with a new version prefixed with `v`. For example, `v2.2.0`.\n3. `git push origin master --tags`.\n4. Publish a new release on the [releases] page. Copy the body from the\n   contents of `CHANGELOG.md` for the version and follow other conventions from\n   previous releases.\n\n## License\n\nThe [BSD 3-clause license][bsd]. Copyright (c) 2014 Martin Angers and contributors.\n\n[blog]: http://0value.com/throttled--guardian-of-the-web-server\n[bsd]: https://opensource.org/licenses/BSD-3-Clause\n[doc]: https://godoc.org/github.com/throttled/throttled\n[gcra]: https://en.wikipedia.org/wiki/Generic_cell_rate_algorithm\n[puerkitobio]: https://github.com/puerkitobio/\n[pr]: https://github.com/throttled/throttled/compare\n[releases]: https://github.com/throttled/throttled/releases\n[throttled-gcra]: https://github.com/throttled/gcra\n\n<!--\n# vim: set tw=79:\n-->\n", "release_dates": []}, {"name": "tracy", "description": "C++ frame profiler", "language": "C++", "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "readme": "# Tracy Profiler\n\n[![Sponsor](.github/sponsor.png)](https://github.com/sponsors/wolfpld/)\n\n### A real time, nanosecond resolution, remote telemetry, hybrid frame and sampling profiler for games and other applications.\n\nTracy supports profiling CPU (Direct support is provided for C, C++, and Lua integration. At the same time, third-party bindings to many other languages exist on the internet, such as Rust, Zig, C#, OCaml, Odin, etc.), GPU (All major graphic APIs: OpenGL, Vulkan, Direct3D 11/12, OpenCL.), memory allocations, locks, context switches, automatically attribute screenshots to captured frames, and much more.\n\n- [Documentation](https://github.com/wolfpld/tracy/releases/latest/download/tracy.pdf) for usage and build process instructions\n- [Releases](https://github.com/wolfpld/tracy/releases) containing the documentation (`tracy.pdf`) and compiled Windows x64 binaries (`Tracy-<version>.7z`) as assets\n- [Changelog](NEWS)\n- [Interactive demo](https://tracy.nereid.pl/)\n\n![](doc/profiler.png)\n\n![](doc/profiler2.png)\n\n![](doc/profiler3.png)\n\n[Introduction to Tracy Profiler v0.2](https://www.youtube.com/watch?v=fB5B46lbapc)  \n[New features in Tracy Profiler v0.3](https://www.youtube.com/watch?v=3SXpDpDh2Uo)  \n[New features in Tracy Profiler v0.4](https://www.youtube.com/watch?v=eAkgkaO8B9o)  \n[New features in Tracy Profiler v0.5](https://www.youtube.com/watch?v=P6E7qLMmzTQ)  \n[New features in Tracy Profiler v0.6](https://www.youtube.com/watch?v=uJkrFgriuOo)  \n[New features in Tracy Profiler v0.7](https://www.youtube.com/watch?v=_hU7vw00MZ4)  \n[New features in Tracy Profiler v0.8](https://www.youtube.com/watch?v=30wpRpHTTag)\n", "release_dates": []}, {"name": "transaction-submitter", "description": "Stellar transaction submitter", "language": null, "license": null, "readme": "# transaction-submitter\nStellar transaction submitter\n", "release_dates": []}, {"name": "tweetnacl-js", "description": "Port of TweetNaCl cryptographic library to JavaScript", "language": "JavaScript", "license": null, "readme": "TweetNaCl.js\n============\n\nPort of [TweetNaCl](http://tweetnacl.cr.yp.to) / [NaCl](http://nacl.cr.yp.to/)\nto JavaScript for modern browsers and Node.js. Public domain.\n\n[![Build Status](https://travis-ci.org/dchest/tweetnacl-js.svg?branch=master)\n](https://travis-ci.org/dchest/tweetnacl-js)\n\n[Demo](https://dchest.github.io/tweetnacl-js/)\n\n**:warning: Beta version. The library is stable and API is frozen, however\nit has not been independently reviewed. If you can help reviewing it, please\n[contact me](mailto:dmitry@codingrobots.com).**\n\nDocumentation\n=============\n\n* [Overview](#overview)\n* [Installation](#installation)\n* [Usage](#usage)\n  * [Public-key authenticated encryption (box)](#public-key-authenticated-encryption-box)\n  * [Secret-key authenticated encryption (secretbox)](#secret-key-authenticated-encryption-secretbox)\n  * [Scalar multiplication](#scalar-multiplication)\n  * [Signatures](#signatures)\n  * [Hashing](#hashing)\n  * [Random bytes generation](#random-bytes-generation)\n  * [Constant-time comparison](#constant-time-comparison)\n  * [Utilities](#utilities)\n* [Examples](#examples)\n* [System requirements](#system-requirements)\n* [Development and testing](#development-and-testing)\n* [Contributors](#contributors)\n* [Who uses it](#who-uses-it)\n\n\nOverview\n--------\n\nThe primary goal of this project is to produce a translation of TweetNaCl to\nJavaScript which is as close as possible to the original C implementation, plus\na thin layer of idiomatic high-level API on top of it.\n\nThere are two versions, you can use either of them:\n\n* `nacl.js` is the port of TweetNaCl with minimum differences from the\n  original + high-level API.\n\n* `nacl-fast.js` is like `nacl.js`, but with some functions replaced with\n  faster versions.\n\n\nInstallation\n------------\n\nYou can install TweetNaCl.is via a package manager:\n\n[Bower](http://bower.io):\n\n    $ bower install tweetnacl\n\n[NPM](https://www.npmjs.org/):\n\n    $ npm install tweetnacl\n\nor [download source code](https://github.com/dchest/tweetnacl-js/releases).\n\n\nUsage\n------\n\nAll API functions accept and return bytes as `Uint8Array`s.  If you need to\nencode or decode strings, use functions from `nacl.util` namespace.\n\n### Public-key authenticated encryption (box)\n\nImplements *curve25519-xsalsa20-poly1305*.\n\n#### nacl.box.keyPair()\n\nGenerates a new random key pair for box and returns it as an object with\n`publicKey` and `secretKey` members:\n\n    {\n       publicKey: ...,  // Uint8Array with 32-byte public key\n       secretKey: ...   // Uint8Array with 32-byte secret key\n    }\n\n\n#### nacl.box.keyPair.fromSecretKey(secretKey)\n\nReturns a key pair for box with public key corresponding to the given secret\nkey.\n\n#### nacl.box(message, nonce, theirPublicKey, mySecretKey)\n\nEncrypt and authenticates message using peer's public key, our secret key, and\nthe given nonce, which must be unique for each distinct message for a key pair.\n\nReturns an encrypted and authenticated message, which is\n`nacl.box.overheadLength` longer than the original message.\n\n#### nacl.box.open(box, nonce, theirPublicKey, mySecretKey)\n\nAuthenticates and decrypts the given box with peer's public key, our secret\nkey, and the given nonce.\n\nReturns the original message, or `false` if authentication fails.\n\n#### nacl.box.before(theirPublicKey, mySecretKey)\n\nReturns a precomputed shared key which can be used in `nacl.box.after` and\n`nacl.box.open.after`.\n\n#### nacl.box.after(message, nonce, sharedKey)\n\nSame as `nacl.box`, but uses a shared key precomputed with `nacl.box.before`.\n\n#### nacl.box.open.after(box, nonce, sharedKey)\n\nSame as `nacl.box.open`, but uses a shared key precomputed with `nacl.box.before`.\n\n#### nacl.box.publicKeyLength = 32\n\nLength of public key in bytes.\n\n#### nacl.box.secretKeyLength = 32\n\nLength of secret key in bytes.\n\n#### nacl.box.sharedKeyLength = 32\n\nLength of precomputed shared key in bytes.\n\n#### nacl.box.nonceLength = 24\n\nLength of nonce in bytes.\n\n#### nacl.box.overheadLength = 16\n\nLength of overhead added to box compared to original message.\n\n\n### Secret-key authenticated encryption (secretbox)\n\nImplements *xsalsa20-poly1305*.\n\n#### nacl.secretbox(message, nonce, key)\n\nEncrypt and authenticates message using the key and the nonce. The nonce must\nbe unique for each distinct message for this key.\n\nReturns an encrypted and authenticated message, which is\n`nacl.secretbox.overheadLength` longer than the original message.\n\n#### nacl.secretbox.open(box, nonce, key)\n\nAuthenticates and decrypts the given secret box using the key and the nonce.\n\nReturns the original message, or `false` if authentication fails.\n\n#### nacl.secretbox.keyLength = 32\n\nLength of key in bytes.\n\n#### nacl.secretbox.nonceLength = 24\n\nLength of nonce in bytes.\n\n#### nacl.secretbox.overheadLength = 16\n\nLength of overhead added to secret box compared to original message.\n\n\n### Scalar multiplication\n\nImplements *curve25519*.\n\n#### nacl.scalarMult(n, p)\n\nMultiplies an integer `n` by a group element `p` and returns the resulting\ngroup element.\n\n#### nacl.scalarMult.base(n)\n\nMultiplies an integer `n` by a standard group element and returns the resulting\ngroup element.\n\n#### nacl.scalarMult.scalarLength = 32\n\nLength of scalar in bytes.\n\n#### nacl.scalarMult.groupElementLength = 32\n\nLength of group element in bytes.\n\n\n### Signatures\n\nImplements [ed25519](http://ed25519.cr.yp.to).\n\n#### nacl.sign.keyPair()\n\nGenerates new random key pair for signing and returns it as an object with\n`publicKey` and `secretKey` members:\n\n    {\n       publicKey: ...,  // Uint8Array with 32-byte public key\n       secretKey: ...   // Uint8Array with 64-byte secret key\n    }\n\n#### nacl.sign.keyPair.fromSecretKey(secretKey)\n\nReturns a signing key pair with public key corresponding to the given\n64-byte secret key. The secret key must have been generated by\n`nacl.sign.keyPair` or `nacl.sign.keyPair.fromSeed`.\n\n#### nacl.sign.keyPair.fromSeed(seed)\n\nReturns a new signing key pair generated deterministically from a 32-byte seed.\nThe seed must contain enough entropy to be secure. This method is not\nrecommended for general use: instead, use `nacl.sign.keyPair` to generate a new\nkey pair from a random seed.\n\n#### nacl.sign(message, secretKey)\n\nSigns the message using the secret key and returns a signed message.\n\n#### nacl.sign.open(signedMessage, publicKey)\n\nVerifies the signed message and returns the message without signature.\n\nReturns `null` if verification failed.\n\n#### nacl.sign.detached(message, secretKey)\n\nSigns the message using the secret key and returns a signature.\n\n#### nacl.sign.detached.verify(message, signature, publicKey)\n\nVerifies the signature for the message and returns `true` if verification\nsucceeded or `false` if it failed.\n\n#### nacl.sign.publicKeyLength = 32\n\nLength of signing public key in bytes.\n\n#### nacl.sign.secretKeyLength = 64\n\nLength of signing secret key in bytes.\n\n#### nacl.sign.seedLength = 32\n\nLength of seed for `nacl.sign.keyPair.fromSeed` in bytes.\n\n#### nacl.sign.signatureLength = 64\n\nLength of signature in bytes.\n\n\n### Hashing\n\nImplements *SHA-512*.\n\n#### nacl.hash(message)\n\nReturns SHA-512 hash of the message.\n\n#### nacl.hash.hashLength = 64\n\nLength of hash in bytes.\n\n\n### Random bytes generation\n\n#### nacl.randomBytes(length)\n\nReturns a `Uint8Array` of the given length containing random bytes of\ncryptographic quality.\n\n**Implementation note**\n\nTweetNaCl.js uses the following methods to generate random bytes,\ndepending on the platform it runs on:\n\n* `window.crypto.getRandomValues` (WebCrypto standard)\n* `window.msCrypto.getRandomValues` (Internet Explorer 11)\n* `crypto.randomBytes` (Node.js)\n\nNote that browsers are required to throw `QuotaExceededError` exception if\nrequested `length` is more than 65536, so do not ask for more than 65536 bytes\nin *one call* (multiple calls to get as many bytes as you like are okay:\nbrowsers can generate infinite amount of random bytes without any bad\nconsequences).\n\nIf the platform doesn't provide a suitable PRNG, the following functions,\nwhich require random numbers, will throw exception:\n\n* `nacl.randomBytes`\n* `nacl.box.keyPair`\n* `nacl.sign.keyPair`\n\nOther functions are deterministic and will continue working.\n\nIf a platform you are targeting doesn't implement secure random number\ngenerator, but you somehow have a cryptographically-strong source of entropy\n(not `Math.random`!), and you know what you are doing, you can plug it into\nTweetNaCl.js like this:\n\n    nacl.setPRNG(function(x, n) {\n      // ... copy n random bytes into x ...\n    });\n\nNote that `nacl.setPRNG` *completely replaces* internal random byte generator\nwith the one provided.\n\n\n### Constant-time comparison\n\n#### nacl.verify(x, y)\n\nCompares `x` and `y` in constant time and returns `true` if their lengths are\nnon-zero and equal, and their contents are equal.\n\nReturns `false` if either of the arguments has zero length, or arguments have\ndifferent lengths, or their contents differ.\n\n\n### Utilities\n\nEncoding/decoding functions are provided for convenience. They are correct,\nhowever their performance and wide compatibility with uncommon runtimes is not\nsomething that is considered important compared to the simplicity and size of\nimplementation. You can use third-party libraries if you need to.\n\n#### nacl.util.decodeUTF8(string)\n\nDecodes string and returns `Uint8Array` of bytes.\n\n#### nacl.util.encodeUTF8(array)\n\nEncodes `Uint8Array` or `Array` of bytes into string.\n\n#### nacl.util.decodeBase64(string)\n\nDecodes Base-64 encoded string and returns `Uint8Array` of bytes.\n\n#### nacl.util.encodeBase64(array)\n\nEncodes `Uint8Array` or `Array` of bytes into string using Base-64 encoding.\n\n\nSystem requirements\n-------------------\n\nTweetNaCl.js supports modern browsers that have a cryptographically secure\npseudorandom number generator and typed arrays, including the latest versions\nof:\n\n* Chrome\n* Firefox\n* Safari (Mac, iOS)\n* Internet Explorer 11\n\nOther systems:\n\n* Node.js (we test on 0.10 and later)\n\n\nDevelopment and testing\n------------------------\n\nInstall NPM modules needed for development:\n\n    $ npm install\n\nTo build minified versions:\n\n    $ npm run build\n\nTests use minified version, so make sure to rebuild it every time you change\n`nacl.js` or `nacl-fast.js`.\n\n### Testing\n\nTo run tests in Node.js:\n\n    $ npm test\n\nBy default all tests described here work on `nacl.min.js`. To test other\nversions, set environment variable `NACL_SRC` to the file name you want to test.\nFor example, the following command will test fast minified version:\n\n    $ NACL_SRC=nacl-fast.min.js npm test\n\nTo run full suite of tests in Node.hs, including comparing outputs of\nJavaScript port to outputs of the original C version:\n\n    $ npm run testall\n\nTo prepare tests for browsers:\n\n    $ npm run browser\n\nand then open `tests/browser/test.html` (or `tests/browser/test-fast.html`) to\nrun them.\n\nTo run headless browser tests with `testling`:\n\n    $ npm run testling\n\n(If you get `Error: spawn ENOENT`, install *xvfb*: `sudo apt-get install xvfb`.)\n\n### Benchmarking\n\nTo run benchmarks in Node.js:\n\n    $ npm run bench\n    $ NACL_SRC=nacl-fast.min.js npm run bench\n\nTo run benchmarks in a browser, open `test/benchmark/bench.html` (or\n`test/benchmark/bench-fast.html`).\n\n\nContributors\n------------\n\nJavaScript port:\n\n * [Dmitry Chestnykh](http://github.com/dchest) (ported xsalsa20, poly1305, curve25519)\n * [Devi Mandiri](https://github.com/devi) (ported curve25519, ed25519, sha512)\n\nOriginal authors of [NaCl](http://nacl.cr.yp.to), [TweetNaCl](http://tweetnacl.cr.yp.to)\nand [Poly1305-donna](https://github.com/floodyberry/poly1305-donna)\n(who are *not* responsible for any errors in this implementation):\n\n  * [Daniel J. Bernstein](http://cr.yp.to/djb.html)\n  * Wesley Janssen\n  * [Tanja Lange](http://hyperelliptic.org/tanja)\n  * [Peter Schwabe](http://www.cryptojedi.org/users/peter/)\n  * [Matthew Dempsky](https://github.com/mdempsky)\n  * [Andrew Moon](https://github.com/floodyberry)\n\nContributors have dedicated their work to the public domain.\n\nThis software is distributed without any warranty.\n\n\nWho uses it\n-----------\n\nSome notable users of TweetNaCl.js:\n\n* [miniLock](http://minilock.io/)\n* [Stellar](https://www.stellar.org/)\n", "release_dates": []}, {"name": "typescript-wallet-sdk", "description": "Typescript Wallet SDK to build Stellar wallets", "language": "TypeScript", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Stellar Typescript Wallet SDK [![npm version](https://badge.fury.io/js/@stellar%2Ftypescript-wallet-sdk.svg)](https://badge.fury.io/js/@stellar%2Ftypescript-wallet-sdk)\n\nTypescript Wallet SDK is a library that allows developers to build wallet\napplications on the Stellar network faster. It utilizes\n[Javascript Stellar SDK](https://github.com/stellar/js-stellar-sdk) to\ncommunicate with a Stellar Horizon server.  \nIt offers wide range of functionality to simplify integration with the Stellar\nnetwork, and connect to the anchors easily, utilizing various Stellar protocols\n(SEPs)\n\n## Dependency\n\nThe library is available via npm. To import `typescript-wallet-sdk` library you\nneed to add it as a dependency to your code:\n\nyarn:\n\n```shell\nyarn add @stellar/typescript-wallet-sdk\n```\n\nnpm:\n\n```shell\nnpm install @stellar/typescript-wallet-sdk\n```\n\n## Introduction\n\nHere's a small example creating main wallet class with default configuration\nconnected to testnet network:\n\n```typescript\nlet wallet = walletSdk.Wallet.TestNet();\n```\n\nIt should later be re-used across the code, as it has access to various useful\nchildren classes. For example, you can authenticate with the `testanchor` as\nsimple as:\n\n```typescript\nconst authKey = SigningKeypair.fromSecret(\"my secret key\");\nconst anchor = wallet.anchor({ homeDomain: \"testanchor.stellar.org\" });\nconst sep10 = await anchor.sep10();\n\nconst authToken = await sep10.authenticate({ accountKp: authKey });\n```\n\nRead\n[full wallet guide](https://developers.stellar.org/docs/category/build-a-wallet-with-the-wallet-sdk)\nfor more info\n", "release_dates": ["2024-01-11T21:31:58Z", "2024-01-09T00:19:38Z", "2023-10-04T21:32:50Z", "2023-09-22T16:20:05Z", "2023-09-20T22:27:33Z", "2023-09-12T18:36:50Z", "2023-09-12T18:39:55Z", "2023-08-21T18:16:03Z", "2023-08-01T21:40:34Z"]}, {"name": "wasmi", "description": "WebAssembly (Wasm) interpreter.", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# soroban-wasmi\n\nThis is a fork of https://github.com/paritytech/wasmi with a small set of local\npatches applied for customizing interaction with https://soroban.stellar.org\n\nIt may be abandoned at some point if Soroban is able to meet its needs strictly\nwith upstream interfaces. The fork was for expedience during development.\n\nOther projects should not use it, and should use upstream instead.\n\nThe Parity authors have been removed from the Cargo.toml metadata to avoid the\nimplication that this fork is their responsibility or action, and to emphasize\nthat users should not bother the Parity authors with support requests for this\ncrate.\n\nThis crate was still entirely (with the exception of a couple small patches)\nwritten by Parity Technologies, and their copyright notices are maintained.\n\n## License\n\n`wasmi` is primarily distributed under the terms of both the MIT\nlicense and the APACHE license (Version 2.0), at your choice.\n\nSee `LICENSE-APACHE` and `LICENSE-MIT` for details.\n\n", "release_dates": ["2024-01-24T01:13:27Z", "2023-12-01T23:24:58Z", "2023-09-12T02:26:24Z", "2023-06-26T22:28:46Z", "2022-11-29T23:54:02Z", "2022-10-06T15:49:52Z", "2022-10-05T20:18:15Z", "2022-10-05T20:19:10Z"]}, {"name": "xdrgen", "description": "A code generator for XDR", "language": "Rust", "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "readme": "# Xdrgen\n\n[![Build Status](https://travis-ci.org/stellar/xdrgen.svg)](https://travis-ci.org/stellar/xdrgen)\n[![Code Climate](https://codeclimate.com/github/stellar/xdrgen/badges/gpa.svg)](https://codeclimate.com/github/stellar/xdrgen)\n\n`xdrgen` is a code generator that takes XDR IDL files (`.x` files) as specified\nin [RFC 4506](http://tools.ietf.org/html/rfc4506.html) and spits code out in\nvarious languages.\n\n`xdrgen` requires ruby 2.1 or later to run.\n\n## Status\n\nXdrgen is a very early project.  Aside from the test fixtures in\n[spec/fixtures](spec/fixtures), the only .x files that have been thrown at it\nare the .x files used for the\n[stellar-core project](https://github.com/stellar/stellar-core).\n\nXdrgen presently supports these output languages: ruby, javacript, java,\ngolang, elixir and Python:\n\n- ruby: complete support\n- javascript: complete support\n- java: complete support\n- golang: currently using a fork of go-xdr, but has complete support\n- rust: support is experimental. Default arms and floats are not supported.\n- elixir: support is experimental as the SDK is in early development. Generated\n  code requires [:exdr](https://github.com/revelrylabs/exdr) in your deps\n- C#: complete support\n- Python: complete support\n  \nTesting is _very_ sparse, but will improve over time.\n\n## Usage as a binary\n\nXdrgen is a rubygem, compatible with ruby 2.1 or higher\n\n    $ gem install xdrgen\n\nThe command line:\n\n`xdrgen [-o OUTPUT_DIR] [-l LANGUAGE] [-n NAMESPACE] [INPUT_FILES ...]`\n\n### Language Specific Options\n\n### Rust\n\n`--rust-types-custom-str-impl`: Used to specify a comma-separated list of type names that should not have string conversion code generated as it will be provided by custom implementations provided by the developer using the generated code.\n\n## Usage as a library\n\nAdd this line to your application's Gemfile:\n\n```ruby\ngem 'xdrgen'\n```\n\nAnd then execute:\n\n    $ bundle\n\nExample usage:\n\n```ruby\nrequire 'xdrgen'\n\n# create a compilation object, specifying your options\n\nc = Xdrgen::Compilation.new(\n  [\"MyProgram.x\"],\n  output_dir:\"src/generated\",\n  language: :ruby,\n  namespace: \"MyProgram::XDR\",\n  options: {\n    rust_types_custom_str_impl: [],\n  },\n)\n\n# then run compile\n\nc.compile\n\n```\n\n## Contributing\n\n1. Fork it ( https://github.com/[my-github-username]/xdrgen/fork )\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create a new Pull Request\n", "release_dates": []}]